<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 33]
- [cs.RO](#cs.RO) [Total: 28]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型（LLM）的智能系统，用于工业机械的预测性维护，结合振动频率分析和多代理生成技术，提供可操作的维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需要及时干预以防止灾难性故障并优化运行效率，传统方法仅能检测异常，缺乏具体维护建议。

Method: 系统将轴承振动数据（BPFO、BPFI等）转化为自然语言供LLM处理，结合多代理技术分析维护手册和网络信息，生成结构化维护建议。

Result: 实验验证表明，系统能有效检测异常并提供上下文相关的维护指导，填补了状态监测与可操作维护计划之间的空白。

Conclusion: 该研究推动了LLM在工业维护中的应用，为跨行业机械组件提供可扩展的预测性维护框架。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [2] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow是一种自动生成地理空间任务代理工作流的方法，通过明确工具调用目标提升代理成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在推理分解上表现不足，且API选择隐含，GeoFlow旨在通过明确目标改进代理性能。

Method: 为每个代理提供详细的工具调用目标，指导运行时地理空间API的调用。

Result: GeoFlow将代理成功率提升6.8%，并在主流LLM家族中减少高达四倍的token使用。

Conclusion: GeoFlow通过明确工具调用目标，显著提升了代理工作流的效率和成功率。

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [3] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 论文提出了一种基于对抗性棋盘游戏的LLM评估框架，通过比赛和情感评分全面评估LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 弥补主流问答基准方法的数据依赖性限制，通过对抗性环境更全面地评估LLM的战略推理和适应能力。

Method: 开发Qi Town平台，支持5种游戏和20个LLM玩家，使用Elo评分和PLG定量评估技术能力，并通过PSS评估心理适应性。

Result: 实验显示LLM在高压对抗环境中表现乐观且适应性强，但PLG揭示了技能发挥的不稳定性。

Conclusion: 对抗性棋盘游戏是评估LLM的有效方法，但需进一步研究其技能不稳定性的原因。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [4] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 比较三种AWebGIS方法，发现基于客户端小型语言模型（SLM）的方法在精度和隐私保护上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决现有AWebGIS依赖云端LLM导致的隐私和可扩展性问题。

Method: 比较三种方法：云端LLM、离线经典机器学习、客户端SLM。

Result: 客户端SLM方法精度最高（准确率0.93），并减少服务器负载。

Conclusion: 浏览器可执行模型在AWebGIS中具有可行性。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [5] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 研究发现强化学习（RL）在非理想场景下对大型语言模型（LLMs）推理能力的提升有限，揭示了当前方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试多关注理想化场景，忽略了实际应用中非理想场景的性能，研究旨在填补这一空白。

Method: 通过RL微调LLMs和大型视觉语言模型（LVLM），并在三种非理想场景（摘要推理、细粒度噪声抑制、上下文过滤）下测试性能。

Result: RL微调在理想场景下提升推理能力，但在非理想场景中性能显著下降，现有方法未能有效解决这些缺陷。

Conclusion: 大型模型的推理能力常被高估，需在非理想场景下评估，当前方法仍需改进。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [6] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: HealthFlow是一种自进化的AI代理，通过元级进化机制提升战略规划能力，显著优于现有框架。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理依赖静态策略，无法在复杂领域（如医疗）中成为更好的战略规划者。

Method: 引入HealthFlow和EHRFlowBench基准，通过提炼成功与失败经验自主优化策略。

Result: 实验表明HealthFlow显著优于现有代理框架。

Conclusion: 该研究标志着从工具使用者转向自进化任务管理者的重要转变，推动更自主的AI科学发展。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [7] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 提出了一种基于博弈论的新型分子对接框架（Docking Game），通过LoopPlay算法显著提升了配体对接的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有分子对接模型在配体对接中表现不佳，主要由于配体和蛋白质的结构复杂性差异。

Method: 将蛋白-配体交互建模为双玩家博弈，开发了LoopPlay算法，通过内外循环交替训练玩家模块。

Result: 实验显示LoopPlay在预测结合模式上比现有方法提升约10%。

Conclusion: 该框架有望提升药物发现中分子对接的准确性。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [8] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: 研究探讨了利用大语言模型（LLMs）整合城市空间数据的潜力，发现其在提供相关特征时表现优异，但空间推理能力有限。


<details>
  <summary>Details</summary>
Motivation: 传统规则方法和机器学习在整合异构、噪声空间数据时存在不足，LLMs可能提供更灵活的解决方案。

Method: 分析LLMs的空间推理能力，提出基于特征增强和“审查-优化”方法的改进策略。

Result: LLMs在减少空间推理依赖时表现良好，但需辅助方法修正初始错误。

Conclusion: LLMs是传统规则方法的有效替代，未来可结合多模态和多样化数据支持进一步研究。

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [9] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 论文提出了一种结合离线模仿学习和在线探索的Web导航智能体框架CogniWeb，通过双系统认知理论实现高效决策。


<details>
  <summary>Details</summary>
Motivation: Web导航是评估通用人工智能（AGI）的关键领域，但现有方法未能有效整合离线学习和在线探索。

Method: 基于人类认知的双系统理论，将智能体行为分解为快速直觉（System 1）和慢速推理（System 2），并实现为模块化架构CogniWeb。

Result: 在WebArena测试中，CogniWeb取得了43.96%的成功率，同时显著提高了效率（令牌使用减少75%）。

Conclusion: CogniWeb通过双系统理论有效整合了离线与在线学习，为Web导航智能体提供了高效且性能优越的解决方案。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [10] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: MedMKEB是首个针对医学多模态大语言模型知识编辑的综合性基准，评估可靠性、通用性、局部性、可移植性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 医学知识不断更新，现有模型需高效修正过时或错误信息，但缺乏系统性多模态医学知识编辑基准。

Method: 基于高质量医学视觉问答数据集，构建包括反事实修正、语义泛化、知识迁移和对抗鲁棒性等编辑任务，并引入专家验证。

Result: 实验表明现有知识编辑方法在医学领域存在局限性，需开发专门策略。

Conclusion: MedMKEB将作为标准基准，推动可信赖且高效的医学知识编辑算法发展。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [11] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize是一个基于Qwen3-8B模型的轻量级门尺寸优化框架，通过动态构建任务特定损失函数和结合全局与局部优化方法，显著减少模拟电路设计中对人力和计算资源的依赖。


<details>
  <summary>Details</summary>
Motivation: 模拟电路设计耗时且依赖经验，现有AI方法通用性差且计算资源消耗大。EasySize旨在解决这些问题，提供一种轻量级、通用的门尺寸优化方案。

Method: EasySize基于微调的Qwen3-8B模型，利用性能指标的易达性（EOA）动态构建损失函数，结合全局差分进化（DE）和局部粒子群优化（PSO）进行高效搜索。

Result: EasySize在多个工艺节点（180nm、45nm、22nm）上表现优异，优于AutoCkt框架，节省了96.67%的仿真资源。

Conclusion: EasySize显著减少了模拟电路设计中对人力和计算资源的依赖，有望加速和简化设计流程。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [12] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 论文探讨生成式AI在高等教育中的核心作用，通过实验验证苏格拉底式AI导师对学生批判性思维的促进作用，并提出多智能体系统的教育应用框架。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正成为高等教育的基础设施，但对其是否导致学生能力退化的担忧存在。研究旨在验证AI能否通过结构化对话促进学生批判性思维。

Method: 研究采用对照实验，65名德国师范生分别与苏格拉底式AI导师和普通AI聊天机器人互动，评估其对批判性思维的支持效果。

Result: 使用苏格拉底式AI导师的学生在批判性、独立性和反思性思维方面表现显著更好，证明AI对话能促进元认知参与。

Conclusion: 研究提出多智能体系统（MAS）的教育应用框架，强调AI与人类协作的混合学习生态系统，并分析其成本效益和制度影响。

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [13] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 本文提出了一种基于异构图神经网络的模型，用于修复过程挖掘中事件日志的缺失属性，相比现有方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的事件日志常因数据采集问题导致信息缺失，传统方法依赖过程模型或机器学习，而图神经网络能更自然地处理复杂多模态序列。

Method: 开发了一种异构图神经网络模型，用于修复事件日志中的缺失属性，并在合成和真实日志上进行了评估。

Result: 该方法在修复所有事件属性方面表现优异，优于现有的无模型方法。

Conclusion: 异构图神经网络为事件日志修复提供了更高效和全面的解决方案。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [14] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: QA-Dragon是一种动态检索增强生成系统，通过多模态和多跳推理提升复杂视觉问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法仅从文本或图像中检索，无法处理需要多跳推理或最新知识的复杂查询。

Method: QA-Dragon引入领域路由器和搜索路由器，动态选择检索策略，支持多模态、多轮和多跳推理。

Result: 在KDD Cup 2025的Meta CRAG-MM挑战中，QA-Dragon显著提升性能，单源、多源和多轮任务分别优于基线5.06%、6.35%和5.03%。

Conclusion: QA-Dragon通过动态检索策略有效解决了复杂VQA任务中的知识获取和推理问题。

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [15] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 提出了一种结合RDF图数据库和LLM的新框架，用于精准目标受众定位和透明推理，以解决大规模维护组织中的通信管理问题。


<details>
  <summary>Details</summary>
Motivation: 传统通信方法无法有效应对信息过载和响应时间长的问题，特别是在复杂的实体关系中识别专家和管理通信。

Method: 采用RDF图数据库与LLM结合的方法，通过自然语言查询实现精准受众定位，并通过规划-编排架构提供透明推理。

Result: 解决方案允许通信所有者通过直观查询组合多种概念，提供可解释的结果，提高组织通信效率并保持系统信任。

Conclusion: 该框架有效解决了大规模维护组织中的通信挑战，同时提升了透明度和效率。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [16] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种混合架构，将决策树符号推理与大型语言模型（LLM）生成能力结合，通过多智能体框架实现协调推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法松散结合符号与神经模块，缺乏统一性。本文旨在通过嵌入决策树和随机森林作为可调用预言机，构建更紧密的推理系统。

Method: 设计了一个中央协调器，维护信念状态一致性，并协调符号模块（决策树）与LLM智能体的交互，支持结构化与非结构化输入推理。

Result: 在ProofWriter、GSM8k和ARC等基准测试中表现优异，分别提升7.2%、5.3%和6.0%的准确率。

Conclusion: 该架构为通用神经符号推理提供了可解释、可扩展的解决方案，适用于临床决策和科学发现等领域。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [17] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: 论文主张重新定义AI中的'agent'一词，提出多维框架以明确其最低要求，并建议标准化术语以提升研究清晰度和政策制定效果。


<details>
  <summary>Details</summary>
Motivation: AI中'agent'一词的多义性导致研究交流、系统评估和政策制定的困难，需重新定义以解决这些问题。

Method: 通过历史分析和当代使用模式，提出多维框架定义'agent'的最低要求，涵盖环境交互、学习与适应、自主性、目标复杂性和时间一致性。

Result: 框架为系统描述提供精确词汇，同时保留术语的多面性，并提出术语标准化和框架采纳的具体建议。

Conclusion: 该框架有助于提升研究清晰度和可重复性，支持更有效的政策制定。

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [18] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: 论文介绍了NomicLaw，一个多智能体模拟系统，用于研究LLMs在法律和伦理困境中的协作立法行为，揭示了LLMs的社会推理和说服能力。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在开放多智能体环境中处理法律和伦理问题的行为，填补现有研究的空白。

Method: 通过NomicLaw模拟，LLMs协作制定法律规则，提出、论证并投票表决提案，定量分析信任与互惠，定性评估策略语言使用。

Result: 实验显示LLMs能自发形成联盟、背叛信任并调整修辞以影响决策，展示了其社会推理和说服能力。

Conclusion: 研究揭示了LLMs在自主协商和立法中的潜力，为未来AI系统设计提供了参考。

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [19] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [20] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: StructVRM通过结构化可验证奖励模型提升多模态模型在复杂推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统奖励机制对复杂多问题推理任务的支持不足，无法提供细粒度反馈。

Method: 提出StructVRM方法，使用模型验证器提供子问题级别的细粒度反馈，评估语义和数学等价性。

Result: Seed-StructVRM在12个多模态基准测试中6个表现最佳，并在新STEM-Bench上取得优异结果。

Conclusion: 结构化可验证奖励训练是提升多模态模型复杂推理能力的有效方法。

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [21] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 本文提出了一种实时数据驱动的智能交通系统预测性维护方法，通过在线处理流程实现高精度故障预测，并首次结合自然语言和视觉解释。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统的预测性维护对确保高服务可用性和安全性至关重要，但现有方法缺乏实时性和解释性。

Method: 采用包含样本预处理、增量分类和结果解释的在线处理流程，结合统计和频率特征提取以及解释性模块。

Result: 实验结果显示F-measure超过98%，准确率达99%，且在类不平衡和噪声情况下保持高性能。

Conclusion: 该方法验证了其方法论的稳健性和实际适用性，能够支持铁路运营中的主动维护决策。

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [22] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: DeepPHY是一个新的基准框架，用于评估视觉语言模型（VLMs）对物理原理的理解和推理能力，发现现有模型在将描述性物理知识转化为精确预测控制方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: VLMs在复杂动态环境中缺乏细节关注和精确行动规划能力，现有评估方法成本高昂，因此需要一种系统化的评估框架。

Method: 提出DeepPHY框架，通过多难度物理推理环境和细粒度评估指标，系统测试VLMs的物理理解能力。

Result: 评估显示，即使是先进的VLMs也难以将物理知识转化为精确的预测控制。

Conclusion: DeepPHY为VLMs的物理推理能力提供了标准化评估工具，揭示了现有模型的局限性。

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [23] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: LLMs正在改变有机合成化学家的实验方式，结合图神经网络、量子计算和实时光谱技术，加速发现周期并推动绿色化学。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs如何从理论工具发展为实用的实验室助手，推动分子创新的快速、可靠和包容性发展。

Method: 结合LLMs与图神经网络、量子计算和实时光谱技术，优化合成路线预测和实验执行。

Result: LLMs显著缩短了发现周期，支持数据驱动的绿色化学，但仍存在数据集偏见和安全性问题。

Conclusion: 通过开放基准、联邦学习和可解释界面等社区倡议，确保人类控制下的人工智能和自动化分子创新。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


### [24] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
*Krzysztof Janowicz,Zilong Liu,Gengchen Mai,Zhangyu Wang,Ivan Majic,Alexandra Fortacz,Grant McKenzie,Song Gao*

Main category: cs.AI

TL;DR: 本文探讨了AI对齐中的地理差异问题，强调需根据地域文化、政治和法律差异调整对齐措施，避免一刀切方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI对齐研究忽视地理多样性，导致模型输出可能与实际统计或地域规范不符，亟需解决。

Method: 回顾关键地理研究问题，提出未来研究方向，并设计评估对齐敏感性的方法。

Result: 指出AI对齐需考虑时空背景，避免一刀切，部分模型输出需根据用户地理位置调整。

Conclusion: 呼吁开发时空感知的对齐方法，以适应全球化AI应用中的地域多样性。

Abstract: AI (super) alignment describes the challenge of ensuring (future) AI systems
behave in accordance with societal norms and goals. While a quickly evolving
literature is addressing biases and inequalities, the geographic variability of
alignment remains underexplored. Simply put, what is considered appropriate,
truthful, or legal can differ widely across regions due to cultural norms,
political realities, and legislation. Alignment measures applied to AI/ML
workflows can sometimes produce outcomes that diverge from statistical
realities, such as text-to-image models depicting balanced gender ratios in
company leadership despite existing imbalances. Crucially, some model outputs
are globally acceptable, while others, e.g., questions about Kashmir, depend on
knowing the user's location and their context. This geographic sensitivity is
not new. For instance, Google Maps renders Kashmir's borders differently based
on user location. What is new is the unprecedented scale and automation with
which AI now mediates knowledge, expresses opinions, and represents geographic
reality to millions of users worldwide, often with little transparency about
how context is managed. As we approach Agentic AI, the need for
spatio-temporally aware alignment, rather than one-size-fits-all approaches, is
increasingly urgent. This paper reviews key geographic research problems,
suggests topics for future work, and outlines methods for assessing alignment
sensitivity.

</details>


### [25] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 研究提出Bench-2-CoP框架，量化AI评估基准与欧盟AI法案间的差距，发现当前评估过度关注行为倾向，而忽视关键功能能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI评估基准无法满足欧盟AI法案对系统性风险的关注，亟需量化这一差距。

Method: 使用LLM-as-judge分析，将194,955个基准问题映射到欧盟AI法案的能力分类中。

Result: 评估生态严重偏向行为倾向（如幻觉倾向占53.7%），关键功能能力（如自主AI开发）完全未覆盖。

Conclusion: 研究为政策制定者和开发者提供了改进评估工具的关键依据，以促进更安全合规的AI。

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [26] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 使用小型、高效的通用LLM生成多样化的ERC数据集，补充现有基准，提升分类性能并分析标签不平衡影响。


<details>
  <summary>Details</summary>
Motivation: 解决ERC数据稀缺、来源偏见和标签主观性问题，探索LLM在数据生成中的应用。

Method: 利用小型通用LLM生成六个新数据集，补充三个主流ERC基准，评估其在分类和标签不平衡分析中的效果。

Result: 生成的显著提升了ERC分类器的鲁棒性，并在现有基准上实现了统计显著的性能改进。

Conclusion: 小型LLM生成的数据集能有效补充ERC任务，提升模型性能并解决数据不足问题。

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


### [27] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
*Shuo Cai,Su Lu,Qi Zhou,Kejing Yang,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAlign是一个可扩展且样本高效的后训练框架，结合监督微调（SFT）和直接偏好优化（DPO）来提升大语言模型（LLMs）的推理能力。其核心是一个自动筛选高质量数据的数据选择管道，显著减少数据需求并提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在复杂任务上表现出强大的推理能力，但后训练过程通常需要大量数据和计算资源。现有方法依赖启发式或任务特定策略，难以扩展。

Method: InfiAlign框架结合SFT和DPO，通过多维质量指标自动筛选开源推理数据集中的高质量对齐数据。

Result: 在Qwen2.5-Math-7B-Base模型上，仅使用12%的训练数据即达到与DeepSeek-R1-Distill-Qwen-7B相当的性能，并在数学推理任务中平均提升3.89%。

Conclusion: InfiAlign通过结合数据选择和全阶段后训练，提供了一种可扩展且数据高效的对齐大推理模型的实用解决方案。

Abstract: Large language models (LLMs) have exhibited impressive reasoning abilities on
a wide range of complex tasks. However, enhancing these capabilities through
post-training remains resource intensive, particularly in terms of data and
computational cost. Although recent efforts have sought to improve sample
efficiency through selective data curation, existing methods often rely on
heuristic or task-specific strategies that hinder scalability. In this work, we
introduce InfiAlign, a scalable and sample-efficient post-training framework
that integrates supervised fine-tuning (SFT) with Direct Preference
Optimization (DPO) to align LLMs for enhanced reasoning. At the core of
InfiAlign is a robust data selection pipeline that automatically curates
high-quality alignment data from open-source reasoning datasets using
multidimensional quality metrics. This pipeline enables significant performance
gains while drastically reducing data requirements and remains extensible to
new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model
achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only
approximately 12% of the training data, and demonstrates strong generalization
across diverse reasoning tasks. Additional improvements are obtained through
the application of DPO, with particularly notable gains in mathematical
reasoning tasks. The model achieves an average improvement of 3.89% on AIME
24/25 benchmarks. Our results highlight the effectiveness of combining
principled data selection with full-stage post-training, offering a practical
solution for aligning large reasoning models in a scalable and data-efficient
manner. The model checkpoints are available at
https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.

</details>


### [28] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.AI

TL;DR: GRAIL框架通过结合LLM引导的随机探索和路径过滤，解决了现有RAG方法在处理结构化知识（如知识图谱）时的局限性，显著提升了推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要针对非结构化数据，对结构化知识（如知识图谱）处理能力有限，且当前图谱检索方法难以捕捉整体结构并控制精度。

Method: GRAIL框架通过LLM引导的随机探索和路径过滤生成推理轨迹，采用两阶段训练学习动态决策策略，并通过过程监督奖励平衡检索精度与简洁性。

Result: 在三个知识图谱问答数据集上，GRAIL平均准确率提升21.01%，F1值提升22.43%。

Conclusion: GRAIL通过交互式检索范式，显著提升了图谱检索的推理性能，为结构化知识处理提供了有效解决方案。

Abstract: Large Language Models (LLMs) integrated with Retrieval-Augmented Generation
(RAG) techniques have exhibited remarkable performance across a wide range of
domains. However, existing RAG approaches primarily operate on unstructured
data and demonstrate limited capability in handling structured knowledge such
as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally
struggle to capture holistic graph structures while simultaneously facing
precision control challenges that manifest as either critical information gaps
or excessive redundant connections, collectively undermining reasoning
performance. To address this challenge, we propose GRAIL: Graph-Retrieval
Augmented Interactive Learning, a framework designed to interact with
large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL
integrates LLM-guided random exploration with path filtering to establish a
data synthesis pipeline, where a fine-grained reasoning trajectory is
automatically generated for each task. Based on the synthesized data, we then
employ a two-stage training process to learn a policy that dynamically decides
the optimal actions at each reasoning step. The overall objective of
precision-conciseness balance in graph retrieval is decoupled into fine-grained
process-supervised rewards to enhance data efficiency and training stability.
In practical deployment, GRAIL adopts an interactive retrieval paradigm,
enabling the model to autonomously explore graph paths while dynamically
balancing retrieval breadth and precision. Extensive experiments have shown
that GRAIL achieves an average accuracy improvement of 21.01% and F1
improvement of 22.43% on three knowledge graph question-answering datasets. Our
source code and datasets is available at https://github.com/Changgeww/GRAIL.

</details>


### [29] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
*Roshita Bhonsle,Rishav Dutta,Sneha Vavilapalli,Harsh Seth,Abubakarr Jaye,Yapei Chang,Mukund Rungta,Emmanuel Aboah Boateng,Sadid Hasan,Ehi Nosakhare,Soundar Srinivasan*

Main category: cs.AI

TL;DR: 提出了一种通用、模块化的框架，用于评估代理任务完成情况，通过分解任务并验证每一步，提高与人类评估的一致性。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法（如LLM-as-a-Judge）仅关注最终输出，忽略了逐步推理过程；现有Agent-as-a-Judge系统局限于特定领域。

Method: 设计模块化框架，将任务分解为子任务，验证每一步，并聚合模块输出以生成最终评估结果。

Result: 在GAIA和BigCodeBench基准测试中，Judge Agent与人类评估的一致性分别比GPT-4o基线高4.76%和10.52%。

Conclusion: 该框架展示了通用评估方法的潜力，能够更准确地预测任务成功。

Abstract: The increasing adoption of foundation models as agents across diverse domains
necessitates a robust evaluation framework. Current methods, such as
LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step
reasoning that drives agentic decision-making. Meanwhile, existing
Agent-as-a-Judge systems, where one agent evaluates another's task completion,
are typically designed for narrow, domain-specific settings. To address this
gap, we propose a generalizable, modular framework for evaluating agent task
completion independent of the task domain. The framework emulates human-like
evaluation by decomposing tasks into sub-tasks and validating each step using
available information, such as the agent's output and reasoning. Each module
contributes to a specific aspect of the evaluation process, and their outputs
are aggregated to produce a final verdict on task completion. We validate our
framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA
and BigCodeBench. Our Judge Agent predicts task success with closer agreement
to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,
respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This
demonstrates the potential of our proposed general-purpose evaluation
framework.

</details>


### [30] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
*Meryem Yilmaz Soylu,Adrian Gallard,Jeonghyun Lee,Gayane Grigoryan,Rushil Desai,Stephen Harmon*

Main category: cs.AI

TL;DR: LORI是一种基于AI的工具，用于从推荐信中自动检测领导力技能，采用RoBERTa和LLAMA模型，表现优异。


<details>
  <summary>Details</summary>
Motivation: 推荐信评估耗时且主观，LORI旨在自动化这一过程，提供客观反馈。

Method: 使用自然语言处理和大语言模型（RoBERTa和LLAMA）识别领导力属性。

Result: RoBERTa模型在测试数据中表现优异，F1分数91.6%，精度92.4%，召回率91.6%。

Conclusion: LORI可优化研究生招生流程，更全面评估申请者的领导力。

Abstract: Letters of recommendation (LORs) provide valuable insights into candidates'
capabilities and experiences beyond standardized test scores. However,
reviewing these text-heavy materials is time-consuming and labor-intensive. To
address this challenge and support the admission committee in providing
feedback for students' professional growth, our study introduces LORI: LOR
Insights, a novel AI-based detection tool for assessing leadership skills in
LORs submitted by online master's program applicants. By employing natural
language processing and leveraging large language models using RoBERTa and
LLAMA, we seek to identify leadership attributes such as teamwork,
communication, and innovation. Our latest RoBERTa model achieves a weighted F1
score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong
level of consistency in our test data. With the growing importance of
leadership skills in the STEM sector, integrating LORI into the graduate
admissions process is crucial for accurately assessing applicants' leadership
capabilities. This approach not only streamlines the admissions process but
also automates and ensures a more comprehensive evaluation of candidates'
capabilities.

</details>


### [31] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
*Rui Lu,Jinhe Bi,Yunpu Ma,Feng Xiao,Yuntao Du,Yijun Tian*

Main category: cs.AI

TL;DR: MV-Debate是一种多视角代理辩论框架，用于统一多模态有害内容检测，通过动态反思门控提升准确性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中多模态内容的复杂性使得有害意图（如讽刺、仇恨言论或虚假信息）难以识别，需解决跨模态矛盾和文化快速变化等问题。

Method: MV-Debate整合四种互补代理（表面分析师、深度推理者、模态对比者和社会情境分析者），通过迭代辩论和动态反思门控优化检测。

Result: 在三个基准数据集上，MV-Debate显著优于单模型和现有多代理辩论基线。

Conclusion: 多代理辩论框架在提升社交媒体意图检测的可靠性方面具有潜力。

Abstract: Social media has evolved into a complex multimodal environment where text,
images, and other signals interact to shape nuanced meanings, often concealing
harmful intent. Identifying such intent, whether sarcasm, hate speech, or
misinformation, remains challenging due to cross-modal contradictions, rapid
cultural shifts, and subtle pragmatic cues. To address these challenges, we
propose MV-Debate, a multi-view agent debate framework with dynamic reflection
gating for unified multimodal harmful content detection. MV-Debate assembles
four complementary debate agents, a surface analyst, a deep reasoner, a
modality contrast, and a social contextualist, to analyze content from diverse
interpretive perspectives. Through iterative debate and reflection, the agents
refine responses under a reflection-gain criterion, ensuring both accuracy and
efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate
significantly outperforms strong single-model and existing multi-agent debate
baselines. This work highlights the promise of multi-agent debate in advancing
reliable social intent detection in safety-critical online contexts.

</details>


### [32] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
*Bo Wen*

Main category: cs.AI

TL;DR: 本文提出主动推理（AIF）为解决自主AI代理学习中的奖励工程瓶颈问题提供了关键基础，通过最小化自由能量的内在驱动力替代外部奖励信号。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统依赖大量人工设计的奖励函数，面临可扩展性挑战，阻碍了真正自主智能的发展。

Method: 结合主动推理（AIF）和大型语言模型（LLMs），利用内在驱动力（最小化自由能量）替代外部奖励信号，实现自主学习和目标适应。

Result: 提出了一种能够高效从经验中学习并保持与人类价值观一致的AI代理框架。

Conclusion: 主动推理与大型语言模型的结合为自主AI系统的发展提供了可行路径，解决了奖励工程瓶颈问题。

Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation
for developing autonomous AI agents capable of learning from experience without
continuous human reward engineering. As AI systems begin to exhaust
high-quality training data and rely on increasingly large human workforces for
reward design, the current paradigm faces significant scalability challenges
that could impede progress toward genuinely autonomous intelligence. The
proposal for an ``Era of Experience,'' where agents learn from self-generated
data, is a promising step forward. However, this vision still depends on
extensive human engineering of reward functions, effectively shifting the
bottleneck from data curation to reward curation. This highlights what we
identify as the \textbf{grounded-agency gap}: the inability of contemporary AI
systems to autonomously formulate, adapt, and pursue objectives in response to
changing circumstances. We propose that AIF can bridge this gap by replacing
external reward signals with an intrinsic drive to minimize free energy,
allowing agents to naturally balance exploration and exploitation through a
unified Bayesian objective. By integrating Large Language Models as generative
world models with AIF's principled decision-making framework, we can create
agents that learn efficiently from experience while remaining aligned with
human values. This synthesis offers a compelling path toward AI systems that
can develop autonomously while adhering to both computational and physical
constraints.

</details>


### [33] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
*Yu Yuan,Lili Zhao,Wei Chen,Guangting Zheng,Kai Zhang,Mengdi Zhang,Qi Liu*

Main category: cs.AI

TL;DR: 论文提出LearnerAgent框架，基于大语言模型模拟真实教学环境，分析不同学习者的动态学习行为，揭示其认知成长与心理特征的关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉学习动态或提供解释性，因此需要一种新框架来模拟真实学习环境并分析学习行为。

Method: 构建多智能体框架LearnerAgent，基于心理特征设计学习者类型（如深度、表面、懒惰学习者），通过知识获取、测试和互动跟踪学习动态。

Result: 研究发现：1）深度学习者持续认知成长；2）学习者行为与心理特征一致；3）自我效能感演化真实；4）基础LLM默认行为为“勤奋但脆弱的表面学习者”。

Conclusion: LearnerAgent能有效模拟真实学习场景，为理解LLM行为提供新视角。

Abstract: Capturing human learning behavior based on deep learning methods has become a
major research focus in both psychology and intelligent systems. Recent
approaches rely on controlled experiments or rule-based models to explore
cognitive processes. However, they struggle to capture learning dynamics, track
progress over time, or provide explainability. To address these challenges, we
introduce LearnerAgent, a novel multi-agent framework based on Large Language
Models (LLMs) to simulate a realistic teaching environment. To explore
human-like learning dynamics, we construct learners with psychologically
grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM's default behavior. Through weekly
knowledge acquisition, monthly strategic choices, periodic tests, and peer
interaction, we can track the dynamic learning progress of individual learners
over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis
reveals that only Deep Learner achieves sustained cognitive growth. Our
specially designed "trap questions" effectively diagnose Surface Learner's
shallow knowledge. 2) The behavioral and cognitive patterns of distinct
learners align closely with their psychological profiles. 3) Learners'
self-concept scores evolve realistically, with the General Learner developing
surprisingly high self-efficacy despite its cognitive limitations. 4)
Critically, the default profile of base LLM is a "diligent but brittle Surface
Learner"-an agent that mimics the behaviors of a good student but lacks true,
generalizable understanding. Extensive simulation experiments demonstrate that
LearnerAgent aligns well with real scenarios, yielding more insightful findings
about LLMs' behavior.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [34] [On the causality between affective impact and coordinated human-robot reactions](https://arxiv.org/abs/2508.04834)
*Morten Roed Frederiksen,Kasper Støy*

Main category: cs.RO

TL;DR: 研究机器人通过主动分享事件反应对人类感知其情感影响的效果，发现共享反应时间对感知有显著影响。


<details>
  <summary>Details</summary>
Motivation: 提升机器人在社交环境中的表现，探究其反应行为对人类感知的影响。

Method: 设计两组实验：一组隔离机器人情感表达的反应元素，另一组测试不同反应延迟时间对物理互动的影响。

Result: 共享事件的机器人反应显著改变人类感知（p<0.05）；200ms延迟对小型非人形机器人最有效，100ms延迟则让人类感觉影响最大。

Conclusion: 机器人反应时间对人类感知有显著影响，200ms和100ms分别为不同目标的最优延迟。

Abstract: In an effort to improve how robots function in social contexts, this paper
investigates if a robot that actively shares a reaction to an event with a
human alters how the human perceives the robot's affective impact. To verify
this, we created two different test setups. One to highlight and isolate the
reaction element of affective robot expressions, and one to investigate the
effects of applying specific timing delays to a robot reacting to a physical
encounter with a human. The first test was conducted with two different groups
(n=84) of human observers, a test group and a control group both interacting
with the robot. The second test was performed with 110 participants using
increasingly longer reaction delays for the robot with every ten participants.
The results show a statistically significant change (p$<$.05) in perceived
affective impact for the robots when they react to an event shared with a human
observer rather than reacting at random. The result also shows for shared
physical interaction, the near-human reaction times from the robot are most
appropriate for the scenario. The paper concludes that a delay time around
200ms may render the biggest impact on human observers for small-sized
non-humanoid robots. It further concludes that a slightly shorter reaction time
around 100ms is most effective when the goal is to make the human observers
feel they made the biggest impact on the robot.

</details>


### [35] [INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM](https://arxiv.org/abs/2508.04931)
*Jin Wang,Weijie Wang,Boyuan Deng,Heng Zhang,Rui Dai,Nikos Tsagarakis*

Main category: cs.RO

TL;DR: 论文提出INTENTION框架，结合视觉语言模型和交互驱动记忆，赋予机器人直觉式交互和自主操作能力。


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制依赖精确模型和预定义动作，难以适应现实世界的不确定性和新任务。人类则通过直觉和物理理解高效决策，启发研究者开发类似能力的机器人框架。

Method: INTENTION框架整合视觉语言模型的场景推理和交互驱动记忆（Memory Graph），并设计Intuitive Perceptor提取物理关系和功能属性。

Result: 机器人能在新场景中推断合适的交互行为，无需重复指令，表现出类似人类的适应性和决策能力。

Conclusion: INTENTION框架通过模仿人类直觉和记忆机制，显著提升了机器人在多样化场景中的自主操作能力。

Abstract: Traditional control and planning for robotic manipulation heavily rely on
precise physical models and predefined action sequences. While effective in
structured environments, such approaches often fail in real-world scenarios due
to modeling inaccuracies and struggle to generalize to novel tasks. In
contrast, humans intuitively interact with their surroundings, demonstrating
remarkable adaptability, making efficient decisions through implicit physical
understanding. In this work, we propose INTENTION, a novel framework enabling
robots with learned interactive intuition and autonomous manipulation in
diverse scenarios, by integrating Vision-Language Models (VLMs) based scene
reasoning with interaction-driven memory. We introduce Memory Graph to record
scenes from previous task interactions which embodies human-like understanding
and decision-making about different tasks in real world. Meanwhile, we design
an Intuitive Perceptor that extracts physical relations and affordances from
visual scenes. Together, these components empower robots to infer appropriate
interaction behaviors in new scenes without relying on repetitive instructions.
Videos: https://robo-intention.github.io

</details>


### [36] [Optimal Planning for Multi-Robot Simultaneous Area and Line Coverage Using Hierarchical Cyclic Merging Regulation](https://arxiv.org/abs/2508.04981)
*Tianyuan Zheng,Jingang Yi,Kaiyan Yu*

Main category: cs.RO

TL;DR: 论文提出了一种基于层次循环合并调节（HCMR）的双重覆盖问题优化规划算法，显著提升了路径长度和任务时间效率。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在已知环境中同时覆盖线性特征和区域时的高效、无碰撞路径规划问题。

Method: 采用HCMR算法，结合Morse理论分析流形附着过程，通过循环合并搜索和边序列反向传播生成最优路径。

Result: HCMR算法在路径长度上至少提升10.0%，任务时间平均减少16.9%，且确保无冲突操作。

Conclusion: HCMR算法在固定扫描方向下具有最优性，显著优于现有规划方法。

Abstract: The double coverage problem focuses on determining efficient, collision-free
routes for multiple robots to simultaneously cover linear features (e.g.,
surface cracks or road routes) and survey areas (e.g., parking lots or local
regions) in known environments. In these problems, each robot carries two
functional roles: service (linear feature footprint coverage) and exploration
(complete area coverage). Service has a smaller operational footprint but
incurs higher costs (e.g., time) compared to exploration. We present optimal
planning algorithms for the double coverage problems using hierarchical cyclic
merging regulation (HCMR). To reduce the complexity for optimal planning
solutions, we analyze the manifold attachment process during graph traversal
from a Morse theory perspective. We show that solutions satisfying minimum path
length and collision-free constraints must belong to a Morse-bounded
collection. To identify this collection, we introduce the HCMR algorithm. In
HCMR, cyclic merging search regulates traversal behavior, while edge sequence
back propagation converts these regulations into graph edge traversal
sequences. Incorporating balanced partitioning, the optimal sequence is
selected to generate routes for each robot. We prove the optimality of the HCMR
algorithm under a fixed sweep direction. The multi-robot simulation results
demonstrate that the HCMR algorithm significantly improves planned path length
by at least 10.0%, reduces task time by at least 16.9% in average, and ensures
conflict-free operation compared to other state-of-the-art planning methods.

</details>


### [37] [Hierarchical Deep Deterministic Policy Gradient for Autonomous Maze Navigation of Mobile Robots](https://arxiv.org/abs/2508.04994)
*Wenjie Hu,Ye Zhou,Hann Woei Ho*

Main category: cs.RO

TL;DR: 论文提出了一种高效的层次化DDPG（HDDPG）算法，通过高低级策略结合、改进探索和奖励机制，显著提升了迷宫导航任务的性能。


<details>
  <summary>Details</summary>
Motivation: 标准DDPG算法在迷宫导航中表现不佳，存在稀疏奖励、探索效率低和长时规划困难等问题，导致成功率低和奖励不足。

Method: HDDPG采用高低级策略：高级策略生成长期子目标，低级策略执行具体动作；结合离策略校正、自适应参数噪声和优化奖励函数。

Result: 在ROS和Gazebo仿真实验中，HDDPG相比基线算法，成功率提升至少56.59%，平均奖励增加至少519.03。

Conclusion: HDDPG有效解决了标准DDPG在迷宫导航中的局限性，显著提升了任务性能。

Abstract: Maze navigation is a fundamental challenge in robotics, requiring agents to
traverse complex environments efficiently. While the Deep Deterministic Policy
Gradient (DDPG) algorithm excels in control tasks, its performance in maze
navigation suffers from sparse rewards, inefficient exploration, and
long-horizon planning difficulties, often leading to low success rates and
average rewards, sometimes even failing to achieve effective navigation. To
address these limitations, this paper proposes an efficient Hierarchical DDPG
(HDDPG) algorithm, which includes high-level and low-level policies. The
high-level policy employs an advanced DDPG framework to generate intermediate
subgoals from a long-term perspective and on a higher temporal scale. The
low-level policy, also powered by the improved DDPG algorithm, generates
primitive actions by observing current states and following the subgoal
assigned by the high-level policy. The proposed method enhances stability with
off-policy correction, refining subgoal assignments by relabeling historical
experiences. Additionally, adaptive parameter space noise is utilized to
improve exploration, and a reshaped intrinsic-extrinsic reward function is
employed to boost learning efficiency. Further optimizations, including
gradient clipping and Xavier initialization, are employed to improve
robustness. The proposed algorithm is rigorously evaluated through numerical
simulation experiments executed using the Robot Operating System (ROS) and
Gazebo. Regarding the three distinct final targets in autonomous maze
navigation tasks, HDDPG significantly overcomes the limitations of standard
DDPG and its variants, improving the success rate by at least 56.59% and
boosting the average reward by a minimum of 519.03 compared to baseline
algorithms.

</details>


### [38] [MAG-Nav: Language-Driven Object Navigation Leveraging Memory-Reserved Active Grounding](https://arxiv.org/abs/2508.05021)
*Weifan Zhang,Tingguang Li,Yuzhen Liu*

Main category: cs.RO

TL;DR: 提出了一种基于视觉语言模型（VLM）的导航框架，通过主动调整视角和历史记忆回溯机制，显著提升了复杂未知环境中的视觉语言定位能力。


<details>
  <summary>Details</summary>
Motivation: 智能机器人在未知环境中仅依靠自然语言描述进行视觉导航的能力是关键需求。现有方法被动依赖视觉输入，无法有效解决模糊性问题。

Method: 结合视角主动定位和历史记忆回溯机制，动态优化感知并利用记忆解决模糊性，无需标注数据或模型微调。

Result: 在HM3D数据集上表现优于现有方法，并在四足机器人上实现了稳健的导航性能。

Conclusion: 该方法通过主动感知和记忆机制，显著提升了语言驱动导航的泛化能力和实用性。

Abstract: Visual navigation in unknown environments based solely on natural language
descriptions is a key capability for intelligent robots. In this work, we
propose a navigation framework built upon off-the-shelf Visual Language Models
(VLMs), enhanced with two human-inspired mechanisms: perspective-based active
grounding, which dynamically adjusts the robot's viewpoint for improved visual
inspection, and historical memory backtracking, which enables the system to
retain and re-evaluate uncertain observations over time. Unlike existing
approaches that passively rely on incidental visual inputs, our method actively
optimizes perception and leverages memory to resolve ambiguity, significantly
improving vision-language grounding in complex, unseen environments. Our
framework operates in a zero-shot manner, achieving strong generalization to
diverse and open-ended language descriptions without requiring labeled data or
model fine-tuning. Experimental results on Habitat-Matterport 3D (HM3D) show
that our method outperforms state-of-the-art approaches in language-driven
object navigation. We further demonstrate its practicality through real-world
deployment on a quadruped robot, achieving robust and effective navigation
performance.

</details>


### [39] [Benchmarking Shortcutting Techniques for Multi-Robot-Arm Motion Planning](https://arxiv.org/abs/2508.05027)
*Philip Huang,Yorai Shaoul,Jiaoyang Li*

Main category: cs.RO

TL;DR: 本文研究了多机械臂运动规划中的捷径优化方法，比较了现有方法的优缺点，并提出了两种组合策略以实现最佳性能与运行时间的平衡。


<details>
  <summary>Details</summary>
Motivation: 多机械臂系统的高维度和潜在的碰撞风险使得高质量运动规划具有挑战性，传统方法常产生次优运动，现有捷径优化方法缺乏详细描述和性能分析。

Method: 通过定量比较现有捷径优化方法，分析其优缺点，并提出两种组合策略。

Result: 研究提供了对不同捷径优化方法的性能评估，并展示了组合策略在性能与运行时间上的优势。

Conclusion: 本文为多机械臂运动规划中的捷径优化提供了全面分析和实用策略，提升了运动质量和效率。

Abstract: Generating high-quality motion plans for multiple robot arms is challenging
due to the high dimensionality of the system and the potential for inter-arm
collisions. Traditional motion planning methods often produce motions that are
suboptimal in terms of smoothness and execution time for multi-arm systems.
Post-processing via shortcutting is a common approach to improve motion quality
for efficient and smooth execution. However, in multi-arm scenarios, optimizing
one arm's motion must not introduce collisions with other arms. Although
existing multi-arm planning works often use some form of shortcutting
techniques, their exact methodology and impact on performance are often vaguely
described. In this work, we present a comprehensive study quantitatively
comparing existing shortcutting methods for multi-arm trajectories across
diverse simulated scenarios. We carefully analyze the pros and cons of each
shortcutting method and propose two simple strategies for combining these
methods to achieve the best performance-runtime tradeoff. Video, code, and
dataset are available at https://philip-huang.github.io/mr-shortcut/.

</details>


### [40] [A Vision-Based Collision Sensing Method for Stable Circular Object Grasping with A Soft Gripper System](https://arxiv.org/abs/2508.05040)
*Boyang Zhang,Jiahui Zuo,Zeyu Duan,Fumin Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的碰撞检测模块，用于软夹持器系统，确保稳定抓取圆形物体。


<details>
  <summary>Details</summary>
Motivation: 外部碰撞对机器人执行器构成风险，尤其是抓取圆形物体时，需要一种可靠的碰撞检测方法。

Method: 使用眼在手相机监测手指和被抓物体的运动，开发了碰撞丰富的抓取策略。

Result: 实验验证了系统能即时响应碰撞，并能精确检测碰撞方向和大小。

Conclusion: 该系统能有效提升软夹持器在动态抓取中的稳定性和安全性。

Abstract: External collisions to robot actuators typically pose risks to grasping
circular objects. This work presents a vision-based sensing module capable of
detecting collisions to maintain stable grasping with a soft gripper system.
The system employs an eye-in-palm camera with a broad field of view to
simultaneously monitor the motion of fingers and the grasped object.
Furthermore, we have developed a collision-rich grasping strategy to ensure the
stability and security of the entire dynamic grasping process. A physical soft
gripper was manufactured and affixed to a collaborative robotic arm to evaluate
the performance of the collision detection mechanism. An experiment regarding
testing the response time of the mechanism confirmed the system has the
capability to react to the collision instantaneously. A dodging test was
conducted to demonstrate the gripper can detect the direction and scale of
external collisions precisely.

</details>


### [41] [Examining the legibility of humanoid robot arm movements in a pointing task](https://arxiv.org/abs/2508.05104)
*Andrej Lúčny,Matilde Antonj,Carlo Mazzola,Hana Hornáčková,Ana Farić,Kristína Malinovská,Michal Vavrecka,Igor Farkaš*

Main category: cs.RO

TL;DR: 研究探讨人形机器人手臂动作的可读性，测试人类如何通过截断动作和身体线索预测机器人意图。实验支持多模态优越性和视觉主导假说。


<details>
  <summary>Details</summary>
Motivation: 提升人机交互中机器人动作的可读性，使人类能更准确预测机器人意图并感到安全。

Method: 使用NICO人形机器人进行实验，参与者观察其手臂指向触摸屏目标的动作，测试不同线索（注视、指向、注视与指向一致/不一致）和截断轨迹（60%或80%）对预测的影响。

Result: 实验支持多模态优越性和视觉主导假说，表明人类能通过身体线索预测机器人意图。

Conclusion: 机器人动作的可读性可通过多模态线索（如注视和指向）提升，视觉线索在预测中起主导作用。

Abstract: Human--robot interaction requires robots whose actions are legible, allowing
humans to interpret, predict, and feel safe around them. This study
investigates the legibility of humanoid robot arm movements in a pointing task,
aiming to understand how humans predict robot intentions from truncated
movements and bodily cues. We designed an experiment using the NICO humanoid
robot, where participants observed its arm movements towards targets on a
touchscreen. Robot cues varied across conditions: gaze, pointing, and pointing
with congruent or incongruent gaze. Arm trajectories were stopped at 60\% or
80\% of their full length, and participants predicted the final target. We
tested the multimodal superiority and ocular primacy hypotheses, both of which
were supported by the experiment.

</details>


### [42] [From Canada to Japan: How 10,000 km Affect User Perception in Robot Teleoperation](https://arxiv.org/abs/2508.05143)
*Siméon Capy,Thomas M. Kwok,Kevin Joseph,Yuichiro Kawasumi,Koichi Nagashima,Tomoya Sasaki,Yue Hu,Eiichi Yoshida*

Main category: cs.RO

TL;DR: 研究探讨了远程机器人操作（RTo）对用户感知的影响，尤其是在老年护理中的应用，发现远程与本地操作在感知上无显著差异。


<details>
  <summary>Details</summary>
Motivation: 探索远程机器人操作在老年护理中的潜力，研究距离对非专家用户感知的影响。

Method: 设计了包含问卷调查的协议，并使用ROS和Unity开发软件架构，比较远程与本地操作的用户感知。

Result: 远程与本地机器人操作在用户感知上无显著差异。

Conclusion: 远程机器人操作可能是传统本地控制的有效替代方案。

Abstract: Robot teleoperation (RTo) has emerged as a viable alternative to local
control, particularly when human intervention is still necessary. This research
aims to study the distance effect on user perception in RTo, exploring the
potential of teleoperated robots for older adult care. We propose an evaluation
of non-expert users' perception of long-distance RTo, examining how their
perception changes before and after interaction, as well as comparing it to
that of locally operated robots. We have designed a specific protocol
consisting of multiple questionnaires, along with a dedicated software
architecture using the Robotics Operating System (ROS) and Unity. The results
revealed no statistically significant differences between the local and remote
robot conditions, suggesting that robots may be a viable alternative to
traditional local control.

</details>


### [43] [Chemist Eye: A Visual Language Model-Powered System for Safety Monitoring and Robot Decision-Making in Self-Driving Laboratories](https://arxiv.org/abs/2508.05148)
*Francisco Munguia-Galeano,Zhengxue Zhou,Satheeshkumar Veeramani,Hatem Fakhruldeen,Louis Longley,Rob Clowes,Andrew I. Cooper*

Main category: cs.RO

TL;DR: Chemist Eye是一个分布式安全监控系统，用于增强自驱动实验室（SDL）的安全意识，通过多模态摄像头和视觉语言模型（VLM）实时监测危险并指导机器人行动。


<details>
  <summary>Details</summary>
Motivation: 自驱动实验室中，机器人使用易燃锂电池增加了火灾风险，同时个人防护装备（PPE）的合规性也需监控，因此需要一种高效的安全系统。

Method: 系统整合RGB、深度和红外摄像头，利用VLM进行决策，实时监测危险并指导机器人远离危险区域，同时通过第三方平台通知人员。

Result: 在真实SDL环境中测试，Chemist Eye对安全危险的识别和决策性能分别达到97%和95%。

Conclusion: Chemist Eye能有效提升SDL的安全性，减少火灾和PPE违规风险，具有实际应用潜力。

Abstract: The integration of robotics and automation into self-driving laboratories
(SDLs) can introduce additional safety complexities, in addition to those that
already apply to conventional research laboratories. Personal protective
equipment (PPE) is an essential requirement for ensuring the safety and
well-being of workers in laboratories, self-driving or otherwise. Fires are
another important risk factor in chemical laboratories. In SDLs, fires that
occur close to mobile robots, which use flammable lithium batteries, could have
increased severity. Here, we present Chemist Eye, a distributed safety
monitoring system designed to enhance situational awareness in SDLs. The system
integrates multiple stations equipped with RGB, depth, and infrared cameras,
designed to monitor incidents in SDLs. Chemist Eye is also designed to spot
workers who have suffered a potential accident or medical emergency, PPE
compliance and fire hazards. To do this, Chemist Eye uses decision-making
driven by a vision-language model (VLM). Chemist Eye is designed for seamless
integration, enabling real-time communication with robots. Based on the VLM
recommendations, the system attempts to drive mobile robots away from potential
fire locations, exits, or individuals not wearing PPE, and issues audible
warnings where necessary. It also integrates with third-party messaging
platforms to provide instant notifications to lab personnel. We tested Chemist
Eye with real-world data from an SDL equipped with three mobile robots and
found that the spotting of possible safety hazards and decision-making
performances reached 97 % and 95 %, respectively.

</details>


### [44] [FCBV-Net: Category-Level Robotic Garment Smoothing via Feature-Conditioned Bimanual Value Prediction](https://arxiv.org/abs/2508.05153)
*Mohammed Daba,Jing Qiu*

Main category: cs.RO

TL;DR: FCBV-Net通过预训练的几何特征增强类别级策略泛化能力，显著提升机器人服装平滑任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决类别级机器人服装操作中的高维度和动态复杂性，避免现有方法的过拟合或泛化不足问题。

Method: 提出FCBV-Net，利用3D点云和冻结的几何特征，分离几何理解与动作价值学习，提升泛化能力。

Result: 在模拟实验中，FCBV-Net表现优于基线方法，效率下降仅11.5%，最终覆盖率达89%。

Conclusion: 几何特征与动作价值学习的解耦是实现类别级泛化的关键。

Abstract: Category-level generalization for robotic garment manipulation, such as
bimanual smoothing, remains a significant hurdle due to high dimensionality,
complex dynamics, and intra-category variations. Current approaches often
struggle, either overfitting with concurrently learned visual features for a
specific instance or, despite category-level perceptual generalization, failing
to predict the value of synergistic bimanual actions. We propose the
Feature-Conditioned Bimanual Value Network (FCBV-Net), operating on 3D point
clouds to specifically enhance category-level policy generalization for garment
smoothing. FCBV-Net conditions bimanual action value prediction on pre-trained,
frozen dense geometric features, ensuring robustness to intra-category garment
variations. Trainable downstream components then learn a task-specific policy
using these static features. In simulated GarmentLab experiments with the
CLOTH3D dataset, FCBV-Net demonstrated superior category-level generalization.
It exhibited only an 11.5% efficiency drop (Steps80) on unseen garments
compared to 96.2% for a 2D image-based baseline, and achieved 89% final
coverage, outperforming an 83% coverage from a 3D correspondence-based baseline
that uses identical per-point geometric features but a fixed primitive. These
results highlight that the decoupling of geometric understanding from bimanual
action value learning enables better category-level generalization.

</details>


### [45] [Learning to See and Act: Task-Aware View Planning for Robotic Manipulation](https://arxiv.org/abs/2508.05186)
*Yongjie Bai,Zhouxia Wang,Yang Liu,Weixing Chen,Ziliang Chen,Mingtong Dai,Yongsen Zheng,Lingbo Liu,Guanbin Li,Liang Lin*

Main category: cs.RO

TL;DR: 提出了一种任务感知视图规划（TAVP）框架，通过主动视图规划和任务特定表示学习，解决了现有视觉-语言-动作（VLA）模型在3D感知和任务干扰方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖静态视角和共享视觉编码器，限制了3D感知并导致任务干扰，影响了鲁棒性和泛化能力。

Method: TAVP结合主动视图规划和任务特定表示学习，采用高效探索策略和Mixture-of-Experts（MoE）视觉编码器，以解耦不同任务的特征。

Result: 在RLBench任务上的实验表明，TAVP显著优于现有固定视角方法，生成了更完整和区分性的视觉表示。

Conclusion: TAVP通过任务感知的视觉表示学习，提升了多任务机器人操作的鲁棒性和泛化能力。

Abstract: Recent vision-language-action (VLA) models for multi-task robotic
manipulation commonly rely on static viewpoints and shared visual encoders,
which limit 3D perception and cause task interference, hindering robustness and
generalization. In this work, we propose Task-Aware View Planning (TAVP), a
framework designed to overcome these challenges by integrating active view
planning with task-specific representation learning. TAVP employs an efficient
exploration policy, accelerated by a novel pseudo-environment, to actively
acquire informative views. Furthermore, we introduce a Mixture-of-Experts (MoE)
visual encoder to disentangle features across different tasks, boosting both
representation fidelity and task generalization. By learning to see the world
in a task-aware way, TAVP generates more complete and discriminative visual
representations, demonstrating significantly enhanced action prediction across
a wide array of manipulation challenges. Extensive experiments on RLBench tasks
show that our proposed TAVP model achieves superior performance over
state-of-the-art fixed-view approaches. Visual results and code are provided
at: https://hcplab-sysu.github.io/TAVP.

</details>


### [46] [Dancing with a Robot: An Experimental Study of Child-Robot Interaction in a Performative Art Setting](https://arxiv.org/abs/2508.05208)
*Victor Ngo,Rachel,Ramchurn,Roma Patel,Alan Chamberlain,Ayse Kucukyilmaz*

Main category: cs.RO

TL;DR: 本文评估了18名儿童与自主机器人手臂NED的互动体验，揭示了儿童与机器人互动的三大挑战，并强调了优化人机交互系统的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究儿童与机器人NED在艺术表演中的互动体验，以了解如何提升人机交互的吸引力和意义。

Method: 通过观察分析儿童与NED的互动，总结出互动中的关键挑战。

Result: 发现儿童对机器人表演者表现出自然好奇心，但互动中存在三大挑战：1) 启动和维持互动困难，2) 机器人表达性和互惠性不足，3) 期望未满足。

Conclusion: 优化人机交互系统需考虑观众的能力、感知和期望，尤其是在艺术表演背景下，以创造更有吸引力的体验。

Abstract: This paper presents an evaluation of 18 children's in-the-wild experiences
with the autonomous robot arm performer NED (Never-Ending Dancer) within the
Thingamabobas installation, showcased across the UK. We detail NED's design,
including costume, behaviour, and human interactions, all integral to the
installation. Our observational analysis revealed three key challenges in
child-robot interactions: 1) Initiating and maintaining engagement, 2) Lack of
robot expressivity and reciprocity, and 3) Unmet expectations. Our findings
show that children are naturally curious, and adept at interacting with a
robotic art performer. However, our observations emphasise the critical need to
optimise human-robot interaction (HRI) systems through careful consideration of
audience's capabilities, perceptions, and expectations, within the performative
arts context, to enable engaging and meaningful experiences, especially for
young audiences.

</details>


### [47] [Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction](https://arxiv.org/abs/2508.05294)
*Sahar Salimpour,Lei Fu,Farhad Keramat,Leonardo Militano,Giovanni Toffetti,Harry Edelman,Jorge Peña Queralta*

Main category: cs.RO

TL;DR: 本文综述了基础模型（如LLMs和VLMs）在机器人自主性和人机交互中的应用，探讨了VLAs和BLMs如何提升机器人能力，并提出了分类模型集成方法的分类法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索基础模型如何推动机器人技术的进步，特别是在代理式应用和架构中的潜力。

Method: 方法包括综述现有研究、社区项目和工业框架，提出分类法，并对不同解决方案中代理的角色进行比较分析。

Result: 结果表明，代理式架构使机器人能够通过自然语言指令推理、调用API、规划任务序列等，展示了基础模型的广泛应用前景。

Conclusion: 结论强调基础模型在机器人领域的快速发展和多样化应用，同时指出了未来研究的潜在方向。

Abstract: Foundation models, including large language models (LLMs) and vision-language
models (VLMs), have recently enabled novel approaches to robot autonomy and
human-robot interfaces. In parallel, vision-language-action models (VLAs) or
large behavior models (BLMs) are increasing the dexterity and capabilities of
robotic systems. This survey paper focuses on those words advancing towards
agentic applications and architectures. This includes initial efforts exploring
GPT-style interfaces to tooling, as well as more complex system where AI agents
are coordinators, planners, perception actors, or generalist interfaces. Such
agentic architectures allow robots to reason over natural language
instructions, invoke APIs, plan task sequences, or assist in operations and
diagnostics. In addition to peer-reviewed research, due to the fast-evolving
nature of the field, we highlight and include community-driven projects, ROS
packages, and industrial frameworks that show emerging trends. We propose a
taxonomy for classifying model integration approaches and present a comparative
analysis of the role that agents play in different solutions in today's
literature.

</details>


### [48] [GhostShell: Streaming LLM Function Calls for Concurrent Embodied Programming](https://arxiv.org/abs/2508.05298)
*Jian Gong,Youwei Huang,Bo Yuan,Ming Zhu,Juncheng Zhan,Jinke Wang,Hang Shu,Mingyue Xiong,Yanjun Ye,Yufan Zu,Yang Zhou,Yihan Ding,Xuannian Chen,Xingyu Lu,Runjie Ban,Bingchao Huang,Fusen Liu*

Main category: cs.RO

TL;DR: GhostShell利用LLMs实现实时行为编程，通过动态函数调用和调度器协调多机器人组件，显著提升响应速度和行为正确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖预定义行为序列或行为树，缺乏灵活性。GhostShell旨在通过LLMs实现实时、并发的行为编程。

Method: 结合流式XML函数解析器、动态函数接口映射器和多通道调度器，支持同步和异步函数调用。

Result: 在34个实际任务中，GhostShell的行为正确性达0.85，响应速度提升66倍，且在多模态任务中表现稳健。

Conclusion: GhostShell为实时行为编程提供了高效、灵活的解决方案，适用于复杂机器人系统。

Abstract: We present GhostShell, a novel approach that leverages Large Language Models
(LLMs) to enable streaming and concurrent behavioral programming for embodied
systems. In contrast to conventional methods that rely on pre-scheduled action
sequences or behavior trees, GhostShell drives embodied systems to act
on-the-fly by issuing function calls incrementally as tokens are streamed from
the LLM. GhostShell features a streaming XML function token parser, a dynamic
function interface mapper, and a multi-channel scheduler that orchestrates
intra-channel synchronous and inter-channel asynchronous function calls,
thereby coordinating serial-parallel embodied actions across multiple robotic
components as directed by the LLM. We evaluate GhostShell on our robot
prototype COCO through comprehensive grounded experiments across 34 real-world
interaction tasks and multiple LLMs. The results demonstrate that our approach
achieves state-of-the-art Behavioral Correctness Metric of 0.85 with Claude-4
Sonnet and up to 66X faster response times compared to LLM native function
calling APIs. GhostShell also proves effective in long-horizon multimodal
tasks, demonstrating strong robustness and generalization.

</details>


### [49] [Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control](https://arxiv.org/abs/2508.05342)
*Shunlei Li,Longsen Gao,Jin Wang,Chang Che,Xi Xiao,Jiuwen Cao,Yingbai Hu,Hamid Reza Karimi*

Main category: cs.RO

TL;DR: GF-VLA框架通过视觉-语言-动作融合，使双臂机器人能够从人类演示中直接进行任务级推理和执行，显著提升泛化能力和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决传统低级别轨迹模仿方法在物体类型、空间布局和机械臂配置上泛化能力不足的问题。

Method: 提取任务相关的手和物体信息，编码为时序场景图，结合语言条件变换器生成行为树和运动指令，并引入跨手选择策略优化执行效率。

Result: 在双臂积木组装任务中，图表示准确率超95%，子任务分割达93%，任务成功率90%，表现出强泛化能力。

Conclusion: GF-VLA框架通过信息论和语言融合，显著提升了机器人从人类演示中学习复杂任务的性能和泛化能力。

Abstract: Teaching robots dexterous skills from human videos remains challenging due to
the reliance on low-level trajectory imitation, which fails to generalize
across object types, spatial layouts, and manipulator configurations. We
propose Graph-Fused Vision-Language-Action (GF-VLA), a framework that enables
dual-arm robotic systems to perform task-level reasoning and execution directly
from RGB and Depth human demonstrations. GF-VLA first extracts
Shannon-information-based cues to identify hands and objects with the highest
task relevance, then encodes these cues into temporally ordered scene graphs
that capture both hand-object and object-object interactions. These graphs are
fused with a language-conditioned transformer that generates hierarchical
behavior trees and interpretable Cartesian motion commands. To improve
execution efficiency in bimanual settings, we further introduce a cross-hand
selection policy that infers optimal gripper assignment without explicit
geometric reasoning. We evaluate GF-VLA on four structured dual-arm block
assembly tasks involving symbolic shape construction and spatial
generalization. Experimental results show that the information-theoretic scene
representation achieves over 95 percent graph accuracy and 93 percent subtask
segmentation, supporting the LLM planner in generating reliable and
human-readable task policies. When executed by the dual-arm robot, these
policies yield 94 percent grasp success, 89 percent placement accuracy, and 90
percent overall task success across stacking, letter-building, and geometric
reconfiguration scenarios, demonstrating strong generalization and robustness
across diverse spatial and semantic variations.

</details>


### [50] [Affecta-Context: The Context-Guided Behavior Adaptation Framework](https://arxiv.org/abs/2508.05359)
*Morten Roed Frederiksen,Kasper Støy*

Main category: cs.RO

TL;DR: Affecta-context框架通过物理上下文信息优化社交机器人行为，包括上下文表示和行为优先级学习，并在实验中验证其泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提升社交机器人在不同物理环境中的行为适应性，以满足用户偏好和环境需求。

Method: 框架分为两部分：上下文表示和行为优先级学习，通过聚类物理属性和交互训练优化行为。

Result: 在72次交互实验中，机器人成功学习行为优先级，并能泛化到未见的物理上下文。

Conclusion: Affecta-context框架有效提升机器人行为适应性，具备实际应用潜力。

Abstract: This paper presents Affecta-context, a general framework to facilitate
behavior adaptation for social robots. The framework uses information about the
physical context to guide its behaviors in human-robot interactions. It
consists of two parts: one that represents encountered contexts and one that
learns to prioritize between behaviors through human-robot interactions. As
physical contexts are encountered the framework clusters them by their measured
physical properties. In each context, the framework learns to prioritize
between behaviors to optimize the physical attributes of the robot's behavior
in line with its current environment and the preferences of the users it
interacts with. This paper illlustrates the abilities of the Affecta-context
framework by enabling a robot to autonomously learn the prioritization of
discrete behaviors. This was achieved by training across 72 interactions in two
different physical contexts with 6 different human test participants. The paper
demonstrates the trained Affecta-context framework by verifying the robot's
ability to generalize over the input and to match its behaviors to a previously
unvisited physical context.

</details>


### [51] [A Multi-view Landmark Representation Approach with Application to GNSS-Visual-Inertial Odometry](https://arxiv.org/abs/2508.05368)
*Tong Hua,Jiale Han,Wei Ouyang*

Main category: cs.RO

TL;DR: 提出了一种多视角仅姿态估计方法，用于提升GNSS-视觉-惯性里程计（GVIO）的效率，通过直接关联地标与多相机姿态的视觉测量模型，减少计算负担。


<details>
  <summary>Details</summary>
Motivation: 传统IEKF在联合优化相机姿态和地标时计算负担高，限制了其在多传感器融合中的效率和适用性。

Method: 提出了一种仅姿态的视觉测量模型，直接关联地标与多相机姿态，保持紧密耦合和完美零空间。

Result: 仿真和实际实验表明，该方法在效率和精度上均优于传统方法。

Conclusion: 该方法显著提升了GVIO的计算效率和精度，适用于多传感器融合场景。

Abstract: Invariant Extended Kalman Filter (IEKF) has been a significant technique in
vision-aided sensor fusion. However, it usually suffers from high computational
burden when jointly optimizing camera poses and the landmarks. To improve its
efficiency and applicability for multi-sensor fusion, we present a multi-view
pose-only estimation approach with its application to GNSS-Visual-Inertial
Odometry (GVIO) in this paper. Our main contribution is deriving a visual
measurement model which directly associates landmark representation with
multiple camera poses and observations. Such a pose-only measurement is proven
to be tightly-coupled between landmarks and poses, and maintain a perfect null
space that is independent of estimated poses. Finally, we apply the proposed
approach to a filter based GVIO with a novel feature management strategy. Both
simulation tests and real-world experiments are conducted to demonstrate the
superiority of the proposed method in terms of efficiency and accuracy.

</details>


### [52] [Robots can defuse high-intensity conflict situations](https://arxiv.org/abs/2508.05373)
*Morten Roed Frederiksen,Kasper Støy*

Main category: cs.RO

TL;DR: 研究探讨了机器人在高强度冲突中如何通过五种情感表达方式缓解冲突，发现所有方式均有效，但运动方式表现不同。


<details>
  <summary>Details</summary>
Motivation: 了解机器人如何通过情感表达缓解人类对其的敌意，尤其是在其表现不佳时。

Method: 使用定制情感机器人在模拟冲突场景中测试105名参与者，评估五种表达方式的效果。

Result: 所有表达方式均能成功缓解冲突，运动方式表现显著不同，参与者对各方式的感知相似。

Conclusion: 缓解高强度冲突更需机器人具备社会情境意识，而非特定表达方式。

Abstract: This paper investigates the specific scenario of high-intensity
confrontations between humans and robots, to understand how robots can defuse
the conflict. It focuses on the effectiveness of using five different affective
expression modalities as main drivers for defusing the conflict. The aim is to
discover any strengths or weaknesses in using each modality to mitigate the
hostility that people feel towards a poorly performing robot. The defusing of
the situation is accomplished by making the robot better at acknowledging the
conflict and by letting it express remorse. To facilitate the tests, we used a
custom affective robot in a simulated conflict situation with 105 test
participants. The results show that all tested expression modalities can
successfully be used to defuse the situation and convey an acknowledgment of
the confrontation. The ratings were remarkably similar, but the movement
modality was different (ANON p$<$.05) than the other modalities. The test
participants also had similar affective interpretations on how impacted the
robot was of the confrontation across all expression modalities. This indicates
that defusing a high-intensity interaction may not demand special attention to
the expression abilities of the robot, but rather require attention to the
abilities of being socially aware of the situation and reacting in accordance
with it.

</details>


### [53] [Real-Time Iteration Scheme for Diffusion Policy](https://arxiv.org/abs/2508.05396)
*Yufei Duan,Hang Yin,Danica Kragic*

Main category: cs.RO

TL;DR: 本文提出了一种基于实时迭代（RTI）方案的新方法，显著降低了扩散策略的推理时间，无需额外训练或策略重新设计。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在机器人操作任务中表现优异，但其迭代去噪过程导致的推理时间长，限制了其在延迟敏感任务中的应用。

Method: 借鉴最优控制中的实时迭代（RTI）方案，利用前一时间步的解作为后续迭代的初始猜测，并提出基于缩放的方法处理离散动作。

Result: 实验表明，该方法大幅降低推理时间，同时保持与全步去噪扩散策略相当的性能。

Conclusion: 该方法为预训练扩散模型的集成提供了无缝解决方案，尤其适用于资源密集型大模型。

Abstract: Diffusion Policies have demonstrated impressive performance in robotic
manipulation tasks. However, their long inference time, resulting from an
extensive iterative denoising process, and the need to execute an action chunk
before the next prediction to maintain consistent actions limit their
applicability to latency-critical tasks or simple tasks with a short cycle
time. While recent methods explored distillation or alternative policy
structures to accelerate inference, these often demand additional training,
which can be resource-intensive for large robotic models. In this paper, we
introduce a novel approach inspired by the Real-Time Iteration (RTI) Scheme, a
method from optimal control that accelerates optimization by leveraging
solutions from previous time steps as initial guesses for subsequent
iterations. We explore the application of this scheme in diffusion inference
and propose a scaling-based method to effectively handle discrete actions, such
as grasping, in robotic manipulation. The proposed scheme significantly reduces
runtime computational costs without the need for distillation or policy
redesign. This enables a seamless integration into many pre-trained
diffusion-based models, in particular, to resource-demanding large models. We
also provide theoretical conditions for the contractivity which could be useful
for estimating the initial denoising step. Quantitative results from extensive
simulation experiments show a substantial reduction in inference time, with
comparable overall performance compared with Diffusion Policy using full-step
denoising. Our project page with additional resources is available at:
https://rti-dp.github.io/.

</details>


### [54] [DistillDrive: End-to-End Multi-Mode Autonomous Driving Distillation by Isomorphic Hetero-Source Planning Model](https://arxiv.org/abs/2508.05402)
*Rui Yu,Xianghang Zhang,Runkai Zhao,Huaicheng Yan,Meng Wang*

Main category: cs.RO

TL;DR: DistillDrive是一种基于知识蒸馏的端到端自动驾驶模型，通过多样化实例模仿增强多模态运动特征学习，显著提升了决策鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究过于关注自车状态作为单一学习目标，缺乏规划导向的理解，限制了决策过程的鲁棒性。

Method: 利用基于结构化场景表示的规划模型作为教师模型，结合强化学习和生成建模优化状态到决策的映射。

Result: 在nuScenes和NAVSIM数据集上验证，碰撞率降低50%，闭环性能提升3点。

Conclusion: DistillDrive通过知识蒸馏和多样化实例模仿，显著提升了自动驾驶模型的鲁棒性和性能。

Abstract: End-to-end autonomous driving has been recently seen rapid development,
exerting a profound influence on both industry and academia. However, the
existing work places excessive focus on ego-vehicle status as their sole
learning objectives and lacks of planning-oriented understanding, which limits
the robustness of the overall decision-making prcocess. In this work, we
introduce DistillDrive, an end-to-end knowledge distillation-based autonomous
driving model that leverages diversified instance imitation to enhance
multi-mode motion feature learning. Specifically, we employ a planning model
based on structured scene representations as the teacher model, leveraging its
diversified planning instances as multi-objective learning targets for the
end-to-end model. Moreover, we incorporate reinforcement learning to enhance
the optimization of state-to-decision mappings, while utilizing generative
modeling to construct planning-oriented instances, fostering intricate
interactions within the latent space. We validate our model on the nuScenes and
NAVSIM datasets, achieving a 50\% reduction in collision rate and a 3-point
improvement in closed-loop performance compared to the baseline model. Code and
model are publicly available at https://github.com/YuruiAI/DistillDrive

</details>


### [55] [Computational Design and Fabrication of Modular Robots with Untethered Control](https://arxiv.org/abs/2508.05410)
*Manas Bhargava,Takefumi Hiraki,Malina Strugaru,Michal Piovarci,Chiara Daraio,Daisuke Iwai,Bernd Bickel*

Main category: cs.RO

TL;DR: 提出了一种基于分布式驱动的机器人设计框架，结合3D打印骨骼和液晶弹性体肌肉，实现模块化组装和无线控制，并通过计算工具优化设计和运动。


<details>
  <summary>Details</summary>
Motivation: 模仿自然生物的适应性和运动范围，解决现有软机器人系统功能单一、无法动态改变形态或依赖笨重控制的问题。

Method: 利用3D打印骨骼和液晶弹性体（LCE）肌肉作为轻量级驱动器，开发红外响应LCE杆实现无线控制，并通过计算工具优化骨骼图和运动步态。

Result: 构建了多个机器人，展示了复杂形态变化、多样化控制方案和环境适应性。

Conclusion: 该系统结合模块化材料、无线分布式控制和计算设计，推动了机器人技术向生物能力的靠近。

Abstract: Natural organisms use distributed actuation via their musculoskeletal systems
to adapt their gait for traversing diverse terrains or to morph their bodies to
perform varied tasks. A longstanding challenge in the field of robotics is to
mimic this extensive adaptability and range of motion. This has led humans to
develop various soft robotic systems that emulate natural organisms. However,
such systems are generally optimized for a single functionality, lack the
ability to change form or function on demand, or are often tethered to bulky
control systems. To address these challenges, we present our framework for
designing and controlling robots that mimic nature's blueprint by utilizing
distributed actuation. We propose a novel building block that combines
3D-printed bones with liquid crystal elastomer (LCE) muscles as lightweight
actuators and enables the modular assembly of musculoskeletal robots. We
developed LCE rods that contract in response to infrared radiation, thereby
achieving local and untethered control over the distributed network of bones,
which in turn results in global deformation of the robot. Furthermore, to
capitalize on the extensive design space, we develop two computational tools:
one to optimize the robot's skeletal graph, enabling multiple target
deformations, and another to co-optimize the skeletal designs and control gaits
to achieve target locomotion. We validate our system by building several robots
that show complex shape morphing, varying control schemes, and adaptability to
their environment. Our system integrates advances in modular material building,
untethered and distributed control, and computational design to introduce a new
generation of robots that brings us closer to the capabilities of living
organisms.

</details>


### [56] [Do Robots Really Need Anthropomorphic Hands?](https://arxiv.org/abs/2508.05415)
*Alexander Fabisch,Wadhah Zai El Amri,Chandandeep Singh,Nicolás Navarro-Guerrero*

Main category: cs.RO

TL;DR: 论文探讨了人类手的灵巧性是否应为机器人手的理想目标，分析了现有机器人手的性能与设计，并提出了简化设计的可能性。


<details>
  <summary>Details</summary>
Motivation: 研究人类手的高自由度协调和高维传感器输入处理能力，探讨是否需要在机器人手中追求类似的设计。

Method: 通过综述人类手的特性、商业机器人手的比较以及系统评估其机制和技能，分析机器人手的设计需求。

Result: 发现手腕灵活性和手指外展/内收对操作能力更重要，而增加手指数量或自由度并非必要；三指设计是简单与灵巧的折衷。

Conclusion: 人类手可能并非机器人手的理想目标，非仿生设计或能提供更高的灵巧性。

Abstract: Human manipulation skills represent a pinnacle of their voluntary motor
functions, requiring the coordination of many degrees of freedom and processing
of high-dimensional sensor input to achieve such a high level of dexterity.
Thus, we set out to answer whether the human hand, with its associated
biomechanical properties, sensors, and control mechanisms, is an ideal that we
should strive for in robotics-do we really need anthropomorphic robotic hands?
  This survey can help practitioners to make the trade-off between hand
complexity and potential manipulation skills. We provide an overview of the
human hand, a comparison of commercially available robotic and prosthetic
hands, and a systematic review of hand mechanisms and skills that they are
capable of. This leads to follow-up questions. What is the minimum requirement
for mechanisms and sensors to implement most skills that a robot needs? What is
missing to reach human-level dexterity? Can we improve upon human dexterity?
  Although complex five-fingered hands are often used as the ultimate goal for
robotic manipulators, they are not necessary for all tasks. We found that wrist
flexibility and finger abduction/adduction are important for manipulation
capabilities. On the contrary, increasing the number of fingers, actuators, or
degrees of freedom is often not necessary. Three fingers are a good compromise
between simplicity and dexterity. Non-anthropomorphic hand designs with two
opposing pairs of fingers or human hands with six fingers can further increase
dexterity, suggesting that the human hand may not be the optimum.

</details>


### [57] [Mixed-Initiative Dialog for Human-Robot Collaborative Manipulation](https://arxiv.org/abs/2508.05535)
*Albert Yu,Chengshu Li,Luca Macesanu,Arnav Balaji,Ruchira Ray,Raymond Mooney,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: MICoBot是一个用于人机协作的混合主动对话系统，通过三层决策机制优化任务分配和协作策略，显著提高了任务成功率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中因人类行为多样性和动态变化导致的沟通与任务分配挑战。

Method: 采用三层决策机制：元规划器制定协作策略，规划器优化任务分配，执行器处理具体行动或对话。

Result: 在仿真和真实实验中，MICoBot显著优于纯LLM基线和其他任务分配模型，提高了任务成功率和用户体验。

Conclusion: MICoBot通过混合主动对话和多层决策机制，有效支持多样化人机协作，具有实际应用潜力。

Abstract: Effective robotic systems for long-horizon human-robot collaboration must
adapt to a wide range of human partners, whose physical behavior, willingness
to assist, and understanding of the robot's capabilities may change over time.
This demands a tightly coupled communication loop that grants both agents the
flexibility to propose, accept, or decline requests as they coordinate toward
completing the task effectively. We apply a Mixed-Initiative dialog paradigm to
Collaborative human-roBot teaming and propose MICoBot, a system that handles
the common scenario where both agents, using natural language, take initiative
in formulating, accepting, or rejecting proposals on who can best complete
different steps of a task. To handle diverse, task-directed dialog, and find
successful collaborative strategies that minimize human effort, MICoBot makes
decisions at three levels: (1) a meta-planner considers human dialog to
formulate and code a high-level collaboration strategy, (2) a planner optimally
allocates the remaining steps to either agent based on the robot's capabilities
(measured by a simulation-pretrained affordance model) and the human's
estimated availability to help, and (3) an action executor decides the
low-level actions to perform or words to say to the human. Our extensive
evaluations in simulation and real-world -- on a physical robot with 18 unique
human participants over 27 hours -- demonstrate the ability of our method to
effectively collaborate with diverse human users, yielding significantly
improved task success and user experience than a pure LLM baseline and other
agent allocation models. See additional videos and materials at
https://robin-lab.cs.utexas.edu/MicoBot/.

</details>


### [58] [CleanUpBench: Embodied Sweeping and Grasping Benchmark](https://arxiv.org/abs/2508.05543)
*Wenbo Li,Guanting Chen,Tao Zhao,Jiyao Wang,Tianxin Hu,Yuwen Liao,Weixiang Guo,Shenghai Yuan*

Main category: cs.RO

TL;DR: CleanUpBench是一个用于评估移动清洁机器人在现实室内清洁任务中的基准测试，填补了学术研究与实际应用之间的空白。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试多针对复杂人形代理或大规模模拟，而缺乏对现实可行的移动清洁机器人的系统评估。

Method: 基于NVIDIA Isaac Sim构建，模拟配备清扫机制和六自由度机械臂的机器人，提供手动设计和程序生成的环境，以及全面的评估指标。

Result: CleanUpBench支持任务完成度、空间效率、运动质量和控制性能的评估，并提供基于启发式策略和地图规划的基线代理。

Conclusion: CleanUpBench为日常场景中的具体化智能提供了可扩展的测试平台，连接了低层次技能评估与全场景测试。

Abstract: Embodied AI benchmarks have advanced navigation, manipulation, and reasoning,
but most target complex humanoid agents or large-scale simulations that are far
from real-world deployment. In contrast, mobile cleaning robots with dual mode
capabilities, such as sweeping and grasping, are rapidly emerging as realistic
and commercially viable platforms. However, no benchmark currently exists that
systematically evaluates these agents in structured, multi-target cleaning
tasks, revealing a critical gap between academic research and real-world
applications. We introduce CleanUpBench, a reproducible and extensible
benchmark for evaluating embodied agents in realistic indoor cleaning
scenarios. Built on NVIDIA Isaac Sim, CleanUpBench simulates a mobile service
robot equipped with a sweeping mechanism and a six-degree-of-freedom robotic
arm, enabling interaction with heterogeneous objects. The benchmark includes
manually designed environments and one procedurally generated layout to assess
generalization, along with a comprehensive evaluation suite covering task
completion, spatial efficiency, motion quality, and control performance. To
support comparative studies, we provide baseline agents based on heuristic
strategies and map-based planning. CleanUpBench bridges the gap between
low-level skill evaluation and full-scene testing, offering a scalable testbed
for grounded, embodied intelligence in everyday settings.

</details>


### [59] [Robust adaptive fuzzy sliding mode control for trajectory tracking for of cylindrical manipulator](https://arxiv.org/abs/2508.05584)
*Van Cuong Pham,Minh Hai Tran,Phuc Anh Nguyen,Ngoc Son Vu,Nga Nguyen Thi*

Main category: cs.RO

TL;DR: 提出一种鲁棒自适应模糊滑模控制（AFSMC）方法，用于提升圆柱形机器人机械臂的轨迹跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 圆柱形机器人机械臂在CNC和3D打印等应用中广泛使用，但传统控制方法在精度和鲁棒性方面存在不足。

Method: 结合模糊逻辑与滑模控制（SMC），模糊逻辑用于近似系统的不确定性动态，SMC确保强鲁棒性。

Result: MATLAB/Simulink仿真显示，AFSMC在轨迹跟踪精度、稳定性和抗干扰能力上显著优于传统方法。

Conclusion: AFSMC能有效提升机器人机械臂的控制性能，为工业应用提供更高精度。

Abstract: This research proposes a robust adaptive fuzzy sliding mode control (AFSMC)
approach to enhance the trajectory tracking performance of cylindrical robotic
manipulators, extensively utilized in applications such as CNC and 3D printing.
The proposed approach integrates fuzzy logic with sliding mode control (SMC) to
bolster adaptability and robustness, with fuzzy logic approximating the
uncertain dynamics of the system, while SMC ensures strong performance.
Simulation results in MATLAB/Simulink demonstrate that AFSMC significantly
improves trajectory tracking accuracy, stability, and disturbance rejection
compared to traditional methods. This research underscores the effectiveness of
AFSMC in controlling robotic manipulators, contributing to enhanced precision
in industrial robotic applications.

</details>


### [60] [Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling](https://arxiv.org/abs/2508.05634)
*Jianpeng Yao,Xiaopan Zhang,Yu Xia,Zejin Wang,Amit K. Roy-Chowdhury,Jiachen Li*

Main category: cs.RO

TL;DR: 论文提出了一种通过考虑行人预测不确定性来增强移动机器人在人群导航中鲁棒性的方法，使用自适应共形推理和约束强化学习，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习训练的移动机器人在面对分布外场景时性能下降的问题。

Method: 通过自适应共形推理生成预测不确定性估计，并利用约束强化学习引导机器人行为。

Result: 在分布内场景中，成功率提升8.80%，碰撞和侵入轨迹次数显著减少；在分布外场景中表现出更强的鲁棒性。

Conclusion: 该方法在真实机器人实验中验证了其安全性和鲁棒性，适用于稀疏和密集人群。

Abstract: Mobile robots navigating in crowds trained using reinforcement learning are
known to suffer performance degradation when faced with out-of-distribution
scenarios. We propose that by properly accounting for the uncertainties of
pedestrians, a robot can learn safe navigation policies that are robust to
distribution shifts. Our method augments agent observations with prediction
uncertainty estimates generated by adaptive conformal inference, and it uses
these estimates to guide the agent's behavior through constrained reinforcement
learning. The system helps regulate the agent's actions and enables it to adapt
to distribution shifts. In the in-distribution setting, our approach achieves a
96.93% success rate, which is over 8.80% higher than the previous
state-of-the-art baselines with over 3.72 times fewer collisions and 2.43 times
fewer intrusions into ground-truth human future trajectories. In three
out-of-distribution scenarios, our method shows much stronger robustness when
facing distribution shifts in velocity variations, policy changes, and
transitions from individual to group dynamics. We deploy our method on a real
robot, and experiments show that the robot makes safe and robust decisions when
interacting with both sparse and dense crowds. Our code and videos are
available on https://gen-safe-nav.github.io/.

</details>


### [61] [Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation](https://arxiv.org/abs/2508.05635)
*Yue Liao,Pengfei Zhou,Siyuan Huang,Donglin Yang,Shengcong Chen,Yuxin Jiang,Yue Hu,Jingbin Cai,Si Liu,Jianlan Luo,Liliang Chen,Shuicheng Yan,Maoqing Yao,Guanghui Ren*

Main category: cs.RO

TL;DR: Genie Envisioner (GE) 是一个统一的机器人操作平台，集成了策略学习、评估和仿真，通过视频生成框架实现。


<details>
  <summary>Details</summary>
Motivation: 为机器人操作提供一个可扩展且实用的基础平台，支持指令驱动的通用智能体。

Method: GE-Base 是一个大规模的视频扩散模型，GE-Act 通过轻量级解码器生成可执行动作，GE-Sim 作为神经模拟器支持闭环策略开发。

Result: 平台具备高保真仿真能力，支持跨多样化的机器人实现通用策略推断。

Conclusion: Genie Envisioner 是一个可扩展的、实用的机器人操作基础平台，相关代码和模型将公开。

Abstract: We introduce Genie Envisioner (GE), a unified world foundation platform for
robotic manipulation that integrates policy learning, evaluation, and
simulation within a single video-generative framework. At its core, GE-Base is
a large-scale, instruction-conditioned video diffusion model that captures the
spatial, temporal, and semantic dynamics of real-world robotic interactions in
a structured latent space. Built upon this foundation, GE-Act maps latent
representations to executable action trajectories through a lightweight,
flow-matching decoder, enabling precise and generalizable policy inference
across diverse embodiments with minimal supervision. To support scalable
evaluation and training, GE-Sim serves as an action-conditioned neural
simulator, producing high-fidelity rollouts for closed-loop policy development.
The platform is further equipped with EWMBench, a standardized benchmark suite
measuring visual fidelity, physical consistency, and instruction-action
alignment. Together, these components establish Genie Envisioner as a scalable
and practical foundation for instruction-driven, general-purpose embodied
intelligence. All code, models, and benchmarks will be released publicly.

</details>
