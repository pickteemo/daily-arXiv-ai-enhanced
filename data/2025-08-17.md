<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]
- [cs.AI](#cs.AI) [Total: 31]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [WiFi-based Global Localization in Large-Scale Environments Leveraging Structural Priors from osmAG](https://arxiv.org/abs/2508.10144)
*Xu Ma,Jiajie Zhang,Fujing Xie,Sören Schwertfeger*

Main category: cs.RO

TL;DR: 提出了一种基于WiFi和OpenStreetMap Area Graph (osmAG)的室内定位框架，结合信号传播建模和osmAG的几何拓扑先验，显著提高了定位精度和空间效率。


<details>
  <summary>Details</summary>
Motivation: 在GPS信号缺失的室内环境中，实现高效、准确的机器人全局定位。

Method: 离线阶段通过迭代优化算法定位WiFi接入点（AP），在线阶段利用增强的osmAG地图进行实时定位。

Result: 离线阶段AP定位误差3.79米（比三边测量提升35.3%），在线阶段指纹区误差3.12米（比KNN指纹提升8.77%），非指纹区误差3.83米（提升81.05%）。

Conclusion: 该框架为室内机器人定位提供了可扩展、经济高效的解决方案，解决了机器人绑架问题。

Abstract: Global localization is essential for autonomous robotics, especially in
indoor environments where the GPS signal is denied. We propose a novel
WiFi-based localization framework that leverages ubiquitous wireless
infrastructure and the OpenStreetMap Area Graph (osmAG) for large-scale indoor
environments. Our approach integrates signal propagation modeling with osmAG's
geometric and topological priors. In the offline phase, an iterative
optimization algorithm localizes WiFi Access Points (APs) by modeling wall
attenuation, achieving a mean localization error of 3.79 m (35.3\% improvement
over trilateration). In the online phase, real-time robot localization uses the
augmented osmAG map, yielding a mean error of 3.12 m in fingerprinted areas
(8.77\% improvement over KNN fingerprinting) and 3.83 m in non-fingerprinted
areas (81.05\% improvement). Comparison with a fingerprint-based method shows
that our approach is much more space efficient and achieves superior
localization accuracy, especially for positions where no fingerprint data are
available. Validated across a complex 11,025 &m^2& multi-floor environment,
this framework offers a scalable, cost-effective solution for indoor robotic
localization, solving the kidnapped robot problem. The code and dataset are
available at https://github.com/XuMa369/osmag-wifi-localization.

</details>


### [2] [Systematic Constraint Formulation and Collision-Free Trajectory Planning Using Space-Time Graphs of Convex Sets](https://arxiv.org/abs/2508.10203)
*Matthew D. Osburn,Cameron K. Peterson,John L. Salmon*

Main category: cs.RO

TL;DR: 论文提出了一种在动态环境中生成最优无碰撞轨迹的方法，利用ST-GCS框架无需初始猜测即可求解。


<details>
  <summary>Details</summary>
Motivation: 动态环境中的空间和时间约束使得数值求解器难以找到初始猜测，需要一种无需初始猜测的优化方法。

Method: 采用空间-时间凸集图（ST-GCS）框架，生成最优无碰撞轨迹，并探索了通用GCS兼容约束的推导方法。

Result: ST-GCS在静态环境中与标准GCS等效，在动态环境中能生成最优无碰撞轨迹。

Conclusion: ST-GCS是一种高效的方法，适用于动态环境中的轨迹优化问题。

Abstract: In this paper, we create optimal, collision-free, time-dependent trajectories
through cluttered dynamic environments. The many spatial and temporal
constraints make finding an initial guess for a numerical solver difficult.
Graphs of Convex Sets (GCS) and the recently developed Space-Time Graphs of
Convex Sets formulation (ST-GCS) enable us to generate optimal minimum distance
collision-free trajectories without providing an initial guess to the solver.
We also explore the derivation of general GCS-compatible constraints and
document an intuitive strategy for adapting general constraints to the
framework. We show that ST-GCS produces equivalent trajectories to the standard
GCS formulation when the environment is static. We then show ST-GCS operating
in dynamic environments to find minimum distance collision-free trajectories.

</details>


### [3] [Hybrid Data-Driven Predictive Control for Robust and Reactive Exoskeleton Locomotion Synthesis](https://arxiv.org/abs/2508.10269)
*Kejun Li,Jeeseop Kim,Maxime Brunet,Marine Pétriaux,Yisong Yue,Aaron D. Ames*

Main category: cs.RO

TL;DR: 提出了一种混合数据驱动预测控制（HDDPC）框架，用于外骨骼机器人的动态环境适应行走。


<details>
  <summary>Details</summary>
Motivation: 解决外骨骼机器人在动态环境中实时反应和步态规划的挑战。

Method: 结合Hankel矩阵建模系统动态，整合步态规划和轨迹规划，实现在线重规划。

Result: 在Atalante外骨骼上验证了方法的鲁棒性和适应性。

Conclusion: HDDPC框架为外骨骼机器人提供了高效、统一的运动合成解决方案。

Abstract: Robust bipedal locomotion in exoskeletons requires the ability to dynamically
react to changes in the environment in real time. This paper introduces the
hybrid data-driven predictive control (HDDPC) framework, an extension of the
data-enabled predictive control, that addresses these challenges by
simultaneously planning foot contact schedules and continuous domain
trajectories. The proposed framework utilizes a Hankel matrix-based
representation to model system dynamics, incorporating step-to-step (S2S)
transitions to enhance adaptability in dynamic environments. By integrating
contact scheduling with trajectory planning, the framework offers an efficient,
unified solution for locomotion motion synthesis that enables robust and
reactive walking through online replanning. We validate the approach on the
Atalante exoskeleton, demonstrating improved robustness and adaptability.

</details>


### [4] [ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver](https://arxiv.org/abs/2508.10333)
*Wenxuan Song,Ziyang Zhou,Han Zhao,Jiayi Chen,Pengxiang Ding,Haodong Yan,Yuxin Huang,Feilong Tang,Donglin Wang,Haoang Li*

Main category: cs.RO

TL;DR: ReconVLA是一种通过重构视觉注意力区域来改进视觉-语言-动作模型的方法，解决了现有模型注意力分散的问题。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型在视觉注意力分配上表现不佳，注意力分散，无法聚焦目标区域。

Method: 提出ReconVLA模型，利用扩散变换器重构图像中的目标区域，引导模型学习细粒度表示并准确分配视觉注意力。

Result: 实验证明该方法在仿真和真实场景中均表现出色，实现了精确操作和泛化能力。

Conclusion: ReconVLA通过隐式接地范式显著提升了视觉-语言-动作模型的性能。

Abstract: Recent advances in Vision-Language-Action (VLA) models have enabled robotic
agents to integrate multimodal understanding with action execution. However,
our empirical analysis reveals that current VLAs struggle to allocate visual
attention to target regions. Instead, visual attention is always dispersed. To
guide the visual attention grounding on the correct target, we propose
ReconVLA, a reconstructive VLA model with an implicit grounding paradigm.
Conditioned on the model's visual outputs, a diffusion transformer aims to
reconstruct the gaze region of the image, which corresponds to the target
manipulated objects. This process prompts the VLA model to learn fine-grained
representations and accurately allocate visual attention, thus effectively
leveraging task-specific visual information and conducting precise
manipulation. Moreover, we curate a large-scale pretraining dataset comprising
over 100k trajectories and 2 million data samples from open-source robotic
datasets, further boosting the model's generalization in visual reconstruction.
Extensive experiments in simulation and the real world demonstrate the
superiority of our implicit grounding method, showcasing its capabilities of
precise manipulation and generalization. Our project page is
https://zionchow.github.io/ReconVLA/.

</details>


### [5] [BEASST: Behavioral Entropic Gradient based Adaptive Source Seeking for Mobile Robots](https://arxiv.org/abs/2508.10363)
*Donipolo Ghimire,Aamodh Suresh,Carlos Nieto-Granda,Solmaz S. Kia*

Main category: cs.RO

TL;DR: BEASST是一种新型机器人源搜索框架，通过行为熵和概率加权函数平衡探索与利用，在复杂未知环境中高效定位目标。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在未知环境中源搜索的效率问题，平衡探索与利用，适应信号可靠性和任务紧迫性。

Method: 利用行为熵和Prelec概率加权函数定义目标函数，动态调整机器人行为（从风险规避到风险寻求）。

Result: 实验证明BEASST在路径长度减少15%和源定位速度提升20%上优于现有方法。

Conclusion: BEASST通过智能不确定性驱动导航，在复杂环境中表现优越，具有理论和实践稳定性。

Abstract: This paper presents BEASST (Behavioral Entropic Gradient-based Adaptive
Source Seeking for Mobile Robots), a novel framework for robotic source seeking
in complex, unknown environments. Our approach enables mobile robots to
efficiently balance exploration and exploitation by modeling normalized signal
strength as a surrogate probability of source location. Building on Behavioral
Entropy(BE) with Prelec's probability weighting function, we define an
objective function that adapts robot behavior from risk-averse to risk-seeking
based on signal reliability and mission urgency. The framework provides
theoretical convergence guarantees under unimodal signal assumptions and
practical stability under bounded disturbances. Experimental validation across
DARPA SubT and multi-room scenarios demonstrates that BEASST consistently
outperforms state-of-the-art methods, achieving 15% reduction in path length
and 20% faster source localization through intelligent uncertainty-driven
navigation that dynamically transitions between aggressive pursuit and cautious
exploration.

</details>


### [6] [Few-shot Vision-based Human Activity Recognition with MLLM-based Visual Reinforcement Learning](https://arxiv.org/abs/2508.10371)
*Wenqi Zheng,Yutaka Arakawa*

Main category: cs.RO

TL;DR: 论文提出了一种名为FAVOR的少样本人类活动识别方法，通过视觉强化学习提升多模态大语言模型的泛化能力和推理能力。


<details>
  <summary>Details</summary>
Motivation: 在多模态人类活动识别（HAR）领域，强化学习的应用尚未充分探索，尤其是在少样本场景下。

Method: 结合视觉强化学习，利用多模态大语言模型生成候选响应，并通过奖励函数和GRPO算法优化模型。

Result: 在四个HAR数据集和五种不同设置下的实验证明了该方法的优越性。

Conclusion: FAVOR方法显著提升了少样本识别能力，并增强了模型的可解释性。

Abstract: Reinforcement learning in large reasoning models enables learning from
feedback on their outputs, making it particularly valuable in scenarios where
fine-tuning data is limited. However, its application in multi-modal human
activity recognition (HAR) domains remains largely underexplored. Our work
extends reinforcement learning to the human activity recognition domain with
multimodal large language models. By incorporating visual reinforcement
learning in the training process, the model's generalization ability on
few-shot recognition can be greatly improved. Additionally, visual
reinforcement learning can enhance the model's reasoning ability and enable
explainable analysis in the inference stage. We name our few-shot human
activity recognition method with visual reinforcement learning FAVOR.
Specifically, our approach first utilizes a multimodal large language model
(MLLM) to generate multiple candidate responses for the human activity image,
each containing reasoning traces and final answers. These responses are then
evaluated using reward functions, and the MLLM model is subsequently optimized
using the Group Relative Policy Optimization (GRPO) algorithm. In this way, the
MLLM model can be adapted to human activity recognition with only a few
samples. Extensive experiments on four human activity recognition datasets and
five different settings demonstrate the superiority of the proposed method.

</details>


### [7] [A Semantic-Aware Framework for Safe and Intent-Integrative Assistance in Upper-Limb Exoskeletons](https://arxiv.org/abs/2508.10378)
*Yu Chen,Shu Miao,Chunyu Wu,Jingsong Mu,Bo OuYang,Xiang Li*

Main category: cs.RO

TL;DR: 本文提出了一种语义感知框架，通过集成大语言模型到任务规划中，使上肢外骨骼能根据任务语义调整辅助配置，实现安全且符合用户意图的辅助。


<details>
  <summary>Details</summary>
Motivation: 现有上肢外骨骼缺乏对任务语义的理解和与用户的协作规划能力，限制了其通用性。

Method: 框架包括透明模式捕捉用户意图、语义信息提取、扩散异常检测器监控交互状态、在线轨迹优化和阻抗控制。

Result: 实验表明，该方法能有效适应用户认知、语义变化任务，并对异常做出可靠响应。

Conclusion: 提出的语义感知框架提升了上肢外骨骼的适应性和安全性。

Abstract: Upper-limb exoskeletons are primarily designed to provide assistive support
by accurately interpreting and responding to human intentions. In home-care
scenarios, exoskeletons are expected to adapt their assistive configurations
based on the semantic information of the task, adjusting appropriately in
accordance with the nature of the object being manipulated. However, existing
solutions often lack the ability to understand task semantics or
collaboratively plan actions with the user, limiting their generalizability. To
address this challenge, this paper introduces a semantic-aware framework that
integrates large language models into the task planning framework, enabling the
delivery of safe and intent-integrative assistance. The proposed approach
begins with the exoskeleton operating in transparent mode to capture the
wearer's intent during object grasping. Once semantic information is extracted
from the task description, the system automatically configures appropriate
assistive parameters. In addition, a diffusion-based anomaly detector is used
to continuously monitor the state of human-robot interaction and trigger
real-time replanning in response to detected anomalies. During task execution,
online trajectory refinement and impedance control are used to ensure safety
and regulate human-robot interaction. Experimental results demonstrate that the
proposed method effectively aligns with the wearer's cognition, adapts to
semantically varying tasks, and responds reliably to anomalies.

</details>


### [8] [Super LiDAR Reflectance for Robotic Perception](https://arxiv.org/abs/2508.10398)
*Wei Gao,Jie Zhang,Mingle Zhao,Zhiyuan Zhang,Shu Kong,Maani Ghaffari,Dezhen Song,Cheng-Zhong Xu,Hui Kong*

Main category: cs.RO

TL;DR: 论文提出了一种从稀疏LiDAR数据生成密集反射图像的创新框架，解决了低成本LiDAR因数据稀疏性受限的问题。


<details>
  <summary>Details</summary>
Motivation: 传统上，主动光学传感未被视为主流视觉模态，但技术进步使其潜力显现。低成本LiDAR因数据稀疏性应用受限，亟需解决方案。

Method: 利用非重复扫描LiDAR（NRS-LiDAR）特性，提出反射校准和动态场景处理技术，构建密集反射图像生成框架。

Result: 开发了LiDAR反射图像密集化数据集和专用网络，成功应用于闭环检测和车道识别等任务。

Conclusion: 该框架为低成本LiDAR的广泛应用提供了新思路，推动了主动视觉技术的发展。

Abstract: Conventionally, human intuition often defines vision as a modality of passive
optical sensing, while active optical sensing is typically regarded as
measuring rather than the default modality of vision. However, the situation
now changes: sensor technologies and data-driven paradigms empower active
optical sensing to redefine the boundaries of vision, ushering in a new era of
active vision. Light Detection and Ranging (LiDAR) sensors capture reflectance
from object surfaces, which remains invariant under varying illumination
conditions, showcasing significant potential in robotic perception tasks such
as detection, recognition, segmentation, and Simultaneous Localization and
Mapping (SLAM). These applications often rely on dense sensing capabilities,
typically achieved by high-resolution, expensive LiDAR sensors. A key challenge
with low-cost LiDARs lies in the sparsity of scan data, which limits their
broader application. To address this limitation, this work introduces an
innovative framework for generating dense LiDAR reflectance images from sparse
data, leveraging the unique attributes of non-repeating scanning LiDAR
(NRS-LiDAR). We tackle critical challenges, including reflectance calibration
and the transition from static to dynamic scene domains, facilitating the
reconstruction of dense reflectance images in real-world settings. The key
contributions of this work include a comprehensive dataset for LiDAR
reflectance image densification, a densification network tailored for
NRS-LiDAR, and diverse applications such as loop closure and traffic lane
detection using the generated dense reflectance images.

</details>


### [9] [Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning](https://arxiv.org/abs/2508.10399)
*Wenlong Liang,Rui Zhou,Yang Ma,Bing Zhang,Songlin Li,Yijia Liao,Ping Kuang*

Main category: cs.RO

TL;DR: 本文综述了大模型赋能的具身AI，重点关注自主决策和具身学习，探讨了分层与端到端决策范式，以及大模型如何增强模仿学习和强化学习，并首次将世界模型纳入具身AI的讨论。


<details>
  <summary>Details</summary>
Motivation: 具身AI是实现通用人工智能（AGI）的重要途径，但目前在开放动态环境中实现人类水平智能仍具挑战。大模型的突破为具身AI的感知、交互、规划和学习带来了革命性进展。

Method: 文章分析了分层决策（高层规划、低层执行与反馈）和端到端决策（视觉-语言-动作模型），并探讨了大模型如何增强模仿学习和强化学习。此外，首次将世界模型引入具身AI的研究。

Result: 大模型显著提升了具身AI的决策和学习能力，但仍有挑战存在。

Conclusion: 尽管取得了进展，具身AI仍面临挑战，这些挑战可能成为未来的研究方向。

Abstract: Embodied AI aims to develop intelligent systems with physical forms capable
of perceiving, decision-making, acting, and learning in real-world
environments, providing a promising way to Artificial General Intelligence
(AGI). Despite decades of explorations, it remains challenging for embodied
agents to achieve human-level intelligence for general-purpose tasks in open
dynamic environments. Recent breakthroughs in large models have revolutionized
embodied AI by enhancing perception, interaction, planning and learning. In
this article, we provide a comprehensive survey on large model empowered
embodied AI, focusing on autonomous decision-making and embodied learning. We
investigate both hierarchical and end-to-end decision-making paradigms,
detailing how large models enhance high-level planning, low-level execution,
and feedback for hierarchical decision-making, and how large models enhance
Vision-Language-Action (VLA) models for end-to-end decision making. For
embodied learning, we introduce mainstream learning methodologies, elaborating
on how large models enhance imitation learning and reinforcement learning
in-depth. For the first time, we integrate world models into the survey of
embodied AI, presenting their design methods and critical roles in enhancing
decision-making and learning. Though solid advances have been achieved,
challenges still exist, which are discussed at the end of this survey,
potentially as the further research directions.

</details>


### [10] [CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model](https://arxiv.org/abs/2508.10416)
*Zhuoyuan Yu,Yuxing Long,Zihan Yang,Chengyan Zeng,Hongwei Fan,Jiyao Zhang,Hao Dong*

Main category: cs.RO

TL;DR: 论文提出了一种名为Self-correction Flywheel的后训练范式，通过利用模型的错误轨迹生成自校正数据，逐步提升视觉与语言导航模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉与语言导航模型在执行指令时容易偏离正确轨迹，且缺乏有效的错误校正能力，限制了其性能提升。

Method: 提出Self-correction Flywheel范式，将模型的错误轨迹视为有价值的数据源，开发了识别偏差并自动生成自校正数据的方法。

Result: 在R2R-CE和RxR-CE基准测试中，模型CorrectNav分别达到65.1%和69.3%的成功率，优于之前最佳模型。

Conclusion: Self-correction Flywheel范式显著提升了模型的错误校正能力和导航性能，适用于动态障碍物避障和长指令跟随。

Abstract: Existing vision-and-language navigation models often deviate from the correct
trajectory when executing instructions. However, these models lack effective
error correction capability, hindering their recovery from errors. To address
this challenge, we propose Self-correction Flywheel, a novel post-training
paradigm. Instead of considering the model's error trajectories on the training
set as a drawback, our paradigm emphasizes their significance as a valuable
data source. We have developed a method to identify deviations in these error
trajectories and devised innovative techniques to automatically generate
self-correction data for perception and action. These self-correction data
serve as fuel to power the model's continued training. The brilliance of our
paradigm is revealed when we re-evaluate the model on the training set,
uncovering new error trajectories. At this time, the self-correction flywheel
begins to spin. Through multiple flywheel iterations, we progressively enhance
our monocular RGB-based VLA navigation model CorrectNav. Experiments on R2R-CE
and RxR-CE benchmarks show CorrectNav achieves new state-of-the-art success
rates of 65.1% and 69.3%, surpassing prior best VLA navigation models by 8.2%
and 16.4%. Real robot tests in various indoor and outdoor environments
demonstrate \method's superior capability of error correction, dynamic obstacle
avoidance, and long instruction following.

</details>


### [11] [MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion](https://arxiv.org/abs/2508.10423)
*Qi Liu,Xiaopeng Zhang,Mingshan Tan,Shuaikang Ma,Jinliang Ding,Yanjie Li*

Main category: cs.RO

TL;DR: 提出一种基于协作异构多智能体深度强化学习（MARL）的新方法MASH，用于提升单个人形机器人的运动能力，通过将每个肢体视为独立智能体并共享全局批评器，显著优于传统单智能体方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法多采用单智能体强化学习或MARL用于多机器人系统，而本研究探索将协作异构MARL应用于单个人形机器人，以优化其运动能力。

Method: 提出MASH方法，将机器人的每个肢体（腿和手臂）视为独立智能体，通过共享全局批评器进行协作学习，探索动作空间。

Result: 实验表明，MASH加速了训练收敛并提升了全身协作能力，优于传统单智能体强化学习方法。

Conclusion: 该研究推动了MARL在单个人形机器人控制中的应用，为高效运动策略提供了新思路。

Abstract: This paper proposes a novel method to enhance locomotion for a single
humanoid robot through cooperative-heterogeneous multi-agent deep reinforcement
learning (MARL). While most existing methods typically employ single-agent
reinforcement learning algorithms for a single humanoid robot or MARL
algorithms for multi-robot system tasks, we propose a distinct paradigm:
applying cooperative-heterogeneous MARL to optimize locomotion for a single
humanoid robot. The proposed method, multi-agent reinforcement learning for
single humanoid locomotion (MASH), treats each limb (legs and arms) as an
independent agent that explores the robot's action space while sharing a global
critic for cooperative learning. Experiments demonstrate that MASH accelerates
training convergence and improves whole-body cooperation ability, outperforming
conventional single-agent reinforcement learning methods. This work advances
the integration of MARL into single-humanoid-robot control, offering new
insights into efficient locomotion strategies.

</details>


### [12] [Enabling Generic Robot Skill Implementation Using Object Oriented Programming](https://arxiv.org/abs/2508.10497)
*Abdullah Farrukh,Achim Wagner,Martin Ruskowski*

Main category: cs.RO

TL;DR: 提出一个简化机器人系统接口的软件框架，减少部署工作，适用于中小企业及研究人员。


<details>
  <summary>Details</summary>
Motivation: 中小企业和研究人员在缺乏机器人专业知识的情况下，部署和维护机器人系统面临挑战，依赖外部支持可能导致供应商锁定。

Method: 使用Python实现一个抽象层，统一不同厂商和型号的机器人接口。

Result: 开发了一个原型，应用于包含Yaskawa Motoman GP4的拣货单元。

Conclusion: 该框架简化了机器人系统的部署，降低了对外部支持的依赖。

Abstract: Developing robotic algorithms and integrating a robotic subsystem into a
larger system can be a difficult task. Particularly in small and medium-sized
enterprises (SMEs) where robotics expertise is lacking, implementing,
maintaining and developing robotic systems can be a challenge. As a result,
many companies rely on external expertise through system integrators, which, in
some cases, can lead to vendor lock-in and external dependency. In the academic
research on intelligent manufacturing systems, robots play a critical role in
the design of robust autonomous systems. Similar challenges are faced by
researchers who want to use robotic systems as a component in a larger smart
system, without having to deal with the complexity and vastness of the robot
interfaces in detail. In this paper, we propose a software framework that
reduces the effort required to deploy a working robotic system. The focus is
solely on providing a concept for simplifying the different interfaces of a
modern robot system and using an abstraction layer for different manufacturers
and models. The Python programming language is used to implement a prototype of
the concept. The target system is a bin-picking cell containing a Yaskawa
Motoman GP4.

</details>


### [13] [KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection](https://arxiv.org/abs/2508.10511)
*Andrea Rosasco,Federico Ceola,Giulia Pasquale,Lorenzo Natale*

Main category: cs.RO

TL;DR: KDPE提出了一种基于核密度估计的策略，用于过滤Diffusion Policy生成的有害轨迹，同时保持低计算开销，提升了性能。


<details>
  <summary>Details</summary>
Motivation: Diffusion Policy在机器人行为克隆中表现优异，但其随机性和对数据异常值的敏感性可能导致策略执行时偏离数据分布。

Method: KDPE利用核密度估计（采用流形感知核）过滤Diffusion Policy生成的轨迹，适用于末端执行器的位置、姿态和夹爪状态。

Result: KDPE在模拟单臂任务和真实机器人实验中表现优于Diffusion Policy。

Conclusion: KDPE通过核密度估计有效解决了Diffusion Policy的局限性，提升了机器人策略的鲁棒性和性能。

Abstract: Learning robot policies that capture multimodality in the training data has
been a long-standing open challenge for behavior cloning. Recent approaches
tackle the problem by modeling the conditional action distribution with
generative models. One of these approaches is Diffusion Policy, which relies on
a diffusion model to denoise random points into robot action trajectories.
While achieving state-of-the-art performance, it has two main drawbacks that
may lead the robot out of the data distribution during policy execution. First,
the stochasticity of the denoising process can highly impact on the quality of
generated trajectory of actions. Second, being a supervised learning approach,
it can learn data outliers from the dataset used for training. Recent work
focuses on mitigating these limitations by combining Diffusion Policy either
with large-scale training or with classical behavior cloning algorithms.
Instead, we propose KDPE, a Kernel Density Estimation-based strategy that
filters out potentially harmful trajectories output of Diffusion Policy while
keeping a low test-time computational overhead. For Kernel Density Estimation,
we propose a manifold-aware kernel to model a probability density function for
actions composed of end-effector Cartesian position, orientation, and gripper
state. KDPE overall achieves better performance than Diffusion Policy on
simulated single-arm tasks and real robot experiments.
  Additional material and code are available on our project page
https://hsp-iit.github.io/KDPE/.

</details>


### [14] [MLM: Learning Multi-task Loco-Manipulation Whole-Body Control for Quadruped Robot with Arm](https://arxiv.org/abs/2508.10538)
*Xin Liu,Bida Ma,Chenkun Qi,Yan Ding,Zhaxizhuoma,Guorong Zhang,Pengan Chen,Kehui Liu,Zhongjie Jia,Chuyue Guan,Yule Mo,Jiaqi Liu,Feng Gao,Jiangwei Zhong,Bin Zhao,Xuelong Li*

Main category: cs.RO

TL;DR: 提出MLM强化学习框架，结合真实与仿真数据，实现六自由度机械臂四足机器人的全身运动与多任务操控。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人全身运动与多任务控制的挑战。

Method: 引入轨迹库与自适应课程采样机制，提出轨迹-速度预测策略网络。

Result: 仿真与真实实验中验证了框架的有效性，实现零样本迁移。

Conclusion: MLM框架在多任务执行中表现出色，适用于复杂场景。

Abstract: Whole-body loco-manipulation for quadruped robots with arm remains a
challenging problem, particularly in achieving multi-task control. To address
this, we propose MLM, a reinforcement learning framework driven by both
real-world and simulation data. It enables a six-DoF robotic arm--equipped
quadruped robot to perform whole-body loco-manipulation for multiple tasks
autonomously or under human teleoperation. To address the problem of balancing
multiple tasks during the learning of loco-manipulation, we introduce a
trajectory library with an adaptive, curriculum-based sampling mechanism. This
approach allows the policy to efficiently leverage real-world collected
trajectories for learning multi-task loco-manipulation. To address deployment
scenarios with only historical observations and to enhance the performance of
policy execution across tasks with different spatial ranges, we propose a
Trajectory-Velocity Prediction policy network. It predicts unobservable future
trajectories and velocities. By leveraging extensive simulation data and
curriculum-based rewards, our controller achieves whole-body behaviors in
simulation and zero-shot transfer to real-world deployment. Ablation studies in
simulation verify the necessity and effectiveness of our approach, while
real-world experiments on the Go2 robot with an Airbot robotic arm demonstrate
the policy's good performance in multi-task execution.

</details>


### [15] [Why Report Failed Interactions With Robots?! Towards Vignette-based Interaction Quality](https://arxiv.org/abs/2508.10603)
*Agnes Axelsson,Merle Reimann,Ronald Cumbal,Hannah Pelikan,Divesh Lala*

Main category: cs.RO

TL;DR: 论文提出使用民族志小故事（vignettes）来揭示人机交互（HRI）中的失败案例，弥补现有研究的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs提升了人机交互质量，但与人人交互相比仍存在不足，且失败案例因情境而异，难以泛化。

Method: 提出使用民族志小故事方法，基于个人经验撰写案例，突出多学科视角下的失败。

Result: 小故事能有效沟通失败案例、提升机器人能力透明度，并记录研究中易忽略的意外行为。

Conclusion: 建议将小故事作为现有交互评估方法的补充工具。

Abstract: Although the quality of human-robot interactions has improved with the advent
of LLMs, there are still various factors that cause systems to be sub-optimal
when compared to human-human interactions. The nature and criticality of
failures are often dependent on the context of the interaction and so cannot be
generalized across the wide range of scenarios and experiments which have been
implemented in HRI research. In this work we propose the use of a technique
overlooked in the field of HRI, ethnographic vignettes, to clearly highlight
these failures, particularly those that are rarely documented. We describe the
methodology behind the process of writing vignettes and create our own based on
our personal experiences with failures in HRI systems. We emphasize the
strength of vignettes as the ability to communicate failures from a
multi-disciplinary perspective, promote transparency about the capabilities of
robots, and document unexpected behaviours which would otherwise be omitted
from research reports. We encourage the use of vignettes to augment existing
interaction evaluation methods.

</details>


### [16] [Synthesis of Deep Neural Networks with Safe Robust Adaptive Control for Reliable Operation of Wheeled Mobile Robots](https://arxiv.org/abs/2508.10634)
*Mehdi Heydari Shahna,Jouni Mattila*

Main category: cs.RO

TL;DR: 论文提出了一种结合深度神经网络（DNN）和鲁棒自适应控制（RAC）的分层控制策略，用于重型轮式移动机器人（WMR），以确保高精度控制和安全操作。


<details>
  <summary>Details</summary>
Motivation: 重型WMR在严格国际标准下运行且易受干扰，传统黑盒DNN方法难以满足其安全需求。

Method: 设计了一个分层控制策略，包括DNN主控策略和两级安全层（低层RAC和高层监控）。

Result: 实验验证了该策略在6000 kg WMR上的有效性，确保了系统稳定性和安全性。

Conclusion: 结合DNN和RAC的分层控制策略能够兼顾高精度和安全性，适用于重型WMR。

Abstract: Deep neural networks (DNNs) can enable precise control while maintaining low
computational costs by circumventing the need for dynamic modeling. However,
the deployment of such black-box approaches remains challenging for heavy-duty
wheeled mobile robots (WMRs), which are subject to strict international
standards and prone to faults and disturbances. We designed a hierarchical
control policy for heavy-duty WMRs, monitored by two safety layers with
differing levels of authority. To this end, a DNN policy was trained and
deployed as the primary control strategy, providing high-precision performance
under nominal operating conditions. When external disturbances arise and reach
a level of intensity such that the system performance falls below a predefined
threshold, a low-level safety layer intervenes by deactivating the primary
control policy and activating a model-free robust adaptive control (RAC)
policy. This transition enables the system to continue operating while ensuring
stability by effectively managing the inherent trade-off between system
robustness and responsiveness. Regardless of the control policy in use, a
high-level safety layer continuously monitors system performance during
operation. It initiates a shutdown only when disturbances become sufficiently
severe such that compensation is no longer viable and continued operation would
jeopardize the system or its environment. The proposed synthesis of DNN and RAC
policy guarantees uniform exponential stability of the entire WMR system while
adhering to safety standards to some extent. The effectiveness of the proposed
approach was further validated through real-time experiments using a 6,000 kg
WMR.

</details>


### [17] [An Open-Source User-Friendly Interface for Simulating Magnetic Soft Robots using Simulation Open Framework Architecture (SOFA)](https://arxiv.org/abs/2508.10686)
*Carla Wehner,Finn Schubert,Heiko Hellkamp,Julius Hahnewald,Kilian Scheafer,Muhammad Bilal Khan,Oliver Gutfleisch*

Main category: cs.RO

TL;DR: 介绍了一个基于SOFA的开源、用户友好型仿真工具，用于模拟磁性软体机器人，填补了现有平台对磁性材料支持的不足。


<details>
  <summary>Details</summary>
Motivation: 现有仿真工具缺乏对磁性材料的专门支持，且对不同专业水平的研究人员不够友好。

Method: 使用SOFA框架开发了一个仿真界面，支持定义材料属性、施加磁场并实时观察变形，集成了直观控制和应力分析功能。

Result: 通过四个基准模型（梁、三指和四指夹持器、蝴蝶）验证了工具的功能性和易用性。

Conclusion: 该工具适用于不同水平的研究人员，未来将通过实验验证和与行业标准求解器对比进一步提升精度。

Abstract: Soft robots, particularly magnetic soft robots, require specialized
simulation tools to accurately model their deformation under external magnetic
fields. However, existing platforms often lack dedicated support for magnetic
materials, making them difficult to use for researchers at different expertise
levels. This work introduces an open-source, user-friendly simulation interface
using the Simulation Open Framework Architecture (SOFA), specifically designed
to model magnetic soft robots. The tool enables users to define material
properties, apply magnetic fields, and observe resulting deformations in real
time. By integrating intuitive controls and stress analysis capabilities, it
aims to bridge the gap between theoretical modeling and practical design. Four
benchmark models - a beam, three- and four-finger grippers, and a butterfly -
demonstrate its functionality. The software's ease of use makes it accessible
to both beginners and advanced researchers. Future improvements will refine
accuracy through experimental validation and comparison with industry-standard
finite element solvers, ensuring realistic and predictive simulations of
magnetic soft robots.

</details>


### [18] [Biasing Frontier-Based Exploration with Saliency Areas](https://arxiv.org/abs/2508.10689)
*Matteo Luperto,Valerii Stakanov,Giacomo Boracchi,Nicola Basilico,Francesco Amigoni*

Main category: cs.RO

TL;DR: 论文提出了一种通过神经网络识别显著区域的方法，以优化机器人自主探索策略，显著提升探索效率。


<details>
  <summary>Details</summary>
Motivation: 现有自主探索策略通常仅关注最大化探索面积，而忽略了环境中某些区域对发现未知区域的重要性。

Method: 利用神经网络生成显著图，识别对探索至关重要的区域，并将这些信息融入现有探索策略中。

Result: 实验表明，显著区域的引入显著影响了机器人的探索行为，提升了探索效率。

Conclusion: 通过识别显著区域，可以更高效地指导机器人探索未知环境。

Abstract: Autonomous exploration is a widely studied problem where a robot
incrementally builds a map of a previously unknown environment. The robot
selects the next locations to reach using an exploration strategy. To do so,
the robot has to balance between competing objectives, like exploring the
entirety of the environment, while being as fast as possible. Most exploration
strategies try to maximise the explored area to speed up exploration; however,
they do not consider that parts of the environment are more important than
others, as they lead to the discovery of large unknown areas. We propose a
method that identifies \emph{saliency areas} as those areas that are of high
interest for exploration, by using saliency maps obtained from a neural network
that, given the current map, implements a termination criterion to estimate
whether the environment can be considered fully-explored or not. We use
saliency areas to bias some widely used exploration strategies, showing, with
an extensive experimental campaign, that this knowledge can significantly
influence the behavior of the robot during exploration.

</details>


### [19] [Learning Task Execution Hierarchies for Redundant Robots](https://arxiv.org/abs/2508.10780)
*Alessandro Adami,Aris Synodinos,Matteo Iovino,Ruggero Carli,Pietro Falco*

Main category: cs.RO

TL;DR: 提出一种自动学习任务堆叠（SoT）层次和参数的新框架，结合强化学习和遗传编程，无需人工干预即可发现任务优先级和控制策略。


<details>
  <summary>Details</summary>
Motivation: 传统SoT由专家手动设计，限制了其适应性和可访问性，需要一种自动化的解决方案。

Method: 结合强化学习和遗传编程，通过基于精度、安全性和执行时间的成本函数指导学习过程。

Result: 在移动-YuMi平台上验证，学习到的SoT使机器人能动态适应环境变化，平衡竞争目标并保持稳健任务执行。

Conclusion: 该方法为复杂机器人冗余管理提供了通用且用户友好的解决方案，减少了对专家设计的依赖。

Abstract: Modern robotic systems, such as mobile manipulators, humanoids, and aerial
robots with arms, often possess high redundancy, enabling them to perform
multiple tasks simultaneously. Managing this redundancy is key to achieving
reliable and flexible behavior. A widely used approach is the Stack of Tasks
(SoT), which organizes control objectives by priority within a unified
framework. However, traditional SoTs are manually designed by experts, limiting
their adaptability and accessibility. This paper introduces a novel framework
that automatically learns both the hierarchy and parameters of a SoT from
user-defined objectives. By combining Reinforcement Learning and Genetic
Programming, the system discovers task priorities and control strategies
without manual intervention. A cost function based on intuitive metrics such as
precision, safety, and execution time guides the learning process. We validate
our method through simulations and experiments on the mobile-YuMi platform, a
dual-arm mobile manipulator with high redundancy. Results show that the learned
SoTs enable the robot to dynamically adapt to changing environments and inputs,
balancing competing objectives while maintaining robust task execution. This
approach provides a general and user-friendly solution for redundancy
management in complex robots, advancing human-centered robot programming and
reducing the need for expert design.

</details>


### [20] [The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems](https://arxiv.org/abs/2508.10798)
*Troi Williams*

Main category: cs.RO

TL;DR: 论文提出SET感知因素框架，通过系统分析环境、目标和自身因素对感知的影响，量化不确定性，以提升自动驾驶系统的安全性和公众信任。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的部署引发对安全和可靠性的担忧，尤其是感知失败可能导致事故，影响公众信任。

Method: 引入SET框架，包括SET状态树和SET因素树，用于分类和建模感知任务中的不确定性，并开发感知因素模型量化风险。

Result: 框架提供透明、标准化的方法，识别、建模和传达感知风险，从而增强安全保证和公众信任。

Conclusion: SET框架为自动驾驶系统的感知可靠性提供系统化分析工具，有助于提升安全性和公众信任。

Abstract: Future autonomous systems promise significant societal benefits, yet their
deployment raises concerns about safety and trustworthiness. A key concern is
assuring the reliability of robot perception, as perception seeds safe
decision-making. Failures in perception are often due to complex yet common
environmental factors and can lead to accidents that erode public trust. To
address this concern, we introduce the SET (Self, Environment, and Target)
Perceptual Factors Framework. We designed the framework to systematically
analyze how factors such as weather, occlusion, or sensor limitations
negatively impact perception. To achieve this, the framework employs SET State
Trees to categorize where such factors originate and SET Factor Trees to model
how these sources and factors impact perceptual tasks like object detection or
pose estimation. Next, we develop Perceptual Factor Models using both trees to
quantify the uncertainty for a given task. Our framework aims to promote
rigorous safety assurances and cultivate greater public understanding and trust
in autonomous systems by offering a transparent and standardized method for
identifying, modeling, and communicating perceptual risks.

</details>


### [21] [A Multimodal Neural Network for Recognizing Subjective Self-Disclosure Towards Social Robots](https://arxiv.org/abs/2508.10828)
*Henry Powell,Guy Laban,Emily S. Cross*

Main category: cs.RO

TL;DR: 本文提出了一种基于情感识别文献的多模态注意力网络，用于建模人类与机器人互动中的主观自我披露行为，并通过新的损失函数提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 主观自我披露是人类社交互动的重要特征，但目前缺乏计算模型来准确建模，尤其是人类与机器人互动中的自我披露行为。随着社交机器人在多种社交场景中的应用需求增加，这一研究变得尤为重要。

Method: 开发了一种基于情感识别文献的多模态注意力网络，使用自收集的自我披露视频语料库进行训练，并提出了新的损失函数——尺度保持交叉熵损失。

Result: 最佳模型在新损失函数下实现了F1分数0.83，比基线模型提高了0.48。

Conclusion: 该研究为社交机器人识别互动伙伴的自我披露行为提供了重要进展，这对具备社交认知能力的机器人至关重要。

Abstract: Subjective self-disclosure is an important feature of human social
interaction. While much has been done in the social and behavioural literature
to characterise the features and consequences of subjective self-disclosure,
little work has been done thus far to develop computational systems that are
able to accurately model it. Even less work has been done that attempts to
model specifically how human interactants self-disclose with robotic partners.
It is becoming more pressing as we require social robots to work in conjunction
with and establish relationships with humans in various social settings. In
this paper, our aim is to develop a custom multimodal attention network based
on models from the emotion recognition literature, training this model on a
large self-collected self-disclosure video corpus, and constructing a new loss
function, the scale preserving cross entropy loss, that improves upon both
classification and regression versions of this problem. Our results show that
the best performing model, trained with our novel loss function, achieves an F1
score of 0.83, an improvement of 0.48 from the best baseline model. This result
makes significant headway in the aim of allowing social robots to pick up on an
interaction partner's self-disclosures, an ability that will be essential in
social robots with social cognition.

</details>


### [22] [CVIRO: A Consistent and Tightly-Coupled Visual-Inertial-Ranging Odometry on Lie Groups](https://arxiv.org/abs/2508.10867)
*Yizhi Zhou,Ziwei Kang,Jiawei Xia,Xuan Wang*

Main category: cs.RO

TL;DR: 论文提出了一种基于李群的视觉-惯性-测距里程计系统（CVIRO），通过联合估计机器人状态和UWB锚点状态，解决了UWB辅助VIO系统中的不一致性问题。


<details>
  <summary>Details</summary>
Motivation: UWB辅助VIO系统中，不一致性主要由系统可观测性未正确保持和UWB锚点位置校准不确定性被忽略引起，导致定位性能下降。

Method: 提出CVIRO系统，将UWB锚点状态纳入系统状态，利用李群的不变误差特性确保可观测一致性，并联合估计机器人和锚点状态。

Result: 理论证明和实验表明，CVIRO在定位精度和一致性上优于现有方法。

Conclusion: CVIRO通过李群方法和联合估计，有效解决了UWB辅助VIO系统中的不一致性问题，提升了定位性能。

Abstract: Ultra Wideband (UWB) is widely used to mitigate drift in visual-inertial
odometry (VIO) systems. Consistency is crucial for ensuring the estimation
accuracy of a UWBaided VIO system. An inconsistent estimator can degrade
localization performance, where the inconsistency primarily arises from two
main factors: (1) the estimator fails to preserve the correct system
observability, and (2) UWB anchor positions are assumed to be known, leading to
improper neglect of calibration uncertainty. In this paper, we propose a
consistent and tightly-coupled visual-inertial-ranging odometry (CVIRO) system
based on the Lie group. Our method incorporates the UWB anchor state into the
system state, explicitly accounting for UWB calibration uncertainty and
enabling the joint and consistent estimation of both robot and anchor states.
Furthermore, observability consistency is ensured by leveraging the invariant
error properties of the Lie group. We analytically prove that the CVIRO
algorithm naturally maintains the system's correct unobservable subspace,
thereby preserving estimation consistency. Extensive simulations and
experiments demonstrate that CVIRO achieves superior localization accuracy and
consistency compared to existing methods.

</details>


### [23] [TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning](https://arxiv.org/abs/2508.10872)
*Anantha Narayanan,Battu Bhanu Teja,Pruthwik Mishra*

Main category: cs.RO

TL;DR: 论文提出了一种基于强化学习（A2C算法）的框架，用于优化低地球轨道卫星的轨道参数，以实现精确的地面覆盖，并在计算效率和收敛速度上优于PPO算法。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道日益拥挤，增加了卫星部署和运行的风险，需要一种高效的方法来优化轨道参数以减少碰撞风险并满足任务需求。

Method: 使用A2C算法在自定义的OpenAI Gymnasium环境中建模为MDP问题，模拟轨道动力学，调整五个轨道参数以实现目标覆盖。

Result: A2C在累积奖励（10.0 vs 9.263025）和收敛速度（2,000 vs 63,000时间步）上显著优于PPO，并能适应多样化的目标坐标。

Conclusion: 该方法验证了强化学习在连续轨道控制中的高效性，为实时任务规划提供了可扩展的解决方案。

Abstract: The increasing congestion of Low Earth Orbit (LEO) poses persistent
challenges to the efficient deployment and safe operation of Earth observation
satellites. Mission planners must now account not only for mission-specific
requirements but also for the increasing collision risk with active satellites
and space debris. This work presents a reinforcement learning framework using
the Advantage Actor-Critic (A2C) algorithm to optimize satellite orbital
parameters for precise terrestrial coverage within predefined surface radii. By
formulating the problem as a Markov Decision Process (MDP) within a custom
OpenAI Gymnasium environment, our method simulates orbital dynamics using
classical Keplerian elements. The agent progressively learns to adjust five of
the orbital parameters - semi-major axis, eccentricity, inclination, right
ascension of ascending node, and the argument of perigee-to achieve targeted
terrestrial coverage. Comparative evaluation against Proximal Policy
Optimization (PPO) demonstrates A2C's superior performance, achieving 5.8x
higher cumulative rewards (10.0 vs 9.263025) while converging in 31.5x fewer
timesteps (2,000 vs 63,000). The A2C agent consistently meets mission
objectives across diverse target coordinates while maintaining computational
efficiency suitable for real-time mission planning applications. Key
contributions include: (1) a TLE-based orbital simulation environment
incorporating physics constraints, (2) validation of actor-critic methods'
superiority over trust region approaches in continuous orbital control, and (3)
demonstration of rapid convergence enabling adaptive satellite deployment. This
approach establishes reinforcement learning as a computationally efficient
alternative for scalable and intelligent LEO mission planning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions](https://arxiv.org/abs/2508.10047)
*Ziyang Xiao,Jingrong Xie,Lilin Xu,Shisi Guan,Jingyan Zhu,Xiongwei Han,Xiaojin Fu,WingYin Yu,Han Wu,Wei Shi,Qingcan Kang,Jiahui Duan,Tao Zhong,Mingxuan Yuan,Jia Zeng,Yuan Wang,Gang Chen,Dongxiang Zhang*

Main category: cs.AI

TL;DR: 本文综述了利用大语言模型（LLMs）自动化数学建模的最新进展，包括数据合成、模型微调、推理框架、基准数据集和性能评估，并清理了高错误率的基准数据集，构建了新的排行榜和在线资源门户。


<details>
  <summary>Details</summary>
Motivation: 优化建模在解决实际问题中具有广泛应用，但需要大量专业知识。LLMs的出现为自动化数学建模提供了新机会。

Method: 综述了技术栈的各个方面，包括数据合成、模型微调、推理框架等，并清理了基准数据集，构建了新的排行榜和在线门户。

Result: 发现基准数据集错误率高，清理后构建了新的排行榜和资源门户，为社区提供了便利。

Conclusion: 当前方法存在局限性，未来研究需进一步探索改进方向。

Abstract: By virtue of its great utility in solving real-world problems, optimization
modeling has been widely employed for optimal decision-making across various
sectors, but it requires substantial expertise from operations research
professionals. With the advent of large language models (LLMs), new
opportunities have emerged to automate the procedure of mathematical modeling.
This survey presents a comprehensive and timely review of recent advancements
that cover the entire technical stack, including data synthesis and fine-tuning
for the base model, inference frameworks, benchmark datasets, and performance
evaluation. In addition, we conducted an in-depth analysis on the quality of
benchmark datasets, which was found to have a surprisingly high error rate. We
cleaned the datasets and constructed a new leaderboard with fair performance
evaluation in terms of base LLM model and datasets. We also build an online
portal that integrates resources of cleaned datasets, code and paper repository
to benefit the community. Finally, we identify limitations in current
methodologies and outline future research opportunities.

</details>


### [25] [Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development](https://arxiv.org/abs/2508.10108)
*Sattvik Sahai,Prasoon Goyal,Michael Johnston,Anna Gottardi,Yao Lu,Lucy Hu,Luke Dai,Shaohua Liu,Samyuth Sagi,Hangjie Shi,Desheng Zhang,Lavina Vaz,Leslie Ball,Maureen Murray,Rahul Gupta,Shankar Ananthakrishna*

Main category: cs.AI

TL;DR: 亚马逊Nova AI挑战赛通过对抗性竞赛推动AI安全性研究，大学团队开发了自动化红队和安全AI助手，并提出了创新方法。


<details>
  <summary>Details</summary>
Motivation: 解决AI在软件开发中的安全性问题，推动安全AI技术的发展。

Method: 通过对抗性竞赛（红队与AI助手对话）和高质量数据支持，团队开发了推理安全对齐、模型护栏等技术。

Result: 团队提出了创新方法，如多轮越狱、高效探测LLMs，并构建了专用模型和评估工具。

Conclusion: 该挑战赛提升了AI安全性标准，展示了协作研究的重要性。

Abstract: AI systems for software development are rapidly gaining prominence, yet
significant challenges remain in ensuring their safety. To address this, Amazon
launched the Trusted AI track of the Amazon Nova AI Challenge, a global
competition among 10 university teams to drive advances in secure AI. In the
challenge, five teams focus on developing automated red teaming bots, while the
other five create safe AI assistants. This challenge provides teams with a
unique platform to evaluate automated red-teaming and safety alignment methods
through head-to-head adversarial tournaments where red teams have multi-turn
conversations with the competing AI coding assistants to test their safety
alignment. Along with this, the challenge provides teams with a feed of high
quality annotated data to fuel iterative improvement. Throughout the challenge,
teams developed state-of-the-art techniques, introducing novel approaches in
reasoning-based safety alignment, robust model guardrails, multi-turn
jail-breaking, and efficient probing of large language models (LLMs). To
support these efforts, the Amazon Nova AI Challenge team made substantial
scientific and engineering investments, including building a custom baseline
coding specialist model for the challenge from scratch, developing a tournament
orchestration service, and creating an evaluation harness. This paper outlines
the advancements made by university teams and the Amazon Nova AI Challenge team
in addressing the safety challenges of AI for software development,
highlighting this collaborative effort to raise the bar for AI safety.

</details>


### [26] [MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection](https://arxiv.org/abs/2508.10143)
*Alexandru-Andrei Avram,Adrian Groza,Alexandru Lecu*

Main category: cs.AI

TL;DR: 提出了一种多智能体系统，通过关系提取检测新闻中的虚假信息，准确率达95.3%。


<details>
  <summary>Details</summary>
Motivation: 数字平台上虚假信息的广泛传播对信息完整性构成挑战，需高效检测方法。

Method: 结合四种智能体：机器学习、维基百科知识检查、连贯性检测和网络数据抓取分析，通过MCP协议协调。

Result: 系统准确率95.3%，F1分数0.964，优于传统方法。

Conclusion: 模块化架构易于扩展，决策过程透明，加权聚合方法优于阈值优化。

Abstract: The large spread of disinformation across digital platforms creates
significant challenges to information integrity. This paper presents a
multi-agent system that uses relation extraction to detect disinformation in
news articles, focusing on titles and short text snippets. The proposed Agentic
AI system combines four agents: (i) a machine learning agent (logistic
regression), (ii) a Wikipedia knowledge check agent (which relies on named
entity recognition), (iii) a coherence detection agent (using LLM prompt
engineering), and (iv) a web-scraped data analyzer that extracts relational
triplets for fact checking. The system is orchestrated via the Model Context
Protocol (MCP), offering shared context and live learning across components.
Results demonstrate that the multi-agent ensemble achieves 95.3% accuracy with
an F1 score of 0.964, significantly outperforming individual agents and
traditional approaches. The weighted aggregation method, mathematically derived
from individual agent misclassification rates, proves superior to algorithmic
threshold optimization. The modular architecture makes the system easily
scalable, while also maintaining details of the decision processes.

</details>


### [27] [Agentic AI Frameworks: Architectures, Protocols, and Design Challenges](https://arxiv.org/abs/2508.10146)
*Hana Derouiche,Zaki Brahmi,Haithem Mazeni*

Main category: cs.AI

TL;DR: 本文系统回顾并比较了多个Agentic AI框架，分析了其架构、通信机制、内存管理等，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的发展催生了Agentic AI，本文旨在评估现有框架的优缺点并提出改进方向。

Method: 通过系统回顾和比较分析多个Agentic AI框架，并深入分析通信协议如CNP、A2A等。

Result: 建立了Agentic AI系统的基础分类法，并提出了未来研究方向。

Conclusion: 本文为研究人员和从业者提供了关于下一代自主AI系统的全面参考。

Abstract: The emergence of Large Language Models (LLMs) has ushered in a transformative
paradigm in artificial intelligence, Agentic AI, where intelligent agents
exhibit goal-directed autonomy, contextual reasoning, and dynamic multi-agent
coordination. This paper provides a systematic review and comparative analysis
of leading Agentic AI frameworks, including CrewAI, LangGraph, AutoGen,
Semantic Kernel, Agno, Google ADK, and MetaGPT, evaluating their architectural
principles, communication mechanisms, memory management, safety guardrails, and
alignment with service-oriented computing paradigms. Furthermore, we identify
key limitations, emerging trends, and open challenges in the field. To address
the issue of agent communication, we conduct an in-depth analysis of protocols
such as the Contract Net Protocol (CNP), Agent-to-Agent (A2A), Agent Network
Protocol (ANP), and Agora. Our findings not only establish a foundational
taxonomy for Agentic AI systems but also propose future research directions to
enhance scalability, robustness, and interoperability. This work serves as a
comprehensive reference for researchers and practitioners working to advance
the next generation of autonomous AI systems.

</details>


### [28] [Improving and Evaluating Open Deep Research Agents](https://arxiv.org/abs/2508.10152)
*Doaa Allabadi,Kyle Bradbury,Jordan M. Malof*

Main category: cs.AI

TL;DR: 本文研究了开源深度研究代理（ODR）与专有系统的性能对比，提出了改进后的ODR+模型，在BC-Small基准测试中达到10%的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究代理（DRAs）多为闭源系统，缺乏开源选项。本文旨在评估开源系统ODR的性能，并通过改进提升其表现。

Method: 使用BrowseComp-Small（BC-Small）基准测试对比ODR与两种专有系统，提出三种改进策略并验证其效果。

Result: 所有系统在60个测试问题上的初始准确率为0%，改进后的ODR+达到10%的成功率。

Conclusion: ODR+在开源和闭源系统中表现最佳，验证了改进策略的有效性。

Abstract: We focus here on Deep Research Agents (DRAs), which are systems that can take
a natural language prompt from a user, and then autonomously search for, and
utilize, internet-based content to address the prompt. Recent DRAs have
demonstrated impressive capabilities on public benchmarks however, recent
research largely involves proprietary closed-source systems. At the time of
this work, we only found one open-source DRA, termed Open Deep Research (ODR).
In this work we adapt the challenging recent BrowseComp benchmark to compare
ODR to existing proprietary systems. We propose BrowseComp-Small (BC-Small),
comprising a subset of BrowseComp, as a more computationally-tractable DRA
benchmark for academic labs. We benchmark ODR and two other proprietary systems
on BC-Small: one system from Anthropic and one system from Google. We find that
all three systems achieve 0% accuracy on the test set of 60 questions. We
introduce three strategic improvements to ODR, resulting in the ODR+ model,
which achieves a state-of-the-art 10% success rate on BC-Small among both
closed-source and open-source systems. We report ablation studies indicating
that all three of our improvements contributed to the success of ODR+.

</details>


### [29] [Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization](https://arxiv.org/abs/2508.10164)
*Bin Hong,Jiayu Liu,Zhenya Huang,Kai Zhang,Mengdi Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种名为LCPO的方法，通过控制生成路径长度和优化偏好，显著减少大型推理模型的输出长度，同时保持推理性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）的长推理链增加了计算成本并可能导致过度思考，当前方法在效率和推理质量之间难以平衡。

Method: 分析生成路径分布并通过难度估计过滤轨迹，研究偏好优化方法的收敛行为，提出LCPO方法直接平衡隐式奖励与NLL损失。

Result: 实验表明，LCPO在多个基准测试中平均输出长度减少50%以上，同时保持推理性能。

Conclusion: LCPO展示了在引导LRMs实现高效推理方面的潜力，为计算效率提供了新思路。

Abstract: Recent advances in Large Reasoning Models (LRMs) have demonstrated strong
performance on complex tasks through long Chain-of-Thought (CoT) reasoning.
However, their lengthy outputs increase computational costs and may lead to
overthinking, raising challenges in balancing reasoning effectiveness and
efficiency. Current methods for efficient reasoning often compromise reasoning
quality or require extensive resources. This paper investigates efficient
methods to reduce the generation length of LRMs. We analyze generation path
distributions and filter generated trajectories through difficulty estimation.
Subsequently, we analyze the convergence behaviors of the objectives of various
preference optimization methods under a Bradley-Terry loss based framework.
Based on the analysis, we propose Length Controlled Preference Optimization
(LCPO) that directly balances the implicit reward related to NLL loss. LCPO can
effectively learn length preference with limited data and training. Extensive
experiments demonstrate that our approach significantly reduces the average
output length by over 50\% across multiple benchmarks while maintaining the
reasoning performance. Our work highlights the potential for computationally
efficient approaches in guiding LRMs toward efficient reasoning.

</details>


### [30] [KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems](https://arxiv.org/abs/2508.10177)
*Stepan Kulibaba,Artem Dzhalilov,Roman Pakhomov,Oleg Svidchenko,Alexander Gasnikov,Aleksei Shpilman*

Main category: cs.AI

TL;DR: KompeteAI是一个新型AutoML框架，通过动态解决方案空间探索、合并候选方案和RAG技术提升性能，解决了现有方法的探索局限和执行瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-based AutoML系统存在探索策略单一和执行瓶颈问题，限制了性能提升。

Method: 引入动态解决方案空间探索、合并候选方案、RAG技术、预测评分模型和加速调试方法。

Result: KompeteAI在MLE-Bench上平均性能提升3%，管道评估速度提升6.9倍。

Conclusion: KompeteAI通过创新方法显著提升了AutoML系统的性能和效率。

Abstract: Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive
capabilities but face significant limitations such as constrained exploration
strategies and a severe execution bottleneck. Exploration is hindered by
one-shot methods lacking diversity and Monte Carlo Tree Search (MCTS)
approaches that fail to recombine strong partial solutions. The execution
bottleneck arises from lengthy code validation cycles that stifle iterative
refinement. To overcome these challenges, we introduce KompeteAI, a novel
AutoML framework with dynamic solution space exploration. Unlike previous MCTS
methods that treat ideas in isolation, KompeteAI introduces a merging stage
that composes top candidates. We further expand the hypothesis space by
integrating Retrieval-Augmented Generation (RAG), sourcing ideas from Kaggle
notebooks and arXiv papers to incorporate real-world strategies. KompeteAI also
addresses the execution bottleneck via a predictive scoring model and an
accelerated debugging method, assessing solution potential using early stage
metrics to avoid costly full-code execution. This approach accelerates pipeline
evaluation 6.9 times. KompeteAI outperforms leading methods (e.g., RD-agent,
AIDE, and Ml-Master) by an average of 3\% on the primary AutoML benchmark,
MLE-Bench. Additionally, we propose Kompete-bench to address limitations in
MLE-Bench, where KompeteAI also achieves state-of-the-art results

</details>


### [31] [Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence](https://arxiv.org/abs/2508.10241)
*Mark Zilberman*

Main category: cs.AI

TL;DR: 本文提出了一种基于事件熵势的概念，用于增强AI中的不确定性量化、决策和可解释性，结合物理学与AI框架，应用于策略评估、奖励设计等领域。


<details>
  <summary>Details</summary>
Motivation: 通过量化离散事件对未来系统熵的影响，提升AI系统的不确定性建模能力，增强决策和解释性。

Method: 将物理学中的熵势概念调整为AI框架，引入事件中心度量，形式化定义并强调条件期望以处理反事实场景。

Result: 熵势框架在策略评估、内在奖励设计、可解释AI和异常检测中展现出潜力，统一并强化了不确定性建模。

Conclusion: 熵势框架为AI中的不确定性管理提供了理论基础、可解释性和多功能性，融合了热力学、信息论和机器学习的原理。

Abstract: This work demonstrates how the concept of the entropic potential of events --
a parameter quantifying the influence of discrete events on the expected future
entropy of a system -- can enhance uncertainty quantification, decision-making,
and interpretability in artificial intelligence (AI). Building on its original
formulation in physics, the framework is adapted for AI by introducing an
event-centric measure that captures how actions, observations, or other
discrete occurrences impact uncertainty at future time horizons. Both the
original and AI-adjusted definitions of entropic potential are formalized, with
the latter emphasizing conditional expectations to account for counterfactual
scenarios. Applications are explored in policy evaluation, intrinsic reward
design, explainable AI, and anomaly detection, highlighting the metric's
potential to unify and strengthen uncertainty modeling in intelligent systems.
Conceptual examples illustrate its use in reinforcement learning, Bayesian
inference, and anomaly detection, while practical considerations for
computation in complex AI models are discussed. The entropic potential
framework offers a theoretically grounded, interpretable, and versatile
approach to managing uncertainty in AI, bridging principles from
thermodynamics, information theory, and machine learning.

</details>


### [32] [Why Cannot Large Language Models Ever Make True Correct Reasoning?](https://arxiv.org/abs/2508.10265)
*Jingde Cheng*

Main category: cs.AI

TL;DR: 本文认为基于大语言模型（LLMs）的AIGC工具（如ChatGPT）的“理解能力”和“推理能力”只是概念模糊者的错觉，LLMs本质上无法具备真正的理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否真正具备理解和推理能力，揭示其工作原理的本质限制。

Method: 通过分析LLMs的工作原理，论证其无法实现真正的正确推理。

Result: LLMs因其本质限制，无法具备真正的理解和推理能力。

Conclusion: LLMs的“理解”和“推理”仅是表象，无法达到人类水平的真正能力。

Abstract: Recently, with the application progress of AIGC tools based on large language
models (LLMs), led by ChatGPT, many AI experts and more non-professionals are
trumpeting the "understanding ability" and "reasoning ability" of the LLMs. The
present author considers that the so-called "understanding ability" and
"reasoning ability" of LLMs are just illusions of those people who with vague
concepts. In fact, the LLMs can never have the true understanding ability and
true reasoning ability. This paper intents to explain that, because the
essential limitations of their working principle, the LLMs can never have the
ability of true correct reasoning.

</details>


### [33] [Promoting Efficient Reasoning with Verifiable Stepwise Reward](https://arxiv.org/abs/2508.10293)
*Chuhuai Yue,Chengqi Dong,Yinan Gao,Hang He,Jiajun Chai,Guojun Yin,Wei Lin*

Main category: cs.AI

TL;DR: 提出了一种基于规则的可验证逐步奖励机制（VSRM），通过奖励有效步骤和惩罚无效步骤，解决了大型推理模型（LRMs）的过度思考问题，显著提高了推理效率。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在复杂推理任务中表现优异，但存在过度思考问题，即在简单问题上浪费计算资源，降低效率。现有方法需要预设预算或选择推理模式，缺乏灵活性。

Method: 提出VSRM机制，根据推理轨迹中中间状态的表现分配奖励，结合PPO和Reinforce++算法进行训练。

Result: 在AIME24和AIME25等数学推理基准测试中，VSRM显著减少了输出长度，同时保持了推理性能，有效抑制了无效步骤。

Conclusion: VSRM通过奖励有效步骤和惩罚无效步骤，从根本上缓解了过度思考问题，为高效推理提供了新思路。

Abstract: Large reasoning models (LRMs) have recently achieved significant progress in
complex reasoning tasks, aided by reinforcement learning with verifiable
rewards. However, LRMs often suffer from overthinking, expending excessive
computation on simple problems and reducing efficiency. Existing efficient
reasoning methods typically require accurate task assessment to preset token
budgets or select reasoning modes, which limits their flexibility and
reliability. In this work, we revisit the essence of overthinking and identify
that encouraging effective steps while penalizing ineffective ones is key to
its solution. To this end, we propose a novel rule-based verifiable stepwise
reward mechanism (VSRM), which assigns rewards based on the performance of
intermediate states in the reasoning trajectory. This approach is intuitive and
naturally fits the step-by-step nature of reasoning tasks. We conduct extensive
experiments on standard mathematical reasoning benchmarks, including AIME24 and
AIME25, by integrating VSRM with PPO and Reinforce++. Results show that our
method achieves substantial output length reduction while maintaining original
reasoning performance, striking an optimal balance between efficiency and
accuracy. Further analysis of overthinking frequency and pass@k score before
and after training demonstrates that our approach in deed effectively
suppresses ineffective steps and encourages effective reasoning, fundamentally
alleviating the overthinking problem. All code will be released upon
acceptance.

</details>


### [34] [A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering](https://arxiv.org/abs/2508.10337)
*Chenliang Zhang,Lin Wang,Yuanyuan Lu,Yusheng Qi,Kexin Wang,Peixu Hou,Wenshi Chen*

Main category: cs.AI

TL;DR: 论文介绍了Dianping-Trust-Safety团队在META CRAG-MM挑战中的解决方案，通过结合视觉大语言模型、强化学习和外部知识检索，在多模态多轮问答任务中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 解决多模态多轮问答的复杂需求，提升信息检索与生成的准确性和上下文理解能力。

Method: 1. 任务1：基于视觉大语言模型，结合GPT-4.1的知识蒸馏和监督微调，采用课程学习策略优化强化学习。2. 任务2和3：引入外部知识检索（如网页搜索API），增强复杂查询和多轮对话的处理能力。

Result: 任务1以52.38%的优势排名第一，任务3排名第三，验证了方法的有效性。

Conclusion: 结合课程学习与强化学习的训练框架在多模态问答任务中表现优异，外部知识检索进一步提升了系统性能。

Abstract: This paper describes the solutions of the Dianping-Trust-Safety team for the
META CRAG-MM challenge. The challenge requires building a comprehensive
retrieval-augmented generation system capable for multi-modal multi-turn
question answering. The competition consists of three tasks: (1) answering
questions using structured data retrieved from an image-based mock knowledge
graph, (2) synthesizing information from both knowledge graphs and web search
results, and (3) handling multi-turn conversations that require context
understanding and information aggregation from multiple sources. For Task 1,
our solution is based on the vision large language model, enhanced by
supervised fine-tuning with knowledge distilled from GPT-4.1. We further
applied curriculum learning strategies to guide reinforcement learning,
resulting in improved answer accuracy and reduced hallucination. For Task 2 and
Task 3, we additionally leveraged web search APIs to incorporate external
knowledge, enabling the system to better handle complex queries and multi-turn
conversations. Our approach achieved 1st place in Task 1 with a significant
lead of 52.38\%, and 3rd place in Task 3, demonstrating the effectiveness of
the integration of curriculum learning with reinforcement learning in our
training pipeline.

</details>


### [35] [Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach](https://arxiv.org/abs/2508.10340)
*Chak Lam Shek,Guangyao Shi,Pratap Tokekar*

Main category: cs.AI

TL;DR: HATRPO-W和HATRPO-G通过动态分配KL阈值优化多智能体强化学习，显著提升性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统HATRPO方法为所有智能体分配相同KL阈值，导致训练效率低和局部最优问题。

Method: 提出HATRPO-W（基于KKT优化阈值分配）和HATRPO-G（基于贪婪算法的优先级分配）。

Result: 实验显示两种方法均显著提升性能（超过22.5%），HATRPO-W稳定性更优。

Conclusion: 动态KL阈值分配在多智能体强化学习中具有显著优势。

Abstract: Multi-agent reinforcement learning (MARL) requires coordinated and stable
policy updates among interacting agents. Heterogeneous-Agent Trust Region
Policy Optimization (HATRPO) enforces per-agent trust region constraints using
Kullback-Leibler (KL) divergence to stabilize training. However, assigning each
agent the same KL threshold can lead to slow and locally optimal updates,
especially in heterogeneous settings. To address this limitation, we propose
two approaches for allocating the KL divergence threshold across agents:
HATRPO-W, a Karush-Kuhn-Tucker-based (KKT-based) method that optimizes
threshold assignment under global KL constraints, and HATRPO-G, a greedy
algorithm that prioritizes agents based on improvement-to-divergence ratio. By
connecting sequential policy optimization with constrained threshold
scheduling, our approach enables more flexible and effective learning in
heterogeneous-agent settings. Experimental results demonstrate that our methods
significantly boost the performance of HATRPO, achieving faster convergence and
higher final rewards across diverse MARL benchmarks. Specifically, HATRPO-W and
HATRPO-G achieve comparable improvements in final performance, each exceeding
22.5%. Notably, HATRPO-W also demonstrates more stable learning dynamics, as
reflected by its lower variance.

</details>


### [36] [What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles](https://arxiv.org/abs/2508.10358)
*Mengtao Zhou,Sifan Wu,Huan Zhang,Qi Sima,Bang Liu*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型（LLMs）在信息稀疏环境中进行想象推理的能力，提出了基于“Turtle Soup”游戏的评估框架，并揭示了LLMs在此任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试多为静态或侧重于社交推理，无法捕捉动态、探索性的想象推理过程，因此需要新的评估方法。

Method: 提出了TurtleSoup-Bench（大规模双语交互式基准测试）和Mosaic-Agent（评估LLMs性能的代理），并开发了多维评估协议。

Result: 实验表明，LLMs在想象推理中存在明显的能力限制和常见失败模式，性能显著低于人类。

Conclusion: 研究为LLMs的想象推理提供了新见解，并为未来探索性代理行为研究奠定了基础。

Abstract: We investigate the capacity of Large Language Models (LLMs) for imaginative
reasoning--the proactive construction, testing, and revision of hypotheses in
information-sparse environments. Existing benchmarks, often static or focused
on social deduction, fail to capture the dynamic, exploratory nature of this
reasoning process. To address this gap, we introduce a comprehensive research
framework based on the classic "Turtle Soup" game, integrating a benchmark, an
agent, and an evaluation protocol. We present TurtleSoup-Bench, the first
large-scale, bilingual, interactive benchmark for imaginative reasoning,
comprising 800 turtle soup puzzles sourced from both the Internet and expert
authors. We also propose Mosaic-Agent, a novel agent designed to assess LLMs'
performance in this setting. To evaluate reasoning quality, we develop a
multi-dimensional protocol measuring logical consistency, detail completion,
and conclusion alignment. Experiments with leading LLMs reveal clear capability
limits, common failure patterns, and a significant performance gap compared to
humans. Our work offers new insights into LLMs' imaginative reasoning and
establishes a foundation for future research on exploratory agent behavior.

</details>


### [37] [LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval](https://arxiv.org/abs/2508.10391)
*Yaoze Zhang,Rong Wu,Pinlong Cai,Xiaoman Wang,Guohang Yan,Song Mao,Ding Wang,Botian Shi*

Main category: cs.AI

TL;DR: LeanRAG通过知识聚合和检索策略的深度协作设计，解决了知识图谱RAG方法中语义孤岛和检索效率低的问题，显著提升了问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱RAG方法存在语义孤岛和检索效率低的问题，限制了其在问答任务中的表现。

Method: LeanRAG采用语义聚合算法构建可导航的语义网络，并结合自底向上的结构引导检索策略。

Result: 在四个QA基准测试中，LeanRAG显著优于现有方法，同时减少了46%的检索冗余。

Conclusion: LeanRAG通过优化知识聚合和检索策略，有效提升了问答任务的性能，并减少了冗余检索。

Abstract: Retrieval-Augmented Generation (RAG) plays a crucial role in grounding Large
Language Models by leveraging external knowledge, whereas the effectiveness is
often compromised by the retrieval of contextually flawed or incomplete
information. To address this, knowledge graph-based RAG methods have evolved
towards hierarchical structures, organizing knowledge into multi-level
summaries. However, these approaches still suffer from two critical,
unaddressed challenges: high-level conceptual summaries exist as disconnected
``semantic islands'', lacking the explicit relations needed for cross-community
reasoning; and the retrieval process itself remains structurally unaware, often
degenerating into an inefficient flat search that fails to exploit the graph's
rich topology. To overcome these limitations, we introduce LeanRAG, a framework
that features a deeply collaborative design combining knowledge aggregation and
retrieval strategies. LeanRAG first employs a novel semantic aggregation
algorithm that forms entity clusters and constructs new explicit relations
among aggregation-level summaries, creating a fully navigable semantic network.
Then, a bottom-up, structure-guided retrieval strategy anchors queries to the
most relevant fine-grained entities and then systematically traverses the
graph's semantic pathways to gather concise yet contextually comprehensive
evidence sets. The LeanRAG can mitigate the substantial overhead associated
with path retrieval on graphs and minimizes redundant information retrieval.
Extensive experiments on four challenging QA benchmarks with different domains
demonstrate that LeanRAG significantly outperforming existing methods in
response quality while reducing 46\% retrieval redundancy. Code is available
at: https://github.com/RaZzzyz/LeanRAG

</details>


### [38] [HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation](https://arxiv.org/abs/2508.10425)
*Yan Ting Chok,Soyon Park,Seungheun Baek,Hajung Kim,Junhyun Lee,Jaewoo Kang*

Main category: cs.AI

TL;DR: HiRef框架结合医学本体层次结构和EHR共现模式，通过双曲空间嵌入和稀疏正则化提升药物推荐的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决EHR数据中罕见实体和不完整记录导致的模型泛化问题。

Method: 结合医学本体层次结构和EHR共现图，使用双曲空间嵌入和稀疏正则化优化。

Result: 在MIMIC-III和MIMIC-IV上表现优异，对未见代码保持高准确率。

Conclusion: HiRef通过本体和网络优化显著提升了药物推荐的鲁棒性和泛化能力。

Abstract: Medication recommendation is a crucial task for assisting physicians in
making timely decisions from longitudinal patient medical records. However,
real-world EHR data present significant challenges due to the presence of
rarely observed medical entities and incomplete records that may not fully
capture the clinical ground truth. While data-driven models trained on
longitudinal Electronic Health Records often achieve strong empirical
performance, they struggle to generalize under missing or novel conditions,
largely due to their reliance on observed co-occurrence patterns. To address
these issues, we propose Hierarchical Ontology and Network Refinement for
Robust Medication Recommendation (HiRef), a unified framework that combines two
complementary structures: (i) the hierarchical semantics encoded in curated
medical ontologies, and (ii) refined co-occurrence patterns derived from
real-world EHRs. We embed ontology entities in hyperbolic space, which
naturally captures tree-like relationships and enables knowledge transfer
through shared ancestors, thereby improving generalizability to unseen codes.
To further improve robustness, we introduce a prior-guided sparse
regularization scheme that refines the EHR co-occurrence graph by suppressing
spurious edges while preserving clinically meaningful associations. Our model
achieves strong performance on EHR benchmarks (MIMIC-III and MIMIC-IV) and
maintains high accuracy under simulated unseen-code settings. Extensive
experiments with comprehensive ablation studies demonstrate HiRef's resilience
to unseen medical codes, supported by in-depth analyses of the learned
sparsified graph structure and medical code embeddings.

</details>


### [39] [MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance](https://arxiv.org/abs/2508.10429)
*Yi Dong,Yusuke Muraoka,Scott Shi,Yi Zhang*

Main category: cs.AI

TL;DR: MM-Food-100K是一个公开的10万样本多模态食品数据集，具有可验证来源，支持图像营养预测任务。


<details>
  <summary>Details</summary>
Motivation: 解决食品数据集的来源和质量问题，同时支持社区贡献和商业化潜力。

Method: 通过Codatta贡献模型收集数据，结合社区众包和AI辅助质量检查，并利用区块链技术确保可追溯性。

Result: 在图像营养预测任务中，微调大型视觉语言模型（如ChatGPT 5）相比基线模型有显著提升。

Conclusion: MM-Food-100K为食品智能研究提供了高质量数据集，并展示了商业化潜力。

Abstract: We present MM-Food-100K, a public 100,000-sample multimodal food intelligence
dataset with verifiable provenance. It is a curated approximately 10% open
subset of an original 1.2 million, quality-accepted corpus of food images
annotated for a wide range of information (such as dish name, region of
creation). The corpus was collected over six weeks from over 87,000
contributors using the Codatta contribution model, which combines community
sourcing with configurable AI-assisted quality checks; each submission is
linked to a wallet address in a secure off-chain ledger for traceability, with
a full on-chain protocol on the roadmap. We describe the schema, pipeline, and
QA, and validate utility by fine-tuning large vision-language models (ChatGPT
5, ChatGPT OSS, Qwen-Max) on image-based nutrition prediction. Fine-tuning
yields consistent gains over out-of-box baselines across standard metrics; we
report results primarily on the MM-Food-100K subset. We release MM-Food-100K
for publicly free access and retain approximately 90% for potential commercial
access with revenue sharing to contributors.

</details>


### [40] [We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning](https://arxiv.org/abs/2508.10433)
*Runqi Qiao,Qiuna Tan,Peiqing Yang,Yanzi Wang,Xiaowan Wang,Enhui Wan,Sitong Zhou,Guanting Dong,Yuchen Zeng,Yida Xu,Jie Wang,Chong Sun,Chen Li,Honggang Zhang*

Main category: cs.AI

TL;DR: We-Math 2.0通过整合结构化数学知识系统、模型中心数据空间建模和强化学习训练范式，提升多模态大语言模型的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注数据集构建和方法优化，忽视了知识驱动设计和数据空间建模，导致复杂数学推理能力不足。

Method: 构建五层次数学知识系统，开发标准与专业数据集，提出两阶段强化学习框架，并引入全面评估基准。

Result: MathBook-RL在四个基准测试中表现优异，并在MathBookEval上展现出强大的泛化能力。

Conclusion: We-Math 2.0通过系统性设计显著提升了数学推理能力，为未来研究提供了新方向。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive
capabilities across various tasks, but still struggle with complex mathematical
reasoning. Existing research primarily focuses on dataset construction and
method optimization, often overlooking two critical aspects: comprehensive
knowledge-driven design and model-centric data space modeling. In this paper,
we introduce We-Math 2.0, a unified system that integrates a structured
mathematical knowledge system, model-centric data space modeling, and a
reinforcement learning (RL)-based training paradigm to comprehensively enhance
the mathematical reasoning abilities of MLLMs. The key contributions of We-Math
2.0 are fourfold: (1) MathBook Knowledge System: We construct a five-level
hierarchical system encompassing 491 knowledge points and 1,819 fundamental
principles. (2) MathBook-Standard & Pro: We develop MathBook-Standard, a
dataset that ensures broad conceptual coverage and flexibility through dual
expansion. Additionally, we define a three-dimensional difficulty space and
generate 7 progressive variants per problem to build MathBook-Pro, a
challenging dataset for robust training. (3) MathBook-RL: We propose a
two-stage RL framework comprising: (i) Cold-Start Fine-tuning, which aligns the
model with knowledge-oriented chain-of-thought reasoning; and (ii) Progressive
Alignment RL, leveraging average-reward learning and dynamic data scheduling to
achieve progressive alignment across difficulty levels. (4) MathBookEval: We
introduce a comprehensive benchmark covering all 491 knowledge points with
diverse reasoning step distributions. Experimental results show that
MathBook-RL performs competitively with existing baselines on four widely-used
benchmarks and achieves strong results on MathBookEval, suggesting promising
generalization in mathematical reasoning.

</details>


### [41] [FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs](https://arxiv.org/abs/2508.10467)
*Xueli Pan,Victor de Boer,Jacco van Ossenbruggen*

Main category: cs.AI

TL;DR: 论文提出FIRESPARQL框架，通过微调LLM和结合RAG技术，解决了SKG问答中SPARQL查询生成的结构和语义错误问题，实验表明微调方法性能最佳。


<details>
  <summary>Details</summary>
Motivation: 由于学术知识图谱（SKG）的复杂性和LLM在生成SPARQL查询时的局限性（如结构不一致和语义不准确），需要一种更有效的方法来提升问答系统的准确性。

Method: 提出FIRESPARQL框架，结合微调LLM、RAG技术和SPARQL查询修正层，通过多种配置（零样本、单样本、微调等）进行实验。

Result: 微调方法表现最佳，测试集上ROUGE-L达0.90，RelaxedEM达0.85。

Conclusion: FIRESPARQL框架显著提升了SKG问答的准确性，微调LLM是解决SPARQL查询生成问题的有效方法。

Abstract: Question answering over Scholarly Knowledge Graphs (SKGs) remains a
challenging task due to the complexity of scholarly content and the intricate
structure of these graphs. Large Language Model (LLM) approaches could be used
to translate natural language questions (NLQs) into SPARQL queries; however,
these LLM-based approaches struggle with SPARQL query generation due to limited
exposure to SKG-specific content and the underlying schema. We identified two
main types of errors in the LLM-generated SPARQL queries: (i) structural
inconsistencies, such as missing or redundant triples in the queries, and (ii)
semantic inaccuracies, where incorrect entities or properties are shown in the
queries despite a correct query structure. To address these issues, we propose
FIRESPARQL, a modular framework that supports fine-tuned LLMs as a core
component, with optional context provided via retrieval-augmented generation
(RAG) and a SPARQL query correction layer. We evaluate the framework on the
SciQA Benchmark using various configurations (zero-shot, zero-shot with RAG,
one-shot, fine-tuning, and fine-tuning with RAG) and compare the performance
with baseline and state-of-the-art approaches. We measure query accuracy using
BLEU and ROUGE metrics, and query result accuracy using relaxed exact
match(RelaxedEM), with respect to the gold standards containing the NLQs,
SPARQL queries, and the results of the queries. Experimental results
demonstrate that fine-tuning achieves the highest overall performance, reaching
0.90 ROUGE-L for query accuracy and 0.85 RelaxedEM for result accuracy on the
test set.

</details>


### [42] [SEQ-GPT: LLM-assisted Spatial Query via Example](https://arxiv.org/abs/2508.10486)
*Ivan Khai Ze Lim,Ningyi Liao,Yiming Yang,Gerald Wei Yong Yip,Siqiang Luo*

Main category: cs.AI

TL;DR: 论文提出了一种基于大语言模型（LLMs）的空间查询系统SEQ-GPT，用于通过自然语言实现更灵活的空间范例查询（SEQ）。


<details>
  <summary>Details</summary>
Motivation: 当前空间服务（如在线地图）主要依赖用户查询进行位置搜索，但在执行复杂任务（如同时搜索多个相关位置）时用户体验有限。

Method: 引入SEQ-GPT系统，利用LLMs的自然语言能力实现交互式操作，并提出一种定制化的LLM适应流程，通过对话合成和多模型协作将自然语言与结构化空间数据对齐。

Result: SEQ-GPT展示了通过真实数据和实际应用场景扩展空间搜索的端到端解决方案。

Conclusion: SEQ-GPT为空间搜索提供了更灵活和交互式的解决方案，扩展了传统查询的功能。

Abstract: Contemporary spatial services such as online maps predominantly rely on user
queries for location searches. However, the user experience is limited when
performing complex tasks, such as searching for a group of locations
simultaneously. In this study, we examine the extended scenario known as
Spatial Exemplar Query (SEQ), where multiple relevant locations are jointly
searched based on user-specified examples. We introduce SEQ-GPT, a spatial
query system powered by Large Language Models (LLMs) towards more versatile SEQ
search using natural language. The language capabilities of LLMs enable unique
interactive operations in the SEQ process, including asking users to clarify
query details and dynamically adjusting the search based on user feedback. We
also propose a tailored LLM adaptation pipeline that aligns natural language
with structured spatial data and queries through dialogue synthesis and
multi-model cooperation. SEQ-GPT offers an end-to-end demonstration for
broadening spatial search with realistic data and application scenarios.

</details>


### [43] [Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model](https://arxiv.org/abs/2508.10492)
*Shicheng Xu,Xin Huang,Zihao Wei,Liang Pang,Huawei Shen,Xueqi Cheng*

Main category: cs.AI

TL;DR: 论文提出了一种新的AI驱动诊断范式DxDirector-7B，通过将AI定位为主要诊断主导者，显著提升诊断效率并减少医生工作量。


<details>
  <summary>Details</summary>
Motivation: 当前AI在临床诊断中仅作为辅助工具，无法主导完整诊断流程，限制了其减轻医生负担和提升效率的潜力。

Method: 提出DxDirector-7B，一种具备深度思考能力的LLM，能够主导从模糊主诉开始的完整诊断流程，并建立责任框架。

Result: 在罕见、复杂及真实病例中，DxDirector-7B的诊断准确性和医生工作量减少效果显著优于现有医学LLM和通用LLM。

Conclusion: DxDirector-7B标志着AI从辅助角色转变为诊断主导者，为高效、准确的诊断解决方案开辟了新方向。

Abstract: Full-process clinical diagnosis in the real world encompasses the entire
diagnostic workflow that begins with only an ambiguous chief complaint. While
artificial intelligence (AI), particularly large language models (LLMs), is
transforming clinical diagnosis, its role remains largely as an assistant to
physicians. This AI-assisted working pattern makes AI can only answer specific
medical questions at certain parts within the diagnostic process, but lack the
ability to drive the entire diagnostic process starting from an ambiguous
complaint, which still relies heavily on human physicians. This gap limits AI's
ability to fully reduce physicians' workload and enhance diagnostic efficiency.
To address this, we propose a paradigm shift that reverses the relationship
between physicians and AI: repositioning AI as the primary director, with
physicians serving as its assistants. So we present DxDirector-7B, an LLM
endowed with advanced deep thinking capabilities, enabling it to drive the
full-process diagnosis with minimal physician involvement. Furthermore,
DxDirector-7B establishes a robust accountability framework for misdiagnoses,
delineating responsibility between AI and human physicians. In evaluations
across rare, complex, and real-world cases under full-process diagnosis
setting, DxDirector-7B not only achieves significant superior diagnostic
accuracy but also substantially reduces physician workload than
state-of-the-art medical LLMs as well as general-purpose LLMs. Fine-grained
analyses across multiple clinical departments and tasks validate its efficacy,
with expert evaluations indicating its potential to serve as a viable
substitute for medical specialists. These findings mark a new era where AI,
traditionally a physicians' assistant, now drives the entire diagnostic process
to drastically reduce physicians' workload, indicating an efficient and
accurate diagnostic solution.

</details>


### [44] [PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning](https://arxiv.org/abs/2508.10501)
*Yushi Feng,Junye Du,Yingying Hong,Qifan Wang,Lequan Yu*

Main category: cs.AI

TL;DR: PASS是一种多模态框架，通过概率标注的决策路径和自适应工具选择，解决了现有工具增强代理系统在医疗AI中的信任、多模态整合和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有系统存在黑盒推理、多模态整合不足和效率低下的问题，尤其在医疗领域（如胸片分析）中影响安全和性能。

Method: PASS通过多工具图自适应采样工作流，结合三阶段训练（专家知识预热、对比路径排序和成本感知强化学习），优化性能和成本平衡。

Result: PASS在多个指标（如准确率、AUC）上显著优于基线，同时提升了解释性和效率。

Conclusion: PASS为可解释、自适应和多模态医疗代理系统提供了新范式。

Abstract: Existing tool-augmented agentic systems are limited in the real world by (i)
black-box reasoning steps that undermine trust of decision-making and pose
safety risks, (ii) poor multimodal integration, which is inherently critical
for healthcare tasks, and (iii) rigid and computationally inefficient agentic
pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the
first multimodal framework to address these challenges in the context of Chest
X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a
multi-tool graph, yielding decision paths annotated with interpretable
probabilities. Given the complex CXR reasoning task with multimodal medical
data, PASS leverages its learned task-conditioned distribution over the agentic
supernet. Thus, it adaptively selects the most suitable tool at each supernet
layer, offering probability-annotated trajectories for post-hoc audits and
directly enhancing medical AI safety. PASS also continuously compresses salient
findings into an evolving personalized memory, while dynamically deciding
whether to deepen its reasoning path or invoke an early exit for efficiency. To
optimize a Pareto frontier balancing performance and cost, we design a novel
three-stage training procedure, including expert knowledge warm-up, contrastive
path-ranking, and cost-aware reinforcement learning. To facilitate rigorous
evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step,
safety-critical, free-form CXR reasoning. Experiments across various benchmarks
validate that PASS significantly outperforms strong baselines in multiple
metrics (e.g., accuracy, AUC, LLM-J.) while balancing computational costs,
pushing a new paradigm shift towards interpretable, adaptive, and multimodal
medical agentic systems.

</details>


### [45] [Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment](https://arxiv.org/abs/2508.10530)
*Zetian Sun,Dongfang Li,Baotian Hu*

Main category: cs.AI

TL;DR: 论文探讨了语言模型（LM）对齐人类偏好的方法，比较了静态数据和动态策略数据的效果差异，并提出了一种两阶段对齐假设。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于优化语言模型对齐方法，解决静态和动态策略数据在效果上的不一致问题。

Method: 提出对齐阶段假设，将过程分为偏好注入和偏好微调两阶段，并通过实验验证其普适性。

Result: 实验表明，动态策略数据在不同模型上效果差异显著（如Llama-3效果提升3倍，Zephyr降低0.4倍）。

Conclusion: 研究证实了两阶段对齐假设的有效性，并提出了一种边界测量方法，适用于多种模型和对齐方法。

Abstract: The alignment of language models (LMs) with human preferences is critical for
building reliable AI systems. The problem is typically framed as optimizing an
LM policy to maximize the expected reward that reflects human preferences.
Recently, Direct Preference Optimization (DPO) was proposed as a LM alignment
method that directly optimize the policy from static preference data, and
further improved by incorporating on-policy sampling (i.e., preference
candidates generated during the training loop) for better LM alignment.
However, we show on-policy data is not always optimal, with systematic
effectiveness difference emerging between static and on-policy preference
candidates. For example, on-policy data can result in a 3$\times$ effectiveness
compared with static data for Llama-3, and a 0.4$\times$ effectiveness for
Zephyr. To explain the phenomenon, we propose the alignment stage assumption,
which divides the alignment process into two distinct stages: the preference
injection stage, which benefits from diverse data, and the preference
fine-tuning stage, which favors high-quality data. Through theoretical and
empirical analysis, we characterize these stages and propose an effective
algorithm to identify the boundaries between them. We perform experiments on 5
models (Llama, Zephyr, Phi-2, Qwen, Pythia) and 2 alignment methods (DPO,
SLiC-HF) to show the generalizability of alignment stage assumption and
boundary measurement.

</details>


### [46] [Improving Value-based Process Verifier via Low-Cost Variance Reduction](https://arxiv.org/abs/2508.10539)
*Zetian Sun,Dongfang Li,Baotian Hu,Min Zhang*

Main category: cs.AI

TL;DR: 论文提出ComMCS方法，通过结合当前和后续步骤的蒙特卡洛估计器，减少方差，提升大语言模型在数学推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂领域（如数学）的推理能力仍有不足，而基于值的验证器因训练标注的估计误差（高方差）受限。

Method: 提出ComMCS方法，线性结合当前和后续步骤的蒙特卡洛估计器，保持无偏估计的同时降低方差。

Result: 在MATH-500和GSM8K基准测试中，ComMCS优于回归优化方法2.8分，优于无方差缩减基线2.2分。

Conclusion: ComMCS通过减少方差有效提升推理验证器的性能，且无需额外计算成本。

Abstract: Large language models (LLMs) have achieved remarkable success in a wide range
of tasks. However, their reasoning capabilities, particularly in complex
domains like mathematics, remain a significant challenge. Value-based process
verifiers, which estimate the probability of a partial reasoning chain leading
to a correct solution, are a promising approach for improving reasoning.
Nevertheless, their effectiveness is often hindered by estimation error in
their training annotations, a consequence of the limited number of Monte Carlo
(MC) samples feasible due to the high cost of LLM inference. In this paper, we
identify that the estimation error primarily arises from high variance rather
than bias, and the MC estimator is a Minimum Variance Unbiased Estimator
(MVUE). To address the problem, we propose the \textsc{Com}pound \textsc{M}onte
\textsc{C}arlo \textsc{S}ampling (ComMCS) method, which constructs an unbiased
estimator by linearly combining the MC estimators from the current and
subsequent steps. Theoretically, we show that our method leads to a predictable
reduction in variance, while maintaining an unbiased estimation without
additional LLM inference cost. We also perform empirical experiments on the
MATH-500 and GSM8K benchmarks to demonstrate the effectiveness of our method.
Notably, ComMCS outperforms regression-based optimization method by 2.8 points,
the non-variance-reduced baseline by 2.2 points on MATH-500 on Best-of-32
sampling experiment.

</details>


### [47] [MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models](https://arxiv.org/abs/2508.10599)
*Xinyan Jiang,Lin Zhang,Jiayi Zhang,Qingsong Yang,Guimin Hu,Di Wang,Lijie Hu*

Main category: cs.AI

TL;DR: MSRS是一种通过子空间表示微调实现多属性控制的新框架，减少属性间干扰并提升控制精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多属性控制中存在干扰和权衡问题，MSRS旨在解决这一问题。

Method: MSRS通过分配正交子空间隔离属性影响，结合共享子空间和动态权重函数实现精确控制。

Result: 实验表明MSRS显著减少属性冲突，优于现有方法，并能泛化到多样化任务。

Conclusion: MSRS为多属性控制提供了一种高效且通用的解决方案。

Abstract: Activation steering offers a promising approach to controlling the behavior
of Large Language Models by directly manipulating their internal activations.
However, most existing methods struggle to jointly steer multiple attributes,
often resulting in interference and undesirable trade-offs. To address this
challenge, we propose Multi-Subspace Representation Steering (MSRS), a novel
framework for effective multi-attribute steering via subspace representation
fine-tuning. MSRS reduces inter-attribute interference by allocating orthogonal
subspaces to each attribute, isolating their influence within the model's
representation space. MSRS also incorporates a hybrid subspace composition
strategy: it combines attribute-specific subspaces for unique steering
directions with a shared subspace for common steering directions. A dynamic
weighting function learns to efficiently integrate these components for precise
control. During inference, MSRS introduces a token-level steering mechanism
that dynamically identifies and intervenes on the most semantically relevant
tokens, enabling fine-grained behavioral modulation. Experimental results show
that MSRS significantly reduces attribute conflicts, surpasses existing methods
across a range of attributes, and generalizes effectively to diverse downstream
tasks.

</details>


### [48] [STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation](https://arxiv.org/abs/2508.10669)
*Zhenye Yang,Jinpeng Chen,Huan Li,Xiongnan Jin,Xuanyang Li,Junwei Zhang,Hongbo Gao,Kaimin Wei,Senzhang Wang*

Main category: cs.AI

TL;DR: STEP是一种基于预训练语言模型的对话推荐系统，通过课程引导的上下文-知识融合和轻量级任务特定提示调优，解决了现有系统在捕捉用户偏好和对话上下文深层语义方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有对话推荐系统难以有效整合外部知识图谱信息，导致推荐结果与用户期望不符。

Method: STEP采用三阶段课程逐步对齐对话上下文与知识图谱实体，并通过双重提示（对话前缀和推荐前缀）注入冻结语言模型。

Result: 实验表明，STEP在两个公共数据集上的推荐精度和对话质量优于主流方法。

Conclusion: STEP通过上下文-知识融合和双重提示调优，显著提升了对话推荐系统的性能。

Abstract: Conversational recommender systems (CRSs) aim to proactively capture user
preferences through natural language dialogue and recommend high-quality items.
To achieve this, CRS gathers user preferences via a dialog module and builds
user profiles through a recommendation module to generate appropriate
recommendations. However, existing CRS faces challenges in capturing the deep
semantics of user preferences and dialogue context. In particular, the
efficient integration of external knowledge graph (KG) information into
dialogue generation and recommendation remains a pressing issue. Traditional
approaches typically combine KG information directly with dialogue content,
which often struggles with complex semantic relationships, resulting in
recommendations that may not align with user expectations.
  To address these challenges, we introduce STEP, a conversational recommender
centered on pre-trained language models that combines curriculum-guided
context-knowledge fusion with lightweight task-specific prompt tuning. At its
heart, an F-Former progressively aligns the dialogue context with
knowledge-graph entities through a three-stage curriculum, thus resolving
fine-grained semantic mismatches. The fused representation is then injected
into the frozen language model via two minimal yet adaptive prefix prompts: a
conversation prefix that steers response generation toward user intent and a
recommendation prefix that biases item ranking toward knowledge-consistent
candidates. This dual-prompt scheme allows the model to share cross-task
semantics while respecting the distinct objectives of dialogue and
recommendation. Experimental results show that STEP outperforms mainstream
methods in the precision of recommendation and dialogue quality in two public
datasets.

</details>


### [49] [GenOM: Ontology Matching with Description Generation and Large Language Model](https://arxiv.org/abs/2508.10703)
*Yiping Song,Jiaoyan Chen,Renate A. Schmidt*

Main category: cs.AI

TL;DR: GenOM是一个基于大语言模型（LLM）的本体对齐框架，通过生成文本定义丰富本体概念的语义表示，结合嵌入模型和精确匹配工具提升对齐精度，在生物医学领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 本体匹配（OM）在实现异构知识源的语义互操作和集成中至关重要，尤其是在生物医学领域，涉及大量复杂的疾病和药物概念。

Method: GenOM框架通过生成文本定义丰富语义表示，使用嵌入模型检索对齐候选，并结合精确匹配工具提升精度。

Result: 在OAEI Bio-ML赛道上的实验表明，GenOM性能优越，超越传统OM系统和近期LLM方法。消融研究证实了语义丰富和少样本提示的有效性。

Conclusion: GenOM展示了强大的鲁棒性和适应性，为生物医学领域的本体对齐提供了高效解决方案。

Abstract: Ontology matching (OM) plays an essential role in enabling semantic
interoperability and integration across heterogeneous knowledge sources,
particularly in the biomedical domain which contains numerous complex concepts
related to diseases and pharmaceuticals. This paper introduces GenOM, a large
language model (LLM)-based ontology alignment framework, which enriches the
semantic representations of ontology concepts via generating textual
definitions, retrieves alignment candidates with an embedding model, and
incorporates exact matching-based tools to improve precision. Extensive
experiments conducted on the OAEI Bio-ML track demonstrate that GenOM can often
achieve competitive performance, surpassing many baselines including
traditional OM systems and recent LLM-based methods. Further ablation studies
confirm the effectiveness of semantic enrichment and few-shot prompting,
highlighting the framework's robustness and adaptability.

</details>


### [50] [Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based Generalized Planning](https://arxiv.org/abs/2508.10747)
*Sangwoo Jeon,Juchul Shin,Gyeong-Tae Kim,YeonJe Cho,Seongwoo Kim*

Main category: cs.AI

TL;DR: 提出了一种稀疏、目标感知的GNN表示方法，解决了传统密集图表示在大型规划问题中的计算和内存问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用全连接图表示规划状态，导致边缘信息组合爆炸和信息稀疏，难以扩展到大规模问题。

Method: 采用稀疏、目标感知的GNN表示，选择性编码局部关系并显式整合目标相关的空间特征。

Result: 实验证明该方法能有效扩展到更大网格规模，显著提升策略泛化能力和成功率。

Conclusion: 为处理现实中的大规模广义规划任务提供了实用基础。

Abstract: Generalized planning using deep reinforcement learning (RL) combined with
graph neural networks (GNNs) has shown promising results in various symbolic
planning domains described by PDDL. However, existing approaches typically
represent planning states as fully connected graphs, leading to a combinatorial
explosion in edge information and substantial sparsity as problem scales grow,
especially evident in large grid-based environments. This dense representation
results in diluted node-level information, exponentially increases memory
requirements, and ultimately makes learning infeasible for larger-scale
problems. To address these challenges, we propose a sparse, goal-aware GNN
representation that selectively encodes relevant local relationships and
explicitly integrates spatial features related to the goal. We validate our
approach by designing novel drone mission scenarios based on PDDL within a grid
world, effectively simulating realistic mission execution environments. Our
experimental results demonstrate that our method scales effectively to larger
grid sizes previously infeasible with dense graph representations and
substantially improves policy generalization and success rates. Our findings
provide a practical foundation for addressing realistic, large-scale
generalized planning tasks.

</details>


### [51] [Agentic Design Review System](https://arxiv.org/abs/2508.10745)
*Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan*

Main category: cs.AI

TL;DR: 提出了一种基于多智能体协作的图形设计评估系统（AgenticDRS），通过图匹配和提示扩展方法提升智能体的设计感知能力，并在DRS-BENCH基准上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 图形设计评估需要综合多方面的反馈，但现有方法缺乏系统性。本文旨在通过多智能体协作解决这一问题。

Method: 采用多智能体协作框架，结合图匹配和提示扩展方法，使智能体具备设计感知能力。

Result: 实验表明，AgenticDRS在评估图形设计和生成反馈方面优于现有基线方法。

Conclusion: AgenticDRS为图形设计评估提供了一种有效方法，并呼吁关注这一实用但研究不足的方向。

Abstract: Evaluating graphic designs involves assessing it from multiple facets like
alignment, composition, aesthetics and color choices. Evaluating designs in a
holistic way involves aggregating feedback from individual expert reviewers.
Towards this, we propose an Agentic Design Review System (AgenticDRS), where
multiple agents collaboratively analyze a design, orchestrated by a meta-agent.
A novel in-context exemplar selection approach based on graph matching and a
unique prompt expansion method plays central role towards making each agent
design aware. Towards evaluating this framework, we propose DRS-BENCH
benchmark. Thorough experimental evaluation against state-of-the-art baselines
adapted to the problem setup, backed-up with critical ablation experiments
brings out the efficacy of Agentic-DRS in evaluating graphic designs and
generating actionable feedback. We hope that this work will attract attention
to this pragmatic, yet under-explored research direction.

</details>


### [52] [Modeling Human Responses to Multimodal AI Content](https://arxiv.org/abs/2508.10769)
*Zhiqi Shen,Shaojing Fan,Danni Xu,Terence Sim,Mohan Kankanhalli*

Main category: cs.AI

TL;DR: 论文研究了AI生成内容对人类行为和感知的影响，提出了MhAIM数据集和T-Lens系统，通过量化信任度、影响力和开放性等指标，帮助LLM更好地预测人类反应。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容的普及，其潜在的信息误导风险增加。现有研究多关注内容真实性，而较少探讨其对人类行为的影响。

Method: 引入MhAIM数据集（含15万+帖子，11万+为AI生成），提出信任度、影响力和开放性三个新指标，并开发T-Lens系统（基于HR-MCP协议）。

Result: 研究发现，人类在图文不一致时更容易识别AI内容；T-Lens系统能更好地预测人类反应。

Conclusion: 研究为LLM提供了人类感知能力的工具，提出了缓解AI误导风险的实际策略。

Abstract: As AI-generated content becomes widespread, so does the risk of
misinformation. While prior research has primarily focused on identifying
whether content is authentic, much less is known about how such content
influences human perception and behavior. In domains like trading or the stock
market, predicting how people react (e.g., whether a news post will go viral),
can be more critical than verifying its factual accuracy. To address this, we
take a human-centered approach and introduce the MhAIM Dataset, which contains
154,552 online posts (111,153 of them AI-generated), enabling large-scale
analysis of how people respond to AI-generated content. Our human study reveals
that people are better at identifying AI content when posts include both text
and visuals, particularly when inconsistencies exist between the two. We
propose three new metrics: trustworthiness, impact, and openness, to quantify
how users judge and engage with online content. We present T-Lens, an LLM-based
agent system designed to answer user queries by incorporating predicted human
responses to multimodal information. At its core is HR-MCP (Human Response
Model Context Protocol), built on the standardized Model Context Protocol
(MCP), enabling seamless integration with any LLM. This integration allows
T-Lens to better align with human reactions, enhancing both interpretability
and interaction capabilities. Our work provides empirical insights and
practical tools to equip LLMs with human-awareness capabilities. By
highlighting the complex interplay among AI, human cognition, and information
reception, our findings suggest actionable strategies for mitigating the risks
of AI-driven misinformation.

</details>


### [53] [The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference](https://arxiv.org/abs/2508.10777)
*Maël Jullien,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: 论文通过临床试验自然语言推理基准测试，发现大语言模型在知识获取和推理能力上存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型是否仅通过数据和参数扩展就能获得结构化、可泛化的内部表征。

Method: 引入包含四种推理家族的临床试验自然语言推理基准，并设计GKMRV探针分离知识获取和推理失败。

Result: 模型在GKMRV上表现优异（准确率0.918），但在主推理任务上表现差（准确率0.25），且输出一致性高（0.87）。

Conclusion: 当前大语言模型缺乏结构化、可组合的内部表征，限制了其在高风险领域的可靠应用。

Abstract: Large language models are often assumed to acquire increasingly structured,
generalizable internal representations simply by scaling data and parameters.
We interrogate this assumption by introducing a Clinical Trial Natural Language
Inference benchmark comprising four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction.
Each item is paired with a targeted Ground Knowledge and Meta-Level Reasoning
Verification (GKMRV) probe, allowing us to dissociate failures of factual
access from failures of inference. We evaluate six contemporary LLMs under both
direct and chain of thought prompting.
  Models achieve near-ceiling GKMRV accuracy (mean accuracy 0.918) yet perform
poorly on the main reasoning tasks (mean accuracy 0.25). Despite low accuracy,
output inferences are highly consistent across samples (mean 0.87), indicating
a systematic application of underlying heuristics and shortcuts.
  These results reveal fundamental structural and representational limitations:
current LLMs often possess the relevant clinical knowledge but lack the
structured, composable internal representations needed to deploy it reliably
(e.g., integrating constraints, weighing evidence, or simulating
counterfactuals). Decoupling knowledge from reasoning with GKMRV makes this
dissociation explicit and measurable, providing an effective framework for
probing the reliability of LLMs in high-stakes domains.

</details>


### [54] [Who Benefits from AI Explanations? Towards Accessible and Interpretable Systems](https://arxiv.org/abs/2508.10806)
*Maria J. P. Peixoto,Akriti Pandey,Ahsan Zaman,Peter R. Lewis*

Main category: cs.AI

TL;DR: 论文探讨了可解释AI（XAI）在视觉障碍用户中的可访问性问题，提出了一种四步方法以改进设计。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在关键领域中的应用增加，可解释性成为提升决策透明度的关键，但视觉障碍用户的可访问性研究不足。

Method: 通过文献综述和四步方法（分类、角色定义、原型设计、评估）研究XAI的可访问性。

Result: 初步发现表明，简化解释和多模态呈现对非视觉用户更易理解。

Conclusion: 需改进XAI设计以提升对视觉障碍用户的可访问性，多模态解释是关键。

Abstract: As AI systems are increasingly deployed to support decision-making in
critical domains, explainability has become a means to enhance the
understandability of these outputs and enable users to make more informed and
conscious choices. However, despite growing interest in the usability of
eXplainable AI (XAI), the accessibility of these methods, particularly for
users with vision impairments, remains underexplored. This paper investigates
accessibility gaps in XAI through a two-pronged approach. First, a literature
review of 79 studies reveals that evaluations of XAI techniques rarely include
disabled users, with most explanations relying on inherently visual formats.
Second, we present a four-part methodological proof of concept that
operationalizes inclusive XAI design: (1) categorization of AI systems, (2)
persona definition and contextualization, (3) prototype design and
implementation, and (4) expert and user assessment of XAI techniques for
accessibility. Preliminary findings suggest that simplified explanations are
more comprehensible for non-visual users than detailed ones, and that
multimodal presentation is required for more equitable interpretability.

</details>
