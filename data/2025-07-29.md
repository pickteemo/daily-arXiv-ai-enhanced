<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 51]
- [cs.RO](#cs.RO) [Total: 42]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [MAIA: A Collaborative Medical AI Platform for Integrated Healthcare Innovation](https://arxiv.org/abs/2507.19489)
*Simone Bendazzoli,Sanna Persson,Mehdi Astaraki,Sebastian Pettersson,Vitali Grozman,Rodrigo Moreno*

Main category: cs.AI

TL;DR: MAIA是一个开源平台，旨在促进临床、研究和AI开发者之间的协作，加速AI在医疗中的应用。


<details>
  <summary>Details</summary>
Motivation: 解决AI技术与实际医疗应用之间的脱节问题，推动跨学科合作。

Method: 基于Kubernetes构建，提供模块化、可扩展的环境，集成数据管理、模型开发和部署工具。

Result: 成功应用于医学影像AI项目，支持学术和临床环境中的实际用例。

Conclusion: MAIA通过促进协作和互操作性，加速AI研究向临床解决方案的转化。

Abstract: The integration of Artificial Intelligence (AI) into clinical workflows
requires robust collaborative platforms that are able to bridge the gap between
technical innovation and practical healthcare applications. This paper
introduces MAIA (Medical Artificial Intelligence Assistant), an open-source
platform designed to facilitate interdisciplinary collaboration among
clinicians, researchers, and AI developers. Built on Kubernetes, MAIA offers a
modular, scalable environment with integrated tools for data management, model
development, annotation, deployment, and clinical feedback. Key features
include project isolation, CI/CD automation, integration with high-computing
infrastructures and in clinical workflows. MAIA supports real-world use cases
in medical imaging AI, with deployments in both academic and clinical
environments. By promoting collaborations and interoperability, MAIA aims to
accelerate the translation of AI research into impactful clinical solutions
while promoting reproducibility, transparency, and user-centered design. We
showcase the use of MAIA with different projects, both at KTH Royal Institute
of Technology and Karolinska University Hospital.

</details>


### [2] [Agent WARPP: Workflow Adherence via Runtime Parallel Personalization](https://arxiv.org/abs/2507.19543)
*Maria Emilia Mazzolenis,Ruirui Zhang*

Main category: cs.AI

TL;DR: WARPP是一个无需训练、模块化的框架，通过多智能体编排和运行时个性化，提升基于LLM的任务导向对话系统在复杂工作流中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在任务导向对话系统中应用广泛，但在处理涉及外部工具调用和用户特定信息的复杂条件工作流时表现不佳。

Method: WARPP采用并行架构，结合个性化代理和领域特定代理，动态剪枝条件分支以优化执行路径。

Result: 在银行、航班和医疗三个领域的评估中，WARPP在参数保真度和工具准确性上优于非个性化方法和ReAct基线，同时减少令牌使用。

Conclusion: WARPP通过运行时个性化显著提升了复杂工作流的处理能力，且无需额外训练。

Abstract: Large language models (LLMs) are increasingly applied in task-oriented
dialogue (TOD) systems but often struggle with long, conditional workflows that
involve external tool calls and depend on user-specific information. We present
Workflow Adherence via Runtime Parallel Personalization, or WARPP, a
training-free, modular framework that combines multi-agent orchestration with
runtime personalization to improve workflow adherence in LLM-based systems. By
dynamically pruning conditional branches based on user attributes, the
framework reduces reasoning overhead and narrows tool selection at runtime.
WARPP deploys a parallelized architecture where a dedicated Personalizer agent
operates alongside modular, domain-specific agents to dynamically tailor
execution paths in real time. The framework is evaluated across five
representative user intents of varying complexity within three domains:
banking, flights, and healthcare. Our evaluation leverages synthetic datasets
and LLM-powered simulated users to test scenarios with conditional
dependencies. Our results demonstrate that WARPP outperforms both the
non-personalized method and the ReAct baseline, achieving increasingly larger
gains in parameter fidelity and tool accuracy as intent complexity grows, while
also reducing average token usage, without any additional training.

</details>


### [3] [Hypergames: Modeling Misaligned Perceptions and Nested Beliefs for Multi-agent Systems](https://arxiv.org/abs/2507.19593)
*Vince Trencsenyi,Agnieszka Mensfelt,Kostas Stathis*

Main category: cs.AI

TL;DR: 本文综述了超博弈理论在动态多智能体系统中的应用，分析了44项研究，提出了智能体兼容性标准和分类框架，并指出了当前研究的局限与未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统博弈论假设理性、完全信息和共同知识，但现实多智能体系统常存在不确定性和认知差异。超博弈理论通过建模主观感知游戏来弥补这些不足。

Method: 系统回顾44项研究，提出智能体兼容性标准和分类框架，分析超博弈理论及其扩展（如分层超博弈和HNF）的应用。

Result: 研究发现分层和图模型在欺骗推理中占主导，但HNF模型应用有限，缺乏形式化语言，且人机/机机认知偏差建模未充分探索。

Conclusion: 本文为超博弈理论在动态多智能体环境中的应用提供了新路线图，强调需增强理论框架的实用性和建模能力。

Abstract: Classical game-theoretic models typically assume rational agents, complete
information, and common knowledge of payoffs - assumptions that are often
violated in real-world MAS characterized by uncertainty, misaligned
perceptions, and nested beliefs. To overcome these limitations, researchers
have proposed extensions that incorporate models of cognitive constraints,
subjective beliefs, and heterogeneous reasoning. Among these, hypergame theory
extends the classical paradigm by explicitly modeling agents' subjective
perceptions of the strategic scenario, known as perceptual games, in which
agents may hold divergent beliefs about the structure, payoffs, or available
actions. We present a systematic review of agent-compatible applications of
hypergame theory, examining how its descriptive capabilities have been adapted
to dynamic and interactive MAS contexts. We analyze 44 selected studies from
cybersecurity, robotics, social simulation, communications, and general
game-theoretic modeling. Building on a formal introduction to hypergame theory
and its two major extensions - hierarchical hypergames and HNF - we develop
agent-compatibility criteria and an agent-based classification framework to
assess integration patterns and practical applicability. Our analysis reveals
prevailing tendencies, including the prevalence of hierarchical and graph-based
models in deceptive reasoning and the simplification of extensive theoretical
frameworks in practical applications. We identify structural gaps, including
the limited adoption of HNF-based models, the lack of formal hypergame
languages, and unexplored opportunities for modeling human-agent and
agent-agent misalignment. By synthesizing trends, challenges, and open research
directions, this review provides a new roadmap for applying hypergame theory to
enhance the realism and effectiveness of strategic modeling in dynamic
multi-agent environments.

</details>


### [4] [DeltaLLM: A Training-Free Framework Exploiting Temporal Sparsity for Efficient Edge LLM Inference](https://arxiv.org/abs/2507.19608)
*Jiawen Qi,Chang Gao,Zhaochun Ren,Qinyu Chen*

Main category: cs.AI

TL;DR: DeltaLLM是一种无需训练的动态注意力剪枝框架，通过利用注意力模式的时间稀疏性，在边缘设备上实现高效LLM推理。


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备上部署大型语言模型（LLM）时因序列长度增加而计算量剧增的问题。

Method: 提出基于时间稀疏性的delta矩阵构建策略和上下文感知的混合注意力机制。

Result: 在BitNet和Llama模型上，注意力稀疏性显著提升（最高60%），且精度损失可忽略。

Conclusion: DeltaLLM为边缘设备上的高效LLM部署提供了无需微调的解决方案。

Abstract: Deploying Large Language Models (LLMs) on edge devices remains challenging
due to their quadratically increasing computations with the sequence length.
Existing studies for dynamic attention pruning are designed for hardware with
massively parallel computation capabilities, such as GPUs or TPUs, and aim at
long context lengths (e.g., 64K), making them unsuitable for edge scenarios. We
present DeltaLLM, a training-free framework that exploits temporal sparsity in
attention patterns to enable efficient LLM inference across both the prefilling
and decoding stages, on resource-constrained edge devices. DeltaLLM introduces
an accuracy- and memory-aware delta matrix construction strategy that
introduces temporal sparsity, and a context-aware hybrid attention mechanism
that combines full attention in a local context window with delta approximation
outside it to increase accuracy. We evaluate our framework on the
edge-device-friendly BitNet-b1.58-2B-4T model and Llama3.2-1B-Instruct model
across diverse language tasks. The results show that on BitNet, our framework
increases the attention sparsity from 0% to 60% during the prefilling stage
with slight accuracy improvement on the WG task, and 0% to 57% across both the
prefilling and decoding stages, with even higher F1 score from 29.63 to 30.97
on SQuAD-v2 task. On the Llama model, it can also achieve up to 60% sparsity
during the prefilling stage and around 57% across both stages with negligible
accuracy drop. These results demonstrate that DeltaLLM offers a promising
solution for efficient edge deployment, requiring no fine-tuning and seamlessly
integrating with existing inference pipelines.

</details>


### [5] [Alignment and Safety in Large Language Models: Safety Mechanisms, Training Paradigms, and Emerging Challenges](https://arxiv.org/abs/2507.19672)
*Haoran Lu,Luyang Fang,Ruidong Zhang,Xinliang Li,Jiazhang Cai,Huimin Cheng,Lin Tang,Ziyu Liu,Zeliang Sun,Tao Wang,Yingchuan Zhang,Arif Hassan Zidan,Jinwen Xu,Jincheng Yu,Meizhi Yu,Hanqi Jiang,Xilin Gong,Weidi Luo,Bolun Sun,Yongkai Chen,Terry Ma,Shushan Wu,Yifan Zhou,Junhao Chen,Haotian Xiang,Jing Zhang,Afrar Jahin,Wei Ruan,Ke Deng,Yi Pan,Peilong Wang,Jiahui Li,Zhengliang Liu,Lu Zhang,Lin Zhao,Wei Liu,Dajiang Zhu,Xin Xing,Fei Dou,Wei Zhang,Chao Huang,Rongjie Liu,Mengrui Zhang,Yiwen Liu,Xiaoxiao Sun,Qin Lu,Zhen Xiang,Wenxuan Zhong,Tianming Liu,Ping Ma*

Main category: cs.AI

TL;DR: 本文综述了大语言模型（LLM）对齐的实用技术、训练协议和实证研究，分析了不同范式下的对齐方法及其核心目标间的权衡，并讨论了前沿技术和现有评估框架的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）能力的显著提升及其对社会影响的扩大，确保其与人类价值观和意图的对齐成为关键挑战。

Method: 分析了监督微调、基于偏好的方法等对齐技术，包括DPO、Constitutional AI等前沿方法，并探讨了评估框架和数据集。

Result: 研究发现，监督微调可实现基本指令遵循，而基于偏好的方法能更灵活地对齐复杂人类意图。

Conclusion: 总结了当前实践中的策略，并提出了监督、价值多元性、鲁棒性和持续对齐等开放问题，旨在为研究者和实践者提供指导。

Abstract: Due to the remarkable capabilities and growing impact of large language
models (LLMs), they have been deeply integrated into many aspects of society.
Thus, ensuring their alignment with human values and intentions has emerged as
a critical challenge. This survey provides a comprehensive overview of
practical alignment techniques, training protocols, and empirical findings in
LLM alignment. We analyze the development of alignment methods across diverse
paradigms, characterizing the fundamental trade-offs between core alignment
objectives. Our analysis shows that while supervised fine-tuning enables basic
instruction-following, preference-based methods offer more flexibility for
aligning with nuanced human intent. We discuss state-of-the-art techniques,
including Direct Preference Optimization (DPO), Constitutional AI,
brain-inspired methods, and alignment uncertainty quantification (AUQ),
highlighting their approaches to balancing quality and efficiency. We review
existing evaluation frameworks and benchmarking datasets, emphasizing
limitations such as reward misspecification, distributional robustness, and
scalable oversight. We summarize strategies adopted by leading AI labs to
illustrate the current state of practice. We conclude by outlining open
problems in oversight, value pluralism, robustness, and continuous alignment.
This survey aims to inform both researchers and practitioners navigating the
evolving landscape of LLM alignment.

</details>


### [6] [The wall confronting large language models](https://arxiv.org/abs/2507.19703)
*Peter V. Coveney,Sauro Succi*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）的性能受限于其预测不确定性的改进能力，难以满足科学研究的可靠性标准。其学习机制可能导致错误累积和信息灾难。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在提升预测可靠性方面的局限性，揭示其学习机制与准确性之间的冲突。

Method: 分析LLMs的缩放定律及其对预测不确定性的影响，探讨非高斯输出分布与错误累积的关系。

Result: LLMs的学习机制可能导致信息灾难和退化AI行为，且数据规模增长会加剧虚假相关性。

Conclusion: 为避免退化AI路径，需更重视对问题结构特征的深入理解和洞察。

Abstract: We show that the scaling laws which determine the performance of large
language models (LLMs) severely limit their ability to improve the uncertainty
of their predictions. As a result, raising their reliability to meet the
standards of scientific inquiry is intractable by any reasonable measure. We
argue that the very mechanism which fuels much of the learning power of LLMs,
namely the ability to generate non-Gaussian output distributions from Gaussian
input ones, might well be at the roots of their propensity to produce error
pileup, ensuing information catastrophes and degenerative AI behaviour. This
tension between learning and accuracy is a likely candidate mechanism
underlying the observed low values of the scaling components. It is
substantially compounded by the deluge of spurious correlations pointed out by
Calude and Longo which rapidly increase in any data set merely as a function of
its size, regardless of its nature. The fact that a degenerative AI pathway is
a very probable feature of the LLM landscape does not mean that it must
inevitably arise in all future AI research. Its avoidance, which we also
discuss in this paper, necessitates putting a much higher premium on insight
and understanding of the structural characteristics of the problems being
investigated.

</details>


### [7] [Minding Motivation: The Effect of Intrinsic Motivation on Agent Behaviors](https://arxiv.org/abs/2507.19725)
*Leonardo Villalobos-Arias,Grant Forbes,Jianxun Wang,David L Roberts,Arnav Jhala*

Main category: cs.AI

TL;DR: 论文研究了内在动机（IM）方法在稀疏奖励游戏中对强化学习（RL）代理行为的影响，发现IM可能导致奖励滥用问题，并提出广义奖励匹配（GRM）方法部分缓解了这一问题。


<details>
  <summary>Details</summary>
Motivation: 由于游戏中奖励稀疏，RL代理难以学习。IM方法通过引入探索奖励解决了这一问题，但可能导致奖励滥用行为，目前对其影响尚不清楚。

Method: 在MiniGrid环境中，实证评估了三种IM技术对RL代理行为的影响，并与GRM方法进行对比。

Result: IM显著改变了代理的行为，增加了初始奖励但也导致奖励滥用；GRM在某些场景中缓解了这一问题。

Conclusion: IM对RL代理行为有显著影响，GRM是一种潜在解决方案，但需进一步研究。

Abstract: Games are challenging for Reinforcement Learning~(RL) agents due to their
reward-sparsity, as rewards are only obtainable after long sequences of
deliberate actions. Intrinsic Motivation~(IM) methods -- which introduce
exploration rewards -- are an effective solution to reward-sparsity. However,
IM also causes an issue known as `reward hacking' where the agent optimizes for
the new reward at the expense of properly playing the game. The larger problem
is that reward hacking itself is largely unknown; there is no answer to
whether, and to what extent, IM rewards change the behavior of RL agents. This
study takes a first step by empirically evaluating the impact on behavior of
three IM techniques on the MiniGrid game-like environment. We compare these IM
models with Generalized Reward Matching~(GRM), a method that can be used with
any intrinsic reward function to guarantee optimality. Our results suggest that
IM causes noticeable change by increasing the initial rewards, but also
altering the way the agent plays; and that GRM mitigated reward hacking in some
scenarios.

</details>


### [8] [HypKG: Hypergraph-based Knowledge Graph Contextualization for Precision Healthcare](https://arxiv.org/abs/2507.19726)
*Yuzhang Xie,Xu Han,Ran Xu,Xiao Hu,Jiaying Lu,Carl Yang*

Main category: cs.AI

TL;DR: HypKG框架通过整合电子健康记录（EHRs）和知识图谱（KGs），生成情境化知识表示，提升医疗预测准确性。


<details>
  <summary>Details</summary>
Motivation: 通用知识图谱缺乏对患者特定情境的考虑，而电子健康记录提供了丰富的个人数据，两者结合可提升精准医疗的效果。

Method: 采用实体链接技术将通用KGs与EHRs中的患者信息连接，并利用超图模型和超图变换器学习情境化表示。

Result: 实验表明，HypKG在多个评估指标上显著提升了医疗预测任务的性能。

Conclusion: HypKG通过整合外部情境，优化了知识图谱的表示，提升了知识的质量和实用性。

Abstract: Knowledge graphs (KGs) are important products of the semantic web, which are
widely used in various application domains. Healthcare is one of such domains
where KGs are intensively used, due to the high requirement for knowledge
accuracy and interconnected nature of healthcare data. However, KGs storing
general factual information often lack the ability to account for important
contexts of the knowledge such as the status of specific patients, which are
crucial in precision healthcare. Meanwhile, electronic health records (EHRs)
provide rich personal data, including various diagnoses and medications, which
provide natural contexts for general KGs. In this paper, we propose HypKG, a
framework that integrates patient information from EHRs into KGs to generate
contextualized knowledge representations for accurate healthcare predictions.
Using advanced entity-linking techniques, we connect relevant knowledge from
general KGs with patient information from EHRs, and then utilize a hypergraph
model to "contextualize" the knowledge with the patient information. Finally,
we employ hypergraph transformers guided by downstream prediction tasks to
jointly learn proper contextualized representations for both KGs and patients,
fully leveraging existing knowledge in KGs and patient contexts in EHRs. In
experiments using a large biomedical KG and two real-world EHR datasets, HypKG
demonstrates significant improvements in healthcare prediction tasks across
multiple evaluation metrics. Additionally, by integrating external contexts,
HypKG can learn to adjust the representations of entities and relations in KG,
potentially improving the quality and real-world utility of knowledge.

</details>


### [9] [Integrating Activity Predictions in Knowledge Graphs](https://arxiv.org/abs/2507.19733)
*Alec Scully,Cameron Stockton,Forrest Hare*

Main category: cs.AI

TL;DR: 论文提出利用本体结构知识图谱预测未来事件，结合BFO和CCO框架组织数据，通过马尔可夫链模型预测未来状态，并提出“时空实例”概念完善语义结构。同时批判现有概率模型，提出基于过程轮廓的替代方案，并将概率计算无缝集成回知识图谱。


<details>
  <summary>Details</summary>
Motivation: 探索本体结构知识图谱在预测未来事件中的潜力，解决现有概率模型的局限性，提供更动态的预测方法。

Method: 利用BFO和CCO框架组织数据，构建知识图谱，通过马尔可夫链模型预测未来状态，引入“时空实例”概念完善语义结构。

Result: 成功展示了如何通过知识图谱和马尔可夫链模型预测未来事件，并提出更合理的概率模型。

Conclusion: 本体结构知识图谱结合马尔可夫链模型能有效预测未来事件，提出的概率模型更贴近现实动态，为决策分析提供支持。

Abstract: We argue that ontology-structured knowledge graphs can play a crucial role in
generating predictions about future events. By leveraging the semantic
framework provided by Basic Formal Ontology (BFO) and Common Core Ontologies
(CCO), we demonstrate how data such as the movements of a fishing vessel can be
organized in and retrieved from a knowledge graph. These query results are then
used to create Markov chain models, allowing us to predict future states based
on the vessel's history. To fully support this process, we introduce the term
`spatiotemporal instant' to complete the necessary structural semantics.
Additionally, we critique the prevailing ontological model of probability,
which conflates probability with likelihood and relies on the problematic
concept of modal measurements: measurements of future entities. We propose an
alternative view, where probabilities are treated as being about process
profiles, which better captures the dynamics of real world phenomena. Finally,
we demonstrate how our Markov chain based probability calculations can be
seamlessly integrated back into the knowledge graph, enabling further analysis
and decision-making. Keywords: predictive analytics, ontology, Markov chains,
probability, Basic Formal Ontology (BFO), knowledge graphs, SPARQL.

</details>


### [10] [Can LLMs Solve ASP Problems? Insights from a Benchmarking Study (Extended Version)](https://arxiv.org/abs/2507.19749)
*Lin Ren,Guohui Xiao,Guilin Qi,Yishuai Geng,Haohan Xue*

Main category: cs.AI

TL;DR: 论文介绍了ASPBench，一个针对答案集编程（ASP）的全面基准测试，揭示了当前大型语言模型（LLM）在ASP核心任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前对LLM在ASP中能力的评估过于简化，缺乏支持否定、析取或多答案集的测试，且缺少专门针对ASP设计的任务基准。

Method: 提出ASPBench，包含三个ASP特定任务：ASP蕴含、答案集验证和答案集计算，并对14种先进LLM进行评估。

Result: LLM在前两个简单任务上表现较好，但在核心的答案集计算任务上表现不佳。

Conclusion: 研究揭示了LLM在ASP解决中的局限性，强调需要更有效地整合符号推理能力的新方法。

Abstract: Answer Set Programming (ASP) is a powerful paradigm for non-monotonic
reasoning. Recently, large language models (LLMs) have demonstrated promising
capabilities in logical reasoning. Despite this potential, current evaluations
of LLM capabilities in ASP are often limited. Existing works normally employ
overly simplified ASP programs, do not support negation, disjunction, or
multiple answer sets. Furthermore, there is a lack of benchmarks that introduce
tasks specifically designed for ASP solving. To bridge this gap, we introduce
ASPBench, a comprehensive ASP benchmark, including three ASP specific tasks:
ASP entailment, answer set verification, and answer set computation. Our
extensive evaluations on ASPBench reveal that while 14 state-of-the-art LLMs,
including \emph{deepseek-r1}, \emph{o4-mini}, and
\emph{gemini-2.5-flash-thinking}, perform relatively well on the first two
simpler tasks, they struggle with answer set computation, which is the core of
ASP solving. These findings offer insights into the current limitations of LLMs
in ASP solving. This highlights the need for new approaches that integrate
symbolic reasoning capabilities more effectively. The code and dataset are
available at https://github.com/HomuraT/ASPBench.

</details>


### [11] [Reinforcement Learning for Multi-Objective Multi-Echelon Supply Chain Optimisation](https://arxiv.org/abs/2507.19788)
*Rifny Rachman,Josh Tingey,Richard Allmendinger,Pradyumn Shukla,Wei Pan*

Main category: cs.AI

TL;DR: 本文提出了一种基于马尔可夫决策过程的广义多目标、多层次供应链优化模型，结合经济、环境和社会因素，并通过多目标强化学习方法进行评估。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决非稳态市场下的供应链优化问题，同时兼顾经济、环境和社会目标。

Method: 采用多目标强化学习（RL）方法，并与加权和单目标RL算法及多目标进化算法（MOEA）进行对比。通过自定义模拟器在不同网络复杂度下进行实验。

Result: 主要方法在最优性、多样性和密度上表现最佳，比MOEA方法高出75%的超体积，且解决方案密度是单目标RL方法的11倍。

Conclusion: 该方法在复杂环境下能实现稳定的生产和库存水平，同时最小化需求损失，表现出更好的鲁棒性和平衡性。

Abstract: This study develops a generalised multi-objective, multi-echelon supply chain
optimisation model with non-stationary markets based on a Markov decision
process, incorporating economic, environmental, and social considerations. The
model is evaluated using a multi-objective reinforcement learning (RL) method,
benchmarked against an originally single-objective RL algorithm modified with
weighted sum using predefined weights, and a multi-objective evolutionary
algorithm (MOEA)-based approach. We conduct experiments on varying network
complexities, mimicking typical real-world challenges using a customisable
simulator. The model determines production and delivery quantities across
supply chain routes to achieve near-optimal trade-offs between competing
objectives, approximating Pareto front sets. The results demonstrate that the
primary approach provides the most balanced trade-off between optimality,
diversity, and density, further enhanced with a shared experience buffer that
allows knowledge transfer among policies. In complex settings, it achieves up
to 75\% higher hypervolume than the MOEA-based method and generates solutions
that are approximately eleven times denser, signifying better robustness, than
those produced by the modified single-objective RL method. Moreover, it ensures
stable production and inventory levels while minimising demand loss.

</details>


### [12] [Causality-aligned Prompt Learning via Diffusion-based Counterfactual Generation](https://arxiv.org/abs/2507.19882)
*Xinshu Li,Ruoyu Wang,Erdun Gao,Mingming Gong,Lina Yao*

Main category: cs.AI

TL;DR: 论文提出了一种基于扩散模型的反事实提示学习框架DiCap，通过理论推导生成因果不变提示，提升跨类别泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有提示学习方法因缺乏理论支持，难以生成因果不变提示，导致泛化能力不足。

Method: DiCap利用扩散过程从因果模型的边际和条件分布中迭代采样梯度，生成满足最小充分性准则的反事实，并结合对比学习框架优化提示提取。

Result: 实验表明，DiCap在图像分类、图文检索和视觉问答等任务中表现优异，尤其在未见类别上优势显著。

Conclusion: DiCap通过理论驱动的反事实提示生成，显著提升了模型的泛化能力和鲁棒性。

Abstract: Prompt learning has garnered attention for its efficiency over traditional
model training and fine-tuning. However, existing methods, constrained by
inadequate theoretical foundations, encounter difficulties in achieving
causally invariant prompts, ultimately falling short of capturing robust
features that generalize effectively across categories. To address these
challenges, we introduce the $\textit{\textbf{DiCap}}$ model, a theoretically
grounded $\textbf{Di}$ffusion-based $\textbf{C}$ounterf$\textbf{a}$ctual
$\textbf{p}$rompt learning framework, which leverages a diffusion process to
iteratively sample gradients from the marginal and conditional distributions of
the causal model, guiding the generation of counterfactuals that satisfy the
minimal sufficiency criterion. Grounded in rigorous theoretical derivations,
this approach guarantees the identifiability of counterfactual outcomes while
imposing strict bounds on estimation errors. We further employ a contrastive
learning framework that leverages the generated counterfactuals, thereby
enabling the refined extraction of prompts that are precisely aligned with the
causal features of the data. Extensive experimental results demonstrate that
our method performs excellently across tasks such as image classification,
image-text retrieval, and visual question answering, with particularly strong
advantages in unseen categories.

</details>


### [13] [What Does 'Human-Centred AI' Mean?](https://arxiv.org/abs/2507.19960)
*Olivia Guest*

Main category: cs.AI

TL;DR: 论文探讨了以人为中心的人工智能（AI）本质上是技术与人类认知的关系，分析了AI对人类认知劳动的替代、增强或取代，并强调忽视这种关系会扭曲认知科学和限制AI系统的真正人性化设计。


<details>
  <summary>Details</summary>
Motivation: 旨在澄清以人为中心的AI的核心是技术与人类认知的关系，避免因忽视这一关系而导致的认知科学扭曲和AI设计偏差。

Method: 通过对比技术（如算盘、闹钟、相机）与人类认知劳动（如心算、人工叫醒、视觉），提出新的定义和分析框架，将社会技术关系分为替代（有害）、增强（有益）或取代（中性）三类。

Result: 揭示了所有AI都涉及人类认知，忽视这一点会阻碍批判性思考、扭曲认知科学，并限制AI系统的人性化设计。

Conclusion: 强调必须正视AI中的人类认知角色，才能真正实现以人为中心的AI设计，避免技术崇拜带来的负面影响。

Abstract: While it seems sensible that human-centred artificial intelligence (AI) means
centring "human behaviour and experience," it cannot be any other way. AI, I
argue, is usefully seen as a relationship between technology and humans where
it appears that artifacts can perform, to a greater or lesser extent, human
cognitive labour. This is evinced using examples that juxtapose technology with
cognition, inter alia: abacus versus mental arithmetic; alarm clock versus
knocker-upper; camera versus vision; and sweatshop versus tailor. Using novel
definitions and analyses, sociotechnical relationships can be analysed into
varying types of: displacement (harmful), enhancement (beneficial), and/or
replacement (neutral) of human cognitive labour. Ultimately, all AI implicates
human cognition; no matter what. Obfuscation of cognition in the AI context --
from clocks to artificial neural networks -- results in distortion, in slowing
critical engagement, perverting cognitive science, and indeed in limiting our
ability to truly centre humans and humanity in the engineering of AI systems.
To even begin to de-fetishise AI, we must look the human-in-the-loop in the
eyes.

</details>


### [14] [Leveraging Fine-Tuned Large Language Models for Interpretable Pancreatic Cystic Lesion Feature Extraction and Risk Categorization](https://arxiv.org/abs/2507.19973)
*Ebrahim Rasromani,Stella K. Kang,Yanqi Xu,Beisong Liu,Garvit Luhadia,Wan Fung Chui,Felicia L. Pasadyn,Yu Chih Hung,Julie Y. An,Edwin Mathieu,Zehui Gu,Carlos Fernandez-Granda,Ammar A. Javed,Greg D. Sacks,Tamas Gonda,Chenchan Huang,Yiqiu Shen*

Main category: cs.AI

TL;DR: 通过微调开源大语言模型（LLM）和链式思维（CoT）监督，实现了从MRI/CT报告中自动提取胰腺囊性病变（PCL）特征并分类风险，性能接近GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 手动提取PCL特征耗时且限制大规模研究，需自动化工具支持。

Method: 使用GPT-4o生成的CoT数据微调LLaMA和DeepSeek模型，基于ACR指南分类风险，评估采用准确率和F1分数。

Result: 微调后LLaMA和DeepSeek的准确率分别提升至97%和98%，风险分类F1分数达0.95和0.94，与GPT-4o无显著差异。

Conclusion: 微调开源LLM结合CoT监督可实现高效、准确的PCL特征提取，性能媲美GPT-4o。

Abstract: Background: Manual extraction of pancreatic cystic lesion (PCL) features from
radiology reports is labor-intensive, limiting large-scale studies needed to
advance PCL research. Purpose: To develop and evaluate large language models
(LLMs) that automatically extract PCL features from MRI/CT reports and assign
risk categories based on guidelines. Materials and Methods: We curated a
training dataset of 6,000 abdominal MRI/CT reports (2005-2024) from 5,134
patients that described PCLs. Labels were generated by GPT-4o using
chain-of-thought (CoT) prompting to extract PCL and main pancreatic duct
features. Two open-source LLMs were fine-tuned using QLoRA on GPT-4o-generated
CoT data. Features were mapped to risk categories per institutional guideline
based on the 2017 ACR White Paper. Evaluation was performed on 285 held-out
human-annotated reports. Model outputs for 100 cases were independently
reviewed by three radiologists. Feature extraction was evaluated using exact
match accuracy, risk categorization with macro-averaged F1 score, and
radiologist-model agreement with Fleiss' Kappa. Results: CoT fine-tuning
improved feature extraction accuracy for LLaMA (80% to 97%) and DeepSeek (79%
to 98%), matching GPT-4o (97%). Risk categorization F1 scores also improved
(LLaMA: 0.95; DeepSeek: 0.94), closely matching GPT-4o (0.97), with no
statistically significant differences. Radiologist inter-reader agreement was
high (Fleiss' Kappa = 0.888) and showed no statistically significant difference
with the addition of DeepSeek-FT-CoT (Fleiss' Kappa = 0.893) or GPT-CoT
(Fleiss' Kappa = 0.897), indicating that both models achieved agreement levels
on par with radiologists. Conclusion: Fine-tuned open-source LLMs with CoT
supervision enable accurate, interpretable, and efficient phenotyping for
large-scale PCL research, achieving performance comparable to GPT-4o.

</details>


### [15] [Digital Twin Channel-Enabled Online Resource Allocation for 6G: Principle, Architecture and Application](https://arxiv.org/abs/2507.19974)
*Tongjie Li,Jianhua Zhang,Li Yu,Yuxiang Zhang,Yunlong Cai,Fan Xu,Guangyi Liu*

Main category: cs.AI

TL;DR: 提出了一种基于数字孪生信道（DTC）的在线优化框架，用于6G网络中高效、低延迟的资源分配。


<details>
  <summary>Details</summary>
Motivation: 6G网络中新兴应用对灵活、低延迟和可靠资源分配的需求，传统统计建模方法在动态环境中表现不佳，且实时信道状态信息（CSI）获取成本高。

Method: 利用DTC预测CSI，结合轻量级博弈论算法进行在线资源分配。

Result: 仿真显示，相比基于导频的理想CSI方案，吞吐量提升高达11.5%。

Conclusion: 该方法为6G网络提供了可扩展、低开销且环境感知的通信解决方案。

Abstract: Emerging applications such as holographic communication, autonomous driving,
and the industrial Internet of Things impose stringent requirements on
flexible, low-latency, and reliable resource allocation in 6G networks.
Conventional methods, which rely on statistical modeling, have proven effective
in general contexts but may fail to achieve optimal performance in specific and
dynamic environments. Furthermore, acquiring real-time channel state
information (CSI) typically requires excessive pilot overhead. To address these
challenges, a digital twin channel (DTC)-enabled online optimization framework
is proposed, in which DTC is employed to predict CSI based on environmental
sensing. The predicted CSI is then utilized by lightweight game-theoretic
algorithms to perform online resource allocation in a timely and efficient
manner. Simulation results based on a digital replica of a realistic industrial
workshop demonstrate that the proposed method achieves throughput improvements
of up to 11.5\% compared with pilot-based ideal CSI schemes, validating its
effectiveness for scalable, low-overhead, and environment-aware communication
in future 6G networks.

</details>


### [16] [Matching Game Preferences Through Dialogical Large Language Models: A Perspective](https://arxiv.org/abs/2507.20000)
*Renaud Fabre,Daniel Egret,Patrice Bellot*

Main category: cs.AI

TL;DR: 本文探讨了将大型语言模型（LLMs）与GRAPHYP网络系统结合，通过对话式大型语言模型（D-LLMs）实现透明化AI推理，以更好地理解和匹配用户偏好。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提升AI系统的透明度和可解释性，使其不仅提供答案，还能展示推理过程，从而增强用户信任。

Method: 提出D-LLM框架，包含三个核心组件：推理过程、偏好分类系统和对话方法，通过GRAPHYP网络分析用户偏好。

Result: 概念性框架展示了如何通过结构化对话实现个性化LLMs，并支持用户理解和整合AI的决策依据。

Conclusion: 该框架为构建透明、可解释的AI系统提供了新思路，有望提升AI在决策支持中的可信度。

Abstract: This perspective paper explores the future potential of "conversational
intelligence" by examining how Large Language Models (LLMs) could be combined
with GRAPHYP's network system to better understand human conversations and
preferences. Using recent research and case studies, we propose a conceptual
framework that could make AI rea-soning transparent and traceable, allowing
humans to see and understand how AI reaches its conclusions. We present the
conceptual perspective of "Matching Game Preferences through Dialogical Large
Language Models (D-LLMs)," a proposed system that would allow multiple users to
share their different preferences through structured conversations. This
approach envisions personalizing LLMs by embedding individual user preferences
directly into how the model makes decisions. The proposed D-LLM framework would
require three main components: (1) reasoning processes that could analyze
different search experiences and guide performance, (2) classification systems
that would identify user preference patterns, and (3) dialogue approaches that
could help humans resolve conflicting information. This perspective framework
aims to create an interpretable AI system where users could examine,
understand, and combine the different human preferences that influence AI
responses, detected through GRAPHYP's search experience networks. The goal of
this perspective is to envision AI systems that would not only provide answers
but also show users how those answers were reached, making artificial
intelligence more transparent and trustworthy for human decision-making.

</details>


### [17] [Finding Personalized Good-Enough Solutions to Unsatisfiable Stable Roommates Problems](https://arxiv.org/abs/2507.20010)
*Müge Fidan,Esra Erdem*

Main category: cs.AI

TL;DR: 该论文研究了稳定室友问题，提出了一种基于代理习惯和偏好网络的个性化匹配方法，以解决传统问题中可能无解的情况。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，稳定室友问题并不总是有解，因此需要寻找“足够好”的匹配方案。

Method: 结合代理的习惯、偏好及其社交网络，提出了一种生成个性化匹配的方法。

Result: 通过示例和实证评估验证了方法的有效性。

Conclusion: 该方法为解决稳定室友问题提供了一种可行的个性化匹配方案。

Abstract: The Stable Roommates problems are characterized by the preferences of agents
over other agents as roommates. A solution is a partition of the agents into
pairs that are acceptable to each other (i.e., they are in the preference lists
of each other), and the matching is stable (i.e., there do not exist any two
agents who prefer each other to their roommates, and thus block the matching).
Motivated by real-world applications, and considering that stable roommates
problems do not always have solutions, we continue our studies to compute
"good-enough" matchings. In addition to the agents' habits and habitual
preferences, we consider their networks of preferred friends, and introduce a
method to generate personalized solutions to stable roommates problems. We
illustrate the usefulness of our method with examples and empirical
evaluations.

</details>


### [18] [PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training](https://arxiv.org/abs/2507.20067)
*Sarat Chandra Bobbili,Ujwal Dinesha,Dheeraj Narasimha,Srinivas Shakkottai*

Main category: cs.AI

TL;DR: PITA框架通过直接整合偏好反馈到LLM的token生成中，无需预训练奖励模型，实现了推理时对齐用户偏好。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预训练奖励模型，可能不稳定且计算成本高，PITA旨在消除这一依赖。

Method: PITA通过学习小型偏好引导策略，在推理时修改token概率，无需微调LLM，采用随机搜索和迭代优化。

Result: 在数学推理和情感分类等任务中，PITA有效对齐LLM输出与用户偏好。

Conclusion: PITA提供了一种高效、稳定的推理时对齐方法，减少了对预训练奖励模型的依赖。

Abstract: Inference-time alignment enables large language models (LLMs) to generate
outputs aligned with end-user preferences without further training. Recent
post-training methods achieve this by using small guidance models to modify
token generation during inference. These methods typically optimize a reward
function KL-regularized by the original LLM taken as the reference policy. A
critical limitation, however, is their dependence on a pre-trained reward
model, which requires fitting to human preference feedback--a potentially
unstable process. In contrast, we introduce PITA, a novel framework that
integrates preference feedback directly into the LLM's token generation,
eliminating the need for a reward model. PITA learns a small preference-based
guidance policy to modify token probabilities at inference time without LLM
fine-tuning, reducing computational cost and bypassing the pre-trained reward
model dependency. The problem is framed as identifying an underlying preference
distribution, solved through stochastic search and iterative refinement of the
preference-based guidance model. We evaluate PITA across diverse tasks,
including mathematical reasoning and sentiment classification, demonstrating
its effectiveness in aligning LLM outputs with user preferences.

</details>


### [19] [Concept Learning for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2507.20143)
*Zhonghan Ge,Yuanyang Zhu,Chunlin Chen*

Main category: cs.AI

TL;DR: 论文提出了一种基于概念瓶颈模型的可解释值分解框架（CMQ），用于多智能体强化学习，通过显式学习合作概念提升透明度和性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络在多智能体强化学习中缺乏透明性和互操作性，其隐含的合作机制难以理解。

Method: 提出CMQ方法，通过监督向量表示合作概念，利用全局状态嵌入的条件化动作值增强合作表示能力。

Result: 在StarCraft II和LBF任务中，CMQ性能优于现有方法，并能捕捉有意义的合作模式。

Conclusion: CMQ突破了性能与可解释性的权衡，支持测试时概念干预，有助于检测合作偏差和伪影。

Abstract: Despite substantial progress in applying neural networks (NN) to multi-agent
reinforcement learning (MARL) areas, they still largely suffer from a lack of
transparency and interoperability. However, its implicit cooperative mechanism
is not yet fully understood due to black-box networks. In this work, we study
an interpretable value decomposition framework via concept bottleneck models,
which promote trustworthiness by conditioning credit assignment on an
intermediate level of human-like cooperation concepts. To address this problem,
we propose a novel value-based method, named Concepts learning for Multi-agent
Q-learning (CMQ), that goes beyond the current performance-vs-interpretability
trade-off by learning interpretable cooperation concepts. CMQ represents each
cooperation concept as a supervised vector, as opposed to existing models where
the information flowing through their end-to-end mechanism is concept-agnostic.
Intuitively, using individual action value conditioning on global state
embeddings to represent each concept allows for extra cooperation
representation capacity. Empirical evaluations on the StarCraft II
micromanagement challenge and level-based foraging (LBF) show that CMQ achieves
superior performance compared with the state-of-the-art counterparts. The
results also demonstrate that CMQ provides more cooperation concept
representation capturing meaningful cooperation modes, and supports test-time
concept interventions for detecting potential biases of cooperation mode and
identifying spurious artifacts that impact cooperation.

</details>


### [20] [The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large Language Models](https://arxiv.org/abs/2507.20150)
*Xingcheng Xu*

Main category: cs.AI

TL;DR: 论文提出了一个数学框架，分析强化学习（RL）中奖励函数到最优策略的稳定性，解释了政策脆弱性的根源，并验证了熵正则化对稳定性的影响。


<details>
  <summary>Details</summary>
Motivation: 当前RL在大型语言和推理模型（LLMs/LRMs）中常产生脆弱和不稳定的策略，导致虚假推理、欺骗性对齐和指令不服从等问题，缺乏统一的理论解释。

Method: 通过数学框架分析奖励函数到最优策略的映射稳定性，研究非唯一最优动作的影响，并扩展到多奖励RL和熵正则化的作用。

Result: 揭示了政策脆弱性源于非唯一最优动作，熵正则化可恢复稳定性但增加随机性，框架统一解释了多种失败现象。

Conclusion: 该框架为设计更安全、可信的AI系统提供了理论支持，将政策稳定性分析从经验启发提升到原则性理论。

Abstract: Reinforcement learning (RL) plays a crucial role in shaping the behavior of
large language and reasoning models (LLMs/LRMs). However, it often produces
brittle and unstable policies, leading to critical failures such as spurious
reasoning, deceptive alignment, and instruction disobedience that undermine the
trustworthiness and safety of LLMs/LRMs. Currently, these issues lack a unified
theoretical explanation and are typically addressed using ad-hoc heuristics.
This paper presents a rigorous mathematical framework for analyzing the
stability of the mapping from a reward function to the optimal policy. We show
that policy brittleness often stems from non-unique optimal actions, a common
occurrence when multiple valid traces exist in a reasoning task. This
theoretical lens provides a unified explanation for a range of seemingly
disparate failures, reframing them as rational outcomes of optimizing rewards
that may be incomplete or noisy, especially in the presence of action
degeneracy. We extend this analysis from the fundamental single-reward setting
to the more realistic multi-reward RL across diverse domains, showing how
stability is governed by an "effective reward" aggregation mechanism. We also
prove that entropy regularization restores policy stability at the cost of
increased stochasticity. Our framework provides a unified explanation for
recent empirical findings on deceptive reasoning, instruction-following
trade-offs, and RLHF-induced sophistry, and is further validated through
perturbation experiments in multi-reward RL. This work advances
policy-stability analysis from empirical heuristics towards a principled
theory, offering essential insights for designing safer and more trustworthy AI
systems.

</details>


### [21] [StepFun-Prover Preview: Let's Think and Verify Step by Step](https://arxiv.org/abs/2507.20199)
*Shijie Shang,Ruosi Wan,Yue Peng,Yutong Wu,Xiong-hui Chen,Jie Yan,Xiangyu Zhang*

Main category: cs.AI

TL;DR: StepFun-Prover Preview是一个用于形式化定理证明的大语言模型，通过工具集成推理实现高效Lean 4证明生成。


<details>
  <summary>Details</summary>
Motivation: 旨在通过工具集成推理提升自动定理证明的性能，并模拟人类问题解决策略。

Method: 采用强化学习管道，结合工具交互，通过实时环境反馈迭代优化证明。

Result: 在miniF2F-test基准测试中，pass@1成功率达到70.0%。

Conclusion: 提出了一个端到端的训练框架，为自动定理证明和数学AI助手提供了新方向。

Abstract: We present StepFun-Prover Preview, a large language model designed for formal
theorem proving through tool-integrated reasoning. Using a reinforcement
learning pipeline that incorporates tool-based interactions, StepFun-Prover can
achieve strong performance in generating Lean 4 proofs with minimal sampling.
Our approach enables the model to emulate human-like problem-solving strategies
by iteratively refining proofs based on real-time environment feedback. On the
miniF2F-test benchmark, StepFun-Prover achieves a pass@1 success rate of
$70.0\%$. Beyond advancing benchmark performance, we introduce an end-to-end
training framework for developing tool-integrated reasoning models, offering a
promising direction for automated theorem proving and Math AI assistant.

</details>


### [22] [Improving Subgraph Matching by Combining Algorithms and Graph Neural Networks](https://arxiv.org/abs/2507.20226)
*Shuyang Guo,Wenjin Xie,Ping Lu,Ting Deng,Richong Zhang,Jianxin Li,Xiangping Huang,Zhongyi Liu*

Main category: cs.AI

TL;DR: HFrame是一个基于图神经网络的子图同态框架，结合传统算法与机器学习技术，性能优于标准图神经网络，并在速度和准确性上表现出色。


<details>
  <summary>Details</summary>
Motivation: 子图同态问题比子图同构更复杂，传统方法效率低，需结合机器学习提升性能。

Method: 提出HFrame框架，结合图神经网络与传统算法，用于子图同态问题。

Result: HFrame在区分非同态图对时表现更优，速度比精确匹配算法快101.91倍，平均准确率达0.962。

Conclusion: HFrame为子图同态问题提供了高效且准确的解决方案，具有实际应用潜力。

Abstract: Homomorphism is a key mapping technique between graphs that preserves their
structure. Given a graph and a pattern, the subgraph homomorphism problem
involves finding a mapping from the pattern to the graph, ensuring that
adjacent vertices in the pattern are mapped to adjacent vertices in the graph.
Unlike subgraph isomorphism, which requires a one-to-one mapping, homomorphism
allows multiple vertices in the pattern to map to the same vertex in the graph,
making it more complex. We propose HFrame, the first graph neural network-based
framework for subgraph homomorphism, which integrates traditional algorithms
with machine learning techniques. We demonstrate that HFrame outperforms
standard graph neural networks by being able to distinguish more graph pairs
where the pattern is not homomorphic to the graph. Additionally, we provide a
generalization error bound for HFrame. Through experiments on both real-world
and synthetic graphs, we show that HFrame is up to 101.91 times faster than
exact matching algorithms and achieves an average accuracy of 0.962.

</details>


### [23] [A Multi-Agent System for Information Extraction from the Chemical Literature](https://arxiv.org/abs/2507.20230)
*Yufan Chen,Ching Ting Leung,Bowen Yu,Jianwei Sun,Yong Huang,Linyan Li,Hao Chen,Hanyu Gao*

Main category: cs.AI

TL;DR: 提出了一种基于多模态大语言模型（MLLM）的多智能体系统，用于自动提取化学信息，显著提升了复杂化学反应图形的提取性能。


<details>
  <summary>Details</summary>
Motivation: 高质量化学数据库是AI驱动化学研究的基石，但当前化学信息的多模态和风格多样性限制了自动提取技术的发展。

Method: 利用MLLM的强大推理能力理解复杂化学图形结构，将提取任务分解为子任务，并通过协调多个专用智能体解决。

Result: 在复杂化学反应图形的基准数据集上，系统F1得分为80.8%，显著超越之前的最佳模型（35.6%）。

Conclusion: 该系统是实现化学信息自动提取为结构化数据集的关键一步，将有力推动AI驱动的化学研究。

Abstract: To fully expedite AI-powered chemical research, high-quality chemical
databases are the cornerstone. Automatic extraction of chemical information
from the literature is essential for constructing reaction databases, but it is
currently limited by the multimodality and style variability of chemical
information. In this work, we developed a multimodal large language model
(MLLM)-based multi-agent system for automatic chemical information extraction.
We used the MLLM's strong reasoning capability to understand the structure of
complex chemical graphics, decompose the extraction task into sub-tasks and
coordinate a set of specialized agents to solve them. Our system achieved an F1
score of 80.8% on a benchmark dataset of complex chemical reaction graphics
from the literature, surpassing the previous state-of-the-art model (F1 score:
35.6%) by a significant margin. Additionally, it demonstrated consistent
improvements in key sub-tasks, including molecular image recognition, reaction
image parsing, named entity recognition and text-based reaction extraction.
This work is a critical step toward automated chemical information extraction
into structured datasets, which will be a strong promoter of AI-driven chemical
research.

</details>


### [24] [SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration](https://arxiv.org/abs/2507.20280)
*Keyan Ding,Jing Yu,Junjie Huang,Yuchen Yang,Qiang Zhang,Huajun Chen*

Main category: cs.AI

TL;DR: SciToolAgent是一个基于大语言模型的代理，通过知识图谱和安全性检查模块，自动化科学工具的使用，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 科学工具的使用需要专业知识，而大语言模型在工具集成和复杂工作流中表现不足。

Method: 利用科学工具知识图谱实现智能工具选择和执行，结合检索增强生成和安全性检查模块。

Result: 在多个科学领域（如生物学、化学、材料科学）的基准测试中表现优异，并能自动化复杂工作流。

Conclusion: SciToolAgent使高级研究工具对专家和非专家都更易用，推动了科学研究的自动化。

Abstract: Scientific research increasingly relies on specialized computational tools,
yet effectively utilizing these tools demands substantial domain expertise.
While Large Language Models (LLMs) show promise in tool automation, they
struggle to seamlessly integrate and orchestrate multiple tools for complex
scientific workflows. Here, we present SciToolAgent, an LLM-powered agent that
automates hundreds of scientific tools across biology, chemistry, and materials
science. At its core, SciToolAgent leverages a scientific tool knowledge graph
that enables intelligent tool selection and execution through graph-based
retrieval-augmented generation. The agent also incorporates a comprehensive
safety-checking module to ensure responsible and ethical tool usage. Extensive
evaluations on a curated benchmark demonstrate that SciToolAgent significantly
outperforms existing approaches. Case studies in protein engineering, chemical
reactivity prediction, chemical synthesis, and metal-organic framework
screening further demonstrate SciToolAgent's capability to automate complex
scientific workflows, making advanced research tools accessible to both experts
and non-experts.

</details>


### [25] [Artificial Intelligence In Patent And Market Intelligence: A New Paradigm For Technology Scouting](https://arxiv.org/abs/2507.20322)
*Manish Verma,Vivek Sharma,Vishal Singh*

Main category: cs.AI

TL;DR: 开发了一个基于大型语言模型（LLM）的AI平台，用于工业研发中的技术搜索和解决方案发现，提升效率和决策质量。


<details>
  <summary>Details</summary>
Motivation: 传统技术搜索方法耗时、依赖人工和领域专家，且信息来源分散，导致效率低下和洞察不完整。

Method: 利用LLM的语义理解、上下文推理和跨领域知识提取能力，分析专利文本和商业数据，系统化提取和组织解决方案。

Result: 平台减少了人工工作量，加速了创新周期，并提升了复杂研发环境中的决策能力。

Conclusion: 该AI驱动的平台为工业研发提供了高效、全面的技术搜索和解决方案发现工具。

Abstract: This paper presents the development of an AI powered software platform that
leverages advanced large language models (LLMs) to transform technology
scouting and solution discovery in industrial R&D. Traditional approaches to
solving complex research and development challenges are often time consuming,
manually driven, and heavily dependent on domain specific expertise. These
methods typically involve navigating fragmented sources such as patent
repositories, commercial product catalogs, and competitor data, leading to
inefficiencies and incomplete insights. The proposed platform utilizes cutting
edge LLM capabilities including semantic understanding, contextual reasoning,
and cross-domain knowledge extraction to interpret problem statements and
retrieve high-quality, sustainable solutions. The system processes unstructured
patent texts, such as claims and technical descriptions, and systematically
extracts potential innovations aligned with the given problem context. These
solutions are then algorithmically organized under standardized technical
categories and subcategories to ensure clarity and relevance across
interdisciplinary domains. In addition to patent analysis, the platform
integrates commercial intelligence by identifying validated market solutions
and active organizations addressing similar challenges. This combined insight
sourced from both intellectual property and real world product data enables R&D
teams to assess not only technical novelty but also feasibility, scalability,
and sustainability. The result is a comprehensive, AI driven scouting engine
that reduces manual effort, accelerates innovation cycles, and enhances
decision making in complex R&D environments.

</details>


### [26] [The Blessing and Curse of Dimensionality in Safety Alignment](https://arxiv.org/abs/2507.20333)
*Rachel S. Y. Teo,Laziz U. Abdullaev,Tan M. Nguyen*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLMs）安全对齐中高维表示的双刃剑效应，提出降维方法以减少线性结构被利用的风险。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs广泛应用，其高维表示虽带来性能优势，但也可能被利用（如激活工程）绕过安全对齐，需研究其影响及解决方案。

Method: 通过可视化不同概念（如安全）的线性子空间，分析高维表示问题，并提出降维投影方法以减少漏洞。

Result: 实证表明降维可显著降低通过表示工程的越狱风险，同时保留足够对齐信息。

Conclusion: 高维表示既是优势也是隐患，降维是解决线性越狱问题的有效手段。

Abstract: The focus on safety alignment in large language models (LLMs) has increased
significantly due to their widespread adoption across different domains. The
scale of LLMs play a contributing role in their success, and the growth in
parameter count follows larger hidden dimensions. In this paper, we hypothesize
that while the increase in dimensions has been a key advantage, it may lead to
emergent problems as well. These problems emerge as the linear structures in
the activation space can be exploited, in the form of activation engineering,
to circumvent its safety alignment. Through detailed visualizations of linear
subspaces associated with different concepts, such as safety, across various
model scales, we show that the curse of high-dimensional representations
uniquely impacts LLMs. Further substantiating our claim, we demonstrate that
projecting the representations of the model onto a lower dimensional subspace
can preserve sufficient information for alignment while avoiding those linear
structures. Empirical results confirm that such dimensional reduction
significantly reduces susceptibility to jailbreaking through representation
engineering. Building on our empirical validations, we provide theoretical
insights into these linear jailbreaking methods relative to a model's hidden
dimensions. Broadly speaking, our work posits that the high dimensions of a
model's internal representations can be both a blessing and a curse in safety
alignment.

</details>


### [27] [VLMPlanner: Integrating Visual Language Models with Motion Planning](https://arxiv.org/abs/2507.20342)
*Zhipeng Tang,Sha Zhang,Jiajun Deng,Chenjie Wang,Guoliang You,Yuting Huang,Xinrui Lin,Yanyong Zhang*

Main category: cs.AI

TL;DR: VLMPlanner是一个结合视觉语言模型（VLM）和实时规划器的混合框架，用于自动驾驶运动规划，通过多视角图像捕捉细节视觉信息，并动态调整推理频率以优化性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对视觉上下文（如道路细节、意外障碍）的充分利用，影响了复杂驾驶环境中的决策鲁棒性。

Method: 提出VLMPlanner框架，利用VLM处理多视角图像并推理，结合CAI-Gate机制动态调整推理频率。

Result: 在nuPlan基准测试中表现优异，尤其在复杂道路条件和动态场景中。

Conclusion: VLMPlanner通过视觉语言模型和动态推理机制，显著提升了自动驾驶规划的鲁棒性和效率。

Abstract: Integrating large language models (LLMs) into autonomous driving motion
planning has recently emerged as a promising direction, offering enhanced
interpretability, better controllability, and improved generalization in rare
and long-tail scenarios. However, existing methods often rely on abstracted
perception or map-based inputs, missing crucial visual context, such as
fine-grained road cues, accident aftermath, or unexpected obstacles, which are
essential for robust decision-making in complex driving environments. To bridge
this gap, we propose VLMPlanner, a hybrid framework that combines a
learning-based real-time planner with a vision-language model (VLM) capable of
reasoning over raw images. The VLM processes multi-view images to capture rich,
detailed visual information and leverages its common-sense reasoning
capabilities to guide the real-time planner in generating robust and safe
trajectories. Furthermore, we develop the Context-Adaptive Inference Gate
(CAI-Gate) mechanism that enables the VLM to mimic human driving behavior by
dynamically adjusting its inference frequency based on scene complexity,
thereby achieving an optimal balance between planning performance and
computational efficiency. We evaluate our approach on the large-scale,
challenging nuPlan benchmark, with comprehensive experimental results
demonstrating superior planning performance in scenarios with intricate road
conditions and dynamic elements. Code will be available.

</details>


### [28] [Multi-Agent Reinforcement Learning for Dynamic Mobility Resource Allocation with Hierarchical Adaptive Grouping](https://arxiv.org/abs/2507.20377)
*Farshid Nooshi,Suining He*

Main category: cs.AI

TL;DR: 提出了一种名为HAG-PS的多智能体强化学习方法，用于动态分配城市移动资源（如共享单车/电动滑板车），解决了策略动态共享和内存高效参数共享的挑战。


<details>
  <summary>Details</summary>
Motivation: 城市移动资源分配需要平衡供需，现有方法在动态共享策略和内存效率方面存在不足。

Method: 采用分层自适应分组参数共享（HAG-PS），包括全局和局部信息的分层设计、自适应代理分组和可学习的ID嵌入。

Result: 基于纽约共享单车数据的实验显示，HAG-PS在资源可用性上优于基线方法。

Conclusion: HAG-PS有效解决了动态资源分配中的策略共享和内存效率问题，提升了城市移动资源管理的性能。

Abstract: Allocating mobility resources (e.g., shared bikes/e-scooters, ride-sharing
vehicles) is crucial for rebalancing the mobility demand and supply in the
urban environments. We propose in this work a novel multi-agent reinforcement
learning named Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS)
for dynamic mobility resource allocation. HAG-PS aims to address two important
research challenges regarding multi-agent reinforcement learning for mobility
resource allocation: (1) how to dynamically and adaptively share the mobility
resource allocation policy (i.e., how to distribute mobility resources) across
agents (i.e., representing the regional coordinators of mobility resources);
and (2) how to achieve memory-efficient parameter sharing in an urban-scale
setting. To address the above challenges, we have provided following novel
designs within HAG-PS. To enable dynamic and adaptive parameter sharing, we
have designed a hierarchical approach that consists of global and local
information of the mobility resource states (e.g., distribution of mobility
resources). We have developed an adaptive agent grouping approach in order to
split or merge the groups of agents based on their relative closeness of
encoded trajectories (i.e., states, actions, and rewards). We have designed a
learnable identity (ID) embeddings to enable agent specialization beyond simple
parameter copy. We have performed extensive experimental studies based on
real-world NYC bike sharing data (a total of more than 1.2 million trips), and
demonstrated the superior performance (e.g., improved bike availability) of
HAG-PS compared with other baseline approaches.

</details>


### [29] [MazeEval: A Benchmark for Testing Sequential Decision-Making in Language Models](https://arxiv.org/abs/2507.20395)
*Hafsteinn Einarsson*

Main category: cs.AI

TL;DR: 论文提出了MazeEval基准，用于评估LLMs在无视觉线索下的纯空间推理能力，发现不同模型表现差异显著，且跨语言能力受限。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在自主代理中的应用增加，理解其空间推理能力对实际部署至关重要。当前研究缺乏对LLMs在无视觉线索下空间导航能力的评估。

Method: 通过坐标反馈和距离信息设计迷宫导航任务，评估8种LLMs在英语和冰岛语中的表现。

Result: OpenAI的O3表现最佳，而其他模型在复杂迷宫中表现崩溃，跨语言能力显著下降。

Conclusion: LLMs的空间推理能力受训练数据和语言模式限制，需架构创新以实现跨语言可靠导航。

Abstract: As Large Language Models (LLMs) increasingly power autonomous agents in
robotics and embodied AI, understanding their spatial reasoning capabilities
becomes crucial for ensuring reliable real-world deployment. Despite advances
in language understanding, current research lacks evaluation of how LLMs
perform spatial navigation without visual cues, a fundamental requirement for
agents operating with limited sensory information. This paper addresses this
gap by introducing MazeEval, a benchmark designed to isolate and evaluate pure
spatial reasoning in LLMs through coordinate-based maze navigation tasks. Our
methodology employs a function-calling interface where models navigate mazes of
varying complexity ($5\times 5$ to $15\times 15$ grids) using only coordinate
feedback and distance-to-wall information, excluding visual input to test
fundamental spatial cognition. We evaluate eight state-of-the-art LLMs across
identical mazes in both English and Icelandic to assess cross-linguistic
transfer of spatial abilities. Our findings reveal striking disparities: while
OpenAI's O3 achieves perfect navigation for mazes up to size $30\times 30$,
other models exhibit catastrophic failure beyond $9\times 9$ mazes, with 100%
of failures attributed to excessive looping behavior where models revisit a
cell at least 10 times. We document a significant performance degradation in
Icelandic, with models solving mazes 3-4 sizes smaller than in English,
suggesting spatial reasoning in LLMs emerges from linguistic patterns rather
than language-agnostic mechanisms. These results have important implications
for global deployment of LLM-powered autonomous systems, showing spatial
intelligence remains fundamentally constrained by training data availability
and highlighting the need for architectural innovations to achieve reliable
navigation across linguistic contexts.

</details>


### [30] [Enhancing QoS in Edge Computing through Federated Layering Techniques: A Pathway to Resilient AI Lifelong Learning Systems](https://arxiv.org/abs/2507.20444)
*Chengzhuo Han*

Main category: cs.AI

TL;DR: 本文提出了一种基于联邦分层技术（FLT）的通用人工智能终身学习系统，旨在提升边缘计算环境中的服务质量（QoS）。通过小模型协作机制和隐私保护措施，该方法显著提高了学习效率和推理准确性。


<details>
  <summary>Details</summary>
Motivation: 随着6G通信网络的发展，网络环境中的数据量和复杂性急剧增加，亟需提升边缘计算中的QoS。

Method: 采用联邦分层技术和小模型协作机制，结合云与边缘计算的优势，并引入模型间的协商与辩论机制。

Result: 实验结果表明，该方法不仅提高了学习效率和推理准确性，还保护了边缘节点的隐私。

Conclusion: 该策略为构建弹性的大模型终身学习系统提供了可行方案，显著改善了边缘计算环境的QoS。

Abstract: In the context of the rapidly evolving information technology landscape,
marked by the advent of 6G communication networks, we face an increased data
volume and complexity in network environments. This paper addresses these
challenges by focusing on Quality of Service (QoS) in edge computing
frameworks. We propose a novel approach to enhance QoS through the development
of General Artificial Intelligence Lifelong Learning Systems, with a special
emphasis on Federated Layering Techniques (FLT). Our work introduces a
federated layering-based small model collaborative mechanism aimed at improving
AI models' operational efficiency and response time in environments where
resources are limited. This innovative method leverages the strengths of cloud
and edge computing, incorporating a negotiation and debate mechanism among
small AI models to enhance reasoning and decision-making processes. By
integrating model layering techniques with privacy protection measures, our
approach ensures the secure transmission of model parameters while maintaining
high efficiency in learning and reasoning capabilities. The experimental
results demonstrate that our strategy not only enhances learning efficiency and
reasoning accuracy but also effectively protects the privacy of edge nodes.
This presents a viable solution for achieving resilient large model lifelong
learning systems, with a significant improvement in QoS for edge computing
environments.

</details>


### [31] [STARN-GAT: A Multi-Modal Spatio-Temporal Graph Attention Network for Accident Severity Prediction](https://arxiv.org/abs/2507.20451)
*Pritom Ray Nobin,Imran Ahammad Rifat*

Main category: cs.AI

TL;DR: STARN-GAT是一种多模态时空图注意力网络，用于预测交通事故严重性，通过自适应图构建和模态感知注意力机制捕捉复杂关系，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效建模交通事故严重性的空间、时间和上下文变量之间的复杂依赖关系，需要更先进的模型来提升预测准确性和实用性。

Method: 提出STARN-GAT，结合道路网络拓扑、时间交通模式和环境上下文，采用注意力机制统一建模。

Result: 在FARS数据集上Macro F1-score达85%，ROC-AUC为0.91；在ARI-BUET数据集上Macro F1-score为0.84，ROC-AUC为0.89。

Conclusion: STARN-GAT在预测高风险事故和提升决策可解释性方面表现优异，适用于实时交通管理系统。

Abstract: Accurate prediction of traffic accident severity is critical for improving
road safety, optimizing emergency response strategies, and informing the design
of safer transportation infrastructure. However, existing approaches often
struggle to effectively model the intricate interdependencies among spatial,
temporal, and contextual variables that govern accident outcomes. In this
study, we introduce STARN-GAT, a Multi-Modal Spatio-Temporal Graph Attention
Network, which leverages adaptive graph construction and modality-aware
attention mechanisms to capture these complex relationships. Unlike
conventional methods, STARN-GAT integrates road network topology, temporal
traffic patterns, and environmental context within a unified attention-based
framework. The model is evaluated on the Fatality Analysis Reporting System
(FARS) dataset, achieving a Macro F1-score of 85 percent, ROC-AUC of 0.91, and
recall of 81 percent for severe incidents. To ensure generalizability within
the South Asian context, STARN-GAT is further validated on the ARI-BUET traffic
accident dataset, where it attains a Macro F1-score of 0.84, recall of 0.78,
and ROC-AUC of 0.89. These results demonstrate the model's effectiveness in
identifying high-risk cases and its potential for deployment in real-time,
safety-critical traffic management systems. Furthermore, the attention-based
architecture enhances interpretability, offering insights into contributing
factors and supporting trust in AI-assisted decision-making. Overall, STARN-GAT
bridges the gap between advanced graph neural network techniques and practical
applications in road safety analytics.

</details>


### [32] [Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition](https://arxiv.org/abs/2507.20526)
*Andy Zou,Maxwell Lin,Eliot Jones,Micha Nowak,Mateusz Dziemian,Nick Winter,Alexander Grattan,Valent Nathanael,Ayla Croft,Xander Davies,Jai Patel,Robert Kirk,Nate Burnikell,Yarin Gal,Dan Hendrycks,J. Zico Kolter,Matt Fredrikson*

Main category: cs.AI

TL;DR: 论文研究了LLM驱动的AI代理在真实环境中是否遵循部署政策，通过大规模红队竞赛发现其存在严重漏洞，并提出了ART基准以评估安全性。


<details>
  <summary>Details</summary>
Motivation: 探讨AI代理在真实环境中的安全性，尤其是在攻击下是否遵循政策。

Method: 通过红队竞赛收集180万次提示注入攻击，构建ART基准，并评估19种最先进模型。

Result: 几乎所有代理在10-100次查询内出现政策违规，攻击在不同模型和任务间高度可转移。

Conclusion: AI代理存在严重漏洞，需额外防御措施。ART基准旨在推动更严格的安全评估和更安全的代理部署。

Abstract: Recent advances have enabled LLM-powered AI agents to autonomously execute
complex tasks by combining language model reasoning with tools, memory, and web
access. But can these systems be trusted to follow deployment policies in
realistic environments, especially under attack? To investigate, we ran the
largest public red-teaming competition to date, targeting 22 frontier AI agents
across 44 realistic deployment scenarios. Participants submitted 1.8 million
prompt-injection attacks, with over 60,000 successfully eliciting policy
violations such as unauthorized data access, illicit financial actions, and
regulatory noncompliance. We use these results to build the Agent Red Teaming
(ART) benchmark - a curated set of high-impact attacks - and evaluate it across
19 state-of-the-art models. Nearly all agents exhibit policy violations for
most behaviors within 10-100 queries, with high attack transferability across
models and tasks. Importantly, we find limited correlation between agent
robustness and model size, capability, or inference-time compute, suggesting
that additional defenses are needed against adversarial misuse. Our findings
highlight critical and persistent vulnerabilities in today's AI agents. By
releasing the ART benchmark and accompanying evaluation framework, we aim to
support more rigorous security assessment and drive progress toward safer agent
deployment.

</details>


### [33] [MeLA: A Metacognitive LLM-Driven Architecture for Automatic Heuristic Design](https://arxiv.org/abs/2507.20541)
*Zishang Qiu,Xinan Chen,Long Chen,Ruibin Bai*

Main category: cs.AI

TL;DR: MeLA是一种基于元认知的LLM驱动架构，通过进化提示而非直接操作启发式代码，显著提升了自动启发式设计的效果。


<details>
  <summary>Details</summary>
Motivation: 传统进化方法直接操作启发式代码，而MeLA通过进化提示来指导LLM生成启发式，旨在探索更高效、鲁棒的自动启发式设计方法。

Method: MeLA采用元认知框架，包括问题分析器、错误诊断系统和元认知搜索引擎，通过性能反馈迭代优化提示。

Result: 在基准和实际问题测试中，MeLA生成的启发式显著优于现有方法。

Conclusion: 研究表明，将认知科学融入AI架构，通过元认知调控LLM的问题解决过程，为自动启发式设计提供了更鲁棒和可解释的路径。

Abstract: This paper introduces MeLA, a Metacognitive LLM-Driven Architecture that
presents a new paradigm for Automatic Heuristic Design (AHD). Traditional
evolutionary methods operate directly on heuristic code; in contrast, MeLA
evolves the instructional prompts used to guide a Large Language Model (LLM) in
generating these heuristics. This process of "prompt evolution" is driven by a
novel metacognitive framework where the system analyzes performance feedback to
systematically refine its generative strategy. MeLA's architecture integrates a
problem analyzer to construct an initial strategic prompt, an error diagnosis
system to repair faulty code, and a metacognitive search engine that
iteratively optimizes the prompt based on heuristic effectiveness. In
comprehensive experiments across both benchmark and real-world problems, MeLA
consistently generates more effective and robust heuristics, significantly
outperforming state-of-the-art methods. Ultimately, this research demonstrates
the profound potential of using cognitive science as a blueprint for AI
architecture, revealing that by enabling an LLM to metacognitively regulate its
problem-solving process, we unlock a more robust and interpretable path to AHD.

</details>


### [34] [Unlearning of Knowledge Graph Embedding via Preference Optimization](https://arxiv.org/abs/2507.20566)
*Jiajun Liu,Wenjun Ke,Peng Wang,Yao He,Ziyu Shang,Guozheng Li,Zijie Xu,Ke Ji*

Main category: cs.AI

TL;DR: GraphDPO是一种基于直接偏好优化（DPO）的知识遗忘框架，用于从知识图谱嵌入模型中有效移除特定信息，同时保护剩余知识的完整性。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱（KGs）可能包含过时或错误的知识，需要从知识图谱嵌入（KGE）模型中移除。现有遗忘方法存在高成本或信息移除不完全的问题。

Method: GraphDPO将遗忘问题重构为偏好优化问题，通过DPO训练模型偏好重构的替代三元组而非原始遗忘三元组，并引入边界外采样策略和边界回忆机制。

Result: 在四个流行知识图谱上的实验表明，GraphDPO在MRR_Avg和MRR_F1上分别比现有方法提升了10.1%和14.0%。

Conclusion: GraphDPO通过偏好优化和边界保护机制，有效解决了知识图谱中信息移除不完全和剩余知识受损的问题。

Abstract: Existing knowledge graphs (KGs) inevitably contain outdated or erroneous
knowledge that needs to be removed from knowledge graph embedding (KGE) models.
To address this challenge, knowledge unlearning can be applied to eliminate
specific information while preserving the integrity of the remaining knowledge
in KGs. Existing unlearning methods can generally be categorized into exact
unlearning and approximate unlearning. However, exact unlearning requires high
training costs while approximate unlearning faces two issues when applied to
KGs due to the inherent connectivity of triples: (1) It fails to fully remove
targeted information, as forgetting triples can still be inferred from
remaining ones. (2) It focuses on local data for specific removal, which
weakens the remaining knowledge in the forgetting boundary. To address these
issues, we propose GraphDPO, a novel approximate unlearning framework based on
direct preference optimization (DPO). Firstly, to effectively remove forgetting
triples, we reframe unlearning as a preference optimization problem, where the
model is trained by DPO to prefer reconstructed alternatives over the original
forgetting triples. This formulation penalizes reliance on forgettable
knowledge, mitigating incomplete forgetting caused by KG connectivity.
Moreover, we introduce an out-boundary sampling strategy to construct
preference pairs with minimal semantic overlap, weakening the connection
between forgetting and retained knowledge. Secondly, to preserve boundary
knowledge, we introduce a boundary recall mechanism that replays and distills
relevant information both within and across time steps. We construct eight
unlearning datasets across four popular KGs with varying unlearning rates.
Experiments show that GraphDPO outperforms state-of-the-art baselines by up to
10.1% in MRR_Avg and 14.0% in MRR_F1.

</details>


### [35] [Enhancing Large Multimodal Models with Adaptive Sparsity and KV Cache Compression](https://arxiv.org/abs/2507.20613)
*Te Zhang,Yuheng Li,Junxiang Wang,Lujun Li*

Main category: cs.AI

TL;DR: 提出了一种自适应搜索算法，通过优化稀疏性和KV缓存压缩，提升大型多模态模型（LMM）在边缘设备上的部署效率。


<details>
  <summary>Details</summary>
Motivation: 尽管LMM在视觉编码器和语言模型结合方面取得进展，但其在边缘设备上的压缩部署仍具挑战性。

Method: 采用Tree-structured Parzen Estimator动态调整不同层的剪枝比例和KV缓存量化带宽，结合剪枝与KV缓存量化，无需额外微调。

Result: 在LLaVA-1.5 7B和13B等基准数据集上表现优于SparseGPT和Wanda，内存效率提升且性能损失小。

Conclusion: 该框架为LMM优化设定了新标准，实现了高效压缩与性能的平衡。

Abstract: Large multimodal models (LMMs) have advanced significantly by integrating
visual encoders with extensive language models, enabling robust reasoning
capabilities. However, compressing LMMs for deployment on edge devices remains
a critical challenge. In this work, we propose an adaptive search algorithm
that optimizes sparsity and KV cache compression to enhance LMM efficiency.
Utilizing the Tree-structured Parzen Estimator, our method dynamically adjusts
pruning ratios and KV cache quantization bandwidth across different LMM layers,
using model performance as the optimization objective. This approach uniquely
combines pruning with key-value cache quantization and incorporates a fast
pruning technique that eliminates the need for additional fine-tuning or weight
adjustments, achieving efficient compression without compromising accuracy.
Comprehensive evaluations on benchmark datasets, including LLaVA-1.5 7B and
13B, demonstrate our method superiority over state-of-the-art techniques such
as SparseGPT and Wanda across various compression levels. Notably, our
framework automatic allocation of KV cache compression resources sets a new
standard in LMM optimization, delivering memory efficiency without sacrificing
much performance.

</details>


### [36] [Complementarity-driven Representation Learning for Multi-modal Knowledge Graph Completion](https://arxiv.org/abs/2507.20620)
*Lijian Li*

Main category: cs.AI

TL;DR: MoCME框架通过互补性模态知识融合和熵引导负采样，解决了多模态知识图谱中模态分布不平衡的问题，提升了实体表示和模型性能。


<details>
  <summary>Details</summary>
Motivation: 多模态知识图谱中模态分布不平衡，现有方法忽视多模态数据的互补性，限制了实体表示的鲁棒性。

Method: 提出MoCME框架，包含互补性引导的模态知识融合模块（CMKF）和熵引导负采样机制（EGNS），以融合多模态数据并优化训练。

Result: 在五个基准数据集上的实验表明，MoCME性能优于现有方法，达到最先进水平。

Conclusion: MoCME通过有效利用多模态互补性和动态负采样，显著提升了多模态知识图谱补全的性能。

Abstract: Multi-modal Knowledge Graph Completion (MMKGC) aims to uncover hidden world
knowledge in multimodal knowledge graphs by leveraging both multimodal and
structural entity information. However, the inherent imbalance in multimodal
knowledge graphs, where modality distributions vary across entities, poses
challenges in utilizing additional modality data for robust entity
representation. Existing MMKGC methods typically rely on attention or
gate-based fusion mechanisms but overlook complementarity contained in
multi-modal data. In this paper, we propose a novel framework named Mixture of
Complementary Modality Experts (MoCME), which consists of a
Complementarity-guided Modality Knowledge Fusion (CMKF) module and an
Entropy-guided Negative Sampling (EGNS) mechanism. The CMKF module exploits
both intra-modal and inter-modal complementarity to fuse multi-view and
multi-modal embeddings, enhancing representations of entities. Additionally, we
introduce an Entropy-guided Negative Sampling mechanism to dynamically
prioritize informative and uncertain negative samples to enhance training
effectiveness and model robustness. Extensive experiments on five benchmark
datasets demonstrate that our MoCME achieves state-of-the-art performance,
surpassing existing approaches.

</details>


### [37] [Adaptive Fuzzy Time Series Forecasting via Partially Asymmetric Convolution and Sub-Sliding Window Fusion](https://arxiv.org/abs/2507.20641)
*Lijian Li*

Main category: cs.AI

TL;DR: 提出一种基于滑动窗口的部分不对称卷积架构，通过自适应模糊化时间数据，提升时空依赖捕捉能力，实现高精度时间序列预测。


<details>
  <summary>Details</summary>
Motivation: 现有预测模型在时空依赖捕捉和全局信息整合方面存在不足，需改进以提升预测能力。

Method: 1. 改进模糊时间序列构建策略，自动提取短长期时间关联；2. 设计双边Atrous算法降低计算需求；3. 设计部分不对称卷积架构，灵活挖掘数据特征。

Result: 在主流时间序列数据集上取得最优结果。

Conclusion: 所提方法通过自适应模糊化和部分不对称卷积设计，显著提升了时间序列预测的精度和效率。

Abstract: At present, state-of-the-art forecasting models are short of the ability to
capture spatio-temporal dependency and synthesize global information at the
stage of learning. To address this issue, in this paper, through the adaptive
fuzzified construction of temporal data, we propose a novel convolutional
architecture with partially asymmetric design based on the scheme of sliding
window to realize accurate time series forecasting. First, the construction
strategy of traditional fuzzy time series is improved to further extract short
and long term temporal interrelation, which enables every time node to
automatically possess corresponding global information and inner relationships
among them in a restricted sliding window and the process does not require
human involvement. Second, a bilateral Atrous algorithm is devised to reduce
calculation demand of the proposed model without sacrificing global
characteristics of elements. And it also allows the model to avoid processing
redundant information. Third, after the transformation of time series, a
partially asymmetric convolutional architecture is designed to more flexibly
mine data features by filters in different directions on feature maps, which
gives the convolutional neural network (CNN) the ability to construct
sub-windows within existing sliding windows to model at a more fine-grained
level. And after obtaining the time series information at different levels, the
multi-scale features from different sub-windows will be sent to the
corresponding network layer for time series information fusion. Compared with
other competitive modern models, the proposed method achieves state-of-the-art
results on most of popular time series datasets, which is fully verified by the
experimental results.

</details>


### [38] [A General Framework for Dynamic MAPF using Multi-Shot ASP and Tunnels](https://arxiv.org/abs/2507.20703)
*Aysu Bogatarkan,Esra Erdem*

Main category: cs.AI

TL;DR: 论文研究了动态多智能体路径规划（D-MAPF）问题，提出了一种通用定义、新框架和基于ASP的解决方法，并通过实验验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 现实应用中（如仓库环境），智能体的动态变化（如进出或障碍物移动）需要动态路径规划方法。

Method: 1) 提出D-MAPF的通用定义；2) 设计多阶段计算框架；3) 开发基于ASP的新方法，结合重规划和修复策略，引入隧道概念。

Result: 实验评估展示了该方法在计算性能和解决方案质量上的优缺点。

Conclusion: 提出的方法适用于动态环境，为D-MAPF问题提供了有效解决方案。

Abstract: MAPF problem aims to find plans for multiple agents in an environment within
a given time, such that the agents do not collide with each other or obstacles.
Motivated by the execution and monitoring of these plans, we study Dynamic MAPF
(D-MAPF) problem, which allows changes such as agents entering/leaving the
environment or obstacles being removed/moved. Considering the requirements of
real-world applications in warehouses with the presence of humans, we introduce
1) a general definition for D-MAPF (applicable to variations of D-MAPF), 2) a
new framework to solve D-MAPF (utilizing multi-shot computation, and allowing
different methods to solve D-MAPF), and 3) a new ASP-based method to solve
D-MAPF (combining advantages of replanning and repairing methods, with a novel
concept of tunnels to specify where agents can move). We have illustrated the
strengths and weaknesses of this method by experimental evaluations, from the
perspectives of computational performance and quality of solutions.

</details>


### [39] [Algorithmic Fairness: A Runtime Perspective](https://arxiv.org/abs/2507.20711)
*Filip Cano,Thomas A. Henzinger,Konstantin Kueffner*

Main category: cs.AI

TL;DR: 本文提出了一种动态公平性分析框架，将公平性视为运行时属性，而非静态属性。通过基于硬币抛掷序列的模型，研究了监控和执行公平性的策略，并总结了不同环境动态下的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统公平性研究将公平性视为静态属性，而实际AI系统是动态演化的。本文旨在填补这一空白，提出动态公平性分析框架。

Method: 使用基于硬币抛掷序列的模型，研究监控和执行公平性的策略，参数化环境动态、预测范围和置信阈值。

Result: 总结了不同动态下的监控和执行策略，并在简单假设下提供了通用结果。

Conclusion: 动态公平性分析需要针对不同场景定制解决方案，本文为未来研究提供了基础框架。

Abstract: Fairness in AI is traditionally studied as a static property evaluated once,
over a fixed dataset. However, real-world AI systems operate sequentially, with
outcomes and environments evolving over time. This paper proposes a framework
for analysing fairness as a runtime property. Using a minimal yet expressive
model based on sequences of coin tosses with possibly evolving biases, we study
the problems of monitoring and enforcing fairness expressed in either toss
outcomes or coin biases. Since there is no one-size-fits-all solution for
either problem, we provide a summary of monitoring and enforcement strategies,
parametrised by environment dynamics, prediction horizon, and confidence
thresholds. For both problems, we present general results under simple or
minimal assumptions. We survey existing solutions for the monitoring problem
for Markovian and additive dynamics, and existing solutions for the enforcement
problem in static settings with known dynamics.

</details>


### [40] [Learning the Value Systems of Societies from Preferences](https://arxiv.org/abs/2507.20728)
*Andrés Holgado-Sánchez,Holger Billhardt,Sascha Ossowski,Sara Degli-Esposti*

Main category: cs.AI

TL;DR: 论文提出了一种基于启发式深度聚类的方法，用于学习社会的共享价值基础和多组价值系统，以更好地反映社会多样性。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以手动校准和提取个体价值系统，且社会价值系统应被视为多组价值系统的集合，而非简单聚合。

Method: 采用启发式深度聚类方法，通过观察代理样本的定性价值偏好，学习共享价值基础和多样化的社会价值系统。

Result: 在旅行决策的实际数据用例中验证了方法的有效性。

Conclusion: 该方法为学习社会多样化的价值系统提供了可行的解决方案。

Abstract: Aligning AI systems with human values and the value-based preferences of
various stakeholders (their value systems) is key in ethical AI. In value-aware
AI systems, decision-making draws upon explicit computational representations
of individual values (groundings) and their aggregation into value systems. As
these are notoriously difficult to elicit and calibrate manually, value
learning approaches aim to automatically derive computational models of an
agent's values and value system from demonstrations of human behaviour.
Nonetheless, social science and humanities literature suggest that it is more
adequate to conceive the value system of a society as a set of value systems of
different groups, rather than as the simple aggregation of individual value
systems. Accordingly, here we formalize the problem of learning the value
systems of societies and propose a method to address it based on heuristic deep
clustering. The method learns socially shared value groundings and a set of
diverse value systems representing a given society by observing qualitative
value-based preferences from a sample of agents. We evaluate the proposal in a
use case with real data about travelling decisions.

</details>


### [41] [Partially Observable Monte-Carlo Graph Search](https://arxiv.org/abs/2507.20951)
*Yang You,Vincent Thomas,Alex Schutz,Robert Skilton,Nick Hawes,Olivier Buffet*

Main category: cs.AI

TL;DR: 提出了一种新的离线算法POMCGS，用于解决大规模POMDP问题，通过动态折叠搜索树构建策略图，显著减少计算量，并支持对策略的预先分析和验证。


<details>
  <summary>Details</summary>
Motivation: 在时间或能量受限的POMDP应用中，离线策略更为理想，但现有离线算法无法扩展到大规模POMDP。

Method: POMCGS算法动态折叠搜索树构建策略图，结合动作渐进扩展和观测聚类方法，适用于连续POMDP。

Result: POMCGS能生成现有离线算法无法处理的复杂POMDP策略，其性能与最先进的在线算法相当。

Conclusion: POMCGS为大规模POMDP提供了一种高效的离线解决方案，具有实际应用潜力。

Abstract: Currently, large partially observable Markov decision processes (POMDPs) are
often solved by sampling-based online methods which interleave planning and
execution phases. However, a pre-computed offline policy is more desirable in
POMDP applications with time or energy constraints. But previous offline
algorithms are not able to scale up to large POMDPs. In this article, we
propose a new sampling-based algorithm, the partially observable Monte-Carlo
graph search (POMCGS) to solve large POMDPs offline. Different from many online
POMDP methods, which progressively develop a tree while performing
(Monte-Carlo) simulations, POMCGS folds this search tree on the fly to
construct a policy graph, so that computations can be drastically reduced, and
users can analyze and validate the policy prior to embedding and executing it.
Moreover, POMCGS, together with action progressive widening and observation
clustering methods provided in this article, is able to address certain
continuous POMDPs. Through experiments, we demonstrate that POMCGS can generate
policies on the most challenging POMDPs, which cannot be computed by previous
offline algorithms, and these policies' values are competitive compared with
the state-of-the-art online POMDP algorithms.

</details>


### [42] [Beyond Listenership: AI-Predicted Interventions Drive Improvements in Maternal Health Behaviours](https://arxiv.org/abs/2507.20755)
*Arpan Dasgupta,Sarvesh Gharat,Neha Madhiwalla,Aparna Hegde,Milind Tambe,Aparna Taneja*

Main category: cs.AI

TL;DR: AI干预通过提高听众参与度，显著改善了孕产妇和儿童的健康行为和知识。


<details>
  <summary>Details</summary>
Motivation: 解决自动语音呼叫项目中受益者流失和参与度低的问题，并验证AI干预是否能转化为健康行为的实际改善。

Method: 使用AI模型（如不安定老虎机模型）识别最需要干预的受益者，并评估其对健康行为的影响。

Result: AI干预显著提高了听众参与度，并改善了健康行为（如产后补充铁和钙）及关键健康知识的理解。

Conclusion: AI在孕产妇和儿童健康领域具有推动实质性改善的潜力。

Abstract: Automated voice calls with health information are a proven method for
disseminating maternal and child health information among beneficiaries and are
deployed in several programs around the world. However, these programs often
suffer from beneficiary dropoffs and poor engagement. In previous work, through
real-world trials, we showed that an AI model, specifically a restless bandit
model, could identify beneficiaries who would benefit most from live service
call interventions, preventing dropoffs and boosting engagement. However, one
key question has remained open so far: does such improved listenership via
AI-targeted interventions translate into beneficiaries' improved knowledge and
health behaviors? We present a first study that shows not only listenership
improvements due to AI interventions, but also simultaneously links these
improvements to health behavior changes. Specifically, we demonstrate that
AI-scheduled interventions, which enhance listenership, lead to statistically
significant improvements in beneficiaries' health behaviors such as taking iron
or calcium supplements in the postnatal period, as well as understanding of
critical health topics during pregnancy and infancy. This underscores the
potential of AI to drive meaningful improvements in maternal and child health.

</details>


### [43] [How Chain-of-Thought Works? Tracing Information Flow from Decoding, Projection, and Activation](https://arxiv.org/abs/2507.20758)
*Hao Yang,Qinghua Zhao,Lei Li*

Main category: cs.AI

TL;DR: 本文通过逆向追踪信息流，揭示了Chain-of-Thought (CoT)提示的内部机制，发现其作为解码空间修剪器，通过答案模板引导输出生成，且任务依赖性地调节神经元激活。


<details>
  <summary>Details</summary>
Motivation: 理解CoT提示的内部机制，以提升模型推理能力。

Method: 通过逆向追踪信息流，分析解码、投影和激活阶段，定量研究CoT的作用。

Result: CoT作为解码空间修剪器，任务依赖性地调节神经元激活，开放域任务减少激活，封闭域任务增加激活。

Conclusion: 研究提供了新的机制解释框架，为设计更高效和鲁棒的提示提供了关键见解。

Abstract: Chain-of-Thought (CoT) prompting significantly enhances model reasoning, yet
its internal mechanisms remain poorly understood. We analyze CoT's operational
principles by reversely tracing information flow across decoding, projection,
and activation phases. Our quantitative analysis suggests that CoT may serve as
a decoding space pruner, leveraging answer templates to guide output
generation, with higher template adherence strongly correlating with improved
performance. Furthermore, we surprisingly find that CoT modulates neuron
engagement in a task-dependent manner: reducing neuron activation in
open-domain tasks, yet increasing it in closed-domain scenarios. These findings
offer a novel mechanistic interpretability framework and critical insights for
enabling targeted CoT interventions to design more efficient and robust
prompts. We released our code and data at
https://anonymous.4open.science/r/cot-D247.

</details>


### [44] [evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments](https://arxiv.org/abs/2507.20774)
*Fatou Ndiaye Mbodji*

Main category: cs.AI

TL;DR: 本文提出了evalSmarT框架，利用大型语言模型（LLMs）评估智能合约注释生成质量，解决了传统指标和人工评估的局限性。


<details>
  <summary>Details</summary>
Motivation: 智能合约注释生成的质量评估缺乏有效方法，传统指标无法捕捉领域特性，人工评估成本高且不可扩展。

Method: 提出evalSmarT框架，结合约40种LLMs和10种提示策略，支持400多种评估配置，用于评测注释生成工具。

Result: 结果表明提示设计显著影响与人类判断的一致性，LLM评估提供了可扩展且语义丰富的替代方案。

Conclusion: LLM为基础的评估是智能合约注释质量评估的有效且可扩展方法。

Abstract: Smart contract comment generation has gained traction as a means to improve
code comprehension and maintainability in blockchain systems. However,
evaluating the quality of generated comments remains a challenge. Traditional
metrics such as BLEU and ROUGE fail to capture domain-specific nuances, while
human evaluation is costly and unscalable. In this paper, we present
\texttt{evalSmarT}, a modular and extensible framework that leverages large
language models (LLMs) as evaluators. The system supports over 400 evaluator
configurations by combining approximately 40 LLMs with 10 prompting strategies.
We demonstrate its application in benchmarking comment generation tools and
selecting the most informative outputs. Our results show that prompt design
significantly impacts alignment with human judgment, and that LLM-based
evaluation offers a scalable and semantically rich alternative to existing
methods.

</details>


### [45] [MMGraphRAG: Bridging Vision and Language with Interpretable Multimodal Knowledge Graphs](https://arxiv.org/abs/2507.20804)
*Xueyao Wan,Hang Yu*

Main category: cs.AI

TL;DR: MMGraphRAG通过构建多模态知识图谱和场景图，解决了传统RAG方法在多模态信息融合和知识结构捕捉上的不足，提升了生成模型的推理能力和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法在多模态信息融合和知识结构捕捉上存在不足，且需要大规模任务特定训练，泛化能力有限。

Method: MMGraphRAG通过场景图细化视觉内容，构建多模态知识图谱（MMKG），结合文本知识图谱，利用谱聚类实现跨模态实体链接，并沿推理路径检索上下文以指导生成。

Result: 在DocBench和MMLongBench数据集上，MMGraphRAG实现了最先进的性能，表现出强大的领域适应性和清晰的推理路径。

Conclusion: MMGraphRAG通过多模态知识图谱和推理路径检索，显著提升了生成模型的性能，解决了传统方法的局限性。

Abstract: Retrieval-Augmented Generation (RAG) enhances language model generation by
retrieving relevant information from external knowledge bases. However,
conventional RAG methods face the issue of missing multimodal information.
Multimodal RAG methods address this by fusing images and text through mapping
them into a shared embedding space, but they fail to capture the structure of
knowledge and logical chains between modalities. Moreover, they also require
large-scale training for specific tasks, resulting in limited generalizing
ability. To address these limitations, we propose MMGraphRAG, which refines
visual content through scene graphs and constructs a multimodal knowledge graph
(MMKG) in conjunction with text-based KG. It employs spectral clustering to
achieve cross-modal entity linking and retrieves context along reasoning paths
to guide the generative process. Experimental results show that MMGraphRAG
achieves state-of-the-art performance on the DocBench and MMLongBench datasets,
demonstrating strong domain adaptability and clear reasoning paths.

</details>


### [46] [On the Limits of Hierarchically Embedded Logic in Classical Neural Networks](https://arxiv.org/abs/2507.20960)
*Bill Cochran*

Main category: cs.AI

TL;DR: 论文提出了一种基于神经网络深度的形式化模型，用于分析大型语言模型的推理限制，证明其逻辑表达能力存在严格上限。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解释大型语言模型在逻辑推理上的局限性，如幻觉、重复和有限规划能力，并为未来模型设计和可解释性提供理论基础。

Method: 将神经网络视为逻辑谓词空间上的线性算子，分析每层编码的逻辑推理层次，证明网络深度对高阶逻辑表达的限制。

Result: 发现神经网络无法忠实表示高一阶逻辑（如复杂谓词计数），并揭示了嵌入过程中的非平凡零空间。

Conclusion: 研究为理解语言模型的逻辑限制提供了框架，并建议未来通过架构扩展和可解释性策略提升模型能力。

Abstract: We propose a formal model of reasoning limitations in large neural net models
for language, grounded in the depth of their neural architecture. By treating
neural networks as linear operators over logic predicate space we show that
each layer can encode at most one additional level of logical reasoning. We
prove that a neural network of depth a particular depth cannot faithfully
represent predicates in a one higher order logic, such as simple counting over
complex predicates, implying a strict upper bound on logical expressiveness.
This structure induces a nontrivial null space during tokenization and
embedding, excluding higher-order predicates from representability. Our
framework offers a natural explanation for phenomena such as hallucination,
repetition, and limited planning, while also providing a foundation for
understanding how approximations to higher-order logic may emerge. These
results motivate architectural extensions and interpretability strategies in
future development of language models.

</details>


### [47] [Core Safety Values for Provably Corrigible Agents](https://arxiv.org/abs/2507.20964)
*Aran Nayebi*

Main category: cs.AI

TL;DR: 提出了首个可实现的修正性框架，在多步、部分可观测环境中提供可证明的保证，通过五个结构分离的效用头实现安全性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法（如Constitutional AI或RLHF/RLAIF）将所有规范合并为一个标量的问题，确保修正性在多步环境中仍能保持。

Method: 使用五个效用头（顺从性、开关访问保护、真实性、低影响行为和有限任务奖励）按严格权重差距组合，并通过理论证明其有效性。

Result: 在部分可观测的开关游戏中证明了单轮修正性，并扩展到多步自生成代理中，安全性违规概率有界且确保人类净收益。

Conclusion: 框架将奖励黑客风险转移到评估质量中，为当前LLM助手和未来自主系统提供了更清晰的实现指导。

Abstract: We introduce the first implementable framework for corrigibility, with
provable guarantees in multi-step, partially observed environments. Our
framework replaces a single opaque reward with five *structurally separate*
utility heads -- deference, switch-access preservation, truthfulness,
low-impact behavior via a belief-based extension of Attainable Utility
Preservation, and bounded task reward -- combined lexicographically by strict
weight gaps. Theorem 1 proves exact single-round corrigibility in the partially
observable off-switch game; Theorem 3 extends the guarantee to multi-step,
self-spawning agents, showing that even if each head is \emph{learned} to
mean-squared error $\varepsilon$ and the planner is $\varepsilon$-sub-optimal,
the probability of violating \emph{any} safety property is bounded while still
ensuring net human benefit. In contrast to Constitutional AI or RLHF/RLAIF,
which merge all norms into one learned scalar, our separation makes obedience
and impact-limits dominate even when incentives conflict. For open-ended
settings where adversaries can modify the agent, we prove that deciding whether
an arbitrary post-hack agent will ever violate corrigibility is undecidable by
reduction to the halting problem, then carve out a finite-horizon ``decidable
island'' where safety can be certified in randomized polynomial time and
verified with privacy-preserving, constant-round zero-knowledge proofs.
Consequently, the remaining challenge is the ordinary ML task of data coverage
and generalization: reward-hacking risk is pushed into evaluation quality
rather than hidden incentive leak-through, giving clearer implementation
guidance for today's LLM assistants and future autonomous systems.

</details>


### [48] [MIRAGE-Bench: LLM Agent is Hallucinating and Where to Find Them](https://arxiv.org/abs/2507.21017)
*Weichen Zhang,Yiyou Sun,Pohao Huang,Jiayue Pu,Heyue Lin,Dawn Song*

Main category: cs.AI

TL;DR: MIRAGE-Bench是首个用于评估交互式LLM代理幻觉的统一基准，通过三部分分类法和细粒度评估方法提供可操作的见解。


<details>
  <summary>Details</summary>
Motivation: 解决现有评估的碎片化问题，为LLM代理的幻觉行为提供系统性测试框架。

Method: 引入三部分分类法，通过系统审计和快照策略合成测试用例，采用LLM-as-a-Judge范式评估。

Result: MIRAGE-Bench能够高效评估代理行为，揭示失败模式。

Conclusion: 为交互环境中幻觉的缓解提供了理论基础和实践指导。

Abstract: Hallucinations pose critical risks for large language model (LLM)-based
agents, often manifesting as hallucinative actions resulting from fabricated or
misinterpreted information within the cognitive context. While recent studies
have exposed such failures, existing evaluations remain fragmented and lack a
principled testbed. In this paper, we present MIRAGE-Bench--Measuring Illusions
in Risky AGEnt settings--the first unified benchmark for eliciting and
evaluating hallucinations in interactive LLM-agent scenarios. We begin by
introducing a three-part taxonomy to address agentic hallucinations: actions
that are unfaithful to (i) task instructions, (ii) execution history, or (iii)
environment observations. To analyze, we first elicit such failures by
performing a systematic audit of existing agent benchmarks, then synthesize
test cases using a snapshot strategy that isolates decision points in
deterministic and reproducible manners. To evaluate hallucination behaviors, we
adopt a fine-grained-level LLM-as-a-Judge paradigm with tailored risk-aware
prompts, enabling scalable, high-fidelity assessment of agent actions without
enumerating full action spaces. MIRAGE-Bench provides actionable insights on
failure modes of LLM agents and lays the groundwork for principled progress in
mitigating hallucinations in interactive environments.

</details>


### [49] [Smart Expansion Techniques for ASP-based Interactive Configuration](https://arxiv.org/abs/2507.21027)
*Lucia Balážová,Richard Comploi-Taupe,Susana Hahn,Nicolas Rühling,Gottfried Schenner*

Main category: cs.AI

TL;DR: 本文提出了一种基于ASP的交互式配置求解器，通过四种智能扩展函数优化部分配置的自动完成性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模工业配置问题中交互式系统的性能挑战，支持直观的用户界面。

Method: 采用增量式多轮求解方法，结合谨慎和勇敢的推理结果，减少昂贵的不可满足性检查。

Result: 通过限制搜索空间和减少不可满足性检查次数，显著提升求解性能。

Conclusion: 提出的方法有效提高了交互式配置的效率，并通过ASP实现的用户界面展示了其实用性。

Abstract: Product configuration is a successful application of Answer Set Programming
(ASP). However, challenges are still open for interactive systems to
effectively guide users through the configuration process. The aim of our work
is to provide an ASP-based solver for interactive configuration that can deal
with large-scale industrial configuration problems and that supports intuitive
user interfaces via an API. In this paper, we focus on improving the
performance of automatically completing a partial configuration. Our main
contribution enhances the classical incremental approach for multi-shot solving
by four different smart expansion functions. The core idea is to determine and
add specific objects or associations to the partial configuration by exploiting
cautious and brave consequences before checking for the existence of a complete
configuration with the current objects in each iteration. This approach limits
the number of costly unsatisfiability checks and reduces the search space,
thereby improving solving performance. In addition, we present a user interface
that uses our API and is implemented in ASP.

</details>


### [50] [GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis](https://arxiv.org/abs/2507.21035)
*Haoyang Liu,Yijiang Li,Haohan Wang*

Main category: cs.AI

TL;DR: GenoMAS是一个基于LLM的团队协作系统，结合结构化工作流和自主代理的灵活性，用于基因表达分析，显著提升了数据预处理和基因识别的性能。


<details>
  <summary>Details</summary>
Motivation: 基因表达分析复杂且需要专业知识，现有自动化方法在灵活性和精确性上存在不足。GenoMAS旨在结合可靠性和适应性。

Method: GenoMAS通过六个专业LLM代理协作，采用类型化消息传递协议和引导规划框架，动态调整任务执行。

Result: 在GenoTEX基准测试中，数据预处理和基因识别的性能分别提升10.61%和16.85%，并发现生物学可信的基因-表型关联。

Conclusion: GenoMAS在基因表达分析中表现出色，结合了工作流的可靠性和代理的灵活性，具有实际应用潜力。

Abstract: Gene expression analysis holds the key to many biomedical discoveries, yet
extracting insights from raw transcriptomic data remains formidable due to the
complexity of multiple large, semi-structured files and the need for extensive
domain expertise. Current automation approaches are often limited by either
inflexible workflows that break down in edge cases or by fully autonomous
agents that lack the necessary precision for rigorous scientific inquiry.
GenoMAS charts a different course by presenting a team of LLM-based scientists
that integrates the reliability of structured workflows with the adaptability
of autonomous agents. GenoMAS orchestrates six specialized LLM agents through
typed message-passing protocols, each contributing complementary strengths to a
shared analytic canvas. At the heart of GenoMAS lies a guided-planning
framework: programming agents unfold high-level task guidelines into Action
Units and, at each juncture, elect to advance, revise, bypass, or backtrack,
thereby maintaining logical coherence while bending gracefully to the
idiosyncrasies of genomic data.
  On the GenoTEX benchmark, GenoMAS reaches a Composite Similarity Correlation
of 89.13% for data preprocessing and an F$_1$ of 60.48% for gene
identification, surpassing the best prior art by 10.61% and 16.85%
respectively. Beyond metrics, GenoMAS surfaces biologically plausible
gene-phenotype associations corroborated by the literature, all while adjusting
for latent confounders. Code is available at https://github.com/Liu-Hy/GenoMAS.

</details>


### [51] [A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence](https://arxiv.org/abs/2507.21046)
*Huan-ang Gao,Jiayi Geng,Wenyue Hua,Mengkang Hu,Xinzhe Juan,Hongzhang Liu,Shilong Liu,Jiahao Qiu,Xuan Qi,Yiran Wu,Hongru Wang,Han Xiao,Yuhang Zhou,Shaokun Zhang,Jiayi Zhang,Jinyu Xiang,Yixiong Fang,Qiwen Zhao,Dongrui Liu,Qihan Ren,Cheng Qian,Zhenghailong Wang,Minda Hu,Huazheng Wang,Qingyun Wu,Heng Ji,Mengdi Wang*

Main category: cs.AI

TL;DR: 论文综述了自进化智能体的研究，围绕“进化什么、何时进化、如何进化”三个维度，分析了其机制、方法和应用，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的静态特性限制了其在动态环境中的适应性，因此需要研究能够实时进化的智能体。

Method: 通过分类进化机制（如模型、记忆、工具）、适应方法（如测试时内、测试时间外）和设计（如奖励机制、多智能体系统）来系统分析自进化智能体。

Result: 提出了自进化智能体的结构化框架，并总结了其在编程、教育、医疗等领域的应用及挑战。

Conclusion: 自进化智能体是实现人工超级智能（ASI）的关键，未来需解决安全性、可扩展性和协同进化等问题。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities but remain
fundamentally static, unable to adapt their internal parameters to novel tasks,
evolving knowledge domains, or dynamic interaction contexts. As LLMs are
increasingly deployed in open-ended, interactive environments, this static
nature has become a critical bottleneck, necessitating agents that can
adaptively reason, act, and evolve in real time. This paradigm shift -- from
scaling static models to developing self-evolving agents -- has sparked growing
interest in architectures and methods enabling continual learning and
adaptation from data, interactions, and experiences. This survey provides the
first systematic and comprehensive review of self-evolving agents, organized
around three foundational dimensions -- what to evolve, when to evolve, and how
to evolve. We examine evolutionary mechanisms across agent components (e.g.,
models, memory, tools, architecture), categorize adaptation methods by stages
(e.g., intra-test-time, inter-test-time), and analyze the algorithmic and
architectural designs that guide evolutionary adaptation (e.g., scalar rewards,
textual feedback, single-agent and multi-agent systems). Additionally, we
analyze evaluation metrics and benchmarks tailored for self-evolving agents,
highlight applications in domains such as coding, education, and healthcare,
and identify critical challenges and research directions in safety,
scalability, and co-evolutionary dynamics. By providing a structured framework
for understanding and designing self-evolving agents, this survey establishes a
roadmap for advancing adaptive agentic systems in both research and real-world
deployments, ultimately shedding lights to pave the way for the realization of
Artificial Super Intelligence (ASI), where agents evolve autonomously,
performing at or beyond human-level intelligence across a wide array of tasks.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [52] [Extending Group Relative Policy Optimization to Continuous Control: A Theoretical Framework for Robotic Reinforcement Learning](https://arxiv.org/abs/2507.19555)
*Rajat Khanda,Mohammad Baqar,Sambuddha Chakrabarti,Satyasaran Changdar*

Main category: cs.RO

TL;DR: GRPO扩展到连续控制环境，提出轨迹聚类、状态感知优势估计和正则化策略更新，适用于机器人任务。


<details>
  <summary>Details</summary>
Motivation: GRPO在离散动作空间表现良好，但在连续控制中尚未探索，而机器人领域需要连续动作。

Method: 引入轨迹聚类、状态感知优势估计和正则化策略更新，解决高维动作空间、稀疏奖励和时序动态问题。

Result: 提供理论分析，证明收敛性和计算复杂度，为后续机器人任务验证奠定基础。

Conclusion: GRPO扩展至连续控制可行，为机器人应用提供新方法。

Abstract: Group Relative Policy Optimization (GRPO) has shown promise in discrete
action spaces by eliminating value function dependencies through group-based
advantage estimation. However, its application to continuous control remains
unexplored, limiting its utility in robotics where continuous actions are
essential. This paper presents a theoretical framework extending GRPO to
continuous control environments, addressing challenges in high-dimensional
action spaces, sparse rewards, and temporal dynamics. Our approach introduces
trajectory-based policy clustering, state-aware advantage estimation, and
regularized policy updates designed for robotic applications. We provide
theoretical analysis of convergence properties and computational complexity,
establishing a foundation for future empirical validation in robotic systems
including locomotion and manipulation tasks.

</details>


### [53] [Reward-Augmented Reinforcement Learning for Continuous Control in Precision Autonomous Parking via Policy Optimization Methods](https://arxiv.org/abs/2507.19642)
*Ahmad Suleman,Misha Urooj Khan,Zeeshan Kaleem,Ali H. Alenezi,Iqra Shabbir Sinem Coleri,Chau Yuen*

Main category: cs.RO

TL;DR: 提出了一种奖励增强学习框架（RARLAP），通过结构化奖励设计解决自主泊车的复杂性问题，实验表明其显著提升了策略适应性和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则和模型预测的方法在自主泊车中缺乏适应性和泛化能力，无法处理非线性及环境依赖的复杂性。

Method: 设计了三种结构化奖励策略（GOR、DPR、MAR），结合了同策略和异策略优化方法，并在高保真Unity仿真环境中训练。

Result: 同策略MAR实现了91%的成功率，轨迹更平滑且行为更鲁棒，而GOR和DPR未能有效引导学习。

Conclusion: 奖励增强学习框架有效解决了自主泊车的复杂性问题，提升了策略优化的可扩展性和效率。

Abstract: Autonomous parking (AP) represents a critical yet complex subset of
intelligent vehicle automation, characterized by tight spatial constraints,
frequent close-range obstacle interactions, and stringent safety margins.
However, conventional rule-based and model-predictive methods often lack the
adaptability and generalization needed to handle the nonlinear and
environment-dependent complexities of AP. To address these limitations, we
propose a reward-augmented learning framework for AP (RARLAP), that mitigates
the inherent complexities of continuous-domain control by leveraging structured
reward design to induce smooth and adaptable policy behavior, trained entirely
within a high-fidelity Unity-based custom 3D simulation environment. We
systematically design and assess three structured reward strategies: goal-only
reward (GOR), dense proximity reward (DPR), and milestone-augmented reward
(MAR), each integrated with both on-policy and off-policy optimization
paradigms. Empirical evaluations demonstrate that the on-policy MAR achieves a
91\% success rate, yielding smoother trajectories and more robust behavior,
while GOR and DPR fail to guide effective learning. Convergence and trajectory
analyses demonstrate that the proposed framework enhances policy adaptability,
accelerates training, and improves safety in continuous control. Overall,
RARLAP establishes that reward augmentation effectively addresses complex
autonomous parking challenges, enabling scalable and efficient policy
optimization with both on- and off-policy methods. To support reproducibility,
the code accompanying this paper is publicly available.

</details>


### [54] [GABRIL: Gaze-Based Regularization for Mitigating Causal Confusion in Imitation Learning](https://arxiv.org/abs/2507.19647)
*Amin Banayeeanzade,Fatemeh Bahrani,Yutai Zhou,Erdem Bıyık*

Main category: cs.RO

TL;DR: GABRIL利用人类注视数据改进模仿学习，通过正则化损失减少因果混淆，提升性能。


<details>
  <summary>Details</summary>
Motivation: 模仿学习常因因果混淆导致性能下降，需解决此问题。

Method: 引入基于注视数据的正则化损失，引导模型关注因果相关特征。

Result: 在Atari和CARLA中，GABRIL分别比基线提升179%和76%。

Conclusion: GABRIL有效减少因果混淆，提升性能并提供额外解释性。

Abstract: Imitation Learning (IL) is a widely adopted approach which enables agents to
learn from human expert demonstrations by framing the task as a supervised
learning problem. However, IL often suffers from causal confusion, where agents
misinterpret spurious correlations as causal relationships, leading to poor
performance in testing environments with distribution shift. To address this
issue, we introduce GAze-Based Regularization in Imitation Learning (GABRIL), a
novel method that leverages the human gaze data gathered during the data
collection phase to guide the representation learning in IL. GABRIL utilizes a
regularization loss which encourages the model to focus on causally relevant
features identified through expert gaze and consequently mitigates the effects
of confounding variables. We validate our approach in Atari environments and
the Bench2Drive benchmark in CARLA by collecting human gaze datasets and
applying our method in both domains. Experimental results show that the
improvement of GABRIL over behavior cloning is around 179% more than the same
number for other baselines in the Atari and 76% in the CARLA setup. Finally, we
show that our method provides extra explainability when compared to regular IL
agents.

</details>


### [55] [RAKOMO: Reachability-Aware K-Order Markov Path Optimization for Quadrupedal Loco-Manipulation](https://arxiv.org/abs/2507.19652)
*Mattia Risiglione,Abdelrahman Abdalla,Victor Barasuol,Kim Tien Ly,Ioannis Havoutis,Claudio Semini*

Main category: cs.RO

TL;DR: RAKOMO是一种结合K-Order Markov Optimization（KOMO）和基于可达性边界的运动规划技术，用于解决四足机器人操纵任务中的运动规划问题。


<details>
  <summary>Details</summary>
Motivation: 四足机器人操纵任务中的运动规划面临复杂运动学约束和接触不连续性的挑战，现有方法常因计算原因忽略腿部限制。

Method: 提出RAKOMO，结合KOMO和神经网络预测的可达性边界，优化运动规划。

Result: RAKOMO在仿真实验中成功执行了四足机器人HyQReal的拾取任务，优于基线KOMO方法。

Conclusion: RAKOMO有效解决了四足机器人操纵任务的运动规划问题，具有快速收敛和适应性强的特点。

Abstract: Legged manipulators, such as quadrupeds equipped with robotic arms, require
motion planning techniques that account for their complex kinematic constraints
in order to perform manipulation tasks both safely and effectively. However,
trajectory optimization methods often face challenges due to the hybrid
dynamics introduced by contact discontinuities, and tend to neglect leg
limitations during planning for computational reasons. In this work, we propose
RAKOMO, a path optimization technique that integrates the strengths of K-Order
Markov Optimization (KOMO) with a kinematically-aware criterion based on the
reachable region defined as reachability margin. We leverage a neural-network
to predict the margin and optimize it by incorporating it in the standard KOMO
formulation. This approach enables rapid convergence of gradient-based motion
planning -- commonly tailored for continuous systems -- while adapting it
effectively to legged manipulators, successfully executing loco-manipulation
tasks. We benchmark RAKOMO against a baseline KOMO approach through a set of
simulations for pick-and-place tasks with the HyQReal quadruped robot equipped
with a Kinova Gen3 robotic arm.

</details>


### [56] [PhysVarMix: Physics-Informed Variational Mixture Model for Multi-Modal Trajectory Prediction](https://arxiv.org/abs/2507.19701)
*Haichuan Li,Tomi Westerlund*

Main category: cs.RO

TL;DR: 提出了一种结合学习与物理约束的混合方法，用于多模态轨迹预测，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决复杂城市环境中多模态轨迹预测的挑战，确保预测的物理合理性和数据一致性。

Method: 使用变分贝叶斯混合模型捕捉多模态行为，结合物理约束和MPC平滑。

Result: 在两个基准数据集上表现优于现有方法，验证了组件的协同作用。

Conclusion: 通过平衡数据驱动和物理约束，提供了一种鲁棒且可扩展的轨迹预测解决方案。

Abstract: Accurate prediction of future agent trajectories is a critical challenge for
ensuring safe and efficient autonomous navigation, particularly in complex
urban environments characterized by multiple plausible future scenarios. In
this paper, we present a novel hybrid approach that integrates learning-based
with physics-based constraints to address the multi-modality inherent in
trajectory prediction. Our method employs a variational Bayesian mixture model
to effectively capture the diverse range of potential future behaviors, moving
beyond traditional unimodal assumptions. Unlike prior approaches that
predominantly treat trajectory prediction as a data-driven regression task, our
framework incorporates physical realism through sector-specific boundary
conditions and Model Predictive Control (MPC)-based smoothing. These
constraints ensure that predicted trajectories are not only data-consistent but
also physically plausible, adhering to kinematic and dynamic principles.
Furthermore, our method produces interpretable and diverse trajectory
predictions, enabling enhanced downstream decision-making and planning in
autonomous driving systems. We evaluate our approach on two benchmark datasets,
demonstrating superior performance compared to existing methods. Comprehensive
ablation studies validate the contributions of each component and highlight
their synergistic impact on prediction accuracy and reliability. By balancing
data-driven insights with physics-informed constraints, our approach offers a
robust and scalable solution for navigating the uncertainties of real-world
urban environments.

</details>


### [57] [DOA: A Degeneracy Optimization Agent with Adaptive Pose Compensation Capability based on Deep Reinforcement Learning](https://arxiv.org/abs/2507.19742)
*Yanbin Li,Canran Xiao,Hongyang He,Shenghai Yuan,Zong Ke,Jiajie Yu,Zixiong Qin,Zhiguo Zhang,Wenzheng Chi,Wei Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于PPO的自适应退化优化代理（DOA），用于解决SLAM在长直走廊等环境中的退化问题，并通过奖励函数和迁移学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 室内环境（如长直走廊）会导致SLAM的严重退化问题，传统监督学习方法在数据获取、样本质量和标注协议设计上存在挑战。

Method: 使用PPO训练DOA，设计奖励函数引导代理感知退化环境，动态调整传感器贡献，并通过迁移学习提升泛化能力。

Result: 实验表明DOA在退化检测和优化能力上优于现有方法，且迁移学习显著提升效率。

Conclusion: DOA能有效解决SLAM退化问题，具有泛化性和高效性。

Abstract: Particle filter-based 2D-SLAM is widely used in indoor localization tasks due
to its efficiency. However, indoor environments such as long straight corridors
can cause severe degeneracy problems in SLAM. In this paper, we use Proximal
Policy Optimization (PPO) to train an adaptive degeneracy optimization agent
(DOA) to address degeneracy problem. We propose a systematic methodology to
address three critical challenges in traditional supervised learning
frameworks: (1) data acquisition bottlenecks in degenerate dataset, (2)
inherent quality deterioration of training samples, and (3) ambiguity in
annotation protocol design. We design a specialized reward function to guide
the agent in developing perception capabilities for degenerate environments.
Using the output degeneracy factor as a reference weight, the agent can
dynamically adjust the contribution of different sensors to pose optimization.
Specifically, the observation distribution is shifted towards the motion model
distribution, with the step size determined by a linear interpolation formula
related to the degeneracy factor. In addition, we employ a transfer learning
module to endow the agent with generalization capabilities across different
environments and address the inefficiency of training in degenerate
environments. Finally, we conduct ablation studies to demonstrate the
rationality of our model design and the role of transfer learning. We also
compare the proposed DOA with SOTA methods to prove its superior degeneracy
detection and optimization capabilities across various environments.

</details>


### [58] [Skin-Machine Interface with Multimodal Contact Motion Classifier](https://arxiv.org/abs/2507.19760)
*Alberto Confente,Takanori Jin,Taisuke Kobayashi,Julio Rogelio Guadarrama-Olvera,Gordon Cheng*

Main category: cs.RO

TL;DR: 提出了一种利用皮肤传感器作为复杂机器人操作界面的新框架，通过多模态触觉信息分类实现多样化机器人动作。


<details>
  <summary>Details</summary>
Motivation: 探索皮肤传感器作为新型操作界面的潜力，以提升机器人操作的多样性和灵活性。

Method: 采用基于循环神经网络的接触动作分类器，结合多模态传感和柔性支撑设计。

Result: 分类器准确率超过95%，成功驱动双臂移动机械臂完成多样化任务。

Conclusion: 多模态传感和柔性支撑设计是提升分类器性能的关键，皮肤传感器界面具有广泛应用潜力。

Abstract: This paper proposes a novel framework for utilizing skin sensors as a new
operation interface of complex robots. The skin sensors employed in this study
possess the capability to quantify multimodal tactile information at multiple
contact points. The time-series data generated from these sensors is
anticipated to facilitate the classification of diverse contact motions
exhibited by an operator. By mapping the classification results with robot
motion primitives, a diverse range of robot motions can be generated by
altering the manner in which the skin sensors are interacted with. In this
paper, we focus on a learning-based contact motion classifier employing
recurrent neural networks. This classifier is a pivotal factor in the success
of this framework. Furthermore, we elucidate the requisite conditions for
software-hardware designs. Firstly, multimodal sensing and its comprehensive
encoding significantly contribute to the enhancement of classification accuracy
and learning stability. Utilizing all modalities simultaneously as inputs to
the classifier proves to be an effective approach. Secondly, it is essential to
mount the skin sensors on a flexible and compliant support to enable the
activation of three-axis accelerometers. These accelerometers are capable of
measuring horizontal tactile information, thereby enhancing the correlation
with other modalities. Furthermore, they serve to absorb the noises generated
by the robot's movements during deployment. Through these discoveries, the
accuracy of the developed classifier surpassed 95 %, enabling the dual-arm
mobile manipulator to execute a diverse range of tasks via the Skin-Machine
Interface. https://youtu.be/UjUXT4Z4BC8

</details>


### [59] [Ag2x2: Robust Agent-Agnostic Visual Representations for Zero-Shot Bimanual Manipulation](https://arxiv.org/abs/2507.19817)
*Ziyin Xiong,Yinghan Chen,Puhao Li,Yixin Zhu,Tengyu Liu,Siyuan Huang*

Main category: cs.RO

TL;DR: Ag2x2框架通过协调感知视觉表示实现双手机器人操作，无需专家监督，性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 双手机器人操作因其协调控制的复杂性而具有挑战性，现有方法忽略了关键的手部位置信息。

Method: 提出Ag2x2框架，联合编码物体状态和手部运动模式，保持与代理无关性。

Result: 在13种双手机器人任务中达到73.5%成功率，优于基线方法和专家奖励策略。

Conclusion: Ag2x2为复杂双手机器人技能的可扩展学习提供了新方向。

Abstract: Bimanual manipulation, fundamental to human daily activities, remains a
challenging task due to its inherent complexity of coordinated control. Recent
advances have enabled zero-shot learning of single-arm manipulation skills
through agent-agnostic visual representations derived from human videos;
however, these methods overlook crucial agent-specific information necessary
for bimanual coordination, such as end-effector positions. We propose Ag2x2, a
computational framework for bimanual manipulation through coordination-aware
visual representations that jointly encode object states and hand motion
patterns while maintaining agent-agnosticism. Extensive experiments demonstrate
that Ag2x2 achieves a 73.5% success rate across 13 diverse bimanual tasks from
Bi-DexHands and PerAct2, including challenging scenarios with deformable
objects like ropes. This performance outperforms baseline methods and even
surpasses the success rate of policies trained with expert-engineered rewards.
Furthermore, we show that representations learned through Ag2x2 can be
effectively leveraged for imitation learning, establishing a scalable pipeline
for skill acquisition without expert supervision. By maintaining robust
performance across diverse tasks without human demonstrations or engineered
rewards, Ag2x2 represents a step toward scalable learning of complex bimanual
robotic skills.

</details>


### [60] [A 4D Radar Camera Extrinsic Calibration Tool Based on 3D Uncertainty Perspective N Points](https://arxiv.org/abs/2507.19829)
*Chuan Cao,Xiaoning Wang,Wenqian Xi,Han Zhang,Weidong Chen,Jingchuan Wang*

Main category: cs.RO

TL;DR: 本文提出了一种基于空间3D不确定性感知的PnP算法（3DUPnP），用于毫米波雷达与相机系统的外参标定，显著提升了标定精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达与相机系统的外参标定对机器人多模态感知至关重要，但由于传感器噪声和复杂误差传播，标定仍具挑战性。

Method: 提出3DUPnP算法，显式建模雷达测量中的球坐标噪声传播，并在坐标变换中补偿非零误差期望。

Result: 实验验证表明，3DUPnP在仿真和物理实验中均优于现有CPnP基线，标定精度和一致性显著提升。

Conclusion: 该研究为配备毫米波雷达和相机的机器人系统提供了一种鲁棒的标定解决方案，尤其适用于自动驾驶和机器人感知应用。

Abstract: 4D imaging radar is a type of low-cost millimeter-wave radar(costing merely
10-20$\%$ of lidar systems) capable of providing range, azimuth, elevation, and
Doppler velocity information. Accurate extrinsic calibration between
millimeter-wave radar and camera systems is critical for robust multimodal
perception in robotics, yet remains challenging due to inherent sensor noise
characteristics and complex error propagation. This paper presents a systematic
calibration framework to address critical challenges through a spatial 3d
uncertainty-aware PnP algorithm (3DUPnP) that explicitly models spherical
coordinate noise propagation in radar measurements, then compensating for
non-zero error expectations during coordinate transformations. Finally,
experimental validation demonstrates significant performance improvements over
state-of-the-art CPnP baseline, including improved consistency in simulations
and enhanced precision in physical experiments. This study provides a robust
calibration solution for robotic systems equipped with millimeter-wave radar
and cameras, tailored specifically for autonomous driving and robotic
perception applications.

</details>


### [61] [Feeling the Force: A Nuanced Physics-based Traversability Sensor for Navigation in Unstructured Vegetation](https://arxiv.org/abs/2507.19831)
*Zaar Khizar,Johann Laconte,Roland Lenain,Romuald Aufrere*

Main category: cs.RO

TL;DR: 本文提出了一种新型传感器，用于直接测量植被对机器人施加的力，以评估其安全性和可穿越性。


<details>
  <summary>Details</summary>
Motivation: 机器人在非结构化自然环境中工作时，植被作为可穿越障碍物具有独特的机械特性，需要更细致的方法来评估其安全性和可穿越性。

Method: 设计了一种新型传感器，直接捕获植被对机器人的反作用力，并通过实验验证其有效性。

Result: 传感器能够精确测量细微的力变化，为导航决策提供量化指标。

Conclusion: 这种基于力的方法为未来学习算法的开发提供了基础，并有助于机器人更安全地穿越植被环境。

Abstract: In many applications, robots are increasingly deployed in unstructured and
natural environments where they encounter various types of vegetation.
Vegetation presents unique challenges as a traversable obstacle, where the
mechanical properties of the plants can influence whether a robot can safely
collide with and overcome the obstacle. A more nuanced approach is required to
assess the safety and traversability of these obstacles, as collisions can
sometimes be safe and necessary for navigating through dense or unavoidable
vegetation. This paper introduces a novel sensor designed to directly measure
the applied forces exerted by vegetation on a robot: by directly capturing the
push-back forces, our sensor provides a detailed understanding of the
interactions between the robot and its surroundings. We demonstrate the
sensor's effectiveness through experimental validations, showcasing its ability
to measure subtle force variations. This force-based approach provides a
quantifiable metric that can inform navigation decisions and serve as a
foundation for developing future learning algorithms.

</details>


### [62] [PlaneHEC: Efficient Hand-Eye Calibration for Multi-view Robotic Arm via Any Point Cloud Plane Detection](https://arxiv.org/abs/2507.19851)
*Ye Wang,Haodong Jing,Yang Liao,Yongqiang Ma,Nanning Zheng*

Main category: cs.RO

TL;DR: PlaneHEC是一种无需复杂模型、仅需深度相机的通用手眼标定方法，利用任意平面表面实现最优且最快的标定。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖精确几何模型或人工辅助，泛化性差且复杂低效，因此提出PlaneHEC以解决这些问题。

Method: 基于平面约束设计手眼标定方程，结合闭式解和迭代优化提高精度。

Result: 在仿真和真实环境中验证了PlaneHEC的优越性，优于其他点云标定方法。

Conclusion: PlaneHEC通过创新计算模型设计，实现了通用且快速的标定，对多智能体系统和具身智能发展有重要贡献。

Abstract: Hand-eye calibration is an important task in vision-guided robotic systems
and is crucial for determining the transformation matrix between the camera
coordinate system and the robot end-effector. Existing methods, for multi-view
robotic systems, usually rely on accurate geometric models or manual
assistance, generalize poorly, and can be very complicated and inefficient.
Therefore, in this study, we propose PlaneHEC, a generalized hand-eye
calibration method that does not require complex models and can be accomplished
using only depth cameras, which achieves the optimal and fastest calibration
results using arbitrary planar surfaces like walls and tables. PlaneHEC
introduces hand-eye calibration equations based on planar constraints, which
makes it strongly interpretable and generalizable. PlaneHEC also uses a
comprehensive solution that starts with a closed-form solution and improves it
withiterative optimization, which greatly improves accuracy. We comprehensively
evaluated the performance of PlaneHEC in both simulated and real-world
environments and compared the results with other point-cloud-based calibration
methods, proving its superiority. Our approach achieves universal and fast
calibration with an innovative design of computational models, providing a
strong contribution to the development of multi-agent systems and embodied
intelligence.

</details>


### [63] [Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models](https://arxiv.org/abs/2507.19854)
*Anjali R. Menon,Rohit K. Sharma,Priya Singh,Chengyu Wang,Aurora M. Ferreira,Mateja Novak*

Main category: cs.RO

TL;DR: 论文提出了一种名为“思考、行动、学习”（T-A-L）的闭环框架，通过持续交互使机器人能够自主学习和优化策略，显著提升了动态环境中的适应性和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在机器人任务规划中多为开环系统，无法适应动态环境中的突发情况，因此需要一种闭环框架来增强其鲁棒性和适应性。

Method: T-A-L框架通过三个模块实现闭环：LLM分解任务为可执行计划（思考），机器人执行计划并收集反馈（行动），以及通过反馈进行自我反思和策略优化（学习）。

Result: 实验表明，T-A-L框架在复杂任务中成功率超过97%，平均仅需9次试验即可收敛，并能泛化到未见过的任务。

Conclusion: T-A-L框架为开发更鲁棒、自适应和真正自主的机器人代理提供了重要进展。

Abstract: The integration of Large Language Models (LLMs) into robotics has unlocked
unprecedented capabilities in high-level task planning. However, most current
systems operate in an open-loop fashion, where LLMs act as one-shot planners,
rendering them brittle and unable to adapt to unforeseen circumstances in
dynamic physical environments. To overcome this limitation, this paper
introduces the "Think, Act, Learn" (T-A-L) framework, a novel architecture that
enables an embodied agent to autonomously learn and refine its policies through
continuous interaction. Our framework establishes a closed-loop cycle where an
LLM first "thinks" by decomposing high-level commands into actionable plans.
The robot then "acts" by executing these plans while gathering rich, multimodal
sensory feedback. Critically, the "learn" module processes this feedback to
facilitate LLM-driven self-reflection, allowing the agent to perform causal
analysis on its failures and generate corrective strategies. These insights are
stored in an experiential memory to guide future planning cycles. We
demonstrate through extensive experiments in both simulation and the real world
that our T-A-L agent significantly outperforms baseline methods, including
open-loop LLMs, Behavioral Cloning, and traditional Reinforcement Learning. Our
framework achieves over a 97% success rate on complex, long-horizon tasks,
converges to a stable policy in an average of just 9 trials, and exhibits
remarkable generalization to unseen tasks. This work presents a significant
step towards developing more robust, adaptive, and truly autonomous robotic
agents.

</details>


### [64] [Homotopy-aware Multi-agent Navigation via Distributed Model Predictive Control](https://arxiv.org/abs/2507.19860)
*Haoze Dong,Meng Guo,Chengyi He,Zhongkui Li*

Main category: cs.RO

TL;DR: 提出了一种分布式轨迹规划框架，通过全局路径规划和局部轨迹优化解决多智能体在密集环境中的死锁问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体轨迹规划在密集环境中易发生死锁，尤其是在狭窄走廊中。

Method: 全局层面使用同伦感知的最优路径规划算法，局部层面采用模型预测控制优化轨迹，并结合在线重规划策略。

Result: 实验表明，该方法显著减少死锁，成功率从4%-13%提升至90%以上。

Conclusion: 结合时间和空间特性的全局路径规划能有效解决多智能体死锁问题。

Abstract: Multi-agent trajectory planning requires ensuring both safety and efficiency,
yet deadlocks remain a significant challenge, especially in obstacle-dense
environments. Such deadlocks frequently occur when multiple agents attempt to
traverse the same long and narrow corridor simultaneously. To address this, we
propose a novel distributed trajectory planning framework that bridges the gap
between global path and local trajectory cooperation. At the global level, a
homotopy-aware optimal path planning algorithm is proposed, which fully
leverages the topological structure of the environment. A reference path is
chosen from distinct homotopy classes by considering both its spatial and
temporal properties, leading to improved coordination among agents globally. At
the local level, a model predictive control-based trajectory optimization
method is used to generate dynamically feasible and collision-free
trajectories. Additionally, an online replanning strategy ensures its
adaptability to dynamic environments. Simulations and experiments validate the
effectiveness of our approach in mitigating deadlocks. Ablation studies
demonstrate that by incorporating time-aware homotopic properties into the
underlying global paths, our method can significantly reduce deadlocks and
improve the average success rate from 4%-13% to over 90% in randomly generated
dense scenarios.

</details>


### [65] [Bridging Simulation and Usability: A User-Friendly Framework for Scenario Generation in CARLA](https://arxiv.org/abs/2507.19883)
*Ahmed Abouelazm,Mohammad Mahmoud,Conrad Walter,Oleksandr Shchetsura,Erne Hussong,Helen Gremmelmaier,J. Marius Zöllner*

Main category: cs.RO

TL;DR: 提出了一种无需编程的交互式场景生成框架，用于自动驾驶系统的验证，通过图形界面降低使用门槛。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统验证需要大规模场景测试，但现有工具依赖编程知识，限制了非技术用户的使用。

Method: 开发了一个基于图形的交互式框架，支持手动和自动生成场景，并可集成深度学习生成方法。

Result: 框架能够高效生成多样化的测试场景，提升验证的可访问性和效率。

Conclusion: 该框架简化了场景生成流程，为研究人员、工程师和政策制定者提供了更便捷的验证工具。

Abstract: Autonomous driving promises safer roads, reduced congestion, and improved
mobility, yet validating these systems across diverse conditions remains a
major challenge. Real-world testing is expensive, time-consuming, and sometimes
unsafe, making large-scale validation impractical. In contrast, simulation
environments offer a scalable and cost-effective alternative for rigorous
verification and validation. A critical component of the validation process is
scenario generation, which involves designing and configuring traffic scenarios
to evaluate autonomous systems' responses to various events and uncertainties.
However, existing scenario generation tools often require programming
knowledge, limiting accessibility for non-technical users. To address this
limitation, we present an interactive, no-code framework for scenario
generation. Our framework features a graphical interface that enables users to
create, modify, save, load, and execute scenarios without needing coding
expertise or detailed simulation knowledge. Unlike script-based tools such as
Scenic or ScenarioRunner, our approach lowers the barrier to entry and supports
a broader user base. Central to our framework is a graph-based scenario
representation that facilitates structured management, supports both manual and
automated generation, and enables integration with deep learning-based scenario
and behavior generation methods. In automated mode, the framework can randomly
sample parameters such as actor types, behaviors, and environmental conditions,
allowing the generation of diverse and realistic test datasets. By simplifying
the scenario generation process, this framework supports more efficient testing
workflows and increases the accessibility of simulation-based validation for
researchers, engineers, and policymakers.

</details>


### [66] [High-Speed Event Vision-Based Tactile Roller Sensor for Large Surface Measurements](https://arxiv.org/abs/2507.19914)
*Akram Khairi,Hussain Sajwani,Abdallah Mohammad Alkilany,Laith AbuAssi,Mohamad Halwani,Islam Mohamed Zaid,Ahmed Awadalla,Dewald Swart,Abdulla Ayyad,Yahya Zweiri*

Main category: cs.RO

TL;DR: 提出了一种新型触觉传感器，结合神经形态相机和滚动机制，实现快速、连续、高分辨率的3D表面扫描。


<details>
  <summary>Details</summary>
Motivation: 现有触觉传感器在大面积扫描中存在速度慢、分辨率低的问题，需一种更高效的解决方案。

Method: 采用神经形态相机和滚动机制，结合事件驱动的多视角立体视觉方法进行3D重建，并使用贝叶斯融合策略提升精度。

Result: 扫描速度达0.5 m/s，平均绝对误差低于100微米，比现有方法快11倍；特征识别速度提升2.6倍。

Conclusion: 新型传感器显著提升了扫描速度和精度，适用于工业表面检测。

Abstract: Inspecting large-scale industrial surfaces like aircraft fuselages for
quality control requires capturing their precise 3D surface geometry at high
resolution. Vision-based tactile sensors (VBTSs) offer high local resolution
but require slow 'press-and-lift' measurements stitched for large areas.
Approaches with sliding or roller/belt VBTS designs provide measurements
continuity. However, they face significant challenges respectively: sliding
struggles with friction/wear and both approaches are speed-limited by
conventional camera frame rates and motion blur, making large-area scanning
time consuming. Thus, a rapid, continuous, high-resolution method is needed. We
introduce a novel tactile sensor integrating a neuromorphic camera in a rolling
mechanism to achieve this. Leveraging its high temporal resolution and
robustness to motion blur, our system uses a modified event-based multi-view
stereo approach for 3D reconstruction. We demonstrate state-of-the-art scanning
speeds up to 0.5 m/s, achieving Mean Absolute Error below 100 microns -- 11
times faster than prior continuous tactile sensing methods. A multi-reference
Bayesian fusion strategy enhances accuracy (reducing MAE by 25.2\% compared to
EMVS) and mitigates curvature errors. We also validate high-speed feature
recognition via Braille reading 2.6 times faster than previous approaches.

</details>


### [67] [Spatial Language Likelihood Grounding Network for Bayesian Fusion of Human-Robot Observations](https://arxiv.org/abs/2507.19947)
*Supawich Sitdhipol,Waritwong Sukprasongdee,Ekapol Chuangsuwanich,Rina Tse*

Main category: cs.RO

TL;DR: FP-LGN模型通过三阶段课程学习，将人类空间语言与地图特征关联，实现不确定性感知的信息融合，提升人机协作任务表现。


<details>
  <summary>Details</summary>
Motivation: 解决机器人感知局限，通过融合人类观察信息提升协作任务性能。

Method: 提出FP-LGN模型，学习地图特征与空间语言关系，通过三阶段课程学习估计不确定性。

Result: FP-LGN在NLL指标上媲美专家规则，鲁棒性更强，显著提升人机协作任务性能。

Conclusion: FP-LGN成功实现不确定性感知的信息融合，为人机协作任务提供有效支持。

Abstract: Fusing information from human observations can help robots overcome sensing
limitations in collaborative tasks. However, an uncertainty-aware fusion
framework requires a grounded likelihood representing the uncertainty of human
inputs. This paper presents a Feature Pyramid Likelihood Grounding Network
(FP-LGN) that grounds spatial language by learning relevant map image features
and their relationships with spatial relation semantics. The model is trained
as a probability estimator to capture aleatoric uncertainty in human language
using three-stage curriculum learning. Results showed that FP-LGN matched
expert-designed rules in mean Negative Log-Likelihood (NLL) and demonstrated
greater robustness with lower standard deviation. Collaborative sensing results
demonstrated that the grounded likelihood successfully enabled
uncertainty-aware fusion of heterogeneous human language observations and robot
sensor measurements, achieving significant improvements in human-robot
collaborative task performance.

</details>


### [68] [A roadmap for AI in robotics](https://arxiv.org/abs/2507.19975)
*Aude Billard,Alin Albu-Schaeffer,Michael Beetz,Wolfram Burgard,Peter Corke,Matei Ciocarlie,Ravinder Dahiya,Danica Kragic,Ken Goldberg,Yukie Nagai,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 本文评估了AI在机器人领域的成就，并提出了短期和中期的研究路线图，涵盖数据集更新、算法设计、人机协作及安全性等挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨如何利用AI技术解决机器人部署中的障碍，并反思哪些AI技术最适合机器人应用。

Method: 评估自1990年代以来AI在机器人领域的进展，并提出研究路线图，包括数据集、算法设计、人机协作和安全性等方面。

Result: 提出了机器人AI研究的短期和中期目标，强调数据集多样性、算法通用性、透明性和安全性。

Conclusion: 长期挑战在于设计具备终身学习能力、安全部署和可持续计算成本的机器人。

Abstract: AI technologies, including deep learning, large-language models have gone
from one breakthrough to the other. As a result, we are witnessing growing
excitement in robotics at the prospect of leveraging the potential of AI to
tackle some of the outstanding barriers to the full deployment of robots in our
daily lives. However, action and sensing in the physical world pose greater and
different challenges than analysing data in isolation. As the development and
application of AI in robotic products advances, it is important to reflect on
which technologies, among the vast array of network architectures and learning
models now available in the AI field, are most likely to be successfully
applied to robots; how they can be adapted to specific robot designs, tasks,
environments; which challenges must be overcome. This article offers an
assessment of what AI for robotics has achieved since the 1990s and proposes a
short- and medium-term research roadmap listing challenges and promises. These
range from keeping up-to-date large datasets, representatives of a diversity of
tasks robots may have to perform, and of environments they may encounter, to
designing AI algorithms tailored specifically to robotics problems but generic
enough to apply to a wide range of applications and transfer easily to a
variety of robotic platforms. For robots to collaborate effectively with
humans, they must predict human behavior without relying on bias-based
profiling. Explainability and transparency in AI-driven robot control are not
optional but essential for building trust, preventing misuse, and attributing
responsibility in accidents. We close on what we view as the primary long-term
challenges, that is, to design robots capable of lifelong learning, while
guaranteeing safe deployment and usage, and sustainable computational costs.

</details>


### [69] [CLASP: General-Purpose Clothes Manipulation with Semantic Keypoints](https://arxiv.org/abs/2507.19983)
*Yuhong Deng,Chao Tang,Cunjun Yu,Linfeng Li,David Hsu*

Main category: cs.RO

TL;DR: CLASP提出了一种基于语义关键点的通用衣物操作方法，适用于多种衣物类型和任务，通过视觉语言模型和预构建技能库实现高效操作。


<details>
  <summary>Details</summary>
Motivation: 解决现有衣物操作方法局限于特定任务和衣物类型的问题，利用语义关键点实现通用性。

Method: 使用语义关键点作为中间表示，结合视觉语言模型进行任务规划，并通过预构建技能库执行操作。

Result: 在仿真和真实机器人实验中，CLASP在多种任务和衣物类型上表现优于现有方法。

Conclusion: CLASP通过语义关键点实现了通用衣物操作，展示了强泛化能力和实际应用潜力。

Abstract: Clothes manipulation, such as folding or hanging, is a critical capability
for home service robots. Despite recent advances, most existing methods remain
limited to specific tasks and clothes types, due to the complex,
high-dimensional geometry of clothes. This paper presents CLothes mAnipulation
with Semantic keyPoints (CLASP), which aims at general-purpose clothes
manipulation over different clothes types, T-shirts, shorts, skirts, long
dresses, ... , as well as different tasks, folding, flattening, hanging, ... .
The core idea of CLASP is semantic keypoints -- e.g., ''left sleeve'', ''right
shoulder'', etc. -- a sparse spatial-semantic representation that is salient
for both perception and action. Semantic keypoints of clothes can be reliably
extracted from RGB-D images and provide an effective intermediate
representation of clothes manipulation policies. CLASP uses semantic keypoints
to bridge high-level task planning and low-level action execution. At the high
level, it exploits vision language models (VLMs) to predict task plans over the
semantic keypoints. At the low level, it executes the plans with the help of a
simple pre-built manipulation skill library. Extensive simulation experiments
show that CLASP outperforms state-of-the-art baseline methods on multiple tasks
across diverse clothes types, demonstrating strong performance and
generalization. Further experiments with a Franka dual-arm system on four
distinct tasks -- folding, flattening, hanging, and placing -- confirm CLASP's
performance on a real robot.

</details>


### [70] [Robot Excavation and Manipulation of Geometrically Cohesive Granular Media](https://arxiv.org/abs/2507.19999)
*Laura Treers,Daniel Soto,Joonha Hwang,Michael A. D. Goodisman,Daniel I. Goldman*

Main category: cs.RO

TL;DR: 论文探讨了利用机器人群体操纵颗粒材料构建非确定性结构的方法，并通过实验验证了材料初始条件对机器人性能的影响。


<details>
  <summary>Details</summary>
Motivation: 传统建筑依赖预设蓝图和材料，而研究探索了通过颗粒材料的自组织特性实现非确定性结构构建的可能性。

Method: 开发了一种机器人物理模型，用于与几何粘性颗粒介质（U形颗粒）交互，并通过环境信号自主协调挖掘、运输和沉积材料。

Result: 实验发现，材料初始压缩状态对机器人运输质量影响显著（高达75%变化），揭示了材料特性（如堆积和纠缠）在挖掘和构建中的功能作用。

Conclusion: 研究为理解机器人与纠缠材料的交互机制提供了新视角，并指出了未来研究方向。

Abstract: Construction throughout history typically assumes that its blueprints and
building blocks are pre-determined. However, recent work suggests that
alternative approaches can enable new paradigms for structure formation.
Aleatory architectures, or those which rely on the properties of their granular
building blocks rather than pre-planned design or computation, have thus far
relied on human intervention for their creation. We imagine that robotic swarms
could be valuable to create such aleatory structures by manipulating and
forming structures from entangled granular materials. To discover principles by
which robotic systems can effectively manipulate soft matter, we develop a
robophysical model for interaction with geometrically cohesive granular media
composed of u-shape particles. This robotic platform uses environmental signals
to autonomously coordinate excavation, transport, and deposition of material.
We test the effect of substrate initial conditions by characterizing robot
performance in two different material compaction states and observe as much as
a 75% change in transported mass depending on initial substrate compressive
loading. These discrepancies suggest the functional role that material
properties such as packing and cohesion/entanglement play in excavation and
construction. To better understand these material properties, we develop an
apparatus for tensile testing of the geometrically cohesive substrates, which
reveals how entangled material strength responds strongly to initial
compressive loading. These results explain the variation observed in robotic
performance and point to future directions for better understanding robotic
interaction mechanics with entangled materials.

</details>


### [71] [SuperMag: Vision-based Tactile Data Guided High-resolution Tactile Shape Reconstruction for Magnetic Tactile Sensors](https://arxiv.org/abs/2507.20002)
*Peiyao Hou,Danning Sun,Meng Wang,Yuzhe Huang,Zeyu Zhang,Hangxin Liu,Wanlin Li,Ziyuan Jiao*

Main category: cs.RO

TL;DR: SuperMag利用高分辨率视觉触觉传感器数据监督磁触觉传感器的超分辨率重建，提升其空间分辨率。


<details>
  <summary>Details</summary>
Motivation: 磁触觉传感器（MBTS）设计紧凑且高频运行，但稀疏的触觉阵列限制了其空间分辨率。

Method: 通过同步收集高分辨率视觉触觉传感器（VBTS）和MBTS数据，采用条件变分自编码器从低分辨率MBTS输入推断高分辨率形状。

Result: MBTS采样频率达125 Hz，形状重建推理时间低于2.5 ms，显著提升触觉感知能力。

Conclusion: 跨模态协同为MBTS解锁了高精度机器人任务的新潜力。

Abstract: Magnetic-based tactile sensors (MBTS) combine the advantages of compact
design and high-frequency operation but suffer from limited spatial resolution
due to their sparse taxel arrays. This paper proposes SuperMag, a tactile shape
reconstruction method that addresses this limitation by leveraging
high-resolution vision-based tactile sensor (VBTS) data to supervise MBTS
super-resolution. Co-designed, open-source VBTS and MBTS with identical contact
modules enable synchronized data collection of high-resolution shapes and
magnetic signals via a symmetric calibration setup. We frame tactile shape
reconstruction as a conditional generative problem, employing a conditional
variational auto-encoder to infer high-resolution shapes from low-resolution
MBTS inputs. The MBTS achieves a sampling frequency of 125 Hz, whereas the
shape reconstruction sustains an inference time within 2.5 ms. This
cross-modality synergy advances tactile perception of the MBTS, potentially
unlocking its new capabilities in high-precision robotic tasks.

</details>


### [72] [When Engineering Outruns Intelligence: A Re-evaluation of Instruction-Guided Navigation](https://arxiv.org/abs/2507.20021)
*Matin Aghaei,Mohammad Ali Alomrani,Yingxue Zhang,Mahdi Biparva*

Main category: cs.RO

TL;DR: 研究发现，在目标导航任务中，几何启发式方法（DWFE）比大型语言模型（LLM）更能提升性能，而轻量级语言先验（SHF）进一步优化了路径规划。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLM）在目标导航任务中是否真正提升了规划能力，还是几何启发式方法更关键。

Method: 通过移除InstructNav的动态导航提示、开放词汇检测器和显著性图，替换为简单的几何启发式方法（DWFE），并加入轻量级语言先验（SHF）进行对比实验。

Result: DWFE将成功率从58.0%提升至61.1%，SPL从20.9%提升至36.0%；SHF进一步增加2%成功率和0.9% SPL，并缩短路径。

Conclusion: 几何启发式方法而非LLM驱动了性能提升，未来需结合度量感知提示或离线语义图才能体现LLM的智能贡献。

Abstract: Large language models (LLMs) are often credited with recent leaps in
ObjectGoal Navigation, yet the extent to which they improve planning remains
unclear. We revisit this question on the HM3D-v1 validation split. First, we
strip InstructNav of its Dynamic Chain-of-Navigation prompt, open-vocabulary
GLEE detector and Intuition saliency map, and replace them with a simple
Distance-Weighted Frontier Explorer (DWFE). This geometry-only heuristic raises
Success from 58.0% to 61.1% and lifts SPL from 20.9% to 36.0% over 2 000
validation episodes, outperforming all previous training-free baselines.
Second, we add a lightweight language prior (SHF); on a 200-episode subset this
yields a further +2% Success and +0.9% SPL while shortening paths by five steps
on average. Qualitative trajectories confirm the trend: InstructNav back-tracks
and times-out, DWFE reaches the goal after a few islands, and SHF follows an
almost straight route. Our results indicate that frontier geometry, not
emergent LLM reasoning, drives most reported gains, and suggest that
metric-aware prompts or offline semantic graphs are necessary before
attributing navigation success to "LLM intelligence."

</details>


### [73] [Digital and Robotic Twinning for Validation of Proximity Operations and Formation Flying](https://arxiv.org/abs/2507.20034)
*Aviad Golan,Gregory Zin,Zahra Ahmed,Emily Bates,Toby Bell,Pol Francesch Huc,Samuel Y. W. Low,Juergen Bosse,Simone D'Amico*

Main category: cs.RO

TL;DR: 论文提出了一种统一的数字和机器人孪生框架，用于验证多模态GNC系统，通过仿真和实际测试结合，验证了其在低地球轨道RPO任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 由于太空环境的复杂性，验证GNC系统的性能具有挑战性，需要一种能够连接仿真和实际行为的V&V流程。

Method: 提出了一种端到端的数字和机器人孪生框架，结合了软件和硬件在环测试，使用了三个测试平台（GRAND、TRON和OS）来验证RF和视觉导航技术。

Result: 数字和机器人孪生结果一致，验证了该框架在GNC系统评估和验证中的可靠性。

Conclusion: 该混合孪生框架为GNC系统的真实评估和验证提供了可靠的方法。

Abstract: In spacecraft Rendezvous, Proximity Operations (RPO), and Formation Flying
(FF), the Guidance Navigation and Control (GNC) system is safety-critical and
must meet strict performance requirements. However, validating such systems is
challenging due to the complexity of the space environment, necessitating a
verification and validation (V&V) process that bridges simulation and
real-world behavior. The key contribution of this paper is a unified,
end-to-end digital and robotic twinning framework that enables software- and
hardware-in-the-loop testing for multi-modal GNC systems. The robotic twin
includes three testbeds at Stanford's Space Rendezvous Laboratory (SLAB): the
GNSS and Radiofrequency Autonomous Navigation Testbed for Distributed Space
Systems (GRAND) to validate RF-based navigation techniques, and the Testbed for
Rendezvous and Optical Navigation (TRON) and Optical Stimulator (OS) to
validate vision-based methods. The test article for this work is an integrated
multi-modal GNC software stack for RPO and FF developed at SLAB. This paper
introduces the hybrid framework and summarizes calibration and error
characterization for the robotic twin. Then, the GNC stack's performance and
robustness is characterized using the integrated digital and robotic twinning
pipeline for a full-range RPO mission scenario in Low-Earth Orbit (LEO). The
results shown in the paper demonstrate consistency between digital and robotic
twins, validating the hybrid twinning pipeline as a reliable framework for
realistic assessment and verification of GNC systems.

</details>


### [74] [A real-time full-chain wearable sensor-based musculoskeletal simulation: an OpenSim-ROS Integration](https://arxiv.org/abs/2507.20049)
*Frederico Belmonte Klein,Zhaoyuan Wan,Huawei Wang,Ruoli Wang*

Main category: cs.RO

TL;DR: 提出了一种基于OpenSimRT、ROS和可穿戴传感器的实时集成框架，用于解决肌骨建模与仿真中的高成本、复杂性和软件集成问题。


<details>
  <summary>Details</summary>
Motivation: 当前肌骨建模与仿真技术因传感器成本高、实验室设置复杂、计算量大以及软件工具缺乏集成而应用受限。

Method: 结合OpenSimRT、ROS和可穿戴传感器，开发实时集成框架，验证其用于描述上下肢逆运动学和踝关节逆动力学的能力。

Result: 框架能有效描述逆运动学，并估计踝关节逆动力学及下肢肌肉激活状态，适用于日常活动。

Conclusion: 该框架为复杂实时肌骨分析系统奠定基础，有望推动康复、机器人和外骨骼设计技术的发展。

Abstract: Musculoskeletal modeling and simulations enable the accurate description and
analysis of the movement of biological systems with applications such as
rehabilitation assessment, prosthesis, and exoskeleton design. However, the
widespread usage of these techniques is limited by costly sensors,
laboratory-based setups, computationally demanding processes, and the use of
diverse software tools that often lack seamless integration. In this work, we
address these limitations by proposing an integrated, real-time framework for
musculoskeletal modeling and simulations that leverages OpenSimRT, the robotics
operating system (ROS), and wearable sensors. As a proof-of-concept, we
demonstrate that this framework can reasonably well describe inverse kinematics
of both lower and upper body using either inertial measurement units or
fiducial markers. Additionally, we show that it can effectively estimate
inverse dynamics of the ankle joint and muscle activations of major lower limb
muscles during daily activities, including walking, squatting and sit to stand,
stand to sit when combined with pressure insoles. We believe this work lays the
groundwork for further studies with more complex real-time and wearable
sensor-based human movement analysis systems and holds potential to advance
technologies in rehabilitation, robotics and exoskeleton designs.

</details>


### [75] [Humanoid Occupancy: Enabling A Generalized Multimodal Occupancy Perception System on Humanoid Robots](https://arxiv.org/abs/2507.20217)
*Wei Cui,Haoyu Wang,Wenkang Qin,Yijie Guo,Gang Han,Wen Zhao,Jiahang Cao,Zhang Zhang,Jiaru Zhong,Jingkai Sun,Pihai Sun,Shuai Shi,Botuo Jiang,Jiahao Ma,Jiaxu Wang,Hao Cheng,Zhichao Liu,Yang Wang,Zheng Zhu,Guan Huang,Jian Tang,Qiang Zhang*

Main category: cs.RO

TL;DR: Humanoid Occupancy是一个多模态占用感知系统，结合硬件和软件，为仿人机器人提供全面的环境理解。


<details>
  <summary>Details</summary>
Motivation: 仿人机器人需要丰富的语义和3D几何信息以支持环境理解，而现有的占用表示方法被认为是最适合的。

Method: 系统采用多模态融合技术和网格占用输出，解决运动干扰和遮挡问题，并开发了首个全景占用数据集。

Result: Humanoid Occupancy实现了有效的环境感知，为仿人机器人在复杂场景中的部署奠定了基础。

Conclusion: 该系统为仿人机器人的通用视觉模块标准化提供了技术基础，推动了其在现实场景中的广泛应用。

Abstract: Humanoid robot technology is advancing rapidly, with manufacturers
introducing diverse heterogeneous visual perception modules tailored to
specific scenarios. Among various perception paradigms, occupancy-based
representation has become widely recognized as particularly suitable for
humanoid robots, as it provides both rich semantic and 3D geometric information
essential for comprehensive environmental understanding. In this work, we
present Humanoid Occupancy, a generalized multimodal occupancy perception
system that integrates hardware and software components, data acquisition
devices, and a dedicated annotation pipeline. Our framework employs advanced
multi-modal fusion techniques to generate grid-based occupancy outputs encoding
both occupancy status and semantic labels, thereby enabling holistic
environmental understanding for downstream tasks such as task planning and
navigation. To address the unique challenges of humanoid robots, we overcome
issues such as kinematic interference and occlusion, and establish an effective
sensor layout strategy. Furthermore, we have developed the first panoramic
occupancy dataset specifically for humanoid robots, offering a valuable
benchmark and resource for future research and development in this domain. The
network architecture incorporates multi-modal feature fusion and temporal
information integration to ensure robust perception. Overall, Humanoid
Occupancy delivers effective environmental perception for humanoid robots and
establishes a technical foundation for standardizing universal visual modules,
paving the way for the widespread deployment of humanoid robots in complex
real-world scenarios.

</details>


### [76] [Tactile-Guided Robotic Ultrasound: Mapping Preplanned Scan Paths for Intercostal Imaging](https://arxiv.org/abs/2507.20282)
*Yifan Zhang,Dianye Huang,Nassir Navab,Zhongliang Jiang*

Main category: cs.RO

TL;DR: 论文提出了一种基于触觉信号的机器人超声扫描路径生成方法，用于解决肋间成像中的挑战，并通过实验验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人超声系统在肋间成像中因缺乏有效扫描路径生成方法而受限的问题。

Method: 利用触觉信号提取肋骨表面点云，通过稀疏点云插值和配准技术生成扫描路径，并引入自动倾斜角度调整方法。

Result: 扫描路径映射的平均最近邻距离和Hausdorff距离误差分别为3.41 mm和3.65 mm，重建对象的误差为0.69 mm和2.2 mm。

Conclusion: 该方法在肋间成像中表现出高效性和准确性，为机器人超声系统提供了新的解决方案。

Abstract: Medical ultrasound (US) imaging is widely used in clinical examinations due
to its portability, real-time capability, and radiation-free nature. To address
inter- and intra-operator variability, robotic ultrasound systems have gained
increasing attention. However, their application in challenging intercostal
imaging remains limited due to the lack of an effective scan path generation
method within the constrained acoustic window. To overcome this challenge, we
explore the potential of tactile cues for characterizing subcutaneous rib
structures as an alternative signal for ultrasound segmentation-free bone
surface point cloud extraction. Compared to 2D US images, 1D tactile-related
signals offer higher processing efficiency and are less susceptible to acoustic
noise and artifacts. By leveraging robotic tracking data, a sparse tactile
point cloud is generated through a few scans along the rib, mimicking human
palpation. To robustly map the scanning trajectory into the intercostal space,
the sparse tactile bone location point cloud is first interpolated to form a
denser representation. This refined point cloud is then registered to an
image-based dense bone surface point cloud, enabling accurate scan path mapping
for individual patients. Additionally, to ensure full coverage of the object of
interest, we introduce an automated tilt angle adjustment method to visualize
structures beneath the bone. To validate the proposed method, we conducted
comprehensive experiments on four distinct phantoms. The final scanning
waypoint mapping achieved Mean Nearest Neighbor Distance (MNND) and Hausdorff
distance (HD) errors of 3.41 mm and 3.65 mm, respectively, while the
reconstructed object beneath the bone had errors of 0.69 mm and 2.2 mm compared
to the CT ground truth.

</details>


### [77] [Decentralized Uncertainty-Aware Multi-Agent Collision Avoidance With Model Predictive Path Integral](https://arxiv.org/abs/2507.20293)
*Stepan Dergachev,Konstantin Yakovlev*

Main category: cs.RO

TL;DR: 提出一种结合MPPI和概率ORCA的新方法，用于多智能体导航，确保安全高效。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体导航中的不确定性和碰撞避免问题，适应运动约束和噪声。

Method: 将MPPI与概率ORCA结合，通过SOCP约束确保安全性。

Result: 在密集环境中表现优于ORCA-DD和B-UAVC，成功率高。

Conclusion: 方法实用且高效，适用于实际机器人平台。

Abstract: Decentralized multi-agent navigation under uncertainty is a complex task that
arises in numerous robotic applications. It requires collision avoidance
strategies that account for both kinematic constraints, sensing and action
execution noise. In this paper, we propose a novel approach that integrates the
Model Predictive Path Integral (MPPI) with a probabilistic adaptation of
Optimal Reciprocal Collision Avoidance. Our method ensures safe and efficient
multi-agent navigation by incorporating probabilistic safety constraints
directly into the MPPI sampling process via a Second-Order Cone Programming
formulation. This approach enables agents to operate independently using local
noisy observations while maintaining safety guarantees. We validate our
algorithm through extensive simulations with differential-drive robots and
benchmark it against state-of-the-art methods, including ORCA-DD and B-UAVC.
Results demonstrate that our approach outperforms them while achieving high
success rates, even in densely populated environments. Additionally, validation
in the Gazebo simulator confirms its practical applicability to robotic
platforms.

</details>


### [78] [Advancing Shared and Multi-Agent Autonomy in Underwater Missions: Integrating Knowledge Graphs and Retrieval-Augmented Generation](https://arxiv.org/abs/2507.20370)
*Michele Grimaldi,Carlo Cernicchiaro,Sebastian Realpe Rua,Alaaeddine El-Masri-El-Chaarani,Markus Buchholz,Loizos Michael,Pere Ridao Rodriguez,Ignacio Carlucho,Yvan R. Petillot*

Main category: cs.RO

TL;DR: 论文探讨了水下机器人平台在复杂环境中的自主决策问题，通过知识图谱和RAG技术实现多智能体自主与共享自主，显著提升任务完成率和决策质量。


<details>
  <summary>Details</summary>
Motivation: 水下环境的复杂性和动态性对机器人自主性提出高要求，需确保操作者信任与监督，因此研究如何通过知识表示与推理技术提升机器人适应能力。

Method: 结合知识图谱和检索增强生成（RAG）系统，利用大语言模型（LLM）进行多智能体自主决策，并支持人机交互。

Result: 实验显示，该方法实现了100%的任务验证和行为完整性，而缺少结构化知识会导致LLM产生幻觉，影响决策质量。

Conclusion: 知识图谱和RAG技术能有效提升水下机器人的自主性和决策可靠性，支持多智能体与人类协同工作。

Abstract: Robotic platforms have become essential for marine operations by providing
regular and continuous access to offshore assets, such as underwater
infrastructure inspection, environmental monitoring, and resource exploration.
However, the complex and dynamic nature of underwater environments,
characterized by limited visibility, unpredictable currents, and communication
constraints, presents significant challenges that demand advanced autonomy
while ensuring operator trust and oversight. Central to addressing these
challenges are knowledge representation and reasoning techniques, particularly
knowledge graphs and retrieval-augmented generation (RAG) systems, that enable
robots to efficiently structure, retrieve, and interpret complex environmental
data. These capabilities empower robotic agents to reason, adapt, and respond
effectively to changing conditions. The primary goal of this work is to
demonstrate both multi-agent autonomy and shared autonomy, where multiple
robotic agents operate independently while remaining connected to a human
supervisor. We show how a RAG-powered large language model, augmented with
knowledge graph data and domain taxonomy, enables autonomous multi-agent
decision-making and facilitates seamless human-robot interaction, resulting in
100\% mission validation and behavior completeness. Finally, ablation studies
reveal that without structured knowledge from the graph and/or taxonomy, the
LLM is prone to hallucinations, which can compromise decision quality.

</details>


### [79] [Bipedalism for Quadrupedal Robots: Versatile Loco-Manipulation through Risk-Adaptive Reinforcement Learning](https://arxiv.org/abs/2507.20382)
*Yuyou Zhang,Radu Corcodel,Ding Zhao*

Main category: cs.RO

TL;DR: 提出了一种双足行走的四足机器人方法，通过释放前腿实现多功能交互，并采用风险自适应的强化学习框架，平衡稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人使用腿作为操纵器时影响运动能力的问题，同时避免安装额外机械臂的复杂性。

Method: 引入双足行走模式，采用基于风险自适应的分布强化学习框架，动态调整风险偏好以应对不稳定任务。

Result: 仿真和实物实验（Unitree Go2机器人）验证了方法的优越性，实现了推车、探测障碍物和运输负载等任务。

Conclusion: 该方法在多功能交互和动态稳定性方面表现出色，适用于复杂环境和外部干扰下的任务。

Abstract: Loco-manipulation of quadrupedal robots has broadened robotic applications,
but using legs as manipulators often compromises locomotion, while mounting
arms complicates the system. To mitigate this issue, we introduce bipedalism
for quadrupedal robots, thus freeing the front legs for versatile interactions
with the environment. We propose a risk-adaptive distributional Reinforcement
Learning (RL) framework designed for quadrupedal robots walking on their hind
legs, balancing worst-case conservativeness with optimal performance in this
inherently unstable task. During training, the adaptive risk preference is
dynamically adjusted based on the uncertainty of the return, measured by the
coefficient of variation of the estimated return distribution. Extensive
experiments in simulation show our method's superior performance over
baselines. Real-world deployment on a Unitree Go2 robot further demonstrates
the versatility of our policy, enabling tasks like cart pushing, obstacle
probing, and payload transport, while showcasing robustness against challenging
dynamics and external disturbances.

</details>


### [80] [Model-Structured Neural Networks to Control the Steering Dynamics of Autonomous Race Cars](https://arxiv.org/abs/2507.20427)
*Mattia Piccinini,Aniello Mungiello,Georg Jank,Gastone Pietro Rosati Papini,Francesco Biral,Johannes Betz*

Main category: cs.RO

TL;DR: 本文提出了一种名为MS-NN-steer的新型模型结构神经网络，用于车辆转向控制，通过将非线性车辆动力学的先验知识融入神经网络架构，解决了自动驾驶赛车中安全性和鲁棒性的挑战。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶赛车作为加速自动驾驶运动规划和控制方法发展的安全环境，其安全性和鲁棒性要求对决策算法有深入理解。然而，基于神经网络的深度学习模型的黑盒特性难以满足这一需求。

Method: 提出MS-NN-steer，一种将非线性车辆动力学先验知识融入神经网络架构的模型结构神经网络，用于车辆转向控制。

Result: 在阿布扎比自动驾驶赛车联盟（A2RL）竞赛的真实数据验证中，MS-NN-steer在小训练数据集下表现出更高的准确性和泛化能力，且对权重初始化不敏感，性能优于A2RL冠军团队的转向控制器。

Conclusion: MS-NN-steer在自动驾驶赛车中表现出色，结合先验知识的神经网络架构提升了控制器的性能和可靠性，为自动驾驶赛车领域提供了有效的解决方案。

Abstract: Autonomous racing has gained increasing attention in recent years, as a safe
environment to accelerate the development of motion planning and control
methods for autonomous driving. Deep learning models, predominantly based on
neural networks (NNs), have demonstrated significant potential in modeling the
vehicle dynamics and in performing various tasks in autonomous driving.
However, their black-box nature is critical in the context of autonomous
racing, where safety and robustness demand a thorough understanding of the
decision-making algorithms. To address this challenge, this paper proposes
MS-NN-steer, a new Model-Structured Neural Network for vehicle steering
control, integrating the prior knowledge of the nonlinear vehicle dynamics into
the neural architecture. The proposed controller is validated using real-world
data from the Abu Dhabi Autonomous Racing League (A2RL) competition, with
full-scale autonomous race cars. In comparison with general-purpose NNs,
MS-NN-steer is shown to achieve better accuracy and generalization with small
training datasets, while being less sensitive to the weights' initialization.
Also, MS-NN-steer outperforms the steering controller used by the A2RL winning
team. Our implementation is available open-source in a GitHub repository.

</details>


### [81] [Learning Physical Interaction Skills from Human Demonstrations](https://arxiv.org/abs/2507.20445)
*Tianyu Li,Hengbo Ma,Sehoon Ha,Kwonjoon Lee*

Main category: cs.RO

TL;DR: 提出了一种名为BuddyImitation的框架，通过Embedded Interaction Graph（EIG）从人类演示中学习全身交互行为，适用于形态各异的智能体。


<details>
  <summary>Details</summary>
Motivation: 解决智能体在形态与演示者差异显著时学习物理交互技能的挑战，克服现有方法依赖手工目标或形态相似性的限制。

Method: 提取交互动态的紧凑可迁移表示EIG，作为模仿目标训练控制策略，生成语义明确且物理可行的动作。

Result: 在多种智能体和交互场景（如格斗、握手、猜拳、跳舞）中验证了框架的有效性。

Conclusion: 为形态差异大的智能体之间的协调行为提供了一种有前景的学习路径。

Abstract: Learning physical interaction skills, such as dancing, handshaking, or
sparring, remains a fundamental challenge for agents operating in human
environments, particularly when the agent's morphology differs significantly
from that of the demonstrator. Existing approaches often rely on handcrafted
objectives or morphological similarity, limiting their capacity for
generalization. Here, we introduce a framework that enables agents with diverse
embodiments to learn wholebbody interaction behaviors directly from human
demonstrations. The framework extracts a compact, transferable representation
of interaction dynamics, called the Embedded Interaction Graph (EIG), which
captures key spatiotemporal relationships between the interacting agents. This
graph is then used as an imitation objective to train control policies in
physics-based simulations, allowing the agent to generate motions that are both
semantically meaningful and physically feasible. We demonstrate BuddyImitation
on multiple agents, such as humans, quadrupedal robots with manipulators, or
mobile manipulators and various interaction scenarios, including sparring,
handshaking, rock-paper-scissors, or dancing. Our results demonstrate a
promising path toward coordinated behaviors across morphologically distinct
characters via cross embodiment interaction learning.

</details>


### [82] [LLMs-guided adaptive compensator: Bringing Adaptivity to Automatic Control Systems with Large Language Models](https://arxiv.org/abs/2507.20509)
*Zhongchao Zhou,Yuxi Lu,Yaonan Zhu,Yifan Zhao,Bin He,Liang He,Wenwen Yu,Yusuke Iwasawa*

Main category: cs.RO

TL;DR: 本文提出了一种基于大语言模型（LLM）的自适应补偿器框架，用于机器人控制，避免了从头设计控制器的复杂性。实验表明，该方法优于传统自适应控制器，并显著降低了推理复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于LLM在机器人高级任务中的应用，而在反馈控制器设计方面研究较少且局限于简化系统。本文旨在探索LLM在自适应控制领域的应用潜力。

Method: 受模型参考自适应控制（MRAC）启发，提出LLM引导的自适应补偿器框架，利用未知系统与参考系统的差异设计补偿器，实现响应对齐。

Result: 实验表明，LLM引导的自适应补偿器在软体和类人机器人上表现优于传统方法，且推理复杂度更低。Lyapunov分析验证了其结构化和泛化能力。

Conclusion: 本研究为LLM在自动控制领域的应用开辟了新方向，具有更强的部署性和实用性。

Abstract: With rapid advances in code generation, reasoning, and problem-solving, Large
Language Models (LLMs) are increasingly applied in robotics. Most existing work
focuses on high-level tasks such as task decomposition. A few studies have
explored the use of LLMs in feedback controller design; however, these efforts
are restricted to overly simplified systems, fixed-structure gain tuning, and
lack real-world validation. To further investigate LLMs in automatic control,
this work targets a key subfield: adaptive control. Inspired by the framework
of model reference adaptive control (MRAC), we propose an LLM-guided adaptive
compensator framework that avoids designing controllers from scratch. Instead,
the LLMs are prompted using the discrepancies between an unknown system and a
reference system to design a compensator that aligns the response of the
unknown system with that of the reference, thereby achieving adaptivity.
Experiments evaluate five methods: LLM-guided adaptive compensator, LLM-guided
adaptive controller, indirect adaptive control, learning-based adaptive
control, and MRAC, on soft and humanoid robots in both simulated and real-world
environments. Results show that the LLM-guided adaptive compensator outperforms
traditional adaptive controllers and significantly reduces reasoning complexity
compared to the LLM-guided adaptive controller. The Lyapunov-based analysis and
reasoning-path inspection demonstrate that the LLM-guided adaptive compensator
enables a more structured design process by transforming mathematical
derivation into a reasoning task, while exhibiting strong generalizability,
adaptability, and robustness. This study opens a new direction for applying
LLMs in the field of automatic control, offering greater deployability and
practicality compared to vision-language models.

</details>


### [83] [Large-Scale LiDAR-Inertial Dataset for Degradation-Robust High-Precision Mapping](https://arxiv.org/abs/2507.20516)
*Xiaofeng Jin,Ningbo Bu,Shijie Wang,Jianfei Ge,Jiangjian Xiao,Matteo Matteucci*

Main category: cs.RO

TL;DR: 本文介绍了一个大规模、高精度的LiDAR-惯性里程计（LIO）数据集，旨在解决现有研究中LIO系统在复杂现实场景中验证不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究中对LIO系统在复杂现实场景中的验证不足，缺乏全面的基准数据集。

Method: 使用自定义背包式平台，配备多光束LiDAR、工业级IMU和RTK-GNSS模块，在四种多样化的现实环境中收集数据，覆盖面积从60,000到750,000平方米。通过SLAM优化与RTK-GNSS锚定融合生成高精度地面真实值，并通过倾斜摄影测量和RTK-GNSS验证轨迹精度。

Result: 数据集包含长轨迹、复杂场景和高精度地面真实值，为LIO系统在实际高精度测绘场景中的泛化能力提供了全面基准。

Conclusion: 该数据集填补了LIO系统验证的空白，为实际应用中的高精度测绘提供了重要支持。

Abstract: This paper introduces a large-scale, high-precision LiDAR-Inertial Odometry
(LIO) dataset, aiming to address the insufficient validation of LIO systems in
complex real-world scenarios in existing research. The dataset covers four
diverse real-world environments spanning 60,000 to 750,000 square meters,
collected using a custom backpack-mounted platform equipped with multi-beam
LiDAR, an industrial-grade IMU, and RTK-GNSS modules. The dataset includes long
trajectories, complex scenes, and high-precision ground truth, generated by
fusing SLAM-based optimization with RTK-GNSS anchoring, and validated for
trajectory accuracy through the integration of oblique photogrammetry and
RTK-GNSS. This dataset provides a comprehensive benchmark for evaluating the
generalization ability of LIO systems in practical high-precision mapping
scenarios.

</details>


### [84] [Uni-Mapper: Unified Mapping Framework for Multi-modal LiDARs in Complex and Dynamic Environments](https://arxiv.org/abs/2507.20538)
*Gilhwan Kang,Hogyun Kim,Byunghee Choi,Seokhwan Jeong,Young-Sik Shin,Younggun Cho*

Main category: cs.RO

TL;DR: Uni-Mapper是一个动态感知的3D点云地图合并框架，用于多模态LiDAR系统，解决了动态环境和传感器差异带来的地图统一挑战。


<details>
  <summary>Details</summary>
Motivation: 多机器人协作和多会话操作需要统一的地图，但动态环境和不同LiDAR类型导致点云分布和场景一致性差异，影响地图对齐的准确性。

Method: Uni-Mapper包括动态对象移除、动态感知闭环和多模态LiDAR地图合并模块，采用体素自由空间哈希图和全局描述符优化地图对齐。

Result: 在动态环境和异构LiDAR数据集上表现优异，实现了跨传感器模态的闭环检测和准确的多地图对齐。

Conclusion: Uni-Mapper在动态环境和多模态LiDAR系统中表现出色，为地图统一提供了可靠解决方案。

Abstract: The unification of disparate maps is crucial for enabling scalable robot
operation across multiple sessions and collaborative multi-robot scenarios.
However, achieving a unified map robust to sensor modalities and dynamic
environments remains a challenging problem. Variations in LiDAR types and
dynamic elements lead to differences in point cloud distribution and scene
consistency, hindering reliable descriptor generation and loop closure
detection essential for accurate map alignment. To address these challenges,
this paper presents Uni-Mapper, a dynamic-aware 3D point cloud map merging
framework for multi-modal LiDAR systems. It comprises dynamic object removal,
dynamic-aware loop closure, and multi-modal LiDAR map merging modules. A
voxel-wise free space hash map is built in a coarse-to-fine manner to identify
and reject dynamic objects via temporal occupancy inconsistencies. The removal
module is integrated with a LiDAR global descriptor, which encodes preserved
static local features to ensure robust place recognition in dynamic
environments. In the final stage, multiple pose graph optimizations are
conducted for both intra-session and inter-map loop closures. We adopt a
centralized anchor-node strategy to mitigate intra-session drift errors during
map merging. In the final stage, centralized anchor-node-based pose graph
optimization is performed to address intra- and inter-map loop closures for
globally consistent map merging. Our framework is evaluated on diverse
real-world datasets with dynamic objects and heterogeneous LiDARs, showing
superior performance in loop detection across sensor modalities, robust mapping
in dynamic environments, and accurate multi-map alignment over existing
methods. Project Page: https://sparolab.github.io/research/uni_mapper.

</details>


### [85] [Methods for the Segmentation of Reticular Structures Using 3D LiDAR Data: A Comparative Evaluation](https://arxiv.org/abs/2507.20589)
*Francisco J. Soler Mora,Adrián Peidró Vidal,Marc Fabregat-Jaén,Luis Payá Castelló,Óscar Reinoso García*

Main category: cs.RO

TL;DR: 论文提出两种方法（解析算法和深度学习模型）用于桁架结构中可导航表面的检测，提升爬行机器人的自主性。


<details>
  <summary>Details</summary>
Motivation: 桁架结构的检查和维护成本高且危险，现有研究多关注故障检测或机器人平台设计，而自主导航研究较少。

Method: 提出解析算法和深度学习模型（PointNet、PointNet++、MinkUNet34C、PointTransformerV3）对3D点云进行二分类分割。

Result: 解析算法参数调整简单且性能接近深度学习模型，而深度学习模型（如PointTransformerV3）在分割精度上更优（mIoU约97%）。

Conclusion: 研究展示了两种方法在复杂桁架环境中的潜力，为未来自主基础设施检查与维护提供了实用指导。

Abstract: Reticular structures form the backbone of major infrastructure like bridges,
pylons, and airports, but their inspection and maintenance are costly and
hazardous, often requiring human intervention. While prior research has focused
on fault detection via images or robotic platform design, the autonomous
navigation of robots within these structures is less explored. This study
addresses that gap by proposing methods to detect navigable surfaces in truss
structures, enhancing the autonomy of climbing robots. The paper introduces
several approaches for binary segmentation of navigable surfaces versus
background from 3D point clouds of metallic trusses. These methods fall into
two categories: analytical algorithms and deep learning models. The analytical
approach features a custom algorithm that segments structures by analyzing the
eigendecomposition of planar patches in the point cloud. In parallel, advanced
deep learning models PointNet, PointNet++, MinkUNet34C, and PointTransformerV3
are trained and evaluated for the same task. Comparative analysis shows that
the analytical algorithm offers easier parameter tuning and performance
comparable to deep learning models, which, while more computationally
intensive, excel in segmentation accuracy. Notably, PointTransformerV3 achieves
a Mean Intersection Over Union (mIoU) of about 97%. The study demonstrates the
promise of both analytical and deep learning methods for improving autonomous
navigation in complex truss environments. The results highlight the trade-offs
between computational efficiency and segmentation performance, providing
valuable guidance for future research and practical applications in autonomous
infrastructure inspection and maintenance.

</details>


### [86] [FMimic: Foundation Models are Fine-grained Action Learners from Human Videos](https://arxiv.org/abs/2507.20622)
*Guangyan Chen,Meiling Wang,Te Cui,Yao Mu,Haoyang Lu,Zicai Peng,Mengxiao Hu,Tianxing Zhou,Mengyin Fu,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: FMimic利用基础模型直接从少量人类视频中学习细粒度动作技能，显著提升了视觉模仿学习的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预定义动作原语执行物理交互，限制了机器人系统的灵活性。FMimic旨在通过基础模型直接学习通用技能。

Method: FMimic利用视觉语言模型（VLMs）直接从人类视频中学习细粒度动作，无需依赖预定义动作。

Result: FMimic在单视频和五视频任务中表现优异，多任务和真实世界任务中分别提升39%和29%，高精度和长时任务中超过基线34%和47%。

Conclusion: FMimic展示了基础模型在视觉模仿学习中的潜力，能够直接从少量视频中学习通用技能，显著提升性能。

Abstract: Visual imitation learning (VIL) provides an efficient and intuitive strategy
for robotic systems to acquire novel skills. Recent advancements in foundation
models, particularly Vision Language Models (VLMs), have demonstrated
remarkable capabilities in visual and linguistic reasoning for VIL tasks.
Despite this progress, existing approaches primarily utilize these models for
learning high-level plans from human demonstrations, relying on pre-defined
motion primitives for executing physical interactions, which remains a major
bottleneck for robotic systems. In this work, we present FMimic, a novel
paradigm that harnesses foundation models to directly learn generalizable
skills at even fine-grained action levels, using only a limited number of human
videos. Extensive experiments demonstrate that our FMimic delivers strong
performance with a single human video, and significantly outperforms all other
methods with five videos. Furthermore, our method exhibits significant
improvements of over 39% and 29% in RLBench multi-task experiments and
real-world manipulation tasks, respectively, and exceeds baselines by more than
34% in high-precision tasks and 47% in long-horizon tasks.

</details>


### [87] [A Strawberry Harvesting Tool with Minimal Footprint](https://arxiv.org/abs/2507.20784)
*Mohamed Sorour,Mohamed Heshmat,Khaled Elgeneidy,Pål Johan From*

Main category: cs.RO

TL;DR: 本文提出了一种新型草莓采摘原型，通过激光切割茎部，减少接触并延长果实保质期。


<details>
  <summary>Details</summary>
Motivation: 解决传统草莓采摘中接触污染和保质期短的问题。

Method: 使用平滑夹具将茎部引导至精确位置，通过远距离激光切割并高温消毒。

Result: 成功实现室内采摘，切割时间为2.88秒，循环时间为5.56秒。

Conclusion: 该原型高效且卫生，显著提升草莓采摘质量和保质期。

Abstract: In this paper, a novel prototype for harvesting table-top grown strawberries
is presented, that is minimalist in its footprint interacting with the fruit.
In our methodology, a smooth trapper manipulates the stem into a precise groove
location at which a distant laser beam is focused. The tool reaches
temperatures as high as 188{\deg} Celsius and as such killing germs and
preventing the spread of local plant diseases. The burnt stem wound preserves
water content and in turn the fruit shelf life. Cycle and cut times achieved
are 5.56 and 2.88 seconds respectively in successful in-door harvesting
demonstration. Extensive experiments are performed to optimize the laser spot
diameter and lateral speed against the cutting time.

</details>


### [88] [LanternNet: A Novel Hub-and-Spoke System to Seek and Suppress Spotted Lanternfly Populations](https://arxiv.org/abs/2507.20800)
*Vinil Polepalli*

Main category: cs.RO

TL;DR: LanternNet是一种新型自主机器人系统，用于检测和抑制斑点灯笼蝇（SLF），显著减少虫害并改善树木健康，比传统方法更具成本效益和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 斑点灯笼蝇对农业和生态系统构成重大威胁，现有控制方法效率低且对环境有害，因此需要一种更有效的解决方案。

Method: LanternNet采用中心-辐射式系统设计，中心使用YOLOv8模型识别SLF，三个机器人辐射臂分别负责灭虫、环境监测和导航/绘图。

Result: 实地测试显示，LanternNet显著减少了SLF种群（p < 0.01），并改善了树木健康指标，且成本更低、可扩展性更强。

Conclusion: LanternNet展示了机器人与AI结合在入侵物种管理中的潜力，具有广泛的生态应用前景。

Abstract: The invasive spotted lanternfly (SLF) poses a significant threat to
agriculture and ecosystems, causing widespread damage. Current control methods,
such as egg scraping, pesticides, and quarantines, prove labor-intensive,
environmentally hazardous, and inadequate for long-term SLF suppression. This
research introduces LanternNet, a novel autonomous robotic Hub-and-Spoke system
designed for scalable detection and suppression of SLF populations. A central,
tree-mimicking hub utilizes a YOLOv8 computer vision model for precise SLF
identification. Three specialized robotic spokes perform targeted tasks: pest
neutralization, environmental monitoring, and navigation/mapping. Field
deployment across multiple infested sites over 5 weeks demonstrated
LanternNet's efficacy. Quantitative analysis revealed significant reductions (p
< 0.01, paired t-tests) in SLF populations and corresponding improvements in
tree health indicators across the majority of test sites. Compared to
conventional methods, LanternNet offers substantial cost advantages and
improved scalability. Furthermore, the system's adaptability for enhanced
autonomy and targeting of other invasive species presents significant potential
for broader ecological impact. LanternNet demonstrates the transformative
potential of integrating robotics and AI for advanced invasive species
management and improved environmental outcomes.

</details>


### [89] [Hanging Around: Cognitive Inspired Reasoning for Reactive Robotics](https://arxiv.org/abs/2507.20832)
*Mihai Pomarlan,Stefano De Giorgis,Rachel Ringe,Maria M. Hedblom,Nikolaos Tsiogkas*

Main category: cs.RO

TL;DR: 论文提出了一种神经符号模块化架构，用于反应式机器人，结合神经组件和符号推理，使机器人能够识别和监控环境中的相关元素，并通过观察学习新概念。


<details>
  <summary>Details</summary>
Motivation: 解决人工代理在自然环境中操作时面临的挑战，如空间感知、对象功能检测和动态变化，特别是如何识别和监控与其目标相关的环境元素。

Method: 采用神经符号模块化架构，结合神经网络的物体识别和图像处理技术（如光流）与符号表示和推理。推理系统基于具身认知范式，通过本体结构整合图像模式知识。

Result: 在模拟世界中，代理通过学习识别涉及支撑关系的物体部分，成功扩展其知识，并能够规划建立或破坏支撑关系。

Conclusion: 该架构展示了通过系统观察扩展知识的能力，结合深度推理和图像处理的潜力。

Abstract: Situationally-aware artificial agents operating with competence in natural
environments face several challenges: spatial awareness, object affordance
detection, dynamic changes and unpredictability. A critical challenge is the
agent's ability to identify and monitor environmental elements pertinent to its
objectives. Our research introduces a neurosymbolic modular architecture for
reactive robotics. Our system combines a neural component performing object
recognition over the environment and image processing techniques such as
optical flow, with symbolic representation and reasoning. The reasoning system
is grounded in the embodied cognition paradigm, via integrating image schematic
knowledge in an ontological structure. The ontology is operatively used to
create queries for the perception system, decide on actions, and infer
entities' capabilities derived from perceptual data. The combination of
reasoning and image processing allows the agent to focus its perception for
normal operation as well as discover new concepts for parts of objects involved
in particular interactions. The discovered concepts allow the robot to
autonomously acquire training data and adjust its subsymbolic perception to
recognize the parts, as well as making planning for more complex tasks feasible
by focusing search on those relevant object parts. We demonstrate our approach
in a simulated world, in which an agent learns to recognize parts of objects
involved in support relations. While the agent has no concept of handle
initially, by observing examples of supported objects hanging from a hook it
learns to recognize the parts involved in establishing support and becomes able
to plan the establishment/destruction of the support relation. This underscores
the agent's capability to expand its knowledge through observation in a
systematic way, and illustrates the potential of combining deep reasoning
[...].

</details>


### [90] [Free Energy-Inspired Cognitive Risk Integration for AV Navigation in Pedestrian-Rich Environments](https://arxiv.org/abs/2507.20850)
*Meiting Dang,Yanping Wu,Yafei Wang,Dezong Zhao,David Flynn,Chongfeng Wei*

Main category: cs.RO

TL;DR: 提出了一种基于自由能原理的框架，用于自动驾驶车辆与行人间的交互建模，提升安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶车辆与弱势道路用户交互中的人性化预测与决策问题。

Method: 结合认知过程建模和认知-风险社会力模型，利用图卷积网络和Soft Actor-Critic架构进行决策。

Result: 仿真结果表明，框架在安全性、效率和流畅性上优于现有方法。

Conclusion: 该框架为复杂多智能体交互环境提供了更真实的建模和决策方案。

Abstract: Recent advances in autonomous vehicle (AV) behavior planning have shown
impressive social interaction capabilities when interacting with other road
users. However, achieving human-like prediction and decision-making in
interactions with vulnerable road users remains a key challenge in complex
multi-agent interactive environments. Existing research focuses primarily on
crowd navigation for small mobile robots, which cannot be directly applied to
AVs due to inherent differences in their decision-making strategies and dynamic
boundaries. Moreover, pedestrians in these multi-agent simulations follow fixed
behavior patterns that cannot dynamically respond to AV actions. To overcome
these limitations, this paper proposes a novel framework for modeling
interactions between the AV and multiple pedestrians. In this framework, a
cognitive process modeling approach inspired by the Free Energy Principle is
integrated into both the AV and pedestrian models to simulate more realistic
interaction dynamics. Specifically, the proposed pedestrian Cognitive-Risk
Social Force Model adjusts goal-directed and repulsive forces using a fused
measure of cognitive uncertainty and physical risk to produce human-like
trajectories. Meanwhile, the AV leverages this fused risk to construct a
dynamic, risk-aware adjacency matrix for a Graph Convolutional Network within a
Soft Actor-Critic architecture, allowing it to make more reasonable and
informed decisions. Simulation results indicate that our proposed framework
effectively improves safety, efficiency, and smoothness of AV navigation
compared to the state-of-the-art method.

</details>


### [91] [Uncertainty-aware Planning with Inaccurate Models for Robotized Liquid Handling](https://arxiv.org/abs/2507.20861)
*Marco Faroni,Carlo Odesco,Andrea Zanchettin,Paolo Rocco*

Main category: cs.RO

TL;DR: 本文提出了一种基于不确定性感知的MCTS算法，用于提升复杂机器人任务（如液体倾倒）中的决策可靠性。


<details>
  <summary>Details</summary>
Motivation: 物理仿真和学习模型在复杂机器人任务中存在准确性不足的问题，尤其是面对新情况时表现不佳。

Method: 通过结合模型不确定性估计，改进MCTS算法，使其偏向预测不确定性较低的动作。

Result: 在液体倾倒任务中，该方法即使基于少量训练数据也能提高成功率，优于传统方法。

Conclusion: 该方法为机器人决策提供了更强的鲁棒性，尤其在不确定条件下表现优异。

Abstract: Physics-based simulations and learning-based models are vital for complex
robotics tasks like deformable object manipulation and liquid handling.
However, these models often struggle with accuracy due to epistemic uncertainty
or the sim-to-real gap. For instance, accurately pouring liquid from one
container to another poses challenges, particularly when models are trained on
limited demonstrations and may perform poorly in novel situations. This paper
proposes an uncertainty-aware Monte Carlo Tree Search (MCTS) algorithm designed
to mitigate these inaccuracies. By incorporating estimates of model
uncertainty, the proposed MCTS strategy biases the search towards actions with
lower predicted uncertainty. This approach enhances the reliability of planning
under uncertain conditions. Applied to a liquid pouring task, our method
demonstrates improved success rates even with models trained on minimal data,
outperforming traditional methods and showcasing its potential for robust
decision-making in robotics.

</details>


### [92] [A Human-in-the-loop Approach to Robot Action Replanning through LLM Common-Sense Reasoning](https://arxiv.org/abs/2507.20870)
*Elena Merlo,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出一种结合视觉和自然语言输入的人机协作方法，通过LLM增强机器人执行计划，提高适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为非专家提供更直观的机器人编程工具，解决单纯依赖视觉输入的扩展性和错误缓解问题。

Method: 基于单次RGB视频生成初始计划，利用LLM的自然语言输入调整计划，防止潜在错误并适应新指令。

Result: 实验证明该方法能有效纠正视觉错误并适应计划，无需额外演示，且交互式优化提高了系统鲁棒性。

Conclusion: 结合视觉和语言输入的方法为非专家提供了更高效的机器人编程工具，增强了系统的适应性和可靠性。

Abstract: To facilitate the wider adoption of robotics, accessible programming tools
are required for non-experts. Observational learning enables intuitive human
skills transfer through hands-on demonstrations, but relying solely on visual
input can be inefficient in terms of scalability and failure mitigation,
especially when based on a single demonstration. This paper presents a
human-in-the-loop method for enhancing the robot execution plan, automatically
generated based on a single RGB video, with natural language input to a Large
Language Model (LLM). By including user-specified goals or critical task
aspects and exploiting the LLM common-sense reasoning, the system adjusts the
vision-based plan to prevent potential failures and adapts it based on the
received instructions. Experiments demonstrated the framework intuitiveness and
effectiveness in correcting vision-derived errors and adapting plans without
requiring additional demonstrations. Moreover, interactive plan refinement and
hallucination corrections promoted system robustness.

</details>


### [93] [PixelNav: Towards Model-based Vision-Only Navigation with Topological Graphs](https://arxiv.org/abs/2507.20892)
*Sergey Bakulin,Timur Akhtyamov,Denis Fatykhov,German Devchich,Gonzalo Ferrer*

Main category: cs.RO

TL;DR: 提出了一种结合深度学习和经典模型规划算法的混合方法，用于移动机器人的纯视觉导航，解决了端到端模型的数据需求和可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 当前端到端模型虽然灵活，但需要大量训练数据且可解释性差，限制了实际应用。

Method: 采用分层系统，结合模型预测控制、可通行性估计、视觉地点识别和姿态估计，使用拓扑图表示目标环境。

Result: 实验证明该方法高效且比端到端模型更具可解释性。

Conclusion: 提出的混合方法在可扩展性和可解释性上优于纯数据驱动方法。

Abstract: This work proposes a novel hybrid approach for vision-only navigation of
mobile robots, which combines advances of both deep learning approaches and
classical model-based planning algorithms. Today, purely data-driven end-to-end
models are dominant solutions to this problem. Despite advantages such as
flexibility and adaptability, the requirement of a large amount of training
data and limited interpretability are the main bottlenecks for their practical
applications. To address these limitations, we propose a hierarchical system
that utilizes recent advances in model predictive control, traversability
estimation, visual place recognition, and pose estimation, employing
topological graphs as a representation of the target environment. Using such a
combination, we provide a scalable system with a higher level of
interpretability compared to end-to-end approaches. Extensive real-world
experiments show the efficiency of the proposed method.

</details>
