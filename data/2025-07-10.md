<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 21]
- [cs.AI](#cs.AI) [Total: 8]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Solving the Constrained Random Disambiguation Path Problem via Lagrangian Relaxation and Graph Reduction](https://arxiv.org/abs/2507.06346)
*Li Zhou,Elvan Ceyhan*

Main category: cs.RO

TL;DR: 研究资源受限的随机消歧路径（RDP）问题，提出COLOGR算法框架，结合拉格朗日松弛和两阶段顶点消除（TPVE），在保证最优解的同时提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决在不确定障碍物环境中，资源受限的路径规划问题，扩展了随机障碍场景（SOS）问题的应用范围。

Method: 将问题建模为权重约束最短路径问题（WCSPP），提出COLOGR算法框架，结合拉格朗日松弛和TPVE，剪枝无效路径并利用对偶界指导搜索。

Result: COLOGR在多种障碍密度、传感器精度和风险模型下表现鲁棒，优于贪心基线并接近离线最优基准。

Conclusion: COLOGR框架适用于随机网络设计、移动规划和不确定条件下的约束决策，具有广泛的应用潜力。

Abstract: We study a resource-constrained variant of the Random Disambiguation Path
(RDP) problem, a generalization of the Stochastic Obstacle Scene (SOS) problem,
in which a navigating agent must reach a target in a spatial environment
populated with uncertain obstacles. Each ambiguous obstacle may be
disambiguated at a (possibly) heterogeneous resource cost, subject to a global
disambiguation budget. We formulate this constrained planning problem as a
Weight-Constrained Shortest Path Problem (WCSPP) with risk-adjusted edge costs
that incorporate probabilistic blockage and traversal penalties. To solve it,
we propose a novel algorithmic framework-COLOGR-combining Lagrangian relaxation
with a two-phase vertex elimination (TPVE) procedure. The method prunes
infeasible and suboptimal paths while provably preserving the optimal solution,
and leverages dual bounds to guide efficient search. We establish correctness,
feasibility guarantees, and surrogate optimality under mild assumptions. Our
analysis also demonstrates that COLOGR frequently achieves zero duality gap and
offers improved computational complexity over prior constrained path-planning
methods. Extensive simulation experiments validate the algorithm's robustness
across varying obstacle densities, sensor accuracies, and risk models,
consistently outperforming greedy baselines and approaching offline-optimal
benchmarks. The proposed framework is broadly applicable to stochastic network
design, mobility planning, and constrained decision-making under uncertainty.

</details>


### [2] [Mapping the Catacombs: An Underwater Cave Segment of the Devil's Eye System](https://arxiv.org/abs/2507.06397)
*Michalis Chatzispyrou,Luke Horgan,Hyunkil Hwang,Harish Sathishchandra,Monika Roznere,Alberto Quattrini Li,Philippos Mordohai,Ioannis Rekleitis*

Main category: cs.RO

TL;DR: 本文提出了一种利用低成本运动相机和潜水电脑绘制水下洞穴地图的框架，结合视觉/惯性框架和全局优化技术，生成洞穴的一维轨迹和密集3D重建。


<details>
  <summary>Details</summary>
Motivation: 水下洞穴对淡水资源管理、水下考古和水文地质学至关重要，但其精确测绘仍具挑战性。本文旨在通过低成本设备和技术实现洞穴的快速、精确测绘。

Method: 使用运动相机和潜水电脑获取数据，结合SVIn2框架估计相机轨迹和稀疏点云，再通过COLMAP进行全局优化生成密集3D重建。同时，手动测量验证方法有效性。

Result: 成功生成洞穴的一维轨迹和边界信息，并通过全局优化技术重建了选定区域的密集3D模型。手动测量验证了方法的准确性。

Conclusion: 低成本设备结合先进算法可实现水下洞穴的高效测绘，为相关领域提供实用工具。

Abstract: This paper presents a framework for mapping underwater caves. Underwater
caves are crucial for fresh water resource management, underwater archaeology,
and hydrogeology. Mapping the cave's outline and dimensions, as well as
creating photorealistic 3D maps, is critical for enabling a better
understanding of this underwater domain. In this paper, we present the mapping
of an underwater cave segment (the catacombs) of the Devil's Eye cave system at
Ginnie Springs, FL. We utilized a set of inexpensive action cameras in
conjunction with a dive computer to estimate the trajectories of the cameras
together with a sparse point cloud. The resulting reconstructions are utilized
to produce a one-dimensional retract of the cave passages in the form of the
average trajectory together with the boundaries (top, bottom, left, and right).
The use of the dive computer enables the observability of the z-dimension in
addition to the roll and pitch in a visual/inertial framework (SVIn2). In
addition, the keyframes generated by SVIn2 together with the estimated camera
poses for select areas are used as input to a global optimization (bundle
adjustment) framework -- COLMAP -- in order to produce a dense reconstruction
of those areas. The same cave segment is manually surveyed using the MNemo V2
instrument, providing an additional set of measurements validating the proposed
approach. It is worth noting that with the use of action cameras, the primary
components of a cave map can be constructed. Furthermore, with the utilization
of a global optimization framework guided by the results of VI-SLAM package
SVIn2, photorealistic dense 3D representations of selected areas can be
reconstructed.

</details>


### [3] [Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction](https://arxiv.org/abs/2507.06404)
*Matteo Tiezzi,Tommaso Apicella,Carlos Cardenas-Perez,Giovanni Fregonese,Stefano Dafarra,Pietro Morerio,Daniele Pucci,Alessio Del Bue*

Main category: cs.RO

TL;DR: 提出了一种基于轨迹性能的模仿学习评估框架NeME，用于比较人形机器人控制策略，无需人工参与。


<details>
  <summary>Details</summary>
Motivation: 由于成功率指标难以复现且无法捕捉机器人运动轨迹的复杂性，评估人形机器人性能具有挑战性。

Method: 设计了NeME（神经元评估器），通过深度学习模型从关节轨迹中分类动作，作为元评估器比较控制策略。

Result: 在ergoCub机器人上验证，结果表明该方法比基线更符合实际成功率。

Conclusion: NeME为复杂人机交互任务中的模仿学习方法提供了可复现、系统化的评估手段。

Abstract: Evaluating and comparing the performance of autonomous Humanoid Robots is
challenging, as success rate metrics are difficult to reproduce and fail to
capture the complexity of robot movement trajectories, critical in Human-Robot
Interaction and Collaboration (HRIC). To address these challenges, we propose a
general evaluation framework that measures the quality of Imitation Learning
(IL) methods by focusing on trajectory performance. We devise the Neural Meta
Evaluator (NeME), a deep learning model trained to classify actions from robot
joint trajectories. NeME serves as a meta-evaluator to compare the performance
of robot control policies, enabling policy evaluation without requiring human
involvement in the loop. We validate our framework on ergoCub, a humanoid
robot, using teleoperation data and comparing IL methods tailored to the
available platform. The experimental results indicate that our method is more
aligned with the success rate obtained on the robot than baselines, offering a
reproducible, systematic, and insightful means for comparing the performance of
multimodal imitation learning approaches in complex HRI tasks.

</details>


### [4] [Evaluating Robots Like Human Infants: A Case Study of Learned Bipedal Locomotion](https://arxiv.org/abs/2507.06426)
*Devin Crowley,Whitney G. Cole,Christina M. Hospodar,Ruiting Shen,Karen E. Adolph,Alan Fern*

Main category: cs.RO

TL;DR: 论文提出了一种将发展心理学方法应用于机器人行为学习的研究，通过系统设计训练方案和精细测量，揭示了训练对机器人行为发展的影响。


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制器的训练和评估方法较为粗放，缺乏对训练方案影响的深入理解，而发展心理学的方法可以提供更细致的分析。

Method: 采用发展心理学的方法，系统设计强化学习训练方案，并在模拟环境中测试双足机器人Cassie的行为。

Result: 研究揭示了不同训练方案对机器人行为的影响，并与婴儿学步行为进行了对比。

Conclusion: 这种跨学科方法为未来研究提供了新思路，可系统测试训练对复杂机器人行为发展的影响。

Abstract: Typically, learned robot controllers are trained via relatively unsystematic
regimens and evaluated with coarse-grained outcome measures such as average
cumulative reward. The typical approach is useful to compare learning
algorithms but provides limited insight into the effects of different training
regimens and little understanding about the richness and complexity of learned
behaviors. Likewise, human infants and other animals are "trained" via
unsystematic regimens, but in contrast, developmental psychologists evaluate
their performance in highly-controlled experiments with fine-grained measures
such as success, speed of walking, and prospective adjustments. However, the
study of learned behavior in human infants is limited by the practical
constraints of training and testing babies. Here, we present a case study that
applies methods from developmental psychology to study the learned behavior of
the simulated bipedal robot Cassie. Following research on infant walking, we
systematically designed reinforcement learning training regimens and tested the
resulting controllers in simulated environments analogous to those used for
babies--but without the practical constraints. Results reveal new insights into
the behavioral impact of different training regimens and the development of
Cassie's learned behaviors relative to infants who are learning to walk. This
interdisciplinary baby-robot approach provides inspiration for future research
designed to systematically test effects of training on the development of
complex learned robot behaviors.

</details>


### [5] [Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies](https://arxiv.org/abs/2507.06519)
*Yuhan Liu,Xinyu Zhang,Haonan Chang,Abdeslam Boularias*

Main category: cs.RO

TL;DR: 提出了一种结合强化学习和故障预测的框架，用于解决机器人高精度重复插入任务（RIT）的挑战，显著提升了仿真到现实的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 解决RIT任务中毫米级精度和重复性能的挑战，尤其是在螺母旋转和摩擦等复杂因素下。

Method: 采用仿真到现实框架，结合强化学习插入策略和故障预测模块，利用6D姿态跟踪实现精确操作。

Result: 实验表明，该方法不仅单次成功率高，还能在长期重复任务中保持稳健性能。

Conclusion: 提出的框架有效提升了RIT任务的精度和鲁棒性，为类似任务提供了可行解决方案。

Abstract: This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where
a robot must repeatedly perform high-precision insertions, such as screwing a
nut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving
millimeter-level accuracy and maintaining consistent performance over multiple
repetitions, particularly when factors like nut rotation and friction introduce
additional complexity. We propose a sim-to-real framework that integrates a
reinforcement learning-based insertion policy with a failure forecasting
module. By representing the wrench's pose in the nut's coordinate frame rather
than the robot's frame, our approach significantly enhances sim-to-real
transferability. The insertion policy, trained in simulation, leverages
real-time 6D pose tracking to execute precise alignment, insertion, and
rotation maneuvers. Simultaneously, a neural network predicts potential
execution failures, triggering a simple recovery mechanism that lifts the
wrench and retries the insertion. Extensive experiments in both simulated and
real-world environments demonstrate that our method not only achieves a high
one-time success rate but also robustly maintains performance over long-horizon
repetitive tasks.

</details>


### [6] [KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and Wall Climbing](https://arxiv.org/abs/2507.06562)
*Keita Yoneda,Kento Kawaharazuka,Temma Suzuki,Takahiro Hattori,Kei Okada*

Main category: cs.RO

TL;DR: 本文开发了带腰部关节的四足机器人KLEIYN，通过强化学习实现垂直运动（如烟囱攀爬），并引入接触引导课程学习（CGCL）优化学习过程。结果显示，KLEIYN能以150 mm/s的速度攀爬800-1000 mm宽的墙壁，速度是传统机器人的50倍，且腰部关节显著提升了狭窄墙壁的跟踪能力。


<details>
  <summary>Details</summary>
Motivation: 近年来硬件进步使四足机器人具备高功率与速度，但稳定垂直运动（如崎岖地形攀爬）的控制方法尚未成熟。本研究旨在通过强化学习扩展四足机器人的运动能力，解决垂直运动控制的挑战。

Method: 开发了带腰部关节的四足机器人KLEIYN，采用强化学习（RL）实现垂直运动（如烟囱攀爬），并引入接触引导课程学习（CGCL）优化学习过程。

Result: KLEIYN成功攀爬800-1000 mm宽的墙壁，平均速度达150 mm/s（比传统机器人快50倍），且腰部关节显著提升了狭窄墙壁的跟踪性能。

Conclusion: 研究表明，腰部关节结合强化学习和CGCL能有效扩展四足机器人的垂直运动能力，为复杂地形任务自动化提供了新思路。

Abstract: In recent years, advancements in hardware have enabled quadruped robots to
operate with high power and speed, while robust locomotion control using
reinforcement learning (RL) has also been realized. As a result, expectations
are rising for the automation of tasks such as material transport and
exploration in unknown environments. However, autonomous locomotion in rough
terrains with significant height variations requires vertical movement, and
robots capable of performing such movements stably, along with their control
methods, have not yet been fully established. In this study, we developed the
quadruped robot KLEIYN, which features a waist joint, and aimed to expand
quadruped locomotion by enabling chimney climbing through RL. To facilitate the
learning of vertical motion, we introduced Contact-Guided Curriculum Learning
(CGCL). As a result, KLEIYN successfully climbed walls ranging from 800 mm to
1000 mm in width at an average speed of 150 mm/s, 50 times faster than
conventional robots. Furthermore, we demonstrated that the introduction of a
waist joint improves climbing performance, particularly enhancing tracking
ability on narrow walls.

</details>


### [7] [SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments](https://arxiv.org/abs/2507.06564)
*Tianshun Li,Tianyi Huai,Zhen Li,Yichun Gao,Haoang Li,Xinhu Zheng*

Main category: cs.RO

TL;DR: SkyVLN框架结合视觉语言导航（VLN）和非线性模型预测控制（NMPC），提升无人机在复杂城市环境中的自主导航能力。


<details>
  <summary>Details</summary>
Motivation: 传统导航方法在动态3D环境中表现不足，SkyVLN通过结合LLM和NMPC，提升无人机导航的准确性和鲁棒性。

Method: SkyVLN利用LLM解析自然语言指令和视觉观察，结合细粒度空间语言化器和历史路径记忆机制，同时使用NMPC模块进行动态避障。

Result: 实验表明，SkyVLN显著提高了导航成功率和效率，尤其是在新环境中。

Conclusion: SkyVLN为无人机在复杂城市环境中的自主导航提供了高效解决方案。

Abstract: Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across
various sectors, driven by their mobility and adaptability. This paper
introduces SkyVLN, a novel framework integrating vision-and-language navigation
(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in
complex urban environments. Unlike traditional navigation methods, SkyVLN
leverages Large Language Models (LLMs) to interpret natural language
instructions and visual observations, enabling UAVs to navigate through dynamic
3D spaces with improved accuracy and robustness. We present a multimodal
navigation agent equipped with a fine-grained spatial verbalizer and a history
path memory mechanism. These components allow the UAV to disambiguate spatial
contexts, handle ambiguous instructions, and backtrack when necessary. The
framework also incorporates an NMPC module for dynamic obstacle avoidance,
ensuring precise trajectory tracking and collision prevention. To validate our
approach, we developed a high-fidelity 3D urban simulation environment using
AirSim, featuring realistic imagery and dynamic urban elements. Extensive
experiments demonstrate that SkyVLN significantly improves navigation success
rates and efficiency, particularly in new and unseen environments.

</details>


### [8] [Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic](https://arxiv.org/abs/2507.06625)
*Shizhe Cai,Jayadeep Jacob,Zeya Yin,Fabio Ramos*

Main category: cs.RO

TL;DR: Q-STAC结合贝叶斯MPC与actor-critic强化学习，通过约束SVGD优化控制序列，提升样本效率与安全性。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习在连续控制任务中数据需求大、长时规划难、安全性不足的问题，同时弥补MPC的局部最优性和成本函数设计复杂性。

Method: 提出Q-STAC框架，利用学习到的Q值作为目标，结合贝叶斯MPC和actor-critic强化学习，通过约束SVGD优化控制序列。

Result: 在2D导航和机器人操作任务中，Q-STAC表现出更高的样本效率、鲁棒性和最优性。

Conclusion: Q-STAC成功整合了MPC与强化学习的优势，实现了高效、安全且最优的控制。

Abstract: Deep reinforcement learning has shown remarkable success in continuous
control tasks, yet often requires extensive training data, struggles with
complex, long-horizon planning, and fails to maintain safety constraints during
operation. Meanwhile, Model Predictive Control (MPC) offers explainability and
constraint satisfaction, but typically yields only locally optimal solutions
and demands careful cost function design. This paper introduces the Q-guided
STein variational model predictive Actor-Critic (Q-STAC), a novel framework
that bridges these approaches by integrating Bayesian MPC with actor-critic
reinforcement learning through constrained Stein Variational Gradient Descent
(SVGD). Our method optimizes control sequences directly using learned Q-values
as objectives, eliminating the need for explicit cost function design while
leveraging known system dynamics to enhance sample efficiency and ensure
control signals remain within safe boundaries. Extensive experiments on 2D
navigation and robotic manipulation tasks demonstrate that Q-STAC achieves
superior sample efficiency, robustness, and optimality compared to
state-of-the-art algorithms, while maintaining the high expressiveness of
policy distributions. Experiment videos are available on our website:
https://sites.google.com/view/q-stac

</details>


### [9] [AI Space Cortex: An Experimental System for Future Era Space Exploration](https://arxiv.org/abs/2507.06574)
*Thomas Touma,Ersin Daş,Erica Tevere,Martin Feather,Ksenia Kolcio,Maurice Prather,Alberto Candela,Ashish Goel,Erik Kramer,Hari Nayar,Lorraine Fesq,Joel W. Burdick*

Main category: cs.RO

TL;DR: REASIMO项目为NASA的COLDTech计划开发AI辅助自主系统，用于解决海洋世界任务中的通信延迟、能源限制和辐射问题，实现异常检测与恢复，并通过测试验证其能力。


<details>
  <summary>Details</summary>
Motivation: 海洋世界任务（如欧罗巴和恩塞拉达斯）面临通信延迟、能源限制和恶劣环境等挑战，传统安全模式无法满足需求，需开发自主系统以完成任务目标。

Method: 结合AI技术，开发了基于预训练行为的智能框架，支持异常检测与恢复，并在NASA喷气推进实验室的测试平台上模拟任务环境进行验证。

Result: 测试验证了框架在自主采样操作中的能力，展示了其在模拟海洋世界任务环境中的实用性。

Conclusion: REASIMO框架为未来海洋世界任务提供了强大的自主能力，解决了传统方法无法应对的挑战，具有重要的科学和任务价值。

Abstract: Our Robust, Explainable Autonomy for Scientific Icy Moon Operations (REASIMO)
effort contributes to NASA's Concepts for Ocean worlds Life Detection
Technology (COLDTech) program, which explores science platform technologies for
ocean worlds such as Europa and Enceladus. Ocean world missions pose
significant operational challenges. These include long communication lags,
limited power, and lifetime limitations caused by radiation damage and hostile
conditions. Given these operational limitations, onboard autonomy will be vital
for future Ocean world missions. Besides the management of nominal lander
operations, onboard autonomy must react appropriately in the event of
anomalies. Traditional spacecraft rely on a transition into 'safe-mode' in
which non-essential components and subsystems are powered off to preserve
safety and maintain communication with Earth. For a severely time-limited Ocean
world mission, resolutions to these anomalies that can be executed without
Earth-in-the-loop communication and associated delays are paramount for
completion of the mission objectives and science goals. To address these
challenges, the REASIMO effort aims to demonstrate a robust level of
AI-assisted autonomy for such missions, including the ability to detect and
recover from anomalies, and to perform missions based on pre-trained behaviors
rather than hard-coded, predetermined logic like all prior space missions. We
developed an AI-assisted, personality-driven, intelligent framework for control
of an Ocean world mission by combining a mix of advanced technologies. To
demonstrate the capabilities of the framework, we perform tests of autonomous
sampling operations on a lander-manipulator testbed at the NASA Jet Propulsion
Laboratory, approximating possible surface conditions such a mission might
encounter.

</details>


### [10] [Growing Trees with an Agent: Accelerating RRTs with Learned, Multi-Step Episodic Exploration](https://arxiv.org/abs/2507.06605)
*Xinyu Wu*

Main category: cs.RO

TL;DR: Episodic RRT（ERRT）是一种结合深度强化学习的混合规划框架，通过多步探索替代随机采样，显著提升了运动规划的效率。


<details>
  <summary>Details</summary>
Motivation: 传统RRT在复杂或高维空间中效率低下，因其依赖随机采样。ERRT旨在通过强化学习的定向探索解决这一问题。

Method: ERRT利用深度强化学习生成多步探索片段，替代随机点采样，实现定向搜索并减少碰撞检测。

Result: 在2D、3D和6D环境中，ERRT及其变体表现显著优于传统RRT，6D机械臂场景中成功率提升至98%，速度提升107倍。

Conclusion: ERRT通过强化学习的定向探索，显著提升了运动规划的性能，尤其在复杂和高维环境中。

Abstract: Classical sampling-based motion planners like the RRTs suffer from
inefficiencies, particularly in cluttered or high-dimensional spaces, due to
their reliance on undirected, random sampling. This paper introduces the
Episodic RRT, a novel hybrid planning framework that replaces the primitive of
a random point with a learned, multi-step "exploratory episode" generated by a
Deep Reinforcement Learning agent. By making the DRL agent the engine of
exploration, ERRT transforms the search process from a diffuse, volumetric
expansion into a directed, branch-like growth. This paradigm shift yields key
advantages: it counters the curse of dimensionality with focused exploration,
minimizes expensive collision checks by proactively proposing locally valid
paths, and improves connectivity by generating inherently connected path
segments. We demonstrate through extensive empirical evaluation across 2D, 3D,
and 6D environments that ERRT and its variants consistently and significantly
outperform their classical counterparts. In a challenging 6D robotic arm
scenario, ERRT achieves a 98% success rate compared to 19% for RRT, is up to
107x faster, reduces collision checks by over 99.6%, and finds initial paths
that are nearly 50% shorter. Furthermore, its asymptotically optimal variant,
ERRT*, demonstrates vastly superior anytime performance, refining solutions to
near-optimality up to 29x faster than standard RRT* in 3D environments. Code:
https://xinyuwuu.github.io/Episodic_RRT/.

</details>


### [11] [Multi-Task Multi-Agent Reinforcement Learning via Skill Graphs](https://arxiv.org/abs/2507.06690)
*Guobin Zhu,Rui Zhou,Wenkang Ji,Hongyin Zhang,Donglin Wang,Shiyu Zhao*

Main category: cs.RO

TL;DR: 提出了一种分层方法，通过技能图（高层模块）和标准MARL算法（低层模块）解决多任务多智能体强化学习（MT-MARL）中无关任务处理与知识迁移的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有多任务学习方法难以处理复杂问题，尤其是无关任务和知识迁移能力有限。

Method: 采用分层结构，高层使用技能图，低层使用标准MARL算法，训练独立进行。

Result: 实验表明，该方法优于最新的分层MAPPO算法，有效处理无关任务并提升知识迁移能力。

Conclusion: 该方法扩展了MTRL的应用范围，为MT-MARL提供了高效解决方案。

Abstract: Multi-task multi-agent reinforcement learning (MT-MARL) has recently gained
attention for its potential to enhance MARL's adaptability across multiple
tasks. However, it is challenging for existing multi-task learning methods to
handle complex problems, as they are unable to handle unrelated tasks and
possess limited knowledge transfer capabilities. In this paper, we propose a
hierarchical approach that efficiently addresses these challenges. The
high-level module utilizes a skill graph, while the low-level module employs a
standard MARL algorithm. Our approach offers two contributions. First, we
consider the MT-MARL problem in the context of unrelated tasks, expanding the
scope of MTRL. Second, the skill graph is used as the upper layer of the
standard hierarchical approach, with training independent of the lower layer,
effectively handling unrelated tasks and enhancing knowledge transfer
capabilities. Extensive experiments are conducted to validate these advantages
and demonstrate that the proposed method outperforms the latest hierarchical
MAPPO algorithms. Videos and code are available at
https://github.com/WindyLab/MT-MARL-SG

</details>


### [12] [Integrating Perceptions: A Human-Centered Physical Safety Model for Human-Robot Interaction](https://arxiv.org/abs/2507.06700)
*Pranav Pandey,Ramviyas Parasuraman,Prashant Doshi*

Main category: cs.RO

TL;DR: 论文提出了一种参数化安全模型，结合个性化参数ρ，以弥合物理安全与主观感知安全之间的差距，并通过实验验证了情感状态、信任和机器人行为对感知安全的影响。


<details>
  <summary>Details</summary>
Motivation: 传统安全模型主要依赖传感器数据，忽略了主观安全感知的个体差异。本文旨在通过引入个性化参数ρ，结合心理和行为维度，提升人机交互中的安全感知。

Method: 通过模拟救援场景的人体实验，研究情感状态、信任和机器人行为对感知安全的影响，并使用参数ρ量化个体差异。

Result: 实验表明，ρ能有效捕捉个体差异，可预测的机器人行为和积极情感状态显著提升感知安全。参与者反应聚类为少量用户类型，支持基于共享安全模型的个性化适配。

Conclusion: 研究强调了结合心理和行为维度的自适应安全模型的重要性，为安全关键领域的人机交互提供了更可信和有效的路径。

Abstract: Ensuring safety in human-robot interaction (HRI) is essential to foster user
trust and enable the broader adoption of robotic systems. Traditional safety
models primarily rely on sensor-based measures, such as relative distance and
velocity, to assess physical safety. However, these models often fail to
capture subjective safety perceptions, which are shaped by individual traits
and contextual factors. In this paper, we introduce and analyze a parameterized
general safety model that bridges the gap between physical and perceived safety
by incorporating a personalization parameter, $\rho$, into the safety
measurement framework to account for individual differences in safety
perception. Through a series of hypothesis-driven human-subject studies in a
simulated rescue scenario, we investigate how emotional state, trust, and robot
behavior influence perceived safety. Our results show that $\rho$ effectively
captures meaningful individual differences, driven by affective responses,
trust in task consistency, and clustering into distinct user types.
Specifically, our findings confirm that predictable and consistent robot
behavior as well as the elicitation of positive emotional states, significantly
enhance perceived safety. Moreover, responses cluster into a small number of
user types, supporting adaptive personalization based on shared safety models.
Notably, participant role significantly shapes safety perception, and repeated
exposure reduces perceived safety for participants in the casualty role,
emphasizing the impact of physical interaction and experiential change. These
findings highlight the importance of adaptive, human-centered safety models
that integrate both psychological and behavioral dimensions, offering a pathway
toward more trustworthy and effective HRI in safety-critical domains.

</details>


### [13] [Spatial-Temporal Aware Visuomotor Diffusion Policy Learning](https://arxiv.org/abs/2507.06710)
*Zhenyang Liu,Yikai Wang,Kuanning Wang,Longfei Liang,Xiangyang Xue,Yanwei Fu*

Main category: cs.RO

TL;DR: 论文提出了一种名为4D Diffusion Policy (DP4)的视觉模仿学习方法，通过引入时空感知能力，显著提升了机器人在3D空间和4D时空中的任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模仿学习方法主要依赖行为克隆和历史轨迹监督，缺乏对3D结构和4D时空关系的捕捉能力，限制了其在真实世界中的应用。

Method: DP4利用动态高斯世界模型，从交互环境中学习3D空间和4D时空感知，通过单视角RGB-D观察构建当前3D场景并预测未来3D场景，显式建模时空依赖以优化轨迹生成。

Result: 在17个模拟任务和3个真实机器人任务中，DP4表现优于基线方法，模拟任务平均成功率提升16.4%（Adroit）、14%（DexArt）和6.45%（RLBench），真实任务平均成功率提升8.6%。

Conclusion: DP4通过引入时空感知能力，显著提升了视觉模仿学习在复杂任务中的性能，为机器人真实世界部署提供了有效解决方案。

Abstract: Visual imitation learning is effective for robots to learn versatile tasks.
However, many existing methods rely on behavior cloning with supervised
historical trajectories, limiting their 3D spatial and 4D spatiotemporal
awareness. Consequently, these methods struggle to capture the 3D structures
and 4D spatiotemporal relationships necessary for real-world deployment. In
this work, we propose 4D Diffusion Policy (DP4), a novel visual imitation
learning method that incorporates spatiotemporal awareness into diffusion-based
policies. Unlike traditional approaches that rely on trajectory cloning, DP4
leverages a dynamic Gaussian world model to guide the learning of 3D spatial
and 4D spatiotemporal perceptions from interactive environments. Our method
constructs the current 3D scene from a single-view RGB-D observation and
predicts the future 3D scene, optimizing trajectory generation by explicitly
modeling both spatial and temporal dependencies. Extensive experiments across
17 simulation tasks with 173 variants and 3 real-world robotic tasks
demonstrate that the 4D Diffusion Policy (DP4) outperforms baseline methods,
improving the average simulation task success rate by 16.4% (Adroit), 14%
(DexArt), and 6.45% (RLBench), and the average real-world robotic task success
rate by 8.6%.

</details>


### [14] [LOVON: Legged Open-Vocabulary Object Navigator](https://arxiv.org/abs/2507.06747)
*Daojie Peng,Jiahang Cao,Qiang Zhang,Jun Ma*

Main category: cs.RO

TL;DR: LOVON框架结合大语言模型和开放词汇视觉检测模型，解决开放世界中长程物体导航问题，通过专用技术（如拉普拉斯方差滤波）提升稳定性，并在多款机器人上验证其兼容性。


<details>
  <summary>Details</summary>
Motivation: 开放世界中的物体导航对机器人系统是巨大挑战，传统方法难以整合开放世界物体检测与高级任务规划，限制了复杂长程导航任务的能力。

Method: 提出LOVON框架，整合大语言模型（LLMs）进行分层任务规划，结合开放词汇视觉检测模型，并设计拉普拉斯方差滤波等技术解决视觉抖动等问题。

Result: 实验证明LOVON能成功完成涉及实时检测、搜索和导航的长序列任务，并在多款腿式机器人上验证其兼容性和即插即用特性。

Conclusion: LOVON为动态非结构化环境中的长程物体导航提供了有效解决方案，展现了强大的任务适应性和鲁棒性。

Abstract: Object navigation in open-world environments remains a formidable and
pervasive challenge for robotic systems, particularly when it comes to
executing long-horizon tasks that require both open-world object detection and
high-level task planning. Traditional methods often struggle to integrate these
components effectively, and this limits their capability to deal with complex,
long-range navigation missions. In this paper, we propose LOVON, a novel
framework that integrates large language models (LLMs) for hierarchical task
planning with open-vocabulary visual detection models, tailored for effective
long-range object navigation in dynamic, unstructured environments. To tackle
real-world challenges including visual jittering, blind zones, and temporary
target loss, we design dedicated solutions such as Laplacian Variance Filtering
for visual stabilization. We also develop a functional execution logic for the
robot that guarantees LOVON's capabilities in autonomous navigation, task
adaptation, and robust task completion. Extensive evaluations demonstrate the
successful completion of long-sequence tasks involving real-time detection,
search, and navigation toward open-vocabulary dynamic targets. Furthermore,
real-world experiments across different legged robots (Unitree Go2, B2, and
H1-2) showcase the compatibility and appealing plug-and-play feature of LOVON.

</details>


### [15] [Distributed Fault-Tolerant Multi-Robot Cooperative Localization in Adversarial Environments](https://arxiv.org/abs/2507.06750)
*Tohid Kargar Tasooji,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: 提出了一种分布式容错协同定位框架，用于对抗环境中传感器和通信中断的增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在多机器人系统中，对抗性攻击（如传感器操纵和通信干扰）对传统定位方法构成挑战，需提高鲁棒性和可扩展性。

Method: 采用自适应事件触发通信策略，动态调整通信阈值，并分析算法的收敛性和稳定性。

Result: 实验表明，该算法在定位精度和通信效率上显著优于传统方法，尤其在对抗环境中。

Conclusion: 该方法提高了多机器人系统的可扩展性、可靠性和容错性，适用于现实世界中的大规模部署。

Abstract: In multi-robot systems (MRS), cooperative localization is a crucial task for
enhancing system robustness and scalability, especially in GPS-denied or
communication-limited environments. However, adversarial attacks, such as
sensor manipulation, and communication jamming, pose significant challenges to
the performance of traditional localization methods. In this paper, we propose
a novel distributed fault-tolerant cooperative localization framework to
enhance resilience against sensor and communication disruptions in adversarial
environments. We introduce an adaptive event-triggered communication strategy
that dynamically adjusts communication thresholds based on real-time sensing
and communication quality. This strategy ensures optimal performance even in
the presence of sensor degradation or communication failure. Furthermore, we
conduct a rigorous analysis of the convergence and stability properties of the
proposed algorithm, demonstrating its resilience against bounded adversarial
zones and maintaining accurate state estimation. Robotarium-based experiment
results show that our proposed algorithm significantly outperforms traditional
methods in terms of localization accuracy and communication efficiency,
particularly in adversarial settings. Our approach offers improved scalability,
reliability, and fault tolerance for MRS, making it suitable for large-scale
deployments in real-world, challenging environments.

</details>


### [16] [Stream Function-Based Navigation for Complex Quadcopter Obstacle Avoidance](https://arxiv.org/abs/2507.06787)
*Sean Smith,Emmanuel Witrant,Ya-Jun Pan*

Main category: cs.RO

TL;DR: 提出了一种基于流函数的导航控制系统，用于障碍物避障，结合涡流面板法和模型预测控制，实现复杂环境中的实时导航。


<details>
  <summary>Details</summary>
Motivation: 解决传统涡流面板法在近距离避障和快速移动障碍物管理中的局限性。

Method: 结合涡流面板法（VPM）和基于高阶控制屏障函数（HOCBF）的模型预测控制器（MPC），利用最小包围椭圆（MBE）和自适应卡尔曼滤波器（AKF）处理障碍物动态。

Result: 在PX4驱动的Clover无人机Gazebo模拟器和实际实验中验证了系统的有效性。

Conclusion: 该系统能够高效处理复杂环境中的实时避障任务。

Abstract: This article presents a novel stream function-based navigational control
system for obstacle avoidance, where obstacles are represented as
two-dimensional (2D) rigid surfaces in inviscid, incompressible flows. The
approach leverages the vortex panel method (VPM) and incorporates safety
margins to control the stream function and flow properties around virtual
surfaces, enabling navigation in complex, partially observed environments using
real-time sensing. To address the limitations of the VPM in managing relative
distance and avoiding rapidly accelerating obstacles at close proximity, the
system integrates a model predictive controller (MPC) based on higher-order
control barrier functions (HOCBF). This integration incorporates VPM trajectory
generation, state estimation, and constraint handling into a receding-horizon
optimization problem. The 2D rigid surfaces are enclosed using minimum bounding
ellipses (MBEs), while an adaptive Kalman filter (AKF) captures and predicts
obstacle dynamics, propagating these estimates into the MPC-HOCBF for rapid
avoidance maneuvers. Evaluation is conducted using a PX4-powered Clover drone
Gazebo simulator and real-time experiments involving a COEX Clover quadcopter
equipped with a 360 degree LiDAR sensor.

</details>


### [17] [Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand](https://arxiv.org/abs/2507.06822)
*Wei Xu,Yanchao Zhao,Weichao Guo,Xinjun Sheng*

Main category: cs.RO

TL;DR: 提出了一种分层目标条件强化学习框架，用于提高仿人机器人手对铰接工具的操控能力，实验成功率达70.8%。


<details>
  <summary>Details</summary>
Motivation: 铰接工具（如镊子或剪刀）的动态形状变化为机器人操控带来独特挑战，此前研究较少涉及。

Method: 采用分层策略：低层策略控制工具配置，高层策略定义目标状态；结合点云编码器和启发式策略提高训练效率。

Result: 实验验证机器人能有效操控镊子状工具，抓取不同形状和大小的物体，成功率达70.8%。

Conclusion: 研究表明强化学习可推动铰接工具的灵巧操控，具有潜在应用价值。

Abstract: Manipulating articulated tools, such as tweezers or scissors, has rarely been
explored in previous research. Unlike rigid tools, articulated tools change
their shape dynamically, creating unique challenges for dexterous robotic
hands. In this work, we present a hierarchical, goal-conditioned reinforcement
learning (GCRL) framework to improve the manipulation capabilities of
anthropomorphic robotic hands using articulated tools. Our framework comprises
two policy layers: (1) a low-level policy that enables the dexterous hand to
manipulate the tool into various configurations for objects of different sizes,
and (2) a high-level policy that defines the tool's goal state and controls the
robotic arm for object-picking tasks. We employ an encoder, trained on
synthetic pointclouds, to estimate the tool's affordance states--specifically,
how different tool configurations (e.g., tweezer opening angles) enable
grasping of objects of varying sizes--from input point clouds, thereby enabling
precise tool manipulation. We also utilize a privilege-informed heuristic
policy to generate replay buffer, improving the training efficiency of the
high-level policy. We validate our approach through real-world experiments,
showing that the robot can effectively manipulate a tweezer-like tool to grasp
objects of diverse shapes and sizes with a 70.8 % success rate. This study
highlights the potential of RL to advance dexterous robotic manipulation of
articulated tools.

</details>


### [18] [Friction Estimation for In-Hand Planar Motion](https://arxiv.org/abs/2507.06824)
*Gabriel Arslan Waltersson,Yiannis Karayiannidis*

Main category: cs.RO

TL;DR: 提出了一种在线估计平行夹持器滑动操作中接触特性的方法，包括静摩擦、库仑摩擦和接触半径。


<details>
  <summary>Details</summary>
Motivation: 在滑动操作中准确估计接触特性对提高机器人操作的稳定性和精确性至关重要。

Method: 通过触觉测量接触力和滑动速度来估计接触特性，并在仿真和真实实验中验证。提出了一种启发式方法处理快速滑移-粘滞动态。

Result: 方法在仿真和实际实验中均得到验证，能够有效估计接触特性。

Conclusion: 该方法为机器人滑动操作提供了可靠的接触特性估计，并通过启发式方法解决了快速动态问题。

Abstract: This paper presents a method for online estimation of contact properties
during in-hand sliding manipulation with a parallel gripper. We estimate the
static and Coulomb friction as well as the contact radius from tactile
measurements of contact forces and sliding velocities. The method is validated
in both simulation and real-world experiments. Furthermore, we propose a
heuristic to deal with fast slip-stick dynamics which can adversely affect the
estimation.

</details>


### [19] [Toward a Full-Stack Co-Simulation Platform for Testing of Automated Driving Systems](https://arxiv.org/abs/2507.06884)
*Dong Bi,Yongqi Zhao,Zhengguo Gu,Tomislav Mihalj,Jia Hu,Arno Eichberger*

Main category: cs.RO

TL;DR: 提出了一种全栈工具链，用于从真实数据自动生成场景并通过基于CarMaker、ROS和Apollo的协同仿真平台进行高效验证。


<details>
  <summary>Details</summary>
Motivation: 现有仿真工具链难以整合快速、自动化的场景生成与支持高级自动驾驶能力的仿真环境。

Method: 开发了一种全栈工具链，结合真实数据集自动生成场景，并通过CarMaker、ROS和Apollo的协同仿真平台进行验证。

Result: 仿真结果证明了该工具链的有效性。

Conclusion: 该工具链解决了现有仿真工具链的局限性，加速了自动驾驶系统的部署。

Abstract: Virtual testing has emerged as an effective approach to accelerate the
deployment of automated driving systems. Nevertheless, existing simulation
toolchains encounter difficulties in integrating rapid, automated scenario
generation with simulation environments supporting advanced automated driving
capabilities. To address this limitation, a full-stack toolchain is presented,
enabling automatic scenario generation from real-world datasets and efficient
validation through a co-simulation platform based on CarMaker, ROS, and Apollo.
The simulation results demonstrate the effectiveness of the proposed toolchain.
A demonstration video showcasing the toolchain is available at the provided
link: https://youtu.be/taJw_-CmSiY.

</details>


### [20] [ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation](https://arxiv.org/abs/2507.06905)
*Wandong Sun,Luying Feng,Baoshi Cao,Yang Liu,Yaochu Jin,Zongwu Xie*

Main category: cs.RO

TL;DR: 提出了一种统一的人形机器人运动与操纵控制框架（ULC），通过单一策略实现全身协调控制，优于传统分层方法。


<details>
  <summary>Details</summary>
Motivation: 现有分层控制方法限制了子系统间的协调性，无法模拟人类的全身统一控制。

Method: 采用序列技能获取、残差动作建模、命令多项式插值等技术，实现端到端的统一控制。

Result: 在Unitree G1机器人上验证，ULC在跟踪精度、工作空间覆盖和鲁棒性上优于基线方法。

Conclusion: 统一控制框架可行且高效，为复杂运动与操纵任务提供了新思路。

Abstract: Loco-Manipulation for humanoid robots aims to enable robots to integrate
mobility with upper-body tracking capabilities. Most existing approaches adopt
hierarchical architectures that decompose control into isolated upper-body
(manipulation) and lower-body (locomotion) policies. While this decomposition
reduces training complexity, it inherently limits coordination between
subsystems and contradicts the unified whole-body control exhibited by humans.
We demonstrate that a single unified policy can achieve a combination of
tracking accuracy, large workspace, and robustness for humanoid
loco-manipulation. We propose the Unified Loco-Manipulation Controller (ULC), a
single-policy framework that simultaneously tracks root velocity, root height,
torso rotation, and dual-arm joint positions in an end-to-end manner, proving
the feasibility of unified control without sacrificing performance. We achieve
this unified control through key technologies: sequence skill acquisition for
progressive learning complexity, residual action modeling for fine-grained
control adjustments, command polynomial interpolation for smooth motion
transitions, random delay release for robustness to deploy variations, load
randomization for generalization to external disturbances, and
center-of-gravity tracking for providing explicit policy gradients to maintain
stability. We validate our method on the Unitree G1 humanoid robot with 3-DOF
(degrees-of-freedom) waist. Compared with strong baselines, ULC shows better
tracking performance to disentangled methods and demonstrating larger workspace
coverage. The unified dual-arm tracking enables precise manipulation under
external loads while maintaining coordinated whole-body control for complex
loco-manipulation tasks.

</details>


### [21] [Bounomodes: the grazing ox algorithm for exploration of clustered anomalies](https://arxiv.org/abs/2507.06960)
*Samuel Matloob,Ayan Dutta,O. Patrick Kreidl,Swapnonel Roy,Ladislau Bölöni*

Main category: cs.RO

TL;DR: 论文提出了一种名为“bounom=odes”的算法，结合均匀覆盖和异常区域探索，通过深度强化学习优化异常集群的探索，实验表明其优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统IPP算法（如boustrophedon）专注于均匀覆盖，但在异常集群场景中效果有限。因此，需要一种能兼顾均匀采样和针对性异常探索的方法。

Method: 提出“bounom=odes”算法，交替进行均匀采样和异常集群探索。异常探索行为通过深度强化学习学习。

Result: 实验证明，该方法在异常集群场景中优于传统基线算法。

Conclusion: 结合均匀采样和针对性探索的算法在IPP任务中更有效，深度强化学习是实现这一目标的关键。

Abstract: A common class of algorithms for informative path planning (IPP) follows
boustrophedon ("as the ox turns") patterns, which aim to achieve uniform area
coverage. However, IPP is often applied in scenarios where anomalies, such as
plant diseases, pollution, or hurricane damage, appear in clusters. In such
cases, prioritizing the exploration of anomalous regions over uniform coverage
is beneficial. This work introduces a class of algorithms referred to as
bounom\=odes ("as the ox grazes"), which alternates between uniform
boustrophedon sampling and targeted exploration of detected anomaly clusters.
While uniform sampling can be designed using geometric principles, close
exploration of clusters depends on the spatial distribution of anomalies and
must be learned. In our implementation, the close exploration behavior is
learned using deep reinforcement learning algorithms. Experimental evaluations
demonstrate that the proposed approach outperforms several established
baselines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [22] [Digital Wargames to Enhance Military Medical Evacuation Decision-Making](https://arxiv.org/abs/2507.06373)
*Jeremy Fischer,Ram Krishnamoorthy,Vishal Kumar,Mahdi Al-Husseini*

Main category: cs.AI

TL;DR: MEWI是一个基于Unity开发的3D多人模拟工具，用于模拟战场医疗后送网络，提升学员在课堂环境中的决策能力和规划能力。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏一种能在课堂环境中模拟医疗后送网络并评估规划和决策能力的工具，MEWI填补了这一空白。

Method: 开发了MEWI模拟工具，模拟战场约束和不确定性，包括伤员收集点、救护车交换点、医疗设施和后送平台。设计了太平洋两栖岛攻击和欧亚大陆冲突两个场景。

Result: MEWI显著提升了学员对医疗后送经验的学习吸收和协作决策能力。

Conclusion: MEWI是医疗教育高保真训练工具的重要进展，为联合部队的医疗后送教育和操作提供了关键改进方向。

Abstract: Medical evacuation is one of the United States Army's most storied and
critical mission sets, responsible for efficiently and expediently evacuating
the battlefield ill and injured. Medical evacuation planning involves designing
a robust network of medical platforms and facilities capable of moving and
treating large numbers of casualties. Until now, there has not been a medium to
simulate these networks in a classroom setting and evaluate both offline
planning and online decision-making performance. This work describes the
Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer
simulation developed in Unity that replicates battlefield constraints and
uncertainties. MEWI accurately models patient interactions at casualty
collection points, ambulance exchange points, medical treatment facilities, and
evacuation platforms. Two operational scenarios are introduced: an amphibious
island assault in the Pacific and a Eurasian conflict across a sprawling road
and river network. These scenarios pit students against the clock to save as
many casualties as possible while adhering to doctrinal lessons learned during
didactic training. We visualize performance data collected from two iterations
of the MEWI Pacific scenario executed in the United States Army's Medical
Evacuation Doctrine Course. We consider post-wargame Likert survey data from
student participants and external observer notes to identify key planning
decision points, document medical evacuation lessons learned, and quantify
general utility. Results indicate that MEWI participation substantially
improves uptake of medical evacuation lessons learned and co-operative
decision-making. MEWI is a substantial step forward in the field of
high-fidelity training tools for medical education, and our study findings
offer critical insights into improving medical evacuation education and
operations across the joint force.

</details>


### [23] [Representing Prompting Patterns with PDL: Compliance Agent Case Study](https://arxiv.org/abs/2507.06396)
*Mandana Vaziri,Louis Mandel,Yuji Watanabe,Hirokuni Kitahara,Martin Hirzel,Anca Sailer*

Main category: cs.AI

TL;DR: 提出了一种名为PDL的新型提示声明语言，旨在解决现有提示工程框架的复杂性和不灵活性问题，通过将提示置于核心位置，支持手动和自动调优，并整合LLM调用、规则代码和外部工具。


<details>
  <summary>Details</summary>
Motivation: 现有提示工程框架要么隐藏复杂性，要么提供不灵活的固定模式，难以支持复杂的代理编程需求。

Method: 开发了PDL（Prompt Declaration Language），通过声明式表示提示，抽象化组合逻辑，支持手动和自动调优。

Result: 通过实际案例（合规代理）验证，PDL的提示调优模式相比固定模式实现了高达4倍的性能提升。

Conclusion: PDL通过提升程序员生产力和优化提示表示，为复杂代理编程提供了一种有效的解决方案。

Abstract: Prompt engineering for LLMs remains complex, with existing frameworks either
hiding complexity behind restrictive APIs or providing inflexible canned
patterns that resist customization -- making sophisticated agentic programming
challenging. We present the Prompt Declaration Language (PDL), a novel approach
to prompt representation that tackles this fundamental complexity by bringing
prompts to the forefront, enabling manual and automatic prompt tuning while
capturing the composition of LLM calls together with rule-based code and
external tools. By abstracting away the plumbing for such compositions, PDL
aims at improving programmer productivity while providing a declarative
representation that is amenable to optimization. This paper demonstrates PDL's
utility through a real-world case study of a compliance agent. Tuning the
prompting pattern of this agent yielded up to 4x performance improvement
compared to using a canned agent and prompt pattern.

</details>


### [24] [Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI](https://arxiv.org/abs/2507.06398)
*David Orban*

Main category: cs.AI

TL;DR: 本文研究Jolting Technologies假说，提出AI能力发展的超指数增长模型，并通过模拟验证检测方法，为未来实证研究提供工具。


<details>
  <summary>Details</summary>
Motivation: 探讨AI能力是否呈现超指数增长（即加速增长），并分析其潜在影响。

Method: 开发理论框架，通过蒙特卡洛模拟验证检测方法，分析缩短的创意到行动间隔和AI迭代改进的复合效应。

Result: 通过模拟验证了检测方法的有效性，为理解AI发展轨迹及其对AGI的影响提供了数学基础。

Conclusion: 研究为未来实证研究提供了工具，并探讨了Jolting Technologies假说若成立的可能影响，对研究和政策具有启示意义。

Abstract: This paper investigates the Jolting Technologies Hypothesis, which posits
superexponential growth (increasing acceleration, or a positive third
derivative) in the development of AI capabilities. We develop a theoretical
framework and validate detection methodologies through Monte Carlo simulations,
while acknowledging that empirical validation awaits suitable longitudinal
data. Our analysis focuses on creating robust tools for future empirical
studies and exploring the potential implications should the hypothesis prove
valid. The study examines how factors such as shrinking idea-to-action
intervals and compounding iterative AI improvements drive this jolting pattern.
By formalizing jolt dynamics and validating detection methods through
simulation, this work provides the mathematical foundation necessary for
understanding potential AI trajectories and their consequences for AGI
emergence, offering insights for research and policy.

</details>


### [25] [Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)](https://arxiv.org/abs/2507.06798)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: 论文证明了q-辩证系统比p-辩证系统更强大，后者又比d-辩证系统更强，强调了反例和矛盾在自动信念修正中的互补作用。


<details>
  <summary>Details</summary>
Motivation: 研究辩证系统的不同模型，以理解其在自动信念修正和数学推理中的作用。

Method: 通过理论分析比较d-、p-和q-辩证系统的能力，证明q-辩证系统的优越性。

Result: q-辩证系统严格强于p-辩证系统，后者又严格强于d-辩证系统。

Conclusion: 反例和矛盾在信念修正中具有互补作用，q-辩证系统提供了更强大的框架。

Abstract: Dialectical systems are a mathematical formalism for modeling an agent
updating a knowledge base seeking consistency. Introduced in the 1970s by
Roberto Magari, they were originally conceived to capture how a working
mathematician or a research community refines beliefs in the pursuit of truth.
Dialectical systems also serve as natural models for the belief change of an
automated agent, offering a unifying, computable framework for dynamic belief
management.
  The literature distinguishes three main models of dialectical systems:
(d-)dialectical systems based on revising beliefs when they are seen to be
inconsistent, p-dialectical systems based on revising beliefs based on finding
a counterexample, and q-dialectical systems which can do both. We answer an
open problem in the literature by proving that q-dialectical systems are
strictly more powerful than p-dialectical systems, which are themselves known
to be strictly stronger than (d-)dialectical systems. This result highlights
the complementary roles of counterexample and contradiction in automated belief
revision, and thus also in the reasoning processes of mathematicians and
research communities.

</details>


### [26] [SCC-recursiveness in infinite argumentation (extended version)](https://arxiv.org/abs/2507.06852)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: 论文提出两种方法将SCC递归语义扩展到无限论证框架（AFs），并通过Baroni和Giacomin的标准评估其有效性，发现方向性在一般情况下失效，但在有限框架中部分语义满足方向性。


<details>
  <summary>Details</summary>
Motivation: SCC递归语义在有限AFs中表现良好，但在无限AFs中因基础性问题失效，需扩展其适用性。

Method: 提出两种扩展SCC递归语义的方法，并系统评估其满足Baroni和Giacomin标准的情况。

Result: 方向性在无限AFs中普遍失效，但在有限框架中部分语义满足方向性。

Conclusion: 研究为无限论证理论奠定基础，支持处理无界或动态领域的推理系统。

Abstract: Argumentation frameworks (AFs) are a foundational tool in artificial
intelligence for modeling structured reasoning and conflict. SCC-recursiveness
is a well-known design principle in which the evaluation of arguments is
decomposed according to the strongly connected components (SCCs) of the attack
graph, proceeding recursively from "higher" to "lower" components. While
SCC-recursive semantics such as \cft and \stgt have proven effective for finite
AFs, Baumann and Spanring showed the failure of SCC-recursive semantics to
generalize reliably to infinite AFs due to issues with well-foundedness.
  We propose two approaches to extending SCC-recursiveness to the infinite
setting. We systematically evaluate these semantics using Baroni and Giacomin's
established criteria, showing in particular that directionality fails in
general. We then examine these semantics' behavior in finitary frameworks,
where we find some of our semantics satisfy directionality. These results
advance the theory of infinite argumentation and lay the groundwork for
reasoning systems capable of handling unbounded or evolving domains.

</details>


### [27] [Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report](https://arxiv.org/abs/2507.06968)
*Li Du,Hanyu Zhao,Yiming Ju,Tengfei Pan*

Main category: cs.AI

TL;DR: 本文提出了一种系统化的指令数据构建框架，旨在提升指令数据的覆盖范围和深度，从而增强模型的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 当前指令数据集虽规模庞大，但在复杂指令和罕见领域任务上表现不佳，主要因覆盖范围和深度不足。

Method: 采用分层标注系统、信息种子选择算法、进化数据合成过程及模型缺陷诊断与针对性数据生成，形成闭环迭代框架。

Result: 构建了InfinityInstruct-Subject数据集（约150万指令），实验证明其在提升指令遵循能力上有效。

Conclusion: 该工作为指令数据集的高效持续进化提供了理论和实践基础，从数量扩展转向质量提升。

Abstract: Instruction tuning has become a foundation for unlocking the capabilities of
large-scale pretrained models and improving their performance on complex tasks.
Thus, the construction of high-quality instruction datasets is crucial for
enhancing model performance and generalizability. Although current instruction
datasets have reached tens of millions of samples, models finetuned on them may
still struggle with complex instruction following and tasks in rare domains.
This is primarily due to limited expansion in both ``coverage'' (coverage of
task types and knowledge areas) and ``depth'' (instruction complexity) of the
instruction set. To address this issue, we propose a systematic instruction
data construction framework, which integrates a hierarchical labeling system,
an informative seed selection algorithm, an evolutionary data synthesis
process, and a model deficiency diagnosis with targeted data generation. These
components form an iterative closed-loop to continuously enhance the coverage
and depth of instruction data. Based on this framework, we construct
InfinityInstruct-Subject, a high-quality dataset containing ~1.5 million
instructions. Experiments on multiple foundation models and benchmark tasks
demonstrate its effectiveness in improving instruction-following capabilities.
Further analyses suggest that InfinityInstruct-Subject shows enlarged coverage
and depth compared to comparable synthesized instruction datasets. Our work
lays a theoretical and practical foundation for the efficient, continuous
evolution of instruction datasets, moving from data quantity expansion to
qualitative improvement.

</details>


### [28] [The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation](https://arxiv.org/abs/2507.06993)
*Jieren Deng,Aleksandar Cvetkovic,Pak Kiu Chung,Dragomir Yankov,Chiqun Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种动态旅行规划系统，通过三个协作代理解决传统系统的不足，显著提升了查询解释、导航准确性和抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 传统旅行规划系统静态且碎片化，无法应对现实世界中的复杂性和突发状况，导致用户体验不佳。

Method: 提出三个协作代理：旅行规划代理（基于网格空间定位和地图分析）、目的地助手代理（提供精细导航）、本地发现代理（利用图像嵌入和RAG技术应对行程中断）。

Result: 系统在查询解释、导航准确性和抗干扰能力方面表现出显著改进。

Conclusion: 该系统在从城市探索到应急响应等多种应用中具有广阔前景。

Abstract: Traditional travel-planning systems are often static and fragmented, leaving
them ill-equipped to handle real-world complexities such as evolving
environmental conditions and unexpected itinerary disruptions. In this paper,
we identify three gaps between existing service providers causing frustrating
user experience: intelligent trip planning, precision "last-100-meter"
navigation, and dynamic itinerary adaptation. We propose three cooperative
agents: a Travel Planning Agent that employs grid-based spatial grounding and
map analysis to help resolve complex multi-modal user queries; a Destination
Assistant Agent that provides fine-grained guidance for the final navigation
leg of each journey; and a Local Discovery Agent that leverages image
embeddings and Retrieval-Augmented Generation (RAG) to detect and respond to
trip plan disruptions. With evaluations and experiments, our system
demonstrates substantial improvements in query interpretation, navigation
accuracy, and disruption resilience, underscoring its promise for applications
from urban exploration to emergency response.

</details>


### [29] [First Return, Entropy-Eliciting Explore](https://arxiv.org/abs/2507.07017)
*Tianyu Zheng,Tianshun Xing,Qingshui Gu,Taoran Liang,Xingwei Qu,Xin Zhou,Yizhi Li,Zhoufutu Wen,Chenghua Lin,Wenhao Huang,Qian Liu,Ge Zhang,Zejun Ma*

Main category: cs.AI

TL;DR: FR3E框架通过结构化探索提升LLM推理能力，解决RLVR的不稳定探索问题。


<details>
  <summary>Details</summary>
Motivation: RLVR在提升LLM推理能力时存在探索不稳定的问题，需要更有效的探索方法。

Method: 提出FR3E框架，识别高不确定性决策点，进行针对性探索并构建语义化中间反馈。

Result: 在数学推理基准测试中，FR3E提升训练稳定性、生成更长且连贯的回答，并增加完全正确轨迹的比例。

Conclusion: FR3E通过结构化探索显著提升LLM推理能力。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning
abilities of Large Language Models (LLMs) but it struggles with unstable
exploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a
structured exploration framework that identifies high-uncertainty decision
points in reasoning trajectories and performs targeted rollouts to construct
semantically grounded intermediate feedback. Our method provides targeted
guidance without relying on dense supervision. Empirical results on
mathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable
training, produces longer and more coherent responses, and increases the
proportion of fully correct trajectories. These results highlight the
framework's effectiveness in improving LLM reasoning through more robust and
structured exploration.

</details>
