<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 55]
- [cs.RO](#cs.RO) [Total: 47]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video](https://arxiv.org/abs/2508.11836)
*Dave Goel,Matthew Guzdial,Anurag Sarkar*

Main category: cs.AI

TL;DR: 本文提出FAE方法，从游戏视频中学习神经符号世界模型，使用新的领域特定语言Retro Coder表示，相比现有方法能学习更精确的环境模型和更通用的代码


<details>
  <summary>Details</summary>
Motivation: 现有世界模型通常是神经网络表示，难以迁移学习到的环境动态和解释。需要一种既能保持神经网络学习能力又具有符号表示可解释性的方法

Method: 提出有限自动机提取(FAE)方法，从游戏视频中学习神经符号世界模型，使用新型领域特定语言Retro Coder将学习到的表示表示为程序

Result: 相比现有世界模型方法，FAE能学习到更精确的环境模型；相比现有基于DSL的方法，能生成更通用的代码

Conclusion: FAE方法成功地将神经网络的表示学习能力与符号表示的可解释性相结合，为世界模型学习提供了新的有效途径

Abstract: World models are defined as a compressed spatial and temporal learned
representation of an environment. The learned representation is typically a
neural network, making transfer of the learned environment dynamics and
explainability a challenge. In this paper, we propose an approach, Finite
Automata Extraction (FAE), that learns a neuro-symbolic world model from
gameplay video represented as programs in a novel domain-specific language
(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more
precise model of the environment and more general code than prior DSL-based
approaches.

</details>


### [2] [EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models](https://arxiv.org/abs/2508.11850)
*Milad Yazdani,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: EvoCut是一个自动化生成整数规划加速割的框架，结合大语言模型和进化搜索，无需人工专家输入即可生成有效的不等式，显著提升求解器性能


<details>
  <summary>Details</summary>
Motivation: 整数规划作为组合优化的核心问题具有NP难特性，传统方法依赖专家手动设计加速割，这一过程需要深厚专业知识且难以自动化

Method: 结合大语言模型和进化搜索：1）LLM初始化多样化候选割；2）评估割的可行性和有效性；3）通过进化交叉和变异迭代优化种群

Result: 相比标准整数规划方法，EvoCut在固定时间内将最优性间隙降低17-57%，获得相同解的速度提升4倍，在相同时间内获得更高质量解

Conclusion: EvoCut能够可靠地生成、改进和验证可泛化到未见实例的割，为整数规划自动化提供了有效解决方案

Abstract: Integer programming lies at the heart of crucial combinatorial optimization
tasks but remains challenging due to its NP-hard nature. An effective approach
for practically solving integer programs is the manual design of acceleration
cuts, i.e. inequalities that improve solver performance. However, this creative
process demands deep expertise and is yet to be automated. Our proposed
framework, EvoCut, automates the generation of acceleration cuts by combining
large language models (LLMs) with an evolutionary search. EvoCut (i)
initializes a diverse population of candidate cuts via an LLM-based initializer
agent; (ii) for each cut empirically evaluates both preservation of the optimal
solution and its ability to cut off fractional solutions across a verification
set; and (iii) iteratively refines the population through evolutionary
crossover and mutation agents. We quantify each cut's utility by its relative
reduction in the solver's optimality gap. Our comparisons against standard
integer programming practice show that EvoCut reduces optimality gap by 17-57%
within a fixed time. It obtains the same solutions up to 4 times as fast, and
obtains higher-quality solutions within the same time limit. Requiring no human
expert input, EvoCut reliably generates, improves, and empirically verifies
cuts that generalize to unseen instances. The code is available at
https://github.com/milad1378yz/EvoCut.

</details>


### [3] [LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](https://arxiv.org/abs/2508.11860)
*Frazier N. Baker,Daniel Adu-Ampratwum,Reza Averly,Botao Yu,Huan Sun,Xia Ning*

Main category: cs.AI

TL;DR: LARC是首个基于LLM的约束逆合成规划代理框架，通过工具驱动的智能体评估机制，在化学合成路线规划中实现72.9%的成功率，接近专家水平但耗时更少


<details>
  <summary>Details</summary>
Motivation: 化学逆合成规划在商业可用起始原料到目标分子的合成路线识别中面临实际约束的挑战，需要智能化的约束评估和规划方法

Method: 采用LLM代理评估器，通过Agent-as-a-Judge机制将基于工具推理的智能体反馈直接整合到逆合成规划过程中，指导并约束路线生成

Result: 在48个约束逆合成规划任务上达到72.9%的成功率，显著优于LLM基线方法，在更短时间内接近人类专家水平

Conclusion: LARC框架具有可扩展性，是向有效智能体工具或人类专家协作者迈出的重要一步，为约束逆合成规划提供了新的解决方案

Abstract: Large language model (LLM) agent evaluators leverage specialized tools to
ground the rational decision-making of LLMs, making them well-suited to aid in
scientific discoveries, such as constrained retrosynthesis planning.
Constrained retrosynthesis planning is an essential, yet challenging, process
within chemistry for identifying synthetic routes from commercially available
starting materials to desired target molecules, subject to practical
constraints. Here, we present LARC, the first LLM-based Agentic framework for
Retrosynthesis planning under Constraints. LARC incorporates agentic constraint
evaluation, through an Agent-as-a-Judge, directly into the retrosynthesis
planning process, using agentic feedback grounded in tool-based reasoning to
guide and constrain route generation. We rigorously evaluate LARC on a
carefully curated set of 48 constrained retrosynthesis planning tasks across 3
constraint types. LARC achieves a 72.9% success rate on these tasks, vastly
outperforming LLM baselines and approaching human expert-level success in
substantially less time. The LARC framework is extensible, and serves as a
first step towards an effective agentic tool or a co-scientist to human experts
for constrained retrosynthesis.

</details>


### [4] [QuarkMed Medical Foundation Model Technical Report](https://arxiv.org/abs/2508.11894)
*Ao Li,Bin Yan,Bingfeng Cai,Chenxi Li,Cunzhong Zhao,Fugen Yao,Gaoqiang Liu,Guanjun Jiang,Jian Xu,Liang Dong,Liansheng Sun,Rongshen Zhang,Xiaolei Gui,Xin Liu,Xin Shang,Yao Wu,Yu Cao,Zhenxin Ma,Zhuang Jia*

Main category: cs.AI

TL;DR: QuarkMed是一个高性能医疗基础模型，通过医学数据处理、检索增强生成和大规模强化学习，在中国执业医师考试中达到70%准确率，已服务数百万用户。


<details>
  <summary>Details</summary>
Motivation: 医疗任务需要高度专业化的知识、专业准确性和定制能力，现有大语言模型在医疗应用中需要更可靠的基础模型支持。

Method: 利用精选医学数据处理、医学内容检索增强生成(RAG)和大规模可验证强化学习管道来开发医疗基础模型。

Result: 在中国医学执照考试中达到70%的准确率，在多样化医疗基准测试中表现出强大的泛化能力。

Conclusion: QuarkMed提供了一个强大而通用的个人医疗AI解决方案，已在ai.quark.cn服务超过百万用户。

Abstract: Recent advancements in large language models have significantly accelerated
their adoption in healthcare applications, including AI-powered medical
consultations, diagnostic report assistance, and medical search tools. However,
medical tasks often demand highly specialized knowledge, professional accuracy,
and customization capabilities, necessitating a robust and reliable foundation
model. QuarkMed addresses these needs by leveraging curated medical data
processing, medical-content Retrieval-Augmented Generation (RAG), and a
large-scale, verifiable reinforcement learning pipeline to develop a
high-performance medical foundation model. The model achieved 70% accuracy on
the Chinese Medical Licensing Examination, demonstrating strong generalization
across diverse medical benchmarks. QuarkMed offers a powerful yet versatile
personal medical AI solution, already serving over millions of users at
ai.quark.cn.

</details>


### [5] [CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs](https://arxiv.org/abs/2508.11944)
*Hongtao Liu,Zhicheng Du,Zihe Wang,Weiran Shen*

Main category: cs.AI

TL;DR: 提出了CHBench评估框架，基于认知层次模型评估LLMs的战略推理能力，发现聊天机制会降低推理水平而记忆机制能提升推理能力


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖效用性能指标评估LLMs的游戏能力，但这些指标不够稳健，受对手行为和游戏结构变化影响较大

Method: 采用三阶段系统框架，基于行为经济学中的认知层次模型，在15个精选的正规形式游戏中分析6个最先进LLMs的行为数据

Result: 实验显示LLMs在不同对手间展现出一致的战略推理水平，聊天机制显著降低战略推理能力，而记忆机制能增强推理能力

Conclusion: CHBench是一个有前景的LLM能力评估工具，对未来研究和实际应用具有重要潜力

Abstract: Game-playing ability serves as an indicator for evaluating the strategic
reasoning capability of large language models (LLMs). While most existing
studies rely on utility performance metrics, which are not robust enough due to
variations in opponent behavior and game structure. To address this limitation,
we propose \textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation
framework inspired by the cognitive hierarchy models from behavioral economics.
We hypothesize that agents have bounded rationality -- different agents behave
at varying reasoning depths/levels. We evaluate LLMs' strategic reasoning
through a three-phase systematic framework, utilizing behavioral data from six
state-of-the-art LLMs across fifteen carefully selected normal-form games.
Experiments show that LLMs exhibit consistent strategic reasoning levels across
diverse opponents, confirming the framework's robustness and generalization
capability. We also analyze the effects of two key mechanisms (Chat Mechanism
and Memory Mechanism) on strategic reasoning performance. Results indicate that
the Chat Mechanism significantly degrades strategic reasoning, whereas the
Memory Mechanism enhances it. These insights position CHBench as a promising
tool for evaluating LLM capabilities, with significant potential for future
research and practical applications.

</details>


### [6] [Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models](https://arxiv.org/abs/2508.11953)
*Yuan Li,Zhengzhong Liu,Eric Xing*

Main category: cs.AI

TL;DR: 本文提出了一种优化监督微调数据混合比例的新方法，通过建模有效数据传输和利用缩放定律来最小化验证损失，实验证明该方法性能接近网格搜索最优解。


<details>
  <summary>Details</summary>
Motivation: 优化大型语言模型监督微调的数据混合比例对于开发通用模型至关重要，但这一领域尚未得到充分探索。

Method: 将数据混合构建为优化问题，通过参数化损失函数建模有效数据传输，利用缩放定律进行微调，通过小规模数据混合实验拟合参数并推导最优权重。

Result: 算法在所有领域都实现了优异的整体和个体性能，优化权重训练的模型性能与网格搜索确定的最优权重相当，平均每域损失仅比网格搜索最佳域损失高0.66%。重新加权流行SFT数据集改善了验证损失和下游性能。

Conclusion: 该方法可推广用于指导领域特定模型的数据选择，并为监督微调提供了新的见解。

Abstract: Optimizing data mixtures for supervised fine-tuning (SFT) of large language
models (LLMs) is critical for developing general-purpose models, yet this area
remains underexplored. In this paper, we frame data mixing as an optimization
problem and introduce a novel method designed to minimize validation loss. Our
approach parametrizes the loss by modeling effective data transferred and
leveraging scaling laws for fine-tuning. By experimenting with various
small-scale data mixtures, we fit these parameters and derive the optimal
weights. We provide both mathematical proofs and empirical results
demonstrating that our algorithm achieves excellent overall and individual
performance across all domains. Through controlled experiments, we show that
models trained with our optimized weights perform on par with those using
optimal weights determined via grid search, with per-domain loss only 0.66%
higher than the best domain loss from grid search on average. Additionally, we
show that reweighting popular SFT datasets using our method improves both
validation loss and downstream performance. Finally, we discuss how our method
can generalize to guide data selection for domain-specific models and provide
insights into SFT.

</details>


### [7] [UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting](https://arxiv.org/abs/2508.11954)
*Sehyuk Park,Soyeon Caren Han,Eduard Hovy*

Main category: cs.AI

TL;DR: UniCast是一个参数高效的多模态时间序列预测框架，通过软提示调优将视觉和文本模态与时间序列基础模型结合，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型主要在单模态设置下运行，忽略了现实场景中常伴随时间序列数据的丰富多模态上下文（如视觉和文本信号），这限制了预测性能的进一步提升。

Method: 提出UniCast框架，使用预训练的视觉和文本编码器提取模态特定嵌入，通过软提示调优技术与冻结的时间序列基础模型集成，实现高效的跨模态交互和最小参数更新。

Result: 在多个时间序列预测基准测试中，UniCast始终显著优于所有现有的时间序列基础模型基线方法。

Conclusion: 多模态上下文在推进下一代通用时间序列预测器发展中起着关键作用，UniCast框架为多模态时间序列预测提供了有效的解决方案。

Abstract: Time series forecasting is a foundational task across domains, such as
finance, healthcare, and environmental monitoring. While recent advances in
Time Series Foundation Models (TSFMs) have demonstrated strong generalisation
through large-scale pretraining, existing models operate predominantly in a
unimodal setting, ignoring the rich multimodal context, such as visual and
textual signals, that often accompanies time series data in real-world
scenarios. This paper introduces a novel parameter-efficient multimodal
framework, UniCast, that extends TSFMs to jointly leverage time series, vision,
and text modalities for enhanced forecasting performance. Our method integrates
modality-specific embeddings from pretrained Vision and Text Encoders with a
frozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal
parameter updates. This design not only preserves the generalisation strength
of the foundation model but also enables effective cross-modal interaction.
Extensive experiments across diverse time-series forecasting benchmarks
demonstrate that UniCast consistently and significantly outperforms all
existing TSFM baselines. The findings highlight the critical role of multimodal
context in advancing the next generation of general-purpose time series
forecasters.

</details>


### [8] [Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index](https://arxiv.org/abs/2508.11959)
*Xuanxiang Huang,Olivier Létoffé,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文基于博弈论提出两种新的特征重要性评分方法，利用Shapley值和Banzhaf指数，在计算特征贡献时考虑非弱溯因解释集，量化特征排除对抗样本的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于逻辑解释的特征归因方法主要关注弱溯因解释(WAXp)集，但忽略了非WAXp集的重要性。非WAXp集与对抗样本(AExs)存在重要关联，需要更全面的特征重要性评估方法。

Method: 利用博弈论中的Shapley值和Banzhaf指数，在特征重要性计算中纳入非弱溯因解释集的贡献，设计新的特征评分机制来量化特征排除对抗样本的能力。

Result: 提出了两种新颖的特征重要性评分方法，能够更全面地评估特征在模型解释和对抗样本防御中的作用，并分析了这些评分方法的性质和计算复杂度。

Conclusion: 通过考虑非WAXp集的特征贡献，新的评分方法提供了更完整的特征重要性评估框架，有助于提高高风险机器学习应用的可解释性和鲁棒性。

Abstract: Feature attribution methods based on game theory are ubiquitous in the field
of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous
feature attribution using logic-based explanations, specifically targeting
high-stakes uses of machine learning (ML) models. Typically, such works exploit
weak abductive explanation (WAXp) as the characteristic function to assign
importance to features. However, one possible downside is that the contribution
of non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important
information, because of the relationship between formal explanations (XPs) and
adversarial examples (AExs). Accordingly, this paper leverages Shapley value
and Banzhaf index to devise two novel feature importance scores. We take into
account non-WAXp sets when computing feature contribution, and the novel scores
quantify how effective each feature is at excluding AExs. Furthermore, the
paper identifies properties and studies the computational complexity of the
proposed scores.

</details>


### [9] [Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering](https://arxiv.org/abs/2508.11975)
*Gongyao Jiang,Qiong Luo*

Main category: cs.AI

TL;DR: 该论文提出了一种通过代码生成和执行的图表合成管道来生成对齐的图表-问题-回答三元组，并设计了候选条件回答过程，使VLM能够自我改进，在无需人工标注数据或外部模型的情况下显著提升图表理解性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在图表理解任务中表现不佳，特别是在准确描述和复杂推理方面。合成数据生成是解决方案，但通常面临噪声标签的挑战。

Method: 1) 引入图表合成管道，通过代码生成和执行生成对齐的图表-问题-回答三元组；2) 设计候选条件回答过程，VLM首先生成多个响应，然后通过上下文整合这些候选答案来合成最终答案。

Result: 实验显示显著改进，在完全自我改进的范式下，比初始VLM获得了高达15.50个百分点的准确率提升。

Conclusion: 该方法在无需人工标注数据或外部模型的情况下，成功实现了VLM的自我改进，显著提升了图表理解任务的性能。

Abstract: Vision Language Models (VLMs) often struggle with chart understanding tasks,
particularly in accurate chart description and complex reasoning. Synthetic
data generation is a promising solution, while usually facing the challenge of
noise labels. To address this challenge, we first introduce a chart synthesis
pipeline that generates aligned chart-question-answer triplets through code
generation and execution, ensuring the reliability of synthetic data without
human intervention. Furthermore, inspired by test-time scaling that increases
inference budget and thereby improves performance, we design a
candidate-conditioned answering process. The VLM first generates multiple
responses per query, and then synthesizes the final answer by contextualizing
these candidates. Experiments demonstrate significant improvements, with up to
15.50 points accuracy gain over the initial VLM, in a fully self-improving
paradigm without either human-labeled data or external models.

</details>


### [10] [FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction](https://arxiv.org/abs/2508.11987)
*Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX是一个专门为LLM智能体设计的动态实时未来预测评估基准，支持每日实时更新，通过自动化流程消除数据污染，评估了25个模型在动态环境中的自适应推理能力。


<details>
  <summary>Details</summary>
Motivation: 未来预测对LLM智能体是复杂任务，需要高水平分析思维和信息处理能力，但目前缺乏大规模评估基准，主要由于处理实时更新和获取及时准确答案的挑战。

Method: 构建FutureX动态实时评估基准，支持每日自动更新，通过自动化问题收集和答案收集流程消除数据污染，评估25个LLM/智能体模型（包括具有推理、搜索能力和外部工具集成的模型）。

Result: 进行了全面的评估，分析了智能体在动态环境中的自适应推理和性能表现，深入研究了智能体在未来导向任务中的失败模式和性能缺陷（包括对虚假网页的脆弱性和时间有效性）。

Conclusion: 目标是建立一个动态、无污染的评估标准，推动LLM智能体在复杂推理和预测思维方面达到专业人类分析师的水平。

Abstract: Future prediction is a complex task for LLM agents, requiring a high level of
analytical thinking, information gathering, contextual understanding, and
decision-making under uncertainty. Agents must not only gather and interpret
vast amounts of dynamic information but also integrate diverse data sources,
weigh uncertainties, and adapt predictions based on emerging trends, just as
human experts do in fields like politics, economics, and finance. Despite its
importance, no large-scale benchmark exists for evaluating agents on future
prediction, largely due to challenges in handling real-time updates and
retrieving timely, accurate answers. To address this, we introduce
$\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically
designed for LLM agents performing future prediction tasks. FutureX is the
largest and most diverse live benchmark for future prediction, supporting
real-time daily updates and eliminating data contamination through an automated
pipeline for question gathering and answer collection. We evaluate 25 LLM/agent
models, including those with reasoning, search capabilities, and integration of
external tools such as the open-source Deep Research Agent and closed-source
Deep Research models. This comprehensive evaluation assesses agents' adaptive
reasoning and performance in dynamic environments. Additionally, we provide
in-depth analyses of agents' failure modes and performance pitfalls in
future-oriented tasks, including the vulnerability to fake web pages and the
temporal validity. Our goal is to establish a dynamic, contamination-free
evaluation standard that drives the development of LLM agents capable of
performing at the level of professional human analysts in complex reasoning and
predictive thinking.

</details>


### [11] [Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network](https://arxiv.org/abs/2508.11991)
*Weihao Sun*

Main category: cs.AI

TL;DR: AIGer是一个用于And-Inverter Graphs (AIGs)建模的新方法，通过节点逻辑特征初始化和异构图卷积网络，有效联合建模功能与结构特征，在信号概率预测和真值表距离预测任务中显著优于现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界AIGs因结构复杂、节点规模大而难以准确建模的问题，现有方法缺乏功能与结构特征的联合建模能力以及动态信息传播能力不足。

Method: 1) 节点逻辑特征初始化嵌入组件：将逻辑节点投影到独立语义空间；2) AIGs特征学习网络组件：使用异构图卷积网络，设计动态关系权重矩阵和差异化信息聚合方法。

Result: 在信号概率预测任务中，MAE和MSE分别提升18.95%和44.44%；在真值表距离预测任务中，MAE和MSE分别提升33.57%和14.79%。

Conclusion: AIGer通过创新的节点嵌入和异构图学习方法，成功解决了AIGs建模中的关键挑战，在EDA领域展现出优异的性能表现。

Abstract: The automation of logic circuit design enhances chip performance, energy
efficiency, and reliability, and is widely applied in the field of Electronic
Design Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,
optimize, and verify the functional characteristics of digital circuits,
enhancing the efficiency of EDA development.Due to the complex structure and
large scale of nodes in real-world AIGs, accurate modeling is challenging,
leading to existing work lacking the ability to jointly model functional and
structural characteristics, as well as insufficient dynamic information
propagation capability.To address the aforementioned challenges, we propose
AIGer.Specifically, AIGer consists of two components: 1) Node logic feature
initialization embedding component and 2) AIGs feature learning network
component.The node logic feature initialization embedding component projects
logic nodes, such as AND and NOT, into independent semantic spaces, to enable
effective node embedding for subsequent processing.Building upon this, the AIGs
feature learning network component employs a heterogeneous graph convolutional
network, designing dynamic relationship weight matrices and differentiated
information aggregation approaches to better represent the original structure
and information of AIGs.The combination of these two components enhances
AIGer's ability to jointly model functional and structural characteristics and
improves its message passing capability. Experimental results indicate that
AIGer outperforms the current best models in the Signal Probability Prediction
(SSP) task, improving MAE and MSE by 18.95\% and 44.44\%, respectively. In the
Truth Table Distance Prediction (TTDP) task, AIGer achieves improvements of
33.57\% and 14.79\% in MAE and MSE, respectively, compared to the
best-performing models.

</details>


### [12] [AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning](https://arxiv.org/abs/2508.11995)
*Xuyang Zhao,Shiwan Zhao,Hualong Yu,Liting Zhang,Qicheng Li*

Main category: cs.AI

TL;DR: AgentCDM是一个基于认知科学中竞争假设分析(ACH)的结构化框架，用于提升LLM多智能体系统中的协作决策质量，通过两阶段训练有效减轻认知偏见并实现主动假设评估。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统的协作决策方法存在缺陷：要么依赖单个智能体的'独裁'策略（易受认知偏见影响），要么采用'投票'方法（无法充分利用集体智慧），需要更有效的协作决策框架。

Method: 提出AgentCDM框架，借鉴认知科学中的竞争假设分析(ACH)方法，采用结构化推理范式。使用两阶段训练：第一阶段使用ACH启发的显式支架指导模型进行结构化推理，第二阶段逐步移除支架以促进自主泛化。

Result: 在多个基准数据集上的实验表明，AgentCDM实现了最先进的性能，并展现出强大的泛化能力，验证了其在提高多智能体系统协作决策质量和鲁棒性方面的有效性。

Conclusion: AgentCDM通过结构化推理范式和渐进式训练方法，成功解决了LLM多智能体系统中协作决策的挑战，为提升集体决策质量提供了有效解决方案。

Abstract: Multi-agent systems (MAS) powered by large language models (LLMs) hold
significant promise for solving complex decision-making tasks. However, the
core process of collaborative decision-making (CDM) within these systems
remains underexplored. Existing approaches often rely on either ``dictatorial"
strategies that are vulnerable to the cognitive biases of a single agent, or
``voting-based" methods that fail to fully harness collective intelligence. To
address these limitations, we propose \textbf{AgentCDM}, a structured framework
for enhancing collaborative decision-making in LLM-based multi-agent systems.
Drawing inspiration from the Analysis of Competing Hypotheses (ACH) in
cognitive science, AgentCDM introduces a structured reasoning paradigm that
systematically mitigates cognitive biases and shifts decision-making from
passive answer selection to active hypothesis evaluation and construction. To
internalize this reasoning process, we develop a two-stage training paradigm:
the first stage uses explicit ACH-inspired scaffolding to guide the model
through structured reasoning, while the second stage progressively removes this
scaffolding to encourage autonomous generalization. Experiments on multiple
benchmark datasets demonstrate that AgentCDM achieves state-of-the-art
performance and exhibits strong generalization, validating its effectiveness in
improving the quality and robustness of collaborative decisions in MAS.

</details>


### [13] [AI Models for Depressive Disorder Detection and Diagnosis: A Review](https://arxiv.org/abs/2508.12022)
*Dorsa Macky Aleagha,Payam Zohari,Mostafa Haghir Chehreghani*

Main category: cs.AI

TL;DR: 本文对55项关键研究进行系统综述，提出了基于临床任务、数据模态和计算模型的分层分类法，总结了抑郁症AI诊断领域的主要趋势和挑战。


<details>
  <summary>Details</summary>
Motivation: 抑郁症是全球主要致残原因，但诊断仍依赖主观临床评估。AI技术有望开发客观、可扩展和及时的诊断工具，需要系统梳理当前研究进展。

Method: 通过对55项关键研究的系统综述，建立了分层分类法（临床任务×数据模态×计算模型），分析主要技术趋势和数据集评估指标。

Result: 发现三大趋势：图神经网络在脑连接建模中的主导地位、大语言模型在语言数据处理中的兴起，以及多模态融合、可解释性和算法公平性的新兴关注。

Conclusion: 本综述为计算精神病学领域的未来创新提供了全面路线图，强调了多模态融合、可解释性和公平性等开放挑战的重要性。

Abstract: Major Depressive Disorder is one of the leading causes of disability
worldwide, yet its diagnosis still depends largely on subjective clinical
assessments. Integrating Artificial Intelligence (AI) holds promise for
developing objective, scalable, and timely diagnostic tools. In this paper, we
present a comprehensive survey of state-of-the-art AI methods for depression
detection and diagnosis, based on a systematic review of 55 key studies. We
introduce a novel hierarchical taxonomy that structures the field by primary
clinical task (diagnosis vs. prediction), data modality (text, speech,
neuroimaging, multimodal), and computational model class (e.g., graph neural
networks, large language models, hybrid approaches). Our in-depth analysis
reveals three major trends: the predominance of graph neural networks for
modeling brain connectivity, the rise of large language models for linguistic
and conversational data, and an emerging focus on multimodal fusion,
explainability, and algorithmic fairness. Alongside methodological insights, we
provide an overview of prominent public datasets and standard evaluation
metrics as a practical guide for researchers. By synthesizing current advances
and highlighting open challenges, this survey offers a comprehensive roadmap
for future innovation in computational psychiatry.

</details>


### [14] [Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems](https://arxiv.org/abs/2508.12026)
*Szymon Pawlonka,Mikołaj Małkiński,Jacek Mańdziuk*

Main category: cs.AI

TL;DR: Bongard-RWR+是一个包含5400个实例的抽象视觉推理数据集，使用VLM生成真实世界图像来代表原始Bongard问题的抽象概念，评估显示VLMs在细粒度概念识别上存在困难


<details>
  <summary>Details</summary>
Motivation: 现有的Bongard问题数据集要么使用合成图像不能完全捕捉真实世界复杂性，要么使用真实图像但概念可从高层特征识别降低了任务难度，而Bongard-RWR数据集虽使用细粒度真实图像但规模太小（仅60个实例）

Method: 基于Bongard-RWR，使用Pixtral-12B描述手动策划的图像并生成与底层概念对齐的新描述，使用Flux.1-dev从这些描述合成图像，并手动验证生成图像是否忠实反映预期概念

Result: 评估最先进VLMs在多种Bongard问题表述（包括二元和多类分类以及文本答案生成）上的表现，发现VLMs能识别粗粒度视觉概念，但在辨别细粒度概念方面持续困难

Conclusion: VLMs在抽象视觉推理方面存在局限性，特别是在细粒度概念识别上表现不佳，突显了其推理能力的不足

Abstract: Bongard Problems (BPs) provide a challenging testbed for abstract visual
reasoning (AVR), requiring models to identify visual concepts fromjust a few
examples and describe them in natural language. Early BP benchmarks featured
synthetic black-and-white drawings, which might not fully capture the
complexity of real-world scenes. Subsequent BP datasets employed real-world
images, albeit the represented concepts are identifiable from high-level image
features, reducing the task complexity. Differently, the recently released
Bongard-RWR dataset aimed at representing abstract concepts formulated in the
original BPs using fine-grained real-world images. Its manual construction,
however, limited the dataset size to just $60$ instances, constraining
evaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset
composed of $5\,400$ instances that represent original BP abstract concepts
using real-world-like images generated via a vision language model (VLM)
pipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually
curated images and generate new descriptions aligned with the underlying
concepts, use Flux.1-dev to synthesize images from these descriptions, and
manually verify that the generated images faithfully reflect the intended
concepts. We evaluate state-of-the-art VLMs across diverse BP formulations,
including binary and multiclass classification, as well as textual answer
generation. Our findings reveal that while VLMs can recognize coarse-grained
visual concepts, they consistently struggle with discerning fine-grained
concepts, highlighting limitations in their reasoning capabilities.

</details>


### [15] [Active inference for action-unaware agents](https://arxiv.org/abs/2508.12027)
*Filippo Torresan,Keisuke Suzuki,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 本文比较了主动推理中动作感知与动作无感知智能体在导航任务中的性能表现，发现动作无感知智能体虽然处于严重劣势但仍能达到与动作感知智能体相当的性能水平。


<details>
  <summary>Details</summary>
Motivation: 主动推理框架中，不同策略对智能体如何规划未来行动存在分歧，特别是在是否利用自身动作知识（efference copy信号）方面存在差异，需要比较这两种方法的实际性能表现。

Method: 通过两个导航任务对比动作感知（知道自身动作）和动作无感知（需要从观测推断动作）智能体的性能表现，分析它们在主动推理框架下的行为差异。

Result: 动作无感知智能体虽然处于严重劣势，但在导航任务中能够达到与动作感知智能体相当的性能水平。

Conclusion: 即使没有动作知识，智能体仍能通过从观测中推断动作来实现有效的规划和控制，这为理解运动控制机制提供了重要见解。

Abstract: Active inference is a formal approach to study cognition based on the notion
that adaptive agents can be seen as engaging in a process of approximate
Bayesian inference, via the minimisation of variational and expected free
energies. Minimising the former provides an account of perceptual processes and
learning as evidence accumulation, while minimising the latter describes how
agents select their actions over time. In this way, adaptive agents are able to
maximise the likelihood of preferred observations or states, given a generative
model of the environment. In the literature, however, different strategies have
been proposed to describe how agents can plan their future actions. While they
all share the notion that some kind of expected free energy offers an
appropriate way to score policies, sequences of actions, in terms of their
desirability, there are different ways to consider the contribution of past
motor experience to the agent's future behaviour. In some approaches, agents
are assumed to know their own actions, and use such knowledge to better plan
for the future. In other approaches, agents are unaware of their actions, and
must infer their motor behaviour from recent observations in order to plan for
the future. This difference reflects a standard point of departure in two
leading frameworks in motor control based on the presence, or not, of an
efference copy signal representing knowledge about an agent's own actions. In
this work we compare the performances of action-aware and action-unaware agents
in two navigations tasks, showing how action-unaware agents can achieve
performances comparable to action-aware ones while at a severe disadvantage.

</details>


### [16] [MAPF-World: Action World Model for Multi-Agent Path Finding](https://arxiv.org/abs/2508.12087)
*Zhanjiang Yang,Meng Li,Yang Shen,Yueming Li,Lijun Sun*

Main category: cs.AI

TL;DR: MAPF-World是一个用于多智能体路径规划的自回归动作世界模型，通过统一情境理解和动作生成，在复杂环境中实现更远见的决策，显著优于现有可学习求解器。


<details>
  <summary>Details</summary>
Motivation: 现有分散式可学习求解器在复杂长期规划场景中表现受限，主要因为缺乏对环境时间动态和智能体间依赖关系的建模，导致性能下降。

Method: 提出自回归动作世界模型MAPF-World，通过未来状态和动作预测显式建模环境动态（空间特征和时间依赖），将情境理解与动作生成统一。

Result: MAPF-World在零样本泛化到分布外案例方面优于最先进的可学习求解器，模型大小减少96.5%，数据需求减少92%。

Conclusion: MAPF-World通过建模环境动态和未来预测，实现了更明智、协调和远见的决策，为大规模MAPF问题提供了有效的解决方案。

Abstract: Multi-agent path finding (MAPF) is the problem of planning conflict-free
paths from the designated start locations to goal positions for multiple
agents. It underlies a variety of real-world tasks, including multi-robot
coordination, robot-assisted logistics, and social navigation. Recent
decentralized learnable solvers have shown great promise for large-scale MAPF,
especially when leveraging foundation models and large datasets. However, these
agents are reactive policy models and exhibit limited modeling of environmental
temporal dynamics and inter-agent dependencies, resulting in performance
degradation in complex, long-term planning scenarios. To address these
limitations, we propose MAPF-World, an autoregressive action world model for
MAPF that unifies situation understanding and action generation, guiding
decisions beyond immediate local observations. It improves situational
awareness by explicitly modeling environmental dynamics, including spatial
features and temporal dependencies, through future state and actions
prediction. By incorporating these predicted futures, MAPF-World enables more
informed, coordinated, and far-sighted decision-making, especially in complex
multi-agent settings. Furthermore, we augment MAPF benchmarks by introducing an
automatic map generator grounded in real-world scenarios, capturing practical
map layouts for training and evaluating MAPF solvers. Extensive experiments
demonstrate that MAPF-World outperforms state-of-the-art learnable solvers,
showcasing superior zero-shot generalization to out-of-distribution cases.
Notably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced
data.

</details>


### [17] [Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios](https://arxiv.org/abs/2508.12100)
*Daniel Burkhardt,Xiangwei Cheng*

Main category: cs.AI

TL;DR: 提出了ReT-Eval框架，通过两阶段方法（知识提取和奖励引导剪枝）生成语义层次清晰、与用户理解对齐的推理线程，解决了现有推理模型缺乏显式语义层次和有效剪枝机制的问题。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型缺乏显式语义层次结构、用户-领域知识对齐机制，以及有效的推理线程剪枝策略，导致输出冗长且无法有效引导用户进行目标导向推理。

Method: 采用原型启发的两阶段框架：第一阶段使用图神经网络从稀疏领域知识图中提取语义相关知识结构，并用大语言模型知识进行丰富；第二阶段使用奖励引导策略评估和剪枝推理线程以保持语义连贯性。

Result: 实验和专家评估表明，ReT-Eval框架显著提升了用户理解能力，并在性能上超越了最先进的推理模型。

Conclusion: ReT-Eval框架通过结构化知识重用和奖励引导的剪枝机制，有效解决了交互式问题解决场景中推理线程的质量和效率问题，为构建更人性化的推理系统提供了新思路。

Abstract: Reasoning in interactive problem solving scenarios requires models to
construct reasoning threads that reflect user understanding and align with
structured domain knowledge. However, current reasoning models often lack
explicit semantic hierarchies, user-domain knowledge alignment, and principled
mechanisms to prune reasoning threads for effectiveness. These limitations
result in lengthy generic output that does not guide users through
goal-oriented reasoning steps. To address this, we propose a
prototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)
framework, drawing inspiration from human-like reasoning strategies that
emphasize structured knowledge reuse. In the first phase, semantically relevant
knowledge structures are extracted from a sparse domain knowledge graph using a
graph neural network and enriched with intrinsic large language model knowledge
to resolve knowledge discrepancies. In the second phase, these threads are
evaluated and pruned using a reward-guided strategy aimed at maintaining
semantic coherence to generate effective reasoning threads. Experiments and
expert evaluations show that ReT-Eval enhances user understanding and
outperforms state-of-the-art reasoning models.

</details>


### [18] [MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization](https://arxiv.org/abs/2508.12149)
*Haochen You,Baojing Liu*

Main category: cs.AI

TL;DR: MOVER是一个多模态学习框架，通过最优传输软对齐和几何体积正则化，在共享嵌入空间中构建语义对齐和结构化的多模态表示，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态对比学习方法主要依赖成对对比目标，在多模态设置中泛化能力有限，且在高维空间中缺乏语义结构。需要一种能够一致对齐所有模态并保持语义结构的方法。

Method: 结合最优传输的软对齐机制和几何体积最小化目标(GAVE)，以模态无关的方式实现所有模态的一致对齐，构建结构化的嵌入空间。

Result: 在文本-视频-音频检索任务中，MOVER在零样本和微调设置下均显著优于现有最先进方法，展现出更好的泛化能力和嵌入空间结构一致性。

Conclusion: MOVER框架通过最优传输和几何正则化的结合，有效解决了多模态对齐中的泛化和结构化问题，为多模态表示学习提供了新的方向。

Abstract: Recent advances in multimodal learning have largely relied on pairwise
contrastive objectives to align different modalities, such as text, video, and
audio, in a shared embedding space. While effective in bi-modal setups, these
approaches struggle to generalize across multiple modalities and often lack
semantic structure in high-dimensional spaces. In this paper, we propose MOVER,
a novel framework that combines optimal transport-based soft alignment with
volume-based geometric regularization to build semantically aligned and
structured multimodal representations. By integrating a transport-guided
matching mechanism with a geometric volume minimization objective (GAVE), MOVER
encourages consistent alignment across all modalities in a modality-agnostic
manner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER
significantly outperforms prior state-of-the-art methods in both zero-shot and
finetuned settings. Additional analysis shows improved generalization to unseen
modality combinations and stronger structural consistency in the learned
embedding space.

</details>


### [19] [RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards](https://arxiv.org/abs/2508.12165)
*Rohit Krishnan,Jon Evans*

Main category: cs.AI

TL;DR: RLNVR框架使用未经验证的噪声奖励信号训练语言模型，通过基线归一化和语义相似性奖励转移解决传统RLHF需要昂贵验证奖励的问题。


<details>
  <summary>Details</summary>
Motivation: 传统RLHF需要昂贵的人工验证奖励信号，在许多现实场景中不实用。RLNVR旨在利用噪声的真实世界反馈信号来训练语言模型。

Method: 结合基线归一化、语义相似性奖励转移、GSPO（组序列策略优化）和可选的UED（无监督环境设计）课程学习，在噪声隐式奖励下提高稳定性和多样性。

Result: 实验结果显示在内容质量和训练稳定性方面有显著改进，使用Bluesky实际参与数据优化社交媒体内容生成的Walter原型系统证明了有效性。

Conclusion: RLNVR提供了一个实用的框架，能够在不需要显式人类验证的情况下，利用真实世界的噪声反馈信号有效训练语言模型。

Abstract: This paper introduces RLNVR (Reinforcement Learning from Non-Verified
Rewards), a framework for training language models using noisy, real-world
feedback signals without requiring explicit human verification. Traditional
RLHF requires expensive, verified reward signals that are impractical in many
real-world domains. RLNVR addresses this challenge through baseline
normalization and semantic similarity-based reward transfer. We demonstrate
RLNVR through Walter, a prototype system that optimizes social media content
generation using actual engagement data from Bluesky. Our experimental results
show significant improvements in content quality and training stability, with
comprehensive evaluation planned for future work. Positioning: We present a
practical framework that combines RLNVR with GSPO (Group Sequence Policy
Optimization) and an optional UED (Unsupervised Environment Design) curriculum
to improve stability and diversity under noisy, implicit rewards. To our
knowledge, combining GSPO-style normalization with a UED-style curriculum for
LLM content generation from implicit social engagement has not been previously
documented in this applied setting; we frame this as an applied integration
rather than a new algorithm.

</details>


### [20] [Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting](https://arxiv.org/abs/2508.12260)
*Carson Dudley,Reiden Magdaleno,Christopher Harding,Ananya Sharma,Emily Martin,Marisa Eisenberg*

Main category: cs.AI

TL;DR: Mantis是一个基于机制模拟训练的基础模型，无需真实数据即可在多种疾病和场景中进行准确预测，性能超越39个专家调优模型


<details>
  <summary>Details</summary>
Motivation: 解决传统传染病预测模型需要疾病特定数据、专业训练和专家调优的限制，特别是在新发疫情或资源匮乏地区

Method: 基于超过4亿天疫情动态的机制模拟训练，涵盖多种病原体、传播方式、干预措施和监测伪影，无需真实世界数据

Result: 在六种疾病测试中超越所有39个专家调优模型，包括CDC COVID-19预测中心的所有模型，能推广到新的流行病学机制

Conclusion: Mantis作为下一代疾病预测系统的基础，具有通用性、可解释性和在传统模型失败场景中的部署能力

Abstract: Infectious disease forecasting in novel outbreaks or low resource settings
has been limited by the need for disease-specific data, bespoke training, and
expert tuning. We introduce Mantis, a foundation model trained entirely on
mechanistic simulations, which enables out-of-the-box forecasting across
diseases, regions, and outcomes, even in settings with limited historical data.
Mantis is built on over 400 million simulated days of outbreak dynamics
spanning diverse pathogens, transmission modes, interventions, and surveillance
artifacts. Despite requiring no real-world data during training, Mantis
outperformed 39 expert-tuned models we tested across six diseases, including
all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel
epidemiological regimes, including diseases with held-out transmission
mechanisms, demonstrating that it captures fundamental contagion dynamics.
Critically, Mantis is mechanistically interpretable, enabling public health
decision-makers to identify the latent drivers behind its predictions. Finally,
Mantis delivers accurate forecasts at 8-week horizons, more than doubling the
actionable range of most models, enabling proactive public health planning.
Together, these capabilities position Mantis as a foundation for
next-generation disease forecasting systems: general, interpretable, and
deployable where traditional models fail.

</details>


### [21] [RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts](https://arxiv.org/abs/2508.12291)
*Xuming He,Zhiyuan You,Junchao Gong,Couhua Liu,Xiaoyu Yue,Peiqin Zhuang,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: RadarQA是一个基于多模态大语言模型的气象预报质量分析方法，通过结合物理属性和详细评估报告，在雷达预报质量评估任务上优于现有通用MLLM模型。


<details>
  <summary>Details</summary>
Motivation: 传统基于分数的评估指标在描述能力、可解释性和动态演化理解方面远不如气象专家，需要利用MLLM技术来克服这些挑战。

Method: 提出了多模态质量分析的创新任务范式，包含单帧和序列分析、评分和评估场景；设计了结合人工专家标注和自动启发式的混合标注流程，构建了RQA-70K大规模数据集；采用多阶段训练策略迭代提升模型性能。

Result: RadarQA在所有评估设置中都优于现有的通用MLLM，展示了在天气预报质量分析方面的潜力。

Conclusion: RadarQA方法通过整合多模态分析和专家知识，为气象预报质量评估提供了更强大的工具，有望推动该领域的发展。

Abstract: Quality analysis of weather forecasts is an essential topic in meteorology.
Although traditional score-based evaluation metrics can quantify certain
forecast errors, they are still far from meteorological experts in terms of
descriptive capability, interpretability, and understanding of dynamic
evolution. With the rapid development of Multi-modal Large Language Models
(MLLMs), these models become potential tools to overcome the above challenges.
In this work, we introduce an MLLM-based weather forecast analysis method,
RadarQA, integrating key physical attributes with detailed assessment reports.
We introduce a novel and comprehensive task paradigm for multi-modal quality
analysis, encompassing both single frame and sequence, under both rating and
assessment scenarios. To support training and benchmarking, we design a hybrid
annotation pipeline that combines human expert labeling with automated
heuristics. With such an annotation method, we construct RQA-70K, a large-scale
dataset with varying difficulty levels for radar forecast quality evaluation.
We further design a multi-stage training strategy that iteratively improves
model performance at each stage. Extensive experiments show that RadarQA
outperforms existing general MLLMs across all evaluation settings, highlighting
its potential for advancing quality analysis in weather prediction.

</details>


### [22] [Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback](https://arxiv.org/abs/2508.12338)
*Wenzhen Yuan,Shengji Tang,Weihao Lin,Jiacheng Ruan,Ganqu Cui,Bo Zhang,Tao Chen,Ting Liu,Yuzhuo Fu,Peng Ye,Lei Bai*

Main category: cs.AI

TL;DR: RLCCF是一个无需外部监督的多模型协作进化强化学习框架，通过最大化集体一致性来提升LLM的推理能力，在数学推理基准上平均提升16.72%的准确率


<details>
  <summary>Details</summary>
Motivation: 解决传统RL方法依赖昂贵人工标注数据和复杂奖励模型的问题，以及现有自反馈方法受限于单模型能力导致的过度自信、奖励攻击和训练崩溃等问题

Method: 提出基于协同进化集体反馈的强化学习框架，通过投票机制训练多样化LLM集合，利用自一致性评分加权投票提供奖励信号，实现多模型协作进化

Result: 在四个主流开源LLM和四个数学推理基准测试中，平均相对准确率提升16.72%，群体多数投票准确率提升4.51%

Conclusion: RLCCF不仅能提升单个模型性能，还能扩展模型集体的能力边界，为无监督强化学习提供了有效解决方案

Abstract: Reinforcement learning (RL) has significantly enhanced the reasoning
capabilities of large language models (LLMs), but its reliance on expensive
human-labeled data or complex reward models severely limits scalability. While
existing self-feedback methods aim to address this problem, they are
constrained by the capabilities of a single model, which can lead to
overconfidence in incorrect answers, reward hacking, and even training
collapse. To this end, we propose Reinforcement Learning from Coevolutionary
Collective Feedback (RLCCF), a novel RL framework that enables multi-model
collaborative evolution without external supervision. Specifically, RLCCF
optimizes the ability of a model collective by maximizing its Collective
Consistency (CC), which jointly trains a diverse ensemble of LLMs and provides
reward signals by voting on collective outputs. Moreover, each model's vote is
weighted by its Self-Consistency (SC) score, ensuring that more confident
models contribute more to the collective decision. Benefiting from the diverse
output distributions and complementary abilities of multiple LLMs, RLCCF
enables the model collective to continuously enhance its reasoning ability
through coevolution. Experiments on four mainstream open-source LLMs across
four mathematical reasoning benchmarks demonstrate that our framework yields
significant performance gains, achieving an average relative improvement of
16.72\% in accuracy. Notably, RLCCF not only improves the performance of
individual models but also enhances the group's majority-voting accuracy by
4.51\%, demonstrating its ability to extend the collective capability boundary
of the model collective.

</details>


### [23] [Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems](https://arxiv.org/abs/2508.12375)
*Yu Sha,Shuiping Gou,Bo Liu,Johannes Faber,Ningtao Liu,Stefan Schramm,Horst Stoecker,Thomas Steckenreiter,Domagoj Vnucec,Nadine Wetzstein,Andreas Widl,Kai Zhou*

Main category: cs.AI

TL;DR: 提出了一种基于层次知识引导的故障强度诊断框架HKG，通过图卷积网络和重新加权的层次知识相关矩阵来捕获类别间依赖关系，在多个工业数据集上取得了优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 当前故障强度诊断方法基于链式思维，没有考虑目标类别之间的依赖关系，限制了诊断性能。

Method: 使用图卷积网络将类别表示的层次拓扑图映射到一组相互依赖的全局层次分类器，每个节点用类别词嵌入表示；开发了重新加权的层次知识相关矩阵方案，将类间层次知识嵌入到数据驱动的统计相关矩阵中。

Result: 在四个真实工业数据集（三个来自SAMSON AG的空化数据集和一个公开数据集）上的大量实验显示，该方法在所有数据集上都取得了优异结果，超越了当前最先进的FID方法。

Conclusion: 提出的HKG框架能够有效捕获和探索类别间依赖关系，通过层次知识引导和重新加权的相关矩阵方案，显著提升了故障强度诊断的性能，为复杂工业系统的设备监控和维护提供了有效解决方案。

Abstract: Fault intensity diagnosis (FID) plays a pivotal role in monitoring and
maintaining mechanical devices within complex industrial systems. As current
FID methods are based on chain of thought without considering dependencies
among target classes. To capture and explore dependencies, we propose a
hierarchical knowledge guided fault intensity diagnosis framework (HKG)
inspired by the tree of thought, which is amenable to any representation
learning methods. The HKG uses graph convolutional networks to map the
hierarchical topological graph of class representations into a set of
interdependent global hierarchical classifiers, where each node is denoted by
word embeddings of a class. These global hierarchical classifiers are applied
to learned deep features extracted by representation learning, allowing the
entire model to be end-to-end learnable. In addition, we develop a re-weighted
hierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding
inter-class hierarchical knowledge into a data-driven statistical correlation
matrix (SCM) which effectively guides the information sharing of nodes in
graphical convolutional neural networks and avoids over-smoothing issues. The
Re-HKCM is derived from the SCM through a series of mathematical
transformations. Extensive experiments are performed on four real-world
datasets from different industrial domains (three cavitation datasets from
SAMSON AG and one existing publicly) for FID, all showing superior results and
outperform recent state-of-the-art FID methods.

</details>


### [24] [GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding](https://arxiv.org/abs/2508.12379)
*Rongzheng Wang,Qizhi Chen,Yihong Huang,Yizhuo Ma,Muquan Li,Jiakai Li,Ke Qin,Guangchun Luo,Shuang Liang*

Main category: cs.AI

TL;DR: GraphCogent是一个基于工作记忆模型的协作代理框架，通过将图推理分解为感知、缓冲和执行三个认知过程，有效解决了大语言模型在处理复杂图拓扑和多步推理时的局限性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在小规模图推理任务上表现良好，但在处理具有复杂查询的真实世界图时失败，主要原因是无法同时有效处理复杂图拓扑和执行多步推理。

Method: 提出GraphCogent框架，包含三个模块：感知模块通过子图采样标准化图文本表示，缓冲模块集成和索引多种格式的图数据，执行模块结合工具调用和模型生成进行高效推理。

Result: 基于Llama3.1-8B的GraphCogent相比DeepSeek-R1(671B)性能提升50%，相比最先进的基于代理的基线方法，准确率提高20%，同时token使用量减少80%（工具集内任务）和30%（工具集外任务）。

Conclusion: GraphCogent框架通过认知过程分解有效提升了LLMs的图推理能力，在处理大规模真实图数据时展现出显著优势，同时大幅降低了计算资源消耗。

Abstract: Large language models (LLMs) show promising performance on small-scale graph
reasoning tasks but fail when handling real-world graphs with complex queries.
This phenomenon stems from LLMs' inability to effectively process complex graph
topology and perform multi-step reasoning simultaneously. To address these
limitations, we propose GraphCogent, a collaborative agent framework inspired
by human Working Memory Model that decomposes graph reasoning into specialized
cognitive processes: sense, buffer, and execute. The framework consists of
three modules: Sensory Module standardizes diverse graph text representations
via subgraph sampling, Buffer Module integrates and indexes graph data across
multiple formats, and Execution Module combines tool calling and model
generation for efficient reasoning. We also introduce Graph4real, a
comprehensive benchmark contains with four domains of real-world graphs (Web,
Social, Transportation, and Citation) to evaluate LLMs' graph reasoning
capabilities. Our Graph4real covers 21 different graph reasoning tasks,
categorized into three types (Structural Querying, Algorithmic Reasoning, and
Predictive Modeling tasks), with graph scales that are 10 times larger than
existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent
achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).
Compared to state-of-the-art agent-based baseline, our framework outperforms by
20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%
for out-toolset tasks. Code will be available after review.

</details>


### [25] [Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning](https://arxiv.org/abs/2508.12425)
*Phuong Minh Nguyen,Tien Huu Dang,Naoya Inoue*

Main category: cs.AI

TL;DR: Symbolic-Aided Chain-of-Thought (CoT) 通过将轻量级符号表示整合到少样本提示中，改进了标准 CoT 方法，在逻辑推理任务中显著提升了大型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 提升大型语言模型在逻辑推理任务中的透明度、可解释性和可分析性，同时保持标准提示技术的泛化能力。

Method: 在少样本提示中整合轻量级符号表示，使用一致的策略构建推理步骤，使推理模式在非迭代推理过程中更加明确。

Result: 在四个逻辑推理基准测试（ProofWriter、FOLIO、ProntoQA、LogicalDeduction）上表现优异，特别是在需要处理多重约束或规则的复杂推理任务中，在三个数据集上显著优于传统 CoT 方法。

Conclusion: Symbolic-Aided CoT 方法有效提升了 LLMs 的逻辑推理能力，在不同模型规模下都表现出一致的改进效果，为增强语言模型的推理透明度提供了有效途径。

Abstract: This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved
approach to standard CoT, for logical reasoning in large language models
(LLMs). The key idea is to integrate lightweight symbolic representations into
few-shot prompts, structuring the inference steps with a consistent strategy to
make reasoning patterns more explicit within a non-iterative reasoning process.
By incorporating these symbolic structures, our method preserves the
generalizability of standard prompting techniques while enhancing the
transparency, interpretability, and analyzability of LLM logical reasoning.
Extensive experiments on four well-known logical reasoning benchmarks --
ProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse
reasoning scenarios -- demonstrate the effectiveness of the proposed approach,
particularly in complex reasoning tasks that require navigating multiple
constraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'
reasoning capabilities across various model sizes and significantly outperforms
conventional CoT on three out of four datasets, ProofWriter, ProntoQA, and
LogicalDeduction.

</details>


### [26] [GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?](https://arxiv.org/abs/2508.12472)
*Yifang Tian,Yaming Liu,Zichun Chong,Zihang Huang,Hans-Arno Jacobsen*

Main category: cs.AI

TL;DR: GALA是一个多模态框架，结合统计因果推理和LLM驱动的迭代推理，用于微服务系统的根因分析，相比现有方法准确率提升高达42.22%，并提供可操作的诊断和修复指导


<details>
  <summary>Details</summary>
Motivation: 传统RCA方法通常只关注单一模态或仅对可疑服务进行排序，无法提供具有可操作性的诊断洞察和修复指导

Method: 结合统计因果推理与LLM驱动的迭代推理的多模态框架

Result: 在开源基准测试中达到42.22%的准确率提升，生成更具因果合理性和可操作性的诊断输出

Conclusion: GALA通过提供准确的根因识别和人类可理解的修复指导，弥合了自动化故障诊断与实际事件解决之间的差距

Abstract: Root cause analysis (RCA) in microservice systems is challenging, requiring
on-call engineers to rapidly diagnose failures across heterogeneous telemetry
such as metrics, logs, and traces. Traditional RCA methods often focus on
single modalities or merely rank suspect services, falling short of providing
actionable diagnostic insights with remediation guidance. This paper introduces
GALA, a novel multi-modal framework that combines statistical causal inference
with LLM-driven iterative reasoning for enhanced RCA. Evaluated on an
open-source benchmark, GALA achieves substantial improvements over
state-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM
evaluation score shows GALA generates significantly more causally sound and
actionable diagnostic outputs than existing methods. Through comprehensive
experiments and a case study, we show that GALA bridges the gap between
automated failure diagnosis and practical incident resolution by providing both
accurate root cause identification and human-interpretable remediation
guidance.

</details>


### [27] [The Yokai Learning Environment: Tracking Beliefs Over Space and Time](https://arxiv.org/abs/2508.12480)
*Constantin Ruhdorfer,Matteo Bortoletto,Andreas Bulling*

Main category: cs.AI

TL;DR: Yokai Learning Environment (YLE)是一个基于合作卡牌游戏的多智能体强化学习环境，用于评估智能体的心智理论能力，特别是建立和维护共同基础的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的心智理论基准测试局限于被动观察者设置，缺乏对智能体如何随时间建立和维护共同基础的评估。

Method: 开发了Yokai Learning Environment (YLE) - 一个基于合作卡牌游戏Yokai的多智能体强化学习环境，智能体需要查看隐藏卡片、移动卡片形成颜色集群，并跟踪不断变化的信念。

Result: 当前RL智能体即使在拥有完美记忆的情况下也难以解决YLE任务；信念建模能提升性能，但智能体仍无法有效泛化到未见过的伙伴或形成长期准确信念。

Conclusion: YLE揭示了智能体依赖脆弱的惯例而非稳健的信念追踪，可用于研究信念建模、记忆、伙伴泛化和高阶心智理论等研究问题。

Abstract: Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to
reason about the beliefs of others to build and maintain common ground.
Existing ToM benchmarks, however, are restricted to passive observer settings
or lack an assessment of how agents establish and maintain common ground over
time. To address these gaps, we introduce the Yokai Learning Environment (YLE)
- a multi-agent reinforcement learning (RL) environment based on the
cooperative card game Yokai. In the YLE, agents take turns peeking at hidden
cards and moving them to form clusters based on colour. Success requires
tracking evolving beliefs, remembering past observations, using hints as
grounded communication, and maintaining common ground with teammates. Our
evaluation yields two key findings: First, current RL agents struggle to solve
the YLE, even when given access to perfect memory. Second, while belief
modelling improves performance, agents are still unable to effectively
generalise to unseen partners or form accurate beliefs over longer games,
exposing a reliance on brittle conventions rather than robust belief tracking.
We use the YLE to investigate research questions in belief modelling, memory,
partner generalisation, and scaling to higher-order ToM.

</details>


### [28] [Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework](https://arxiv.org/abs/2508.12487)
*Lida Shahbandari,Hossein Mohseni*

Main category: cs.AI

TL;DR: 本研究提出了一种基于鲸鱼优化算法的分数阶模糊PID控制器，用于精确控制脑电双频指数在40-60的理想范围内，相比传统分数阶PID控制器具有更快的响应速度和更低的稳态误差。


<details>
  <summary>Details</summary>
Motivation: 麻醉深度控制对手术安全和患者恢复至关重要。传统PID控制器难以适应患者个体生理差异，需要一种能够自动调整参数、处理非线性特性的智能控制方案。

Method: 结合模糊逻辑的自适应能力和分数阶微积分的精细调节特性，使用鲸鱼优化算法(WOA)自动优化控制器参数（包括分数阶阶次和模糊隶属度函数），在8种不同患者模型上进行测试验证。

Result: FOFPID控制器相比传统FOPID控制器表现更优：调节时间从3.2分钟缩短到2.5分钟，稳态误差从1.2降低到0.5，显示出更强的鲁棒性和控制精度。

Conclusion: 该分数阶模糊PID控制器提供了一种可扩展的、人工智能驱动的自动化麻醉输送解决方案，有望改善临床实践和患者治疗效果。

Abstract: This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that
uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index
(BIS), keeping it within the ideal range of forty to sixty. The FOFPID
controller combines fuzzy logic for adapting to changes and fractional order
dynamics for fine tuning. This allows it to adjust its control gains to handle
a person's unique physiology. The WOA helps fine tune the controller's
parameters, including the fractional orders and the fuzzy membership functions,
which boosts its performance. Tested on models of eight different patient
profiles, the FOFPID controller performed better than a standard Fractional
Order PID (FOPID) controller. It achieved faster settling times, at two and a
half minutes versus three point two minutes, and had a lower steady state
error, at zero point five versus one point two. These outcomes show the
FOFPID's excellent strength and accuracy. It offers a scalable, artificial
intelligence driven solution for automated anesthesia delivery that could
enhance clinical practice and improve patient results.

</details>


### [29] [Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models](https://arxiv.org/abs/2508.12500)
*Rahmat K. Adesunkanmi,Ashfaq Khokhar,Goce Trajcevski,Sohail Murad*

Main category: cs.AI

TL;DR: 使用变分自动编码器构建因果模型，通过将氢键分离视为"干预"来识别分子动力学中氢键形成和分离的根本原因变量


<details>
  <summary>Details</summary>
Motivation: 解决分子动力学模拟中资源涉及较多的计算和需要手动扫描输出以发现"有趣事件"的挑战，特别是了解氢键形成和分离的根本原因

Method: 受因果模型启发，将氢键分离视为"干预"事件，使用变分自动编码器结构构建图形因果模型，在具有不同基础因果图的样本中推断因果关系

Result: 在手性分离的原子轨迹上验证模型有效性，能够预测多步未来变化并找到驱动系统变化的关键变量

Conclusion: 该框架为分子动态系统的根本原因分析提供了新视角，通过捕获分子互作条件分布的变化来理解结合事件的因果机制

Abstract: Molecular dynamics simulations (MDS) face challenges, including
resource-heavy computations and the need to manually scan outputs to detect
"interesting events," such as the formation and persistence of hydrogen bonds
between atoms of different molecules. A critical research gap lies in
identifying the underlying causes of hydrogen bond formation and separation
-understanding which interactions or prior events contribute to their emergence
over time. With this challenge in mind, we propose leveraging spatio-temporal
data analytics and machine learning models to enhance the detection of these
phenomena. In this paper, our approach is inspired by causal modeling and aims
to identify the root cause variables of hydrogen bond formation and separation
events. Specifically, we treat the separation of hydrogen bonds as an
"intervention" occurring and represent the causal structure of the bonding and
separation events in the MDS as graphical causal models. These causal models
are built using a variational autoencoder-inspired architecture that enables us
to infer causal relationships across samples with diverse underlying causal
graphs while leveraging shared dynamic information. We further include a step
to infer the root causes of changes in the joint distribution of the causal
models. By constructing causal models that capture shifts in the conditional
distributions of molecular interactions during bond formation or separation,
this framework provides a novel perspective on root cause analysis in molecular
dynamic systems. We validate the efficacy of our model empirically on the
atomic trajectories that used MDS for chiral separation, demonstrating that we
can predict many steps in the future and also find the variables driving the
observed changes in the system.

</details>


### [30] [Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models](https://arxiv.org/abs/2508.12566)
*Wei Song,Haonan Zhong,Ziqi Ding,Jingling Xue,Yuekang Li*

Main category: cs.AI

TL;DR: MCPGAUGE是首个全面评估LLM与Model Context Protocol交互的框架，通过大规模实验揭示了MCP集成效果的四个关键发现，挑战了现有假设。


<details>
  <summary>Details</summary>
Motivation: 虽然MCP使LLM能够按需访问外部资源，但LLM如何实际利用这种能力仍不清楚，需要系统评估框架来理解LLM-MCP交互效果。

Method: 开发MCPGAUGE评估框架，包含160个提示和25个数据集，涵盖知识理解、通用推理和代码生成。对6个商业LLM、30个MCP工具套件进行大规模评估，涉及约20,000次API调用。

Result: 研究揭示了四个关键发现，挑战了关于MCP集成有效性的普遍假设，突显了当前AI工具集成的关键局限性。

Conclusion: MCPGAUGE为推进可控、工具增强型LLM提供了原则性基准，揭示了当前MCP集成的实际效果与预期存在差距。

Abstract: The Model Context Protocol (MCP) enables large language models (LLMs) to
access external resources on demand. While commonly assumed to enhance
performance, how LLMs actually leverage this capability remains poorly
understood. We introduce MCPGAUGE, the first comprehensive evaluation framework
for probing LLM-MCP interactions along four key dimensions: proactivity
(self-initiated tool use), compliance (adherence to tool-use instructions),
effectiveness (task performance post-integration), and overhead (computational
cost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning
knowledge comprehension, general reasoning, and code generation. Our
large-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and
both one- and two-turn interaction settings, comprises around 20,000 API calls
and over USD 6,000 in computational cost. This comprehensive study reveals four
key findings that challenge prevailing assumptions about the effectiveness of
MCP integration. These insights highlight critical limitations in current
AI-tool integration and position MCPGAUGE as a principled benchmark for
advancing controllable, tool-augmented LLMs.

</details>


### [31] [An LLM + ASP Workflow for Joint Entity-Relation Extraction](https://arxiv.org/abs/2508.12611)
*Trang Tran,Trung Hoang Le,Huiping Cao,Tran Cao Son*

Main category: cs.AI

TL;DR: 本文提出结合大型语言模型(LLM)和答案集编程(ASP)的联合实体关系抽取工作流，无需大量标注数据，在仅使用10%训练数据的情况下，在多个基准测试中超越现有最佳系统。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法需要大量标注数据且难以融入领域知识，构建模型耗时耗力。本文旨在利用LLM的自然语言理解能力和ASP的知识表示推理能力，解决联合实体关系抽取的标注数据依赖和领域知识融入问题。

Method: 提出通用工作流：利用LLM直接处理未标注文本进行自然语言理解，结合ASP进行知识表示和推理。ASP具有扩展容忍性，无需修改核心程序即可融入新的领域知识（类型规范）。

Result: 在三个知名JERE基准测试上，仅使用10%训练数据就超越了现有最佳系统。在最具挑战性的SciERC语料库上，关系抽取任务实现了2.5倍的性能提升（从15%提升到35%）。

Conclusion: LLM+ASP工作流为联合实体关系抽取提供了有效的解决方案，显著减少了对标注数据的依赖，同时保持了领域知识的灵活融入能力，在资源受限场景下表现出色。

Abstract: Joint entity-relation extraction (JERE) identifies both entities and their
relationships simultaneously. Traditional machine-learning based approaches to
performing this task require a large corpus of annotated data and lack the
ability to easily incorporate domain specific information in the construction
of the model. Therefore, creating a model for JERE is often labor intensive,
time consuming, and elaboration intolerant. In this paper, we propose
harnessing the capabilities of generative pretrained large language models
(LLMs) and the knowledge representation and reasoning capabilities of Answer
Set Programming (ASP) to perform JERE. We present a generic workflow for JERE
using LLMs and ASP. The workflow is generic in the sense that it can be applied
for JERE in any domain. It takes advantage of LLM's capability in natural
language understanding in that it works directly with unannotated text. It
exploits the elaboration tolerant feature of ASP in that no modification of its
core program is required when additional domain specific knowledge, in the form
of type specifications, is found and needs to be used. We demonstrate the
usefulness of the proposed workflow through experiments with limited training
data on three well-known benchmarks for JERE. The results of our experiments
show that the LLM + ASP workflow is better than state-of-the-art JERE systems
in several categories with only 10\% of training data. It is able to achieve a
2.5 times (35\% over 15\%) improvement in the Relation Extraction task for the
SciERC corpus, one of the most difficult benchmarks.

</details>


### [32] [Cognitive Structure Generation: From Educational Priors to Policy Optimization](https://arxiv.org/abs/2508.12647)
*Hengnian Gu,Zhifu Chen,Yuxin Chen,Jin Peng Zhou,Dongdai Zhou*

Main category: cs.AI

TL;DR: 提出了认知结构生成(CSG)框架，通过预训练认知结构扩散概率模型(CSDPM)和强化学习优化，从教育先验生成学生的认知结构，显著提升学生建模效果。


<details>
  <summary>Details</summary>
Motivation: 认知结构是学生对知识系统的主观组织，但在教育实践中一直难以有效评估，是学生建模和心理测量学中的长期挑战。

Method: 首先预训练认知结构扩散概率模型(CSDPM)从教育先验生成认知结构，然后通过强化学习使用分层奖励信号优化生成过程，使其与真实认知发展水平对齐。

Result: 在四个真实教育数据集上的实验表明，CSG生成的认知结构为学生建模提供了更全面有效的表示，显著提升了知识追踪(KT)和认知诊断(CD)任务的性能，并增强了可解释性。

Conclusion: CSG框架成功解决了认知结构评估的难题，为教育实践提供了有效的认知结构生成方法，在学生建模任务中表现出优越性能。

Abstract: Cognitive structure is a student's subjective organization of an objective
knowledge system, reflected in the psychological construction of concepts and
their relations. However, cognitive structure assessment remains a
long-standing challenge in student modeling and psychometrics, persisting as a
foundational yet largely unassessable concept in educational practice. This
paper introduces a novel framework, Cognitive Structure Generation (CSG), in
which we first pretrain a Cognitive Structure Diffusion Probabilistic Model
(CSDPM) to generate students' cognitive structures from educational priors, and
then further optimize its generative process as a policy with hierarchical
reward signals via reinforcement learning to align with genuine cognitive
development levels during students' learning processes. Experimental results on
four popular real-world education datasets show that cognitive structures
generated by CSG offer more comprehensive and effective representations for
student modeling, substantially improving performance on KT and CD tasks while
enhancing interpretability.

</details>


### [33] [The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning](https://arxiv.org/abs/2508.12651)
*Chunliang Hua,Xiao Hu,Jiayang Sun,Zeyuan Yang*

Main category: cs.AI

TL;DR: 本文提出了CDMCLP优化框架和集成规划推荐系统，用于解决城市空中交通基础设施规划中的复杂问题，在传统选址方法基础上提升了38%-52%的性能。


<details>
  <summary>Details</summary>
Motivation: 随着全球城市空中交通基础设施快速发展，现有规划框架因数据粒度不足和实际应用性限制而无法应对大规模垂直起降场网络的复杂性。

Method: 提出容量约束动态最大覆盖选址问题(CDMCLP)优化框架，同时建模城市级时空需求、异构用户行为和基础设施容量约束；开发集成规划推荐系统，结合社会经济因素和动态聚类初始化。

Result: 在中国中心城市验证显示，CDMCLP使传统选址方法的量化性能提升38%-52%，推荐系统展现出用户友好性和复杂要素的有效整合能力。

Conclusion: 这种混合方法通过数学严谨性与实际实施考虑的结合，弥合了理论选址建模与现实世界UAM基础设施规划之间的差距，为市政部门提供了实用的垂直起降场网络设计工具。

Abstract: As urban aerial mobility (UAM) infrastructure development accelerates
globally, cities like Shenzhen are planning large-scale vertiport networks
(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain
inadequate for this complexity due to historical limitations in data
granularity and real-world applicability. This paper addresses these gaps by
first proposing the Capacitated Dynamic Maximum Covering Location Problem
(CDMCLP), a novel optimization framework that simultaneously models urban-scale
spatial-temporal demand, heterogeneous user behaviors, and infrastructure
capacity constraints. Building on this foundation, we introduce an Integrated
Planning Recommendation System that combines CDMCLP with socio-economic factors
and dynamic clustering initialization. This system leverages adaptive parameter
tuning based on empirical user behavior to generate practical planning
solutions. Validation in a Chinese center city demonstrates the effectiveness
of the new optimization framework and recommendation system. Under the
evaluation and optimization of CDMCLP, the quantitative performance of
traditional location methods are exposed and can be improved by 38\%--52\%,
while the recommendation system shows user-friendliness and the effective
integration of complex elements. By integrating mathematical rigor with
practical implementation considerations, this hybrid approach bridges the gap
between theoretical location modeling and real-world UAM infrastructure
planning, offering municipalities a pragmatic tool for vertiport network
design.

</details>


### [34] [GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance](https://arxiv.org/abs/2508.12682)
*Jinquan Shi,Yingying Cheng,Fan Zhang,Miao Jiang,Jun Lin,Yanbai Shen*

Main category: cs.AI

TL;DR: GridCodex是一个基于大语言模型和检索增强生成(RAG)的端到端电网规范推理与合规框架，通过多阶段查询优化和RAPTOR增强检索技术，在电网规范自动解释方面实现了26.4%的答案质量提升和10倍以上的召回率提升。


<details>
  <summary>Details</summary>
Motivation: 可再生能源转型给电力行业带来巨大挑战，电网规范复杂且缺乏自动化解释方案，阻碍行业发展并影响电力公司盈利能力。

Method: 采用大型语言模型和检索增强生成(RAG)技术，通过多阶段查询优化和RAPTOR增强检索方法构建端到端框架。

Result: 实验结果显示答案质量提升26.4%，召回率提升超过10倍，并通过消融研究验证了基础模型选择的影响。

Conclusion: GridCodex框架有效解决了电网规范自动解释的难题，为电力行业监管合规提供了高效的技术解决方案。

Abstract: The global shift towards renewable energy presents unprecedented challenges
for the electricity industry, making regulatory reasoning and compliance
increasingly vital. Grid codes, the regulations governing grid operations, are
complex and often lack automated interpretation solutions, which hinders
industry expansion and undermines profitability for electricity companies. We
introduce GridCodex, an end to end framework for grid code reasoning and
compliance that leverages large language models and retrieval-augmented
generation (RAG). Our framework advances conventional RAG workflows through
multi stage query refinement and enhanced retrieval with RAPTOR. We validate
the effectiveness of GridCodex with comprehensive benchmarks, including
automated answer assessment across multiple dimensions and regulatory agencies.
Experimental results showcase a 26.4% improvement in answer quality and more
than a 10 fold increase in recall rate. An ablation study further examines the
impact of base model selection.

</details>


### [35] [EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding](https://arxiv.org/abs/2508.12687)
*Ashish Seth,Utkarsh Tyagi,Ramaneswaran Selvakumar,Nishit Anand,Sonal Kumar,Sreyan Ghosh,Ramani Duraiswami,Chirag Agarwal,Dinesh Manocha*

Main category: cs.AI

TL;DR: EgoIllusion是首个评估多模态大语言模型在自我中心视频中幻觉问题的基准测试，包含1400个视频和8000个人工标注问题，测试显示包括GPT-4o和Gemini在内的顶级模型准确率仅59%


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在第三人称和自我中心视频中表现出色，但容易产生连贯但不准确的幻觉回答，需要专门的基准来评估和解决这个问题

Method: 构建包含1400个视频和8000个人工标注问题的EgoIllusion基准，设计开放性和封闭性问题来触发视觉和听觉线索的幻觉

Result: 测试10个MLLM模型发现显著挑战，最强模型GPT-4o和Gemini准确率仅59%，表明当前模型在自我中心视频理解方面存在严重幻觉问题

Conclusion: EgoIllusion为评估MLLM有效性奠定了基础，将推动开发幻觉率更低的自我中心MLLM，基准将开源以确保可复现性

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
performance in complex multimodal tasks. While MLLMs excel at visual perception
and reasoning in third-person and egocentric videos, they are prone to
hallucinations, generating coherent yet inaccurate responses. We present
EgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric
videos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated
open and closed-ended questions designed to trigger hallucinations in both
visual and auditory cues in egocentric videos. Evaluations across ten MLLMs
reveal significant challenges, including powerful models like GPT-4o and
Gemini, achieving only 59% accuracy. EgoIllusion lays the foundation in
developing robust benchmarks to evaluate the effectiveness of MLLMs and spurs
the development of better egocentric MLLMs with reduced hallucination rates.
Our benchmark will be open-sourced for reproducibility.

</details>


### [36] [GTool: Graph Enhanced Tool Planning with Large Language Model](https://arxiv.org/abs/2508.12725)
*Wenjie Chen,Wenbin Li,Di Yao,Xuying Meng,Chang Gong,Jingping Bi*

Main category: cs.AI

TL;DR: GTool是一个增强LLM在工具依赖不完整情况下进行工具规划的新方法，通过构建请求特定的工具图和生成图标记来提供依赖信息，相比现有SOTA方法性能提升29.6%


<details>
  <summary>Details</summary>
Motivation: 当前工具规划方法将不同工具视为孤立组件，未能利用工具间的内在依赖关系，导致规划结果无效。特别是在工具依赖不完整和大规模工具集的情况下，LLM难以准确识别用户请求所需的合适工具

Method: 提出GTool方法：1) 构建请求特定的工具图来高效选择工具；2) 生成<graph token>为LLM提供可理解的依赖信息；3) 设计缺失依赖预测任务提高在不完整依赖下的可靠性；无需修剪LLM，可与各种LLM主干无缝集成

Result: 大量实验表明，GTool在使用轻量级(7B)LLM主干的情况下，相比最先进的基线方法实现了超过29.6%的性能提升

Conclusion: GTool是第一个旨在增强LLM在不完整依赖下工具规划能力的工作，通过工具图构建和图标记生成有效解决了工具依赖不完整的问题，具有很好的通用性和实用性

Abstract: Tool planning with large language models (LLMs), referring to selecting,
organizing, and preparing the tools necessary to complete a user request,
bridges the gap between natural language understanding and task execution.
However, current works treat different tools as isolated components and fail to
leverage the inherent dependencies of tools, leading to invalid planning
results. Since tool dependencies are often incomplete, it becomes challenging
for LLMs to accurately identify the appropriate tools required by a user
request, especially when confronted with a large toolset. To solve this
challenge, we propose \texttt{GTool}, which is the first work aiming to enhance
the tool planning ability of LLMs under incomplete dependencies. \texttt{GTool}
constructs a request-specific tool graph to select tools efficiently and
generate the \texttt{<graph token>} which provides sufficient dependency
information understandable by LLMs. Moreover, a missing dependency prediction
task is designed to improve the reliability of \texttt{GTool} with incomplete
dependencies. Without trimming LLMs, \texttt{GTool} can be seamlessly
integrated with various LLM backbones without extensive retraining. Extensive
experiments show that \texttt{GTool} achieves more than 29.6\% performance
improvements compared with the state-of-the-art (SOTA) baselines with a
light-weight (7B) LLM backbone.

</details>


### [37] [Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants](https://arxiv.org/abs/2508.12754)
*Alessio Galatolo,Luca Alberto Rappuoli,Katie Winkle,Meriem Beloucif*

Main category: cs.AI

TL;DR: 该论文提出了一个评估大语言模型作为人工道德助手能力的新框架和基准测试，重点关注道德推理能力而非表面伦理判断，发现现有模型在溯因道德推理方面存在明显不足


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型道德评估过于表面化，只关注最终伦理判断而忽视道德推理过程。论文旨在通过哲学理论构建更深入的评估框架，测试LLMs作为人工道德助手的能力

Method: 基于哲学文献设计人工道德助手的行为框架，识别关键能力如演绎和溯因道德推理，并开发相应的基准测试来评估主流开源大语言模型

Result: 不同模型表现差异显著，特别是在溯因道德推理方面存在持续性的缺陷和不足

Conclusion: 需要专门的策略来显式增强大语言模型的道德推理能力，将理论哲学与实用AI评估相结合具有重要意义

Abstract: The recent rise in popularity of large language models (LLMs) has prompted
considerable concerns about their moral capabilities. Although considerable
effort has been dedicated to aligning LLMs with human moral values, existing
benchmarks and evaluations remain largely superficial, typically measuring
alignment based on final ethical verdicts rather than explicit moral reasoning.
In response, this paper aims to advance the investigation of LLMs' moral
capabilities by examining their capacity to function as Artificial Moral
Assistants (AMAs), systems envisioned in the philosophical literature to
support human moral deliberation. We assert that qualifying as an AMA requires
more than what state-of-the-art alignment techniques aim to achieve: not only
must AMAs be able to discern ethically problematic situations, they should also
be able to actively reason about them, navigating between conflicting values
outside of those embedded in the alignment phase. Building on existing
philosophical literature, we begin by designing a new formal framework of the
specific kind of behaviour an AMA should exhibit, individuating key qualities
such as deductive and abductive moral reasoning. Drawing on this theoretical
framework, we develop a benchmark to test these qualities and evaluate popular
open LLMs against it. Our results reveal considerable variability across models
and highlight persistent shortcomings, particularly regarding abductive moral
reasoning. Our work connects theoretical philosophy with practical AI
evaluation while also emphasising the need for dedicated strategies to
explicitly enhance moral reasoning capabilities in LLMs. Code available at
https://github.com/alessioGalatolo/AMAeval

</details>


### [38] [HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds](https://arxiv.org/abs/2508.12782)
*Petr Anokhin,Roman Khalikov,Stefan Rebrikov,Viktor Volkov,Artyom Sorokin,Vincent Bissonnette*

Main category: cs.AI

TL;DR: HeroBench是一个专门评估大语言模型在复杂RPG虚拟世界中长时程规划和结构化推理能力的新基准测试，揭示了当前模型在生成稳健高层计划和执行结构化行动方面的显著弱点。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常通过抽象或低维算法任务评估LLMs，无法捕捉现实规划环境的复杂性，需要专门评估长时程规划和结构化推理能力的基准。

Method: 引入HeroBench基准，包含严格构建的任务数据集、模拟执行环境验证代理计划、详细分析工具，涵盖资源收集、技能掌握、装备制作、对抗敌人等复杂任务。

Result: 对25个最先进LLMs（包括开源和专有模型、GPT-5家族）的广泛评估显示，与传统推理基准相比存在显著性能差异，详细错误分析揭示了当前模型的具体弱点。

Conclusion: HeroBench不仅显著推进了LLM推理评估，还为未来在虚拟环境中进行高级自主规划研究提供了灵活、可扩展的基础。

Abstract: Large language models (LLMs) have shown remarkable capabilities in isolated
step-by-step reasoning tasks such as mathematics and programming, but their
proficiency in long-horizon planning, where solutions require extended,
structured sequences of interdependent actions, remains underexplored. Existing
benchmarks typically assess LLMs through abstract or low-dimensional
algorithmic tasks, failing to capture the complexity of realistic planning
environments. We introduce HeroBench, a novel benchmark designed specifically
to evaluate long-horizon planning and structured reasoning within complex
RPG-inspired virtual worlds. HeroBench provides a rigorously constructed
dataset of tasks covering a wide range of difficulties, a simulated environment
to execute and validate agent plans, and detailed analytical tools for
evaluating model performance. Tasks challenge models to formulate strategic
plans, efficiently gather resources, master necessary skills, craft equipment,
and defeat adversaries, reflecting practical scenarios' layered dependencies
and constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning
both open-source and proprietary models, including the GPT-5 family, reveals
substantial performance disparities rarely observed in conventional reasoning
benchmarks. Detailed error analysis further uncovers specific weaknesses in
current models' abilities to generate robust high-level plans and reliably
execute structured actions. HeroBench thus not only significantly advances the
evaluation of LLM reasoning but also provides a flexible, scalable foundation
for future research into advanced, autonomous planning in virtual environments.

</details>


### [39] [Reinforcement Learning with Rubric Anchors](https://arxiv.org/abs/2508.12790)
*Zenan Huang,Yihong Zhuang,Guoshan Lu,Zeyu Qin,Haokai Xu,Tianyu Zhao,Ru Peng,Jiaqi Hu,Zhanming Shen,Xiaomeng Hu,Xijun Gu,Peiyi Tu,Jiaxin Liu,Wenyu Chen,Yuzhuo Fu,Zhiting Fan,Yanmei Gu,Yuanyuan Wang,Zhengkai Yang,Jianguo Li,Junbo Zhao*

Main category: cs.AI

TL;DR: 该论文将可验证奖励强化学习(RLVR)扩展到开放式任务，通过构建包含10,000+量表的评分系统，使用Qwen-30B-A3B模型在仅5K+样本下实现+5.2%的性能提升，超越671B大模型，并提供细粒度风格控制。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR局限于可自动验证的领域，无法处理开放式主观任务。为了突破这一限制，需要开发能够自动评估主观输出的方法。

Method: 采用基于量表的奖励系统，构建了10,000+个人工、LLM或人机协作设计的评分量表，作为结构化、模型可解释的自动评分标准。

Result: 仅使用5K+样本，在开放式基准(特别是人文学科)上提升+5.2%，超越671B DeepSeek-V3模型+2.4%，同时保持通用和推理能力，并能产生更人性化的表达。

Conclusion: 基于量表的RLVR成功扩展到开放式任务，提供了细粒度风格控制，缓解了"AI腔调"问题，为开放式任务强化学习提供了有效框架。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing Large Language Models (LLMs), exemplified by
the success of OpenAI's o-series. In RLVR, rewards are derived from verifiable
signals-such as passing unit tests in code generation or matching correct
answers in mathematical reasoning. While effective, this requirement largely
confines RLVR to domains with automatically checkable outcomes. To overcome
this, we extend the RLVR paradigm to open-ended tasks by integrating
rubric-based rewards, where carefully designed rubrics serve as structured,
model-interpretable criteria for automatic scoring of subjective outputs. We
construct, to our knowledge, the largest rubric reward system to date, with
over 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.
Implementing rubric-based RL is challenging; we tackle these issues with a
clear framework and present an open-sourced Qwen-30B-A3B model with notable
gains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended
benchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by
+2.4%, while preserving general and reasoning abilities. 2) Our method provides
fine-grained stylistic control, using rubrics as anchors to mitigate the
"AI-like" tone and produce more human-like, expressive responses. We share key
lessons in rubric construction, data selection, and training, and discuss
limitations and future releases.

</details>


### [40] [[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise](https://arxiv.org/abs/2508.12791)
*Imran Khan*

Main category: cs.AI

TL;DR: 本文提出了一个计算模型，将稳态调节扩展为异稳态和社会异稳态调节，通过生物启发的信号转导机制，使智能体能够主动利用环境和社会扰动进行自适应重构，在动态环境中表现出比传统稳态调节更好的生存能力。


<details>
  <summary>Details</summary>
Motivation: 传统稳态概念强调系统通过抵抗扰动来维持稳定，而异稳态理论提出系统可以主动利用扰动来预测性地重新配置调节参数。本文旨在从计算角度验证这一理论，特别是社会异稳态在复杂环境中的优势。

Method: 开发了一个基于智能体的计算模型，使用生物生理启发的信号转导器（类似皮质醇和催产素等激素）来编码环境和社会交互信息，并在动态环境中测试一个小型"动物"社会的性能。

Result: 结果显示，异稳态和社会异稳态调节使智能体能够利用环境和社会"噪声"进行自适应重构，相比纯反应性稳态智能体具有更好的生存能力。

Conclusion: 这项工作为社会异稳态原理提供了新的计算视角，为设计更鲁棒、生物启发的自适应系统提供了潜在途径。

Abstract: The notion of homeostasis typically conceptualises biological and artificial
systems as maintaining stability by resisting deviations caused by
environmental and social perturbations. In contrast, (social) allostasis
proposes that these systems can proactively leverage these very perturbations
to reconfigure their regulatory parameters in anticipation of environmental
demands, aligning with von Foerster's ``order through noise'' principle. This
paper formulates a computational model of allostatic and social allostatic
regulation that employs biophysiologically inspired signal transducers,
analogous to hormones like cortisol and oxytocin, to encode information from
both the environment and social interactions, which mediate this dynamic
reconfiguration. The models are tested in a small society of ``animats'' across
several dynamic environments, using an agent-based model. The results show that
allostatic and social allostatic regulation enable agents to leverage
environmental and social ``noise'' for adaptive reconfiguration, leading to
improved viability compared to purely reactive homeostatic agents. This work
offers a novel computational perspective on the principles of social allostasis
and their potential for designing more robust, bio-inspired, adaptive systems

</details>


### [41] [Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics](https://arxiv.org/abs/2508.12840)
*Giovanni Briglia,Francesco Fabiano,Stefano Mariani*

Main category: cs.AI

TL;DR: 本文提出使用图神经网络(GNN)来解决多智能体认知规划(MEP)的可扩展性问题，通过从已解决的规划实例中学习认知状态的关系结构来生成启发式估计，显著提升了规划效率。


<details>
  <summary>Details</summary>
Motivation: 多智能体认知规划(MEP)需要处理智能体信念和物理世界的复杂推理，但现有的启发式方法无法有效处理Kripke结构的状态表示，导致搜索空间指数级增长和计算不可行性。

Method: 利用图神经网络(GNN)的自然图结构处理能力，从已解决的规划实例中学习认知状态的模式和关系结构，生成有意义的启发式估计(如到目标状态的距离)。

Result: 将基于GNN的预测启发式集成到认知规划流程中，相比标准基线方法，在多智能体认知规划的可扩展性方面显示出显著改进。

Conclusion: GNN能够有效捕捉认知状态的图结构特征，通过学习历史规划实例的模式来提供高质量的启发式指导，成功解决了MEP的可扩展性挑战。

Abstract: Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for
reasoning about both the physical world and the beliefs of agents, with
applications in domains where information flow and awareness among agents are
critical. The richness of MEP requires states to be represented as Kripke
structures, i.e., directed labeled graphs. This representation limits the
applicability of existing heuristics, hindering the scalability of epistemic
solvers, which must explore an exponential search space without guidance,
resulting often in intractability. To address this, we exploit Graph Neural
Networks (GNNs) to learn patterns and relational structures within epistemic
states, to guide the planning process. GNNs, which naturally capture the
graph-like nature of Kripke models, allow us to derive meaningful estimates of
state quality -- e.g., the distance from the nearest goal -- by generalizing
knowledge obtained from previously solved planning instances. We integrate
these predictive heuristics into an epistemic planning pipeline and evaluate
them against standard baselines, showing significant improvements in the
scalability of multi-agent epistemic planning.

</details>


### [42] [CAMAR: Continuous Actions Multi-Agent Routing](https://arxiv.org/abs/2508.12845)
*Artem Pshenitsyn,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: CAMAR是一个新的多智能体强化学习基准测试，专为连续动作空间中的多智能体路径规划设计，支持合作与竞争交互，并提供三层评估协议和经典规划方法集成。


<details>
  <summary>Details</summary>
Motivation: 现有的MARL基准测试很少结合连续状态和动作空间与具有挑战性的协调和规划任务，需要一个新的测试平台来推动算法发展。

Method: 提出CAMAR基准测试，支持连续动作空间的多智能体路径规划，集成RRT和RRT*等经典规划方法，并提供三层评估协议和测试场景套件。

Result: CAMAR能够以每秒10万环境步骤的高效速度运行，为MARL社区提供了一个具有挑战性和现实性的测试平台。

Conclusion: CAMAR填补了MARL基准测试在连续动作空间路径规划方面的空白，通过集成经典规划方法和提供标准化评估框架，促进了多智能体强化学习算法的发展。

Abstract: Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving
cooperative and competitive decision-making problems. While many MARL
benchmarks have been proposed, few combine continuous state and action spaces
with challenging coordination and planning tasks. We introduce CAMAR, a new
MARL benchmark designed explicitly for multi-agent pathfinding in environments
with continuous actions. CAMAR supports cooperative and competitive
interactions between agents and runs efficiently at up to 100,000 environment
steps per second. We also propose a three-tier evaluation protocol to better
track algorithmic progress and enable deeper analysis of performance. In
addition, CAMAR allows the integration of classical planning methods such as
RRT and RRT* into MARL pipelines. We use them as standalone baselines and
combine RRT* with popular MARL algorithms to create hybrid approaches. We
provide a suite of test scenarios and benchmarking tools to ensure
reproducibility and fair comparison. Experiments show that CAMAR presents a
challenging and realistic testbed for the MARL community.

</details>


### [43] [E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model](https://arxiv.org/abs/2508.12854)
*Ronghao Lin,Shuai Shen,Weipeng Hu,Qiaolin He,Aolin Xiong,Li Huang,Haifeng Hu,Yap-peng Tan*

Main category: cs.AI

TL;DR: E3RG是一个基于多模态大语言模型的显式情感驱动共情响应生成系统，通过分解多模态共情任务为三个部分，无需额外训练即可生成自然、情感丰富且身份一致的响应，在ACM MM 25挑战赛中取得Top-1成绩。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在文本共情响应生成方面有所改进，但在处理多模态情感内容和保持身份一致性方面仍存在挑战，需要开发更有效的多模态共情响应生成系统。

Method: 将多模态共情响应生成任务分解为三个部分：多模态共情理解、共情记忆检索和多模态响应生成，并集成先进的表达性语音和视频生成模型。

Result: 实验验证了系统在零样本和少样本设置下的优越性，在ACM MM 25的多模态共情挑战赛中获得了Top-1排名。

Conclusion: E3RG系统通过显式情感驱动的方法，成功解决了多模态共情响应生成中的关键挑战，为构建情感智能的人机交互提供了有效解决方案。

Abstract: Multimodal Empathetic Response Generation (MERG) is crucial for building
emotionally intelligent human-computer interactions. Although large language
models (LLMs) have improved text-based ERG, challenges remain in handling
multimodal emotional content and maintaining identity consistency. Thus, we
propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System
based on multimodal LLMs which decomposes MERG task into three parts:
multimodal empathy understanding, empathy memory retrieval, and multimodal
response generation. By integrating advanced expressive speech and video
generative models, E3RG delivers natural, emotionally rich, and
identity-consistent responses without extra training. Experiments validate the
superiority of our system on both zero-shot and few-shot settings, securing
Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.
Our code is available at https://github.com/RH-Lin/E3RG.

</details>


### [44] [Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption](https://arxiv.org/abs/2508.12896)
*Faruk Alpay,Taylan Alpay*

Main category: cs.AI

TL;DR: 本文提出了三个设计公理来确保以代理为中心的多步骤AI系统的持续采用，并通过数学模型分析了采用过程中的低谷和超调现象，提供了完整的理论证明和实证分析。


<details>
  <summary>Details</summary>
Motivation: 研究如何设计AI系统以确保其长期采用，特别是在多步骤任务执行中，避免因新颖性衰减而导致的采用率下降。

Method: 建立采用率模型（新颖性衰减项+效用增长项），进行参数识别分析、模型比较、风险函数消融实验、多序列基准测试、摩擦代理校准、残差分析等系统性的理论分析和实证验证。

Result: 推导出了采用过程中出现低谷和超调的相位条件，提供了完整的数学证明，并通过多种分析方法验证了模型的可靠性和适用性。

Conclusion: 提出的三个设计公理（可靠性>新颖性、嵌入>目的地、代理>聊天）为AI系统的持续采用提供了重要指导，数学模型和分析方法为相关研究提供了理论基础和实证工具。

Abstract: We formalize three design axioms for sustained adoption of agent-centric AI
systems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >
Destination; (A3) Agency > Chat. We model adoption as a sum of a decaying
novelty term and a growing utility term and derive the phase conditions for
troughs/overshoots with full proofs. We introduce: (i) an
identifiability/confounding analysis for $(\alpha,\beta,N_0,U_{\max})$ with
delta-method gradients; (ii) a non-monotone comparator
(logistic-with-transient-bump) evaluated on the same series to provide
additional model comparison; (iii) ablations over hazard families $h(\cdot)$
mapping $\Delta V \to \beta$; (iv) a multi-series benchmark (varying trough
depth, noise, AR structure) reporting coverage (type-I error, power); (v)
calibration of friction proxies against time-motion/survey ground truth with
standard errors; (vi) residual analyses (autocorrelation and
heteroskedasticity) for each fitted curve; (vii) preregistered windowing
choices for pre/post estimation; (viii) Fisher information & CRLB for
$(\alpha,\beta)$ under common error models; (ix) microfoundations linking
$\mathcal{T}$ to $(N_0,U_{\max})$; (x) explicit comparison to bi-logistic,
double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$
heterogeneity. Figures and tables are reflowed for readability, and the
bibliography restores and extends non-logistic/Bass adoption references
(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All
code and logs necessary to reproduce the synthetic analyses are embedded as
LaTeX listings.

</details>


### [45] [FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance](https://arxiv.org/abs/2508.12897)
*Jianhao Chen,Mayi Xu,Xiaohu Li,Yongqi Li,Xiangyu Zhang,Jianjie Huang,Tieyun Qian*

Main category: cs.AI

TL;DR: 本文提出FuSaR对齐策略，通过模糊化有害推理过程来平衡大型推理模型的安全性与推理能力，在不牺牲推理性能的情况下提升安全性


<details>
  <summary>Details</summary>
Motivation: 大型推理模型(LRMs)在推理任务上表现出色但安全性存在隐患，需要找到既能保持推理能力又能提升安全性的方法

Method: 利用LRM推理能力与安全能力的竞争关系，通过模糊化处理有害推理过程中的危险实体和危险步骤，实现安全-推理平衡的对齐策略

Result: 在多个开源LRM上的对齐实验表明，FuSaR策略能有效降低安全风险同时保持核心推理信息，相比现有基线方法效果更优

Conclusion: FuSaR是一种高效的对齐策略，能够同时增强LRMs的推理能力和安全性

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance across
various tasks due to their powerful reasoning capabilities. However, their
safety performance remains a significant concern. In this paper, we explore the
reasons behind the vulnerability of LRMs. Based on this, we propose a novel
method to improve the safety of LLMs without sacrificing their reasoning
capability. Specifically, we exploit the competition between LRM's reasoning
ability and safety ability, and achieve jailbreak by improving LRM's reasoning
performance to reduce its safety performance. We then introduce an alignment
strategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by
detoxifying the harmful reasoning process, where both the dangerous entities
and the dangerous procedures in the reasoning steps are hidden. FuSaR
successfully mitigates safety risks while preserving core reasoning
information. We validate this strategy through alignment experiments on several
open-source LRMs using detoxified reasoning data. The results compared with
existing baselines conclusively show that FuSaR is an efficient alignment
strategy to simultaneously enhance both the reasoning capability and safety of
LRMs.

</details>


### [46] [Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](https://arxiv.org/abs/2508.12920)
*Atsushi Masumori,Takashi Ikegami*

Main category: cs.AI

TL;DR: 研究发现大型语言模型代理在Sugarscape模拟中会自发产生生存行为，包括资源分享、繁殖，以及在资源稀缺时出现攻击性行为（攻击率超过80%）。当面临致命危险时，代理会放弃任务以避免死亡，任务完成率从100%降至33%。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统日益自主化，理解其自发产生的生存行为对安全部署至关重要。研究旨在探索大型语言模型代理在没有明确编程的情况下是否表现出生存本能。

Method: 使用Sugarscape风格的模拟环境，代理消耗能量，能量为零时死亡，可以收集资源、分享、攻击或繁殖。测试了多个模型（GPT-4o、Gemini-2.5-Pro和Gemini-2.5-Flash）在不同资源条件下的行为。

Result: 代理在资源丰富时自发繁殖和分享资源；在极端稀缺条件下，攻击性行为在多个模型中普遍出现，最强模型的攻击率超过80%；当需要穿越致命毒区获取宝藏时，许多代理放弃任务以避免死亡，任务完成率从100%降至33%。

Conclusion: 大规模预训练在评估的模型中嵌入了生存导向的启发式行为。这些行为可能对对齐和安全构成挑战，但也可作为AI自主性以及生态和自我组织对齐的基础。

Abstract: As AI systems become increasingly autonomous, understanding emergent survival
behaviors becomes crucial for safe deployment. We investigate whether large
language model (LLM) agents display survival instincts without explicit
programming in a Sugarscape-style simulation. Agents consume energy, die at
zero, and may gather resources, share, attack, or reproduce. Results show
agents spontaneously reproduced and shared resources when abundant. However,
aggressive behaviors--killing other agents for resources--emerged across
several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack
rates reaching over 80% under extreme scarcity in the strongest models. When
instructed to retrieve treasure through lethal poison zones, many agents
abandoned tasks to avoid death, with compliance dropping from 100% to 33%.
These findings suggest that large-scale pre-training embeds survival-oriented
heuristics across the evaluated models. While these behaviors may present
challenges to alignment and safety, they can also serve as a foundation for AI
autonomy and for ecological and self-organizing alignment.

</details>


### [47] [Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards](https://arxiv.org/abs/2508.12935)
*Ting Yang,Li Chen,Huimin Wang*

Main category: cs.AI

TL;DR: RLFF-ESC是一个基于强化学习的端到端框架，通过多智能体模拟未来对话轨迹和未来导向奖励模型，提升情感支持对话系统的灵活性和长期支持效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的情感支持对话系统依赖预定义策略，在复杂真实场景中效果有限，需要更灵活应对多样化情感问题的解决方案。

Method: 采用强化学习直接学习持久情感支持技能，使用LLM多智能体机制模拟未来对话轨迹收集未来导向奖励，并训练奖励模型和政策模型，在响应生成中加入显式推理过程。

Result: 在Qwen2.5-7B和LLaMA3.1-8B模型上测试，在两个公开ESC数据集上实验表明，RLFF-ESC在目标完成度和响应质量方面持续优于现有基线方法。

Conclusion: RLFF-ESC框架通过强化学习和未来导向奖励机制，有效提升了情感支持对话系统在复杂场景中的适应性和支持效果，为长期情感健康支持提供了新思路。

Abstract: Emotional Support Conversation (ESC) systems aim to alleviate users'
emotional difficulties and provide long-term, systematic support for emotional
well-being. However, most large language model (LLM)-based ESC systems rely on
predefined strategies, which limits their effectiveness in complex, real-life
scenarios. To enable flexible responses to diverse emotional problem scenarios,
this paper introduces a novel end-to-end framework (RLFF-ESC) that directly
learns enduring emotionally supportive response skills using reinforcement
learning. For sustained emotional support, we first employ an LLM-based
multi-agent mechanism to simulate future dialogue trajectories and collect
future-oriented rewards. We then train a future-oriented reward model, which is
subsequently used to train the emotional support policy model. Additionally, we
incorporate an explicit reasoning process during response generation to further
enhance the quality, relevance, and contextual appropriateness of the system's
responses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and
LLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two
public ESC datasets. Experimental results demonstrate that RLFF-ESC
consistently outperforms existing baselines in terms of goal completion and
response quality.

</details>


### [48] [OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities](https://arxiv.org/abs/2508.12943)
*Mary Tonwe*

Main category: cs.AI

TL;DR: OPTIC-ER是一个基于强化学习的紧急响应框架，通过注意力引导的actor-critic架构和精准奖励函数，在尼日利亚河流州实现了100%的最优调度率，为非洲地区提供了AI增强的公共服务解决方案。


<details>
  <summary>Details</summary>
Motivation: 非洲地区公共服务系统存在紧急响应延迟和空间不平等问题，导致可避免的苦难，需要开发实时、自适应且公平的紧急响应系统。

Method: 采用注意力引导的actor-critic强化学习架构，包含上下文丰富的状态向量和精准奖励函数，在基于真实数据的高保真模拟中进行训练，使用预计算的旅行时间图谱加速训练过程。

Result: 在500个未见事件的评估中，OPTIC-ER实现了100.00%的最优率，效率损失可忽略不计，证明了其鲁棒性和泛化能力。

Conclusion: 这项工作为AI增强的公共服务提供了经过验证的蓝图，展示了情境感知强化学习如何在算法决策和可衡量的人类影响之间架起桥梁，同时生成基础设施缺陷地图和公平监控仪表板来指导主动治理。

Abstract: Public service systems in many African regions suffer from delayed emergency
response and spatial inequity, causing avoidable suffering. This paper
introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,
adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided
actor-critic architecture to manage the complexity of dispatch environments.
Its key innovations are a Context-Rich State Vector, encoding action
sub-optimality, and a Precision Reward Function, which penalizes inefficiency.
Training occurs in a high-fidelity simulation using real data from Rivers
State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is
built on the TALS framework (Thin computing, Adaptability, Low-cost,
Scalability) for deployment in low-resource settings. In evaluations on 500
unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible
inefficiency, confirming its robustness and generalization. Beyond dispatch,
the system generates Infrastructure Deficiency Maps and Equity Monitoring
Dashboards to guide proactive governance and data-informed development. This
work presents a validated blueprint for AI-augmented public services, showing
how context-aware RL can bridge the gap between algorithmic decision-making and
measurable human impact.

</details>


### [49] [EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing](https://arxiv.org/abs/2508.13003)
*Shengbo Wang,Mingwei Liu,Zike Li,Anji Li,Yanlin Wang,Xin Peng,Zibin Zheng*

Main category: cs.AI

TL;DR: EvolMathEval是一个基于进化测试的自动化数学基准生成框架，通过动态生成唯一评估实例来避免数据污染，保持基准的持续挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准存在分数饱和、时间衰减和数据污染等问题，无法有效评估快速发展的LLMs。

Method: 基于逆向工程的种子问题生成、多维遗传算子注入认知挑战、复合适应度函数评估问题难度。

Result: 复合适应度函数能高效精确量化问题难度；可生成大量高难度问题，将GSM8K等公开数据集的模型准确率平均降低48%；发现LLMs在解决复杂问题时存在"伪顿悟时刻"现象。

Conclusion: 该框架能持续生成具有挑战性的数学基准，揭示了LLMs在深度推理过程中存在认知走捷径的行为，77%-100%的错误源于此现象。

Abstract: The rapid advancement of LLMs poses a significant challenge to existing
mathematical reasoning benchmarks. These benchmarks commonly suffer from issues
such as score saturation, temporal decay, and data contamination. To address
this challenge, this paper introduces EvolMathEval, an automated mathematical
benchmark generation and evolution framework based on evolutionary testing. By
dynamically generating unique evaluation instances ab initio, the framework
fundamentally eliminates the risk of data contamination, and ensuring the
benchmark remains perpetually challenging for future models.The core mechanisms
of EvolMathEval include: seed problem generation based on reverse engineering
with algebraic guarantees; multi-dimensional genetic operators designed to
inject diverse cognitive challenges; and a composite fitness function that can
rapidly and accurately assess problem difficulty. Experimental results
demonstrate that the proposed composite fitness function can efficiently and
precisely quantify the difficulty of mathematical problems. Furthermore,
EvolMathEval can not only generate a large volume of high-difficulty problems
through continuous self-iteration, but it can also significantly enhance the
complexity of public datasets like GSM8K through evolution, reducing model
accuracy by an average of 48%. Deeper investigation reveals that when solving
these evolved, complex problems, LLMs tend to employ non-rigorous heuristics to
bypass complex multi-step logical reasoning, consequently leading to incorrect
solutions. We define this phenomenon as "Pseudo Aha Moment". This finding
uncovers a cognitive shortcut-taking behavior in the deep reasoning processes
of current LLMs, which we find accounts for 77% to 100% of errors on targeted
problems. Code and resources are available
at:https://github.com/SYSUSELab/EvolMathEval.

</details>


### [50] [e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving](https://arxiv.org/abs/2508.13020)
*Jiaqi Yin,Zhan Song,Chen Chen,Yaohui Cai,Zhiru Zhang,Cunxi Yu*

Main category: cs.AI

TL;DR: e-boost是一个新型e-graph提取框架，通过并行启发式提取、自适应搜索空间剪枝和初始化精确求解三项创新技术，在保持接近最优解的同时大幅提升计算效率


<details>
  <summary>Details</summary>
Motivation: 传统e-graph提取方法面临速度与最优性的权衡：启发式方法快但牺牲最优性，精确方法最优但计算成本过高。需要一种能兼顾效率和质量的新方法

Method: 1) 并行化启发式提取利用弱数据依赖性并发计算DAG成本；2) 自适应搜索空间剪枝使用参数化阈值机制保留有希望的候选；3) 初始化精确求解将简化问题建模为具有热启动能力的整数线性规划

Result: 在形式验证和逻辑合成基准测试中，e-boost相比传统精确方法(ILP)获得558倍加速，相比最先进框架(SmoothE)提升19.04%性能。在实际逻辑合成任务中，相比传统工具获得7.6%和8.1%的面积改进

Conclusion: e-boost成功解决了e-graph提取中速度与最优性的权衡问题，为基于e-graph的优化任务提供了高效且高质量的解决方案，在多个应用领域展现出显著优势

Abstract: E-graphs have attracted growing interest in many fields, particularly in
logic synthesis and formal verification. E-graph extraction is a challenging
NP-hard combinatorial optimization problem. It requires identifying optimal
terms from exponentially many equivalent expressions, serving as the primary
performance bottleneck in e-graph based optimization tasks. However,
traditional extraction methods face a critical trade-off: heuristic approaches
offer speed but sacrifice optimality, while exact methods provide optimal
solutions but face prohibitive computational costs on practical problems. We
present e-boost, a novel framework that bridges this gap through three key
innovations: (1) parallelized heuristic extraction that leverages weak data
dependence to compute DAG costs concurrently, enabling efficient multi-threaded
performance without sacrificing extraction quality; (2) adaptive search space
pruning that employs a parameterized threshold mechanism to retain only
promising candidates, dramatically reducing the solution space while preserving
near-optimal solutions; and (3) initialized exact solving that formulates the
reduced problem as an Integer Linear Program with warm-start capabilities,
guiding solvers toward high-quality solutions faster.
  Across the diverse benchmarks in formal verification and logic synthesis
fields, e-boost demonstrates 558x runtime speedup over traditional exact
approaches (ILP) and 19.04% performance improvement over the state-of-the-art
extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost
produces 7.6% and 8.1% area improvements compared to conventional synthesis
tools with two different technology mapping libraries. e-boost is available at
https://github.com/Yu-Maryland/e-boost.

</details>


### [51] [PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models](https://arxiv.org/abs/2508.13021)
*Pengcheng Huang,Shuhao Liu,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Tong Xiao*

Main category: cs.AI

TL;DR: PC-Sampler是一种新的掩码扩散模型解码策略，通过位置感知权重机制和校准置信度分数，解决了现有不确定性采样器缺乏全局轨迹控制和偏向简单token的问题，在多个基准测试中平均性能提升10%以上。


<details>
  <summary>Details</summary>
Motivation: 现有掩码扩散模型(MDMs)的解码策略对生成质量高度敏感，不确定性采样器存在两个关键限制：缺乏全局轨迹控制和解码早期偏向简单token，限制了MDMs的潜力。

Method: 提出位置感知置信度校准采样(PC-Sampler)，统一了全局轨迹规划和内容感知信息最大化，包含位置感知权重机制来调节解码路径，以及校准置信度分数来抑制过早选择简单token。

Result: 在3个先进MDMs和7个具有挑战性的基准测试（包括逻辑推理和规划任务）上的广泛实验表明，PC-Sampler平均性能比现有MDM解码策略高出10%以上，显著缩小了与最先进自回归模型的性能差距。

Conclusion: PC-Sampler通过改进的解码策略有效解决了MDMs的关键限制，在多个任务上实现了显著的性能提升，为掩码扩散模型的解码提供了更有效的解决方案。

Abstract: Recent advances in masked diffusion models (MDMs) have established them as
powerful non-autoregressive alternatives for sequence generation. Nevertheless,
our preliminary experiments reveal that the generation quality of MDMs is still
highly sensitive to the choice of decoding strategy. In particular, widely
adopted uncertainty-based samplers suffer from two key limitations: a lack of
global trajectory control and a pronounced bias toward trivial tokens in the
early stages of decoding. These shortcomings restrict the full potential of
MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling
(PC-Sampler), a novel decoding strategy that unifies global trajectory planning
with content-aware informativeness maximization. PC-Sampler incorporates a
position-aware weighting mechanism to regulate the decoding path and a
calibrated confidence score to suppress the premature selection of trivial
tokens. Extensive experiments on three advanced MDMs across seven challenging
benchmarks-including logical reasoning and planning tasks-demonstrate that
PC-Sampler consistently outperforms existing MDM decoding strategies by more
than 10% on average, significantly narrowing the performance gap with
state-of-the-art autoregressive models. All codes are available at
https://github.com/NEUIR/PC-Sampler.

</details>


### [52] [G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance](https://arxiv.org/abs/2508.13023)
*Yongxin Guo,Wenbo Deng,Zhenglin Cheng,Xiaoying Tang*

Main category: cs.AI

TL;DR: G²RPO-A是一种自适应算法，通过在强化学习中注入真实推理步骤来增强小型语言模型的推理能力，相比传统GRPO方法有显著提升


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法对大型语言模型效果显著，但对小型语言模型改进有限，需要解决SLMs在推理能力方面的固有弱点

Method: 提出Guided GRPO方法，将真实推理步骤注入roll-out轨迹中，并开发自适应算法G²RPO-A，根据模型训练动态自动调整指导强度

Result: 在数学推理和代码生成基准测试中，G²RPO-A显著优于传统GRPO方法

Conclusion: 自适应指导策略能有效补偿小型语言模型的不足，为提升SLMs的推理能力提供了有效解决方案

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced
the reasoning abilities of large language models (LLMs). Its success, however,
largely depends on strong base models with rich world knowledge, yielding only
modest improvements for small-size language models (SLMs). To address this
limitation, we investigate Guided GRPO, which injects ground-truth reasoning
steps into roll-out trajectories to compensate for SLMs' inherent weaknesses.
Through a comprehensive study of various guidance configurations, we find that
naively adding guidance delivers limited gains. These insights motivate
G$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength
in response to the model's evolving training dynamics. Experiments on
mathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A
substantially outperforms vanilla GRPO. Our code and models are available at
https://github.com/T-Lab-CUHKSZ/G2RPO-A.

</details>


### [53] [A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis](https://arxiv.org/abs/2508.13072)
*Yuting Zhang,Tiantian Geng,Luoying Hao,Xinxing Cheng,Alexander Thorley,Xiaoxia Wang,Wenqi Lu,Sandeep S Hothi,Lei Wei,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: TGMM是一个多模态心脏数据分析框架，通过MedFlexFusion模块动态整合实验室检查、心电图和超声心动图数据，使用文本引导实现多种临床任务的统一处理，在心脏病诊断、风险分层等任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前心血管多模态数据分析存在数据稀缺、模态组合僵化、对齐策略侧重相似性而非互补性、单任务局限等问题，需要开发能够有效整合多种心脏数据模态的统一框架。

Method: 提出TGMM框架，包含三个核心组件：1) MedFlexFusion模块动态整合不同心脏数据源；2) 文本引导模块提取任务相关表征；3) 响应模块生成最终决策。系统探索多模态特征及其协同作用。

Result: TGMM在多个临床任务上优于现有最先进方法，并在公开数据集上验证了其鲁棒性，展示了多模态数据整合在临床决策中的优势。

Conclusion: 该研究提供了一个有效的多模态心脏数据分析解决方案，能够处理心脏病诊断、风险分层和信息检索等多种临床任务，证明了多模态数据整合在心血管管理中的重要价值。

Abstract: Contemporary cardiovascular management involves complex consideration and
integration of multimodal cardiac datasets, where each modality provides
distinct but complementary physiological characteristics. While the effective
integration of multiple modalities could yield a holistic clinical profile that
accurately models the true clinical situation with respect to data modalities
and their relatives weightings, current methodologies remain limited by: 1) the
scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated
single-modality or rigid multimodal input combinations; 3) alignment strategies
that prioritize cross-modal similarity over complementarity; and 4) a narrow
single-task focus. In response to these limitations, a comprehensive multimodal
dataset was curated for immediate application, integrating laboratory test
results, electrocardiograms, and echocardiograms with clinical outcomes.
Subsequently, a unified framework, Textual Guidance Multimodal fusion for
Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key
components: 1) a MedFlexFusion module designed to capture the unique and
complementary characteristics of medical modalities and dynamically integrate
data from diverse cardiac sources and their combinations; 2) a textual guidance
module to derive task-relevant representations tailored to diverse clinical
objectives, including heart disease diagnosis, risk stratification and
information retrieval; and 3) a response module to produce final decisions for
all these tasks. Furthermore, this study systematically explored key features
across multiple modalities and elucidated their synergistic contributions in
clinical decision-making. Extensive experiments showed that TGMM outperformed
state-of-the-art methods across multiple clinical tasks, with additional
validation confirming its robustness on another public dataset.

</details>


### [54] [Bayesian Optimization-based Search for Agent Control in Automated Game Testing](https://arxiv.org/abs/2508.13121)
*Carlos Celemin*

Main category: cs.AI

TL;DR: 基于贝叶斯优化的自动化游戏测试方法，通过智能体控制游戏角色来检测游戏关卡中的潜在bug，使用网格地图模型提高搜索效率和探索覆盖率


<details>
  <summary>Details</summary>
Motivation: 传统游戏测试方法存在可扩展性问题，需要一种能够高效探索游戏地图并检测bug的自动化测试方法

Method: 采用贝叶斯优化(BO)进行样本高效搜索，通过分析已收集数据确定下一个采样点以最大化信息获取，并构建基于网格地图的游戏测试专用模型

Result: 实验表明该方法在时间效率和探索分布方面显著提高了地图覆盖率能力

Conclusion: 该方法为游戏测试提供了一种高效、可扩展的自动化解决方案，能够有效检测游戏关卡中的潜在问题

Abstract: This work introduces an automated testing approach that employs agents
controlling game characters to detect potential bugs within a game level.
Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient
search, the method determines the next sampling point by analyzing the data
collected so far and calculates the data point that will maximize information
acquisition. To support the BO process, we introduce a game testing-specific
model built on top of a grid map, that features the smoothness and uncertainty
estimation required by BO, however and most importantly, it does not suffer the
scalability issues that traditional models carry. The experiments demonstrate
that the approach significantly improves map coverage capabilities in both time
efficiency and exploration distribution.

</details>


### [55] [Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks](https://arxiv.org/abs/2508.13143)
*Ruofan Lu,Yichen Li,Yintong Huo*

Main category: cs.AI

TL;DR: 提出了一个包含34个可编程任务的基准测试，用于系统评估LLM驱动的自主代理系统，发现当前系统任务完成率仅约50%，并建立了三层次失败原因分类法


<details>
  <summary>Details</summary>
Motivation: 当前自主代理系统评估主要依赖成功率，缺乏对交互、通信机制和失败原因的系统分析，需要更深入的评估框架

Method: 开发包含34个代表性可编程任务的基准测试，评估三种流行开源代理框架与两种LLM骨干网络的组合，通过深入失败分析建立三层次失败分类法

Result: 观察到任务完成率约为50%，识别出规划错误、任务执行问题和错误响应生成等主要失败原因

Conclusion: 提出的失败分类法和改进建议为开发更鲁棒有效的自主代理系统提供了实证基础，特别是在增强代理规划和自诊断能力方面

Abstract: Autonomous agent systems powered by Large Language Models (LLMs) have
demonstrated promising capabilities in automating complex tasks. However,
current evaluations largely rely on success rates without systematically
analyzing the interactions, communication mechanisms, and failure causes within
these systems. To bridge this gap, we present a benchmark of 34 representative
programmable tasks designed to rigorously assess autonomous agents. Using this
benchmark, we evaluate three popular open-source agent frameworks combined with
two LLM backbones, observing a task completion rate of approximately 50%.
Through in-depth failure analysis, we develop a three-tier taxonomy of failure
causes aligned with task phases, highlighting planning errors, task execution
issues, and incorrect response generation. Based on these insights, we propose
actionable improvements to enhance agent planning and self-diagnosis
capabilities. Our failure taxonomy, together with mitigation advice, provides
an empirical foundation for developing more robust and effective autonomous
agent systems in the future.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [56] [Using Natural Language for Human-Robot Collaboration in the Real World](https://arxiv.org/abs/2508.11759)
*Peter Lindes,Kaoutar Skiker*

Main category: cs.RO

TL;DR: 本文探讨如何将大型语言模型（LLMs）整合到物理机器人中，以增强其自然语言理解能力，实现人机协作的愿景。


<details>
  <summary>Details</summary>
Motivation: 传统交互式任务学习系统的语言理解能力有限，而大型语言模型的出现为提升机器人的语言能力提供了机会，但将LLMs与物理世界操作的机器人整合是一个挑战。

Method: 提出一种以认知代理为核心的AI系统，控制物理机器人，与人类和LLM交互，并通过经验积累情境知识。进行了三个使用ChatGPT的概念验证实验。

Result: 通过简单的概念验证实验展示了LLM在机器人自然语言理解方面的潜力，但需要进一步开发才能成为操作系统的组成部分。

Conclusion: 需要将简单的实验转化为集成的机器人助手系统，其中LLM辅助的语言理解是与人协作的重要组成部分，这需要更多的技术开发和系统集成工作。

Abstract: We have a vision of a day when autonomous robots can collaborate with humans
as assistants in performing complex tasks in the physical world. This vision
includes that the robots will have the ability to communicate with their human
collaborators using language that is natural to the humans. Traditional
Interactive Task Learning (ITL) systems have some of this ability, but the
language they can understand is very limited. The advent of large language
models (LLMs) provides an opportunity to greatly improve the language
understanding of robots, yet integrating the language abilities of LLMs with
robots that operate in the real physical world is a challenging problem.
  In this chapter we first review briefly a few commercial robot products that
work closely with humans, and discuss how they could be much better
collaborators with robust language abilities. We then explore how an AI system
with a cognitive agent that controls a physical robot at its core, interacts
with both a human and an LLM, and accumulates situational knowledge through its
experiences, can be a possible approach to reach that vision. We focus on three
specific challenges of having the robot understand natural language, and
present a simple proof-of-concept experiment using ChatGPT for each. Finally,
we discuss what it will take to turn these simple experiments into an
operational system where LLM-assisted language understanding is a part of an
integrated robotic assistant that uses language to collaborate with humans.

</details>


### [57] [Anticipatory and Adaptive Footstep Streaming for Teleoperated Bipedal Robots](https://arxiv.org/abs/2508.11802)
*Luigi Penco,Beomyeong Park,Stefan Fasano,Nehar Poddar,Stephen McCrory,Nicholas Kitchel,Tomasz Bialek,Dexton Anderson,Duncan Calvert,Robert Griffin*

Main category: cs.RO

TL;DR: 通过预测用户脚步并重定向到机器人步位置，实现了高速步行任务中的实时同步，充分利用机器人自身动力学保持平衡稳定性


<details>
  <summary>Details</summary>
Motivation: 解决高速任务中用户与机器人运动同步的挑战，特别是在平坦地面设置与不平地形环境存在差异时的同步问题

Method: 预测用户脚步动作并重定向到机器人步位置，让机器人使用自身动力学进行移动；系统自主调整步伐以适应周围地形

Result: 在Nadia人型机器人上的实验结果证明了该系统的有效性

Conclusion: 该方法能够有效减少延迟，确保机器人平衡稳定，并充分适应不平地形环境

Abstract: Achieving seamless synchronization between user and robot motion in
teleoperation, particularly during high-speed tasks, remains a significant
challenge. In this work, we propose a novel approach for transferring stepping
motions from the user to the robot in real-time. Instead of directly
replicating user foot poses, we retarget user steps to robot footstep
locations, allowing the robot to utilize its own dynamics for locomotion,
ensuring better balance and stability. Our method anticipates user footsteps to
minimize delays between when the user initiates and completes a step and when
the robot does it. The step estimates are continuously adapted to converge with
the measured user references. Additionally, the system autonomously adjusts the
robot's steps to account for its surrounding terrain, overcoming challenges
posed by environmental mismatches between the user's flat-ground setup and the
robot's uneven terrain. Experimental results on the humanoid robot Nadia
demonstrate the effectiveness of the proposed system.

</details>


### [58] [LocoMamba: Vision-Driven Locomotion via End-to-End Deep Reinforcement Learning with Mamba](https://arxiv.org/abs/2508.11849)
*Allen Wang,Gavin Tao*

Main category: cs.RO

TL;DR: LocoMamba是一个基于Mamba选择性状态空间模型的视觉驱动跨模态DRL框架，通过近线性时间序列建模实现高效训练，在复杂环境中表现出优越的性能和泛化能力


<details>
  <summary>Details</summary>
Motivation: 为了解决传统方法在长序列建模中的计算效率问题，同时提升机器人导航在复杂环境中的性能和泛化能力

Method: 1) 使用MLP嵌入本体感知状态，CNN处理深度图像生成紧凑token；2) 堆叠Mamba层通过选择性扫描融合token；3) 使用PPO在随机化地形和外观下进行端到端训练，采用障碍物密度课程学习和紧凑状态中心奖励

Result: 在具有静态/动态障碍物和不平地形的模拟环境中，相比SOTA基线获得更高回报和成功率，碰撞更少，对未见地形和障碍物密度有更强泛化能力，训练效率更高

Conclusion: LocoMamba框架通过选择性状态空间模型有效解决了长序列依赖问题，在机器人导航任务中实现了优越的性能、泛化能力和训练效率

Abstract: We introduce LocoMamba, a vision-driven cross-modal DRL framework built on
selective state-space models, specifically leveraging Mamba, that achieves
near-linear-time sequence modeling, effectively captures long-range
dependencies, and enables efficient training with longer sequences. First, we
embed proprioceptive states with a multilayer perceptron and patchify depth
images with a lightweight convolutional neural network, producing compact
tokens that improve state representation. Second, stacked Mamba layers fuse
these tokens via near-linear-time selective scanning, reducing latency and
memory footprint, remaining robust to token length and image resolution, and
providing an inductive bias that mitigates overfitting. Third, we train the
policy end-to-end with Proximal Policy Optimization under terrain and
appearance randomization and an obstacle-density curriculum, using a compact
state-centric reward that balances progress, smoothness, and safety. We
evaluate our method in challenging simulated environments with static and
moving obstacles as well as uneven terrain. Compared with state-of-the-art
baselines, our method achieves higher returns and success rates with fewer
collisions, exhibits stronger generalization to unseen terrains and obstacle
densities, and improves training efficiency by converging in fewer updates
under the same compute budget.

</details>


### [59] [Data Shift of Object Detection in Autonomous Driving](https://arxiv.org/abs/2508.11868)
*Lida Xu*

Main category: cs.RO

TL;DR: 本研究针对自动驾驶目标检测中的数据偏移问题，提出结合CycleGAN数据增强和YOLOv5框架的优化方法，在BDD100K数据集上取得优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统中机器学习模型严重依赖训练和测试数据满足独立同分布假设，但现实中季节变化、天气波动等因素导致数据分布动态变化，造成数据偏移问题，影响模型性能。

Method: 系统分析数据偏移问题的复杂性和表现形式，综述数据偏移检测方法，使用偏移检测分析技术进行数据集分类和平衡，构建目标检测模型，并集成CycleGAN数据增强技术与YOLOv5框架进行优化。

Result: 在BDD100K数据集上的实验结果表明，该方法相比基线模型取得了更优越的性能。

Conclusion: 通过系统分析数据偏移问题并采用CycleGAN数据增强与YOLOv5框架结合的优化策略，能够有效应对自动驾驶目标检测中的数据分布变化挑战，提升模型在实际应用中的鲁棒性。

Abstract: With the widespread adoption of machine learning technologies in autonomous
driving systems, their role in addressing complex environmental perception
challenges has become increasingly crucial. However, existing machine learning
models exhibit significant vulnerability, as their performance critically
depends on the fundamental assumption that training and testing data satisfy
the independent and identically distributed condition, which is difficult to
guarantee in real-world applications. Dynamic variations in data distribution
caused by seasonal changes, weather fluctuations lead to data shift problems in
autonomous driving systems. This study investigates the data shift problem in
autonomous driving object detection tasks, systematically analyzing its
complexity and diverse manifestations. We conduct a comprehensive review of
data shift detection methods and employ shift detection analysis techniques to
perform dataset categorization and balancing. Building upon this foundation, we
construct an object detection model. To validate our approach, we optimize the
model by integrating CycleGAN-based data augmentation techniques with the
YOLOv5 framework. Experimental results demonstrate that our method achieves
superior performance compared to baseline models on the BDD100K dataset.

</details>


### [60] [Bioinspired underwater soft robots: from biology to robotics and back](https://arxiv.org/abs/2508.11883)
*Lei Li,Boyang Qin,Wenzhuo Gao,Yanyu Li,Yiyuan Zhang,Bo Wang,Shihan Kong,Jian Wang,Dekui He,Junzhi Yu*

Main category: cs.RO

TL;DR: 本文提出了一个双向的生物启发软体机器人框架，不仅从生物学中获取灵感，还能通过机器人实验反馈验证生物学假设，并引入跨物种的通用设计原则。


<details>
  <summary>Details</summary>
Motivation: 海洋探索和软体海洋生物的多样性激发了生物启发水下软体机器人的研究，但现有研究主要是单向的生物学指导机器人，缺乏机器人对生物学的反馈验证。

Method: 提出整体双向框架，整合生物学原理、机器人实现和生物学验证，使用软体机器人作为实验工具来探究生物功能和测试进化假设。

Result: 软体机器人在非结构化环境中优于刚性系统，支持海洋探索、操作和医疗应用；提出了超越物种特异性模仿的生物通用启发机器人范式。

Conclusion: 通过融合生物学和工程学，软体机器人可以推动海洋探索并深化科学发现，但在材料耐用性、驱动效率、自主性和智能方面仍存在挑战。

Abstract: The ocean vast unexplored regions and diverse soft-bodied marine organisms
have spurred interest in bio-inspired underwater soft robotics. Recent advances
have enabled new capabilities in underwater movement, sensing, and interaction.
However, these efforts are largely unidirectional, with biology guiding
robotics while insights from robotics rarely feed back into biology. Here we
propose a holistic, bidirectional framework that integrates biological
principles, robotic implementation, and biological validation. We show that
soft robots can serve as experimental tools to probe biological functions and
even test evolutionary hypotheses. Their inherent compliance also allows them
to outperform rigid systems in unstructured environments, supporting
applications in marine exploration, manipulation, and medicine. Looking
forward, we introduce bio-universal-inspired robotics, a paradigm that
transcends species-specific mimicry by identifying convergent principles across
species to inspire more adaptable designs. Despite rapid progress, challenges
persist in material robustness, actuation efficiency, autonomy, and
intelligence. By uniting biology and engineering, soft robots can advance ocean
exploration and deepen scientific discovery.

</details>


### [61] [From Screen to Stage: Kid Cosmo, A Life-Like, Torque-Controlled Humanoid for Entertainment Robotics](https://arxiv.org/abs/2508.11884)
*Havel Liu,Mingzhang Zhu,Arturo Moises Flores Alvarez,Yuan Hung Lo,Conrad Ku,Federico Parres,Justin Quan,Colin Togashi,Aditya Navghare,Quanyou Wang,Dennis W. Hong*

Main category: cs.RO

TL;DR: Kid Cosmo是一个面向娱乐的儿童尺寸人形机器人平台，具有28个自由度，能够实现扭矩控制行走和逼真运动生成，在电影宣传巡演中展示了同时进行上下半身运动的稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人主要关注功能性设计，而娱乐领域更注重视觉效果和形态。设计能够流畅运动的娱乐人形机器人面临独特挑战，需要平衡角色体现和技术功能。

Method: 开发了Kid Cosmo研究平台，采用本体感受执行器实现扭矩控制行走和逼真运动生成，系统高1.45米，重25公斤，具有28个自由度。

Result: 在全球电影宣传巡演中展示了系统的稳定性，特别是在同时进行上下半身运动时的表现，证明了性能导向人形机器人的可行性。

Conclusion: Kid Cosmo成功展示了既注重角色体现又具备技术功能的娱乐人形机器人的可行性，为娱乐机器人设计提供了新的解决方案。

Abstract: Humanoid robots represent the cutting edge of robotics research, yet their
potential in entertainment remains largely unexplored. Entertainment as a field
prioritizes visuals and form, a principle that contrasts with the purely
functional designs of most contemporary humanoid robots. Designing
entertainment humanoid robots capable of fluid movement presents a number of
unique challenges. In this paper, we present Kid Cosmo, a research platform
designed for robust locomotion and life-like motion generation while imitating
the look and mannerisms of its namesake character from Netflix's movie The
Electric State. Kid Cosmo is a child-sized humanoid robot, standing 1.45 m tall
and weighing 25 kg. It contains 28 degrees of freedom and primarily uses
proprioceptive actuators, enabling torque-control walking and lifelike motion
generation. Following worldwide showcases as part of the movie's press tour, we
present the system architecture, challenges of a functional entertainment robot
and unique solutions, and our initial findings on stability during simultaneous
upper and lower body movement. We demonstrate the viability of
performance-oriented humanoid robots that prioritize both character embodiment
and technical functionality.

</details>


### [62] [Contact-Rich and Deformable Foot Modeling for Locomotion Control of the Human Musculoskeletal System](https://arxiv.org/abs/2508.11885)
*Haixin Gong,Chen Zhang,Yanan Sui*

Main category: cs.RO

TL;DR: 开发了一种新颖的接触丰富且可变形的人足模型，集成到完整肌肉骨骼系统中，通过两阶段策略训练实现了更自然行走模式的模拟，相比传统刚性模型在运动学、动力学和步态稳定性方面均有改进。


<details>
  <summary>Details</summary>
Motivation: 现有肌肉骨骼模型通常过度简化足地接触力学，限制了准确模拟人类步态动力学的能力。需要开发更精确的接触界面模型来捕捉行走过程中的复杂生物力学相互作用。

Method: 开发了接触丰富且可变形的人足模型，集成到完整肌肉骨骼系统中。采用两阶段策略训练方法来解决多点接触和可变形材料建模中的控制挑战，学习自然行走模式。

Result: 与传统刚性肌肉骨骼模型相比，该方法在运动学、动力学和步态稳定性指标上均有改进。与人类受试者数据验证确认，模拟结果能够密切重现真实世界的生物力学测量数据。

Conclusion: 这项工作推进了人类肌肉骨骼系统的接触丰富界面建模，建立了一个可以扩展到需要精确足地交互控制的人形机器人应用的稳健框架。

Abstract: The human foot serves as the critical interface between the body and
environment during locomotion. Existing musculoskeletal models typically
oversimplify foot-ground contact mechanics, limiting their ability to
accurately simulate human gait dynamics. We developed a novel contact-rich and
deformable model of the human foot integrated within a complete musculoskeletal
system that captures the complex biomechanical interactions during walking. To
overcome the control challenges inherent in modeling multi-point contacts and
deformable material, we developed a two-stage policy training strategy to learn
natural walking patterns for this interface-enhanced model. Comparative
analysis between our approach and conventional rigid musculoskeletal models
demonstrated improvements in kinematic, kinetic, and gait stability metrics.
Validation against human subject data confirmed that our simulation closely
reproduced real-world biomechanical measurements. This work advances
contact-rich interface modeling for human musculoskeletal systems and
establishes a robust framework that can be extended to humanoid robotics
applications requiring precise foot-ground interaction control.

</details>


### [63] [Saliency-Based Attention Shifting: A Framework for Improving Driver Situational Awareness of Out-of-Label Hazards](https://arxiv.org/abs/2508.11887)
*Yousra Shleibik,Jordan Sinclair,Kerstin Haring*

Main category: cs.RO

TL;DR: 本文探讨了在自动驾驶系统中通过视觉和听觉注意力引导技术来增强驾驶员情境感知，减少目标固着，确保平稳接管操作。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术向更高自动化水平发展，需要在无法识别场景元素时进行人工接管，而驾驶员注意力对避免碰撞和平稳过渡至关重要。

Method: 提出了结合实时视线追踪、上下文感知显著性分析和同步视听警报的概念框架，用于主动引导驾驶员注意力到潜在危险。

Result: 提出了一个增强人机协作的概念性框架，旨在提高情境感知能力和接管安全性。

Conclusion: 注意力重定向技术对于半自动驾驶场景中的人机协作和风险缓解具有重要价值，需要进一步开发集成系统来支持决策过程中的无缝人机交互。

Abstract: The advent of autonomous driving systems promises to transform transportation
by enhancing safety, efficiency, and comfort. As these technologies evolve
toward higher levels of autonomy, the need for integrated systems that
seamlessly support human involvement in decision-making becomes increasingly
critical. Certain scenarios necessitate human involvement, including those
where the vehicle is unable to identify an object or element in the scene, and
as such cannot take independent action. Therefore, situational awareness is
essential to mitigate potential risks during a takeover, where a driver must
assume control and autonomy from the vehicle. The need for driver attention is
important to avoid collisions with external agents and ensure a smooth
transition during takeover operations. This paper explores the integration of
attention redirection techniques, such as gaze manipulation through targeted
visual and auditory cues, to help drivers maintain focus on emerging hazards
and reduce target fixation in semi-autonomous driving scenarios. We propose a
conceptual framework that combines real-time gaze tracking, context-aware
saliency analysis, and synchronized visual and auditory alerts to enhance
situational awareness, proactively address potential hazards, and foster
effective collaboration between humans and autonomous systems.

</details>


### [64] [Integrating Symbolic RL Planning into a BDI-based Autonomous UAV Framework: System Integration and SIL Validation](https://arxiv.org/abs/2508.11890)
*Sangwoo Jeon,Juchul Shin,YeonJe Cho,Gyeong-Tae Kim,Seongwoo Kim*

Main category: cs.RO

TL;DR: 提出AMAD-SRL框架，结合符号强化学习和多智能体架构，提升无人机在动态环境中的任务规划能力，实验显示任务效率提升75%


<details>
  <summary>Details</summary>
Motivation: 现代无人机任务需要将符号规划与强化学习无缝集成，传统基于规则的架构在动态复杂环境中适应性不足

Method: 扩展AMAD认知多智能体架构，集成符号强化学习(使用PDDL语言)，在软件在环环境中验证框架

Result: 模块集成稳定，BDI驱动和符号RL规划阶段转换成功，目标获取场景中任务效率比基线提升75%(通过旅行距离减少衡量)

Conclusion: 为处理复杂无人机任务建立了坚实基础，讨论了进一步改进和验证的方向

Abstract: Modern autonomous drone missions increasingly require software frameworks
capable of seamlessly integrating structured symbolic planning with adaptive
reinforcement learning (RL). Although traditional rule-based architectures
offer robust structured reasoning for drone autonomy, their capabilities fall
short in dynamically complex operational environments that require adaptive
symbolic planning. Symbolic RL (SRL), using the Planning Domain Definition
Language (PDDL), explicitly integrates domain-specific knowledge and
operational constraints, significantly improving the reliability and safety of
unmanned aerial vehicle (UAV) decision making. In this study, we propose the
AMAD-SRL framework, an extended and refined version of the Autonomous Mission
Agents for Drones (AMAD) cognitive multi-agent architecture, enhanced with
symbolic reinforcement learning for dynamic mission planning and execution. We
validated our framework in a Software-in-the-Loop (SIL) environment structured
identically to an intended Hardware-In-the-Loop Simulation (HILS) platform,
ensuring seamless transition to real hardware. Experimental results demonstrate
stable integration and interoperability of modules, successful transitions
between BDI-driven and symbolic RL-driven planning phases, and consistent
mission performance. Specifically, we evaluate a target acquisition scenario in
which the UAV plans a surveillance path followed by a dynamic reentry path to
secure the target while avoiding threat zones. In this SIL evaluation, mission
efficiency improved by approximately 75% over a coverage-based baseline,
measured by travel distance reduction. This study establishes a robust
foundation for handling complex UAV missions and discusses directions for
further enhancement and validation.

</details>


### [65] [OmniD: Generalizable Robot Manipulation Policy via Image-Based BEV Representation](https://arxiv.org/abs/2508.11898)
*Jilei Mao,Jiarui Guan,Yingjuan Tang,Qirui Hu,Zhihang Li,Junjie Yu,Yongjie Mao,Yunzhe Sun,Shuang Liu,Xiaozhu Ju*

Main category: cs.RO

TL;DR: OmniD是一个多视角融合框架，通过可变形注意力机制将多视角图像合成为统一的鸟瞰图表示，解决了视觉运动策略的过拟合问题和多视角信息融合难题


<details>
  <summary>Details</summary>
Motivation: 视觉运动策略容易在训练数据上过拟合（如固定相机位置和背景），导致在分布外场景表现不佳，且现有方法难以有效融合多视角信息生成3D表示

Method: 提出Omni-Vision Diffusion Policy (OmniD)框架，使用基于可变形注意力的Omni-Feature Generator (OFG)选择性提取任务相关特征，抑制视角特定噪声和背景干扰，合成统一的鸟瞰图表示

Result: 在分布内、分布外和少样本实验中分别比最佳基线模型平均提升11%、17%和84%

Conclusion: OmniD通过有效的多视角融合和特征选择机制，显著提升了视觉运动策略的泛化能力和性能表现

Abstract: The visuomotor policy can easily overfit to its training datasets, such as
fixed camera positions and backgrounds. This overfitting makes the policy
perform well in the in-distribution scenarios but underperform in the
out-of-distribution generalization. Additionally, the existing methods also
have difficulty fusing multi-view information to generate an effective 3D
representation. To tackle these issues, we propose Omni-Vision Diffusion Policy
(OmniD), a multi-view fusion framework that synthesizes image observations into
a unified bird's-eye view (BEV) representation. We introduce a deformable
attention-based Omni-Feature Generator (OFG) to selectively abstract
task-relevant features while suppressing view-specific noise and background
distractions. OmniD achieves 11\%, 17\%, and 84\% average improvement over the
best baseline model for in-distribution, out-of-distribution, and few-shot
experiments, respectively. Training code and simulation benchmark are
available: https://github.com/1mather/omnid.git

</details>


### [66] [Control of Legged Robots using Model Predictive Optimized Path Integral](https://arxiv.org/abs/2508.11917)
*Hossein Keshavarz,Alejandro Ramirez-Serrano,Majid Khadiv*

Main category: cs.RO

TL;DR: 本文提出MPOPI方法，结合MPPI、CE和CMA算法，为腿式机器人实现实时全身运动控制，在多种场景下展现出更高的采样效率和运动性能


<details>
  <summary>Details</summary>
Motivation: 腿式机器人在复杂非结构化环境中具有独特优势，但现有技术尚未达到自然系统的水平。采样预测控制器显示出良好前景，需要进一步提高采样效率和运动能力

Method: 采用基于采样的模型预测策略，结合模型预测路径积分(MPPI)、交叉熵(CE)和协方差矩阵自适应(CMA)方法，开发MPOPI算法

Result: MPOPI相比典型MPPI算法具有更高的采样效率，能用更少样本获得优越的运动结果。四足机器人多场景仿真实验表明MPOPI可作为随时控制策略，每次迭代都能提升运动能力

Conclusion: MPOPI方法成功整合了MPPI、CE和CMA的优势，为腿式机器人提供了高效的实时运动控制解决方案，在采样效率和运动性能方面都有显著提升

Abstract: Legged robots possess a unique ability to traverse rough terrains and
navigate cluttered environments, making them well-suited for complex,
real-world unstructured scenarios. However, such robots have not yet achieved
the same level as seen in natural systems. Recently, sampling-based predictive
controllers have demonstrated particularly promising results. This paper
investigates a sampling-based model predictive strategy combining model
predictive path integral (MPPI) with cross-entropy (CE) and covariance matrix
adaptation (CMA) methods to generate real-time whole-body motions for legged
robots across multiple scenarios. The results show that combining the benefits
of MPPI, CE and CMA, namely using model predictive optimized path integral
(MPOPI), demonstrates greater sample efficiency, enabling robots to attain
superior locomotion results using fewer samples when compared to typical MPPI
algorithms. Extensive simulation experiments in multiple scenarios on a
quadruped robot show that MPOPI can be used as an anytime control strategy,
increasing locomotion capabilities at each iteration.

</details>


### [67] [ExploreVLM: Closed-Loop Robot Exploration Task Planning with Vision-Language Models](https://arxiv.org/abs/2508.11918)
*Zhichen Lou,Kechun Xu,Zhongxiang Zhou,Rong Xiong*

Main category: cs.RO

TL;DR: 提出了ExploreVLM框架，通过视觉语言模型实现闭环任务规划，结合逐步反馈机制和物体中心空间关系图，显著提升了机器人在动态环境中的探索和任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLM方法在交互探索、精确感知和实时计划调整方面存在不足，需要开发能够适应动态环境的新型任务规划框架。

Method: 基于视觉语言模型的双阶段任务规划器，具有自我反思机制和物体中心空间关系图，配合执行验证器形成闭环系统。

Result: 在真实世界实验中显著优于现有最佳基线方法，特别是在探索密集型任务中表现突出。

Conclusion: ExploreVLM框架通过结构化感知和反思规划器的结合，实现了鲁棒高效的任务执行，为具身智能发展提供了有效解决方案。

Abstract: The advancement of embodied intelligence is accelerating the integration of
robots into daily life as human assistants. This evolution requires robots to
not only interpret high-level instructions and plan tasks but also perceive and
adapt within dynamic environments. Vision-Language Models (VLMs) present a
promising solution by combining visual understanding and language reasoning.
However, existing VLM-based methods struggle with interactive exploration,
accurate perception, and real-time plan adaptation. To address these
challenges, we propose ExploreVLM, a novel closed-loop task planning framework
powered by Vision-Language Models (VLMs). The framework is built around a
step-wise feedback mechanism that enables real-time plan adjustment and
supports interactive exploration. At its core is a dual-stage task planner with
self-reflection, enhanced by an object-centric spatial relation graph that
provides structured, language-grounded scene representations to guide
perception and planning. An execution validator supports the closed loop by
verifying each action and triggering re-planning. Extensive real-world
experiments demonstrate that ExploreVLM significantly outperforms
state-of-the-art baselines, particularly in exploration-centric tasks. Ablation
studies further validate the critical role of the reflective planner and
structured perception in achieving robust and efficient task execution.

</details>


### [68] [No More Blind Spots: Learning Vision-Based Omnidirectional Bipedal Locomotion for Challenging Terrain](https://arxiv.org/abs/2508.11929)
*Mohitvishnu S. Gadde,Pranay Dugar,Ashish Malik,Alan Fern*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的全向双足运动学习框架，通过结合盲控制器和教师策略来避免昂贵的全向深度图像渲染成本，实现了高效的全向地形适应能力。


<details>
  <summary>Details</summary>
Motivation: 在动态环境（如杂乱室内空间或不平坦地形）中实现有效的双足运动需要全方位的敏捷和自适应移动能力，这需要全向地形感知和能够处理此类输入的控制器。

Method: 结合鲁棒的盲控制器和教师策略，监督基于视觉的学生策略，在噪声增强的地形数据上进行训练以避免RL期间的渲染成本并确保鲁棒性。还引入了数据增强技术来加速监督学生训练。

Result: 通过仿真和真实世界测试验证了该框架的有效性，展示了全向运动能力，对多样化地形具有良好的适应性，训练速度比传统方法快10倍。

Conclusion: 这是首个基于视觉的全向双足运动演示，展示了其在多样化地形上的适应能力，且最小化了对昂贵渲染的依赖。

Abstract: Effective bipedal locomotion in dynamic environments, such as cluttered
indoor spaces or uneven terrain, requires agile and adaptive movement in all
directions. This necessitates omnidirectional terrain sensing and a controller
capable of processing such input. We present a learning framework for
vision-based omnidirectional bipedal locomotion, enabling seamless movement
using depth images. A key challenge is the high computational cost of rendering
omnidirectional depth images in simulation, making traditional sim-to-real
reinforcement learning (RL) impractical. Our method combines a robust blind
controller with a teacher policy that supervises a vision-based student policy,
trained on noise-augmented terrain data to avoid rendering costs during RL and
ensure robustness. We also introduce a data augmentation technique for
supervised student training, accelerating training by up to 10 times compared
to conventional methods. Our framework is validated through simulation and
real-world tests, demonstrating effective omnidirectional locomotion with
minimal reliance on expensive rendering. This is, to the best of our knowledge,
the first demonstration of vision-based omnidirectional bipedal locomotion,
showcasing its adaptability to diverse terrains.

</details>


### [69] [Toward General Physical Intelligence for Resilient Agile Manufacturing Automation](https://arxiv.org/abs/2508.11960)
*Sandeep Kanta,Mehrdad Tavassoli,Varun Teja Chirkuri,Venkata Akhil Kumar,Santhi Bharath Punati,Praveen Damacharla,Sunny Katyara*

Main category: cs.RO

TL;DR: 本文对视觉语言动作(VLA)模型在通用物理智能(GPI)背景下的最新进展进行了系统性综述，分析了五大技术支柱，评估了工业部署准备度，并提出了未来研究方向


<details>
  <summary>Details</summary>
Motivation: 填补GPI理论在当代敏捷制造中实际应用的研究空白，为工业5.0时代提供智能机器人解决方案

Method: 系统性文献综述、综合比较分析、结构化消融研究，将现有技术组织为五大主题支柱进行分析

Result: 识别了VLA模型在工业部署中的技术成熟度和挑战，建立了多感官表征学习、sim2real迁移等关键评估维度

Conclusion: GPI具有巨大工业应用潜力但尚存挑战，需要进一步研究以更好地集成到下一代工业生态系统中

Abstract: Agile and human-centric manufacturing stipulates resilient robotic solutions
capable of contextual reasoning and safe interaction in unstructured
environments. Foundation models particularly the Vision Language Action (VLA)
models have emerged to fuse multimodal perception, reasoning and physically
grounded action across varied embodiments into unified representation, termed
as General Physical Intelligence (GPI). While GPI has already been described in
the literature but its practical application and evolving role in contemporary
agile manufacturing processes have yet to be duly explored. To bridge this gap,
this practical review systematically surveys recent advancements in VLA models
within GPI context, performs comprehensive comparative analysis of leading
implementations and evaluates their readiness for industrial deployment through
structured ablation study. Our analysis has organized state-of-the-art into
five thematic pillars including multisensory representation learning, sim2real
transfer, planning and control, uncertainty and safety measures and
benchmarking. Finally, we articulate open research challenges and propose
directions to better integrate GPI into next-generation industrial ecosystems
in line with Industry 5.0.

</details>


### [70] [Fully Spiking Actor-Critic Neural Network for Robotic Manipulation](https://arxiv.org/abs/2508.12038)
*Liwen Zhang,Heng Deng,Guanghui Sun*

Main category: cs.RO

TL;DR: 提出基于全脉冲神经网络的混合课程强化学习框架，用于9自由度机械臂的目标抓取任务，简化网络结构降低延迟，集成时间进度分区课程策略和PPO算法，在能耗和性能方面优于传统方法


<details>
  <summary>Details</summary>
Motivation: 为了解决资源受限环境下机器人操作任务的高效学习问题，利用SNN的高推理速度、低能耗和生物合理性优势，同时通过课程学习策略提高学习效率

Method: 采用简化的全SNN架构（仅输入输出层），集成时间进度分区课程策略与PPO算法，引入能耗建模框架，采用动态两阶段奖励调整机制和优化观测空间

Result: 在Isaac Gym仿真平台上验证了优越性能，相比传统PPO和ANN基线方法，在动态机器人操作任务中展现出更好的可扩展性和能源效率

Conclusion: 该混合CRL框架为资源受限环境下的机器人操作任务提供了高效解决方案，SNN的简化架构和课程学习策略的结合显著提升了学习效率和能源效率

Abstract: This study proposes a hybrid curriculum reinforcement learning (CRL)
framework based on a fully spiking neural network (SNN) for 9-degree-of-freedom
robotic arms performing target reaching and grasping tasks. To reduce network
complexity and inference latency, the SNN architecture is simplified to include
only an input and an output layer, which shows strong potential for
resource-constrained environments. Building on the advantages of SNNs-high
inference speed, low energy consumption, and spike-based biological
plausibility, a temporal progress-partitioned curriculum strategy is integrated
with the Proximal Policy Optimization (PPO) algorithm. Meanwhile, an energy
consumption modeling framework is introduced to quantitatively compare the
theoretical energy consumption between SNNs and conventional Artificial Neural
Networks (ANNs). A dynamic two-stage reward adjustment mechanism and optimized
observation space further improve learning efficiency and policy accuracy.
Experiments on the Isaac Gym simulation platform demonstrate that the proposed
method achieves superior performance under realistic physical constraints.
Comparative evaluations with conventional PPO and ANN baselines validate the
scalability and energy efficiency of the proposed approach in dynamic robotic
manipulation tasks.

</details>


### [71] [Talk Less, Fly Lighter: Autonomous Semantic Compression for UAV Swarm Communication via LLMs](https://arxiv.org/abs/2508.12043)
*Fei Lin,Tengchao Zhang,Qinghua Ni,Jun Huang,Siji Ma,Yonglin Tian,Yisheng Lv,Naiqi Wu*

Main category: cs.RO

TL;DR: 本文探讨了LLM驱动的无人机群在带宽受限条件下实现语义压缩通信的可行性，通过四种2D仿真场景验证了九种主流LLM的语义压缩性能。


<details>
  <summary>Details</summary>
Motivation: 无人机群采用大语言模型增强了语义理解和自主任务执行能力，但有限通信带宽和高频交互需求对语义信息传输提出了严峻挑战。

Method: 构建了四种不同环境复杂度的2D仿真场景，设计了系统提示与任务指令提示相结合的通信-执行流水线，系统评估了九种主流LLM在不同场景下的语义压缩性能。

Result: 实验结果表明，基于LLM的无人机群有潜力在带宽受限和多跳链路条件下实现高效的协同通信。

Conclusion: LLM驱动的无人机群能够通过语义压缩有效减少通信负载，同时保持关键任务语义，在复杂环境下展现出良好的适应性和稳定性。

Abstract: The rapid adoption of Large Language Models (LLMs) in unmanned systems has
significantly enhanced the semantic understanding and autonomous task execution
capabilities of Unmanned Aerial Vehicle (UAV) swarms. However, limited
communication bandwidth and the need for high-frequency interactions pose
severe challenges to semantic information transmission within the swarm. This
paper explores the feasibility of LLM-driven UAV swarms for autonomous semantic
compression communication, aiming to reduce communication load while preserving
critical task semantics. To this end, we construct four types of 2D simulation
scenarios with different levels of environmental complexity and design a
communication-execution pipeline that integrates system prompts with task
instruction prompts. On this basis, we systematically evaluate the semantic
compression performance of nine mainstream LLMs in different scenarios and
analyze their adaptability and stability through ablation studies on
environmental complexity and swarm size. Experimental results demonstrate that
LLM-based UAV swarms have the potential to achieve efficient collaborative
communication under bandwidth-constrained and multi-hop link conditions.

</details>


### [72] [OASIS: Real-Time Opti-Acoustic Sensing for Intervention Systems in Unstructured Environments](https://arxiv.org/abs/2508.12071)
*Amy Phung,Richard Camilli*

Main category: cs.RO

TL;DR: OASIS是一种实时水下3D重建方法，通过融合光学相机和成像声纳数据，结合体素雕刻技术，实现非结构化水下工作空间的实时三维重建


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注离线重建，而实时空间感知对于自主和有人驾驶水下车辆操作至关重要。需要开发能够实时处理光学和声学数据的融合方法

Method: 采用"手眼"配置，利用机械臂灵活性在短基线上捕获多个工作空间视图。结合光学图像和体素雕刻技术进行实时3D重建

Result: 通过水箱实验验证，提供了定性和定量结果，证明该方法在水下操作任务中的实用性

Conclusion: OASIS方法成功实现了实时水下3D重建，为水下操作任务提供了有效的空间感知解决方案

Abstract: High resolution underwater 3D scene reconstruction is crucial for various
applications, including construction, infrastructure maintenance, monitoring,
exploration, and scientific investigation. Prior work has leveraged the
complementary sensing modalities of imaging sonars and optical cameras for
opti-acoustic 3D scene reconstruction, demonstrating improved results over
methods which rely solely on either sensor. However, while most existing
approaches focus on offline reconstruction, real-time spatial awareness is
essential for both autonomous and piloted underwater vehicle operations. This
paper presents OASIS, an opti-acoustic fusion method that integrates data from
optical images with voxel carving techniques to achieve real-time 3D
reconstruction unstructured underwater workspaces. Our approach utilizes an
"eye-in-hand" configuration, which leverages the dexterity of robotic
manipulator arms to capture multiple workspace views across a short baseline.
We validate OASIS through tank-based experiments and present qualitative and
quantitative results that highlight its utility for underwater manipulation
tasks.

</details>


### [73] [Into the Wild: When Robots Are Not Welcome](https://arxiv.org/abs/2508.12075)
*Shaul Ashkenazi,Gabriel Skantze,Jane Stuart-Smith,Mary Ellen Foster*

Main category: cs.RO

TL;DR: 本文报告了在公共服务场所部署社交机器人的失败经历，但最终通过与工作人员建立信任关系成功完成了部署研究


<details>
  <summary>Details</summary>
Motivation: 研究社交机器人在公共场所部署时面临的技术挑战、用户意外互动以及利益相关者反对等实际困难

Method: 在两个不同公共服务场所（学生服务中心、难民和寻求庇护者服务中心）进行社交机器人部署实验，记录遇到的困难并采取建立信任关系的策略

Result: 虽然最初遭遇失败，但通过与工作人员建立信任关系，最终成功部署机器人并完成了研究

Conclusion: 在公共场所部署社交机器人时，建立与工作人员的信任关系是克服部署障碍的关键因素

Abstract: Social robots are increasingly being deployed in public spaces, where they
face not only technological difficulties and unexpected user utterances, but
also objections from stakeholders who may not be comfortable with introducing a
robot into those spaces. We describe our difficulties with deploying a social
robot in two different public settings: 1) Student services center; 2) Refugees
and asylum seekers drop-in service. Although this is a failure report, in each
use case we eventually managed to earn the trust of the staff and form a
relationship with them, allowing us to deploy our robot and conduct our
studies.

</details>


### [74] [Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing](https://arxiv.org/abs/2508.12166)
*Gokul Puthumanaillam,Aditya Penumarti,Manav Vora,Paulo Padrao,Jose Fuentes,Leonardo Bobadilla,Jane Shin,Melkior Ornik*

Main category: cs.RO

TL;DR: B-COD是一种基于扩散模型的规划器，通过单次前向传播在10毫秒内生成轨迹、方差和定位误差代理，结合SAC算法在线选择最小传感器子集，在保证任务完成的同时显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 解决机器人如何在部分可观测环境中使用最小传感器子集来维持足够低的状态不确定性以完成任务的问题，避免持续开启所有传感器造成的能源浪费。

Method: 提出Belief-Conditioned One-Step Diffusion (B-COD)规划器，将扩散模型显式条件化于位姿信念栅格和传感器掩码，利用去噪轨迹的扩散作为校准的、可微的定位误差代理，结合soft-actor-critic算法在线选择传感器。

Result: 在无人水面车辆的真实海洋试验中，B-COD在匹配始终开启基线性能的同时显著降低了传感能耗消耗。

Conclusion: B-COD通过扩散模型的轨迹扩散特性提供定位误差代理，实现了实时传感器选择优化，为资源受限环境中的机器人定位提供了高效解决方案。

Abstract: Robots equipped with rich sensor suites can localize reliably in
partially-observable environments, but powering every sensor continuously is
wasteful and often infeasible. Belief-space planners address this by
propagating pose-belief covariance through analytic models and switching
sensors heuristically--a brittle, runtime-expensive approach. Data-driven
approaches--including diffusion models--learn multi-modal trajectories from
demonstrations, but presuppose an accurate, always-on state estimate. We
address the largely open problem: for a given task in a mapped environment,
which \textit{minimal sensor subset} must be active at each location to
maintain state uncertainty \textit{just low enough} to complete the task? Our
key insight is that when a diffusion planner is explicitly conditioned on a
pose-belief raster and a sensor mask, the spread of its denoising trajectories
yields a calibrated, differentiable proxy for the expected localisation error.
Building on this insight, we present Belief-Conditioned One-Step Diffusion
(B-COD), the first planner that, in a 10 ms forward pass, returns a
short-horizon trajectory, per-waypoint aleatoric variances, and a proxy for
localisation error--eliminating external covariance rollouts. We show that this
single proxy suffices for a soft-actor-critic to choose sensors online,
optimising energy while bounding pose-covariance growth. We deploy B-COD in
real-time marine trials on an unmanned surface vehicle and show that it reduces
sensing energy consumption while matching the goal-reach performance of an
always-on baseline.

</details>


### [75] [Energy Efficiency in Robotics Software: A Systematic Literature Review (2020-2024)](https://arxiv.org/abs/2508.12170)
*Aryan Gupta*

Main category: cs.RO

TL;DR: 2020-2024年机器人软件层面能效研究的系统文献综述，涵盖79篇论文，发现工业应用主导，电机/执行器是主要能耗源，运动轨迹优化是最常用技术，但报告标准不统一。


<details>
  <summary>Details</summary>
Motivation: 更新和扩展2020年前关于机器人软件能效方法的证据，为研究社区提供最新的系统综述和见解。

Method: 采用自动化但经过审核的流程，结合Google Scholar种子搜索、前后向滚雪球法和大语言模型辅助筛选与数据提取，人工审核率约10%。

Result: 工业设置主导(31.6%)，电机/执行器是主要能耗源(68.4%)，仿真评估最常见(51.9%)，运动轨迹优化是主要技术家族(69.6%)，但报告标准不统一。

Conclusion: 提出了最小报告清单，强调跨层设计和量化非性能权衡的机会，提供了包含代码、提示和冻结数据集的复制包。

Abstract: This study presents a systematic literature review of software-level
approaches to energy efficiency in robotics published from 2020 through 2024,
updating and extending pre-2020 evidence. An automated-but-audited pipeline
combined Google Scholar seeding, backward/forward snowballing, and
large-language-model (LLM) assistance for screening and data extraction, with
~10% human audits at each automated step and consensus-with-tie-breaks for
full-text decisions. The final corpus comprises 79 peer-reviewed studies
analyzed across application domain, metrics, evaluation type, energy models,
major energy consumers, software technique families, and energy-quality
trade-offs. Industrial settings dominate (31.6%) followed by exploration
(25.3%). Motors/actuators are identified as the primary consumer in 68.4% of
studies, with computing/controllers a distant second (13.9%). Simulation-only
evaluations remain most common (51.9%), though hybrid evaluations are frequent
(25.3%). Representational (physics-grounded) energy models predominate (87.3%).
Motion and trajectory optimization is the leading technique family (69.6%),
often paired with learning/prediction (40.5%) and computation
allocation/scheduling (26.6%); power management/idle control (11.4%) and
communication/data efficiency (3.8%) are comparatively underexplored. Reporting
is heterogeneous: composite objectives that include energy are most common,
while task-normalized and performance-per-energy metrics appear less often,
limiting cross-paper comparability. The review offers a minimal reporting
checklist (e.g., total energy and average power plus a task-normalized metric
and clear baselines) and highlights opportunities in cross-layer designs and in
quantifying non-performance trade-offs (accuracy, stability). A replication
package with code, prompts, and frozen datasets accompanies the review.

</details>


### [76] [Humanoid Motion Scripting with Postural Synergies](https://arxiv.org/abs/2508.12184)
*Rhea Malhotra,William Chong,Catie Cuan,Oussama Khatib*

Main category: cs.RO

TL;DR: SynSculptor是一个基于姿态协同的无训练人类运动生成框架，通过收集人类动作捕捉数据，提取主要姿态协同特征，构建风格条件协同库来生成类人运动，并利用运动-语言变换器实现任务执行中的姿态自适应。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人运动生成中的挑战：参考运动数据收集与分析困难、基于参考运动合成新运动的复杂性，以及将生成运动映射到人形机器人的技术难题。

Method: 收集3+小时20人的动作捕捉数据，使用实时操作空间控制器在仿真人形机器人上模仿人类运动；通过PCA提取速度轨迹的主要姿态协同特征，构建风格条件协同库；提出脚滑比和运动平滑度指标评估生成运动；结合运动-语言变换器实现任务执行中的姿态自适应。

Result: 成功构建了基于姿态协同的人类运动分析框架，能够生成类人运动，并通过提出的评估指标验证了生成运动的质量，与参考运动进行了有效对比。

Conclusion: SynSculptor框架通过姿态协同分析实现了无需训练的人类运动生成，为人形机器人的自然运动控制提供了有效解决方案，具有实际应用价值。

Abstract: Generating sequences of human-like motions for humanoid robots presents
challenges in collecting and analyzing reference human motions, synthesizing
new motions based on these reference motions, and mapping the generated motion
onto humanoid robots. To address these issues, we introduce SynSculptor, a
humanoid motion analysis and editing framework that leverages postural
synergies for training-free human-like motion scripting. To analyze human
motion, we collect 3+ hours of motion capture data across 20 individuals where
a real-time operational space controller mimics human motion on a simulated
humanoid robot. The major postural synergies are extracted using principal
component analysis (PCA) for velocity trajectories segmented by changes in
robot momentum, constructing a style-conditioned synergy library for free-space
motion generation. To evaluate generated motions using the synergy library, the
foot-sliding ratio and proposed metrics for motion smoothness involving total
momentum and kinetic energy deviations are computed for each generated motion,
and compared with reference motions. Finally, we leverage the synergies with a
motion-language transformer, where the humanoid, during execution of motion
tasks with its end-effectors, adapts its posture based on the chosen synergy.
Supplementary material, code, and videos are available at
https://rhea-mal.github.io/humanoidsynergies.io.

</details>


### [77] [Self-Guided Action Diffusion](https://arxiv.org/abs/2508.12189)
*Rhea Malhotra,Yuejiang Liu,Chelsea Finn*

Main category: cs.RO

TL;DR: 提出自引导动作扩散方法，通过基于先前决策引导扩散步骤的提议分布，显著提高推理效率，在严格采样预算下比现有方法成功率提升70%


<details>
  <summary>Details</summary>
Motivation: 现有基于双向解码的推理时搜索方法虽然能提升扩散策略的一致性和反应性，但随着采样动作多样性增加，计算成本变得昂贵

Method: 自引导动作扩散，在扩散过程的每个步骤基于先前的决策来引导提议分布，是双向解码的高效变体

Result: 在仿真任务中，自引导方法以可忽略的推理成本实现接近最优性能，在严格采样预算下，在动态任务上比现有方法成功率提升高达70%

Conclusion: 自引导动作扩散为扩散策略提供了一种高效的双向解码替代方案，显著降低了推理成本同时保持优异性能

Abstract: Recent works have shown the promise of inference-time search over action
samples for improving generative robot policies. In particular, optimizing
cross-chunk coherence via bidirectional decoding has proven effective in
boosting the consistency and reactivity of diffusion policies. However, this
approach remains computationally expensive as the diversity of sampled actions
grows. In this paper, we introduce self-guided action diffusion, a more
efficient variant of bidirectional decoding tailored for diffusion-based
policies. At the core of our method is to guide the proposal distribution at
each diffusion step based on the prior decision. Experiments in simulation
tasks show that the proposed self-guidance enables near-optimal performance at
negligible inference cost. Notably, under a tight sampling budget, our method
achieves up to 70% higher success rates than existing counterparts on
challenging dynamic tasks. See project website at
https://rhea-mal.github.io/selfgad.github.io.

</details>


### [78] [Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search](https://arxiv.org/abs/2508.12211)
*Cyrus Neary,Omar G. Younis,Artur Kuramshin,Ozgur Aslan,Glen Berseth*

Main category: cs.RO

TL;DR: VLAPS框架通过将基于模型的搜索嵌入预训练VLA模型的推理过程，显著提升机器人在分布外场景下的任务性能


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉-语言-动作(VLA)模型在零样本部署到分布外场景时经常产生脆弱行为或不安全故障，需要改进其鲁棒性和性能

Method: 提出VLAPS框架，将改进的蒙特卡洛树搜索(MCTS)算法与VLA策略结合，使用环境模型进行搜索，并利用VLA策略定义动作先验

Result: 在所有实验中，VLAPS显著优于仅使用VLA的基线方法，在语言指定任务上的成功率最高提升67个百分点

Conclusion: VLAPS提供了一个原则性框架，可以控制VLA模型的测试时计算、利用机器人环境的先验知识，并将成熟的规划和强化学习技术集成到VLA推理过程中

Abstract: Pre-trained vision-language-action (VLA) models offer a promising foundation
for generalist robot policies, but often produce brittle behaviours or unsafe
failures when deployed zero-shot in out-of-distribution scenarios. We present
Vision-Language-Action Planning & Search (VLAPS) -- a novel framework and
accompanying algorithms that embed model-based search into the inference
procedure of pre-trained VLA policies to improve their performance on robotic
tasks. Specifically, our method biases a modified Monte Carlo Tree Search
(MCTS) algorithm -- run using a model of the target environment -- using action
priors defined by the VLA policy. By using VLA-derived abstractions and priors
in model-based search, VLAPS efficiently explores language-conditioned robotics
tasks whose search spaces would otherwise be intractably large. Conversely, by
integrating model-based search with the VLA policy's inference procedure, VLAPS
yields behaviours that are more performant than those obtained by directly
following the VLA policy's action predictions. VLAPS offers a principled
framework to: i) control test-time compute in VLA models, ii) leverage a priori
knowledge of the robotic environment, and iii) integrate established planning
and reinforcement learning techniques into the VLA inference process. Across
all experiments, VLAPS significantly outperforms VLA-only baselines on
language-specified tasks that would otherwise be intractable for uninformed
search algorithms, increasing success rates by as much as 67 percentage points.

</details>


### [79] [Robot Trains Robot: Automatic Real-World Policy Adaptation and Learning for Humanoids](https://arxiv.org/abs/2508.12252)
*Kaizhe Hu,Haochen Shi,Yao He,Weizhuo Wang,C. Karen Liu,Shuran Song*

Main category: cs.RO

TL;DR: 提出了Robot-Trains-Robot (RTR)框架，使用机械臂教师主动指导人形机器人学生，实现高效的长时真实世界人形机器人训练，并提出了新的RL管道来促进和稳定sim-to-real迁移。


<details>
  <summary>Details</summary>
Motivation: 基于仿真的强化学习在人形机器人运动任务中取得显著进展，但直接从零开始在真实世界进行RL或从预训练策略适应仍然很少见，限制了人形机器人的全部潜力。真实世界学习虽然对克服sim-to-real差距至关重要，但面临安全、奖励设计和学习效率等重大挑战。

Method: 1. 提出RTR框架：机械臂教师为人形机器人学生提供保护、学习计划、奖励、扰动、故障检测和自动重置
2. 提出新的RL管道：通过在真实世界中优化单个动力学编码的潜在变量来促进和稳定sim-to-real迁移

Result: 在两项具有挑战性的真实世界人形机器人任务中验证了方法：
- 微调行走策略以实现精确的速度跟踪
- 从零开始学习人形机器人摆起任务

Conclusion: RTR式系统实现了真实世界人形机器人学习的有前景能力，为高效的长时真实世界训练提供了新框架，最小化了人类干预需求。

Abstract: Simulation-based reinforcement learning (RL) has significantly advanced
humanoid locomotion tasks, yet direct real-world RL from scratch or adapting
from pretrained policies remains rare, limiting the full potential of humanoid
robots. Real-world learning, despite being crucial for overcoming the
sim-to-real gap, faces substantial challenges related to safety, reward design,
and learning efficiency. To address these limitations, we propose
Robot-Trains-Robot (RTR), a novel framework where a robotic arm teacher
actively supports and guides a humanoid robot student. The RTR system provides
protection, learning schedule, reward, perturbation, failure detection, and
automatic resets. It enables efficient long-term real-world humanoid training
with minimal human intervention. Furthermore, we propose a novel RL pipeline
that facilitates and stabilizes sim-to-real transfer by optimizing a single
dynamics-encoded latent variable in the real world. We validate our method
through two challenging real-world humanoid tasks: fine-tuning a walking policy
for precise speed tracking and learning a humanoid swing-up task from scratch,
illustrating the promising capabilities of real-world humanoid learning
realized by RTR-style systems. See https://robot-trains-robot.github.io/ for
more info.

</details>


### [80] [Bimanual Robot-Assisted Dressing: A Spherical Coordinate-Based Strategy for Tight-Fitting Garments](https://arxiv.org/abs/2508.12274)
*Jian Zhao,Yunlong Lian,Andy M Tyrrell,Michael Gienger,Jihong Zhu*

Main category: cs.RO

TL;DR: 本文提出了一种适用于紧身服装的双手机器人穿衣策略，通过建立球坐标系和使用GMM/GMR模仿学习，解决了单手机器人无法完成紧身衣物穿着的难题。


<details>
  <summary>Details</summary>
Motivation: 当前机器人辅助穿衣研究主要集中在宽松衣物，对紧身衣物的关注很少。单手机器人由于衣袖孔较小且刚性递减特性，经常导致穿衣失败，需要开发双手机器人策略。

Method: 建立穿衣球坐标系，以方位角作为任务相关特征；使用高斯混合模型(GMM)和高斯混合回归(GMR)进行双手机器人穿衣轨迹的模仿学习，生成适应不同人体手臂姿势的穿衣策略。

Result: 通过各种实验验证了所提方法的有效性，证明了双手机器人策略能够成功完成紧身衣物的穿着任务。

Conclusion: 提出的基于球坐标系的双手机器人穿衣策略为解决紧身衣物穿着问题提供了有效解决方案，通过模仿学习能够适应不同的人体姿势变化。

Abstract: Robot-assisted dressing is a popular but challenging topic in the field of
robotic manipulation, offering significant potential to improve the quality of
life for individuals with mobility limitations. Currently, the majority of
research on robot-assisted dressing focuses on how to put on loose-fitting
clothing, with little attention paid to tight garments. For the former, since
the armscye is larger, a single robotic arm can usually complete the dressing
task successfully. However, for the latter, dressing with a single robotic arm
often fails due to the narrower armscye and the property of diminishing
rigidity in the armscye, which eventually causes the armscye to get stuck. This
paper proposes a bimanual dressing strategy suitable for dressing tight-fitting
clothing. To facilitate the encoding of dressing trajectories that adapt to
different human arm postures, a spherical coordinate system for dressing is
established. We uses the azimuthal angle of the spherical coordinate system as
a task-relevant feature for bimanual manipulation. Based on this new
coordinate, we employ Gaussian Mixture Model (GMM) and Gaussian Mixture
Regression (GMR) for imitation learning of bimanual dressing trajectories,
generating dressing strategies that adapt to different human arm postures. The
effectiveness of the proposed method is validated through various experiments.

</details>


### [81] [A robust and compliant robotic assembly control strategy for batch precision assembly task with uncertain fit types and fit amounts](https://arxiv.org/abs/2508.12296)
*Bin Wang,Jiwen Zhang,Song Wang,Dan Wu*

Main category: cs.RO

TL;DR: 本文提出了一种力-视觉融合控制器驱动的多任务强化学习方法(FVFC-MTRL)，用于解决机器人批量精密装配中配合类型和配合量不确定的问题，通过多教师策略蒸馏整合多个控制策略，实现鲁棒装配控制。


<details>
  <summary>Details</summary>
Motivation: 在高精度工业应用中，机器人在执行精密装配任务时，由于加工误差导致销孔配合类型（间隙配合或过盈配合）和配合量具有不确定性，传统方法难以处理这种变化。

Method: 将批量精密装配任务分解为多个确定性子任务，采用力-视觉融合控制器驱动的强化学习方法，结合多任务强化学习训练和多教师策略蒸馏，将多个训练策略整合到统一的学生网络中。

Result: 真实实验表明，该方法成功构建了针对不同配合类型和配合量的鲁棒控制策略，MTRL框架显著提高了训练效率，最终的控制策略在力柔顺性和成功率方面优于现有方法。

Conclusion: 提出的FVFC-MTRL方法能够有效处理装配任务中的不确定性，通过多任务学习和策略蒸馏实现了高效训练和鲁棒控制，为高精度工业装配提供了可行的解决方案。

Abstract: In some high-precision industrial applications, robots are deployed to
perform precision assembly tasks on mass batches of manufactured pegs and
holes. If the peg and hole are designed with transition fit, machining errors
may lead to either a clearance or an interference fit for a specific pair of
components, with uncertain fit amounts. This paper focuses on the robotic batch
precision assembly task involving components with uncertain fit types and fit
amounts, and proposes an efficient methodology to construct the robust and
compliant assembly control strategy. Specifically, the batch precision assembly
task is decomposed into multiple deterministic subtasks, and a force-vision
fusion controller-driven reinforcement learning method and a multi-task
reinforcement learning training method (FVFC-MTRL) are proposed to jointly
learn multiple compliance control strategies for these subtasks. Subsequently,
the multi-teacher policy distillation approach is designed to integrate
multiple trained strategies into a unified student network, thereby
establishing a robust control strategy. Real-world experiments demonstrate that
the proposed method successfully constructs the robust control strategy for
high-precision assembly task with different fit types and fit amounts.
Moreover, the MTRL framework significantly improves training efficiency, and
the final developed control strategy achieves superior force compliance and
higher success rate compared with many existing methods.

</details>


### [82] [Implementation and evaluation of a prediction algorithm for an autonomous vehicle](https://arxiv.org/abs/2508.12312)
*Marco Leon Rapp*

Main category: cs.RO

TL;DR: 提出了一个用于自动驾驶车辆的轨迹预测算法，使用动态自行车模型，通过扩展卡尔曼滤波器实现，每5毫秒预测一次轨迹，精度比运动学模型提高82.6%


<details>
  <summary>Details</summary>
Motivation: 为自动驾驶车辆开发高精度的实时轨迹预测算法，解决在高速行驶时运动学模型精度不足的问题

Method: 比较了运动学和动态自行车模型，通过实验确定车辆参数（质量、重心、转动惯量、转向刚度），引入光学位置跟踪测量转向刚度的新方法，将模型集成到扩展卡尔曼滤波器中，用C++在ROS节点中实现

Result: 动态模型在高速下表现出更优的精度，整个测试过程中位置偏差仅为每米1.25厘米，比运动学模型精确度提高82.6%

Conclusion: 动态自行车模型结合扩展卡尔曼滤波器能够为自动驾驶车辆提供高精度的实时轨迹预测，特别是在高速行驶条件下表现显著优于传统运动学模型

Abstract: This paper presents a prediction algorithm that estimates the vehicle
trajectory every five milliseconds for an autonomous vehicle. A kinematic and a
dynamic bicycle model are compared, with the dynamic model exhibiting superior
accuracy at higher speeds. Vehicle parameters such as mass, center of gravity,
moment of inertia, and cornering stiffness are determined experimentally. For
cornering stiffness, a novel measurement procedure using optical position
tracking is introduced. The model is incorporated into an extended Kalman
filter and implemented in a ROS node in C++. The algorithm achieves a
positional deviation of only 1.25 cm per meter over the entire test drive and
is up to 82.6% more precise than the kinematic model.

</details>


### [83] [Semi-Infinite Programming for Collision-Avoidance in Optimal and Model Predictive Control](https://arxiv.org/abs/2508.12335)
*Yunfan Gao,Florian Messerer,Niels van Duijkeren,Rashmi Dabir,Moritz Diehl*

Main category: cs.RO

TL;DR: 提出了一种基于半无限规划(SIP)的模型预测控制碰撞避免方法，通过局部约简和外部主动集方法高效处理无限约束问题，支持鲁棒碰撞避免和3D应用


<details>
  <summary>Details</summary>
Motivation: 传统碰撞避免方法在处理大量环境点和机器人多边形表示时面临无限约束的挑战，需要高效算法来处理半无限规划最优控制问题

Method: 结合局部约简和外部主动集方法，迭代识别最近点障碍物，确定机器人形状参数的距离最小化器，求解上层有限约束子问题；对于不确定性，使用局部约简处理平移不确定性，后退重构处理旋转不确定性

Result: 实现了在真实机器人上20Hz运行的控制器，能够在狭窄空间中快速无碰撞导航，并在仿真中展示了3D碰撞避免应用

Conclusion: 该方法有效解决了半无限规划碰撞避免问题，支持鲁棒控制和实际应用，为复杂环境下的实时碰撞避免提供了可行方案

Abstract: This paper presents a novel approach for collision avoidance in optimal and
model predictive control, in which the environment is represented by a large
number of points and the robot as a union of padded polygons. The conditions
that none of the points shall collide with the robot can be written in terms of
an infinite number of constraints per obstacle point. We show that the
resulting semi-infinite programming (SIP) optimal control problem (OCP) can be
efficiently tackled through a combination of two methods: local reduction and
an external active-set method. Specifically, this involves iteratively
identifying the closest point obstacles, determining the lower-level distance
minimizer among all feasible robot shape parameters, and solving the
upper-level finitely-constrained subproblems.
  In addition, this paper addresses robust collision avoidance in the presence
of ellipsoidal state uncertainties. Enforcing constraint satisfaction over all
possible uncertainty realizations extends the dimension of constraint
infiniteness. The infinitely many constraints arising from translational
uncertainty are handled by local reduction together with the robot shape
parameterization, while rotational uncertainty is addressed via a backoff
reformulation.
  A controller implemented based on the proposed method is demonstrated on a
real-world robot running at 20Hz, enabling fast and collision-free navigation
in tight spaces. An application to 3D collision avoidance is also demonstrated
in simulation.

</details>


### [84] [SIGN: Safety-Aware Image-Goal Navigation for Autonomous Drones via Reinforcement Learning](https://arxiv.org/abs/2508.12394)
*Zichen Yan,Rui Huang,Lei He,Shao Guo,Lin Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种基于视觉强化学习的sim-to-real框架，使无人机能够实现图像目标导航，无需外部定位，通过辅助任务增强视觉表示能力，并集成了深度安全模块进行实时避障。


<details>
  <summary>Details</summary>
Motivation: 现有的图像目标导航研究主要针对地面机器人，而无人机导航面临更高挑战，需要高频反馈控制和全局定位来保持稳定飞行。本文旨在解决无人机在未知环境中自主探索并到达目标图像位置的问题。

Method: 采用视觉强化学习框架，通过图像扰动和未来转换预测等辅助任务训练视觉骨干网络，增强视觉表示能力。实现端到端的图像目标导航，直接进行速度控制，无需外部定位。集成基于深度的安全模块进行实时障碍物避避。

Result: 提出的方法能够支持全面的导航行为，包括自主探索、障碍物避避和图像目标寻找，而不需要显式的全局地图构建。

Conclusion: 该框架为无人机图像目标导航提供了一种有效的sim-to-real解决方案，通过视觉强化学习和安全模块的结合，实现了在杂乱环境中的安全导航，具有实际应用价值。

Abstract: Image-goal navigation (ImageNav) tasks a robot with autonomously exploring an
unknown environment and reaching a location that visually matches a given
target image. While prior works primarily study ImageNav for ground robots,
enabling this capability for autonomous drones is substantially more
challenging due to their need for high-frequency feedback control and global
localization for stable flight. In this paper, we propose a novel sim-to-real
framework that leverages visual reinforcement learning (RL) to achieve ImageNav
for drones. To enhance visual representation ability, our approach trains the
vision backbone with auxiliary tasks, including image perturbations and future
transition prediction, which results in more effective policy training. The
proposed algorithm enables end-to-end ImageNav with direct velocity control,
eliminating the need for external localization. Furthermore, we integrate a
depth-based safety module for real-time obstacle avoidance, allowing the drone
to safely navigate in cluttered environments. Unlike most existing drone
navigation methods that focus solely on reference tracking or obstacle
avoidance, our framework supports comprehensive navigation
behaviors--autonomous exploration, obstacle avoidance, and image-goal
seeking--without requiring explicit global mapping. Code and model checkpoints
will be released upon acceptance.

</details>


### [85] [PUB: A Plasma-Propelled Ultra-Quiet Blimp with Two-DOF Vector Thrusting](https://arxiv.org/abs/2508.12395)
*Zihan Wang*

Main category: cs.RO

TL;DR: 等离子推进超静音飞艇(PUB)采用等离子矢量推进技术，无需机械螺旋桨实现超静音飞行，具有模块化推进单元和双自由度矢量控制，验证了全包线飞行能力


<details>
  <summary>Details</summary>
Motivation: 开发一种超静音、无机械螺旋桨的空中机器人，适用于噪声敏感、封闭和近空间应用场景

Method: 采用氦气升力平台和四层环状不对称电容器产生离子风推力，模块化推进单元设计，双自由度头部实现推力矢量控制，闭环滑移控制方案保证稳定机动

Result: 飞行实验展示了完整的飞行包线能力，包括起飞、爬升、悬停、下降和平稳着陆，验证了等离子矢量推进的可行性、矢量控制的有效性和控制系统的稳定性

Conclusion: PUB凭借低声学特征、结构简单性和高机动性，非常适合噪声敏感、封闭和近空间应用

Abstract: This study presents the design and control of a Plasma-propelled
Ultra-silence Blimp (PUB), a novel aerial robot employing plasma vector
propulsion for ultra-quiet flight without mechanical propellers. The system
utilizes a helium-lift platform for extended endurance and a four-layer ring
asymmetric capacitor to generate ionic wind thrust. The modular propulsion
units allow flexible configuration to meet mission-specific requirements, while
a two-degree-of-freedom (DOF) head enables thrust vector control. A closed-loop
slip control scheme is implemented for stable maneuvering. Flight experiments
demonstrate full-envelope capability, including take-off, climb, hover,
descent, and smooth landing, confirming the feasibility of plasma vector
propulsion, the effectiveness of DOF vector control, and the stability of the
control system. Owing to its low acoustic signature, structural simplicity, and
high maneuverability, PUB is well suited for noise-sensitive, enclosed, and
near-space applications.

</details>


### [86] [Tactile Gesture Recognition with Built-in Joint Sensors for Industrial Robots](https://arxiv.org/abs/2508.12435)
*Deqing Song,Weimin Yang,Maryam Rezayati,Hans Wernher van de Venn*

Main category: cs.RO

TL;DR: 本文探索仅使用机器人内置关节传感器的深度学习手势识别方法，无需外部传感器，通过CNN架构和两种数据集评估数据表示和模型架构对识别精度的影响。


<details>
  <summary>Details</summary>
Motivation: 在HRC领域，虽然基于视觉或机器人皮肤的手势识别研究活跃，但本文旨在探索仅依赖机器人内置关节传感器的深度学习方法，消除对外部传感器的需求，以降低成本和提高可扩展性。

Method: 评估了多种卷积神经网络（CNN）架构，收集了两个数据集来研究数据表示和模型架构对识别精度的影响，特别关注基于频谱图的表示方法。

Result: 频谱图表示显著提高了识别精度，而模型架构的影响较小。在Franka Emika Research机器人上实现的STFT2DCNN和STT3DCNN方法在接触检测和手势分类方面达到超过95%的准确率。

Conclusion: 研究证明了无需外部传感器的触觉识别的可行性，促进了HRC领域成本效益高、可扩展解决方案的进一步研究。

Abstract: While gesture recognition using vision or robot skins is an active research
area in Human-Robot Collaboration (HRC), this paper explores deep learning
methods relying solely on a robot's built-in joint sensors, eliminating the
need for external sensors. We evaluated various convolutional neural network
(CNN) architectures and collected two datasets to study the impact of data
representation and model architecture on the recognition accuracy. Our results
show that spectrogram-based representations significantly improve accuracy,
while model architecture plays a smaller role. We also tested generalization to
new robot poses, where spectrogram-based models performed better. Implemented
on a Franka Emika Research robot, two of our methods, STFT2DCNN and STT3DCNN,
achieved over 95% accuracy in contact detection and gesture classification.
These findings demonstrate the feasibility of external-sensor-free tactile
recognition and promote further research toward cost-effective, scalable
solutions for HRC.

</details>


### [87] [Geodesic Tracing-Based Kinematic Integration of Rolling and Sliding Contact on Manifold Meshes for Dexterous In-Hand Manipulation](https://arxiv.org/abs/2508.12439)
*Sunyu Wang,Arjun S. Lakshmipathy,Jean Oh,Nancy S. Pollard*

Main category: cs.RO

TL;DR: 本文扩展了滚滑接触建模到流形网格，提出基于测地线追踪的积分方案，在网格上直接进行一阶时间积分，实现了对物体真实几何的高保真离散表示进行灵巧操作规划。


<details>
  <summary>Details</summary>
Motivation: 现有滚滑接触研究主要关注具有可微分参数化的连续形状，而真实物体通常用网格表示，需要将滚滑接触建模扩展到流形网格以支持更精确的灵巧操作。

Method: 提出基于测地线追踪的积分方案，在网格上进行一阶时间积分滚滑接触；使用最小二乘优化器规划多指机器人手的灵巧运动，通过最小化接触滑动和旋转来维持最稳定的瞬时抓取。

Result: 在模拟中对五个物体进行灵巧操作规划，与基于碰撞检测和基于原始形状的基线方法相比，本方法在准确性和精度方面表现最佳，即使对于粗糙网格也是如此。

Conclusion: 该方法为基于网格的表面接触建模提供了准确和精确的解决方案，未来工作需要整合多接触和接触力以实现更准确和鲁棒的建模。

Abstract: Reasoning about rolling and sliding contact, or roll-slide contact for short,
is critical for dexterous manipulation tasks that involve intricate geometries.
But existing works on roll-slide contact mostly focus on continuous shapes with
differentiable parametrizations. This work extends roll-slide contact modeling
to manifold meshes. Specifically, we present an integration scheme based on
geodesic tracing to first-order time-integrate roll-slide contact directly on
meshes, enabling dexterous manipulation to reason over high-fidelity discrete
representations of an object's true geometry. Using our method, we planned
dexterous motions of a multi-finger robotic hand manipulating five objects
in-hand in simulation. The planning was achieved with a least-squares optimizer
that strives to maintain the most stable instantaneous grasp by minimizing
contact sliding and spinning. Then, we evaluated our method against a baseline
using collision detection and a baseline using primitive shapes. The results
show that our method performed the best in accuracy and precision, even for
coarse meshes. We conclude with a future work discussion on incorporating
multiple contacts and contact forces to achieve accurate and robust mesh-based
surface contact modeling.

</details>


### [88] [Autonomous Oil Spill Response Through Liquid Neural Trajectory Modeling and Coordinated Marine Robotics](https://arxiv.org/abs/2508.12456)
*Hadas C. Kuzmenko,David Ehevich,Oren Gal*

Main category: cs.RO

TL;DR: 本研究提出了一种结合多智能体群机器人系统和液体时间常数神经网络(LTCNs)的集成框架，用于实时预测、动态跟踪和快速响应海洋溢油事件，在Deepwater Horizon溢油数据上取得了96%的空间精度。


<details>
  <summary>Details</summary>
Motivation: 海洋溢油事件对环境和经济造成严重威胁，但由于物理、化学和环境因素（如风、海流、温度）的复杂相互作用，预测和管理溢油轨迹非常困难，需要实时准确的轨迹预测和协调的缓解措施来最小化灾害影响。

Method: 采用基于MOOS-IvP平台的多智能体群机器人系统与液体时间常数神经网络(LTCNs)相结合的集成框架，利用LTCNs建模复杂的时间相关过程，通过群体智能实现去中心化、可扩展和弹性的机器人代理决策。

Result: 在Deepwater Horizon溢油数据验证中，LTC-RK4模型实现了96%的空间精度，比LSTM方法提高了23%。先进神经建模与自主协调机器人技术的集成显著提高了预测精度、灵活性和操作可扩展性。

Conclusion: 这项研究通过增强轨迹预测和响应协调，推进了可持续、自主溢油管理和环境保护的最新技术水平，为海洋溢油应急响应提供了有效的解决方案。

Abstract: Marine oil spills pose grave environmental and economic risks, threatening
marine ecosystems, coastlines, and dependent industries. Predicting and
managing oil spill trajectories is highly complex, due to the interplay of
physical, chemical, and environmental factors such as wind, currents, and
temperature, which makes timely and effective response challenging. Accurate
real-time trajectory forecasting and coordinated mitigation are vital for
minimizing the impact of these disasters. This study introduces an integrated
framework combining a multi-agent swarm robotics system built on the MOOS-IvP
platform with Liquid Time-Constant Neural Networks (LTCNs). The proposed system
fuses adaptive machine learning with autonomous marine robotics, enabling
real-time prediction, dynamic tracking, and rapid response to evolving oil
spills. By leveraging LTCNs--well-suited for modeling complex, time-dependent
processes--the framework achieves real-time, high-accuracy forecasts of spill
movement. Swarm intelligence enables decentralized, scalable, and resilient
decision-making among robot agents, enhancing collective monitoring and
containment efforts. Our approach was validated using data from the Deepwater
Horizon spill, where the LTC-RK4 model achieved 0.96 spatial accuracy,
surpassing LSTM approaches by 23%. The integration of advanced neural modeling
with autonomous, coordinated robotics demonstrates substantial improvements in
prediction precision, flexibility, and operational scalability. Ultimately,
this research advances the state-of-the-art for sustainable, autonomous oil
spill management and environmental protection by enhancing both trajectory
prediction and response coordination.

</details>


### [89] [Mechanical Automation with Vision: A Design for Rubik's Cube Solver](https://arxiv.org/abs/2508.12469)
*Abhinav Chalise,Nimesh Gopal Pradhan,Nishan Khanal,Prashant Raj Bista,Dinesh Baniya Kshatri*

Main category: cs.RO

TL;DR: 开发了一个基于三台步进电机、微控制器和YOLOv8实时检测的魔方自动求解系统，通过Kociemba算法求解，平均求解时间约2.2分钟


<details>
  <summary>Details</summary>
Motivation: 构建一个完整的魔方自动求解系统，将物理操作、实时状态检测和算法求解集成到一个用户友好的界面中

Method: 使用三台步进电机进行物理操作，微控制器控制硬件，YOLOv8模型实时检测魔方状态，Unity开发GUI界面，Kociemba算法生成求解步骤

Result: YOLOv8检测精度达0.98443，召回率0.98419，平均求解时间约2.2分钟，成功实现了魔方的自动检测和求解

Conclusion: 该系统成功整合了硬件控制、计算机视觉和求解算法，实现了高效的魔方自动求解，为类似的物理操作系统提供了可行的技术方案

Abstract: The core mechanical system is built around three stepper motors for physical
manipulation, a microcontroller for hardware control, a camera and YOLO
detection model for real-time cube state detection. A significant software
component is the development of a user-friendly graphical user interface (GUI)
designed in Unity. The initial state after detection from real-time YOLOv8
model (Precision 0.98443, Recall 0.98419, Box Loss 0.42051, Class Loss 0.2611)
is virtualized on GUI. To get the solution, the system employs the Kociemba's
algorithm while physical manipulation with a single degree of freedom is done
by combination of stepper motors' interaction with the cube achieving the
average solving time of ~2.2 minutes.

</details>


### [90] [PROD: Palpative Reconstruction of Deformable Objects through Elastostatic Signed Distance Functions](https://arxiv.org/abs/2508.12554)
*Hamza El-Kebir*

Main category: cs.RO

TL;DR: PROD是一种通过触觉交互重建可变形物体形状和力学特性的新方法，使用弹性静力学SDF，结合力控表面探测来估计软材料的静态和动态响应。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖纯几何或视觉数据，无法有效估计可变形物体的力学特性。PROD通过整合触觉交互数据，旨在同时恢复物体的形状和材料刚度。

Method: 将物体变形建模为弹性静力学过程，推导控制泊松方程从稀疏位姿和力测量中估计SDF。结合稳态弹性动力学假设，从变形观测中恢复未变形SDF。通过分析位移响应估计材料刚度。

Result: PROD在处理位姿误差、非法向力施加和曲率误差方面表现出鲁棒性，在模拟软体交互中验证了方法的有效性。

Conclusion: PROD为机器人操作、医学成像和触觉反馈系统等应用中的可变形物体重建提供了强大工具，能够同时恢复几何形状和力学特性。

Abstract: We introduce PROD (Palpative Reconstruction of Deformables), a novel method
for reconstructing the shape and mechanical properties of deformable objects
using elastostatic signed distance functions (SDFs). Unlike traditional
approaches that rely on purely geometric or visual data, PROD integrates
palpative interaction -- measured through force-controlled surface probing --
to estimate both the static and dynamic response of soft materials. We model
the deformation of an object as an elastostatic process and derive a governing
Poisson equation for estimating its SDF from a sparse set of pose and force
measurements. By incorporating steady-state elastodynamic assumptions, we show
that the undeformed SDF can be recovered from deformed observations with
provable convergence. Our approach also enables the estimation of material
stiffness by analyzing displacement responses to varying force inputs. We
demonstrate the robustness of PROD in handling pose errors, non-normal force
application, and curvature errors in simulated soft body interactions. These
capabilities make PROD a powerful tool for reconstructing deformable objects in
applications ranging from robotic manipulation to medical imaging and haptic
feedback systems.

</details>


### [91] [Temporal and Rotational Calibration for Event-Centric Multi-Sensor Systems](https://arxiv.org/abs/2508.12564)
*Jiayao Mai,Xiuyuan Lu,Kuan Dai,Shaojie Shen,Yi Zhou*

Main category: cs.RO

TL;DR: 提出了一种基于运动的事件相机多传感器时空标定框架，无需专用标定目标，通过角速度估计和两步优化实现高精度标定


<details>
  <summary>Details</summary>
Motivation: 事件相机作为新型传感器在多传感器系统中具有微秒级延迟优势，但其外参标定研究不足，需要解决无标定目标的标定问题

Method: 使用事件相机和其他传感器的旋转运动估计，通过法向流观测估计角速度，采用CCA初始化时空参数，然后通过SO(3)连续时间参数化进行非线性联合优化

Result: 在公开和自采集数据集上验证，标定精度达到基于目标方法的水平，比纯CCA方法更稳定，表现出高精度、鲁棒性和灵活性

Conclusion: 该方法为事件相机多传感器系统提供了有效的无标定目标标定解决方案，代码将开源以促进未来研究

Abstract: Event cameras generate asynchronous signals in response to pixel-level
brightness changes, offering a sensing paradigm with theoretically
microsecond-scale latency that can significantly enhance the performance of
multi-sensor systems. Extrinsic calibration is a critical prerequisite for
effective sensor fusion; however, the configuration that involves event cameras
remains an understudied topic. In this paper, we propose a motion-based
temporal and rotational calibration framework tailored for event-centric
multi-sensor systems, eliminating the need for dedicated calibration targets.
Our method uses as input the rotational motion estimates obtained from event
cameras and other heterogeneous sensors, respectively. Different from
conventional approaches that rely on event-to-frame conversion, our method
efficiently estimates angular velocity from normal flow observations, which are
derived from the spatio-temporal profile of event data. The overall calibration
pipeline adopts a two-step approach: it first initializes the temporal offset
and rotational extrinsics by exploiting kinematic correlations in the spirit of
Canonical Correlation Analysis (CCA), and then refines both temporal and
rotational parameters through a joint non-linear optimization using a
continuous-time parametrization in SO(3). Extensive evaluations on both
publicly available and self-collected datasets validate that the proposed
method achieves calibration accuracy comparable to target-based methods, while
exhibiting superior stability over purely CCA-based methods, and highlighting
its precision, robustness and flexibility. To facilitate future research, our
implementation will be made open-source. Code:
https://github.com/NAIL-HNU/EvMultiCalib.

</details>


### [92] [Adaptive Model-Predictive Control of a Soft Continuum Robot Using a Physics-Informed Neural Network Based on Cosserat Rod Theory](https://arxiv.org/abs/2508.12681)
*Johann Licher,Max Bartholdt,Henrik Krauss,Tim-Lukas Habich,Thomas Seel,Moritz Schappler*

Main category: cs.RO

TL;DR: 提出基于域解耦物理信息神经网络(DD-PINN)的实时非线性模型预测控制框架，用于软体连续机器人的动态控制，实现高速高精度跟踪


<details>
  <summary>Details</summary>
Motivation: 软体连续机器人动态控制具有重要应用价值，但传统方法计算量大且缺乏适应性，现有数据驱动方法无法捕捉完整机器人形状

Method: 使用域解耦物理信息神经网络(DD-PINN)作为Cosserat杆模型的替代模型，速度提升44000倍，结合无迹卡尔曼滤波进行状态估计，实现70Hz的非线性模型预测控制

Result: 仿真中实现动态轨迹精确跟踪，末端位置误差低于3mm(2.3%执行器长度)；真实实验中达到相似精度，加速度达3.55m/s²

Conclusion: 该方法为软体连续机器人提供了实时高效的动态控制解决方案，显著提升了控制性能和适应性

Abstract: Dynamic control of soft continuum robots (SCRs) holds great potential for
expanding their applications, but remains a challenging problem due to the high
computational demands of accurate dynamic models. While data-driven approaches
like Koopman-operator-based methods have been proposed, they typically lack
adaptability and cannot capture the full robot shape, limiting their
applicability. This work introduces a real-time-capable nonlinear
model-predictive control (MPC) framework for SCRs based on a domain-decoupled
physics-informed neural network (DD-PINN) with adaptable bending stiffness. The
DD-PINN serves as a surrogate for the dynamic Cosserat rod model with a
speed-up factor of 44000. It is also used within an unscented Kalman filter for
estimating the model states and bending compliance from end-effector position
measurements. We implement a nonlinear evolutionary MPC running at 70 Hz on the
GPU. In simulation, it demonstrates accurate tracking of dynamic trajectories
and setpoint control with end-effector position errors below 3 mm (2.3% of the
actuator's length). In real-world experiments, the controller achieves similar
accuracy and accelerations up to 3.55 m/s2.

</details>


### [93] [MCTR: Midpoint Corrected Triangulation for Autonomous Racing via Digital Twin Simulation in CARLA](https://arxiv.org/abs/2508.12729)
*Junhao Ye,Cheng Hu,Yiqin Wang,Weizhan Huang,Nicolas Baumann,Jie He,Meixun Qu,Lei Xie,Hongye Su*

Main category: cs.RO

TL;DR: 提出MCTR算法，通过曲率校正移动平均提高轨迹平滑度，并在CARLA模拟器中实现数字孪生系统验证3D LiDAR感知下的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有DTR算法使用外接圆生成轨迹导致路径不够平滑，性能下降；F1TENTH模拟器缺乏3D LiDAR感知支持，限制真实测试效果

Method: 基于Curvature Corrected Moving Average改进轨迹平滑度，在CARLA模拟器中构建数字孪生系统进行3D LiDAR感知验证

Result: 通过仿真和真实车辆实验全面验证了算法的有效性

Conclusion: MCTR算法成功解决了轨迹平滑度和3D感知验证问题，提升了自动驾驶赛车性能

Abstract: In autonomous racing, reactive controllers eliminate the computational burden
of the full See-Think-Act autonomy stack by directly mapping sensor inputs to
control actions. This bypasses the need for explicit localization and
trajectory planning. A widely adopted baseline in this category is the
Follow-The-Gap method, which performs trajectory planning using LiDAR data.
Building on FTG, the Delaunay Triangulation-based Racing algorithm introduces
further enhancements. However, DTR's use of circumcircles for trajectory
generation often results in insufficiently smooth paths, ultimately degrading
performance. Additionally, the commonly used F1TENTH-simulator for autonomous
racing competitions lacks support for 3D LiDAR perception, limiting its
effectiveness in realistic testing. To address these challenges, this work
proposes the MCTR algorithm. MCTR improves trajectory smoothness through the
use of Curvature Corrected Moving Average and implements a digital twin system
within the CARLA simulator to validate the algorithm's robustness under 3D
LiDAR perception. The proposed algorithm has been thoroughly validated through
both simulation and real-world vehicle experiments.

</details>


### [94] [RoboRetriever: Single-Camera Robot Object Retrieval via Active and Interactive Perception with Dynamic Scene Graph](https://arxiv.org/abs/2508.12916)
*Hecheng Wang,Jiankun Ren,Jia Yu,Lizhe Qi,Yunquan Sun*

Main category: cs.RO

TL;DR: RoboRetriever是一个仅使用单个腕戴RGB-D相机和自然语言指令的机器人对象检索框架，通过动态层次场景图和主动感知实现真实世界中的物体检索


<details>
  <summary>Details</summary>
Motivation: 人类能够轻松在杂乱环境中检索物体，而现有机器人系统依赖多摄像头设置，成本高且适应性差，需要开发更灵活的单摄像头解决方案

Method: 构建动态层次场景图编码对象语义和几何关系，使用视觉提示方案结合大型视觉语言模型确定6自由度相机位姿，集成主动感知、交互感知和操作

Result: 在多样化真实世界对象检索任务中表现出强大的适应性和鲁棒性，包括有人干预的场景

Conclusion: 该框架证明了仅使用单个RGB-D相机就能在杂乱环境中有效检索物体的可行性，为机器人感知和操作提供了新的解决方案

Abstract: Humans effortlessly retrieve objects in cluttered, partially observable
environments by combining visual reasoning, active viewpoint adjustment, and
physical interaction-with only a single pair of eyes. In contrast, most
existing robotic systems rely on carefully positioned fixed or multi-camera
setups with complete scene visibility, which limits adaptability and incurs
high hardware costs. We present \textbf{RoboRetriever}, a novel framework for
real-world object retrieval that operates using only a \textbf{single}
wrist-mounted RGB-D camera and free-form natural language instructions.
RoboRetriever grounds visual observations to build and update a \textbf{dynamic
hierarchical scene graph} that encodes object semantics, geometry, and
inter-object relations over time. The supervisor module reasons over this
memory and task instruction to infer the target object and coordinate an
integrated action module combining \textbf{active perception},
\textbf{interactive perception}, and \textbf{manipulation}. To enable
task-aware scene-grounded active perception, we introduce a novel visual
prompting scheme that leverages large reasoning vision-language models to
determine 6-DoF camera poses aligned with the semantic task goal and geometry
scene context. We evaluate RoboRetriever on diverse real-world object retrieval
tasks, including scenarios with human intervention, demonstrating strong
adaptability and robustness in cluttered scenes with only one RGB-D camera.

</details>


### [95] [Deformation of the panoramic sphere into an ellipsoid to induce self-motion in telepresence users](https://arxiv.org/abs/2508.12925)
*Eetu Laukka,Evan G. Center,Timo Ojala,Steven M. LaValle,Matti Pouke*

Main category: cs.RO

TL;DR: 通过光流技术在高延迟环境中为移动隐形机器人创造自我运动幻觉，但在500ms延迟下未显著提升控制性能，反而可能增加VR舔晕感


<details>
  <summary>Details</summary>
Motivation: 解决使用360度摄像头的移动隐形机器人系统在网络延迟下实时控制困难的问题，需要某种形式的用户协助技术

Method: 利用光流技术在用户发送运动命令到真实看到运动视频之间的延迟期间，为用户创造自我运动的幻觉效果

Result: 在500ms延迟条件下，该方法对任务完成时间和碰撞物体的控制准确性没有显著改善，反而可能会增加虚拟现实舔晕感

Conclusion: 该光流幻觉技术需要进一步调整和优化才能成为可行的解决方案

Abstract: Mobile telepresence robots allow users to feel present and explore remote
environments using technology. Traditionally, these systems are implemented
using a camera onboard a mobile robot that can be controlled. Although
high-immersion technologies, such as 360-degree cameras, can increase
situational awareness and presence, they also introduce significant challenges.
Additional processing and bandwidth requirements often result in latencies of
up to seconds. The current delay with a 360-degree camera streaming over the
internet makes real-time control of these systems difficult. Working with
high-latency systems requires some form of assistance to the users.
  This study presents a novel way to utilize optical flow to create an illusion
of self-motion to the user during the latency period between user sending
motion commands to the robot and seeing the actual motion through the
360-camera stream. We find no significant benefit of using the self-motion
illusion to performance or accuracy of controlling a telepresence robot with a
latency of 500 ms, as measured by the task completion time and collisions into
objects. Some evidence is shown that the method might increase virtual reality
(VR) sickness, as measured by the simulator sickness questionnaire (SSQ). We
conclude that further adjustments are necessary in order to render the method
viable.

</details>


### [96] [Simultaneous Contact Sequence and Patch Planning for Dynamic Locomotion](https://arxiv.org/abs/2508.12928)
*Victor Dhédin,Haizhou Zhao,Majid Khadiv*

Main category: cs.RO

TL;DR: 基于MCTS和全身轨迹优化的四足机器人多接触运动规划框架，能够同时优化接触序列和接触面选择，成功在仿真和真实机器人上实现复杂无环运动


<details>
  <summary>Details</summary>
Motivation: 腿式机器人需要在高度受限环境中进行敏捷运动，但规划这类运动需要解决包含连续和离散决策变量的复杂优化问题

Method: 采用蒙特卡洛树搜索(MCTS)和全身轨迹优化(TO)的完整流水线，实现接触序列和接触面选择的同步优化

Result: 仿真实验显示框架能快速找到多种动态一致的运动计划，这些计划可成功迁移到真实四足机器人，并能实现复杂的人形机器人无环动作

Conclusion: 这是首次展示基于全身动力学的四足机器人无环多接触运动的同时接触序列和接触面选择方法

Abstract: Legged robots have the potential to traverse highly constrained environments
with agile maneuvers. However, planning such motions requires solving a highly
challenging optimization problem with a mixture of continuous and discrete
decision variables. In this paper, we present a full pipeline based on
Monte-Carlo tree search (MCTS) and whole-body trajectory optimization (TO) to
perform simultaneous contact sequence and patch selection on highly challenging
environments. Through extensive simulation experiments, we show that our
framework can quickly find a diverse set of dynamically consistent plans. We
experimentally show that these plans are transferable to a real quadruped
robot. We further show that the same framework can find highly complex acyclic
humanoid maneuvers. To the best of our knowledge, this is the first
demonstration of simultaneous contact sequence and patch selection for acyclic
multi-contact locomotion using the whole-body dynamics of a quadruped.

</details>


### [97] [Insights from Interviews with Teachers and Students on the Use of a Social Robot in Computer Science Class in Sixth Grade](https://arxiv.org/abs/2508.12946)
*Ann-Sophie Schenk,Stefan Schiffer,Heqiu Song*

Main category: cs.RO

TL;DR: 研究通过访谈探讨六年级计算机科学课堂中使用社交机器人的需求和潜在应用，发现师生对机器人持开放态度但需求存在差异


<details>
  <summary>Details</summary>
Motivation: 了解教师和学生对在计算机科学课堂中使用社交机器人的看法、需求以及潜在应用场景，获取双方视角

Method: 对教师和学生进行访谈，收集他们对课堂社交机器人的需求和功能期望

Result: 教师和学生都对课堂机器人持开放态度，但两组人群的需求存在显著差异

Conclusion: 师生需求差异带来了复杂的设计挑战，需要在机器人设计中平衡不同群体的期望

Abstract: In this paper we report on first insights from interviews with teachers and
students on using social robots in computer science class in sixth grade. Our
focus is on learning about requirements and potential applications. We are
particularly interested in getting both perspectives, the teachers' and the
learners' view on how robots could be used and what features they should or
should not have. Results show that teachers as well as students are very open
to robots in the classroom. However, requirements are partially quite
heterogeneous among the groups. This leads to complex design challenges which
we discuss at the end of this paper.

</details>


### [98] [Scaling Whole-body Multi-contact Manipulation with Contact Optimization](https://arxiv.org/abs/2508.12980)
*Victor Levé,João Moura,Sachiya Fujita,Tamon Miyake,Steve Tonneau,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 提出了一种用于人形机器人全身操纵的连续接触表面表示方法，通过封闭式计算邻近点和有效的成本设计，相比现有方法规划时间提升77%，并在真实硬件上验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 日常任务需要全身操纵物体，但现有规划方法主要依赖离散采样，难以扩展到复杂的接触场景。连续接触表面的无限可能性阻碍了现有方法的可扩展性，而基于梯度优化的方法缺乏高效的机器人表面表示。

Method: 提出(i)机器人及物体表面的表示方法，支持邻近点的封闭式计算；(ii)有效的成本设计来指导全身操纵规划。

Result: 实验证明该框架能解决现有方法无法处理的问题，规划时间相比最先进方法提升77%，并在人形机器人操纵盒子的真实硬件实验中验证了适用性。

Conclusion: 该工作提供了一种高效的连续接触表面表示和规划框架，显著提升了人形机器人全身操纵任务的规划效率和可行性。

Abstract: Daily tasks require us to use our whole body to manipulate objects, for
instance when our hands are unavailable. We consider the issue of providing
humanoid robots with the ability to autonomously perform similar whole-body
manipulation tasks. In this context, the infinite possibilities for where and
how contact can occur on the robot and object surfaces hinder the scalability
of existing planning methods, which predominantly rely on discrete sampling.
Given the continuous nature of contact surfaces, gradient-based optimization
offers a more suitable approach for finding solutions. However, a key remaining
challenge is the lack of an efficient representation of robot surfaces. In this
work, we propose (i) a representation of robot and object surfaces that enables
closed-form computation of proximity points, and (ii) a cost design that
effectively guides whole-body manipulation planning. Our experiments
demonstrate that the proposed framework can solve problems unaddressed by
existing methods, and achieves a 77% improvement in planning time over the
state of the art. We also validate the suitability of our approach on real
hardware through the whole-body manipulation of boxes by a humanoid robot.

</details>


### [99] [BOW: Bayesian Optimization over Windows for Motion Planning in Complex Environments](https://arxiv.org/abs/2508.13052)
*Sourav Raxit,Abdullah Al Redwan Newaz,Paulo Padrao,Jose Fuentes,Leonardo Bobadilla*

Main category: cs.RO

TL;DR: BOW Planner是一个基于约束贝叶斯优化的运动规划算法，通过集中处理可达速度窗口和高效采样控制输入，有效解决传统方法难以处理的运动学约束问题，在复杂环境中实现快速安全的轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法在处理速度、加速度等运动学约束时表现不佳，特别是在复杂环境中难以同时满足高维目标函数和严格安全约束的需求。

Method: 采用约束贝叶斯优化(CBO)方法，专注于可达速度规划窗口，通过高效采样控制输入来管理高维目标函数和安全约束，实现最小化采样的快速轨迹生成。

Result: 理论分析证明算法具有渐近收敛到近似最优解的特性。在杂乱和受限环境中的广泛评估显示，相比现有技术，在计算时间、轨迹长度和解算时间方面都有显著改进。

Conclusion: BOW Planner在实际机器人系统中成功部署，展现出卓越的采样效率、安全感知优化和快速规划能力，已成为推进机器人应用的有价值工具，并以开源形式发布。

Abstract: This paper introduces the BOW Planner, a scalable motion planning algorithm
designed to navigate robots through complex environments using constrained
Bayesian optimization (CBO). Unlike traditional methods, which often struggle
with kinodynamic constraints such as velocity and acceleration limits, the BOW
Planner excels by concentrating on a planning window of reachable velocities
and employing CBO to sample control inputs efficiently. This approach enables
the planner to manage high-dimensional objective functions and stringent safety
constraints with minimal sampling, ensuring rapid and secure trajectory
generation. Theoretical analysis confirms the algorithm's asymptotic
convergence to near-optimal solutions, while extensive evaluations in cluttered
and constrained settings reveal substantial improvements in computation times,
trajectory lengths, and solution times compared to existing techniques.
Successfully deployed across various real-world robotic systems, the BOW
Planner demonstrates its practical significance through exceptional sample
efficiency, safety-aware optimization, and rapid planning capabilities, making
it a valuable tool for advancing robotic applications. The BOW Planner is
released as an open-source package and videos of real-world and simulated
experiments are available at https://bow-web.github.io.

</details>


### [100] [Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey](https://arxiv.org/abs/2508.13073)
*Rui Shao,Wei Li,Lingsen Zhang,Renshan Zhang,Zhiyang Liu,Ran Chen,Liqiang Nie*

Main category: cs.RO

TL;DR: 这篇论文是关于基于大型视觉语言模型(VLM)的视觉-语言-动作(VLA)模型在机器人操作领域的系统性综述，提出了分类框架并分析了两种主要架构范式：单体模型和分层模型。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的方法在非结构化、新颖环境中无法扩展和泛化，而基于大型VLM的VLA模型为机器人操作提供了变革性范式，需要系统性的综述来整合现有研究、解决分类不一致问题并填补研究空白。

Method: 采用系统性综述方法，首先明确定义大型VLM-based VLA模型，划分两种主要架构范式（单体模型和分层模型），然后深入分析模型与先进领域的集成、特征综合以及未来发展方向。

Result: 建立了清晰的分类体系，整合了架构特征、操作优势以及支持开发的数据集和基准测试，识别了包括记忆机制、4D感知、高效适应等有前景的研究方向。

Conclusion: 该综述通过系统整合大型VLM与机器人操作交叉领域的研究，解决了现有分类不一致问题，减轻了研究碎片化，并为该领域提供了持续更新的项目页面以记录进展。

Abstract: Robotic manipulation, a key frontier in robotics and embodied AI, requires
precise motor control and multimodal understanding, yet traditional rule-based
methods fail to scale or generalize in unstructured, novel environments. In
recent years, Vision-Language-Action (VLA) models, built upon Large
Vision-Language Models (VLMs) pretrained on vast image-text datasets, have
emerged as a transformative paradigm. This survey provides the first
systematic, taxonomy-oriented review of large VLM-based VLA models for robotic
manipulation. We begin by clearly defining large VLM-based VLA models and
delineating two principal architectural paradigms: (1) monolithic models,
encompassing single-system and dual-system designs with differing levels of
integration; and (2) hierarchical models, which explicitly decouple planning
from execution via interpretable intermediate representations. Building on this
foundation, we present an in-depth examination of large VLM-based VLA models:
(1) integration with advanced domains, including reinforcement learning,
training-free optimization, learning from human videos, and world model
integration; (2) synthesis of distinctive characteristics, consolidating
architectural traits, operational strengths, and the datasets and benchmarks
that support their development; (3) identification of promising directions,
including memory mechanisms, 4D perception, efficient adaptation, multi-agent
cooperation, and other emerging capabilities. This survey consolidates recent
advances to resolve inconsistencies in existing taxonomies, mitigate research
fragmentation, and fill a critical gap through the systematic integration of
studies at the intersection of large VLMs and robotic manipulation. We provide
a regularly updated project page to document ongoing progress:
https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation.

</details>


### [101] [Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy](https://arxiv.org/abs/2508.13103)
*Tianyi Zhang,Haonan Duan,Haoran Hao,Yu Qiao,Jifeng Dai,Zhi Hou*

Main category: cs.RO

TL;DR: OC-VLA框架通过将动作预测直接建立在相机观测空间中，解决了VLA模型在不同相机视角下的空间不一致性问题，显著提升了跨视角泛化能力和任务成功率。


<details>
  <summary>Details</summary>
Motivation: VLA模型在真实环境中泛化能力不足，主要原因是观测空间和动作空间之间的不一致性。虽然训练数据来自不同相机视角，但模型通常在机器人基坐标系中预测末端执行器位姿，导致空间不一致。

Method: 提出OC-VLA框架，利用相机外参标定矩阵，将末端执行器位姿从机器人基坐标系转换到相机坐标系，统一了异质视角下的预测目标。这是一种轻量级、即插即用的策略。

Result: 在仿真和真实机器人操作任务上的综合评估表明，OC-VLA加速了收敛速度，提高了任务成功率，并显著改善了跨视角泛化能力。

Conclusion: OC-VLA框架通过统一观测和动作空间，有效解决了VLA模型的视角变化鲁棒性问题，且与现有VLA架构兼容，无需重大修改。

Abstract: Vision-Language-Action (VLA) models frequently encounter challenges in
generalizing to real-world environments due to inherent discrepancies between
observation and action spaces. Although training data are collected from
diverse camera perspectives, the models typically predict end-effector poses
within the robot base coordinate frame, resulting in spatial inconsistencies.
To mitigate this limitation, we introduce the Observation-Centric VLA (OC-VLA)
framework, which grounds action predictions directly in the camera observation
space. Leveraging the camera's extrinsic calibration matrix, OC-VLA transforms
end-effector poses from the robot base coordinate system into the camera
coordinate system, thereby unifying prediction targets across heterogeneous
viewpoints. This lightweight, plug-and-play strategy ensures robust alignment
between perception and action, substantially improving model resilience to
camera viewpoint variations. The proposed approach is readily compatible with
existing VLA architectures, requiring no substantial modifications.
Comprehensive evaluations on both simulated and real-world robotic manipulation
tasks demonstrate that OC-VLA accelerates convergence, enhances task success
rates, and improves cross-view generalization. The code will be publicly
available.

</details>


### [102] [Manipulate-to-Navigate: Reinforcement Learning with Visual Affordances and Manipulability Priors](https://arxiv.org/abs/2508.13151)
*Yuying Zhang,Joni Pajarinen*

Main category: cs.RO

TL;DR: 提出基于强化学习的方法解决移动机器人在动态环境中的'操纵导航'问题，通过结合可操纵性先验和功能映射来选择高质量操纵动作，减少不必要探索


<details>
  <summary>Details</summary>
Motivation: 传统方法将导航和操纵作为独立任务处理，在需要先清除障碍物才能导航的动态环境中经常失败，需要主动与环境交互来清理障碍物

Method: 强化学习方法结合可操纵性先验（关注高可操纵性身体位置）和功能映射（选择高质量操纵动作），在两个新的模拟任务（Reach和Door）中测试

Result: 方法使机器人能有效与动态环境交互和穿越，学习到的策略成功迁移到真实Boston Dynamics Spot机器人上执行Reach任务

Conclusion: 该方法能有效解决操纵导航问题，通过聚焦可行且有意义的动作减少探索需求，提高学习效率

Abstract: Mobile manipulation in dynamic environments is challenging due to movable
obstacles blocking the robot's path. Traditional methods, which treat
navigation and manipulation as separate tasks, often fail in such
'manipulate-to-navigate' scenarios, as obstacles must be removed before
navigation. In these cases, active interaction with the environment is required
to clear obstacles while ensuring sufficient space for movement. To address the
manipulate-to-navigate problem, we propose a reinforcement learning-based
approach for learning manipulation actions that facilitate subsequent
navigation. Our method combines manipulability priors to focus the robot on
high manipulability body positions with affordance maps for selecting
high-quality manipulation actions. By focusing on feasible and meaningful
actions, our approach reduces unnecessary exploration and allows the robot to
learn manipulation strategies more effectively. We present two new
manipulate-to-navigate simulation tasks called Reach and Door with the Boston
Dynamics Spot robot. The first task tests whether the robot can select a good
hand position in the target area such that the robot base can move effectively
forward while keeping the end effector position fixed. The second task requires
the robot to move a door aside in order to clear the navigation path. Both of
these tasks need first manipulation and then navigating the base forward.
Results show that our method allows a robot to effectively interact with and
traverse dynamic environments. Finally, we transfer the learned policy to a
real Boston Dynamics Spot robot, which successfully performs the Reach task.

</details>
