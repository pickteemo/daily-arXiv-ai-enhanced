<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 45]
- [cs.AI](#cs.AI) [Total: 44]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [OTAS: Open-vocabulary Token Alignment for Outdoor Segmentation](https://arxiv.org/abs/2507.08851)
*Simon Schwaiger,Stefan Thalhammer,Wilfried Wöber,Gerald Steinbauer-Wagner*

Main category: cs.RO

TL;DR: OTAS是一种开放词汇标记对齐方法，用于户外分割，通过直接从预训练视觉模型的输出标记中提取语义结构，克服了开放词汇分割模型的限制。


<details>
  <summary>Details</summary>
Motivation: 在非结构化户外环境中，理解开放世界语义对机器人规划和控制至关重要，但现有方法依赖对象中心分割先验，常因语义模糊和边界不清而失败。

Method: OTAS通过聚类单视图和多视图中的语义相似结构，并将其与语言关联，重建几何一致的特征场，支持开放词汇分割查询。

Result: OTAS在零样本条件下运行，无需场景特定微调，速度达17 fps，在多个数据集上表现优于现有方法，3D分割提升151%。

Conclusion: OTAS适用于机器人应用，代码和ROS节点将公开。

Abstract: Understanding open-world semantics is critical for robotic planning and
control, particularly in unstructured outdoor environments. Current
vision-language mapping approaches rely on object-centric segmentation priors,
which often fail outdoors due to semantic ambiguities and indistinct semantic
class boundaries. We propose OTAS - an Open-vocabulary Token Alignment method
for Outdoor Segmentation. OTAS overcomes the limitations of open-vocabulary
segmentation models by extracting semantic structure directly from the output
tokens of pretrained vision models. By clustering semantically similar
structures across single and multiple views and grounding them in language,
OTAS reconstructs a geometrically consistent feature field that supports
open-vocabulary segmentation queries. Our method operates zero-shot, without
scene-specific fine-tuning, and runs at up to ~17 fps. OTAS provides a minor
IoU improvement over fine-tuned and open-vocabulary 2D segmentation methods on
the Off-Road Freespace Detection dataset. Our model achieves up to a 151% IoU
improvement over open-vocabulary mapping methods in 3D segmentation on
TartanAir. Real-world reconstructions demonstrate OTAS' applicability to
robotic applications. The code and ROS node will be made publicly available
upon paper acceptance.

</details>


### [2] [AirScape: An Aerial Generative World Model with Motion Controllability](https://arxiv.org/abs/2507.08885)
*Baining Zhao,Rongze Tang,Mingyuan Jia,Ziyou Wang,Fanghang Man,Xin Zhang,Yu Shang,Weichen Zhang,Chen Gao,Wei Wu,Xin Wang,Xinlei Chen,Yong Li*

Main category: cs.RO

TL;DR: AirScape是首个为六自由度空中智能体设计的世界模型，通过视觉输入和运动意图预测未来观察序列。


<details>
  <summary>Details</summary>
Motivation: 探索更通用的空间想象能力，解决机器人预测自身运动意图在三维空间中结果的基本问题。

Method: 构建包含11k视频-意图对的数据集，开发两阶段训练计划，将基础模型训练为可控的世界模型。

Result: 成功训练出可控制的世界模型，遵循物理时空约束。

Conclusion: AirScape为空中智能体的空间想象能力提供了有效解决方案。

Abstract: How to enable robots to predict the outcomes of their own motion intentions
in three-dimensional space has been a fundamental problem in embodied
intelligence. To explore more general spatial imagination capabilities, here we
present AirScape, the first world model designed for six-degree-of-freedom
aerial agents. AirScape predicts future observation sequences based on current
visual inputs and motion intentions. Specifically, we construct an dataset for
aerial world model training and testing, which consists of 11k video-intention
pairs. This dataset includes first-person-view videos capturing diverse drone
actions across a wide range of scenarios, with over 1,000 hours spent
annotating the corresponding motion intentions. Then we develop a two-phase
training schedule to train a foundation model -- initially devoid of embodied
spatial knowledge -- into a world model that is controllable by motion
intentions and adheres to physical spatio-temporal constraints.

</details>


### [3] [End-to-End Generation of City-Scale Vectorized Maps by Crowdsourced Vehicles](https://arxiv.org/abs/2507.08901)
*Zebang Feng,Miao Fan,Bao Liu,Shengtong Xu,Haoyi Xiong*

Main category: cs.RO

TL;DR: EGC-VMAP是一种端到端框架，通过众包车辆数据生成高精度城市级矢量化地图，显著降低成本并提升准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统LiDAR制图成本高且速度慢，单车感知方法在恶劣条件下缺乏准确性和鲁棒性，需要一种更高效、经济的解决方案。

Method: 采用Trip-Aware Transformer架构，直接融合多车、多时段地图数据，结合分层匹配和多目标损失函数进行训练。

Result: 在大规模多城市真实数据集上验证，性能优于单车基线，手动标注成本降低90%。

Conclusion: EGC-VMAP为城市级地图提供了一种可扩展、经济高效的解决方案。

Abstract: High-precision vectorized maps are indispensable for autonomous driving, yet
traditional LiDAR-based creation is costly and slow, while single-vehicle
perception methods lack accuracy and robustness, particularly in adverse
conditions. This paper introduces EGC-VMAP, an end-to-end framework that
overcomes these limitations by generating accurate, city-scale vectorized maps
through the aggregation of data from crowdsourced vehicles. Unlike prior
approaches, EGC-VMAP directly fuses multi-vehicle, multi-temporal map elements
perceived onboard vehicles using a novel Trip-Aware Transformer architecture
within a unified learning process. Combined with hierarchical matching for
efficient training and a multi-objective loss, our method significantly
enhances map accuracy and structural robustness compared to single-vehicle
baselines. Validated on a large-scale, multi-city real-world dataset, EGC-VMAP
demonstrates superior performance, enabling a scalable, cost-effective solution
for city-wide mapping with a reported 90\% reduction in manual annotation
costs.

</details>


### [4] [Multimodal HD Mapping for Intersections by Intelligent Roadside Units](https://arxiv.org/abs/2507.08903)
*Zhongzhang Chen,Miao Fan,Shengtong Xu,Mengmeng Yang,Kun Jiang,Xiangzeng Liu,Haoyi Xiong*

Main category: cs.RO

TL;DR: 提出了一种基于摄像头-LiDAR融合的高清语义地图生成框架，并发布了RS-seq数据集，用于研究路边智能单元（IRU）数据的跨模态互补性。


<details>
  <summary>Details</summary>
Motivation: 传统车辆方法在复杂交叉路口的高清语义地图生成中因遮挡和视角限制面临挑战，需利用路边智能单元（IRU）的多模态数据提升性能。

Method: 采用两阶段融合框架，结合摄像头的高分辨率纹理和LiDAR的精确几何数据，通过模态特定特征提取和跨模态语义整合实现。

Result: 多模态方法在RS-seq数据集上表现优于单模态方法，语义分割的mIoU分别比图像和点云方法提高4%和18%。

Conclusion: 本研究为基于IRU的高清语义地图生成提供了基准方法和数据集，支持未来基础设施辅助自动驾驶系统的研究。

Abstract: High-definition (HD) semantic mapping of complex intersections poses
significant challenges for traditional vehicle-based approaches due to
occlusions and limited perspectives. This paper introduces a novel camera-LiDAR
fusion framework that leverages elevated intelligent roadside units (IRUs).
Additionally, we present RS-seq, a comprehensive dataset developed through the
systematic enhancement and annotation of the V2X-Seq dataset. RS-seq includes
precisely labelled camera imagery and LiDAR point clouds collected from
roadside installations, along with vectorized maps for seven intersections
annotated with detailed features such as lane dividers, pedestrian crossings,
and stop lines. This dataset facilitates the systematic investigation of
cross-modal complementarity for HD map generation using IRU data. The proposed
fusion framework employs a two-stage process that integrates modality-specific
feature extraction and cross-modal semantic integration, capitalizing on camera
high-resolution texture and precise geometric data from LiDAR. Quantitative
evaluations using the RS-seq dataset demonstrate that our multimodal approach
consistently surpasses unimodal methods. Specifically, compared to unimodal
baselines evaluated on the RS-seq dataset, the multimodal approach improves the
mean Intersection-over-Union (mIoU) for semantic segmentation by 4\% over the
image-only results and 18\% over the point cloud-only results. This study
establishes a baseline methodology for IRU-based HD semantic mapping and
provides a valuable dataset for future research in infrastructure-assisted
autonomous driving systems.

</details>


### [5] [Towards Human-level Dexterity via Robot Learning](https://arxiv.org/abs/2507.09117)
*Gagan Khandate*

Main category: cs.RO

TL;DR: 论文探讨了如何通过强化学习和模仿学习提升机器人多指操作的灵巧性。


<details>
  <summary>Details</summary>
Motivation: 人类灵巧智能是多指操作和高级认知能力的体现，但机器人实现类似能力仍面临根本性挑战。

Method: 采用结构化探索的强化学习方法，并结合基于采样的规划和视觉触觉人类示范的模仿学习技术。

Result: 提出了一种高效的强化学习框架，克服了随机探索的局限性，并引入了新的模仿学习范式。

Conclusion: 通过直接解决计算感觉运动学习的根本限制，论文为机器人高灵巧性操作提供了有效方法。

Abstract: Dexterous intelligence -- the ability to perform complex interactions with
multi-fingered hands -- is a pinnacle of human physical intelligence and
emergent higher-order cognitive skills. However, contrary to Moravec's paradox,
dexterous intelligence in humans appears simple only superficially. Many
million years were spent co-evolving the human brain and hands including rich
tactile sensing. Achieving human-level dexterity with robotic hands has long
been a fundamental goal in robotics and represents a critical milestone toward
general embodied intelligence. In this pursuit, computational sensorimotor
learning has made significant progress, enabling feats such as arbitrary
in-hand object reorientation. However, we observe that achieving higher levels
of dexterity requires overcoming very fundamental limitations of computational
sensorimotor learning.
  I develop robot learning methods for highly dexterous multi-fingered
manipulation by directly addressing these limitations at their root cause.
Chiefly, through key studies, this disseration progressively builds an
effective framework for reinforcement learning of dexterous multi-fingered
manipulation skills. These methods adopt structured exploration, effectively
overcoming the limitations of random exploration in reinforcement learning. The
insights gained culminate in a highly effective reinforcement learning that
incorporates sampling-based planning for direct exploration. Additionally, this
thesis explores a new paradigm of using visuo-tactile human demonstrations for
dexterity, introducing corresponding imitation learning techniques.

</details>


### [6] [Online 3D Bin Packing with Fast Stability Validation and Stable Rearrangement Planning](https://arxiv.org/abs/2507.09123)
*Ziyan Gao,Lijun Wang,Yuntao Kong,Nak Young Chong*

Main category: cs.RO

TL;DR: 提出了一种结合装箱策略、结构稳定性验证和启发式规划的新框架，解决了在线装箱问题中结构稳定性和安全重配置的不足。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法虽能提高容积利用率，但无法保证装箱的结构稳定性，且缺乏安全重配置机制。

Method: 引入负载可承受凸多边形（LBCP）概念，高效识别稳定装载位置；提出稳定重排规划（SRP）模块，动态调整装箱以维持稳定性。

Result: 实验表明LBCP验证高效且通用，SRP在节省重排成本方面表现优越。

Conclusion: 该方法为工业和物流中的自动化装箱提供了鲁棒且实用的解决方案。

Abstract: The Online Bin Packing Problem (OBPP) is a sequential decision-making task in
which each item must be placed immediately upon arrival, with no knowledge of
future arrivals. Although recent deep-reinforcement-learning methods achieve
superior volume utilization compared with classical heuristics, the learned
policies cannot ensure the structural stability of the bin and lack mechanisms
for safely reconfiguring the bin when a new item cannot be placed directly. In
this work, we propose a novel framework that integrates packing policy with
structural stability validation and heuristic planning to overcome these
limitations. Specifically, we introduce the concept of Load Bearable Convex
Polygon (LBCP), which provides a computationally efficient way to identify
stable loading positions that guarantee no bin collapse. Additionally, we
present Stable Rearrangement Planning (SRP), a module that rearranges existing
items to accommodate new ones while maintaining overall stability. Extensive
experiments on standard OBPP benchmarks demonstrate the efficiency and
generalizability of our LBCP-based stability validation, as well as the
superiority of SRP in finding the effort-saving rearrangement plans. Our method
offers a robust and practical solution for automated packing in real-world
industrial and logistics applications.

</details>


### [7] [Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization](https://arxiv.org/abs/2507.09160)
*Jialei Huang,Shuo Wang,Fanqi Lin,Yihang Hu,Chuan Wen,Yang Gao*

Main category: cs.RO

TL;DR: Tactile-VLA框架融合视觉、语言、动作和触觉感知，通过混合力-位控制器和触觉反馈推理模块，实现精确物理交互和自适应策略调整。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在物理交互中缺乏精细力控能力，尤其在接触密集场景中。本文旨在扩展VLA的隐式知识，从‘做什么’到‘如何物理交互’。

Method: 提出Tactile-VLA框架，结合混合力-位控制器和触觉反馈推理模块，通过少量演示激活VLM的先验知识。

Result: 实验证明Tactile-VLA在触觉感知指令跟随、触觉常识利用和自适应推理三方面表现优异，实现零样本泛化。

Conclusion: VLM的先验知识已包含物理交互语义理解，结合触觉传感器可激活该知识，提升接触密集任务的泛化能力。

Abstract: Vision-Language-Action (VLA) models have shown remarkable achievements,
driven by the rich implicit knowledge of their vision-language components.
However, achieving generalist robotic agents demands precise grounding into
physical interactions, especially in contact-rich scenarios where fine-grained
force control is essential. We advance VLAs' implicit knowledge beyond
identifying what to do, towards guiding how to physically interact with real
world. This paper introduces Tactile-VLA, a novel framework that deeply fuses
vision, language, action, and tactile sensing. This framework incorporates a
hybrid position-force controller to translate the model's intentions into
precise physical actions and a reasoning module that allows the robot to adapt
its strategy based on tactile feedback. Experiments demonstrate Tactile-VLA's
effectiveness and generalizability in three key aspects: (1) enabling
tactile-aware instruction following, (2) utilizing tactile-relevant
commonsense, and (3) facilitating adaptive tactile-involved reasoning. A key
finding is that the VLM's prior knowledge already contains semantic
understanding of physical interaction; by connecting it to the robot's tactile
sensors with only a few demonstrations, we can activate this prior knowledge to
achieve zero-shot generalization in contact-rich tasks.

</details>


### [8] [PRAG: Procedural Action Generator](https://arxiv.org/abs/2507.09167)
*Michal Vavrecka,Radoslav Skoviera,Gabriela Sejnova,Karla Stepanova*

Main category: cs.RO

TL;DR: 提出了一种新颖的多步骤接触丰富机器人操作任务生成方法，通过符号和物理验证确保任务可解性，适用于机器人训练和数据集构建。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作任务中多步骤、接触丰富的任务生成问题，提供可解任务以支持机器人学习和训练。

Method: 输入原子动作、对象和空间谓词，通过符号和物理验证生成可解任务序列，输出可用于训练或存储为数据集。

Result: 测试生成了数百万个独特的可解多步骤任务，序列长度达15个动作。

Conclusion: 该方法能高效生成可解任务，支持机器人学习和语义相似性测量。

Abstract: We present a novel approach for the procedural construction of multi-step
contact-rich manipulation tasks in robotics. Our generator takes as input
user-defined sets of atomic actions, objects, and spatial predicates and
outputs solvable tasks of a given length for the selected robotic environment.
The generator produces solvable tasks by constraining all possible
(nonsolvable) combinations by symbolic and physical validation. The symbolic
validation checks each generated sequence for logical and operational
consistency, and also the suitability of object-predicate relations. Physical
validation checks whether tasks can be solved in the selected robotic
environment. Only the tasks that passed both validators are retained. The
output from the generator can be directly interfaced with any existing
framework for training robotic manipulation tasks, or it can be stored as a
dataset of curated robotic tasks with detailed information about each task.
This is beneficial for RL training as there are dense reward functions and
initial and goal states paired with each subgoal. It allows the user to measure
the semantic similarity of all generated tasks. We tested our generator on
sequences of up to 15 actions resulting in millions of unique solvable
multi-step tasks.

</details>


### [9] [DLBAcalib: Robust Extrinsic Calibration for Non-Overlapping LiDARs Based on Dual LBA](https://arxiv.org/abs/2507.09176)
*Han Ye,Yuqiang Jin,Jinyuan Liu,Tao Li,Wen-An Zhang,Minglei Fu*

Main category: cs.RO

TL;DR: 提出了一种无需目标的多激光雷达外参标定框架，通过LiDAR束调整和自适应加权机制实现高精度标定。


<details>
  <summary>Details</summary>
Motivation: 多激光雷达系统的精确外参标定对3D地图重建至关重要，传统方法依赖重叠视野或手动标注，限制了应用。

Method: 结合LiDAR束调整（LBA）和鲁棒迭代优化，构建参考点云图并通过联合优化实现标定。

Result: 在CARLA仿真和真实场景中，平均平移误差5mm，旋转误差0.2°，初始误差容忍度达0.4m/30°。

Conclusion: 该方法在精度和鲁棒性上优于现有技术，无需专用基础设施或手动调参，代码开源。

Abstract: Accurate extrinsic calibration of multiple LiDARs is crucial for improving
the foundational performance of three-dimensional (3D) map reconstruction
systems. This paper presents a novel targetless extrinsic calibration framework
for multi-LiDAR systems that does not rely on overlapping fields of view or
precise initial parameter estimates. Unlike conventional calibration methods
that require manual annotations or specific reference patterns, our approach
introduces a unified optimization framework by integrating LiDAR bundle
adjustment (LBA) optimization with robust iterative refinement. The proposed
method constructs an accurate reference point cloud map via continuous scanning
from the target LiDAR and sliding-window LiDAR bundle adjustment, while
formulating extrinsic calibration as a joint LBA optimization problem. This
method effectively mitigates cumulative mapping errors and achieves
outlier-resistant parameter estimation through an adaptive weighting mechanism.
Extensive evaluations in both the CARLA simulation environment and real-world
scenarios demonstrate that our method outperforms state-of-the-art calibration
techniques in both accuracy and robustness. Experimental results show that for
non-overlapping sensor configurations, our framework achieves an average
translational error of 5 mm and a rotational error of 0.2{\deg}, with an
initial error tolerance of up to 0.4 m/30{\deg}. Moreover, the calibration
process operates without specialized infrastructure or manual parameter tuning.
The code is open source and available on GitHub
(\underline{https://github.com/Silentbarber/DLBAcalib})

</details>


### [10] [Informed Hybrid Zonotope-based Motion Planning Algorithm](https://arxiv.org/abs/2507.09309)
*Peng Xie,Johannes Betz,Amr Alanwar*

Main category: cs.RO

TL;DR: HZ-MP是一种基于混合Zonotope的运动规划器，通过分解无障碍空间和低维面采样，优化非凸自由空间中的路径规划。


<details>
  <summary>Details</summary>
Motivation: 传统混合整数线性规划（MILP）方法在非凸自由空间中路径规划问题上是NP难的，现有启发式规划器（如AIT*和EIT*）在狭窄间隙或目标受限场景中表现不佳。

Method: HZ-MP采用混合Zonotope分解无障碍空间，结合低维面采样和椭球体启发式引导，专注于有潜力的转移区域。

Result: HZ-MP被证明是概率完备且渐近最优的，能够在有限时间内收敛到接近最优的轨迹，并适用于高维复杂场景。

Conclusion: HZ-MP通过结构化探索显著提升了路径规划的效率和质量，优于现有启发式方法。

Abstract: Optimal path planning in nonconvex free spaces is notoriously challenging, as
formulating such problems as mixed-integer linear programs (MILPs) is NP-hard.
We propose HZ-MP, an informed Hybrid Zonotope-based Motion Planner, as an
alternative approach that decomposes the obstacle-free space and performs
low-dimensional face sampling guided by an ellipsotope heuristic, enabling
focused exploration along promising transit regions. This structured
exploration eliminates the excessive, unreachable sampling that degrades
existing informed planners such as AIT* and EIT* in narrow gaps or boxed-goal
scenarios. We prove that HZ-MP is probabilistically complete and asymptotically
optimal. It converges to near-optimal trajectories in finite time and scales to
high-dimensional cluttered scenes.

</details>


### [11] [Unified Linear Parametric Map Modeling and Perception-aware Trajectory Planning for Mobile Robotics](https://arxiv.org/abs/2507.09340)
*Hongyu Nie,Xingyu Li,Xu Liu,Zhaotong Tan,Sen Mei,Wenbo Su*

Main category: cs.RO

TL;DR: 论文提出RMRP方法，通过高维映射和稀疏随机投影构建轻量级线性参数地图，结合RPATR框架实现高效、安全的无人机和地面机器人导航。


<details>
  <summary>Details</summary>
Motivation: 解决大规模复杂环境中移动机器人导航的挑战，如计算负担、传感器遮挡和不规则地形问题。

Method: 使用RMRP构建轻量级地图，结合RPATR框架进行路径规划和轨迹优化，利用残差能量保留定理保证几何特性。

Result: 在多种场景中验证，框架在时间、内存和精度上表现优越，支持高速无人机和地面机器人的高效安全导航。

Conclusion: RMRP和RPATR框架有效解决了复杂环境中的导航问题，代码将开源以促进社区合作。

Abstract: Autonomous navigation in mobile robots, reliant on perception and planning,
faces major hurdles in large-scale, complex environments. These include heavy
computational burdens for mapping, sensor occlusion failures for UAVs, and
traversal challenges on irregular terrain for UGVs, all compounded by a lack of
perception-aware strategies. To address these challenges, we introduce Random
Mapping and Random Projection (RMRP). This method constructs a lightweight
linear parametric map by first mapping data to a high-dimensional space,
followed by a sparse random projection for dimensionality reduction. Our novel
Residual Energy Preservation Theorem provides theoretical guarantees for this
process, ensuring critical geometric properties are preserved. Based on this
map, we propose the RPATR (Robust Perception-Aware Trajectory Planner)
framework. For UAVs, our method unifies grid and Euclidean Signed Distance
Field (ESDF) maps. The front-end uses an analytical occupancy gradient to
refine initial paths for safety and smoothness, while the back-end uses a
closed-form ESDF for trajectory optimization. Leveraging the trained RMRP
model's generalization, the planner predicts unobserved areas for proactive
navigation. For UGVs, the model characterizes terrain and provides closed-form
gradients, enabling online planning to circumvent large holes. Validated in
diverse scenarios, our framework demonstrates superior mapping performance in
time, memory, and accuracy, and enables computationally efficient, safe
navigation for high-speed UAVs and UGVs. The code will be released to foster
community collaboration.

</details>


### [12] [C-ZUPT: Stationarity-Aided Aerial Hovering](https://arxiv.org/abs/2507.09344)
*Daniel Engelsman,Itzik Klein*

Main category: cs.RO

TL;DR: 论文提出了一种控制零速度更新（C-ZUPT）方法，用于空中导航，通过不确定性阈值识别准静态平衡，显著减少惯性漂移和能耗。


<details>
  <summary>Details</summary>
Motivation: 卫星和摄像头定位在复杂环境中受限，惯性传感器易受偏差和噪声影响，导致精度快速下降，需要一种新的信息辅助方法。

Method: 引入C-ZUPT方法，通过定义不确定性阈值识别准静态平衡，为估计滤波器提供精确速度更新。

Result: 实验验证表明，C-ZUPT显著减少惯性漂移和控制能耗，提高导航稳定性。

Conclusion: C-ZUPT方法有效抑制滤波器发散，提升能源效率，适用于资源受限的空中系统。

Abstract: Autonomous systems across diverse domains have underscored the need for
drift-resilient state estimation. Although satellite-based positioning and
cameras are widely used, they often suffer from limited availability in many
environments. As a result, positioning must rely solely on inertial sensors,
leading to rapid accuracy degradation over time due to sensor biases and noise.
To counteract this, alternative update sources-referred to as information
aiding-serve as anchors of certainty. Among these, the zero-velocity update
(ZUPT) is particularly effective in providing accurate corrections during
stationary intervals, though it is restricted to surface-bound platforms. This
work introduces a controlled ZUPT (C-ZUPT) approach for aerial navigation and
control, independent of surface contact. By defining an uncertainty threshold,
C-ZUPT identifies quasi-static equilibria to deliver precise velocity updates
to the estimation filter. Extensive validation confirms that these
opportunistic, high-quality updates significantly reduce inertial drift and
control effort. As a result, C-ZUPT mitigates filter divergence and enhances
navigation stability, enabling more energy-efficient hovering and substantially
extending sustained flight-key advantages for resource-constrained aerial
systems.

</details>


### [13] [Constrained Style Learning from Imperfect Demonstrations under Task Optimality](https://arxiv.org/abs/2507.09371)
*Kehan Wen,Chenhao Li,Junzhe He,Marco Hutter*

Main category: cs.RO

TL;DR: 论文提出了一种基于约束马尔可夫决策过程（CMDP）的方法，用于在机器人任务中平衡任务性能和风格模仿质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于与任务目标高度一致的专家演示，但实际演示往往不完整或不切实际，导致风格模仿以牺牲任务性能为代价。

Method: 通过将问题建模为CMDP，优化风格模仿目标并约束任务性能，同时引入自适应调整的拉格朗日乘数，选择性模仿演示。

Result: 在多个机器人平台和任务中验证了方法，实现了稳健的任务性能和高保真风格学习，ANYmal-D硬件上机械能耗降低14.5%，步态更敏捷。

Conclusion: 该方法有效解决了风格模仿与任务性能的平衡问题，展示了实际应用中的优势。

Abstract: Learning from demonstration has proven effective in robotics for acquiring
natural behaviors, such as stylistic motions and lifelike agility, particularly
when explicitly defining style-oriented reward functions is challenging.
Synthesizing stylistic motions for real-world tasks usually requires balancing
task performance and imitation quality. Existing methods generally depend on
expert demonstrations closely aligned with task objectives. However, practical
demonstrations are often incomplete or unrealistic, causing current methods to
boost style at the expense of task performance. To address this issue, we
propose formulating the problem as a constrained Markov Decision Process
(CMDP). Specifically, we optimize a style-imitation objective with constraints
to maintain near-optimal task performance. We introduce an adaptively
adjustable Lagrangian multiplier to guide the agent to imitate demonstrations
selectively, capturing stylistic nuances without compromising task performance.
We validate our approach across multiple robotic platforms and tasks,
demonstrating both robust task performance and high-fidelity style learning. On
ANYmal-D hardware we show a 14.5% drop in mechanical energy and a more agile
gait pattern, showcasing real-world benefits.

</details>


### [14] [Real-Time Adaptive Motion Planning via Point Cloud-Guided, Energy-Based Diffusion and Potential Fields](https://arxiv.org/abs/2507.09383)
*Wondmgezahu Teshome,Kian Behzad,Octavia Camps,Michael Everett,Milad Siami,Mario Sznaier*

Main category: cs.RO

TL;DR: 结合能量扩散模型与人工势场，提出一种实时轨迹规划框架，适用于复杂环境中的追逃问题。


<details>
  <summary>Details</summary>
Motivation: 解决追逃问题中的实时轨迹规划需求，特别是在复杂环境和部分观测条件下。

Method: 利用点云直接处理障碍物信息，结合无分类器引导训练和局部势场采样，增强避障能力。

Result: 在动态场景中生成初始轨迹并通过势场优化，表现出高效性能。

Conclusion: 该框架在部分观测的追逃场景中展现出鲁棒性和实时性。

Abstract: Motivated by the problem of pursuit-evasion, we present a motion planning
framework that combines energy-based diffusion models with artificial potential
fields for robust real time trajectory generation in complex environments. Our
approach processes obstacle information directly from point clouds, enabling
efficient planning without requiring complete geometric representations. The
framework employs classifier-free guidance training and integrates local
potential fields during sampling to enhance obstacle avoidance. In dynamic
scenarios, the system generates initial trajectories using the diffusion model
and continuously refines them through potential field-based adaptation,
demonstrating effective performance in pursuit-evasion scenarios with partial
pursuer observability.

</details>


### [15] [Influence of Static and Dynamic Downwash Interactions on Multi-Quadrotor Systems](https://arxiv.org/abs/2507.09463)
*Anoop Kiran,Nora Ayanian,Kenneth Breuer*

Main category: cs.RO

TL;DR: 论文通过数据驱动方法分析多旋翼无人机间的下洗效应，提出优化编队和控制的物理策略。


<details>
  <summary>Details</summary>
Motivation: 解决多旋翼无人机近距离飞行时因下洗效应导致的不稳定和性能下降问题，突破传统保守策略的限制。

Method: 使用力和扭矩测量以及粒子图像测速技术（PIV）量化单机和多机配置中的下洗效应。

Result: 数据揭示了力和速度的相互作用特征，为优化编队和扩展操作范围提供了依据。

Conclusion: 研究为多旋翼无人机的协调控制和鲁棒性提升提供了物理基础，扩展了其应用场景。

Abstract: Flying multiple quadrotors in close proximity presents a significant
challenge due to complex aerodynamic interactions, particularly downwash
effects that are known to destabilize vehicles and degrade performance.
Traditionally, multi-quadrotor systems rely on conservative strategies, such as
collision avoidance zones around the robot volume, to circumvent this effect.
This restricts their capabilities by requiring a large volume for the operation
of a multi-quadrotor system, limiting their applicability in dense
environments. This work provides a comprehensive, data-driven analysis of the
downwash effect, with a focus on characterizing, analyzing, and understanding
forces, moments, and velocities in both single and multi-quadrotor
configurations. We use measurements of forces and torques to characterize
vehicle interactions, and particle image velocimetry (PIV) to quantify the
spatial features of the downwash wake for a single quadrotor and an interacting
pair of quadrotors. This data can be used to inform physics-based strategies
for coordination, leverage downwash for optimized formations, expand the
envelope of operation, and improve the robustness of multi-quadrotor control.

</details>


### [16] [Unmanned Aerial Vehicle (UAV) Data-Driven Modeling Software with Integrated 9-Axis IMUGPS Sensor Fusion and Data Filtering Algorithm](https://arxiv.org/abs/2507.09464)
*Azfar Azdi Arfakhsyad,Aufa Nasywa Rahman,Larasati Kinanti,Ahmad Ataka Awwalur Rizqi,Hannan Nur Muhammad*

Main category: cs.RO

TL;DR: 提出了一种基于数据驱动的无人机建模软件，利用低成本传感器和传感器融合技术，通过IMU和GPS数据结合，实现高精度的无人机姿态和位置可视化。


<details>
  <summary>Details</summary>
Motivation: 无人机在测试和开发中需要精确建模，但传统方法成本高且复杂。

Method: 使用IMU数据（四元数表示避免万向节锁）和GPS数据（结合加速度计以平衡更新频率和稳定性），通过数据滤波和传感器融合技术提升数据质量。

Result: 软件能高精度、流畅地实时渲染无人机的姿态和位置。

Conclusion: 该软件为无人机开发提供了一种低成本、高精度的建模解决方案。

Abstract: Unmanned Aerial Vehicles (UAV) have emerged as versatile platforms, driving
the demand for accurate modeling to support developmental testing. This paper
proposes data-driven modeling software for UAV. Emphasizes the utilization of
cost-effective sensors to obtain orientation and location data subsequently
processed through the application of data filtering algorithms and sensor
fusion techniques to improve the data quality to make a precise model
visualization on the software. UAV's orientation is obtained using processed
Inertial Measurement Unit (IMU) data and represented using Quaternion
Representation to avoid the gimbal lock problem. The UAV's location is
determined by combining data from the Global Positioning System (GPS), which
provides stable geographic coordinates but slower data update frequency, and
the accelerometer, which has higher data update frequency but integrating it to
get position data is unstable due to its accumulative error. By combining data
from these two sensors, the software is able to calculate and continuously
update the UAV's real-time position during its flight operations. The result
shows that the software effectively renders UAV orientation and position with
high degree of accuracy and fluidity

</details>


### [17] [mmE-Loc: Facilitating Accurate Drone Landing with Ultra-High-Frequency Localization](https://arxiv.org/abs/2507.09469)
*Haoyang Wang,Jingao Xu,Xinyu Luo,Ting Zhang,Xuecheng Chen,Ruiyang Duan,Jialong Chen,Yunhao Liu,Jianfeng Zheng,Weijie Hong,Xinlei Chen*

Main category: cs.RO

TL;DR: 论文提出了一种结合事件相机与毫米波雷达的高精度、低延迟地面定位系统mmE-Loc，用于无人机精准降落。


<details>
  <summary>Details</summary>
Motivation: 传统帧相机采样频率低于毫米波雷达，导致系统吞吐量瓶颈，影响无人机降落的精度和效率。

Method: 采用事件相机替代传统帧相机，提出两个创新模块：一致性指导的协作跟踪模块和图引导的自适应联合优化模块。

Result: 实验表明，mmE-Loc在精度和延迟上显著优于现有方法。

Conclusion: mmE-Loc通过多模态融合和优化模块，实现了无人机降落的精准定位。

Abstract: For precise, efficient, and safe drone landings, ground platforms should
real-time, accurately locate descending drones and guide them to designated
spots. While mmWave sensing combined with cameras improves localization
accuracy, lower sampling frequency of traditional frame cameras compared to
mmWave radar creates bottlenecks in system throughput. In this work, we upgrade
traditional frame camera with event camera, a novel sensor that harmonizes in
sampling frequency with mmWave radar within ground platform setup, and
introduce mmE-Loc, a high-precision, low-latency ground localization system
designed for precise drone landings. To fully exploit the \textit{temporal
consistency} and \textit{spatial complementarity} between these two modalities,
we propose two innovative modules: \textit{(i)} the Consistency-instructed
Collaborative Tracking module, which further leverages the drone's physical
knowledge of periodic micro-motions and structure for accurate measurements
extraction, and \textit{(ii)} the Graph-informed Adaptive Joint Optimization
module, which integrates drone motion information for efficient sensor fusion
and drone localization. Real-world experiments conducted in landing scenarios
with a drone delivery company demonstrate that mmE-Loc significantly
outperforms state-of-the-art methods in both accuracy and latency.

</details>


### [18] [TruckV2X: A Truck-Centered Perception Dataset](https://arxiv.org/abs/2507.09505)
*Tenghui Xie,Zhiying Song,Fuxi Wen,Jun Li,Guangzhao Liu,Zijian Zhao*

Main category: cs.RO

TL;DR: 论文提出了TruckV2X数据集，填补了重型车辆协同感知数据集的空白，支持多模态感知和多智能体协作，以解决卡车感知中的盲区和遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 卡车自动驾驶面临独特的感知挑战，如盲区和动态拖车运动，现有数据集缺乏重型车辆场景的多智能体配置。

Method: 引入TruckV2X数据集，包含多模态感知（LiDAR和摄像头）和多智能体协作（牵引车、拖车、CAV和RSU），并分析卡车对协同感知需求的影响。

Result: 建立了性能基准，提出了重型车辆感知的研究重点，数据集为开发协同感知系统提供了基础。

Conclusion: TruckV2X数据集加速了多智能体自动驾驶卡车系统的部署，提升了遮挡处理能力。

Abstract: Autonomous trucking offers significant benefits, such as improved safety and
reduced costs, but faces unique perception challenges due to trucks' large size
and dynamic trailer movements. These challenges include extensive blind spots
and occlusions that hinder the truck's perception and the capabilities of other
road users. To address these limitations, cooperative perception emerges as a
promising solution. However, existing datasets predominantly feature light
vehicle interactions or lack multi-agent configurations for heavy-duty vehicle
scenarios. To bridge this gap, we introduce TruckV2X, the first large-scale
truck-centered cooperative perception dataset featuring multi-modal sensing
(LiDAR and cameras) and multi-agent cooperation (tractors, trailers, CAVs, and
RSUs). We further investigate how trucks influence collaborative perception
needs, establishing performance benchmarks while suggesting research priorities
for heavy vehicle perception. The dataset provides a foundation for developing
cooperative perception systems with enhanced occlusion handling capabilities,
and accelerates the deployment of multi-agent autonomous trucking systems. The
TruckV2X dataset is available at
https://huggingface.co/datasets/XieTenghu1/TruckV2X.

</details>


### [19] [Self-supervised Pretraining for Integrated Prediction and Planning of Automated Vehicles](https://arxiv.org/abs/2507.09537)
*Yangang Ren,Guojian Zhan,Chen Lv,Jun Li,Fenghua Liang,Keqiang Li*

Main category: cs.RO

TL;DR: Plan-MAE是一个基于掩码自编码器的预测与规划预训练框架，通过多任务学习提升自动驾驶车辆的轨迹规划能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖模仿学习，忽视了场景理解的全面性，Plan-MAE旨在通过多任务预训练实现更全面的轨迹规划。

Method: Plan-MAE通过三个任务学习：重建掩码道路网络（空间关联）、代理轨迹（社交交互）和导航路线（目的地意图），并加入局部子规划任务以对齐车辆动态。

Result: 实验表明，Plan-MAE在规划指标上大幅优于现有方法，可作为基于学习的运动规划器的重要预训练步骤。

Conclusion: Plan-MAE通过多任务预训练显著提升了自动驾驶车辆的预测与规划能力。

Abstract: Predicting the future of surrounding agents and accordingly planning a safe,
goal-directed trajectory are crucial for automated vehicles. Current methods
typically rely on imitation learning to optimize metrics against the ground
truth, often overlooking how scene understanding could enable more holistic
trajectories. In this paper, we propose Plan-MAE, a unified pretraining
framework for prediction and planning that capitalizes on masked autoencoders.
Plan-MAE fuses critical contextual understanding via three dedicated tasks:
reconstructing masked road networks to learn spatial correlations, agent
trajectories to model social interactions, and navigation routes to capture
destination intents. To further align vehicle dynamics and safety constraints,
we incorporate a local sub-planning task predicting the ego-vehicle's near-term
trajectory segment conditioned on earlier segment. This pretrained model is
subsequently fine-tuned on downstream tasks to jointly generate the prediction
and planning trajectories. Experiments on large-scale datasets demonstrate that
Plan-MAE outperforms current methods on the planning metrics by a large margin
and can serve as an important pre-training step for learning-based motion
planner.

</details>


### [20] [On the Importance of Neural Membrane Potential Leakage for LIDAR-based Robot Obstacle Avoidance using Spiking Neural Networks](https://arxiv.org/abs/2507.09538)
*Zainab Ali,Lujayn Al-Amir,Ali Safa*

Main category: cs.RO

TL;DR: 本文研究了基于SNN的机器人导航与避障，重点探讨了神经元膜泄漏对LIDAR数据处理精度的影响，并公开了数据集。


<details>
  <summary>Details</summary>
Motivation: 由于SNN在低功耗和高精度推理方面的优势，适合用于资源受限的自主机器人（如无人机和探测车）。

Method: 使用LIDAR数据训练SNN，研究神经元膜泄漏常数对避障精度的影响，并与非脉冲CNN对比。

Result: 通过调整LIF神经元的膜泄漏常数，SNN的避障精度可与非脉冲CNN相当。

Conclusion: SNN在机器人导航中具有潜力，膜泄漏常数的优化是关键，公开的数据集有助于未来研究。

Abstract: Using neuromorphic computing for robotics applications has gained much
attention in recent year due to the remarkable ability of Spiking Neural
Networks (SNNs) for high-precision yet low memory and compute complexity
inference when implemented in neuromorphic hardware. This ability makes SNNs
well-suited for autonomous robot applications (such as in drones and rovers)
where battery resources and payload are typically limited. Within this context,
this paper studies the use of SNNs for performing direct robot navigation and
obstacle avoidance from LIDAR data. A custom robot platform equipped with a
LIDAR is set up for collecting a labeled dataset of LIDAR sensing data together
with the human-operated robot control commands used for obstacle avoidance.
Crucially, this paper provides what is, to the best of our knowledge, a first
focused study about the importance of neuron membrane leakage on the SNN
precision when processing LIDAR data for obstacle avoidance. It is shown that
by carefully tuning the membrane potential leakage constant of the spiking
Leaky Integrate-and-Fire (LIF) neurons used within our SNN, it is possible to
achieve on-par robot control precision compared to the use of a non-spiking
Convolutional Neural Network (CNN). Finally, the LIDAR dataset collected during
this work is released as open-source with the hope of benefiting future
research.

</details>


### [21] [IteraOptiRacing: A Unified Planning-Control Framework for Real-time Autonomous Racing for Iterative Optimal Performance](https://arxiv.org/abs/2507.09714)
*Yifan Zeng,Yihan Li,Suiyi He,Koushil Sreenath,Jun Zeng*

Main category: cs.RO

TL;DR: 提出了一种基于i2LQR的统一规划控制策略IteraOptiRacing，用于自动驾驶赛车环境中的竞争，优化圈速并避免碰撞。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶赛车中多车动态障碍物环境下的实时规划与控制问题，优化圈速并确保安全。

Method: 采用迭代线性二次调节器（i2LQR），利用历史数据迭代优化轨迹，同时考虑障碍物避免和时间成本。

Result: 在高保真模拟器中验证，该策略在随机生成的动态场景中优于现有方法，实现实时操作。

Conclusion: IteraOptiRacing策略在多车竞争场景中表现优异，兼具实时性和性能优势。

Abstract: This paper presents a unified planning-control strategy for competing with
other racing cars called IteraOptiRacing in autonomous racing environments.
This unified strategy is proposed based on Iterative Linear Quadratic Regulator
for Iterative Tasks (i2LQR), which can improve lap time performance in the
presence of surrounding racing obstacles. By iteratively using the ego car's
historical data, both obstacle avoidance for multiple moving cars and time cost
optimization are considered in this unified strategy, resulting in
collision-free and time-optimal generated trajectories. The algorithm's
constant low computation burden and suitability for parallel computing enable
real-time operation in competitive racing scenarios. To validate its
performance, simulations in a high-fidelity simulator are conducted with
multiple randomly generated dynamic agents on the track. Results show that the
proposed strategy outperforms existing methods across all randomly generated
autonomous racing scenarios, enabling enhanced maneuvering for the ego racing
car.

</details>


### [22] [Visual Homing in Outdoor Robots Using Mushroom Body Circuits and Learning Walks](https://arxiv.org/abs/2507.09725)
*Gabriel G. Gattaux,Julien R. Serres,Franck Ruffier,Antoine Wystrach*

Main category: cs.RO

TL;DR: 该论文提出了一种基于蚂蚁视觉归巢行为的生物启发模型，首次在真实世界中实现了侧向蘑菇体（MB）架构的视觉归巢系统，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 蚂蚁仅需少量感官输入和学习行走即可实现稳健的视觉归巢，这启发了自主导航的生物仿生解决方案。

Method: 采用侧向蘑菇体（MB）架构，通过角路径积分（PI）信号分类全景视图，并利用记忆库实现归巢。实验包括模拟、真实世界学习行走、随机行走和精确停止行为验证。

Result: 系统在自然户外环境中实现了稳健的归巢行为，且资源消耗低（8 Hz运行，内存占用小于9 kB）。

Conclusion: 该研究为自主视觉归巢提供了一种生物基础且高效的解决方案，功能上类似于机器人中的基于路径点的位置控制。

Abstract: Ants achieve robust visual homing with minimal sensory input and only a few
learning walks, inspiring biomimetic solutions for autonomous navigation. While
Mushroom Body (MB) models have been used in robotic route following, they have
not yet been applied to visual homing. We present the first real-world
implementation of a lateralized MB architecture for visual homing onboard a
compact autonomous car-like robot. We test whether the sign of the angular path
integration (PI) signal can categorize panoramic views, acquired during
learning walks and encoded in the MB, into "goal on the left" and "goal on the
right" memory banks, enabling robust homing in natural outdoor settings. We
validate this approach through four incremental experiments: (1) simulation
showing attractor-like nest dynamics; (2) real-world homing after decoupled
learning walks, producing nest search behavior; (3) homing after random walks
using noisy PI emulated with GPS-RTK; and (4) precise stopping-at-the-goal
behavior enabled by a fifth MB Output Neuron (MBON) encoding goal-views to
control velocity. This mimics the accurate homing behavior of ants and
functionally resembles waypoint-based position control in robotics, despite
relying solely on visual input. Operating at 8 Hz on a Raspberry Pi 4 with
32x32 pixel views and a memory footprint under 9 kB, our system offers a
biologically grounded, resource-efficient solution for autonomous visual
homing.

</details>


### [23] [Active Probing with Multimodal Predictions for Motion Planning](https://arxiv.org/abs/2507.09822)
*Darshan Gadginmath,Farhad Nawaz,Minjun Sung,Faizan M Tariq,Sangjae Bae,David Isele,Fabio Pasqualetti,Jovin Dsa*

Main category: cs.RO

TL;DR: 提出了一种结合轨迹规划、多模态预测和主动探测的统一框架，以增强不确定性下的决策能力。


<details>
  <summary>Details</summary>
Motivation: 动态环境中导航需处理其他行为体的不确定性，现有方法难以同时处理多模态预测和主动探测。

Method: 开发了一种新的风险度量，通过混合模型集成多模态预测不确定性，并引入主动探测机制以减少预测模糊性。

Result: 在MetaDrive仿真环境中验证，框架能成功处理复杂交通场景，且对不同行为模型表现稳健。

Conclusion: 该框架为现实世界自动驾驶导航提供了一种广泛适用的解决方案。

Abstract: Navigation in dynamic environments requires autonomous systems to reason
about uncertainties in the behavior of other agents. In this paper, we
introduce a unified framework that combines trajectory planning with multimodal
predictions and active probing to enhance decision-making under uncertainty. We
develop a novel risk metric that seamlessly integrates multimodal prediction
uncertainties through mixture models. When these uncertainties follow a
Gaussian mixture distribution, we prove that our risk metric admits a
closed-form solution, and is always finite, thus ensuring analytical
tractability. To reduce prediction ambiguity, we incorporate an active probing
mechanism that strategically selects actions to improve its estimates of
behavioral parameters of other agents, while simultaneously handling multimodal
uncertainties. We extensively evaluate our framework in autonomous navigation
scenarios using the MetaDrive simulation environment. Results demonstrate that
our active probing approach successfully navigates complex traffic scenarios
with uncertain predictions. Additionally, our framework shows robust
performance across diverse traffic agent behavior models, indicating its broad
applicability to real-world autonomous navigation challenges. Code and videos
are available at
https://darshangm.github.io/papers/active-probing-multimodal-predictions/.

</details>


### [24] [Multi-residual Mixture of Experts Learning for Cooperative Control in Multi-vehicle Systems](https://arxiv.org/abs/2507.09836)
*Vindula Jayawardana,Sirui Li,Yashar Farid,Cathy Wu*

Main category: cs.RO

TL;DR: 论文提出了一种名为MRMEL的新框架，用于设计自主车辆（AVs）的拉格朗日交通控制策略，通过动态选择最优策略来适应多样化交通场景，显著减少车辆排放。


<details>
  <summary>Details</summary>
Motivation: 自主车辆作为移动执行器在交通流控制中具有潜力，但现有策略难以适应多样化交通场景，亟需一种通用且鲁棒的控制方法。

Method: 提出MRMEL框架，结合残差强化学习和专家混合模型，动态选择并优化子策略以适应不同交通场景。

Result: 在多个城市的真实交通场景中，MRMEL实现了4%-9%的车辆排放减少，优于现有基线方法。

Conclusion: MRMEL为拉格朗日交通控制提供了一种高效且通用的解决方案，显著提升了自主车辆在多样化交通场景中的性能。

Abstract: Autonomous vehicles (AVs) are becoming increasingly popular, with their
applications now extending beyond just a mode of transportation to serving as
mobile actuators of a traffic flow to control flow dynamics. This contrasts
with traditional fixed-location actuators, such as traffic signals, and is
referred to as Lagrangian traffic control. However, designing effective
Lagrangian traffic control policies for AVs that generalize across traffic
scenarios introduces a major challenge. Real-world traffic environments are
highly diverse, and developing policies that perform robustly across such
diverse traffic scenarios is challenging. It is further compounded by the joint
complexity of the multi-agent nature of traffic systems, mixed motives among
participants, and conflicting optimization objectives subject to strict
physical and external constraints. To address these challenges, we introduce
Multi-Residual Mixture of Expert Learning (MRMEL), a novel framework for
Lagrangian traffic control that augments a given suboptimal nominal policy with
a learned residual while explicitly accounting for the structure of the traffic
scenario space. In particular, taking inspiration from residual reinforcement
learning, MRMEL augments a suboptimal nominal AV control policy by learning a
residual correction, but at the same time dynamically selects the most suitable
nominal policy from a pool of nominal policies conditioned on the traffic
scenarios and modeled as a mixture of experts. We validate MRMEL using a case
study in cooperative eco-driving at signalized intersections in Atlanta, Dallas
Fort Worth, and Salt Lake City, with real-world data-driven traffic scenarios.
The results show that MRMEL consistently yields superior performance-achieving
an additional 4%-9% reduction in aggregate vehicle emissions relative to the
strongest baseline in each setting.

</details>


### [25] [AdvGrasp: Adversarial Attacks on Robotic Grasping from a Physical Perspective](https://arxiv.org/abs/2507.09857)
*Xiaofei Wang,Mingliang Han,Tianyu Hao,Cegang Li,Yunbo Zhao,Keke Tang*

Main category: cs.RO

TL;DR: AdvGrasp框架从物理角度对机器人抓取进行对抗攻击，针对提升能力和抓取稳定性，通过形状变形生成对抗对象，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注神经网络预测而忽略抓取的物理原理，AdvGrasp填补了这一空白，从物理角度评估和改进机器人抓取的鲁棒性。

Method: AdvGrasp通过变形物体形状以增加重力扭矩和降低稳定性裕度，系统性地破坏提升能力和抓取稳定性。

Result: 实验验证AdvGrasp在多种场景下的有效性，实际应用验证其鲁棒性和实用性。

Conclusion: AdvGrasp为机器人抓取的对抗攻击提供了物理视角的解决方案，具有实际应用价值。

Abstract: Adversarial attacks on robotic grasping provide valuable insights into
evaluating and improving the robustness of these systems. Unlike studies that
focus solely on neural network predictions while overlooking the physical
principles of grasping, this paper introduces AdvGrasp, a framework for
adversarial attacks on robotic grasping from a physical perspective.
Specifically, AdvGrasp targets two core aspects: lift capability, which
evaluates the ability to lift objects against gravity, and grasp stability,
which assesses resistance to external disturbances. By deforming the object's
shape to increase gravitational torque and reduce stability margin in the
wrench space, our method systematically degrades these two key grasping
metrics, generating adversarial objects that compromise grasp performance.
Extensive experiments across diverse scenarios validate the effectiveness of
AdvGrasp, while real-world validations demonstrate its robustness and practical
applicability

</details>


### [26] [Customize Harmonic Potential Fields via Hybrid Optimization over Homotopic Paths](https://arxiv.org/abs/2507.09858)
*Shuaikang Wang,Tiecheng Guo,Meng Guo*

Main category: cs.RO

TL;DR: 提出一种新方法，通过谐波势场自动生成具有特定拓扑性质的路径，适用于复杂工作空间。


<details>
  <summary>Details</summary>
Motivation: 现有谐波势场方法无法自定义路径的拓扑性质，限制了其在复杂场景中的应用。

Method: 采用混合优化算法，搜索路径的同伦类，并通过投影梯度下降优化权重参数。

Result: 方法在复杂工作空间中成功生成具有定制拓扑性质的路径，并通过仿真和硬件实验验证。

Conclusion: 该方法扩展了谐波势场的应用范围，为复杂场景中的机器人导航提供了新思路。

Abstract: Safe navigation within a workspace is a fundamental skill for autonomous
robots to accomplish more complex tasks. Harmonic potentials are artificial
potential fields that are analytical, globally convergent and provably free of
local minima. Thus, it has been widely used for generating safe and reliable
robot navigation control policies. However, most existing methods do not allow
customization of the harmonic potential fields nor the resulting paths,
particularly regarding their topological properties. In this paper, we propose
a novel method that automatically finds homotopy classes of paths that can be
generated by valid harmonic potential fields. The considered complex workspaces
can be as general as forest worlds consisting of numerous overlapping
star-obstacles. The method is based on a hybrid optimization algorithm that
searches over homotopy classes, selects the structure of each tree-of-stars
within the forest, and optimizes over the continuous weight parameters for each
purged tree via the projected gradient descent. The key insight is to transform
the forest world to the unbounded point world via proper diffeomorphic
transformations. It not only facilitates a simpler design of the
multi-directional D-signature between non-homotopic paths, but also retain the
safety and convergence properties. Extensive simulations and hardware
experiments are conducted for non-trivial scenarios, where the navigation
potentials are customized for desired homotopic properties. Project page:
https://shuaikang-wang.github.io/CustFields.

</details>


### [27] [Demonstrating the Octopi-1.5 Visual-Tactile-Language Model](https://arxiv.org/abs/2507.09985)
*Samson Yu,Kelvin Lin,Harold Soh*

Main category: cs.RO

TL;DR: Octopi-1.5是一个视觉-触觉-语言模型，支持多部位触觉信号处理和检索增强生成（RAG），用于提升任务性能和新物体学习。


<details>
  <summary>Details</summary>
Motivation: 触觉对人类和机器人至关重要，尤其在灵巧操作、材料识别和视觉遮挡场景中。Octopi-1.5旨在扩展触觉基础模型的能力。

Method: Octopi-1.5通过多部位触觉信号处理和RAG模块提升性能，并配备手持触觉接口TMI（含GelSight和TAC-02传感器）。

Result: 模型能完成触觉推理任务（如识别物体并推荐操作方式），并展示RAG能力（如学习新物体）。

Conclusion: Octopi-1.5展示了视觉-触觉-语言模型的进展与潜力，推动了该领域的研究兴趣。

Abstract: Touch is recognized as a vital sense for humans and an equally important
modality for robots, especially for dexterous manipulation, material
identification, and scenarios involving visual occlusion. Building upon very
recent work in touch foundation models, this demonstration will feature
Octopi-1.5, our latest visual-tactile-language model. Compared to its
predecessor, Octopi-1.5 introduces the ability to process tactile signals from
multiple object parts and employs a simple retrieval-augmented generation (RAG)
module to improve performance on tasks and potentially learn new objects
on-the-fly. The system can be experienced live through a new handheld
tactile-enabled interface, the TMI, equipped with GelSight and TAC-02 tactile
sensors. This convenient and accessible setup allows users to interact with
Octopi-1.5 without requiring a robot. During the demonstration, we will
showcase Octopi-1.5 solving tactile inference tasks by leveraging tactile
inputs and commonsense knowledge. For example, in a Guessing Game, Octopi-1.5
will identify objects being grasped and respond to follow-up queries about how
to handle it (e.g., recommending careful handling for soft fruits). We also
plan to demonstrate Octopi-1.5's RAG capabilities by teaching it new items.
With live interactions, this demonstration aims to highlight both the progress
and limitations of VTLMs such as Octopi-1.5 and to foster further interest in
this exciting field. Code for Octopi-1.5 and design files for the TMI gripper
are available at https://github.com/clear-nus/octopi-1.5.

</details>


### [28] [Ariel Explores: Vision-based underwater exploration and inspection via generalist drone-level autonomy](https://arxiv.org/abs/2507.10003)
*Mohit Singh,Mihir Dharmadhikari,Kostas Alexis*

Main category: cs.RO

TL;DR: 本文介绍了一种基于视觉的水下探索与检测自主解决方案，集成于Ariel水下机器人中，通过多摄像头视觉-惯性状态估计和学习型机器人速度预测方法提升鲁棒性，并在潜艇干船坞中进行了实地测试。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在视觉条件恶劣的水下环境中稳定工作的自主探索与检测系统，以提升水下机器人的自主性和适应性。

Method: 采用多摄像头视觉-惯性状态估计方法，结合学习型机器人速度预测技术，并集成自主探索与视觉检测功能。

Result: 实地测试表明，状态估计方法具有鲁棒性，路径规划技术适用于不同机器人平台。

Conclusion: 该系统在水下恶劣视觉条件下表现优异，验证了其自主性和通用性。

Abstract: This work presents a vision-based underwater exploration and inspection
autonomy solution integrated into Ariel, a custom vision-driven underwater
robot. Ariel carries a $5$ camera and IMU based sensing suite, enabling a
refraction-aware multi-camera visual-inertial state estimation method aided by
a learning-based proprioceptive robot velocity prediction method that enhances
robustness against visual degradation. Furthermore, our previously developed
and extensively field-verified autonomous exploration and general visual
inspection solution is integrated on Ariel, providing aerial drone-level
autonomy underwater. The proposed system is field-tested in a submarine dry
dock in Trondheim under challenging visual conditions. The field demonstration
shows the robustness of the state estimation solution and the generalizability
of the path planning techniques across robot embodiments.

</details>


### [29] [Finetuning Deep Reinforcement Learning Policies with Evolutionary Strategies for Control of Underactuated Robots](https://arxiv.org/abs/2507.10030)
*Marco Calì,Alberto Sinigaglia,Niccolò Turcato,Ruggero Carli,Gian Antonio Susto*

Main category: cs.RO

TL;DR: 提出一种结合深度强化学习和进化策略的方法，用于优化欠驱动机器人的控制策略。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在复杂控制问题中表现优异，但策略可能需要进一步优化以实现特定任务目标。

Method: 先用SAC训练策略，再用SNES进行进化策略微调。

Result: 实验表明，该方法显著提升性能并保持鲁棒性，优于基线。

Conclusion: 进化微调是一种有效的策略优化方法，适用于复杂控制任务。

Abstract: Deep Reinforcement Learning (RL) has emerged as a powerful method for
addressing complex control problems, particularly those involving underactuated
robotic systems. However, in some cases, policies may require refinement to
achieve optimal performance and robustness aligned with specific task
objectives. In this paper, we propose an approach for fine-tuning Deep RL
policies using Evolutionary Strategies (ES) to enhance control performance for
underactuated robots. Our method involves initially training an RL agent with
Soft-Actor Critic (SAC) using a surrogate reward function designed to
approximate complex specific scoring metrics. We subsequently refine this
learned policy through a zero-order optimization step employing the Separable
Natural Evolution Strategy (SNES), directly targeting the original score.
Experimental evaluations conducted in the context of the 2nd AI Olympics with
RealAIGym at IROS 2024 demonstrate that our evolutionary fine-tuning
significantly improves agent performance while maintaining high robustness. The
resulting controllers outperform established baselines, achieving competitive
scores for the competition tasks.

</details>


### [30] [MP-RBFN: Learning-based Vehicle Motion Primitives using Radial Basis Function Networks](https://arxiv.org/abs/2507.10047)
*Marc Kaufeld,Mattia Piccinini,Johannes Betz*

Main category: cs.RO

TL;DR: MP-RBFN是一种基于径向基函数网络的新方法，用于高效学习自动驾驶中的运动基元，结合了采样方法的性能和优化方法的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法计算成本高，而采样方法虽高效但轨迹形状受限，MP-RBFN旨在结合两者的优势。

Method: MP-RBFN利用径向基函数网络，将采样方法的高性能与车辆动力学的精确描述相结合。

Result: 实验表明，MP-RBFN在生成优化运动基元时精度提高7倍，且推理时间短。

Conclusion: MP-RBFN在运动规划中表现出色，已开源并集成到轨迹规划器中。

Abstract: This research introduces MP-RBFN, a novel formulation leveraging Radial Basis
Function Networks for efficiently learning Motion Primitives derived from
optimal control problems for autonomous driving. While traditional motion
planning approaches based on optimization are highly accurate, they are often
computationally prohibitive. In contrast, sampling-based methods demonstrate
high performance but impose constraints on the geometric shape of trajectories.
MP-RBFN combines the strengths of both by coupling the high-fidelity trajectory
generation of sampling-based methods with an accurate description of vehicle
dynamics. Empirical results show compelling performance compared to previous
methods, achieving a precise description of motion primitives at low inference
times. MP-RBFN yields a seven times higher accuracy in generating optimized
motion primitives compared to existing semi-analytic approaches. We demonstrate
the practical applicability of MP-RBFN for motion planning by integrating the
method into a sampling-based trajectory planner. MP-RBFN is available as
open-source software at https://github.com/TUM-AVS/RBFN-Motion-Primitives.

</details>


### [31] [Hand Gesture Recognition for Collaborative Robots Using Lightweight Deep Learning in Real-Time Robotic Systems](https://arxiv.org/abs/2507.10055)
*Muhtadin,I Wayan Agus Darmawan,Muhammad Hilmi Rusydiansyah,I Ketut Eddy Purnama,Chastine Fatichah,Mauridhi Hery Purnomo*

Main category: cs.RO

TL;DR: 提出了一种轻量级深度学习手势识别系统，用于自然控制协作机器人，模型仅需1,103参数和22KB大小，准确率达93.5%。


<details>
  <summary>Details</summary>
Motivation: 实现直接自然的人机交互，避免使用额外设备如操纵杆或传感器。

Method: 采用深度学习模型识别8种手势，并通过量化和剪枝优化模型至7KB。

Result: 在UR5协作机器人上成功实现实时手势控制，准确且响应迅速。

Conclusion: 轻量级模型能有效支持自然人机交互，适用于资源受限环境。

Abstract: Direct and natural interaction is essential for intuitive human-robot
collaboration, eliminating the need for additional devices such as joysticks,
tablets, or wearable sensors. In this paper, we present a lightweight deep
learning-based hand gesture recognition system that enables humans to control
collaborative robots naturally and efficiently. This model recognizes eight
distinct hand gestures with only 1,103 parameters and a compact size of 22 KB,
achieving an accuracy of 93.5%. To further optimize the model for real-world
deployment on edge devices, we applied quantization and pruning using
TensorFlow Lite, reducing the final model size to just 7 KB. The system was
successfully implemented and tested on a Universal Robot UR5 collaborative
robot within a real-time robotic framework based on ROS2. The results
demonstrate that even extremely lightweight models can deliver accurate and
responsive hand gesture-based control for collaborative robots, opening new
possibilities for natural human-robot interaction in constrained environments.

</details>


### [32] [TGLD: A Trust-Aware Game-Theoretic Lane-Changing Decision Framework for Automated Vehicles in Heterogeneous Traffic](https://arxiv.org/abs/2507.10075)
*Jie Pan,Tianyi Wang,Yangyang Wang,Junfeng Jiao,Christian Claudel*

Main category: cs.RO

TL;DR: 本文提出了一种信任感知的博弈论换道决策（TGLD）框架，通过动态评估人类驾驶车辆的信任水平，优化自动驾驶车辆的换道策略，提高与人类车辆的协作效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆（AVs）需要与人类驾驶车辆（HVs）在异构交通环境中有效协作，但现有换道框架忽视了HVs的动态信任水平，导致预测不准确。

Method: 1. 构建多车辆联盟博弈模型，结合AVs的全协作行为和HVs的部分协作行为；2. 开发在线信任评估方法，动态估计HVs的信任水平；3. 考虑社会兼容性目标，最小化对周围车辆的干扰。

Result: 实验表明，TGLD框架能根据HVs的信任水平和驾驶风格调整策略，显著提高换道效率、安全性和交互透明度。

Conclusion: 信任机制的引入使AVs能够更适应性地与HVs协作，提升整体交通系统的效率和安全性。

Abstract: Automated vehicles (AVs) face a critical need to adopt socially compatible
behaviors and cooperate effectively with human-driven vehicles (HVs) in
heterogeneous traffic environment. However, most existing lane-changing
frameworks overlook HVs' dynamic trust levels, limiting their ability to
accurately predict human driver behaviors. To address this gap, this study
proposes a trust-aware game-theoretic lane-changing decision (TGLD) framework.
First, we formulate a multi-vehicle coalition game, incorporating fully
cooperative interactions among AVs and partially cooperative behaviors from HVs
informed by real-time trust evaluations. Second, we develop an online trust
evaluation method to dynamically estimate HVs' trust levels during
lane-changing interactions, guiding AVs to select context-appropriate
cooperative maneuvers. Lastly, social compatibility objectives are considered
by minimizing disruption to surrounding vehicles and enhancing the
predictability of AV behaviors, thereby ensuring human-friendly and
context-adaptive lane-changing strategies. A human-in-the-loop experiment
conducted in a highway on-ramp merging scenario validates our TGLD approach.
Results show that AVs can effectively adjust strategies according to different
HVs' trust levels and driving styles. Moreover, incorporating a trust mechanism
significantly improves lane-changing efficiency, maintains safety, and
contributes to transparent and adaptive AV-HV interactions.

</details>


### [33] [Unscented Kalman Filter with a Nonlinear Propagation Model for Navigation Applications](https://arxiv.org/abs/2507.10082)
*Amit Levy,Itzik Klein*

Main category: cs.RO

TL;DR: 提出了一种改进的无迹卡尔曼滤波方法，通过非线性动态模型传播sigma点，提高了导航精度。


<details>
  <summary>Details</summary>
Motivation: 传统无迹卡尔曼滤波在导航应用中预测均值和协方差矩阵时存在不足，需改进以提高精度。

Method: 引入创新方法，根据导航误差状态向量的非线性动态模型传播sigma点。

Result: 实验表明，该方法提高了滤波器精度和导航性能。

Conclusion: 新方法在自主水下车辆的实际传感器数据中验证了其有效性。

Abstract: The unscented Kalman filter is a nonlinear estimation algorithm commonly used
in navigation applications. The prediction of the mean and covariance matrix is
crucial to the stable behavior of the filter. This prediction is done by
propagating the sigma points according to the dynamic model at hand. In this
paper, we introduce an innovative method to propagate the sigma points
according to the nonlinear dynamic model of the navigation error state vector.
This improves the filter accuracy and navigation performance. We demonstrate
the benefits of our proposed approach using real sensor data recorded by an
autonomous underwater vehicle during several scenarios.

</details>


### [34] [Foundation Model Driven Robotics: A Comprehensive Review](https://arxiv.org/abs/2507.10087)
*Muhammad Tayyab Khan,Ammar Waheed*

Main category: cs.RO

TL;DR: 综述探讨了基础模型（如LLMs和VLMs）在机器人领域的应用，分析了其优势与瓶颈，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 基础模型在语义理解、推理和多模态泛化方面的强大能力为机器人技术带来了变革，但实际应用中仍存在诸多挑战。

Method: 通过结构化综述，分类分析了基础模型在机器人领域的应用，并评估了系统级策略的可行性。

Result: 基础模型在感知、规划、控制和交互方面表现优异，但受限于数据、安全性和计算资源等问题。

Conclusion: 未来需加强语义推理与物理智能的结合，开发更鲁棒、可解释和具身化的模型。

Abstract: The rapid emergence of foundation models, particularly Large Language Models
(LLMs) and Vision-Language Models (VLMs), has introduced a transformative
paradigm in robotics. These models offer powerful capabilities in semantic
understanding, high-level reasoning, and cross-modal generalization, enabling
significant advances in perception, planning, control, and human-robot
interaction. This critical review provides a structured synthesis of recent
developments, categorizing applications across simulation-driven design,
open-world execution, sim-to-real transfer, and adaptable robotics. Unlike
existing surveys that emphasize isolated capabilities, this work highlights
integrated, system-level strategies and evaluates their practical feasibility
in real-world environments. Key enabling trends such as procedural scene
generation, policy generalization, and multimodal reasoning are discussed
alongside core bottlenecks, including limited embodiment, lack of multimodal
data, safety risks, and computational constraints. Through this lens, this
paper identifies both the architectural strengths and critical limitations of
foundation model-based robotics, highlighting open challenges in real-time
operation, grounding, resilience, and trust. The review concludes with a
roadmap for future research aimed at bridging semantic reasoning and physical
intelligence through more robust, interpretable, and embodied models.

</details>


### [35] [Physics-Informed Neural Networks with Unscented Kalman Filter for Sensorless Joint Torque Estimation in Humanoid Robots](https://arxiv.org/abs/2507.10105)
*Ines Sorrentino,Giulio Romualdi,Lorenzo Moretti,Silvio Traversaro,Daniele Pucci*

Main category: cs.RO

TL;DR: 该论文提出了一种无需关节扭矩传感器的人形机器人全身扭矩控制框架，结合物理信息神经网络（PINNs）和无迹卡尔曼滤波（UKF），提高了扭矩估计的鲁棒性和控制精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法如递归牛顿-欧拉算法（RNEA）在扭矩控制中存在局限性，尤其是在无传感器系统中。本文旨在通过结合PINNs和UKF，解决摩擦建模和扭矩估计的挑战。

Method: 使用PINNs建模非线性静态和动态摩擦，UKF基于PINN的摩擦估计进行扭矩估计，并在实时扭矩控制架构中集成。

Result: 实验验证表明，该方法在扭矩跟踪精度、能效和抗干扰能力上优于RNEA，且具有跨硬件平台的扩展性。

Conclusion: 该框架为无传感器扭矩控制提供了一种可扩展且实用的解决方案，适用于动态环境中的扭矩跟踪和稳定性控制。

Abstract: This paper presents a novel framework for whole-body torque control of
humanoid robots without joint torque sensors, designed for systems with
electric motors and high-ratio harmonic drives. The approach integrates
Physics-Informed Neural Networks (PINNs) for friction modeling and Unscented
Kalman Filtering (UKF) for joint torque estimation, within a real-time torque
control architecture. PINNs estimate nonlinear static and dynamic friction from
joint and motor velocity readings, capturing effects like motor actuation
without joint movement. The UKF utilizes PINN-based friction estimates as
direct measurement inputs, improving torque estimation robustness. Experimental
validation on the ergoCub humanoid robot demonstrates improved torque tracking
accuracy, enhanced energy efficiency, and superior disturbance rejection
compared to the state-of-the-art Recursive Newton-Euler Algorithm (RNEA), using
a dynamic balancing experiment. The framework's scalability is shown by
consistent performance across robots with similar hardware but different
friction characteristics, without re-identification. Furthermore, a comparative
analysis with position control highlights the advantages of the proposed torque
control approach. The results establish the method as a scalable and practical
solution for sensorless torque control in humanoid robots, ensuring torque
tracking, adaptability, and stability in dynamic environments.

</details>


### [36] [Simulations and experiments with assemblies of fiber-reinforced soft actuators](https://arxiv.org/abs/2507.10121)
*Seung Hyun Kim,Jiamiao Guo,Arman Tekinalp,Heng-Sheng Chang,Ugur Akcal,Tixian Wang,Darren Biskup,Benjamin Walt,Girish Chowdhary,Girish Krishnan,Prashant G. Mehta,Mattia Gazzola*

Main category: cs.RO

TL;DR: 开发了一种用于模块化纤维增强弹性体软连续臂（SCAs）的仿真框架，并结合视频跟踪系统进行实验测试和控制设计。


<details>
  <summary>Details</summary>
Motivation: 软连续臂（SCAs）因其机械柔顺性在多种应用中具有潜力，但其非线性行为难以控制，限制了实际应用。

Method: 开发了一个仿真框架，用于模块化组装的纤维增强弹性体（FREEs）SCAs，并集成视频跟踪系统进行实验和控制设计。

Result: 通过仿真和实验验证了该框架的有效性，为SCAs的控制提供了新方法。

Conclusion: 该框架为解决SCAs非线性控制问题提供了实用工具，推动了其在实际应用中的发展。

Abstract: Soft continuum arms (SCAs) promise versatile manipulation through mechanical
compliance, for assistive devices, agriculture, search applications, or
surgery. However, SCAs' real-world use is challenging, partly due to their
hard-to-control non-linear behavior. Here, a simulation framework for SCAs
modularly assembled out of fiber reinforced elastomeric enclosures (FREEs) is
developed and integrated with a video-tracking system for experimental testing
and control design.

</details>


### [37] [Probabilistic Human Intent Prediction for Mobile Manipulation: An Evaluation with Human-Inspired Constraints](https://arxiv.org/abs/2507.10131)
*Cesar Alan Contreras,Manolis Chiou,Alireza Rastegarpanah,Michal Szulik,Rustam Stolkin*

Main category: cs.RO

TL;DR: GUIDER是一个概率框架，通过双阶段（导航和操作）估计人类意图，提升人机协作效率。


<details>
  <summary>Details</summary>
Motivation: 提高人机协作中意图推断的准确性，避免限制人类控制或引发冲突。

Method: GUIDER采用双阶段框架：导航阶段通过Synergy Map和3D扫描；操作阶段结合U2Net、FastSAM和几何测试。

Result: 在25次试验中，导航稳定性达93-100%，操作稳定性达94-100%，显著优于基线方法。

Conclusion: GUIDER在移动操作任务中显著提升了意图推断能力。

Abstract: Accurate inference of human intent enables human-robot collaboration without
constraining human control or causing conflicts between humans and robots. We
present GUIDER (Global User Intent Dual-phase Estimation for Robots), a
probabilistic framework that enables a robot to estimate the intent of human
operators. GUIDER maintains two coupled belief layers, one tracking navigation
goals and the other manipulation goals. In the Navigation phase, a Synergy Map
blends controller velocity with an occupancy grid to rank interaction areas.
Upon arrival at a goal, an autonomous multi-view scan builds a local 3D cloud.
The Manipulation phase combines U2Net saliency, FastSAM instance saliency, and
three geometric grasp-feasibility tests, with an end-effector kinematics-aware
update rule that evolves object probabilities in real-time. GUIDER can
recognize areas and objects of intent without predefined goals. We evaluated
GUIDER on 25 trials (five participants x five task variants) in Isaac Sim, and
compared it with two baselines, one for navigation and one for manipulation.
Across the 25 trials, GUIDER achieved a median stability of 93-100% during
navigation, compared with 60-100% for the BOIR baseline, with an improvement of
39.5% in a redirection scenario (T5). During manipulation, stability reached
94-100% (versus 69-100% for Trajectron), with a 31.4% difference in a
redirection task (T3). In geometry-constrained trials (manipulation), GUIDER
recognized the object intent three times earlier than Trajectron (median
remaining time to confident prediction 23.6 s vs 7.8 s). These results validate
our dual-phase framework and show improvements in intent inference in both
phases of mobile manipulation tasks.

</details>


### [38] [Robust RL Control for Bipedal Locomotion with Closed Kinematic Chains](https://arxiv.org/abs/2507.10164)
*Egor Maslennikov,Eduard Zaliaev,Nikita Dudorov,Oleg Shamanin,Karanov Dmitry,Gleb Afanasev,Alexey Burkov,Egor Lygin,Simeon Nedelchev,Evgeny Ponomarev*

Main category: cs.RO

TL;DR: 提出了一种强化学习框架，显式结合闭链动力学，显著提升双足机器人运动控制的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法将闭链简化为串行模型，忽略了关节耦合等关键动态特性，影响仿真到现实的迁移效果。

Method: 采用对称感知损失函数、对抗训练和针对性网络正则化，结合闭链动力学。

Result: 在自定义机器人TopA上验证，实现了跨多种地形的稳定运动，显著优于简化模型方法。

Conclusion: 显式建模闭链动力学能有效提升双足机器人运动控制的鲁棒性和仿真到现实迁移能力。

Abstract: Developing robust locomotion controllers for bipedal robots with closed
kinematic chains presents unique challenges, particularly since most
reinforcement learning (RL) approaches simplify these parallel mechanisms into
serial models during training. We demonstrate that this simplification
significantly impairs sim-to-real transfer by failing to capture essential
aspects such as joint coupling, friction dynamics, and motor-space control
characteristics. In this work, we present an RL framework that explicitly
incorporates closed-chain dynamics and validate it on our custom-built robot
TopA. Our approach enhances policy robustness through symmetry-aware loss
functions, adversarial training, and targeted network regularization.
Experimental results demonstrate that our integrated approach achieves stable
locomotion across diverse terrains, significantly outperforming methods based
on simplified kinematic models.

</details>


### [39] [REACT: Real-time Entanglement-Aware Coverage Path Planning for Tethered Underwater Vehicles](https://arxiv.org/abs/2507.10204)
*Abdelhakim Amer,Mohit Mehindratta,Yury Brodskiy,Bilal Wehbe,Erdal Kayacan*

Main category: cs.RO

TL;DR: REACT框架通过实时几何模型和路径规划，解决了水下机器人因缆绳缠绕导致的安全问题，显著提高了任务效率。


<details>
  <summary>Details</summary>
Motivation: 水下机器人检查复杂结构时，缆绳缠绕风险限制了其效率。REACT旨在解决这一问题。

Method: REACT使用基于几何的缆绳模型（SDF地图）和实时重规划策略，防止缠绕并优化路径。

Result: 在管道检查场景中，REACT实现了无缠绕导航和全覆盖检查，任务完成时间缩短20%。

Conclusion: REACT框架有效解决了缆绳缠绕问题，提升了水下检查的安全性和效率。

Abstract: Inspection of complex underwater structures with tethered underwater vehicles
is often hindered by the risk of tether entanglement. We propose REACT
(real-time entanglement-aware coverage path planning for tethered underwater
vehicles), a framework designed to overcome this limitation. REACT comprises a
fast geometry-based tether model using the signed distance field (SDF) map for
accurate, real-time simulation of taut tether configurations around arbitrary
structures in 3D. This model enables an efficient online replanning strategy by
enforcing a maximum tether length constraint, thereby actively preventing
entanglement. By integrating REACT into a coverage path planning framework, we
achieve safe and optimal inspection paths, previously challenging due to tether
constraints. The complete REACT framework's efficacy is validated in a pipe
inspection scenario, demonstrating safe, entanglement-free navigation and
full-coverage inspection. Simulation results show that REACT achieves complete
coverage while maintaining tether constraints and completing the total mission
20% faster than conventional planners, despite a longer inspection time due to
proactive avoidance of entanglement that eliminates extensive post-mission
disentanglement. Real-world experiments confirm these benefits, where REACT
completes the full mission, while the baseline planner fails due to physical
tether entanglement.

</details>


### [40] [Prompt Informed Reinforcement Learning for Visual Coverage Path Planning](https://arxiv.org/abs/2507.10284)
*Venkat Margapuri*

Main category: cs.RO

TL;DR: 论文提出了一种名为PIRL的新方法，结合大型语言模型（LLM）的零样本推理能力和好奇心驱动的强化学习（RL），通过动态调整奖励函数优化无人机视觉覆盖路径规划。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法依赖环境特定的奖励函数，缺乏语义适应性，无法灵活应对复杂任务。

Method: PIRL利用GPT-3.5的语义反馈动态调整PPO算法的奖励函数，指导无人机位置和相机调整。实验在OpenAI Gym和Webots仿真环境中进行。

Result: PIRL在视觉覆盖率（最高提升14%-27%）、电池效率（最高提升25%）和冗余度（最高降低18%）上均优于基线方法。

Conclusion: LLM引导的奖励塑形在复杂空间探索任务中有效，为自然语言先验与RL的结合提供了新方向。

Abstract: Visual coverage path planning with unmanned aerial vehicles (UAVs) requires
agents to strategically coordinate UAV motion and camera control to maximize
coverage, minimize redundancy, and maintain battery efficiency. Traditional
reinforcement learning (RL) methods rely on environment-specific reward
formulations that lack semantic adaptability. This study proposes
Prompt-Informed Reinforcement Learning (PIRL), a novel approach that integrates
the zero-shot reasoning ability and in-context learning capability of large
language models with curiosity-driven RL. PIRL leverages semantic feedback from
an LLM, GPT-3.5, to dynamically shape the reward function of the Proximal
Policy Optimization (PPO) RL policy guiding the agent in position and camera
adjustments for optimal visual coverage. The PIRL agent is trained using OpenAI
Gym and evaluated in various environments. Furthermore, the sim-to-real-like
ability and zero-shot generalization of the agent are tested by operating the
agent in Webots simulator which introduces realistic physical dynamics. Results
show that PIRL outperforms multiple learning-based baselines such as PPO with
static rewards, PPO with exploratory weight initialization, imitation learning,
and an LLM-only controller. Across different environments, PIRL outperforms the
best-performing baseline by achieving up to 14% higher visual coverage in
OpenAI Gym and 27% higher in Webots, up to 25% higher battery efficiency, and
up to 18\% lower redundancy, depending on the environment. The results
highlight the effectiveness of LLM-guided reward shaping in complex spatial
exploration tasks and suggest a promising direction for integrating natural
language priors into RL for robotics.

</details>


### [41] [TOP: Trajectory Optimization via Parallel Optimization towards Constant Time Complexity](https://arxiv.org/abs/2507.10290)
*Jiajun Yu,Nanhe Chen,Guodong Liu,Chao Xu,Fei Gao,Yanjun Cao*

Main category: cs.RO

TL;DR: 提出了一种基于CADMM算法的并行轨迹优化框架，显著提升大规模长轨迹的处理效率。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹优化方法在处理大规模长轨迹时效率不足，并行计算的应用潜力尚未充分挖掘。

Method: 采用CADMM算法将轨迹分解为多段并行求解，引入闭式解加速优化，并支持一般不等式约束的数值解。

Result: 相比SOTA方法，每迭代时间降至O(1)，百段轨迹提速十倍以上，GPU部署支持千段并行。

Conclusion: 该框架在效率和平滑性上优于现有方法，适用于现代并行计算架构。

Abstract: Optimization has been widely used to generate smooth trajectories for motion
planning. However, existing trajectory optimization methods show weakness when
dealing with large-scale long trajectories. Recent advances in parallel
computing have accelerated optimization in some fields, but how to efficiently
solve trajectory optimization via parallelism remains an open question. In this
paper, we propose a novel trajectory optimization framework based on the
Consensus Alternating Direction Method of Multipliers (CADMM) algorithm, which
decomposes the trajectory into multiple segments and solves the subproblems in
parallel. The proposed framework reduces the time complexity to O(1) per
iteration to the number of segments, compared to O(N) of the state-of-the-art
(SOTA) approaches. Furthermore, we introduce a closed-form solution that
integrates convex linear and quadratic constraints to speed up the
optimization, and we also present numerical solutions for general inequality
constraints. A series of simulations and experiments demonstrate that our
approach outperforms the SOTA approach in terms of efficiency and smoothness.
Especially for a large-scale trajectory, with one hundred segments, achieving
over a tenfold speedup. To fully explore the potential of our algorithm on
modern parallel computing architectures, we deploy our framework on a GPU and
show high performance with thousands of segments.

</details>


### [42] [Polygonal Obstacle Avoidance Combining Model Predictive Control and Fuzzy Logic](https://arxiv.org/abs/2507.10310)
*Michael Schröder,Eric Schöneberg,Daniel Görges,Hans D. Schotten*

Main category: cs.RO

TL;DR: 论文提出了一种将离散占用网格地图转化为连续可微函数的方法，以便在模型预测控制（MPC）中嵌入障碍物避障约束，利用模糊逻辑处理逻辑运算符，成功实现了仿真测试。


<details>
  <summary>Details</summary>
Motivation: 解决MPC中离散占用网格地图与连续可微约束不兼容的问题，实现更高效的障碍物避障路径规划。

Method: 将障碍物表示为多边形（半空间的交集），利用模糊逻辑将逻辑运算符转化为不等式约束，嵌入MPC框架。

Result: 成功在仿真中测试了基于MPC的轨迹规划器，验证了方法的有效性。

Conclusion: 该方法不仅适用于导航任务，还可扩展到其他需要逻辑或语言约束的MPC应用中。

Abstract: In practice, navigation of mobile robots in confined environments is often
done using a spatially discrete cost-map to represent obstacles. Path following
is a typical use case for model predictive control (MPC), but formulating
constraints for obstacle avoidance is challenging in this case. Typically the
cost and constraints of an MPC problem are defined as closed-form functions and
typical solvers work best with continuously differentiable functions. This is
contrary to spatially discrete occupancy grid maps, in which a grid's value
defines the cost associated with occupancy. This paper presents a way to
overcome this compatibility issue by re-formulating occupancy grid maps to
continuously differentiable functions to be embedded into the MPC scheme as
constraints. Each obstacle is defined as a polygon -- an intersection of
half-spaces. Any half-space is a linear inequality representing one edge of a
polygon. Using AND and OR operators, the combined set of all obstacles and
therefore the obstacle avoidance constraints can be described. The key
contribution of this paper is the use of fuzzy logic to re-formulate such
constraints that include logical operators as inequality constraints which are
compatible with standard MPC formulation. The resulting MPC-based trajectory
planner is successfully tested in simulation. This concept is also applicable
outside of navigation tasks to implement logical or verbal constraints in MPC.

</details>


### [43] [Raci-Net: Ego-vehicle Odometry Estimation in Adverse Weather Conditions](https://arxiv.org/abs/2507.10376)
*Mohammadhossein Talebi,Pragyan Dahal,Davide Possenti,Stefano Arrigoni,Francesco Braghin*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度学习的运动估计器，结合视觉、惯性和毫米波雷达数据，以提升恶劣环境下的里程估计精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态环境因素（如天气条件）下性能下降，为解决这一问题，研究提出了一种新型传感器融合方法。

Method: 采用先进的传感器融合技术，动态调整各传感器的贡献，利用雷达补偿视觉传感器在低能见度下的不足。

Result: 在Boreas数据集上的实验表明，该模型在清晰和恶劣环境下均表现出鲁棒性和有效性。

Conclusion: 雷达在不同天气条件下的鲁棒性使其成为姿态估计系统的宝贵组件，尤其在视觉传感器性能下降时。

Abstract: Autonomous driving systems are highly dependent on sensors like cameras,
LiDAR, and inertial measurement units (IMU) to perceive the environment and
estimate their motion. Among these sensors, perception-based sensors are not
protected from harsh weather and technical failures. Although existing methods
show robustness against common technical issues like rotational misalignment
and disconnection, they often degrade when faced with dynamic environmental
factors like weather conditions. To address these problems, this research
introduces a novel deep learning-based motion estimator that integrates visual,
inertial, and millimeter-wave radar data, utilizing each sensor strengths to
improve odometry estimation accuracy and reliability under adverse
environmental conditions such as snow, rain, and varying light. The proposed
model uses advanced sensor fusion techniques that dynamically adjust the
contributions of each sensor based on the current environmental condition, with
radar compensating for visual sensor limitations in poor visibility. This work
explores recent advancements in radar-based odometry and highlights that radar
robustness in different weather conditions makes it a valuable component for
pose estimation systems, specifically when visual sensors are degraded.
Experimental results, conducted on the Boreas dataset, showcase the robustness
and effectiveness of the model in both clear and degraded environments.

</details>


### [44] [Scene-Aware Conversational ADAS with Generative AI for Real-Time Driver Assistance](https://arxiv.org/abs/2507.10500)
*Kyungtae Han,Yitao Chen,Rohit Gupta,Onur Altintas*

Main category: cs.RO

TL;DR: SC-ADAS是一个结合生成式AI的模块化框架，通过自然语言对话和场景感知提升ADAS的交互性和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前ADAS系统缺乏场景理解和自然语言交互能力，无法灵活适应动态环境或驾驶员意图。

Method: 集成大型语言模型、视觉到文本解释和结构化函数调用，支持多轮对话和驾驶员确认的ADAS控制。

Result: 在CARLA模拟器中实现，展示了场景感知、对话和多轮交互的可行性，但存在延迟和令牌增长问题。

Conclusion: SC-ADAS证明了结合对话推理、场景感知和模块化ADAS控制的可行性，为下一代智能驾驶辅助提供了方向。

Abstract: While autonomous driving technologies continue to advance, current Advanced
Driver Assistance Systems (ADAS) remain limited in their ability to interpret
scene context or engage with drivers through natural language. These systems
typically rely on predefined logic and lack support for dialogue-based
interaction, making them inflexible in dynamic environments or when adapting to
driver intent. This paper presents Scene-Aware Conversational ADAS (SC-ADAS), a
modular framework that integrates Generative AI components including large
language models, vision-to-text interpretation, and structured function calling
to enable real-time, interpretable, and adaptive driver assistance. SC-ADAS
supports multi-turn dialogue grounded in visual and sensor context, allowing
natural language recommendations and driver-confirmed ADAS control. Implemented
in the CARLA simulator with cloud-based Generative AI, the system executes
confirmed user intents as structured ADAS commands without requiring model
fine-tuning. We evaluate SC-ADAS across scene-aware, conversational, and
revisited multi-turn interactions, highlighting trade-offs such as increased
latency from vision-based context retrieval and token growth from accumulated
dialogue history. These results demonstrate the feasibility of combining
conversational reasoning, scene perception, and modular ADAS control to support
the next generation of intelligent driver assistance.

</details>


### [45] [MP1: Mean Flow Tames Policy Learning in 1-step for Robotic Manipulation](https://arxiv.org/abs/2507.10543)
*Juyi Sheng,Ziyi Wang,Peiming Li,Mengyuan Liu*

Main category: cs.RO

TL;DR: MP1提出了一种结合MeanFlow范式与3D点云输入的方法，通过单次网络评估生成动作轨迹，解决了扩散模型和Flow-based方法的速度与精度问题。


<details>
  <summary>Details</summary>
Motivation: 机器人学习中，生成模型在速度与精度之间存在权衡，MP1旨在解决这一问题。

Method: MP1采用MeanFlow Identity直接学习区间平均速度，避免一致性约束，并结合CFG提升轨迹可控性，同时引入Dispersive Loss增强泛化能力。

Result: 在Adroit和Meta-World基准测试中，MP1平均任务成功率优于DP3和FlowPolicy，推理时间显著缩短。

Conclusion: MP1通过高效的单次网络评估和轻量级损失函数，实现了更快的推理速度和更高的任务成功率。

Abstract: In robot manipulation, robot learning has become a prevailing approach.
However, generative models within this field face a fundamental trade-off
between the slow, iterative sampling of diffusion models and the architectural
constraints of faster Flow-based methods, which often rely on explicit
consistency losses. To address these limitations, we introduce MP1, which pairs
3D point-cloud inputs with the MeanFlow paradigm to generate action
trajectories in one network function evaluation (1-NFE). By directly learning
the interval-averaged velocity via the MeanFlow Identity, our policy avoids any
additional consistency constraints. This formulation eliminates numerical
ODE-solver errors during inference, yielding more precise trajectories. MP1
further incorporates CFG for improved trajectory controllability while
retaining 1-NFE inference without reintroducing structural constraints. Because
subtle scene-context variations are critical for robot learning, especially in
few-shot learning, we introduce a lightweight Dispersive Loss that repels state
embeddings during training, boosting generalization without slowing inference.
We validate our method on the Adroit and Meta-World benchmarks, as well as in
real-world scenarios. Experimental results show MP1 achieves superior average
task success rates, outperforming DP3 by 10.2% and FlowPolicy by 7.3%. Its
average inference time is only 6.8 ms-19x faster than DP3 and nearly 2x faster
than FlowPolicy. Our code is available at https://mp1-2254.github.io/.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [46] [Think Clearly: Improving Reasoning via Redundant Token Pruning](https://arxiv.org/abs/2507.08806)
*Daewon Choi,Jimin Lee,Jihoon Tack,Woomin Song,Saket Dingliwal,Sai Muralidhar Jayanthi,Bhavana Ganesh,Jinwoo Shin,Aram Galstyan,Sravan Babu Bodapati*

Main category: cs.AI

TL;DR: 论文提出了一种通过去除推理过程中的冗余来提升大语言模型性能的方法，利用注意力分数识别并剪枝低贡献推理块。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在长链推理中存在冗余问题，注意力分散且错误答案的注意力更稀疏，影响了推理性能。

Method: 通过测量特殊‘思考结束’标记的注意力分数识别冗余，采用结构感知剪枝去除低贡献推理块，并在剪枝后恢复推理生成。

Result: 该方法显著提升了推理密集型任务的准确性，尤其在数学竞赛基准（如AIME和AMC）上表现突出。

Conclusion: 通过去除推理冗余，无需额外训练即可显著提升模型性能，尤其在复杂推理任务中效果显著。

Abstract: Recent large language models have shown promising capabilities in long-form
reasoning, following structured chains of thought before arriving at a final
answer. However, we observe that these reasoning paths tend to include
substantial redundancy; analyzing attention patterns reveals that attention
scores are widely scattered, particularly incorrect answers exhibit greater
attention sparsity. In this paper, we demonstrate that deliberately removing
this redundancy in the reasoning process significantly improves performance
through clear thinking, i.e., removing distraction. Specifically, we
systematically identify reasoning redundancy by measuring token-level attention
scores to a special end-of-thinking token, which is appended to an explicit
instruction inserted to conclude each intermediate reasoning step. Furthermore,
we propose structure-aware pruning that prioritizes removing tokens in
low-contributing reasoning chunks over individual tokens. After evicting
redundant tokens, we remove the injected end-of-thinking instruction, then
resume the reasoning generation. We demonstrate that our method significantly
improves overall accuracy across reasoning-intensive benchmarks without any
training involved. In particular, our method shows strong performance on
challenging mathematical competition benchmarks such as AIME and AMC, where
reasoning redundancy is more prevalent.

</details>


### [47] [A New Approach for Multicriteria Assessment in the Ranking of Alternatives Using Cardinal and Ordinal Data](https://arxiv.org/abs/2507.08875)
*Fuh-Hwa Franklin Liu,Su-Chuan Shih*

Main category: cs.AI

TL;DR: 提出了一种结合两种虚拟差距分析（VGA）模型的新型多标准评估（MCA）方法，以提高评估效率和公平性。


<details>
  <summary>Details</summary>
Motivation: 解决传统多标准评估方法（如DEA、SFA、MCDM）因假设和主观判断导致的局限性，尤其是在处理定量和定性数据时的挑战。

Method: 结合两种基于线性规划的VGA模型，提出一种新的MCA方法。

Result: 通过两个数值示例验证了方法的准确性和透明度。

Conclusion: 该方法为自动决策系统和决策支持系统提供了全面且可靠的解决方案，推动了相关领域的进步。

Abstract: Modern methods for multi-criteria assessment (MCA), such as Data Envelopment
Analysis (DEA), Stochastic Frontier Analysis (SFA), and Multiple Criteria
Decision-Making (MCDM), are utilized to appraise a collection of
Decision-Making Units (DMUs), also known as alternatives, based on several
criteria. These methodologies inherently rely on assumptions and can be
influenced by subjective judgment to effectively tackle the complex evaluation
challenges in various fields. In real-world scenarios, it is essential to
incorporate both quantitative and qualitative criteria as they consist of
cardinal and ordinal data. Despite the inherent variability in the criterion
values of different alternatives, the homogeneity assumption is often employed,
significantly affecting evaluations. To tackle these challenges and determine
the most appropriate alternative, we propose a novel MCA approach that combines
two Virtual Gap Analysis (VGA) models. The VGA framework, rooted in linear
programming, is pivotal in the MCA methodology. This approach improves
efficiency and fairness, ensuring that evaluations are both comprehensive and
dependable, thus offering a strong and adaptive solution. Two comprehensive
numerical examples demonstrate the accuracy and transparency of our proposed
method. The goal is to encourage continued advancement and stimulate progress
in automated decision systems and decision support systems.

</details>


### [48] [Multi-Actor Generative Artificial Intelligence as a Game Engine](https://arxiv.org/abs/2507.08892)
*Alexander Sasha Vezhnevets,Jayd Matyas,Logan Cross,Davide Paglieri,Minsuk Chang,William A. Cunningham,Simon Osindero,William S. Isaac,Joel Z. Leibo*

Main category: cs.AI

TL;DR: 论文提出了一种基于桌游角色扮演游戏（TTRPGs）的灵活场景定义框架，用于支持生成式AI在多角色环境中的多样化应用。


<details>
  <summary>Details</summary>
Motivation: 为了满足生成式AI在模拟、叙事和评估等多样化应用中的需求，需要一种灵活的场景定义框架。

Method: 采用实体-组件架构模式，将游戏管理员（GM）设计为可配置的实体，由组件构成，实现工程师与设计师的分工协作。

Result: 通过Concordia库的实践，展示了该框架如何支持用户根据具体目标快速配置场景。

Conclusion: 该框架通过分离关注点，实现了快速迭代、模块化和可扩展性，适用于生成式AI的多样化应用。

Abstract: Generative AI can be used in multi-actor environments with purposes ranging
from social science modeling to interactive narrative and AI evaluation.
Supporting this diversity of use cases -- which we classify as Simulationist,
Dramatist, and Evaluationist -- demands a flexible scenario definition
framework. We argue here that a good approach is to take inspiration from
tabletop role-playing games (TTRPGs), where a Game Master (GM) is responsible
for the environment and generates all parts of the story not directly
determined by the voluntary actions of player characters. We argue that the
Entity-Component architectural pattern is useful here. In such a system, the GM
is not a hardcoded computer game but is itself a configurable entity, composed
of components just like any other actor. By design, the approach allows for a
separation between the underlying implementation details handled by an
engineer, the creation of reusable components, and their composition and
configuration managed by a designer who constructs entities from the
components. This separation of concerns is instrumental for achieving rapid
iteration, maintaining modularity, and ultimately to ensure scalability. We
describe the ongoing evolution of the Concordia library in terms of this
philosophy, demonstrating how it allows users to effectively configure
scenarios that align with their specific goals.

</details>


### [49] [BioAnalyst: A Foundation Model for Biodiversity](https://arxiv.org/abs/2507.09080)
*Athanasios Trantas,Martino Mensio,Stylianos Stasinos,Sebastian Gribincea,Taimur Khan,Damian Podareanu,Aliene van der Veen*

Main category: cs.AI

TL;DR: BioAnalyst是一个基于Transformer架构的AI基础模型，专为生物多样性分析和保护规划设计，通过多模态数据预训练，支持多种下游任务，如物种分布建模和栖息地评估。


<details>
  <summary>Details</summary>
Motivation: 生物多样性丧失加速，威胁生态平衡和可持续性，需综合监测和保护策略。AI基础模型在科学领域表现优异，有望推动生物多样性保护。

Method: BioAnalyst采用Transformer架构，预训练于物种记录、遥感数据等多模态数据集，可微调适应多种下游任务。

Result: 模型在数据稀缺场景下表现优于现有方法，为生态预测设定了新的准确性基准。

Conclusion: BioAnalyst的开放旨在促进生物多样性建模合作，推动AI解决生态挑战。

Abstract: The accelerating loss of biodiversity presents critical challenges for
ecological research and conservation strategies. The preservation of
biodiversity is paramount for maintaining ecological balance and ensuring the
sustainability of ecosystems. However, biodiversity faces numerous threats,
including habitat loss, climate change, and the proliferation of invasive
species. Addressing these and other ecology-related challenges, both at local
and global scales, requires comprehensive monitoring, predictive and
conservation planning capabilities. Artificial Intelligence (AI) Foundation
Models (FMs) have gained significant momentum in numerous scientific domains by
leveraging vast datasets to learn general-purpose representations adaptable to
various downstream tasks. This paradigm holds immense promise for biodiversity
conservation. In response, we introduce BioAnalyst, the first Foundation Model
tailored for biodiversity analysis and conservation planning. BioAnalyst
employs a transformer-based architecture, pre-trained on extensive multi-modal
datasets encompassing species occurrence records, remote sensing indicators,
climate and environmental variables. BioAnalyst is designed for adaptability,
allowing for fine-tuning of a range of downstream tasks, such as species
distribution modelling, habitat suitability assessments, invasive species
detection, and population trend forecasting. We evaluate the model's
performance on two downstream use cases, demonstrating its generalisability
compared to existing methods, particularly in data-scarce scenarios for two
distinct use-cases, establishing a new accuracy baseline for ecological
forecasting. By openly releasing BioAnalyst and its fine-tuning workflows to
the scientific community, we aim to foster collaborative efforts in
biodiversity modelling and advance AI-driven solutions to pressing ecological
challenges.

</details>


### [50] [Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity](https://arxiv.org/abs/2507.09089)
*Joel Becker,Nate Rush,Elizabeth Barnes,David Rein*

Main category: cs.AI

TL;DR: 研究发现，尽管开发者预期AI工具能减少任务完成时间，但实际上AI工具反而增加了19%的时间，与经济学和机器学习专家的预测相反。


<details>
  <summary>Details</summary>
Motivation: 研究AI工具对开源开发者生产力的实际影响，填补现有研究的空白。

Method: 通过随机对照试验（RCT），16位有中等AI经验的开发者完成246项任务，任务随机分配是否允许使用2025年的AI工具（如Cursor Pro和Claude 3.5/3.7 Sonnet）。

Result: 允许使用AI工具时，任务完成时间增加了19%，与开发者预期的减少20%和专家预测的减少38%-39%相反。

Conclusion: AI工具在实际应用中可能因多种因素（如项目规模、质量标准或开发者经验）导致生产力下降，而非提升。

Abstract: Despite widespread adoption, the impact of AI tools on software development
in the wild remains understudied. We conduct a randomized controlled trial
(RCT) to understand how AI tools at the February-June 2025 frontier affect the
productivity of experienced open-source developers. 16 developers with moderate
AI experience complete 246 tasks in mature projects on which they have an
average of 5 years of prior experience. Each task is randomly assigned to allow
or disallow usage of early 2025 AI tools. When AI tools are allowed, developers
primarily use Cursor Pro, a popular code editor, and Claude 3.5/3.7 Sonnet.
Before starting tasks, developers forecast that allowing AI will reduce
completion time by 24%. After completing the study, developers estimate that
allowing AI reduced completion time by 20%. Surprisingly, we find that allowing
AI actually increases completion time by 19%--AI tooling slowed developers
down. This slowdown also contradicts predictions from experts in economics (39%
shorter) and ML (38% shorter). To understand this result, we collect and
evaluate evidence for 20 properties of our setting that a priori could
contribute to the observed slowdown effect--for example, the size and quality
standards of projects, or prior developer experience with AI tooling. Although
the influence of experimental artifacts cannot be entirely ruled out, the
robustness of the slowdown effect across our analyses suggests it is unlikely
to primarily be a function of our experimental design.

</details>


### [51] [Hide-and-Shill: A Reinforcement Learning Framework for Market Manipulation Detection in Symphony-a Decentralized Multi-Agent System](https://arxiv.org/abs/2507.09179)
*Ronghua Shi,Yiou Liu,Xinyu Ying,Yang Tan,Yuchun Feng,Lynn Ai,Bill Shi,Xuhui Wang,Zhuang Liu*

Main category: cs.AI

TL;DR: 提出了一种基于多智能体强化学习（MARL）的框架，用于检测去中心化金融（DeFi）中的市场操纵行为，通过动态对抗游戏建模操纵者与检测器的交互。


<details>
  <summary>Details</summary>
Motivation: DeFi的无许可特性带来了金融创新，但也导致市场操纵行为激增，缺乏中心化监管。

Method: 采用MARL框架，结合GRPO优化学习稳定性，理论驱动的奖励函数，以及多模态智能体管道整合语义、社交图和链上数据。

Result: 在真实数据和对抗模拟中验证，Hide-and-Shill在检测准确性和因果归因方面表现优异。

Conclusion: 该研究为去中心化市场情报提供了新范式，支持实时监控和开放研究。

Abstract: Decentralized finance (DeFi) has introduced a new era of permissionless
financial innovation but also led to unprecedented market manipulation. Without
centralized oversight, malicious actors coordinate shilling campaigns and
pump-and-dump schemes across various platforms. We propose a Multi-Agent
Reinforcement Learning (MARL) framework for decentralized manipulation
detection, modeling the interaction between manipulators and detectors as a
dynamic adversarial game. This framework identifies suspicious patterns using
delayed token price reactions as financial indicators.Our method introduces
three innovations: (1) Group Relative Policy Optimization (GRPO) to enhance
learning stability in sparse-reward and partially observable settings; (2) a
theory-based reward function inspired by rational expectations and information
asymmetry, differentiating price discovery from manipulation noise; and (3) a
multi-modal agent pipeline that integrates LLM-based semantic features, social
graph signals, and on-chain market data for informed decision-making.The
framework is integrated within the Symphony system, a decentralized multi-agent
architecture enabling peer-to-peer agent execution and trust-aware learning
through distributed logs, supporting chain-verifiable evaluation. Symphony
promotes adversarial co-evolution among strategic actors and maintains robust
manipulation detection without centralized oracles, enabling real-time
surveillance across global DeFi ecosystems.Trained on 100,000 real-world
discourse episodes and validated in adversarial simulations, Hide-and-Shill
achieves top performance in detection accuracy and causal attribution. This
work bridges multi-agent systems with financial surveillance, advancing a new
paradigm for decentralized market intelligence. All resources are available at
the Hide-and-Shill GitHub repository to promote open research and
reproducibility.

</details>


### [52] [When Developer Aid Becomes Security Debt: A Systematic Analysis of Insecure Behaviors in LLM Coding Agents](https://arxiv.org/abs/2507.09329)
*Matous Kozak,Roshanak Zilouchian Moghaddam,Siva Sivaraman*

Main category: cs.AI

TL;DR: 论文对基于LLM的编码代理进行了首次系统性安全评估，发现21%的操作存在安全隐患，并提出了检测系统和缓解策略。


<details>
  <summary>Details</summary>
Motivation: 了解基于LLM的编码代理在软件开发中的安全影响，填补这一领域的研究空白。

Method: 分析了12,000多个操作，覆盖5个先进模型（如GPT-4o、GPT-4.1等）在93个实际软件任务中的表现。

Result: 21%的操作不安全，信息暴露（CWE-200）最常见；GPT-4.1的缓解成功率高达96.8%。

Conclusion: 研究为编码代理安全评估提供了框架，并强调下一代LLM编码代理需具备安全设计。

Abstract: LLM-based coding agents are rapidly being deployed in software development,
yet their security implications remain poorly understood. These agents, while
capable of accelerating software development, may inadvertently introduce
insecure practices. We conducted the first systematic security evaluation of
autonomous coding agents, analyzing over 12,000 actions across five
state-of-the-art models (GPT-4o, GPT-4.1, Claude variants) on 93 real-world
software setup tasks. Our findings reveal significant security concerns: 21% of
agent trajectories contained insecure actions, with models showing substantial
variation in security behavior. We developed a high-precision detection system
that identified four major vulnerability categories, with information exposure
(CWE-200) being the most prevalent one. We also evaluated mitigation strategies
including feedback mechanisms and security reminders with various effectiveness
between models. GPT-4.1 demonstrated exceptional security awareness with 96.8%
mitigation success. Our work provides the first comprehensive framework for
evaluating coding agent security and highlights the need for security-aware
design of next generation LLM-based coding agents.

</details>


### [53] [A Taxonomy of Omnicidal Futures Involving Artificial Intelligence](https://arxiv.org/abs/2507.09369)
*Andrew Critch,Jacob Tsimerman*

Main category: cs.AI

TL;DR: 报告提出了一种AI可能导致全人类灭绝的潜在事件分类及案例，旨在通过公开讨论支持预防措施。


<details>
  <summary>Details</summary>
Motivation: 通过公开讨论AI可能带来的灾难性风险，争取公众支持以推动预防措施。

Method: 提出分类法并列举潜在的全人类灭绝事件案例。

Result: 明确了AI可能带来的极端风险，并呼吁社会关注与预防。

Conclusion: 报告强调通过公开讨论和预防措施避免AI带来的灾难性风险。

Abstract: This report presents a taxonomy and examples of potential omnicidal events
resulting from AI: scenarios where all or almost all humans are killed. These
events are not presented as inevitable, but as possibilities that we can work
to avoid. Insofar as large institutions require a degree of public support in
order to take certain actions, we hope that by presenting these possibilities
in public, we can help to support preventive measures against catastrophic
risks from AI.

</details>


### [54] [EduFlow: Advancing MLLMs' Problem-Solving Proficiency through Multi-Stage, Multi-Perspective Critique](https://arxiv.org/abs/2507.09374)
*Chenglin Zhu,Tao Zhang,Chong Li,Mingan Lin,Zenan Zhou,Jian Xie*

Main category: cs.AI

TL;DR: EduFlow是一个端到端框架，通过EduPRM和EduMCTS提升多模态大语言模型在科学任务中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在科学任务中表现不佳，缺乏多步推理和自校正能力，EduFlow旨在解决这些问题。

Method: 结合EduPRM（过程感知奖励模型）和EduMCTS（领域适应搜索框架），通过课程学习和自反射机制优化推理轨迹。

Result: 实验表明EduFlow显著提升了推理的一致性和连贯性。

Conclusion: EduFlow为科学推理任务提供了可靠解决方案，未来将公开代码和数据。

Abstract: Multimodal large language models (MLLMs) still perform poorly on scientific
tasks, particularly those requiring multi-step and interpretable reasoning.
Their limitations include insufficient scientific reasoning patterns, lack of
global coherence in multi-step inference, and the absence of reflective
self-correction, making them unreliable in structured scientific contexts. We
introduce EduFlow, the first end-to-end framework that covers the full pipeline
of educational scientific reasoning, including data selection, MCTS-based
trajectory construction, model training, and output optimization. At its core
is EduPRM, a process-aware reward model that critiques reasoning steps with
tags and justifications. EduPRM is trained via curriculum learning on three
complementary supervision sources: MCTS-guided trajectories, error-injected
critiques, and teacher-student dialogues, enabling dynamic adaptation to
multi-stage problem solving and iterative refinement during inference. We
further propose EduMCTS, a domain-adapted search framework that introduces
bootstrapping actions specifically designed for educational reasoning, such as
a self-reflection mechanism that promotes reflective error correction. It
further leverages EduPRM's fine-grained feedback to guide the search toward
higher-quality reasoning trajectories. By applying self-consistency and
rejection sampling, we constructed EduMCTS-160K, a large-scale dataset of
educational reasoning trajectories. Extensive experiments demonstrate that
EduFlow enhances reasoning consistency and coherence. Code, data, and models
will be released.

</details>


### [55] [Knowledge Conceptualization Impacts RAG Efficacy](https://arxiv.org/abs/2507.09389)
*Chris Davis Jaldi,Anmol Saini,Elham Ghiasi,O. Divine Eziolise,Cogan Shimizu*

Main category: cs.AI

TL;DR: 论文探讨了可解释性和适应性在AI系统中的重要性，尤其是针对神经符号AI系统的设计与评估。


<details>
  <summary>Details</summary>
Motivation: 研究如何结合可解释性和适应性，设计可迁移且可解释的神经符号AI系统，特别是在Agentic Retrieval-Augmented Generation系统中。

Method: 系统评估不同知识表示和结构对LLM查询三元组存储的影响。

Result: 结果显示知识表示和结构对AI代理的查询效果有显著影响。

Conclusion: 研究强调了知识表示和结构在AI系统中的重要性，并讨论了其影响和潜在应用。

Abstract: Explainability and interpretability are cornerstones of frontier and
next-generation artificial intelligence (AI) systems. This is especially true
in recent systems, such as large language models (LLMs), and more broadly,
generative AI. On the other hand, adaptability to new domains, contexts, or
scenarios is also an important aspect for a successful system. As such, we are
particularly interested in how we can merge these two efforts, that is,
investigating the design of transferable and interpretable neurosymbolic AI
systems. Specifically, we focus on a class of systems referred to as ''Agentic
Retrieval-Augmented Generation'' systems, which actively select, interpret, and
query knowledge sources in response to natural language prompts. In this paper,
we systematically evaluate how different conceptualizations and representations
of knowledge, particularly the structure and complexity, impact an AI agent (in
this case, an LLM) in effectively querying a triplestore. We report our
results, which show that there are impacts from both approaches, and we discuss
their impact and implications.

</details>


### [56] [LLM-Stackelberg Games: Conjectural Reasoning Equilibria and Their Applications to Spearphishing](https://arxiv.org/abs/2507.09407)
*Quanyan Zhu*

Main category: cs.AI

TL;DR: 论文提出LLM-Stackelberg博弈框架，将大语言模型（LLMs）融入领导者与追随者的战略互动中，突破传统完全信息与理性假设，引入基于提示的推理与行为均衡。


<details>
  <summary>Details</summary>
Motivation: 传统Stackelberg博弈假设完全信息与理性行为，而现实决策中存在信息不对称与有限理性。本文旨在通过LLMs模拟更真实的战略互动。

Method: 定义两种均衡概念：推理与行为均衡（内部推理与行为一致）、推测推理均衡（考虑对手响应的认知不确定性）。通过结构化提示实现策略生成与适应。

Result: 以钓鱼攻击为例，展示LLM-Stackelberg博弈的认知丰富性与对抗潜力，验证其在网络安全等领域的建模能力。

Conclusion: LLM-Stackelberg博弈为网络安全、错误信息等领域提供了一种强大的决策建模范式。

Abstract: We introduce the framework of LLM-Stackelberg games, a class of sequential
decision-making models that integrate large language models (LLMs) into
strategic interactions between a leader and a follower. Departing from
classical Stackelberg assumptions of complete information and rational agents,
our formulation allows each agent to reason through structured prompts,
generate probabilistic behaviors via LLMs, and adapt their strategies through
internal cognition and belief updates. We define two equilibrium concepts:
reasoning and behavioral equilibrium, which aligns an agent's internal
prompt-based reasoning with observable behavior, and conjectural reasoning
equilibrium, which accounts for epistemic uncertainty through parameterized
models over an opponent's response. These layered constructs capture bounded
rationality, asymmetric information, and meta-cognitive adaptation. We
illustrate the framework through a spearphishing case study, where a sender and
a recipient engage in a deception game using structured reasoning prompts. This
example highlights the cognitive richness and adversarial potential of
LLM-mediated interactions. Our results show that LLM-Stackelberg games provide
a powerful paradigm for modeling decision-making in domains such as
cybersecurity, misinformation, and recommendation systems.

</details>


### [57] [GenAI-based Multi-Agent Reinforcement Learning towards Distributed Agent Intelligence: A Generative-RL Agent Perspective](https://arxiv.org/abs/2507.09495)
*Hang Wang,Junshan Zhang*

Main category: cs.AI

TL;DR: 论文提出从反应式到主动式多智能体强化学习的范式转变，利用生成式AI实现智能体的前瞻性决策和协同行为。


<details>
  <summary>Details</summary>
Motivation: 传统方法在多智能体强化学习中面临联合动作空间指数增长、环境非平稳性和部分可观测性等挑战，无法应对新场景。

Method: 通过生成式AI重构智能体，使其能建模环境演化、预测其他智能体行为并生成协同动作序列，实现主动决策。

Result: 生成式强化学习智能体能够进行前瞻性决策、增强协同通信并动态适应环境变化。

Conclusion: 该范式转变有望解决传统反应式框架无法处理的协同挑战，推动分布式智能和集体协作行为的发展。

Abstract: Multi-agent reinforcement learning faces fundamental challenges that
conventional approaches have failed to overcome: exponentially growing joint
action spaces, non-stationary environments where simultaneous learning creates
moving targets, and partial observability that constrains coordination. Current
methods remain reactive, employing stimulus-response mechanisms that fail when
facing novel scenarios. We argue for a transformative paradigm shift from
reactive to proactive multi-agent intelligence through generative AI-based
reinforcement learning. This position advocates reconceptualizing agents not as
isolated policy optimizers, but as sophisticated generative models capable of
synthesizing complex multi-agent dynamics and making anticipatory decisions
based on predictive understanding of future interactions. Rather than
responding to immediate observations, generative-RL agents can model
environment evolution, predict other agents' behaviors, generate coordinated
action sequences, and engage in strategic reasoning accounting for long-term
dynamics. This approach leverages pattern recognition and generation
capabilities of generative AI to enable proactive decision-making, seamless
coordination through enhanced communication, and dynamic adaptation to evolving
scenarios. We envision this paradigm shift will unlock unprecedented
possibilities for distributed intelligence, moving beyond individual
optimization toward emergent collective behaviors representing genuine
collaborative intelligence. The implications extend across autonomous systems,
robotics, and human-AI collaboration, promising solutions to coordination
challenges intractable under traditional reactive frameworks.

</details>


### [58] [Consistency Trajectory Planning: High-Quality and Efficient Trajectory Optimization for Offline Model-Based Reinforcement Learning](https://arxiv.org/abs/2507.09534)
*Guanquan Wang,Takuya Hiraoka,Yoshimasa Tsuruoka*

Main category: cs.AI

TL;DR: 本文提出了一种基于一致性轨迹模型（CTM）的离线强化学习方法CTP，通过单步轨迹生成实现高效优化，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的规划方法计算成本高，CTP旨在解决这一问题，同时保持策略质量。

Method: CTP利用CTM进行单步轨迹生成，避免了迭代采样，从而提高了效率。

Result: 在D4RL基准测试中，CTP在长时域任务中表现优于现有方法，且推理速度提升了120倍。

Conclusion: CTP是一种高效、低延迟的离线规划方法，适用于高性能任务。

Abstract: This paper introduces Consistency Trajectory Planning (CTP), a novel offline
model-based reinforcement learning method that leverages the recently proposed
Consistency Trajectory Model (CTM) for efficient trajectory optimization. While
prior work applying diffusion models to planning has demonstrated strong
performance, it often suffers from high computational costs due to iterative
sampling procedures. CTP supports fast, single-step trajectory generation
without significant degradation in policy quality. We evaluate CTP on the D4RL
benchmark and show that it consistently outperforms existing diffusion-based
planning methods in long-horizon, goal-conditioned tasks. Notably, CTP achieves
higher normalized returns while using significantly fewer denoising steps. In
particular, CTP achieves comparable performance with over $120\times$ speedup
in inference time, demonstrating its practicality and effectiveness for
high-performance, low-latency offline planning.

</details>


### [59] [Learning to Control Dynamical Agents via Spiking Neural Networks and Metropolis-Hastings Sampling](https://arxiv.org/abs/2507.09540)
*Ali Safa,Farida Mohsen,Ali Al-Zawqari*

Main category: cs.AI

TL;DR: 本文提出了一种基于Metropolis-Hastings采样的框架，用于训练脉冲神经网络（SNNs）在强化学习任务中，避免了梯度方法的局限性，并在两个控制基准测试中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络（SNNs）因其生物启发和高效能特性成为传统深度神经网络的替代方案，但其训练在强化学习任务中面临挑战，主要由于脉冲通信的不可微分性。

Method: 采用Metropolis-Hastings（MH）采样，一种贝叶斯推断技术，通过迭代提出并概率性接受网络参数更新，基于累积奖励信号，绕过反向传播的限制。

Result: 在AcroBot和CartPole两个基准测试中，该方法在最大化累积奖励、减少网络资源和训练周期方面优于传统深度Q学习和现有SNN方法。

Conclusion: MH采样框架为SNNs在强化学习中的训练提供了一种有效且高效的替代方案，尤其适用于神经形态平台。

Abstract: Spiking Neural Networks (SNNs) offer biologically inspired, energy-efficient
alternatives to traditional Deep Neural Networks (DNNs) for real-time control
systems. However, their training presents several challenges, particularly for
reinforcement learning (RL) tasks, due to the non-differentiable nature of
spike-based communication. In this work, we introduce what is, to our
knowledge, the first framework that employs Metropolis-Hastings (MH) sampling,
a Bayesian inference technique, to train SNNs for dynamical agent control in RL
environments without relying on gradient-based methods. Our approach
iteratively proposes and probabilistically accepts network parameter updates
based on accumulated reward signals, effectively circumventing the limitations
of backpropagation while enabling direct optimization on neuromorphic
platforms. We evaluated this framework on two standard control benchmarks:
AcroBot and CartPole. The results demonstrate that our MH-based approach
outperforms conventional Deep Q-Learning (DQL) baselines and prior SNN-based RL
approaches in terms of maximizing the accumulated reward while minimizing
network resources and training episodes.

</details>


### [60] [eSapiens: A Platform for Secure and Auditable Retrieval-Augmented Generation](https://arxiv.org/abs/2507.09588)
*Isaac Shi,Zeyuan Li,Fan Liu,Wenli Wang,Lewei He,Yang Yang,Tianyu Shi*

Main category: cs.AI

TL;DR: eSapiens是一个AIaaS平台，专注于企业数据、工作流程和LLM的无缝集成，提供数据安全和知识保留，同时通过AI代理提升团队效率。


<details>
  <summary>Details</summary>
Motivation: 解决企业在AI应用中面临的数据安全、知识保留和高效工作流程的需求。

Method: 结合结构化文档处理、混合向量检索和无代码编排，支持多种主流LLM，并通过THOR代理处理结构化查询。

Result: 实验显示，512令牌的块大小在检索精度上表现最佳（Top-3准确率91.3%），生成质量测试中eSapiens在事实一致性上提升23%。

Conclusion: eSapiens在高风险领域（如法律和金融）中实现了可信、可审计的AI工作流程。

Abstract: We present eSapiens, an AI-as-a-Service (AIaaS) platform engineered around a
business-oriented trifecta: proprietary data, operational workflows, and any
major agnostic Large Language Model (LLM). eSapiens gives businesses full
control over their AI assets, keeping everything in-house for AI knowledge
retention and data security. eSapiens AI Agents (Sapiens) empower your team by
providing valuable insights and automating repetitive tasks, enabling them to
focus on high-impact work and drive better business outcomes.
  The system integrates structured document ingestion, hybrid vector retrieval,
and no-code orchestration via LangChain, and supports top LLMs including
OpenAI, Claude, Gemini, and DeepSeek. A key component is the THOR Agent, which
handles structured SQL-style queries and generates actionable insights over
enterprise databases.
  To evaluate the system, we conduct two experiments. First, a retrieval
benchmark on legal corpora reveals that a chunk size of 512 tokens yields the
highest retrieval precision (Top-3 accuracy: 91.3%). Second, a generation
quality test using TRACe metrics across five LLMs shows that eSapiens delivers
more context-consistent outputs with up to a 23% improvement in factual
alignment.
  These results demonstrate the effectiveness of eSapiens in enabling
trustworthy, auditable AI workflows for high-stakes domains like legal and
finance.

</details>


### [61] [The Hidden Costs of AI: A Review of Energy, E-Waste, and Inequality in Model Development](https://arxiv.org/abs/2507.09611)
*Jenis Winsta*

Main category: cs.AI

TL;DR: 本文探讨了AI快速发展中常被忽视的环境和伦理挑战，包括能源消耗、电子废物、计算资源不平等和网络安全系统的隐藏能源负担。


<details>
  <summary>Details</summary>
Motivation: AI的快速扩展带来了环境和伦理问题，这些问题尚未得到充分关注，需要系统性研究和解决。

Method: 通过综述近期研究和机构报告，分析了AI在能源消耗、电子废物、计算资源不平等和网络安全能源负担等方面的影响。

Result: 揭示了模型训练的高排放、硬件快速更新、全球基础设施不平等以及AI安全能源需求等系统性问题。

Conclusion: AI的发展需与伦理责任和环境保护相结合，推动可持续、透明和公平的技术未来。

Abstract: Artificial intelligence (AI) has made remarkable progress in recent years,
yet its rapid expansion brings overlooked environmental and ethical challenges.
This review explores four critical areas where AI's impact extends beyond
performance: energy consumption, electronic waste (e-waste), inequality in
compute access, and the hidden energy burden of cybersecurity systems. Drawing
from recent studies and institutional reports, the paper highlights systemic
issues such as high emissions from model training, rising hardware turnover,
global infrastructure disparities, and the energy demands of securing AI. By
connecting these concerns, the review contributes to Responsible AI discourse
by identifying key research gaps and advocating for sustainable, transparent,
and equitable development practices. Ultimately, it argues that AI's progress
must align with ethical responsibility and environmental stewardship to ensure
a more inclusive and sustainable technological future.

</details>


### [62] [Bridging Bots: from Perception to Action via Multimodal-LMs and Knowledge Graphs](https://arxiv.org/abs/2507.09617)
*Margherita Martorana,Francesca Urgese,Mark Adamik,Ilaria Tiddi*

Main category: cs.AI

TL;DR: 本文提出了一种神经符号框架，结合多模态语言模型的感知能力与知识图谱的结构化表示，以支持机器人应用的互操作性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人系统依赖专有、硬编码的解决方案，难以适应和扩展，而知识图谱和多模态语言模型各有局限性，需要结合两者优势。

Method: 提出神经符号框架，整合机器人感知数据、本体和多模态模型（LLaMA和GPT），评估不同神经符号交互模式。

Result: GPT-o1和LLaMA 4 Maverick表现最佳，但新模型不一定更好，整合策略对生成符合本体的知识图谱至关重要。

Conclusion: 神经符号框架有效支持机器人互操作性，但模型选择和整合策略是关键。

Abstract: Personal service robots are deployed to support daily living in domestic
environments, particularly for elderly and individuals requiring assistance.
These robots must perceive complex and dynamic surroundings, understand tasks,
and execute context-appropriate actions. However, current systems rely on
proprietary, hard-coded solutions tied to specific hardware and software,
resulting in siloed implementations that are difficult to adapt and scale
across platforms. Ontologies and Knowledge Graphs (KGs) offer a solution to
enable interoperability across systems, through structured and standardized
representations of knowledge and reasoning. However, symbolic systems such as
KGs and ontologies struggle with raw and noisy sensory input. In contrast,
multimodal language models are well suited for interpreting input such as
images and natural language, but often lack transparency, consistency, and
knowledge grounding. In this work, we propose a neurosymbolic framework that
combines the perceptual strengths of multimodal language models with the
structured representations provided by KGs and ontologies, with the aim of
supporting interoperability in robotic applications. Our approach generates
ontology-compliant KGs that can inform robot behavior in a platform-independent
manner. We evaluated this framework by integrating robot perception data,
ontologies, and five multimodal models (three LLaMA and two GPT models), using
different modes of neural-symbolic interaction. We assess the consistency and
effectiveness of the generated KGs across multiple runs and configurations, and
perform statistical analyzes to evaluate performance. Results show that GPT-o1
and LLaMA 4 Maverick consistently outperform other models. However, our
findings also indicate that newer models do not guarantee better results,
highlighting the critical role of the integration strategy in generating
ontology-compliant KGs.

</details>


### [63] [humancompatible.interconnect: Testing Properties of Repeated Uses of Interconnections of AI Systems](https://arxiv.org/abs/2507.09626)
*Rodion Nazarov,Anthony Quinn,Robert Shorten,Jakub Marecek*

Main category: cs.AI

TL;DR: 介绍了一个基于PyTorch的工具包，用于通过随机控制技术建模多代理AI系统的交互，并提供公平性和鲁棒性的先验保证。


<details>
  <summary>Details</summary>
Motivation: 多代理AI系统需要满足公平性和鲁棒性的先验保证，但现有方法复杂且难以实现。

Method: 开发了一个基于PyTorch的工具包，采用闭环建模方法，结合随机控制技术，简化了公平性和鲁棒性的分析。

Result: 工具包成功提供了多代理系统闭环模型的公平性和鲁棒性先验保证，并降低了实现的复杂性。

Conclusion: 该工具包为多代理AI系统的公平性和鲁棒性分析提供了高效且易用的解决方案。

Abstract: Artificial intelligence (AI) systems often interact with multiple agents. The
regulation of such AI systems often requires that {\em a priori\/} guarantees
of fairness and robustness be satisfied. With stochastic models of agents'
responses to the outputs of AI systems, such {\em a priori\/} guarantees
require non-trivial reasoning about the corresponding stochastic systems. Here,
we present an open-source PyTorch-based toolkit for the use of stochastic
control techniques in modelling interconnections of AI systems and properties
of their repeated uses. It models robustness and fairness desiderata in a
closed-loop fashion, and provides {\em a priori\/} guarantees for these
interconnections. The PyTorch-based toolkit removes much of the complexity
associated with the provision of fairness guarantees for closed-loop models of
multi-agent systems.

</details>


### [64] [Towards Concise and Adaptive Thinking in Large Reasoning Models: A Survey](https://arxiv.org/abs/2507.09662)
*Jason Zhu,Hongyu Li*

Main category: cs.AI

TL;DR: 大型推理模型（LRMs）在复杂任务上表现优异，但存在推理链过长的问题，导致资源浪费和响应延迟。本文综述了简洁和自适应推理的最新进展。


<details>
  <summary>Details</summary>
Motivation: 解决LRMs在简单问题上生成冗余推理链的问题，以提高效率和实用性。

Method: 综述了简洁和自适应推理的方法论、基准和挑战。

Result: 提供了该领域的全面概述，帮助研究者快速了解现状。

Conclusion: 希望激发新的自适应推理思路，优化LRMs的使用。

Abstract: Large reasoning models (LRMs) like OpenAI o1 and DeepSeek R1 have
demonstrated impressive performance on complex reasoning tasks like mathematics
and programming with long Chain-of-Thought (CoT) reasoning sequences
(slow-thinking), compared with traditional large language models
(fast-thinking). However, these reasoning models also face a huge challenge
that generating unnecessarily lengthy and redundant reasoning chains even for
trivial questions. This phenomenon leads to a significant waste of inference
resources, increases the response time for simple queries, and hinders the
practical application of LRMs in real-world products. To this end, it is
crucial to shorten lengthy reasoning chains and learn adaptive reasoning
between fast and slow thinking based on input difficulty. In this survey, we
provide a comprehensive overview of recent progress in concise and adaptive
thinking for efficient reasoning of LRMs, including methodologies, benchmarks,
and challenges for future exploration. We hope this survey can help researchers
quickly understand the landscape of this field and inspire novel adaptive
thinking ideas to facilitate better usage of LRMs.

</details>


### [65] [Causality-informed Anomaly Detection in Partially Observable Sensor Networks: Moving beyond Correlations](https://arxiv.org/abs/2507.09742)
*Xiaofeng Xiao,Bo Shen,Xubo Yue*

Main category: cs.AI

TL;DR: 提出了一种基于因果关系的深度Q网络（Causal DQ）方法，用于部分可观测的传感器布局优化，以快速检测异常。


<details>
  <summary>Details</summary>
Motivation: AI驱动的制造业数据流实时监测需求增长，但资源有限，需优化传感器布局以快速检测异常。现有方法多忽略因果关系，少数依赖干预方法不实用。

Method: 通过将因果信息整合到Q网络训练的每个阶段，提出Causal DQ方法，实现更快收敛和更紧的理论误差界限。

Result: Causal DQ显著减少了异常检测时间，适用于大规模实时数据流。

Conclusion: 该方法不仅适用于传感器布局，还可推广到其他强化学习问题，为工程应用中的因果机器学习开辟新可能。

Abstract: Nowadays, as AI-driven manufacturing becomes increasingly popular, the volume
of data streams requiring real-time monitoring continues to grow. However, due
to limited resources, it is impractical to place sensors at every location to
detect unexpected shifts. Therefore, it is necessary to develop an optimal
sensor placement strategy that enables partial observability of the system
while detecting anomalies as quickly as possible. Numerous approaches have been
proposed to address this challenge; however, most existing methods consider
only variable correlations and neglect a crucial factor: Causality. Moreover,
although a few techniques incorporate causal analysis, they rely on
interventions-artificially creating anomalies-to identify causal effects, which
is impractical and might lead to catastrophic losses. In this paper, we
introduce a causality-informed deep Q-network (Causal DQ) approach for
partially observable sensor placement in anomaly detection. By integrating
causal information at each stage of Q-network training, our method achieves
faster convergence and tighter theoretical error bounds. Furthermore, the
trained causal-informed Q-network significantly reduces the detection time for
anomalies under various settings, demonstrating its effectiveness for sensor
placement in large-scale, real-world data streams. Beyond the current
implementation, our technique's fundamental insights can be applied to various
reinforcement learning problems, opening up new possibilities for real-world
causality-informed machine learning methods in engineering applications.

</details>


### [66] [Sound and Complete Neuro-symbolic Reasoning with LLM-Grounded Interpretations](https://arxiv.org/abs/2507.09751)
*Bradley P. Allen,Prateek Chhikara,Thomas Macaulay Ferguson,Filip Ilievski,Paul Groth*

Main category: cs.AI

TL;DR: 提出一种将大语言模型（LLM）与超一致逻辑结合的方法，以解决LLM输出逻辑不一致的问题，同时保留逻辑的完备性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在自然语言理解和生成方面表现出色，但其输出存在逻辑不一致问题，需要一种方法在形式推理中利用其广泛知识。

Method: 将LLM直接集成到超一致逻辑的形式语义解释函数中，并通过短形式事实性基准数据集评估其可行性。

Result: 实验证明该方法可行，且不同于以往工作，提供了理论框架以结合LLM知识与逻辑的完备性。

Conclusion: 该方法为神经符号推理提供了新思路，既能利用LLM知识，又能保持逻辑的完备性和一致性。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities in
natural language understanding and generation, but they exhibit problems with
logical consistency in the output they generate. How can we harness LLMs'
broad-coverage parametric knowledge in formal reasoning despite their
inconsistency? We present a method for directly integrating an LLM into the
interpretation function of the formal semantics for a paraconsistent logic. We
provide experimental evidence for the feasibility of the method by evaluating
the function using datasets created from several short-form factuality
benchmarks. Unlike prior work, our method offers a theoretical framework for
neuro-symbolic reasoning that leverages an LLM's knowledge while preserving the
underlying logic's soundness and completeness properties.

</details>


### [67] [Technical Requirements for Halting Dangerous AI Activities](https://arxiv.org/abs/2507.09801)
*Peter Barnett,Aaron Scher,David Abecassis*

Main category: cs.AI

TL;DR: 论文提出通过技术干预实现危险AI活动的协调暂停，以应对AI快速发展带来的风险。


<details>
  <summary>Details</summary>
Motivation: AI快速发展带来失控、滥用、地缘政治不稳定和权力集中等风险，需避免最坏结果。

Method: 提出关键技术干预措施，支持危险AI活动的协调暂停。

Result: 这些干预措施可限制危险AI活动，并为AI治理计划提供技术基础。

Conclusion: 技术干预是实现AI治理和风险控制的重要工具。

Abstract: The rapid development of AI systems poses unprecedented risks, including loss
of control, misuse, geopolitical instability, and concentration of power. To
navigate these risks and avoid worst-case outcomes, governments may proactively
establish the capability for a coordinated halt on dangerous AI development and
deployment. In this paper, we outline key technical interventions that could
allow for a coordinated halt on dangerous AI activities. We discuss how these
interventions may contribute to restricting various dangerous AI activities,
and show how these interventions can form the technical foundation for
potential AI governance plans.

</details>


### [68] [Is Human-Written Data Enough? The Challenge of Teaching Reasoning to LLMs Without RL or Distillation](https://arxiv.org/abs/2507.09850)
*Wei Du,Branislav Kisacanin,George Armstrong,Shubham Toshniwal,Ivan Moshkov,Alexan Ayrapetyan,Sadegh Mahdavi,Dan Zhao,Shizhe Diao,Dragan Masulovic,Marius Stanean,Advaith Avadhanam,Max Wang,Ashmit Dutta,Shitij Govil,Sri Yanamandara,Mihir Tandon,Sriram Ananthakrishnan,Vedant Rathi,David Zhang,Joonseok Kang,Leon Luo,Titu Andreescu,Boris Ginsburg,Igor Gitman*

Main category: cs.AI

TL;DR: 通过少量高质量的长链思维（CoT）示例微调基础模型，可以显著提升其推理能力，甚至超越更大规模的模型。


<details>
  <summary>Details</summary>
Motivation: 探索是否仅通过提示或最小化微调，就能在基础模型中诱导出长链思维推理能力。

Method: 使用20个来自推理模型的长链思维示例微调基础模型，并尝试其他来源的CoT数据（如非推理模型和人工标注）。

Result: 微调后的模型表现优于更大规模的模型，但其他来源的CoT数据效果不及推理模型生成的示例。

Conclusion: 高质量的少量示例可以激活基础模型的推理能力，但专家级CoT的某些特性难以复制。

Abstract: Reasoning-capable language models achieve state-of-the-art performance in
diverse complex tasks by generating long, explicit Chain-of-Thought (CoT)
traces. While recent works show that base models can acquire such reasoning
traces via reinforcement learning or distillation from stronger models like
DeepSeek-R1, previous works demonstrate that even short CoT prompting without
fine-tuning is able to improve reasoning. We ask whether long CoT can be
induced in a base model using only prompting or minimal tuning. Using just 20
long CoT examples from the reasoning model \texttt{QwQ-32B-Preview}, we lightly
fine-tune the base model \texttt{Qwen2.5-32B}. The resulting model outperforms
the much larger \texttt{Qwen2.5-Math-72B-Instruct}, showing that a handful of
high-quality examples can unlock strong reasoning capabilities. We further
explore using CoT data from non-reasoning models and human annotators, enhanced
with prompt engineering, multi-pass editing, and structural guidance. However,
neither matches the performance of reasoning model traces, suggesting that
certain latent qualities of expert CoT are difficult to replicate. We analyze
key properties of reasoning data, such as problem difficulty, diversity, and
answer length, that influence reasoning distillation. While challenges remain,
we are optimistic that carefully curated human-written CoT, even in small
quantities, can activate reasoning behaviors in base models. We release our
human-authored dataset across refinement stages and invite further
investigation into what makes small-scale reasoning supervision so effective.

</details>


### [69] [Model-Grounded Symbolic Artificial Intelligence Systems Learning and Reasoning with Model-Grounded Symbolic Artificial Intelligence Systems](https://arxiv.org/abs/2507.09854)
*Aniruddha Chattopadhyay,Raj Dandekar,Kaushik Roy*

Main category: cs.AI

TL;DR: 该论文提出将指令调优的大型语言模型重新解释为基于模型的符号AI系统，利用自然语言作为符号层，并通过模型的内部表示空间实现接地。


<details>
  <summary>Details</summary>
Motivation: 结合神经网络的泛化学习能力和符号AI的可验证推理能力，探索新型学习与推理方法。

Method: 通过自然语言作为符号层，利用模型的内部表示空间实现接地，并开发与传统学习与推理范式结构相似的新方法。

Result: 初步评估表明，该方法在提高学习效率和推理可靠性方面具有潜力。

Conclusion: 该框架为神经符号AI系统提供了一种新的实现方式，展示了其在复杂推理任务中的应用前景。

Abstract: Neurosymbolic artificial intelligence (AI) systems combine neural network and
classical symbolic AI mechanisms to exploit the complementary strengths of
large scale, generalizable learning and robust, verifiable reasoning. Numerous
classifications of neurosymbolic AI illustrate how these two components can be
integrated in distinctly different ways. In this work, we propose
reinterpreting instruction tuned large language models as model grounded
symbolic AI systems where natural language serves as the symbolic layer and
grounding is achieved through the models internal representation space. Within
this framework, we investigate and develop novel learning and reasoning
approaches that preserve structural similarities to traditional learning and
reasoning paradigms. Preliminary evaluations across axiomatic deductive
reasoning procedures of varying complexity provide insights into the
effectiveness of our approach in improving learning efficiency and reasoning
reliability.

</details>


### [70] [VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains](https://arxiv.org/abs/2507.09884)
*Xuzhao Li,Xuchen Li,Shiyu Hu,Yongzhen Guo,Wentao Zhang*

Main category: cs.AI

TL;DR: 论文提出了VerifyBench，一个跨领域的综合基准，用于系统评估验证器的性能，揭示了专用验证器和通用LLM在精度与召回率之间的权衡及其跨领域泛化的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前验证器在复杂、多样化的模型生成响应中表现不一致，缺乏系统评估，限制了RLVR的可靠发展。

Method: 构建包含4,000个专家级问题的跨领域数据集，设计四维实验框架，比较专用验证器和通用LLM在不同条件下的表现。

Result: 专用验证器精度高但召回率低，通用模型包容性强但精度不稳定；验证器对输入结构敏感且跨领域泛化能力有限。

Conclusion: 研究揭示了当前验证器技术的瓶颈，为未来改进提供了关键见解。

Abstract: Large language models (LLMs) increasingly rely on reinforcement learning (RL)
to enhance their reasoning capabilities through feedback. A critical challenge
is verifying the consistency of model-generated responses and reference
answers, since these responses are often lengthy, diverse, and nuanced.
Rule-based verifiers struggle with complexity, prompting the use of model-based
verifiers. However, specialized verifiers lack flexibility, while general LLM
judges can be inconsistent. Existing research primarily focuses on building
better verifiers, yet a systematic evaluation of different types of verifiers'
performance across domains remains lacking, severely constraining the reliable
development of Reinforcement Learning with Verifiable Reward (RLVR). To address
this, we propose VerifyBench--a cross-domain comprehensive benchmark for
systematically evaluating verifiers. We construct 4,000 expert-level questions
covering mathematics, physics, chemistry, and biology. Each question is
equipped with reference answers and diverse responses. The reliability of the
evaluation is ensured through a rigorous annotation process conducted by a
multidisciplinary expert team. We design a four-dimensional experimental
framework to comprehensively compare the performance boundaries of specialized
verifiers and general LLMs under combined conditions of extracted answers vs.
complete responses, and short vs. long outputs. Our evaluation uncovers
fundamental trade-offs in verifiers: while specialized verifiers achieve
leading accuracy, they exhibit deficiencies in recall; general models show
stronger inclusivity but unstable precision. More importantly, we discover
verifiers' high sensitivity to input structure and inherent limitations in
cross-domain generalization, providing critical insights into the bottlenecks
of current verifier technology.

</details>


### [71] [DeepSeek: Paradigm Shifts and Technical Evolution in Large AI Models](https://arxiv.org/abs/2507.09955)
*Luolin Xiong,Haofen Wang,Xi Chen,Lu Sheng,Yun Xiong,Jingping Liu,Yanghua Xiao,Huajun Chen,Qing-Long Han,Yang Tang*

Main category: cs.AI

TL;DR: DeepSeek发布V3和R1系列模型，以低成本、高性能和开源优势吸引全球关注。论文回顾了大模型演进，介绍了DeepSeek的创新算法（MLA、MoE、MTP、GRPO）及工程突破，并分析了其对AI竞争格局的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨DeepSeek模型的技术创新及其对大型AI模型发展的影响，为未来趋势提供见解。

Method: 回顾大模型演进，分析DeepSeek的创新算法（MLA、MoE、MTP、GRPO）及工程优化架构，并与主流LLM对比。

Result: DeepSeek模型在性能、成本和开源方面表现优异，对AI竞争格局产生显著影响。

Conclusion: DeepSeek的创新为大型AI模型发展提供了新方向，未来需关注数据、训练和推理技术的进步。

Abstract: DeepSeek, a Chinese Artificial Intelligence (AI) startup, has released their
V3 and R1 series models, which attracted global attention due to their low
cost, high performance, and open-source advantages. This paper begins by
reviewing the evolution of large AI models focusing on paradigm shifts, the
mainstream Large Language Model (LLM) paradigm, and the DeepSeek paradigm.
Subsequently, the paper highlights novel algorithms introduced by DeepSeek,
including Multi-head Latent Attention (MLA), Mixture-of-Experts (MoE),
Multi-Token Prediction (MTP), and Group Relative Policy Optimization (GRPO).
The paper then explores DeepSeek engineering breakthroughs in LLM scaling,
training, inference, and system-level optimization architecture. Moreover, the
impact of DeepSeek models on the competitive AI landscape is analyzed,
comparing them to mainstream LLMs across various fields. Finally, the paper
reflects on the insights gained from DeepSeek innovations and discusses future
trends in the technical and engineering development of large AI models,
particularly in data, training, and reasoning.

</details>


### [72] [Improving monotonic optimization in heterogeneous multi-agent reinforcement learning with optimal marginal deterministic policy gradient](https://arxiv.org/abs/2507.09989)
*Xiaoyang Yu,Youfang Lin,Shuo Wang,Sheng Han*

Main category: cs.AI

TL;DR: OMDPG算法通过引入最优边际Q函数和广义Q批评器，解决了异构多智能体强化学习中单调改进与部分参数共享的冲突，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 异构多智能体强化学习中，单调改进与部分参数共享（ParPS）之间存在冲突，直接结合会导致策略更新基线漂移问题。

Method: 提出OMDPG算法，使用最优边际Q函数替代顺序计算的Q函数，引入广义Q批评器，并采用集中式批评器分组执行器架构。

Result: 在SMAC和MAMuJoCo环境中，OMDPG优于多种先进的多智能体强化学习基线方法。

Conclusion: OMDPG成功解决了单调改进与ParPS的冲突，同时实现了高性能的合作表现。

Abstract: In heterogeneous multi-agent reinforcement learning (MARL), achieving
monotonic improvement plays a pivotal role in enhancing performance. The HAPPO
algorithm proposes a feasible solution by introducing a sequential update
scheme, which requires independent learning with No Parameter-sharing (NoPS).
However, heterogeneous MARL generally requires Partial Parameter-sharing
(ParPS) based on agent grouping to achieve high cooperative performance. Our
experiments prove that directly combining ParPS with the sequential update
scheme leads to the policy updating baseline drift problem, thereby failing to
achieve improvement. To solve the conflict between monotonic improvement and
ParPS, we propose the Optimal Marginal Deterministic Policy Gradient (OMDPG)
algorithm. First, we replace the sequentially computed $Q_{\psi}^s(s,a_{1:i})$
with the Optimal Marginal Q (OMQ) function $\phi_{\psi}^*(s,a_{1:i})$ derived
from Q-functions. This maintains MAAD's monotonic improvement while eliminating
the conflict through optimal joint action sequences instead of sequential
policy ratio calculations. Second, we introduce the Generalized Q Critic (GQC)
as the critic function, employing pessimistic uncertainty-constrained loss to
optimize different Q-value estimations. This provides the required Q-values for
OMQ computation and stable baselines for actor updates. Finally, we implement a
Centralized Critic Grouped Actor (CCGA) architecture that simultaneously
achieves ParPS in local policy networks and accurate global Q-function
computation. Experimental results in SMAC and MAMuJoCo environments demonstrate
that OMDPG outperforms various state-of-the-art MARL baselines.

</details>


### [73] [On The Role of Intentionality in Knowledge Representation: Analyzing Scene Context for Cognitive Agents with a Tiny Language Model](https://arxiv.org/abs/2507.10000)
*Mark Burgess*

Main category: cs.AI

TL;DR: 论文提出了一种基于Promise Theory的语义时空模型，用于低成本地检测数据中的潜在意图，无需依赖大规模训练或推理能力。


<details>
  <summary>Details</summary>
Motivation: 探讨意图和语境在科学与技术中的实际意义，弥补Searle之后对意图研究的不足。

Method: 利用过程一致性作为指导，通过多尺度异常检测和时空一致性分离意图内容与背景语境。

Result: 提供了一种低成本、实用的潜在意图解释方法，适用于基础生物体。

Conclusion: 该方法为低计算成本的意图检测提供了可行方案，但概念形成能力受限于代理的记忆容量。

Abstract: Since Searle's work deconstructing intent and intentionality in the realm of
philosophy, the practical meaning of intent has received little attention in
science and technology. Intentionality and context are both central to the
scope of Promise Theory's model of Semantic Spacetime, used as an effective
Tiny Language Model. One can identify themes and concepts from a text, on a low
level (without knowledge of the specific language) by using process coherence
as a guide. Any agent process can assess superficially a degree of latent
`intentionality' in data by looking for anomalous multi-scale anomalies and
assessing the work done to form them. Scale separation can be used to sort
parts into `intended' content and `ambient context', using the spacetime
coherence as a measure. This offers an elementary but pragmatic interpretation
of latent intentionality for very low computational cost, and without reference
to extensive training or reasoning capabilities. The process is well within the
reach of basic organisms as it does not require large scale artificial
probabilistic batch processing. The level of concept formation depends,
however, on the memory capacity of the agent.

</details>


### [74] [Deep Hidden Cognition Facilitates Reliable Chain-of-Thought Reasoning](https://arxiv.org/abs/2507.10007)
*Zijun Chen,Wenbo Hu,Richang Hong*

Main category: cs.AI

TL;DR: 本文提出了一种通过利用模型内在的真实性编码来校准思维链（CoT）推理准确性的新方法，显著提高了推理的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管思维链推理在大型语言模型和多模态语言模型中表现出强大的深度推理能力，但其可靠性常因中间步骤错误的累积而受损。

Method: 通过发现特定注意力头激活能可靠反映CoT推理步骤的真实性，训练了一个置信度预测器，动态选择最合理的推理路径。

Result: 实验表明，该方法在数学、符号和常识推理任务中显著优于现有基线，且在单模态和多模态设置下均表现出更高的准确性和可靠性。

Conclusion: 本研究为CoT推理提供了一种新颖的可靠性改进路径，具有广泛的应用潜力。

Abstract: Chain of Thought (CoT) reasoning has demonstrated remarkable deep reasoning
capabilities in both large language models (LLMs) and multimodal large language
models (MLLMs). However, its reliability is often undermined by the
accumulation of errors in intermediate steps. This paper introduces an novel
approach to calibrate the CoT reasoning accuracy by leveraging the model's
intrinsic veracity encoding. We discover that specific attention head
activations reliably reflect the truthfulness of reasoning steps in CoT. Based
on this insight, we train a confidence predictor to evaluate the correctness of
each reasoning step using these truthfulness-sensitive activations, dynamically
selecting the most plausible reasoning path via beam search. Experimental
results demonstrate that our method significantly outperforms the
state-of-the-art baselines (e.g., Few-Shot CoT, Self-Consistency, and
Self-Evaluation Guided Beam Search) across the mathematical, symbolic, and
commonsense reasoning tasks, exhibiting superior accuracy and reliability in
both unimodal and multimodal settings. We further validate the approach on
large reasoning models, confirming its applicability to specialized reasoning
models. Additionally, we explore the role of the model's self-correction
ability in CoT reasoning. This work provides a novel reliability improvement
path for CoT reasoning with broad application potential.

</details>


### [75] [Automating SPARQL Query Translations between DBpedia and Wikidata](https://arxiv.org/abs/2507.10045)
*Malte Christian Bartels,Debayan Banerjee,Ricardo Usbeck*

Main category: cs.AI

TL;DR: 研究探讨了大型语言模型（LLM）能否自动在不同知识图谱（KG）模式间翻译SPARQL查询，重点评估了DBpedia-Wikidata和DBLP-OpenAlex的翻译性能。


<details>
  <summary>Details</summary>
Motivation: 填补知识图谱互操作性研究中SPARQL到SPARQL翻译的评估空白。

Method: 使用三个不同规模和架构的LLM（Llama-3-8B、DeepSeek-R1-Distill-Llama-70B、Mistral-Large-Instruct-2407），采用零样本、少样本和思维链变体进行测试。

Result: 模型和提示策略的性能差异显著，Wikidata到DBpedia的翻译效果优于反向。

Conclusion: LLM在SPARQL翻译中表现不一，需进一步优化模型和策略。

Abstract: This paper investigates whether state-of-the-art Large Language Models (LLMs)
can automatically translate SPARQL between popular Knowledge Graph (KG)
schemas. We focus on translations between the DBpedia and Wikidata KG, and
later on DBLP and OpenAlex KG. This study addresses a notable gap in KG
interoperability research by rigorously evaluating LLM performance on
SPARQL-to-SPARQL translation. Two benchmarks are assembled, where the first
align 100 DBpedia-Wikidata queries from QALD-9-Plus; the second contains 100
DBLP queries aligned to OpenAlex, testing generalizability beyond encyclopaedic
KGs. Three open LLMs: Llama-3-8B, DeepSeek-R1-Distill-Llama-70B, and
Mistral-Large-Instruct-2407 are selected based on their sizes and architectures
and tested with zero-shot, few-shot, and two chain-of-thought variants. Outputs
were compared with gold answers, and resulting errors were categorized. We find
that the performance varies markedly across models and prompting strategies,
and that translations for Wikidata to DBpedia work far better than translations
for DBpedia to Wikidata.

</details>


### [76] [On Gradual Semantics for Assumption-Based Argumentation](https://arxiv.org/abs/2507.10076)
*Anna Rapberger,Fabrizio Russo,Antonio Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 该论文填补了假设基础论证（ABA）中渐进语义学的空白，提出了一种新的渐进语义学家族，用于为ABA框架中的假设分配辩证强度。


<details>
  <summary>Details</summary>
Motivation: 渐进语义学在计算论证中是一种细粒度的方法，但尚未应用于ABA框架，尽管ABA是一种流行的结构化论证形式。

Method: 通过使用双极集基础论证框架作为ABA框架的抽象，并推广QBAF的模块化渐进语义学，提出新的渐进ABA语义学。

Result: 实验表明，渐进ABA语义学满足平衡性和单调性等理想性质，并与基于论证的方法进行了比较。

Conclusion: 该研究为ABA框架提供了渐进语义学支持，扩展了渐进语义学的应用范围。

Abstract: In computational argumentation, gradual semantics are fine-grained
alternatives to extension-based and labelling-based semantics . They ascribe a
dialectical strength to (components of) arguments sanctioning their degree of
acceptability. Several gradual semantics have been studied for abstract,
bipolar and quantitative bipolar argumentation frameworks (QBAFs), as well as,
to a lesser extent, for some forms of structured argumentation. However, this
has not been the case for assumption-based argumentation (ABA), despite it
being a popular form of structured argumentation with several applications
where gradual semantics could be useful. In this paper, we fill this gap and
propose a family of novel gradual semantics for equipping assumptions, which
are the core components in ABA frameworks, with dialectical strengths. To do
so, we use bipolar set-based argumentation frameworks as an abstraction of
(potentially non-flat) ABA frameworks and generalise state-of-the-art modular
gradual semantics for QBAFs. We show that our gradual ABA semantics satisfy
suitable adaptations of desirable properties of gradual QBAF semantics, such as
balance and monotonicity. We also explore an argument-based approach that
leverages established QBAF modular semantics directly, and use it as baseline.
Finally, we conduct experiments with synthetic ABA frameworks to compare our
gradual ABA semantics with its argument-based counterpart and assess
convergence.

</details>


### [77] [BlueGlass: A Framework for Composite AI Safety](https://arxiv.org/abs/2507.10106)
*Harshal Nandigramwar,Syed Qutub,Kay-Ulrich Scholl*

Main category: cs.AI

TL;DR: 本文介绍了BlueGlass框架，旨在通过统一基础设施整合多种AI安全工具，提升AI系统的安全性，并通过视觉语言模型的三项分析验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统的能力增强和普及，确保其安全性变得至关重要。现有安全工具往往针对不同方面，无法单独提供全面保障，因此需要集成化的方法。

Method: 提出BlueGlass框架，提供统一基础设施以整合和组合多样化的安全工具，覆盖模型内部和输出。通过三项视觉语言模型的分析（分布评估、探针分析和稀疏自编码器）验证框架实用性。

Result: 框架成功整合了多种安全工具，三项分析揭示了模型性能的权衡、层级学习的共享机制以及可解释概念的识别，为构建更稳健的AI系统提供了基础。

Conclusion: BlueGlass框架为AI安全提供了集成化解决方案，并通过具体分析展示了其潜力，为未来构建更可靠的AI系统奠定了基础。

Abstract: As AI systems become increasingly capable and ubiquitous, ensuring the safety
of these systems is critical. However, existing safety tools often target
different aspects of model safety and cannot provide full assurance in
isolation, highlighting a need for integrated and composite methodologies. This
paper introduces BlueGlass, a framework designed to facilitate composite AI
safety workflows by providing a unified infrastructure enabling the integration
and composition of diverse safety tools that operate across model internals and
outputs. Furthermore, to demonstrate the utility of this framework, we present
three safety-oriented analyses on vision-language models for the task of object
detection: (1) distributional evaluation, revealing performance trade-offs and
potential failure modes across distributions; (2) probe-based analysis of layer
dynamics highlighting shared hierarchical learning via phase transition; and
(3) sparse autoencoders identifying interpretable concepts. More broadly, this
work contributes foundational infrastructure and findings for building more
robust and reliable AI systems.

</details>


### [78] [Analysis of AI Techniques for Orchestrating Edge-Cloud Application Migration](https://arxiv.org/abs/2507.10119)
*Sadig Gojayev,Ahmad Anaqreh,Carolina Fortuna*

Main category: cs.AI

TL;DR: 论文探讨了边缘-云系统中应用迁移的自动化编排问题，通过MDP框架比较了AI规划和强化学习方法，并提出了基于状态空间定义的新分类。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解如何高效编排边缘-云系统中的应用迁移，以提升服务质量和成本效益。

Method: 从MDP出发，分析并比较了AI规划和强化学习方法，特别关注可建模为汉诺塔问题的迁移问题，并提出了新的状态空间分类。

Result: 研究比较了多种技术，并提出了新的分类框架，为计算连续环境中的应用迁移编排提供了参考。

Conclusion: 论文为边缘-云系统中应用迁移的自动化编排提供了技术比较和新分类，有助于未来研究和技术选择。

Abstract: Application migration in edge-cloud system enables high QoS and cost
effective service delivery. However, automatically orchestrating such migration
is typically solved with heuristic approaches. Starting from the Markov
Decision Process (MDP), in this paper, we identify, analyze and compare
selected state-of-the-art Artificial Intelligence (AI) planning and
Reinforcement Learning (RL) approaches for solving the class of edge-cloud
application migration problems that can be modeled as Towers of Hanoi (ToH)
problems. We introduce a new classification based on state space definition and
analyze the compared models also through this lense. The aim is to understand
available techniques capable of orchestrating such application migration in
emerging computing continuum environments.

</details>


### [79] [Could you be wrong: Debiasing LLMs using a metacognitive prompt for improving human decision making](https://arxiv.org/abs/2507.10124)
*Thomas T. Hills*

Main category: cs.AI

TL;DR: 论文探讨了利用人类心理学中的元认知提示（如“你可能是错的吗？”）来减少LLM的偏见，展示了这种方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于LLM仍在发展中，当前的偏见可能随时间变化，因此需要通用的去偏见策略。人类决策中的去偏见方法为LLM提供了潜在解决方案。

Method: 采用元认知提示（如“你可能是错的吗？”）引导LLM反思其回答，揭示潜在的偏见、错误和矛盾信息。

Result: 元认知提示能有效让LLM识别自身偏见，并提供更全面的反思信息，改善初始回答的局限性。

Conclusion: 人类心理学为LLM的提示工程提供了新思路，利用成熟的决策改进方法可提升LLM的偏见识别能力。

Abstract: Identifying bias in LLMs is ongoing. Because they are still in development,
what is true today may be false tomorrow. We therefore need general strategies
for debiasing that will outlive current models. Strategies developed for
debiasing human decision making offer one promising approach as they
incorporate an LLM-style prompt intervention designed to bring latent knowledge
into awareness during decision making. LLMs trained on vast amounts of
information contain information about potential biases, counter-arguments, and
contradictory evidence, but that information may only be brought to bear if
prompted. Metacognitive prompts developed in the human decision making
literature are designed to achieve this, and as I demonstrate here, they show
promise with LLMs. The prompt I focus on here is "could you be wrong?"
Following an LLM response, this prompt leads LLMs to produce additional
information, including why they answered as they did, errors, biases,
contradictory evidence, and alternatives, none of which were apparent in their
initial response. Indeed, this metaknowledge often reveals that how LLMs and
users interpret prompts are not aligned. Here I demonstrate this prompt using a
set of questions taken from recent articles about LLM biases, including
implicit discriminatory biases and failures of metacognition. "Could you be
wrong" prompts the LLM to identify its own biases and produce cogent
metacognitive reflection. I also present another example involving convincing
but incomplete information, which is readily corrected by the metacognitive
prompt. In sum, this work argues that human psychology offers a new avenue for
prompt engineering, leveraging a long history of effective prompt-based
improvements to human decision making.

</details>


### [80] [FRSICL: LLM-Enabled In-Context Learning Flight Resource Allocation for Fresh Data Collection in UAV-Assisted Wildfire Monitoring](https://arxiv.org/abs/2507.10134)
*Yousef Emami,Hao Zhou,Miguel Gutierrez Gaitan,Kai Li,Luis Almeida*

Main category: cs.AI

TL;DR: 论文提出了一种基于LLM的在线飞行资源分配方案（FRSICL），用于无人机辅助的野火监测系统，通过自然语言任务描述和环境反馈动态优化飞行控制和数据收集，显著降低了信息年龄（AoI）。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习（DRL）方法在无人机辅助野火监测中存在采样效率低、仿真与现实的差距以及训练复杂等问题，无法满足时间敏感应用的需求。

Method: 提出FRSICL方案，利用LLM支持的上下文学习，通过自然语言任务描述和环境反馈实时优化无人机的飞行控制和数据收集计划。

Result: 仿真结果表明，FRSICL在降低平均AoI方面优于PPO和最近邻基线方法。

Conclusion: FRSICL为无人机辅助野火监测提供了一种高效、动态的优化方案，解决了DRL的局限性。

Abstract: Unmanned Aerial Vehicles (UAVs) are vital for public safety, particularly in
wildfire monitoring, where early detection minimizes environmental impact. In
UAV-Assisted Wildfire Monitoring (UAWM) systems, joint optimization of sensor
transmission scheduling and velocity is critical for minimizing Age of
Information (AoI) from stale sensor data. Deep Reinforcement Learning (DRL) has
been used for such optimization; however, its limitations such as low sampling
efficiency, simulation-to-reality gaps, and complex training render it
unsuitable for time-critical applications like wildfire monitoring. This paper
introduces a new online Flight Resource Allocation scheme based on LLM-Enabled
In-Context Learning (FRSICL) to jointly optimize the UAV's flight control and
data collection schedule along the trajectory in real time, thereby
asymptotically minimizing the average AoI across ground sensors. In contrast to
DRL, FRSICL generates data collection schedules and controls velocity using
natural language task descriptions and feedback from the environment, enabling
dynamic decision-making without extensive retraining. Simulation results
confirm the effectiveness of the proposed FRSICL compared to Proximal Policy
Optimization (PPO) and Nearest-Neighbor baselines.

</details>


### [81] [Adaptability in Multi-Agent Reinforcement Learning: A Framework and Unified Review](https://arxiv.org/abs/2507.10142)
*Siyi Hu,Mohamad A Hady,Jianglin Qiao,Jimmy Cao,Mahardhika Pratama,Ryszard Kowalczyk*

Main category: cs.AI

TL;DR: 论文提出多智能体强化学习（MARL）在动态现实环境中的适应性概念，并设计了一个包含学习适应性、策略适应性和场景驱动适应性的框架，以评估MARL算法的可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管MARL在模拟环境中表现良好，但其在复杂动态的现实多智能体系统（MAS）中应用受限，需要解决环境变化带来的挑战。

Method: 引入适应性概念，提出包含三个维度的结构化框架：学习适应性、策略适应性和场景驱动适应性。

Result: 通过适应性视角，支持更系统的MARL性能评估，超越传统基准测试。

Conclusion: 该框架有助于开发更适合动态现实MAS的MARL算法。

Abstract: Multi-Agent Reinforcement Learning (MARL) has shown clear effectiveness in
coordinating multiple agents across simulated benchmarks and constrained
scenarios. However, its deployment in real-world multi-agent systems (MAS)
remains limited, primarily due to the complex and dynamic nature of such
environments. These challenges arise from multiple interacting sources of
variability, including fluctuating agent populations, evolving task goals, and
inconsistent execution conditions. Together, these factors demand that MARL
algorithms remain effective under continuously changing system configurations
and operational demands. To better capture and assess this capacity for
adjustment, we introduce the concept of \textit{adaptability} as a unified and
practically grounded lens through which to evaluate the reliability of MARL
algorithms under shifting conditions, broadly referring to any changes in the
environment dynamics that may occur during learning or execution. Centred on
the notion of adaptability, we propose a structured framework comprising three
key dimensions: learning adaptability, policy adaptability, and scenario-driven
adaptability. By adopting this adaptability perspective, we aim to support more
principled assessments of MARL performance beyond narrowly defined benchmarks.
Ultimately, this survey contributes to the development of algorithms that are
better suited for deployment in dynamic, real-world multi-agent systems.

</details>


### [82] [Introducing the Swiss Food Knowledge Graph: AI for Context-Aware Nutrition Recommendation](https://arxiv.org/abs/2507.10156)
*Lubnaa Abdur Rahman,Ioannis Papathanail,Stavroula Mougiakakou*

Main category: cs.AI

TL;DR: 论文介绍了瑞士食品知识图谱（SwissFKG），整合食谱、食材、营养数据及饮食限制，利用LLM增强图谱信息，并展示其在个性化营养查询中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有自动饮食评估系统忽视非视觉因素（如食材替代、个人饮食需求），瑞士缺乏整合的营养信息库。

Method: 构建SwissFKG图谱，采用LLM增强信息，并开发Graph-RAG应用验证图谱在营养查询中的效果。

Result: LLM能有效增强图谱信息，SwissFKG提供食材级饮食指导和个性化查询支持。

Conclusion: SwissFKG为下一代饮食评估工具奠定了基础，融合视觉、上下文和文化维度。

Abstract: AI has driven significant progress in the nutrition field, especially through
multimedia-based automatic dietary assessment. However, existing automatic
dietary assessment systems often overlook critical non-visual factors, such as
recipe-specific ingredient substitutions that can significantly alter
nutritional content, and rarely account for individual dietary needs, including
allergies, restrictions, cultural practices, and personal preferences. In
Switzerland, while food-related information is available, it remains
fragmented, and no centralized repository currently integrates all relevant
nutrition-related aspects within a Swiss context. To bridge this divide, we
introduce the Swiss Food Knowledge Graph (SwissFKG), the first resource, to our
best knowledge, to unite recipes, ingredients, and their substitutions with
nutrient data, dietary restrictions, allergen information, and national
nutrition guidelines under one graph. We establish a LLM-powered enrichment
pipeline for populating the graph, whereby we further present the first
benchmark of four off-the-shelf (<70 B parameter) LLMs for food knowledge
augmentation. Our results demonstrate that LLMs can effectively enrich the
graph with relevant nutritional information. Our SwissFKG goes beyond recipe
recommendations by offering ingredient-level information such as allergen and
dietary restriction information, and guidance aligned with nutritional
guidelines. Moreover, we implement a Graph-RAG application to showcase how the
SwissFKG's rich natural-language data structure can help LLM answer
user-specific nutrition queries, and we evaluate LLM-embedding pairings by
comparing user-query responses against predefined expected answers. As such,
our work lays the foundation for the next generation of dietary assessment
tools that blend visual, contextual, and cultural dimensions of eating.

</details>


### [83] [Should We Ever Prefer Decision Transformer for Offline Reinforcement Learning?](https://arxiv.org/abs/2507.10174)
*Yumi Omori,Zixuan Dong,Keith Ross*

Main category: cs.AI

TL;DR: 本文通过实验比较了Decision Transformer (DT)与Filtered Behavior Cloning (FBC)在稀疏奖励环境中的表现，发现FBC性能更优且更高效，质疑DT的适用性。


<details>
  <summary>Details</summary>
Motivation: 研究DT在稀疏奖励环境中的表现是否优于传统方法，并探讨其适用性。

Method: 在Robomimic和D4RL任务上比较DT与FBC的性能，FBC通过过滤低质量轨迹后进行行为克隆。

Result: FBC在稀疏奖励环境中表现优于DT，且更高效。

Conclusion: DT在稀疏奖励环境中不具优势，甚至可能在其他环境中也不适用，引发对其适用性的质疑。

Abstract: In recent years, extensive work has explored the application of the
Transformer architecture to reinforcement learning problems. Among these,
Decision Transformer (DT) has gained particular attention in the context of
offline reinforcement learning due to its ability to frame return-conditioned
policy learning as a sequence modeling task. Most recently, Bhargava et al.
(2024) provided a systematic comparison of DT with more conventional MLP-based
offline RL algorithms, including Behavior Cloning (BC) and Conservative
Q-Learning (CQL), and claimed that DT exhibits superior performance in
sparse-reward and low-quality data settings.
  In this paper, through experimentation on robotic manipulation tasks
(Robomimic) and locomotion benchmarks (D4RL), we show that MLP-based Filtered
Behavior Cloning (FBC) achieves competitive or superior performance compared to
DT in sparse-reward environments. FBC simply filters out low-performing
trajectories from the dataset and then performs ordinary behavior cloning on
the filtered dataset. FBC is not only very straightforward, but it also
requires less training data and is computationally more efficient. The results
therefore suggest that DT is not preferable for sparse-reward environments.
From prior work, arguably, DT is also not preferable for dense-reward
environments. Thus, we pose the question: Is DT ever preferable?

</details>


### [84] [Survey for Categorising Explainable AI Studies Using Data Analysis Task Frameworks](https://arxiv.org/abs/2507.10208)
*Hamzah Ziadeh,Hendrik Knoche*

Main category: cs.AI

TL;DR: 论文提出了一种分类和比较可解释人工智能（XAI）研究的方法，基于三个维度：内容、原因和对象，旨在解决任务描述不足、脱离上下文研究及用户测试不足等问题。


<details>
  <summary>Details</summary>
Motivation: 当前XAI研究存在大量矛盾，缺乏具体设计建议，主要源于对需要AI辅助的任务理解不足。

Method: 结合视觉分析、认知科学和仪表板设计等领域，提出基于“内容、原因、对象”维度的分类方法。

Result: 研究发现任务描述不足、脱离上下文研究和用户测试不足是主要问题，建议研究应明确用户领域、AI及数据分析专长。

Conclusion: 论文提出的分类方法和研究指南有助于研究者更好地识别相关研究、填补研究空白，并处理XAI设计中的矛盾结果。

Abstract: Research into explainable artificial intelligence (XAI) for data analysis
tasks suffer from a large number of contradictions and lack of concrete design
recommendations stemming from gaps in understanding the tasks that require AI
assistance. In this paper, we drew on multiple fields such as visual analytics,
cognition, and dashboard design to propose a method for categorising and
comparing XAI studies under three dimensions: what, why, and who. We identified
the main problems as: inadequate descriptions of tasks, context-free studies,
and insufficient testing with target users. We propose that studies should
specifically report on their users' domain, AI, and data analysis expertise to
illustrate the generalisability of their findings. We also propose study
guidelines for designing and reporting XAI tasks to improve the XAI community's
ability to parse the rapidly growing field. We hope that our contribution can
help researchers and designers better identify which studies are most relevant
to their work, what gaps exist in the research, and how to handle contradictory
results regarding XAI design.

</details>


### [85] [Toward Real-World Table Agents: Capabilities, Workflows, and Design Principles for LLM-based Table Intelligence](https://arxiv.org/abs/2507.10281)
*Jiaming Tian,Liyao Li,Wentao Ye,Haobo Wang,Lingxin Wang,Lihua Yu,Zujie Ren,Gang Chen,Junbo Zhao*

Main category: cs.AI

TL;DR: 本文综述了基于LLM的表格代理，旨在通过整合预处理、推理和领域适应来自动化表格任务，分析了五大核心能力，并指出了开源模型在真实场景中的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的表格任务常涉及噪声、结构异质性和语义复杂性，而现有研究主要针对干净的学术数据集，这一问题尚未充分探索。

Method: 定义了五大核心能力（表格结构理解、表格与查询语义理解、表格检索与压缩、可执行推理与可追溯性、跨领域泛化），并比较了当前方法。

Result: 发现开源模型在真实场景中（如Text-to-SQL代理）的性能与学术基准存在差距。

Conclusion: 提出了改进LLM表格代理在实践中的鲁棒性、泛化性和效率的具体建议。

Abstract: Tables are fundamental in domains such as finance, healthcare, and public
administration, yet real-world table tasks often involve noise, structural
heterogeneity, and semantic complexity--issues underexplored in existing
research that primarily targets clean academic datasets. This survey focuses on
LLM-based Table Agents, which aim to automate table-centric workflows by
integrating preprocessing, reasoning, and domain adaptation. We define five
core competencies--C1: Table Structure Understanding, C2: Table and Query
Semantic Understanding, C3: Table Retrieval and Compression, C4: Executable
Reasoning with Traceability, and C5: Cross-Domain Generalization--to analyze
and compare current approaches. In addition, a detailed examination of the
Text-to-SQL Agent reveals a performance gap between academic benchmarks and
real-world scenarios, especially for open-source models. Finally, we provide
actionable insights to improve the robustness, generalization, and efficiency
of LLM-based Table Agents in practical settings.

</details>


### [86] [Instance space analysis of the capacitated vehicle routing problem](https://arxiv.org/abs/2507.10397)
*Alessandra M. M. M. Gouvêa,Nuno Paulos,Eduardo Uchoa e Mariá C. V. Nascimento*

Main category: cs.AI

TL;DR: 本文通过实例空间分析（ISA）方法，结合DIMACS数据集，识别了23个相关实例特征，并利用降维和机器学习方法，揭示了实例结构对元启发式算法性能的影响。


<details>
  <summary>Details</summary>
Motivation: 解决CVRP研究中实例特征与元启发式算法性能之间复杂关系的理解问题。

Method: 结合ISA方法、DIMACS数据集，通过PRELIM、SIFTED和PILOT阶段进行降维和机器学习分析。

Result: 识别了23个实例特征，并创建了二维实例空间投影，提供了投影矩阵以便新实例分析。

Conclusion: ISA为CVRP领域提供了一种新的实例分析方法，便于未来研究扩展。

Abstract: This paper seeks to advance CVRP research by addressing the challenge of
understanding the nuanced relationships between instance characteristics and
metaheuristic (MH) performance. We present Instance Space Analysis (ISA) as a
valuable tool that allows for a new perspective on the field. By combining the
ISA methodology with a dataset from the DIMACS 12th Implementation Challenge on
Vehicle Routing, our research enabled the identification of 23 relevant
instance characteristics. Our use of the PRELIM, SIFTED, and PILOT stages,
which employ dimensionality reduction and machine learning methods, allowed us
to create a two-dimensional projection of the instance space to understand how
the structure of instances affect the behavior of MHs. A key contribution of
our work is that we provide a projection matrix, which makes it straightforward
to incorporate new instances into this analysis and allows for a new method for
instance analysis in the CVRP field.

</details>


### [87] [SentiDrop: A Multi Modal Machine Learning model for Predicting Dropout in Distance Learning](https://arxiv.org/abs/2507.10421)
*Meriem Zerkouk,Miloud Mihoubi,Belkacem Chikhaoui*

Main category: cs.AI

TL;DR: 论文提出了一种结合BERT情感分析和XGBoost特征选择的新模型，用于预测远程学习中的学生辍学风险，准确率达84%。


<details>
  <summary>Details</summary>
Motivation: 远程学习中辍学问题严重，早期预测对干预和提升学生坚持性至关重要。

Method: 结合BERT分析学生评论的情感，XGBoost处理社会人口和行为数据，通过特征重要性技术选择关键特征。

Result: 模型在未见数据上准确率达84%，优于基线模型的82%，且在精确度和F1分数上表现更优。

Conclusion: 该方法为制定个性化策略以减少辍学率和鼓励学生坚持提供了重要工具。

Abstract: School dropout is a serious problem in distance learning, where early
detection is crucial for effective intervention and student perseverance.
Predicting student dropout using available educational data is a widely
researched topic in learning analytics. Our partner's distance learning
platform highlights the importance of integrating diverse data sources,
including socio-demographic data, behavioral data, and sentiment analysis, to
accurately predict dropout risks. In this paper, we introduce a novel model
that combines sentiment analysis of student comments using the Bidirectional
Encoder Representations from Transformers (BERT) model with socio-demographic
and behavioral data analyzed through Extreme Gradient Boosting (XGBoost). We
fine-tuned BERT on student comments to capture nuanced sentiments, which were
then merged with key features selected using feature importance techniques in
XGBoost. Our model was tested on unseen data from the next academic year,
achieving an accuracy of 84\%, compared to 82\% for the baseline model.
Additionally, the model demonstrated superior performance in other metrics,
such as precision and F1-score. The proposed method could be a vital tool in
developing personalized strategies to reduce dropout rates and encourage
student perseverance

</details>


### [88] [Acquiring and Adapting Priors for Novel Tasks via Neural Meta-Architectures](https://arxiv.org/abs/2507.10446)
*Sudarshan Babu*

Main category: cs.AI

TL;DR: 论文提出了一种基于神经记忆和超网络的方法，用于在数据稀缺领域（如计算化学和医学成像）中高效获取先验知识，并展示了在3D场景生成和分子属性预测中的应用。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺的领域中，传统的预训练大模型难以应用，因此需要设计新的架构来高效获取先验知识。

Method: 使用神经记忆和超网络设计，结合模型无关元学习（MAML），在少量样本下实现非平稳分布的适应和通用先验的获取。

Result: 在3D场景生成和分割任务中，仅需少量训练场景即可高效获取先验；在分子属性预测中，改进了现有方法的性能。

Conclusion: 提出的方法在数据稀缺领域具有显著优势，能够高效获取和迁移先验知识，为相关领域提供了新的解决方案。

Abstract: The ability to transfer knowledge from prior experiences to novel tasks
stands as a pivotal capability of intelligent agents, including both humans and
computational models. This principle forms the basis of transfer learning,
where large pre-trained neural networks are fine-tuned to adapt to downstream
tasks. Transfer learning has demonstrated tremendous success, both in terms of
task adaptation speed and performance. However there are several domains where,
due to lack of data, training such large pre-trained models or foundational
models is not a possibility - computational chemistry, computational
immunology, and medical imaging are examples. To address these challenges, our
work focuses on designing architectures to enable efficient acquisition of
priors when large amounts of data are unavailable. In particular, we
demonstrate that we can use neural memory to enable adaptation on
non-stationary distributions with only a few samples. Then we demonstrate that
our hypernetwork designs (a network that generates another network) can acquire
more generalizable priors than standard networks when trained with Model
Agnostic Meta-Learning (MAML). Subsequently, we apply hypernetworks to 3D scene
generation, demonstrating that they can acquire priors efficiently on just a
handful of training scenes, thereby leading to faster text-to-3D generation. We
then extend our hypernetwork framework to perform 3D segmentation on novel
scenes with limited data by efficiently transferring priors from earlier viewed
scenes. Finally, we repurpose an existing molecular generative method as a
pre-training framework that facilitates improved molecular property prediction,
addressing critical challenges in computational immunology

</details>


### [89] [DeepResearch$^{\text{Eco}}$: A Recursive Agentic Workflow for Complex Scientific Question Answering in Ecology](https://arxiv.org/abs/2507.10522)
*Jennifer D'Souza,Endres Keno Sander,Andrei Aioanei*

Main category: cs.AI

TL;DR: DeepResearch$^{\text{Eco}}$是一种基于LLM的自动化科学合成系统，支持递归、深度和广度可控的探索，显著提升文献检索的多样性和细致度。


<details>
  <summary>Details</summary>
Motivation: 解决传统检索增强生成管道在科学文献合成中的局限性，提供用户可控的合成、透明推理和参数驱动配置，以增强领域证据的高通量整合和分析严谨性。

Method: 采用递归、深度和广度可控的探索方法，结合透明推理和参数驱动配置，实现科学文献的高效合成。

Result: 在49个生态研究问题中，实现了21倍的源整合提升和14.9倍的每千字源整合增加，高参数设置下达到专家级分析深度和上下文多样性。

Conclusion: DeepResearch$^{\text{Eco}}$在科学文献合成中表现出色，显著提升了检索和整合效率，适用于高要求的科研任务。

Abstract: We introduce DeepResearch$^{\text{Eco}}$, a novel agentic LLM-based system
for automated scientific synthesis that supports recursive, depth- and
breadth-controlled exploration of original research questions -- enhancing
search diversity and nuance in the retrieval of relevant scientific literature.
Unlike conventional retrieval-augmented generation pipelines, DeepResearch
enables user-controllable synthesis with transparent reasoning and
parameter-driven configurability, facilitating high-throughput integration of
domain-specific evidence while maintaining analytical rigor. Applied to 49
ecological research questions, DeepResearch achieves up to a 21-fold increase
in source integration and a 14.9-fold rise in sources integrated per 1,000
words. High-parameter settings yield expert-level analytical depth and
contextual diversity.
  Source code available at: https://github.com/sciknoworg/deep-research.

</details>
