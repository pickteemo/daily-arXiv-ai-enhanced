<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 61]
- [cs.AI](#cs.AI) [Total: 65]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Automated Seam Folding and Sewing Machine on Pleated Pants for Apparel Manufacturing](https://arxiv.org/abs/2508.06518)
*Ray Wai Man Kong*

Main category: cs.RO

TL;DR: 研究设计了一款自动化折叠与缝纫机，用于褶裥裤的生产，显著提升了效率并减少了人工操作的需求。


<details>
  <summary>Details</summary>
Motivation: 传统褶裥制作方法劳动密集、易出错且依赖高技能工人，亟需自动化解决方案。

Method: 开发了一款集成精密折叠机制和实时监控功能的自动化缝纫机，消除了标记步骤。

Result: 劳动力时间减少93%，机器时间提升73%，总产出率增加72%，周期时间从117秒降至33秒。

Conclusion: 该自动化机器不仅降低成本与浪费，还符合可持续性与效率的行业趋势。

Abstract: The applied research is the design and development of an automated folding
and sewing machine for pleated pants. It represents a significant advancement
in addressing the challenges associated with manual sewing processes.
Traditional methods for creating pleats are labour-intensive, prone to
inconsistencies, and require high levels of skill, making automation a critical
need in the apparel industry. This research explores the technical feasibility
and operational benefits of integrating advanced technologies into garment
production, focusing on the creation of an automated machine capable of precise
folding and sewing operations and eliminating the marking operation.
  The proposed machine incorporates key features such as a precision folding
mechanism integrated into the automated sewing unit with real-time monitoring
capabilities. The results demonstrate remarkable improvements: the standard
labour time has been reduced by 93%, dropping from 117 seconds per piece to
just 8 seconds with the automated system. Similarly, machinery time improved by
73%, and the total output rate increased by 72%. These enhancements translate
into a cycle time reduction from 117 seconds per piece to an impressive 33
seconds, enabling manufacturers to meet customer demand more swiftly. By
eliminating manual marking processes, the machine not only reduces labour costs
but also minimizes waste through consistent pleat formation. This automation
aligns with industry trends toward sustainability and efficiency, potentially
reducing environmental impact by decreasing material waste and energy
consumption.

</details>


### [2] [Optimization of Flip-Landing Trajectories for Starship based on a Deep Learned Simulator](https://arxiv.org/abs/2508.06520)
*Liwei Chen,Tong Qin,Zhenhua Huangfu,Li Li,Wei Wei*

Main category: cs.RO

TL;DR: 提出了一种基于可微分优化的可重复使用航天器翻转与着陆轨迹设计框架，结合深度学习与动力学求解器，实现端到端梯度优化。


<details>
  <summary>Details</summary>
Motivation: 解决传统轨迹优化方法中因线性化或凸松弛导致的物理一致性不足问题，提升复杂非线性机动任务的建模与优化能力。

Method: 使用深度神经网络代理模型预测气动力与力矩，结合可微分刚体动力学求解器，支持端到端梯度优化。同时处理执行器限制与终端着陆约束。

Result: 框架成功建模并优化了高非线性复杂机动任务，验证了其有效性。

Conclusion: 为未来涉及非定常气动力学、羽流交互和智能制导设计的扩展奠定了基础。

Abstract: We propose a differentiable optimization framework for flip-and-landing
trajectory design of reusable spacecraft, exemplified by the Starship vehicle.
A deep neural network surrogate, trained on high-fidelity CFD data, predicts
aerodynamic forces and moments, and is tightly coupled with a differentiable
rigid-body dynamics solver. This enables end-to-end gradient-based trajectory
optimization without linearization or convex relaxation. The framework handles
actuator limits and terminal landing constraints, producing physically
consistent, optimized control sequences. Both standard automatic
differentiation and Neural ODEs are applied to support long-horizon rollouts.
Results demonstrate the framework's effectiveness in modeling and optimizing
complex maneuvers with high nonlinearities. This work lays the groundwork for
future extensions involving unsteady aerodynamics, plume interactions, and
intelligent guidance design.

</details>


### [3] [Stinger Robot: A Self-Bracing Robotic Platform for Autonomous Drilling in Confined Underground Environments](https://arxiv.org/abs/2508.06521)
*H. Liu,L. S. Moreu,T. S. Andersen,V. V. Puche,M. Fumagalli*

Main category: cs.RO

TL;DR: 本文介绍了一种名为Stinger Robot的新型紧凑机器人平台，专为在废弃地下矿山等极端环境中进行自主高力钻孔而设计。


<details>
  <summary>Details</summary>
Motivation: 由于废弃地下矿山环境狭窄、无结构且缺乏基础设施，传统钻探机械难以应对，因此需要开发新型机器人平台。

Method: 机器人采用机械自锁三腿支撑机制，结合力感知闭环控制策略，通过ROS 2中的有限状态机动态调整腿部部署。

Result: 仿真和初步硬件测试表明，该机器人能在传统采矿机械无法工作的环境中自主稳定钻孔。

Conclusion: 该研究首次验证了分布式力支撑与自主钻孔结合的机器人架构，为未来模块化机器人协作采矿奠定了基础。

Abstract: The increasing demand for critical raw materials has revitalized interest in
abandoned underground mines, which pose extreme challenges for conventional
drilling machinery due to confined, unstructured, and infrastructure-less
environments. This paper presents the Stinger Robot, a novel compact robotic
platform specifically designed for autonomous high-force drilling in such
settings. The robot features a mechanically self-locking tri-leg bracing
mechanism that enables stable anchoring to irregular tunnel surfaces. A key
innovation lies in its force-aware, closed-loop control strategy, which enables
force interaction with unstructured environments during bracing and drilling.
Implemented as a finite-state machine in ROS 2, the control policy dynamically
adapts leg deployment based on real-time contact feedback and load thresholds,
ensuring stability without external supports. We demonstrate, through
simulation and preliminary hardware tests, that the Stinger Robot can
autonomously stabilize and drill in conditions previously inaccessible to
nowadays mining machines. This work constitutes the first validated robotic
architecture to integrate distributed force-bracing and autonomous drilling in
underground environments, laying the groundwork for future collaborative mining
operations using modular robot systems.

</details>


### [4] [MetAdv: A Unified and Interactive Adversarial Testing Platform for Autonomous Driving](https://arxiv.org/abs/2508.06534)
*Aishan Liu,Jiakai Wang,Tianyuan Zhang,Hainan Li,Jiangfan Liu,Siyuan Liang,Yilong Ren,Xianglong Liu,Dacheng Tao*

Main category: cs.RO

TL;DR: MetAdv是一个新型对抗测试平台，通过虚拟仿真与物理车辆反馈的紧密结合，实现了自动驾驶系统的动态、交互式对抗评估。


<details>
  <summary>Details</summary>
Motivation: 评估和确保自动驾驶系统的对抗鲁棒性是一个关键且未解决的挑战，需要一种更现实、动态的测试方法。

Method: MetAdv构建了一个混合虚拟-物理沙盒，设计了三层闭环测试环境，支持从高层对抗生成到低层物理车辆执行的端到端评估。

Result: 平台支持多种自动驾驶任务和算法范式，兼容商业平台，并具备人机交互能力，可实时捕获驾驶员生理信号和行为反馈。

Conclusion: MetAdv为对抗评估提供了一个可扩展的统一框架，有助于推动更安全的自动驾驶发展。

Abstract: Evaluating and ensuring the adversarial robustness of autonomous driving (AD)
systems is a critical and unresolved challenge. This paper introduces MetAdv, a
novel adversarial testing platform that enables realistic, dynamic, and
interactive evaluation by tightly integrating virtual simulation with physical
vehicle feedback. At its core, MetAdv establishes a hybrid virtual-physical
sandbox, within which we design a three-layer closed-loop testing environment
with dynamic adversarial test evolution. This architecture facilitates
end-to-end adversarial evaluation, ranging from high-level unified adversarial
generation, through mid-level simulation-based interaction, to low-level
execution on physical vehicles. Additionally, MetAdv supports a broad spectrum
of AD tasks, algorithmic paradigms (e.g., modular deep learning pipelines,
end-to-end learning, vision-language models). It supports flexible 3D vehicle
modeling and seamless transitions between simulated and physical environments,
with built-in compatibility for commercial platforms such as Apollo and Tesla.
A key feature of MetAdv is its human-in-the-loop capability: besides flexible
environmental configuration for more customized evaluation, it enables
real-time capture of physiological signals and behavioral feedback from
drivers, offering new insights into human-machine trust under adversarial
conditions. We believe MetAdv can offer a scalable and unified framework for
adversarial assessment, paving the way for safer AD.

</details>


### [5] [Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots](https://arxiv.org/abs/2508.06538)
*Gioele Buriani,Jingyue Liu,Maximilian Stölzle,Cosimo Della Santina,Jiatao Ding*

Main category: cs.RO

TL;DR: 提出了一种结合SINDy与物理结构先验的学习架构，用于构建四足机器人跳跃的可解释降阶模型，其精度优于传统aSLIP模型。


<details>
  <summary>Details</summary>
Motivation: 降阶模型对四足机器人的运动规划与控制至关重要，但需在简化复杂动力学的同时保留关键行为。

Method: 结合Sparse Identification of Nonlinear Dynamics (SINDy)与跳跃动力学的物理结构先验，构建低维潜在空间模型。

Result: 新方法在仿真和硬件实验中验证了其优于传统aSLIP模型的准确性。

Conclusion: 该方法为四足机器人跳跃提供了更精确的可解释降阶模型。

Abstract: Reduced-order models are essential for motion planning and control of
quadruped robots, as they simplify complex dynamics while preserving critical
behaviors. This paper introduces a novel methodology for deriving such
interpretable dynamic models, specifically for jumping. We capture the
high-dimensional, nonlinear jumping dynamics in a low-dimensional latent space
by proposing a learning architecture combining Sparse Identification of
Nonlinear Dynamics (SINDy) with physical structural priors on the jump
dynamics. Our approach demonstrates superior accuracy to the traditional
actuated Spring-loaded Inverted Pendulum (aSLIP) model and is validated through
simulation and hardware experiments across different jumping strategies.

</details>


### [6] [A tutorial note on collecting simulated data for vision-language-action models](https://arxiv.org/abs/2508.06547)
*Heran Wu,Zirun Zhou,Jingfeng Zhang*

Main category: cs.RO

TL;DR: VLA模型通过单一神经网络统一处理视觉、语言和动作，依赖高质量数据集。教程回顾了PyBullet、LIBERO和RT-X三种代表性系统。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统将智能分解为独立模块，VLA模型通过统一框架提升效率，但需高质量数据集支持。

Method: 使用PyBullet生成定制数据，LIBERO定义标准化任务，RT-X收集大规模多机器人数据。

Result: 展示了PyBullet中的数据生成方法和LIBERO中的定制数据收集，概述了RT-X的特点和作用。

Conclusion: VLA模型依赖高质量数据集，PyBullet、LIBERO和RT-X为数据生成和收集提供了有效工具。

Abstract: Traditional robotic systems typically decompose intelligence into independent
modules for computer vision, natural language processing, and motion control.
Vision-Language-Action (VLA) models fundamentally transform this approach by
employing a single neural network that can simultaneously process visual
observations, understand human instructions, and directly output robot actions
-- all within a unified framework. However, these systems are highly dependent
on high-quality training datasets that can capture the complex relationships
between visual observations, language instructions, and robotic actions. This
tutorial reviews three representative systems: the PyBullet simulation
framework for flexible customized data generation, the LIBERO benchmark suite
for standardized task definition and evaluation, and the RT-X dataset
collection for large-scale multi-robot data acquisition. We demonstrated
dataset generation approaches in PyBullet simulation and customized data
collection within LIBERO, and provide an overview of the characteristics and
roles of the RT-X dataset for large-scale multi-robot data acquisition.

</details>


### [7] [AquaChat++: LLM-Assisted Multi-ROV Inspection for Aquaculture Net Pens with Integrated Battery Management and Thruster Fault Tolerance](https://arxiv.org/abs/2508.06554)
*Abdelhaleem Saad,Waseem Akram,Irfan Hussain*

Main category: cs.RO

TL;DR: AquaChat++是一个基于大型语言模型的多ROV检查框架，用于水产养殖网箱的自适应任务规划和容错控制。


<details>
  <summary>Details</summary>
Motivation: 传统水产养殖网箱检查方法适应性差，无法应对实时约束（如能耗、硬件故障和动态水下环境）。

Method: 采用两层架构：高层使用LLM（如ChatGPT-4）将自然语言命令转化为多代理检查计划；低层实现轨迹跟踪和故障检测补偿。

Result: 模拟实验显示，AquaChat++提高了检查覆盖率、能效和抗故障能力。

Conclusion: LLM驱动的框架有望支持水产养殖中可扩展、智能和自主的水下机器人操作。

Abstract: Inspection of aquaculture net pens is essential for ensuring the structural
integrity and sustainable operation of offshore fish farming systems.
Traditional methods, typically based on manually operated or single-ROV
systems, offer limited adaptability to real-time constraints such as energy
consumption, hardware faults, and dynamic underwater conditions. This paper
introduces AquaChat++, a novel multi-ROV inspection framework that uses Large
Language Models (LLMs) to enable adaptive mission planning, coordinated task
execution, and fault-tolerant control in complex aquaculture environments. The
proposed system consists of a two-layered architecture. The high-level plan
generation layer employs an LLM, such as ChatGPT-4, to translate natural
language user commands into symbolic, multi-agent inspection plans. A task
manager dynamically allocates and schedules actions among ROVs based on their
real-time status and operational constraints, including thruster faults and
battery levels. The low-level control layer ensures accurate trajectory
tracking and integrates thruster fault detection and compensation mechanisms.
By incorporating real-time feedback and event-triggered replanning, AquaChat++
enhances system robustness and operational efficiency. Simulated experiments in
a physics-based aquaculture environment demonstrate improved inspection
coverage, energy-efficient behavior, and resilience to actuator failures. These
findings highlight the potential of LLM-driven frameworks to support scalable,
intelligent, and autonomous underwater robotic operations within the
aquaculture sector.

</details>


### [8] [Robust and Agile Quadrotor Flight via Adaptive Unwinding-Free Quaternion Sliding Mode Control](https://arxiv.org/abs/2508.06568)
*Amin Yazdanshenas,Reza Faieghi*

Main category: cs.RO

TL;DR: 提出一种新型自适应滑模控制框架，用于四旋翼无人机在计算资源受限下实现鲁棒和敏捷飞行。


<details>
  <summary>Details</summary>
Motivation: 解决现有滑模控制在收敛速度、稳定性、旋转动力学简化、增益增长等问题上的不足。

Method: 利用非光滑稳定性分析，设计全局稳定的姿态和位置滑模动力学，并在资源受限的纳米四旋翼上高效运行。

Result: 在130多次飞行试验中，控制器性能优于三种基准方法，支持高动态机动（如3g加速度）。

Conclusion: 该控制器在外部干扰和计算约束下表现出色，具有实际应用潜力。

Abstract: This paper presents a new adaptive sliding mode control (SMC) framework for
quadrotors that achieves robust and agile flight under tight computational
constraints. The proposed controller addresses key limitations of prior SMC
formulations, including (i) the slow convergence and almost-global stability of
$\mathrm{SO(3)}$-based methods, (ii) the oversimplification of rotational
dynamics in Euler-based controllers, (iii) the unwinding phenomenon in
quaternion-based formulations, and (iv) the gain overgrowth problem in adaptive
SMC schemes. Leveraging nonsmooth stability analysis, we provide rigorous
global stability proofs for both the nonsmooth attitude sliding dynamics
defined on $\mathbb{S}^3$ and the position sliding dynamics. Our controller is
computationally efficient and runs reliably on a resource-constrained nano
quadrotor, achieving 250 Hz and 500 Hz refresh rates for position and attitude
control, respectively. In an extensive set of hardware experiments with over
130 flight trials, the proposed controller consistently outperforms three
benchmark methods, demonstrating superior trajectory tracking accuracy and
robustness with relatively low control effort. The controller enables
aggressive maneuvers such as dynamic throw launches, flip maneuvers, and
accelerations exceeding 3g, which is remarkable for a 32-gram nano quadrotor.
These results highlight promising potential for real-world applications,
particularly in scenarios requiring robust, high-performance flight control
under significant external disturbances and tight computational constraints.

</details>


### [9] [Efficient Safety Testing of Autonomous Vehicles via Adaptive Search over Crash-Derived Scenarios](https://arxiv.org/abs/2508.06575)
*Rui Zhou*

Main category: cs.RO

TL;DR: 该研究设计了一种加速测试算法（ALVNS-SA），用于验证自动驾驶车辆在安全关键场景中的安全性，显著提高了测试效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆的安全性至关重要，尤其是在安全关键场景中，需要高效的测试方法验证其驾驶能力。

Method: 从真实事故数据库中提取典型逻辑场景，集成百度Apollo自动驾驶系统，并提出ALVNS-SA算法加速测试过程。

Result: ALVNS-SA算法在安全关键场景中的覆盖率达到84.00%，其中碰撞场景覆盖率为96.83%，接近碰撞场景覆盖率为92.07%，显著优于其他算法。

Conclusion: ALVNS-SA算法在自动驾驶车辆安全测试中表现出高效性和优越性，适用于安全关键场景的快速验证。

Abstract: Ensuring the safety of autonomous vehicles (AVs) is paramount in their
development and deployment. Safety-critical scenarios pose more severe
challenges, necessitating efficient testing methods to validate AVs safety.
This study focuses on designing an accelerated testing algorithm for AVs in
safety-critical scenarios, enabling swift recognition of their driving
capabilities. First, typical logical scenarios were extracted from real-world
crashes in the China In-depth Mobility Safety Study-Traffic Accident (CIMSS-TA)
database, obtaining pre-crash features through reconstruction. Second, Baidu
Apollo, an advanced black-box automated driving system (ADS) is integrated to
control the behavior of the ego vehicle. Third, we proposed an adaptive
large-variable neighborhood-simulated annealing algorithm (ALVNS-SA) to
expedite the testing process. Experimental results demonstrate a significant
enhancement in testing efficiency when utilizing ALVNS-SA. It achieves an
84.00% coverage of safety-critical scenarios, with crash scenario coverage of
96.83% and near-crash scenario coverage of 92.07%. Compared to genetic
algorithm (GA), adaptive large neighborhood-simulated annealing algorithm
(ALNS-SA), and random testing, ALVNS-SA exhibits substantially higher coverage
in safety-critical scenarios.

</details>


### [10] [Optimal Planning and Machine Learning for Responsive Tracking and Enhanced Forecasting of Wildfires using a Spacecraft Constellation](https://arxiv.org/abs/2508.06687)
*Sreeja Roy-Singh,Vinay Ravindra,Richard Levinson,Mahta Moghaddam,Jan Mandel,Adam Kochanski,Angel Farguell Caus,Kurtis Nelson,Samira Alkaee Taleghan,Archana Kannan,Amer Melebari*

Main category: cs.RO

TL;DR: 论文提出了一种结合优化规划和机器学习的方法，用于收集和处理太空数据以监测野火，并通过低延迟工具支持消防决策。


<details>
  <summary>Details</summary>
Motivation: 现有野火监测和决策支持工具的延迟和数据分辨率不足，需要更高效的方法来改进。

Method: 采用混合整数规划调度卫星观测和数据下行，结合机器学习预测野火并生成新产品（如燃烧区域地图）。

Result: 优化规划实现了98-100%的观测机会捕获，机器学习预测准确率提升40%，数据集成使燃烧预测准确率提升13%-15%。

Conclusion: 该方法显著提升了野火监测和预测能力，具有低延迟、可扩展性和全球适用性。

Abstract: We propose a novel concept of operations using optimal planning methods and
machine learning (ML) to collect spaceborne data that is unprecedented for
monitoring wildfires, process it to create new or enhanced products in the
context of wildfire danger or spread monitoring, and assimilate them to improve
existing, wildfire decision support tools delivered to firefighters within
latency appropriate for time-critical applications. The concept is studied with
respect to NASA's CYGNSS Mission, a constellation of passive microwave
receivers that measure specular GNSS-R reflections despite clouds and smoke.
Our planner uses a Mixed Integer Program formulation to schedule joint
observation data collection and downlink for all satellites. Optimal solutions
are found quickly that collect 98-100% of available observation opportunities.
ML-based fire predictions that drive the planner objective are greater than 40%
more correlated with ground truth than existing state-of-art. The presented
case study on the TX Smokehouse Creek fire in 2024 and LA fires in 2025
represents the first high-resolution data collected by CYGNSS of active fires.
Creation of Burnt Area Maps (BAM) using ML applied to the data during active
fires and BAM assimilation into NASA's Weather Research and Forecasting Model
using ML to broadcast fire spread are novel outcomes. BAM and CYGNSS obtained
soil moisture are integrated for the first time into USGS fire danger maps.
Inclusion of CYGNSS data in ML-based burn predictions boosts accuracy by 13%,
and inclusion of high-resolution data boosts ML recall by another 15%. The
proposed workflow has an expected latency of 6-30h, improving on the current
delivery time of multiple days. All components in the proposed concept are
shown to be computationally scalable and globally generalizable, with
sustainability considerations such as edge efficiency and low latency on small
devices.

</details>


### [11] [Improved Obstacle Avoidance for Autonomous Robots with ORCA-FLC](https://arxiv.org/abs/2508.06722)
*Justin London*

Main category: cs.RO

TL;DR: ORCA-FL通过模糊逻辑控制器改进ORCA算法，提升多智能体环境中的避障性能，并在速度超过阈值时减少碰撞次数。


<details>
  <summary>Details</summary>
Motivation: 现有避障算法（如DWA、TEB、RVO）存在路径次优、计算成本高或动态适应性不足的问题，ORCA虽改进RVO但仍需优化。

Method: 提出ORCA-FL，结合模糊逻辑控制器（FLCs）处理不确定性，并引入模糊Q强化学习（FQL）优化FLCs。

Result: 实验表明，ORCA-FL在速度超过阈值时能减少碰撞次数，优于ORCA。

Conclusion: ORCA-FL通过模糊逻辑和强化学习提升了避障性能，适用于动态多智能体环境。

Abstract: Obstacle avoidance enables autonomous agents and robots to operate safely and
efficiently in dynamic and complex environments, reducing the risk of
collisions and damage. For a robot or autonomous system to successfully
navigate through obstacles, it must be able to detect such obstacles. While
numerous collision avoidance algorithms like the dynamic window approach (DWA),
timed elastic bands (TEB), and reciprocal velocity obstacles (RVO) have been
proposed, they may lead to suboptimal paths due to fixed weights, be
computationally expensive, or have limited adaptability to dynamic obstacles in
multi-agent environments. Optimal reciprocal collision avoidance (ORCA), which
improves on RVO, provides smoother trajectories and stronger collision
avoidance guarantees. We propose ORCA-FL to improve on ORCA by using fuzzy
logic controllers (FLCs) to better handle uncertainty and imprecision for
obstacle avoidance in path planning. Numerous multi-agent experiments are
conducted and it is shown that ORCA-FL can outperform ORCA in reducing the
number of collision if the agent has a velocity that exceeds a certain
threshold. In addition, a proposed algorithm for improving ORCA-FL using fuzzy
Q reinforcement learning (FQL) is detailed for optimizing and tuning FLCs.

</details>


### [12] [Learning Causal Structure Distributions for Robust Planning](https://arxiv.org/abs/2508.06742)
*Alejandro Murillo-Gonzalez,Junhong Xu,Lantao Liu*

Main category: cs.RO

TL;DR: 论文提出了一种结合结构因果模型和功能关系学习的方法，提升机器人系统动态模型的鲁棒性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有模型学习方法常忽略因果关系和机器人系统中交互的稀疏性，导致模型不够鲁棒且计算资源消耗大。

Method: 通过估计因果结构分布并采样因果图，结合编码器-多解码器概率模型学习动态关系。

Result: 模型在仿真和真实环境中验证了其有效性，提升了动态学习的适应性和对输入噪声及环境变化的鲁棒性。

Conclusion: 该方法显著提升了机器人动态模型的性能，适用于复杂现实场景。

Abstract: Structural causal models describe how the components of a robotic system
interact. They provide both structural and functional information about the
relationships that are present in the system. The structural information
outlines the variables among which there is interaction. The functional
information describes how such interactions work, via equations or learned
models. In this paper we find that learning the functional relationships while
accounting for the uncertainty about the structural information leads to more
robust dynamics models which improves downstream planning, while using
significantly lower computational resources. This in contrast with common
model-learning methods that ignore the causal structure and fail to leverage
the sparsity of interactions in robotic systems. We achieve this by estimating
a causal structure distribution that is used to sample causal graphs that
inform the latent-space representations in an encoder-multidecoder
probabilistic model. We show that our model can be used to learn the dynamics
of a robot, which together with a sampling-based planner can be used to perform
new tasks in novel environments, provided an objective function for the new
requirement is available. We validate our method using manipulators and mobile
robots in both simulation and the real-world. Additionally, we validate the
learned dynamics' adaptability and increased robustness to corrupted inputs and
changes in the environment, which is highly desirable in challenging real-world
robotics scenarios. Video: https://youtu.be/X6k5t7OOnNc.

</details>


### [13] [Robust-Sub-Gaussian Model Predictive Control for Safe Ultrasound-Image-Guided Robotic Spinal Surgery](https://arxiv.org/abs/2508.06744)
*Yunke Ao,Manish Prajapat,Yarden As,Yassine Taoudi-Benchekroun,Fabio Carrillo,Hooman Esfandiari,Benjamin F. Grewe,Andreas Krause,Philipp Fürnstahl*

Main category: cs.RO

TL;DR: 论文提出了一种基于高维光学数据的安全关键控制方法，利用子高斯噪声模型处理估计误差，并结合MPC框架确保线性系统的闭环安全性，应用于机器人脊柱手术。


<details>
  <summary>Details</summary>
Motivation: 高维光学数据（如图像、点云）在自动驾驶和机器人手术等领域的控制中存在估计误差分布复杂、难以建模的问题，导致安全保证困难。

Method: 提出子高斯噪声模型描述估计误差，结合鲁棒集方法和子高斯方差传播技术，开发了具有安全保证的MPC框架。

Result: 在机器人脊柱手术的仿真环境中验证了方法的有效性，确保了任务的安全执行。

Conclusion: 该方法为高维数据驱动的安全控制提供了新思路，尤其在复杂图像引导的机器人手术中具有潜力。

Abstract: Safety-critical control using high-dimensional sensory feedback from optical
data (e.g., images, point clouds) poses significant challenges in domains like
autonomous driving and robotic surgery. Control can rely on low-dimensional
states estimated from high-dimensional data. However, the estimation errors
often follow complex, unknown distributions that standard probabilistic models
fail to capture, making formal safety guarantees challenging. In this work, we
introduce a novel characterization of these general estimation errors using
sub-Gaussian noise with bounded mean. We develop a new technique for
uncertainty propagation of proposed noise characterization in linear systems,
which combines robust set-based methods with the propagation of sub-Gaussian
variance proxies. We further develop a Model Predictive Control (MPC) framework
that provides closed-loop safety guarantees for linear systems under the
proposed noise assumption. We apply this MPC approach in an
ultrasound-image-guided robotic spinal surgery pipeline, which contains
deep-learning-based semantic segmentation, image-based registration, high-level
optimization-based planning, and low-level robotic control. To validate the
pipeline, we developed a realistic simulation environment integrating real
human anatomy, robot dynamics, efficient ultrasound simulation, as well as
in-vivo data of breathing motion and drilling force. Evaluation results in
simulation demonstrate the potential of our approach for solving complex
image-guided robotic surgery task while ensuring safety.

</details>


### [14] [Learning a Vision-Based Footstep Planner for Hierarchical Walking Control](https://arxiv.org/abs/2508.06779)
*Minku Kim,Brian Acosta,Pratik Chaudhari,Michael Posa*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的分层控制框架，结合强化学习的高层脚步规划器和低层操作空间控制器，用于双足机器人在非结构化环境中的实时脚步规划。


<details>
  <summary>Details</summary>
Motivation: 当前双足机器人的框架依赖本体感知或手动设计的视觉管道，在现实环境中脆弱且难以实时规划脚步。

Method: 采用分层控制框架，高层使用强化学习生成脚步命令，低层跟踪轨迹；利用角动量线性倒立摆模型简化状态表示。

Result: 在仿真和硬件实验中验证了方法在不同地形条件下的有效性。

Conclusion: 该框架为双足机器人在复杂地形中的导航提供了可行的解决方案，但仍存在挑战。

Abstract: Bipedal robots demonstrate potential in navigating challenging terrains
through dynamic ground contact. However, current frameworks often depend solely
on proprioception or use manually designed visual pipelines, which are fragile
in real-world settings and complicate real-time footstep planning in
unstructured environments. To address this problem, we present a vision-based
hierarchical control framework that integrates a reinforcement learning
high-level footstep planner, which generates footstep commands based on a local
elevation map, with a low-level Operational Space Controller that tracks the
generated trajectories. We utilize the Angular Momentum Linear Inverted
Pendulum model to construct a low-dimensional state representation to capture
an informative encoding of the dynamics while reducing complexity. We evaluate
our method across different terrain conditions using the underactuated bipedal
robot Cassie and investigate the capabilities and challenges of our approach
through simulation and hardware experiments.

</details>


### [15] [D3P: Dynamic Denoising Diffusion Policy via Reinforcement Learning](https://arxiv.org/abs/2508.06804)
*Shu-Ang Yu,Feng Gao,Yi Wu,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: D3P是一种动态去噪扩散策略，通过自适应分配去噪步骤提升机器人任务的实时性能。


<details>
  <summary>Details</summary>
Motivation: 机器人任务中关键动作和常规动作对任务成功的影响不同，固定去噪步骤效率低。

Method: 提出D3P，使用轻量级状态感知适配器动态分配去噪步骤，并通过强化学习联合优化。

Result: 在模拟任务中实现2.2倍加速，物理机器人上实现1.9倍加速，且不影响任务成功率。

Conclusion: D3P显著提升扩散策略的实时性能，适用于实际机器人任务。

Abstract: Diffusion policies excel at learning complex action distributions for robotic
visuomotor tasks, yet their iterative denoising process poses a major
bottleneck for real-time deployment. Existing acceleration methods apply a
fixed number of denoising steps per action, implicitly treating all actions as
equally important. However, our experiments reveal that robotic tasks often
contain a mix of \emph{crucial} and \emph{routine} actions, which differ in
their impact on task success. Motivated by this finding, we propose
\textbf{D}ynamic \textbf{D}enoising \textbf{D}iffusion \textbf{P}olicy
\textbf{(D3P)}, a diffusion-based policy that adaptively allocates denoising
steps across actions at test time. D3P uses a lightweight, state-aware adaptor
to allocate the optimal number of denoising steps for each action. We jointly
optimize the adaptor and base diffusion policy via reinforcement learning to
balance task performance and inference efficiency. On simulated tasks, D3P
achieves an averaged 2.2$\times$ inference speed-up over baselines without
degrading success. Furthermore, we demonstrate D3P's effectiveness on a
physical robot, achieving a 1.9$\times$ acceleration over the baseline.

</details>


### [16] [Vibration-Based Energy Metric for Restoring Needle Alignment in Autonomous Robotic Ultrasound](https://arxiv.org/abs/2508.06921)
*Zhongyu Chen,Chenyang Li,Xuesong Li,Dianye Huang,Zhongliang Jiang,Stefanie Speidel,Xiangyu Chu,K. W. Samuel Au*

Main category: cs.RO

TL;DR: 提出一种基于振动的能量度量方法，用于在超声引导针插入过程中恢复针的对齐，即使针完全脱离平面也能有效工作。


<details>
  <summary>Details</summary>
Motivation: 在超声引导针插入过程中，针的对齐至关重要，但传统方法依赖针在超声图像中的可见性，而实际中常因噪声、伪影或低分辨率导致针难以检测。

Method: 通过机械系统周期性振动针，提出一种振动能量度量，并开发控制策略以调整超声探头位置，应对成像平面与针插入平面的错位。

Result: 在离体猪组织实验中，平移误差为0.41±0.27毫米，旋转误差为0.51±0.19度。

Conclusion: 该方法在针不可见时仍能有效恢复对齐，提高了超声引导针插入的鲁棒性。

Abstract: Precise needle alignment is essential for percutaneous needle insertion in
robotic ultrasound-guided procedures. However, inherent challenges such as
speckle noise, needle-like artifacts, and low image resolution make robust
needle detection difficult, particularly when visibility is reduced or lost. In
this paper, we propose a method to restore needle alignment when the ultrasound
imaging plane and the needle insertion plane are misaligned. Unlike many
existing approaches that rely heavily on needle visibility in ultrasound
images, our method uses a more robust feature by periodically vibrating the
needle using a mechanical system. Specifically, we propose a vibration-based
energy metric that remains effective even when the needle is fully out of
plane. Using this metric, we develop a control strategy to reposition the
ultrasound probe in response to misalignments between the imaging plane and the
needle insertion plane in both translation and rotation. Experiments conducted
on ex-vivo porcine tissue samples using a dual-arm robotic ultrasound-guided
needle insertion system demonstrate the effectiveness of the proposed approach.
The experimental results show the translational error of 0.41$\pm$0.27 mm and
the rotational error of 0.51$\pm$0.19 degrees.

</details>


### [17] [Manipulator for people with limited abilities](https://arxiv.org/abs/2508.06969)
*Bingkun Huang,Evgeniy Kotov,Arkady Yuschenko*

Main category: cs.RO

TL;DR: 开发一种四自由度机械手，用于辅助残疾人，结合机械设计、控制系统及ROS软件集成。


<details>
  <summary>Details</summary>
Motivation: 机器人技术进步为残疾人辅助设备提供了新可能，提升其生活质量。

Method: 设计机械结构、开发控制系统，并集成技术视觉系统与ROS软件。

Result: 成功开发出适用于实际操作的机械手原型。

Conclusion: 该机械手设计为残疾人辅助设备提供了实用解决方案，具有科学和实践意义。

Abstract: The topic of this final qualification work was chosen due to the importance
of developing robotic systems designed to assist people with disabilities.
Advances in robotics and automation technologies have opened up new prospects
for creating devices that can significantly improve the quality of life for
these people. In this context, designing a robotic hand with a control system
adapted to the needs of people with disabilities is a major scientific and
practical challenge. This work addresses the problem of developing and
manufacturing a four-degree-of-freedom robotic hand suitable for practical
manipulation. Addressing this issue requires a comprehensive approach,
encompassing the design of the hand's mechanical structure, the development of
its control system, and its integration with a technical vision system and
software based on the Robot Operating System (ROS).

</details>


### [18] [Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation](https://arxiv.org/abs/2508.06990)
*Yue Hu,Junzhe Wu,Ruihan Xu,Hang Liu,Avery Xi,Henry X. Liu,Ram Vasudevan,Maani Ghaffari*

Main category: cs.RO

TL;DR: SGImagineNav是一种新颖的导航框架，通过符号化世界建模和大型语言模型预测未来场景，提升语义导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖过去观察，缺乏对未来场景的预测能力，限制了导航效率。SGImagineNav旨在通过主动构建全局环境表示来解决这一问题。

Method: SGImagineNav采用分层场景图建模，结合大型语言模型预测未探索区域，并自适应地选择语义捷径或探索未知区域。

Result: 在HM3D和HSSD基准测试中，SGImagineNav成功率达到65.4%和66.8%，并在真实环境中展示了跨楼层和跨房间导航能力。

Conclusion: SGImagineNav通过主动预测和自适应策略显著提升了语义导航的效率和泛化能力。

Abstract: Semantic navigation requires an agent to navigate toward a specified target
in an unseen environment. Employing an imaginative navigation strategy that
predicts future scenes before taking action, can empower the agent to find
target faster. Inspired by this idea, we propose SGImagineNav, a novel
imaginative navigation framework that leverages symbolic world modeling to
proactively build a global environmental representation. SGImagineNav maintains
an evolving hierarchical scene graphs and uses large language models to predict
and explore unseen parts of the environment. While existing methods solely
relying on past observations, this imaginative scene graph provides richer
semantic context, enabling the agent to proactively estimate target locations.
Building upon this, SGImagineNav adopts an adaptive navigation strategy that
exploits semantic shortcuts when promising and explores unknown areas otherwise
to gather additional context. This strategy continuously expands the known
environment and accumulates valuable semantic contexts, ultimately guiding the
agent toward the target. SGImagineNav is evaluated in both real-world scenarios
and simulation benchmarks. SGImagineNav consistently outperforms previous
methods, improving success rate to 65.4 and 66.8 on HM3D and HSSD, and
demonstrating cross-floor and cross-room navigation in real-world environments,
underscoring its effectiveness and generalizability.

</details>


### [19] [EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events](https://arxiv.org/abs/2508.07003)
*Siyu Chen,Shenghai Yuan,Thien-Minh Nguyen,Zhuyu Huang,Chenyang Shi,Jin Jing,Lihua Xie*

Main category: cs.RO

TL;DR: EGS-SLAM通过融合事件数据和RGB-D输入，解决了GS-SLAM在运动模糊下的性能问题，提升了跟踪精度和3D重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统GS-SLAM在严重运动模糊下表现不佳，导致跟踪和重建质量下降。

Method: 提出EGS-SLAM框架，结合事件数据和RGB-D输入，建模相机连续轨迹，引入可学习的相机响应函数和无事件损失。

Result: 在合成和真实数据集上验证，EGS-SLAM在轨迹精度和3D重建质量上优于现有GS-SLAM系统。

Conclusion: EGS-SLAM显著提升了在运动模糊场景下的性能，代码将开源。

Abstract: Gaussian Splatting SLAM (GS-SLAM) offers a notable improvement over
traditional SLAM methods, enabling photorealistic 3D reconstruction that
conventional approaches often struggle to achieve. However, existing GS-SLAM
systems perform poorly under persistent and severe motion blur commonly
encountered in real-world scenarios, leading to significantly degraded tracking
accuracy and compromised 3D reconstruction quality. To address this limitation,
we propose EGS-SLAM, a novel GS-SLAM framework that fuses event data with RGB-D
inputs to simultaneously reduce motion blur in images and compensate for the
sparse and discrete nature of event streams, enabling robust tracking and
high-fidelity 3D Gaussian Splatting reconstruction. Specifically, our system
explicitly models the camera's continuous trajectory during exposure,
supporting event- and blur-aware tracking and mapping on a unified 3D Gaussian
Splatting scene. Furthermore, we introduce a learnable camera response function
to align the dynamic ranges of events and images, along with a no-event loss to
suppress ringing artifacts during reconstruction. We validate our approach on a
new dataset comprising synthetic and real-world sequences with significant
motion blur. Extensive experimental results demonstrate that EGS-SLAM
consistently outperforms existing GS-SLAM systems in both trajectory accuracy
and photorealistic 3D Gaussian Splatting reconstruction. The source code will
be available at https://github.com/Chensiyu00/EGS-SLAM.

</details>


### [20] [$\mathcal{P}^3$: Toward Versatile Embodied Agents](https://arxiv.org/abs/2508.07033)
*Shengli Zhou,Xiangchen Wang,Jinrui Zhang,Ruozai Tian,Rongtao Xu,Feng Zheng*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Embodied agents have shown promising generalization capabilities across
diverse physical environments, making them essential for a wide range of
real-world applications. However, building versatile embodied agents poses
critical challenges due to three key issues: dynamic environment perception,
open-ended tool usage, and complex multi-task planning. Most previous works
rely solely on feedback from tool agents to perceive environmental changes and
task status, which limits adaptability to real-time dynamics, causes error
accumulation, and restricts tool flexibility. Furthermore, multi-task
scheduling has received limited attention, primarily due to the inherent
complexity of managing task dependencies and balancing competing priorities in
dynamic and complex environments. To overcome these challenges, we introduce
$\mathcal{P}^3$, a unified framework that integrates real-time perception and
dynamic scheduling. Specifically, $\mathcal{P}^3$ enables 1) \textbf Perceive
relevant task information actively from the environment, 2) \textbf Plug and
utilize any tool without feedback requirement, and 3) \textbf Plan multi-task
execution based on prioritizing urgent tasks and dynamically adjusting task
order based on dependencies. Extensive real-world experiments show that our
approach bridges the gap between benchmarks and practical deployment,
delivering highly transferable, general-purpose embodied agents. Code and data
will be released soon.

</details>


### [21] [From Data to Safe Mobile Robot Navigation: An Efficient and Modular Robust MPC Design Pipeline](https://arxiv.org/abs/2508.07045)
*Dennis Benders,Johannes Köhler,Robert Babuška,Javier Alonso-Mora,Laura Ferranti*

Main category: cs.RO

TL;DR: 提出了一种模块化、高效的鲁棒MPC设计流程，通过闭环实验数据估计扰动边界，并在四旋翼仿真中验证了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有MPC方法在真实环境中因噪声和扰动导致的安全性问题，避免依赖理想化假设和启发式边界猜测。

Method: 采用迭代流程，利用闭环实验数据估计扰动边界，并合成鲁棒输出反馈MPC方案。

Result: 在Gazebo的四旋翼仿真中实现了鲁棒约束满足和递归可行性。

Conclusion: 提出的方法有效解决了MPC在噪声和扰动环境中的安全性问题，具有实用性和可重复性。

Abstract: Model predictive control (MPC) is a powerful strategy for planning and
control in autonomous mobile robot navigation. However, ensuring safety in
real-world deployments remains challenging due to the presence of disturbances
and measurement noise. Existing approaches often rely on idealized assumptions,
neglect the impact of noisy measurements, and simply heuristically guess
unrealistic bounds. In this work, we present an efficient and modular robust
MPC design pipeline that systematically addresses these limitations. The
pipeline consists of an iterative procedure that leverages closed-loop
experimental data to estimate disturbance bounds and synthesize a robust
output-feedback MPC scheme. We provide the pipeline in the form of
deterministic and reproducible code to synthesize the robust output-feedback
MPC from data. We empirically demonstrate robust constraint satisfaction and
recursive feasibility in quadrotor simulations using Gazebo.

</details>


### [22] [Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction](https://arxiv.org/abs/2508.07079)
*Mohamed Parvez Aslam,Bojan Derajic,Mohamed-Khalil Bouzidi,Sebastian Bernhard,Jan Oliver Ringert*

Main category: cs.RO

TL;DR: 该论文研究了在行人密集环境中，将基于深度学习的Social-Implicit（SI）行人轨迹预测器与模型预测控制（MPC）框架结合，以提升机器人导航的安全性和流畅性。


<details>
  <summary>Details</summary>
Motivation: 在行人密集环境中，自主机器人的安全导航是一个关键挑战。传统方法（如恒定速度模型）在动态环境中表现不佳，因此需要更智能的预测和控制方法。

Method: 论文将SI行人轨迹预测器集成到MPC框架中，并在物理机器人上测试。通过对比SI-MPC与传统CV模型在开环预测和闭环导航中的表现，评估其性能。

Result: SI模型显著降低了轨迹预测误差（低密度环境下减少76%），并在拥挤场景中提升了安全性和运动流畅性。实际部署还发现开环指标与闭环性能的差异。

Conclusion: SI-MPC框架在动态、人多的环境中展现出更安全和自适应的导航潜力，强调了系统级评估的重要性。

Abstract: Safe navigation in pedestrian-rich environments remains a key challenge for
autonomous robots. This work evaluates the integration of a deep learning-based
Social-Implicit (SI) pedestrian trajectory predictor within a Model Predictive
Control (MPC) framework on the physical Continental Corriere robot. Tested
across varied pedestrian densities, the SI-MPC system is compared to a
traditional Constant Velocity (CV) model in both open-loop prediction and
closed-loop navigation. Results show that SI improves trajectory prediction -
reducing errors by up to 76% in low-density settings - and enhances safety and
motion smoothness in crowded scenes. Moreover, real-world deployment reveals
discrepancies between open-loop metrics and closed-loop performance, as the SI
model yields broader, more cautious predictions. These findings emphasize the
importance of system-level evaluation and highlight the SI-MPC framework's
promise for safer, more adaptive navigation in dynamic, human-populated
environments.

</details>


### [23] [An Evolutionary Game-Theoretic Merging Decision-Making Considering Social Acceptance for Autonomous Driving](https://arxiv.org/abs/2508.07080)
*Haolin Liu,Zijun Guo,Yanbo Chen,Jiaqi Chen,Huilong Yu,Junqiang Xi*

Main category: cs.RO

TL;DR: 论文提出了一种基于进化博弈论（EGT）的自动驾驶车辆（AVs）匝道合并决策框架，通过动态平衡AVs和主路车辆（MVs）的利益，优化合并效率、舒适性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有决策算法未能充分应对动态复杂性和自动驾驶车辆的社会接受度，导致合并决策次优或不安全。

Method: 采用进化博弈论框架，结合人类驾驶员的有限理性，设计多目标收益函数，并通过求解复制动态方程得到最优合并时机。

Result: 实验表明，该方法在效率、舒适性和安全性上优于现有博弈论和传统规划方法。

Conclusion: 该框架为自动驾驶车辆匝道合并提供了更优的决策方案，平衡了多方利益。

Abstract: Highway on-ramp merging is of great challenge for autonomous vehicles (AVs),
since they have to proactively interact with surrounding vehicles to enter the
main road safely within limited time. However, existing decision-making
algorithms fail to adequately address dynamic complexities and social
acceptance of AVs, leading to suboptimal or unsafe merging decisions. To
address this, we propose an evolutionary game-theoretic (EGT) merging
decision-making framework, grounded in the bounded rationality of human
drivers, which dynamically balances the benefits of both AVs and main-road
vehicles (MVs). We formulate the cut-in decision-making process as an EGT
problem with a multi-objective payoff function that reflects human-like driving
preferences. By solving the replicator dynamic equation for the evolutionarily
stable strategy (ESS), the optimal cut-in timing is derived, balancing
efficiency, comfort, and safety for both AVs and MVs. A real-time driving style
estimation algorithm is proposed to adjust the game payoff function online by
observing the immediate reactions of MVs. Empirical results demonstrate that we
improve the efficiency, comfort and safety of both AVs and MVs compared with
existing game-theoretic and traditional planning approaches across multi-object
metrics.

</details>


### [24] [DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit](https://arxiv.org/abs/2508.07118)
*Aiden Swann,Alex Qiu,Matthew Strong,Angelina Zhang,Samuel Morstein,Kai Rayle,Monroe Kennedy III*

Main category: cs.RO

TL;DR: DexFruit是一个机器人操作框架，通过光学触觉传感实现脆弱水果的轻柔自主处理，减少损伤。FruitSplat技术通过3D高斯泼溅量化视觉损伤，提升抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 许多水果易碎且易受损伤，需人工小心采摘。研究旨在通过机器人技术实现轻柔自主操作，减少损伤。

Method: 使用光学触觉传感和触觉信息扩散策略，结合FruitSplat技术（3D高斯泼溅）量化损伤。

Result: 抓取成功率92%，视觉损伤减少20%，抓取成功率提升31%。

Conclusion: DexFruit框架显著提升水果操作的轻柔性和成功率，FruitSplat技术为损伤量化提供新方法。

Abstract: DexFruit is a robotic manipulation framework that enables gentle, autonomous
handling of fragile fruit and precise evaluation of damage. Many fruits are
fragile and prone to bruising, thus requiring humans to manually harvest them
with care. In this work, we demonstrate by using optical tactile sensing,
autonomous manipulation of fruit with minimal damage can be achieved. We show
that our tactile informed diffusion policies outperform baselines in both
reduced bruising and pick-and-place success rate across three fruits:
strawberries, tomatoes, and blackberries. In addition, we introduce FruitSplat,
a novel technique to represent and quantify visual damage in high-resolution 3D
representation via 3D Gaussian Splatting (3DGS). Existing metrics for measuring
damage lack quantitative rigor or require expensive equipment. With FruitSplat,
we distill a 2D strawberry mask as well as a 2D bruise segmentation mask into
the 3DGS representation. Furthermore, this representation is modular and
general, compatible with any relevant 2D model. Overall, we demonstrate a 92%
grasping policy success rate, up to a 20% reduction in visual bruising, and up
to an 31% improvement in grasp success rate on challenging fruit compared to
our baselines across our three tested fruits. We rigorously evaluate this
result with over 630 trials. Please checkout our website at
https://dex-fruit.github.io .

</details>


### [25] [Integrating Neurosymbolic AI in Advanced Air Mobility: A Comprehensive Survey](https://arxiv.org/abs/2508.07163)
*Kamal Acharya,Iman Sharifi,Mehul Lad,Liang Sun,Houbing Song*

Main category: cs.RO

TL;DR: 神经符号AI结合神经网络与符号推理，为高级空中交通（AAM）的复杂挑战提供解决方案。本文综述了其在需求预测、飞机设计和实时交通管理等领域的应用，指出当前研究在可扩展性和合规性方面仍存挑战。


<details>
  <summary>Details</summary>
Motivation: 高级空中交通（AAM）面临复杂的监管、运营和安全挑战，神经符号AI有望通过结合神经网络的适应性与符号推理的透明性来解决这些问题。

Method: 通过分类当前进展、展示案例研究，并分析神经符号强化学习等方法在动态优化中的潜力与局限性。

Result: 研究发现神经符号AI在AAM中具有潜力，但在可扩展性、鲁棒性和合规性方面仍需改进。

Conclusion: 本文为研究人员和从业者提供了整合神经符号AI到可靠、透明的AAM系统中的未来研究方向。

Abstract: Neurosymbolic AI combines neural network adaptability with symbolic
reasoning, promising an approach to address the complex regulatory,
operational, and safety challenges in Advanced Air Mobility (AAM). This survey
reviews its applications across key AAM domains such as demand forecasting,
aircraft design, and real-time air traffic management. Our analysis reveals a
fragmented research landscape where methodologies, including Neurosymbolic
Reinforcement Learning, have shown potential for dynamic optimization but still
face hurdles in scalability, robustness, and compliance with aviation
standards. We classify current advancements, present relevant case studies, and
outline future research directions aimed at integrating these approaches into
reliable, transparent AAM systems. By linking advanced AI techniques with AAM's
operational demands, this work provides a concise roadmap for researchers and
practitioners developing next-generation air mobility solutions.

</details>


### [26] [3D Gaussian Representations with Motion Trajectory Field for Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.07182)
*Xuesong Li,Lars Petersson,Vivien Rolland*

Main category: cs.RO

TL;DR: 提出了一种结合3D高斯泼溅与运动轨迹场的新方法，用于动态场景的新视角合成与运动重建。


<details>
  <summary>Details</summary>
Motivation: 解决单目视频中动态场景的新视角合成与运动重建问题，填补NeRF和3DGS在动态场景中的不足。

Method: 结合3DGS与运动轨迹场，解耦动态物体与静态背景，优化运动轨迹场，使用时间不变运动系数和共享运动轨迹基。

Result: 在单目视频的新视角合成和运动轨迹恢复中取得最先进结果。

Conclusion: 该方法显著提升了动态场景重建的能力。

Abstract: This paper addresses the challenge of novel-view synthesis and motion
reconstruction of dynamic scenes from monocular video, which is critical for
many robotic applications. Although Neural Radiance Fields (NeRF) and 3D
Gaussian Splatting (3DGS) have demonstrated remarkable success in rendering
static scenes, extending them to reconstruct dynamic scenes remains
challenging. In this work, we introduce a novel approach that combines 3DGS
with a motion trajectory field, enabling precise handling of complex object
motions and achieving physically plausible motion trajectories. By decoupling
dynamic objects from static background, our method compactly optimizes the
motion trajectory field. The approach incorporates time-invariant motion
coefficients and shared motion trajectory bases to capture intricate motion
patterns while minimizing optimization complexity. Extensive experiments
demonstrate that our approach achieves state-of-the-art results in both
novel-view synthesis and motion trajectory recovery from monocular video,
advancing the capabilities of dynamic scene reconstruction.

</details>


### [27] [Impact of Gaze-Based Interaction and Augmentation on Human-Robot Collaboration in Critical Tasks](https://arxiv.org/abs/2508.07244)
*Ayesha Jena,Stefan Reitmann,Elin Anna Topp*

Main category: cs.RO

TL;DR: 研究分析了基于头部注视的机器人控制和聚焦视觉增强在模拟搜救任务中的效果，结果显示聚焦增强显著提升任务表现，降低认知负荷38%，缩短任务时间60%以上。


<details>
  <summary>Details</summary>
Motivation: 探索聚焦视觉增强和头部注视模式在搜救任务中的效果，以优化用户意图理解和任务表现。

Method: 通过用户研究分析头部注视模式和聚焦视觉增强在模拟搜救任务中的应用。

Result: 聚焦增强显著提升任务表现，降低认知负荷38%，缩短任务时间60%以上；头部注视模式分析显示远近注意力捕捉对理解用户意图至关重要。

Conclusion: 聚焦增强技术具有潜力，需进一步研究注视测量以在关键任务中发挥作用。

Abstract: We present a user study analyzing head-gaze-based robot control and foveated
visual augmentation in a simulated search-and-rescue task. Results show that
foveated augmentation significantly improves task performance, reduces
cognitive load by 38%, and shortens task time by over 60%. Head-gaze patterns
analysed over both the entire task duration and shorter time segments show that
near and far attention capture is essential to better understand user intention
in critical scenarios. Our findings highlight the potential of foveation as an
augmentation technique and the need to further study gaze measures to leverage
them during critical tasks.

</details>


### [28] [Bio-Inspired Topological Autonomous Navigation with Active Inference in Robotics](https://arxiv.org/abs/2508.07267)
*Daria de Tinguy,Tim Verbelen,Emilio Gamba,Bart Dhoedt*

Main category: cs.RO

TL;DR: 本文提出了一种基于主动推理框架（AIF）的生物启发智能体，用于自主导航，无需预训练即可实时构建和更新环境拓扑图，实现探索和目标到达。


<details>
  <summary>Details</summary>
Motivation: 现有自主导航方法依赖严格规则或预训练，缺乏动态环境适应性，计算成本高。本文旨在提供一种统一、自适应且透明的解决方案。

Method: 采用主动推理框架（AIF），结合概率推理和模块化ROS2架构，实时构建拓扑图并规划目标导向轨迹。

Result: 在仿真和真实环境中测试，智能体成功探索大规模环境并适应动态障碍，性能与Gbplanner、FAEL等方法相当。

Conclusion: 该方法为复杂非结构化环境提供了一种可扩展且透明的导航方案。

Abstract: Achieving fully autonomous exploration and navigation remains a critical
challenge in robotics, requiring integrated solutions for localisation,
mapping, decision-making and motion planning. Existing approaches either rely
on strict navigation rules lacking adaptability or on pre-training, which
requires large datasets. These AI methods are often computationally intensive
or based on static assumptions, limiting their adaptability in dynamic or
unknown environments. This paper introduces a bio-inspired agent based on the
Active Inference Framework (AIF), which unifies mapping, localisation, and
adaptive decision-making for autonomous navigation, including exploration and
goal-reaching. Our model creates and updates a topological map of the
environment in real-time, planning goal-directed trajectories to explore or
reach objectives without requiring pre-training. Key contributions include a
probabilistic reasoning framework for interpretable navigation, robust
adaptability to dynamic changes, and a modular ROS2 architecture compatible
with existing navigation systems. Our method was tested in simulated and
real-world environments. The agent successfully explores large-scale simulated
environments and adapts to dynamic obstacles and drift, proving to be
comparable to other exploration strategies such as Gbplanner, FAEL and
Frontiers. This approach offers a scalable and transparent approach for
navigating complex, unstructured environments.

</details>


### [29] [Navigation and Exploration with Active Inference: from Biology to Industry](https://arxiv.org/abs/2508.07269)
*Daria de Tinguy,Tim Verbelen,Bart Dhoedt*

Main category: cs.RO

TL;DR: 提出了一种基于主动推理框架（AIF）的实时机器人导航系统，无需预先训练，通过构建拓扑地图和最小化不确定性实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 受动物通过构建认知地图实现复杂环境导航的启发，开发一种生物启发的机器人导航方法。

Method: 利用主动推理框架，增量构建拓扑地图，推断位置并规划动作，集成于ROS2生态系统。

Result: 在2D和3D环境中验证了系统的适应性和效率，性能与传统及前沿方法相当。

Conclusion: 该系统提供了一种生物启发的导航方法，具有实际应用潜力。

Abstract: By building and updating internal cognitive maps, animals exhibit
extraordinary navigation abilities in complex, dynamic environments. Inspired
by these biological mechanisms, we present a real time robotic navigation
system grounded in the Active Inference Framework (AIF). Our model
incrementally constructs a topological map, infers the agent's location, and
plans actions by minimising expected uncertainty and fulfilling perceptual
goals without any prior training. Integrated into the ROS2 ecosystem, we
validate its adaptability and efficiency across both 2D and 3D environments
(simulated and real world), demonstrating competitive performance with
traditional and state of the art exploration approaches while offering a
biologically inspired navigation approach.

</details>


### [30] [Multimodal Spiking Neural Network for Space Robotic Manipulation](https://arxiv.org/abs/2508.07287)
*Liwen Zhang,Dong Zhou,Shibo Shao,Zihao Su,Guanghui Sun*

Main category: cs.RO

TL;DR: 本文提出了一种基于脉冲神经网络（SNN）的多模态控制框架，用于空间站上的机械臂操作，旨在解决资源有限的问题，同时实现自主操作和材料转移。


<details>
  <summary>Details</summary>
Motivation: 空间站上的机械臂操作面临资源有限的挑战，需要一种高效且自主的控制方法。

Method: 结合几何状态、触觉和语义信息，采用双通道三阶段课程强化学习（CRL）方案。

Result: 在目标接近、物体抓取和稳定提升等任务中表现可靠，任务成功率和能效均优于基线方法。

Conclusion: 该框架适用于实际航空航天应用，具有较高的实用价值。

Abstract: This paper presents a multimodal control framework based on spiking neural
networks (SNNs) for robotic arms aboard space stations. It is designed to cope
with the constraints of limited onboard resources while enabling autonomous
manipulation and material transfer in space operations. By combining geometric
states with tactile and semantic information, the framework strengthens
environmental awareness and contributes to more robust control strategies. To
guide the learning process progressively, a dual-channel, three-stage
curriculum reinforcement learning (CRL) scheme is further integrated into the
system. The framework was tested across a range of tasks including target
approach, object grasping, and stable lifting with wall-mounted robotic arms,
demonstrating reliable performance throughout. Experimental evaluations
demonstrate that the proposed method consistently outperforms baseline
approaches in both task success rate and energy efficiency. These findings
highlight its suitability for real-world aerospace applications.

</details>


### [31] [A Hybrid Force-Position Strategy for Shape Control of Deformable Linear Objects With Graph Attention Networks](https://arxiv.org/abs/2508.07319)
*Yanzhao Yu,Haotian Yang,Junbo Tan,Xueqian Wang*

Main category: cs.RO

TL;DR: 提出了一种混合力-位置策略，用于变形线性物体（DLO）的形状控制，结合力空间的状态轨迹规划和位置空间的模型预测控制（MPC）。


<details>
  <summary>Details</summary>
Motivation: DLO（如电线、电缆）的操控在电子组装和医疗手术中至关重要，但由于其无限自由度、复杂非线性动力学和系统欠驱动特性，面临挑战。

Method: 提出了一个结合力和位置表示的框架，包括力空间的状态轨迹规划和位置空间的MPC。模型包含动作编码器、属性提取器和基于图注意力网络的图处理器。

Result: 仿真和实际实验表明，该方法能高效稳定地控制DLO的形状。

Conclusion: 该方法有效解决了DLO形状控制的挑战，代码和视频已公开。

Abstract: Manipulating deformable linear objects (DLOs) such as wires and cables is
crucial in various applications like electronics assembly and medical
surgeries. However, it faces challenges due to DLOs' infinite degrees of
freedom, complex nonlinear dynamics, and the underactuated nature of the
system. To address these issues, this paper proposes a hybrid force-position
strategy for DLO shape control. The framework, combining both force and
position representations of DLO, integrates state trajectory planning in the
force space and Model Predictive Control (MPC) in the position space. We
present a dynamics model with an explicit action encoder, a property extractor
and a graph processor based on Graph Attention Networks. The model is used in
the MPC to enhance prediction accuracy. Results from both simulations and
real-world experiments demonstrate the effectiveness of our approach in
achieving efficient and stable shape control of DLOs. Codes and videos are
available at https://sites.google.com/view/dlom.

</details>


### [32] [Collision-Free Trajectory Planning and control of Robotic Manipulator using Energy-Based Artificial Potential Field (E-APF)](https://arxiv.org/abs/2508.07323)
*Adeetya Uppal,Rakesh Kumar Sahoo,Manoranjan Sinha*

Main category: cs.RO

TL;DR: 提出了一种基于能量的APF框架（E-APF），结合位置和速度依赖的势能函数，解决了传统APF的局部极小值和振荡问题，并通过混合轨迹优化器实现平滑且高效的轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 动态和复杂环境中机器人轨迹规划的关键挑战在于同时满足时间效率和运动平滑性，传统APF方法存在局部极小值和振荡问题。

Method: 提出E-APF框架，结合位置和速度依赖的势能函数，并与混合轨迹优化器联合优化，最小化急动和执行时间。

Result: 在7自由度Kinova Gen3机械臂仿真中验证，实现了无碰撞、平滑、高效且无振荡的轨迹。

Conclusion: E-APF框架为未来与反应控制策略和实际硬件部署的集成奠定了基础。

Abstract: Robotic trajectory planning in dynamic and cluttered environments remains a
critical challenge, particularly when striving for both time efficiency and
motion smoothness under actuation constraints. Traditional path planner, such
as Artificial Potential Field (APF), offer computational efficiency but suffer
from local minima issue due to position-based potential field functions and
oscillatory motion near the obstacles due to Newtonian mechanics. To address
this limitation, an Energy-based Artificial Potential Field (APF) framework is
proposed in this paper that integrates position and velocity-dependent
potential functions. E-APF ensures dynamic adaptability and mitigates local
minima, enabling uninterrupted progression toward the goal. The proposed
framework integrates E-APF with a hybrid trajectory optimizer that jointly
minimizes jerk and execution time under velocity and acceleration constraints,
ensuring geometric smoothness and time efficiency. The entire framework is
validated in simulation using the 7-degree-of-freedom Kinova Gen3 robotic
manipulator. The results demonstrate collision-free, smooth, time-efficient,
and oscillation-free trajectory in the presence of obstacles, highlighting the
efficacy of the combined trajectory optimization and real-time obstacle
avoidance approach. This work lays the foundation for future integration with
reactive control strategies and physical hardware deployment in real-world
manipulation tasks.

</details>


### [33] [MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control](https://arxiv.org/abs/2508.07387)
*Basant Sharma,Prajyot Jadhav,Pranjal Paul,K. Madhava Krishna,Arun Kumar Singh*

Main category: cs.RO

TL;DR: 提出了一种基于学习的碰撞模型，利用RGB相机估计的深度信息作为上下文输入，预测障碍物最小间距分布，结合风险感知MPC规划器，显著提高了导航成功率。


<details>
  <summary>Details</summary>
Motivation: 单RGB相机在未知环境中导航时缺乏深度信息，传统深度估计方法噪声过大，无法可靠用于碰撞检测。

Method: 使用估计深度作为学习碰撞模型的输入，预测障碍物最小间距分布，结合风险感知MPC规划器进行导航。通过联合训练优化碰撞模型和风险度量。

Result: 在真实环境中，导航成功率比NoMaD和ROS堆栈分别提高了9倍和7倍。

Conclusion: 提出的联合学习框架和风险感知规划器显著提升了在复杂环境中的导航性能，消融实验验证了设计有效性。

Abstract: Navigating unknown environments with a single RGB camera is challenging, as
the lack of depth information prevents reliable collision-checking. While some
methods use estimated depth to build collision maps, we found that depth
estimates from vision foundation models are too noisy for zero-shot navigation
in cluttered environments.
  We propose an alternative approach: instead of using noisy estimated depth
for direct collision-checking, we use it as a rich context input to a learned
collision model. This model predicts the distribution of minimum obstacle
clearance that the robot can expect for a given control sequence. At inference,
these predictions inform a risk-aware MPC planner that minimizes estimated
collision risk. Our joint learning pipeline co-trains the collision model and
risk metric using both safe and unsafe trajectories. Crucially, our
joint-training ensures optimal variance in our collision model that improves
navigation in highly cluttered environments. Consequently, real-world
experiments show 9x and 7x improvements in success rates over NoMaD and the ROS
stack, respectively. Ablation studies further validate the effectiveness of our
design choices.

</details>


### [34] [AgriVLN: Vision-and-Language Navigation for Agricultural Robots](https://arxiv.org/abs/2508.07406)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 论文提出了农业场景下的视觉与语言导航基准A2A和基线方法AgriVLN，解决了现有方法在农业领域的不足，并通过指令分解模块提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有农业机器人依赖人工操作或固定轨道，移动性差；现有视觉与语言导航方法未针对农业场景设计。

Method: 提出A2A基准和AgriVLN基线方法，基于视觉语言模型，并引入指令分解模块STL。

Result: AgriVLN在短指令上表现良好，长指令执行较差；STL模块将成功率从0.33提升至0.47。

Conclusion: AgriVLN在农业领域表现优异，STL模块显著提升长指令执行能力。

Abstract: Agricultural robots have emerged as powerful members in agricultural tasks,
nevertheless, still heavily rely on manual operation or untransportable railway
for movement, resulting in limited mobility and poor adaptability.
Vision-and-Language Navigation (VLN) enables robots to navigate to the target
destinations following natural language instructions, demonstrating strong
performance on several domains. However, none of the existing benchmarks or
methods is specifically designed for agricultural scenes. To bridge this gap,
we propose Agriculture to Agriculture (A2A) benchmark, containing 1,560
episodes across six diverse agricultural scenes, in which all realistic RGB
videos are captured by front-facing camera on a quadruped robot at a height of
0.38 meters, aligning with the practical deployment conditions. Meanwhile, we
propose Vision-and-Language Navigation for Agricultural Robots (AgriVLN)
baseline based on Vision-Language Model (VLM) prompted with carefully crafted
templates, which can understand both given instructions and agricultural
environments to generate appropriate low-level actions for robot control. When
evaluated on A2A, AgriVLN performs well on short instructions but struggles
with long instructions, because it often fails to track which part of the
instruction is currently being executed. To address this, we further propose
Subtask List (STL) instruction decomposition module and integrate it into
AgriVLN, improving Success Rate (SR) from 0.33 to 0.47. We additionally compare
AgriVLN with several existing VLN methods, demonstrating the state-of-the-art
performance in the agricultural domain.

</details>


### [35] [Triple-S: A Collaborative Multi-LLM Framework for Solving Long-Horizon Implicative Tasks in Robotics](https://arxiv.org/abs/2508.07421)
*Zixi Jia,Hongbin Gao,Fashe Li,Jiqiang Liu,Hexiao Li,Qinghua Liu*

Main category: cs.RO

TL;DR: Triple-S框架通过多LLM协作，改进长时隐式任务中的政策代码生成，成功率达89%。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在长时隐式任务中生成政策代码时的API参数、注释和顺序错误问题。

Method: 提出Triple-S框架，利用多LLM在简化-解决-总结闭环过程中分工协作，并结合演示库更新机制。

Result: 在LDIP数据集中，Triple-S在可观察和部分可观察场景下任务成功率达89%。

Conclusion: Triple-S框架显著提升了长时隐式任务的执行成功率和鲁棒性，实验验证了其有效性。

Abstract: Leveraging Large Language Models (LLMs) to write policy code for controlling
robots has gained significant attention. However, in long-horizon implicative
tasks, this approach often results in API parameter, comments and sequencing
errors, leading to task failure. To address this problem, we propose a
collaborative Triple-S framework that involves multiple LLMs. Through
In-Context Learning, different LLMs assume specific roles in a closed-loop
Simplification-Solution-Summary process, effectively improving success rates
and robustness in long-horizon implicative tasks. Additionally, a novel
demonstration library update mechanism which learned from success allows it to
generalize to previously failed tasks. We validate the framework in the
Long-horizon Desktop Implicative Placement (LDIP) dataset across various
baseline models, where Triple-S successfully executes 89% of tasks in both
observable and partially observable scenarios. Experiments in both simulation
and real-world robot settings further validated the effectiveness of Triple-S.
Our code and dataset is available at: https://github.com/Ghbbbbb/Triple-S.

</details>


### [36] [A Learning-Based Framework for Collision-Free Motion Planning](https://arxiv.org/abs/2508.07502)
*Mateus Salomão,Tianyü Ren,Alexander König*

Main category: cs.RO

TL;DR: 论文提出了一种基于学习的环形场运动规划器扩展，通过深度神经网络从单张深度图像推断最优规划增益，实现高效无碰撞轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 解决传统手动调整力场参数的局限性，提高在复杂环境中的规划效率和泛化能力。

Method: 结合CUDA加速的感知模块、基于预测的代理规划策略，以及通过贝叶斯优化生成的数据集。

Result: 实验验证了实时规划无需手动调参，任务完成成功率高，泛化能力优于传统规划器。

Conclusion: 该框架在仿真和真实机器人上均表现优异，为复杂环境中的运动规划提供了有效解决方案。

Abstract: This paper presents a learning-based extension to a Circular Field (CF)-based
motion planner for efficient, collision-free trajectory generation in cluttered
environments. The proposed approach overcomes the limitations of hand-tuned
force field parameters by employing a deep neural network trained to infer
optimal planner gains from a single depth image of the scene. The pipeline
incorporates a CUDA-accelerated perception module, a predictive agent-based
planning strategy, and a dataset generated through Bayesian optimization in
simulation. The resulting framework enables real-time planning without manual
parameter tuning and is validated both in simulation and on a Franka Emika
Panda robot. Experimental results demonstrate successful task completion and
improved generalization compared to classical planners.

</details>


### [37] [Progressive Bird's Eye View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey](https://arxiv.org/abs/2508.07560)
*Yan Gong,Naibang Wang,Jianli Lu,Xinyu Zhang,Yongsheng Gao,Jie Zhao,Zifan Huang,Haozhi Bai,Nanxin Zeng,Nayu Su,Lei Yang,Ziying Song,Xiaoxi Hu,Xinmin Jiang,Xiaojuan Zhang,Susanto Rahardja*

Main category: cs.RO

TL;DR: 本文综述了自动驾驶中鸟瞰图（BEV）感知的安全关键视角，分析了单模态、多模态及多代理协作感知的框架，并探讨了开放世界中的挑战与未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆从受控环境转向实际部署，确保BEV感知在复杂场景（如遮挡、恶劣天气和动态交通）中的安全性和可靠性成为关键挑战。

Method: 系统分析了BEV感知的三个渐进阶段：单模态车辆侧、多模态车辆侧和多代理协作感知，并评估了相关公共数据集的安全性和鲁棒性。

Result: 识别了开放世界中的关键挑战，如开放集识别、大规模未标记数据、传感器退化和代理间通信延迟。

Conclusion: 提出了未来研究方向，包括与端到端自动驾驶系统、具身智能和大语言模型的集成。

Abstract: Bird's-Eye-View (BEV) perception has become a foundational paradigm in
autonomous driving, enabling unified spatial representations that support
robust multi-sensor fusion and multi-agent collaboration. As autonomous
vehicles transition from controlled environments to real-world deployment,
ensuring the safety and reliability of BEV perception in complex scenarios -
such as occlusions, adverse weather, and dynamic traffic - remains a critical
challenge. This survey provides the first comprehensive review of BEV
perception from a safety-critical perspective, systematically analyzing
state-of-the-art frameworks and implementation strategies across three
progressive stages: single-modality vehicle-side, multimodal vehicle-side, and
multi-agent collaborative perception. Furthermore, we examine public datasets
encompassing vehicle-side, roadside, and collaborative settings, evaluating
their relevance to safety and robustness. We also identify key open-world
challenges - including open-set recognition, large-scale unlabeled data, sensor
degradation, and inter-agent communication latency - and outline future
research directions, such as integration with end-to-end autonomous driving
systems, embodied intelligence, and large language models.

</details>


### [38] [Feedback Control of a Single-Tail Bioinspired 59-mg Swimmer](https://arxiv.org/abs/2508.07566)
*Conor K. Trygstad,Cody R. Longwell,Francisco M. F. R. Gonçalves,Elijah K. Blankenship,Néstor O. Pérez-Arancibia*

Main category: cs.RO

TL;DR: 本文介绍了一种改进版的FRISSHBot，一种受生物启发的微型游泳机器人，通过新型SMA双压电晶片驱动器实现二维空间控制，并首次展示了亚克级单尾水下机器人的反馈控制轨迹跟踪。


<details>
  <summary>Details</summary>
Motivation: 改进原始FRISSHBot的设计，以实现更高的游泳速度和精确的轨迹跟踪能力。

Method: 采用物理信息设计方法，增大头部并缩短尾部，结合新型SMA驱动器。

Result: 改进后的机器人最高游泳速度达13.6 mm/s（是原版的四倍），闭环跟踪时速度达9.1 mm/s，跟踪误差低至2.6 mm，转弯半径小至10 mm。

Conclusion: 新型FRISSHBot在速度和精确控制方面显著优于原版，为微型水下机器人提供了新可能。

Abstract: We present an evolved steerable version of the single-tail
Fish-&-Ribbon-Inspired Small Swimming Harmonic roBot (FRISSHBot), a 59-mg
biologically inspired swimmer, which is driven by a new shape-memory alloy
(SMA)-based bimorph actuator. The new FRISSHBot is controllable in the
two-dimensional (2D) space, which enabled the first demonstration of
feedback-controlled trajectory tracking of a single-tail aquatic robot with
onboard actuation at the subgram scale. These new capabilities are the result
of a physics-informed design with an enlarged head and shortened tail relative
to those of the original platform. Enhanced by its design, this new platform
achieves forward swimming speeds of up to 13.6 mm/s (0.38 Bl/s), which is over
four times that of the original platform. Furthermore, when following 2D
references in closed loop, the tested FRISSHBot prototype attains forward
swimming speeds of up to 9.1 mm/s, root-mean-square (RMS) tracking errors as
low as 2.6 mm, turning rates of up to 13.1 {\deg}/s, and turning radii as small
as 10 mm.

</details>


### [39] [In-situ Value-aligned Human-Robot Interactions with Physical Constraints](https://arxiv.org/abs/2508.07606)
*Hongtao Li,Ziyuan Jiao,Xiaofeng Liu,Hangxin Liu,Zilong Zheng*

Main category: cs.RO

TL;DR: 该论文提出了一种结合人类偏好与物理约束的框架，通过上下文学习人类反馈（ICLHF）来帮助机器人完成任务并适应未来场景。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）使机器人能完成复杂任务，但仅完成任务不足以满足认知机器人的需求，机器人还需学习并应用人类偏好。

Method: 开发了一个日常家庭活动基准，并引入ICLHF框架，通过人类直接指令和日常调整的反馈来学习。

Result: 实验表明，ICLHF能高效生成任务计划并平衡物理约束与人类偏好。

Conclusion: 该框架为机器人学习人类偏好提供了有效方法，提升了其在复杂环境中的适应性。

Abstract: Equipped with Large Language Models (LLMs), human-centered robots are now
capable of performing a wide range of tasks that were previously deemed
challenging or unattainable. However, merely completing tasks is insufficient
for cognitive robots, who should learn and apply human preferences to future
scenarios. In this work, we propose a framework that combines human preferences
with physical constraints, requiring robots to complete tasks while considering
both. Firstly, we developed a benchmark of everyday household activities, which
are often evaluated based on specific preferences. We then introduced
In-Context Learning from Human Feedback (ICLHF), where human feedback comes
from direct instructions and adjustments made intentionally or unintentionally
in daily life. Extensive sets of experiments, testing the ICLHF to generate
task plans and balance physical constraints with preferences, have demonstrated
the efficiency of our approach.

</details>


### [40] [End-to-End Humanoid Robot Safe and Comfortable Locomotion Policy](https://arxiv.org/abs/2508.07611)
*Zifan Wang,Xun Yang,Jianzhuang Zhao,Jiaming Zhou,Teli Ma,Ziyao Gao,Arash Ajoudani,Junwei Liang*

Main category: cs.RO

TL;DR: 提出一种端到端运动策略，将LiDAR点云直接映射为电机命令，结合CMDP和CBFs确保安全，并通过P3O训练实现安全约束。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在非结构化环境中需要更强的导航能力，现有方法在环境感知和安全约束上存在不足。

Method: 使用CMDP分离安全与任务目标，将CBFs转化为成本函数，结合P3O训练，并引入舒适性奖励。

Result: 框架成功实现仿真到现实的迁移，机器人能在复杂动态环境中安全导航。

Conclusion: 该方法通过结合安全约束和舒适性奖励，显著提升了人形机器人的导航能力。

Abstract: The deployment of humanoid robots in unstructured, human-centric environments
requires navigation capabilities that extend beyond simple locomotion to
include robust perception, provable safety, and socially aware behavior.
Current reinforcement learning approaches are often limited by blind
controllers that lack environmental awareness or by vision-based systems that
fail to perceive complex 3D obstacles. In this work, we present an end-to-end
locomotion policy that directly maps raw, spatio-temporal LiDAR point clouds to
motor commands, enabling robust navigation in cluttered dynamic scenes. We
formulate the control problem as a Constrained Markov Decision Process (CMDP)
to formally separate safety from task objectives. Our key contribution is a
novel methodology that translates the principles of Control Barrier Functions
(CBFs) into costs within the CMDP, allowing a model-free Penalized Proximal
Policy Optimization (P3O) to enforce safety constraints during training.
Furthermore, we introduce a set of comfort-oriented rewards, grounded in
human-robot interaction research, to promote motions that are smooth,
predictable, and less intrusive. We demonstrate the efficacy of our framework
through a successful sim-to-real transfer to a physical humanoid robot, which
exhibits agile and safe navigation around both static and dynamic 3D obstacles.

</details>


### [41] [Grasp-HGN: Grasping the Unexpected](https://arxiv.org/abs/2508.07648)
*Mehrshad Zandigohar,Mallesham Dasari,Gunar Schirner*

Main category: cs.RO

TL;DR: 论文提出Grasp-LLaVA和HGN模型，解决假肢手控制中未见物体的抓取泛化问题，显著提升准确性和延迟性能。


<details>
  <summary>Details</summary>
Motivation: 现有假肢手抓取模型对未见物体泛化能力差，影响用户独立性和生活质量。

Method: 提出Grasp-LLaVA（基于视觉语言模型）和HGN（边缘-云混合部署架构），结合语义推理和动态切换策略。

Result: Grasp-LLaVA在未见物体上准确率达50.2%，HGN进一步将准确率提升至42.3%，延迟降低3.5倍。

Conclusion: Grasp-LLaVA和HGN显著提升假肢手对未见物体的抓取能力，平衡了准确性与延迟。

Abstract: For transradial amputees, robotic prosthetic hands promise to regain the
capability to perform daily living activities. To advance next-generation
prosthetic hand control design, it is crucial to address current shortcomings
in robustness to out of lab artifacts, and generalizability to new
environments. Due to the fixed number of object to interact with in existing
datasets, contrasted with the virtually infinite variety of objects encountered
in the real world, current grasp models perform poorly on unseen objects,
negatively affecting users' independence and quality of life.
  To address this: (i) we define semantic projection, the ability of a model to
generalize to unseen object types and show that conventional models like YOLO,
despite 80% training accuracy, drop to 15% on unseen objects. (ii) we propose
Grasp-LLaVA, a Grasp Vision Language Model enabling human-like reasoning to
infer the suitable grasp type estimate based on the object's physical
characteristics resulting in a significant 50.2% accuracy over unseen object
types compared to 36.7% accuracy of an SOTA grasp estimation model.
  Lastly, to bridge the performance-latency gap, we propose Hybrid Grasp
Network (HGN), an edge-cloud deployment infrastructure enabling fast grasp
estimation on edge and accurate cloud inference as a fail-safe, effectively
expanding the latency vs. accuracy Pareto. HGN with confidence calibration (DC)
enables dynamic switching between edge and cloud models, improving semantic
projection accuracy by 5.6% (to 42.3%) with 3.5x speedup over the unseen object
types. Over a real-world sample mix, it reaches 86% average accuracy (12.2%
gain over edge-only), and 2.2x faster inference than Grasp-LLaVA alone.

</details>


### [42] [GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions](https://arxiv.org/abs/2508.07650)
*Helong Huang,Min Cen,Kai Tan,Xingyue Quan,Guowei Huang,Hong Zhang*

Main category: cs.RO

TL;DR: 论文提出GraphCoT-VLA模型，通过结构化思维链和3D姿态-物体图解决现有VLA模型在模糊指令和未知环境状态下的局限性，显著提升任务成功率和响应速度。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在模糊语言指令和未知环境状态处理上表现不足，且感知局限于静态二维观察，缺乏三维交互建模能力。

Method: 设计结构化思维链推理模块和实时更新的3D姿态-物体图，结合混合推理策略。

Result: 实验表明，GraphCoT-VLA在任务成功率和响应速度上显著优于现有方法，具有强泛化性和鲁棒性。

Conclusion: GraphCoT-VLA通过改进推理和三维建模能力，有效提升了机器人操作的性能。

Abstract: Vision-language-action models have emerged as a crucial paradigm in robotic
manipulation. However, existing VLA models exhibit notable limitations in
handling ambiguous language instructions and unknown environmental states.
Furthermore, their perception is largely constrained to static two-dimensional
observations, lacking the capability to model three-dimensional interactions
between the robot and its environment. To address these challenges, this paper
proposes GraphCoT-VLA, an efficient end-to-end model. To enhance the model's
ability to interpret ambiguous instructions and improve task planning, we
design a structured Chain-of-Thought reasoning module that integrates
high-level task understanding and planning, failed task feedback, and low-level
imaginative reasoning about future object positions and robot actions.
Additionally, we construct a real-time updatable 3D Pose-Object graph, which
captures the spatial configuration of robot joints and the topological
relationships between objects in 3D space, enabling the model to better
understand and manipulate their interactions. We further integrates a dropout
hybrid reasoning strategy to achieve efficient control outputs. Experimental
results across multiple real-world robotic tasks demonstrate that GraphCoT-VLA
significantly outperforms existing methods in terms of task success rate and
response speed, exhibiting strong generalization and robustness in open
environments and under uncertain instructions.

</details>


### [43] [MoRoCo: Multi-operator-robot Coordination, Interaction and Exploration under Restricted Communication](https://arxiv.org/abs/2508.07657)
*Zhuoli Tian,Yuyang Zhang,Jinsheng Wei,Meng Guo*

Main category: cs.RO

TL;DR: MoRoCo框架支持多操作员与多机器人在有限通信下的实时交互与协调，通过三种模式（spread、migrate、chain）实现高效探索。


<details>
  <summary>Details</summary>
Motivation: 现有研究多忽视人类操作员与机器人团队的实时交互需求，而实际任务中需动态调整任务、获取状态更新等。

Method: 提出MoRoCo框架，支持三种协调模式切换（spread、migrate、chain），通过分布式算法管理。

Result: 实验验证MoRoCo在有限通信下实现高效协调，提升人机交互可靠性。

Conclusion: MoRoCo为复杂环境中人机协同多机器人系统提供了鲁棒解决方案。

Abstract: Fleets of autonomous robots are increasingly deployed alongside multiple
human operators to explore unknown environments, identify salient features, and
perform complex tasks in scenarios such as subterranean exploration,
reconnaissance, and search-and-rescue missions. In these contexts,
communication is often severely limited to short-range exchanges via ad-hoc
networks, posing challenges to coordination. While recent studies have
addressed multi-robot exploration under communication constraints, they largely
overlook the essential role of human operators and their real-time interaction
with robotic teams. Operators may demand timely updates on the exploration
progress and robot status, reprioritize or cancel tasks dynamically, or request
live video feeds and control access. Conversely, robots may seek human
confirmation for anomalous events or require help recovering from motion or
planning failures. To enable such bilateral, context-aware interactions under
restricted communication, this work proposes MoRoCo, a unified framework for
online coordination and exploration in multi-operator, multi-robot systems.
MoRoCo enables the team to adaptively switch among three coordination modes:
spread mode for parallelized exploration with intermittent data sharing,
migrate mode for coordinated relocation, and chain mode for maintaining
high-bandwidth connectivity through multi-hop links. These transitions are
managed through distributed algorithms via only local communication. Extensive
large-scale human-in-the-loop simulations and hardware experiments validate the
necessity of incorporating human robot interactions and demonstrate that MoRoCo
enables efficient, reliable coordination under limited communication, marking a
significant step toward robust human-in-the-loop multi-robot autonomy in
challenging environments.

</details>


### [44] [Risk Map As Middleware: Towards Interpretable Cooperative End-to-end Autonomous Driving for Risk-Aware Planning](https://arxiv.org/abs/2508.07686)
*Mingyue Lei,Zewei Zhou,Hongchen Li,Jiaqi Ma,Jia Hu*

Main category: cs.RO

TL;DR: 提出了一种基于风险地图的中间件（RiskMM）和可解释的协作端到端驾驶框架，以解决单智能体端到端驾驶中的遮挡、感知范围限制和黑盒问题。


<details>
  <summary>Details</summary>
Motivation: 现有单智能体端到端驾驶系统因遮挡和有限感知范围导致危险驾驶，且黑盒特性使其行为难以解释，缺乏可信度。

Method: 通过风险地图学习驾驶数据，构建多智能体时空表示，利用注意力建模环境交互，并结合基于学习的模型预测控制（MPC）模块进行规划。

Result: 在真实数据集V2XPnP-Seq上的评估表明，RiskMM在风险感知轨迹规划中表现优越且稳健，显著提升了框架的可解释性。

Conclusion: RiskMM通过风险地图和MPC模块的结合，有效解决了端到端驾驶的局限性和可解释性问题，为未来研究提供了基础。

Abstract: End-to-end paradigm has emerged as a promising approach to autonomous
driving. However, existing single-agent end-to-end pipelines are often
constrained by occlusion and limited perception range, resulting in hazardous
driving. Furthermore, their black-box nature prevents the interpretability of
the driving behavior, leading to an untrustworthiness system. To address these
limitations, we introduce Risk Map as Middleware (RiskMM) and propose an
interpretable cooperative end-to-end driving framework. The risk map learns
directly from the driving data and provides an interpretable spatiotemporal
representation of the scenario from the upstream perception and the
interactions between the ego vehicle and the surrounding environment for
downstream planning. RiskMM first constructs a multi-agent spatiotemporal
representation with unified Transformer-based architecture, then derives
risk-aware representations by modeling interactions among surrounding
environments with attention. These representations are subsequently fed into a
learning-based Model Predictive Control (MPC) module. The MPC planner
inherently accommodates physical constraints and different vehicle types and
can provide interpretation by aligning learned parameters with explicit MPC
elements. Evaluations conducted on the real-world V2XPnP-Seq dataset confirm
that RiskMM achieves superior and robust performance in risk-aware trajectory
planning, significantly enhancing the interpretability of the cooperative
end-to-end driving framework. The codebase will be released to facilitate
future research in this field.

</details>


### [45] [LAURON VI: A Six-Legged Robot for Dynamic Walking](https://arxiv.org/abs/2508.07689)
*Christian Eichmann,Sabine Bellmann,Nicolas Hügel,Louis-Elias Enslin,Carsten Plasberg,Georg Heppner,Arne Roennau,Ruediger Dillmann*

Main category: cs.RO

TL;DR: 本文介绍了六足机器人LAURON VI，旨在通过动态步态和自主控制研究提升其在混合地形中的适应性。


<details>
  <summary>Details</summary>
Motivation: 六足机器人在复杂地形中表现出色，但在简单地形中缺乏快速步态，限制了其广泛应用。

Method: 设计了三种控制方法：基于运动学的、模型预测的和强化学习的控制器，并在实验室和火星模拟任务中测试。

Result: 通过引入快速运动策略，LAURON VI显著提升了六足机器人在实际应用中的适用性。

Conclusion: LAURON VI的研究为六足机器人在更广泛场景中的应用提供了技术基础。

Abstract: Legged locomotion enables robotic systems to traverse extremely challenging
terrains. In many real-world scenarios, the terrain is not that difficult and
these mixed terrain types introduce the need for flexible use of different
walking strategies to achieve mission goals in a fast, reliable, and
energy-efficient way. Six-legged robots have a high degree of flexibility and
inherent stability that aids them in traversing even some of the most difficult
terrains, such as collapsed buildings. However, their lack of fast walking
gaits for easier surfaces is one reason why they are not commonly applied in
these scenarios.
  This work presents LAURON VI, a six-legged robot platform for research on
dynamic walking gaits as well as on autonomy for complex field missions. The
robot's 18 series elastic joint actuators offer high-frequency interfaces for
Cartesian impedance and pure torque control. We have designed, implemented, and
compared three control approaches: kinematic-based, model-predictive, and
reinforcement-learned controllers. The robot hardware and the different control
approaches were extensively tested in a lab environment as well as on a Mars
analog mission. The introduction of fast locomotion strategies for LAURON VI
makes six-legged robots vastly more suitable for a wide range of real-world
applications.

</details>


### [46] [Robot and Overhead Crane Collaboration Scheme to Enhance Payload Manipulation](https://arxiv.org/abs/2508.07758)
*Antonio Rosales,Alaa Abderrahim,Markku Suomalainen,Mikael Haag,Tapio Heikkilä*

Main category: cs.RO

TL;DR: 提出了一种机器人协作吊车增强载荷操控的方案，通过力交互实现精确引导。


<details>
  <summary>Details</summary>
Motivation: 当前工业实践中，吊车载荷的精确操控依赖人工，效率低且风险高。

Method: 采用两种导纳传递函数，机器人基于位置的导纳控制与吊车的导纳控制协作。

Result: 仿真与实验验证了方案的可行性。

Conclusion: 协作方案提高了载荷操控的精确性与安全性。

Abstract: This paper presents a scheme to enhance payload manipulation using a robot
collaborating with an overhead crane. In the current industrial practice, when
the crane's payload has to be accurately manipulated and located in a desired
position, the task becomes laborious and risky since the operators have to
guide the fine motions of the payload by hand. In the proposed collaborative
scheme, the crane lifts the payload while the robot's end-effector guides it
toward the desired position. The only link between the robot and the crane is
the interaction force produced during the guiding of the payload. Two
admittance transfer functions are considered to accomplish harmless and smooth
contact with the payload. The first is used in a position-based admittance
control integrated with the robot. The second one adds compliance to the crane
by processing the interaction force through the admittance transfer function to
generate a crane's velocity command that makes the crane follow the payload.
Then the robot's end-effector and the crane move collaboratively to guide the
payload to the desired location. A method is presented to design the admittance
controllers that accomplish a fluent robot-crane collaboration. Simulations and
experiments validating the scheme potential are shown.

</details>


### [47] [AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation](https://arxiv.org/abs/2508.07770)
*Yizheng Zhang,Zhenjun Yu,Jiaxin Lai,Cewu Lu,Lei Han*

Main category: cs.RO

TL;DR: AgentWorld是一个交互式模拟平台，用于开发家庭移动操作能力，结合自动化场景构建和双模式远程操作系统，支持从基础动作到多阶段活动的任务数据收集，并通过模仿学习方法验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂家庭环境中机器人技能的可扩展获取问题，缩小仿真训练与实际部署之间的差距。

Method: 平台结合自动化场景构建（布局生成、语义资产放置、视觉材质配置、物理模拟）和双模式远程操作系统（轮式底座和人形运动策略），收集多样化任务数据。

Result: 通过模仿学习方法（如行为克隆、动作分块变换器、扩散策略和视觉-语言-动作模型）验证了数据集的仿真到现实转移效果。

Conclusion: AgentWorld为复杂家庭环境中的机器人技能获取提供了全面解决方案，代码和数据集将公开。

Abstract: We introduce AgentWorld, an interactive simulation platform for developing
household mobile manipulation capabilities. Our platform combines automated
scene construction that encompasses layout generation, semantic asset
placement, visual material configuration, and physics simulation, with a
dual-mode teleoperation system supporting both wheeled bases and humanoid
locomotion policies for data collection. The resulting AgentWorld Dataset
captures diverse tasks ranging from primitive actions (pick-and-place,
push-pull, etc.) to multistage activities (serve drinks, heat up food, etc.)
across living rooms, bedrooms, and kitchens. Through extensive benchmarking of
imitation learning methods including behavior cloning, action chunking
transformers, diffusion policies, and vision-language-action models, we
demonstrate the dataset's effectiveness for sim-to-real transfer. The
integrated system provides a comprehensive solution for scalable robotic skill
acquisition in complex home environments, bridging the gap between
simulation-based training and real-world deployment. The code, datasets will be
available at https://yizhengzhang1.github.io/agent_world/

</details>


### [48] [SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing](https://arxiv.org/abs/2508.07814)
*Malaika Zafar,Roohan Ahmed Khan,Faryal Batool,Yasheerah Yaqoot,Ziang Guo,Mikhail Litvinov,Aleksey Fedoseev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: SwarmVLM通过视觉语言模型和阻抗控制实现无人机与地面机器人的语义协作，解决无人机电池寿命和负载限制问题。


<details>
  <summary>Details</summary>
Motivation: 随着物流需求增长，无人机与自动导引车协同工作成为趋势，但无人机受限于电池寿命和飞行时间，需地面支持。

Method: SwarmVLM结合VLM和RAG技术，通过阻抗控制调整参数，无人机作为领导者使用APF规划实时导航，地面机器人通过虚拟阻抗链接跟随。

Result: 系统在12次真实试验中成功率达92%，VLM-RAG在理想光照下物体检测和参数选择准确率为8%，地面机器人能安全避开短障碍物。

Conclusion: SwarmVLM展示了异构导航的可行性，为无人机与地面机器人协作提供了高效解决方案。

Abstract: With the growing demand for efficient logistics, unmanned aerial vehicles
(UAVs) are increasingly being paired with automated guided vehicles (AGVs).
While UAVs offer the ability to navigate through dense environments and varying
altitudes, they are limited by battery life, payload capacity, and flight
duration, necessitating coordinated ground support.
  Focusing on heterogeneous navigation, SwarmVLM addresses these limitations by
enabling semantic collaboration between UAVs and ground robots through
impedance control. The system leverages the Vision Language Model (VLM) and the
Retrieval-Augmented Generation (RAG) to adjust impedance control parameters in
response to environmental changes. In this framework, the UAV acts as a leader
using Artificial Potential Field (APF) planning for real-time navigation, while
the ground robot follows via virtual impedance links with adaptive link
topology to avoid collisions with short obstacles.
  The system demonstrated a 92% success rate across 12 real-world trials. Under
optimal lighting conditions, the VLM-RAG framework achieved 8% accuracy in
object detection and selection of impedance parameters. The mobile robot
prioritized short obstacle avoidance, occasionally resulting in a lateral
deviation of up to 50 cm from the UAV path, which showcases safe navigation in
a cluttered setting.

</details>


### [49] [Touch Speaks, Sound Feels: A Multimodal Approach to Affective and Social Touch from Robots to Humans](https://arxiv.org/abs/2508.07839)
*Qiaoqiao Ren,Tony Belpaeme*

Main category: cs.RO

TL;DR: 研究开发了一个结合触觉和听觉的多模态交互系统，用于机器人情感表达，实验表明多模态显著提高了情感解码准确性。


<details>
  <summary>Details</summary>
Motivation: 探索机器人通过触觉和听觉结合的方式表达情感和社交手势的能力，填补现有研究的空白。

Method: 开发了一个包含25个振动电机和音频播放的多模态系统，通过振动、声音或组合方式呈现情感和手势，32名参与者评估了刺激的唤醒度和效价。

Result: 多模态显著提高了解码准确性；触觉和听觉各自对某些情感识别有优势；手势单独难以清晰传达情感。

Conclusion: 多感官整合对情感人机交互至关重要，触觉和听觉线索在情感沟通中具有互补作用。

Abstract: Affective tactile interaction constitutes a fundamental component of human
communication. In natural human-human encounters, touch is seldom experienced
in isolation; rather, it is inherently multisensory. Individuals not only
perceive the physical sensation of touch but also register the accompanying
auditory cues generated through contact. The integration of haptic and auditory
information forms a rich and nuanced channel for emotional expression. While
extensive research has examined how robots convey emotions through facial
expressions and speech, their capacity to communicate social gestures and
emotions via touch remains largely underexplored. To address this gap, we
developed a multimodal interaction system incorporating a 5*5 grid of 25
vibration motors synchronized with audio playback, enabling robots to deliver
combined haptic-audio stimuli. In an experiment involving 32 Chinese
participants, ten emotions and six social gestures were presented through
vibration, sound, or their combination. Participants rated each stimulus on
arousal and valence scales. The results revealed that (1) the combined
haptic-audio modality significantly enhanced decoding accuracy compared to
single modalities; (2) each individual channel-vibration or sound-effectively
supported certain emotions recognition, with distinct advantages depending on
the emotional expression; and (3) gestures alone were generally insufficient
for conveying clearly distinguishable emotions. These findings underscore the
importance of multisensory integration in affective human-robot interaction and
highlight the complementary roles of haptic and auditory cues in enhancing
emotional communication.

</details>


### [50] [DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of Disentangled Experts](https://arxiv.org/abs/2508.07842)
*Yutong Shen,Hangxu Liu,Penghui Liu,Ruizhe Xia,Tianyi Yao,Yitong Sun,Tongtong Feng*

Main category: cs.RO

TL;DR: DETACH框架通过双流解耦方法提升长时程任务的跨域泛化能力，平均子任务成功率提升23%，执行效率提升29%。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖技能链，无法泛化到新环境和技能组合，导致跨域长时程任务失败。

Method: DETACH采用生物启发的双流解耦机制，包括环境学习模块（空间理解）和技能学习模块（任务执行）。

Result: 实验显示DETACH在子任务成功率和执行效率上分别平均提升23%和29%。

Conclusion: DETACH通过解耦环境与自身状态，显著提升了跨域长时程任务的泛化能力。

Abstract: Long-Horizon (LH) tasks in Human-Scene Interaction (HSI) are complex
multi-step tasks that require continuous planning, sequential decision-making,
and extended execution across domains to achieve the final goal. However,
existing methods heavily rely on skill chaining by concatenating pre-trained
subtasks, with environment observations and self-state tightly coupled, lacking
the ability to generalize to new combinations of environments and skills,
failing to complete various LH tasks across domains. To solve this problem,
this paper presents DETACH, a cross-domain learning framework for LH tasks via
biologically inspired dual-stream disentanglement. Inspired by the brain's
"where-what" dual pathway mechanism, DETACH comprises two core modules: i) an
environment learning module for spatial understanding, which captures object
functions, spatial relationships, and scene semantics, achieving cross-domain
transfer through complete environment-self disentanglement; ii) a skill
learning module for task execution, which processes self-state information
including joint degrees of freedom and motor patterns, enabling cross-skill
transfer through independent motor pattern encoding. We conducted extensive
experiments on various LH tasks in HSI scenes. Compared with existing methods,
DETACH can achieve an average subtasks success rate improvement of 23% and
average execution efficiency improvement of 29%.

</details>


### [51] [Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning](https://arxiv.org/abs/2508.07885)
*Shoaib Ahmmad,Zubayer Ahmed Aditto,Md Mehrab Hossain,Noushin Yeasmin,Shorower Hossain*

Main category: cs.RO

TL;DR: 论文提出了一种基于AI的感知系统，用于GPS缺失的室内环境中自主四轴飞行器导航，结合云计算和定制PCB，实现了高效导航。


<details>
  <summary>Details</summary>
Motivation: 解决GPS缺失环境下四轴飞行器的自主导航问题，提升在狭小空间中的感知和决策能力。

Method: 系统整合了YOLOv11目标检测、Depth Anything V2深度估计、定制PCB（含ToF传感器和IMU）及云端LLM，采用多线程架构和虚拟安全包络。

Result: 实验显示，目标检测mAP50为0.6，深度估计MAE为7.2 cm，42次试验中仅16次安全包络突破，系统延迟低于1秒。

Conclusion: 该框架为GPS缺失环境下的无人机导航提供了高效辅助感知系统。

Abstract: This paper introduces an advanced AI-driven perception system for autonomous
quadcopter navigation in GPS-denied indoor environments. The proposed framework
leverages cloud computing to offload computationally intensive tasks and
incorporates a custom-designed printed circuit board (PCB) for efficient sensor
data acquisition, enabling robust navigation in confined spaces. The system
integrates YOLOv11 for object detection, Depth Anything V2 for monocular depth
estimation, a PCB equipped with Time-of-Flight (ToF) sensors and an Inertial
Measurement Unit (IMU), and a cloud-based Large Language Model (LLM) for
context-aware decision-making. A virtual safety envelope, enforced by
calibrated sensor offsets, ensures collision avoidance, while a multithreaded
architecture achieves low-latency processing. Enhanced spatial awareness is
facilitated by 3D bounding box estimation with Kalman filtering. Experimental
results in an indoor testbed demonstrate strong performance, with object
detection achieving a mean Average Precision (mAP50) of 0.6, depth estimation
Mean Absolute Error (MAE) of 7.2 cm, only 16 safety envelope breaches across 42
trials over approximately 11 minutes, and end-to-end system latency below 1
second. This cloud-supported, high-intelligence framework serves as an
auxiliary perception and navigation system, complementing state-of-the-art
drone autonomy for GPS-denied confined spaces.

</details>


### [52] [MolmoAct: Action Reasoning Models that can Reason in Space](https://arxiv.org/abs/2508.07917)
*Jason Lee,Jiafei Duan,Haoquan Fang,Yuquan Deng,Shuo Liu,Boyang Li,Bohan Fang,Jieyu Zhang,Yi Ru Wang,Sangho Lee,Winson Han,Wilbert Pumacay,Angelica Wu,Rose Hendrix,Karen Farley,Eli VanderBilt,Ali Farhadi,Dieter Fox,Ranjay Krishna*

Main category: cs.RO

TL;DR: 论文提出了一种名为ARMs的视觉-语言-动作模型，通过三阶段结构化流程整合感知、规划与控制，显著提升了机器人的适应性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人基础模型直接将感知和指令映射到控制，限制了适应性、泛化和语义理解能力，因此需要一种更结构化的推理方法。

Method: 提出MolmoAct模型，通过深度感知标记、可编辑轨迹规划和精确动作预测的三阶段流程实现可解释和可操控的行为。

Result: MolmoAct-7B-D在仿真和真实环境中表现优异，零样本准确率达70.5%，长时任务成功率提升6.3%，并显著优于基线模型。

Conclusion: MolmoAct不仅是一种先进的机器人基础模型，还提供了构建ARMs的开放蓝图，通过结构化推理将感知转化为有目的的行为。

Abstract: Reasoning is central to purposeful action, yet most robotic foundation models
map perception and instructions directly to control, which limits adaptability,
generalization, and semantic grounding. We introduce Action Reasoning Models
(ARMs), a class of vision-language-action models that integrate perception,
planning, and control through a structured three-stage pipeline. Our model,
MolmoAct, encodes observations and instructions into depth-aware perception
tokens, generates mid-level spatial plans as editable trajectory traces, and
predicts precise low-level actions, enabling explainable and steerable
behavior. MolmoAct-7B-D achieves strong performance across simulation and
real-world settings: 70.5% zero-shot accuracy on SimplerEnv Visual Matching
tasks, surpassing closed-source Pi-0 and GR00T N1; 86.6% average success on
LIBERO, including an additional 6.3% gain over ThinkAct on long-horizon tasks;
and in real-world fine-tuning, an additional 10% (single-arm) and an additional
22.7% (bimanual) task progression over Pi-0-FAST. It also outperforms baselines
by an additional 23.3% on out-of-distribution generalization and achieves top
human-preference scores for open-ended instruction following and trajectory
steering. Furthermore, we release, for the first time, the MolmoAct Dataset --
a mid-training robot dataset comprising over 10,000 high quality robot
trajectories across diverse scenarios and tasks. Training with this dataset
yields an average 5.5% improvement in general performance over the base model.
We release all model weights, training code, our collected dataset, and our
action reasoning dataset, establishing MolmoAct as both a state-of-the-art
robotics foundation model and an open blueprint for building ARMs that
transform perception into purposeful action through structured reasoning.
Blogpost: https://allenai.org/blog/molmoact

</details>


### [53] [PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF](https://arxiv.org/abs/2508.07945)
*En Yen Puang,Federico Ceola,Giulia Pasquale,Lorenzo Natale*

Main category: cs.RO

TL;DR: PCHands提出了一种通用表示方法，用于不同形态机械手的灵巧操作学习，基于锚点位置统一描述格式，提取主成分，并在强化学习中验证其高效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决不同形态机械手在灵巧操作中通用表示的学习问题。

Method: 提出PCHands方法，基于锚点位置统一描述格式，提取主成分作为通用表示，并用于强化学习策略的观测和动作空间编码。

Result: PCHands在学习和一致性上优于关节空间基线，且在演示学习中也表现鲁棒。

Conclusion: PCHands为不同形态机械手的灵巧操作提供了一种高效且通用的表示方法。

Abstract: We consider the problem of learning a common representation for dexterous
manipulation across manipulators of different morphologies. To this end, we
propose PCHands, a novel approach for extracting hand postural synergies from a
large set of manipulators. We define a simplified and unified description
format based on anchor positions for manipulators ranging from 2-finger
grippers to 5-finger anthropomorphic hands. This enables learning a
variable-length latent representation of the manipulator configuration and the
alignment of the end-effector frame of all manipulators. We show that it is
possible to extract principal components from this latent representation that
is universal across manipulators of different structures and degrees of
freedom. To evaluate PCHands, we use this compact representation to encode
observation and action spaces of control policies for dexterous manipulation
tasks learned with RL. In terms of learning efficiency and consistency, the
proposed representation outperforms a baseline that learns the same tasks in
joint space. We additionally show that PCHands performs robustly in RL from
demonstration, when demonstrations are provided from a different manipulator.
We further support our results with real-world experiments that involve a
2-finger gripper and a 4-finger anthropomorphic hand. Code and additional
material are available at https://hsp-iit.github.io/PCHands/.

</details>


### [54] [Aerial Target Encirclement and Interception with Noisy Range Observations](https://arxiv.org/abs/2508.08046)
*Fen Liu,Shenghai Yuan,Thien-Minh Nguyen,Wei Meng,Lihua Xie*

Main category: cs.RO

TL;DR: 提出一种利用噪声距离测量进行状态估计的策略，以包围和拦截非合作空中目标。


<details>
  <summary>Details</summary>
Motivation: 针对非合作目标的快速状态估计和拦截需求，设计一种主动确保目标可观测性的方法。

Method: 采用反同步（AS）3D“振动弦”轨迹和卡尔曼滤波进行状态估计，设计新型反目标控制器实现自适应过渡。

Result: 通过理论分析和实验验证，证明了状态估计误差的指数有界稳定性和包围误差的收敛性。

Conclusion: 系统设计在仿真和实际无人机实验中均表现出有效性。

Abstract: This paper proposes a strategy to encircle and intercept a non-cooperative
aerial point-mass moving target by leveraging noisy range measurements for
state estimation. In this approach, the guardians actively ensure the
observability of the target by using an anti-synchronization (AS), 3D
``vibrating string" trajectory, which enables rapid position and velocity
estimation based on the Kalman filter. Additionally, a novel anti-target
controller is designed for the guardians to enable adaptive transitions from
encircling a protected target to encircling, intercepting, and neutralizing a
hostile target, taking into consideration the input constraints of the
guardians. Based on the guaranteed uniform observability, the exponentially
bounded stability of the state estimation error and the convergence of the
encirclement error are rigorously analyzed. Simulation results and real-world
UAV experiments are presented to further validate the effectiveness of the
system design.

</details>


### [55] [Capsizing-Guided Trajectory Optimization for Autonomous Navigation with Rough Terrain](https://arxiv.org/abs/2508.08108)
*Wei Zhang,Yinchuan Wang,Wangtao Lu,Pengyu Zhang,Xiang Zhang,Yue Wang,Chaoqun Wang*

Main category: cs.RO

TL;DR: 论文提出了一种防倾覆的轨迹规划方法（CAP），用于地面机器人在复杂地形中的自主导航，结合稳定性分析和轨迹优化，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 地面机器人在复杂地形中导航时容易倾覆，现有方法难以平衡安全性与效率，因此需要一种新的轨迹规划方法来解决这一问题。

Method: 通过分析机器人在不平地形的倾覆稳定性，定义可通行方向，并将其作为约束条件融入轨迹优化中，使用图求解器生成安全且高效的轨迹。

Result: 仿真和实际实验表明，CAP方法在复杂地形中表现优于现有技术，提供了更高的导航效率和安全性。

Conclusion: CAP方法通过结合倾覆稳定性分析和轨迹优化，显著提升了地面机器人在复杂地形中的导航能力。

Abstract: It is a challenging task for ground robots to autonomously navigate in harsh
environments due to the presence of non-trivial obstacles and uneven terrain.
This requires trajectory planning that balances safety and efficiency. The
primary challenge is to generate a feasible trajectory that prevents robot from
tip-over while ensuring effective navigation. In this paper, we propose a
capsizing-aware trajectory planner (CAP) to achieve trajectory planning on the
uneven terrain. The tip-over stability of the robot on rough terrain is
analyzed. Based on the tip-over stability, we define the traversable
orientation, which indicates the safe range of robot orientations. This
orientation is then incorporated into a capsizing-safety constraint for
trajectory optimization. We employ a graph-based solver to compute a robust and
feasible trajectory while adhering to the capsizing-safety constraint.
Extensive simulation and real-world experiments validate the effectiveness and
robustness of the proposed method. The results demonstrate that CAP outperforms
existing state-of-the-art approaches, providing enhanced navigation performance
on uneven terrains.

</details>


### [56] [AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies](https://arxiv.org/abs/2508.08113)
*Yinpei Dai,Jayjun Lee,Yichi Zhang,Ziqiao Ma,Jed Yang,Amir Zadeh,Chuan Li,Nima Fazeli,Joyce Chai*

Main category: cs.RO

TL;DR: AimBot是一种轻量级视觉增强技术，通过空间提示提升机器人操作的视觉运动策略学习。


<details>
  <summary>Details</summary>
Motivation: 改善视觉运动策略学习中的空间感知，提供更直观的视觉反馈。

Method: 在多视角RGB图像上叠加射击线和瞄准镜标记，利用深度图像、相机外参和末端执行器姿态计算覆盖层。

Result: AimBot显著提升了多种视觉运动策略在仿真和现实环境中的性能，计算开销极低（<1ms）。

Conclusion: AimBot通过空间视觉反馈有效提升机器人操作性能，且无需修改模型架构。

Abstract: In this paper, we propose AimBot, a lightweight visual augmentation technique
that provides explicit spatial cues to improve visuomotor policy learning in
robotic manipulation. AimBot overlays shooting lines and scope reticles onto
multi-view RGB images, offering auxiliary visual guidance that encodes the
end-effector's state. The overlays are computed from depth images, camera
extrinsics, and the current end-effector pose, explicitly conveying spatial
relationships between the gripper and objects in the scene. AimBot incurs
minimal computational overhead (less than 1 ms) and requires no changes to
model architectures, as it simply replaces original RGB images with augmented
counterparts. Despite its simplicity, our results show that AimBot consistently
improves the performance of various visuomotor policies in both simulation and
real-world settings, highlighting the benefits of spatially grounded visual
feedback.

</details>


### [57] [COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models](https://arxiv.org/abs/2508.08144)
*Ganesh Sundaram,Jonas Ulmen,Amjad Haider,Daniel Görges*

Main category: cs.RO

TL;DR: 本文提出了一种基于组件感知结构化剪枝的模型压缩方法，用于在资源受限的移动平台上部署神经网络控制器（NNCs），同时保持控制性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 随着移动机器人、可穿戴设备和物联网设备等资源受限平台的快速发展，对计算高效的神经网络控制器的需求增加，但深度神经网络的高计算复杂性和内存需求限制了其实际部署。

Method: 采用组件感知结构化剪枝方法，结合数学稳定性保证（如Lyapunov准则），在时间差分模型预测控制（TD-MPC）算法上进行系统评估。

Result: 实验验证表明，该方法能显著降低模型复杂度，同时保持控制性能和稳定性，并确定了安全压缩比的理论界限。

Conclusion: 该框架为模型压缩提供了理论界限，确保在资源受限环境中安全部署压缩后的神经网络控制器。

Abstract: The rapid growth of resource-constrained mobile platforms, including mobile
robots, wearable systems, and Internet-of-Things devices, has increased the
demand for computationally efficient neural network controllers (NNCs) that can
operate within strict hardware limitations. While deep neural networks (DNNs)
demonstrate superior performance in control applications, their substantial
computational complexity and memory requirements present significant barriers
to practical deployment on edge devices. This paper introduces a comprehensive
model compression methodology that leverages component-aware structured pruning
to determine the optimal pruning magnitude for each pruning group, ensuring a
balance between compression and stability for NNC deployment. Our approach is
rigorously evaluated on Temporal Difference Model Predictive Control (TD-MPC),
a state-of-the-art model-based reinforcement learning algorithm, with a
systematic integration of mathematical stability guarantee properties,
specifically Lyapunov criteria. The key contribution of this work lies in
providing a principled framework for determining the theoretical limits of
model compression while preserving controller stability. Experimental
validation demonstrates that our methodology successfully reduces model
complexity while maintaining requisite control performance and stability
characteristics. Furthermore, our approach establishes a quantitative boundary
for safe compression ratios, enabling practitioners to systematically determine
the maximum permissible model reduction before violating critical stability
properties, thereby facilitating the confident deployment of compressed NNCs in
resource-limited environments.

</details>


### [58] [Verti-Arena: A Controllable and Standardized Indoor Testbed for Multi-Terrain Off-Road Autonomy](https://arxiv.org/abs/2508.08226)
*Haiyue Chen,Aniket Datar,Tong Xu,Francesco Cancelliere,Harsh Rangwala,Madhan Balaji Rao,Daeun Song,David Eichinger,Xuesu Xiao*

Main category: cs.RO

TL;DR: Verti-Arena是一个可重构的室内设施，旨在为越野自主性研究提供标准化测试环境，支持可重复实验和远程协作。


<details>
  <summary>Details</summary>
Motivation: 越野导航对移动机器人至关重要，但缺乏可控且标准化的真实测试环境限制了研究进展。

Method: 开发Verti-Arena设施，配备传感器和运动捕捉系统，提供精确地面真实数据，并支持远程实验。

Result: Verti-Arena为越野自主性研究提供了可重复的基准环境和标准化数据收集。

Conclusion: Verti-Arena填补了越野自主性研究中的测试环境空白，促进了全球协作和算法比较。

Abstract: Off-road navigation is an important capability for mobile robots deployed in
environments that are inaccessible or dangerous to humans, such as disaster
response or planetary exploration. Progress is limited due to the lack of a
controllable and standardized real-world testbed for systematic data collection
and validation. To fill this gap, we introduce Verti-Arena, a reconfigurable
indoor facility designed specifically for off-road autonomy. By providing a
repeatable benchmark environment, Verti-Arena supports reproducible experiments
across a variety of vertically challenging terrains and provides precise ground
truth measurements through onboard sensors and a motion capture system.
Verti-Arena also supports consistent data collection and comparative evaluation
of algorithms in off-road autonomy research. We also develop a web-based
interface that enables research groups worldwide to remotely conduct
standardized off-road autonomy experiments on Verti-Arena.

</details>


### [59] [ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks](https://arxiv.org/abs/2508.08240)
*Kaijun Wang,Liqin Lu,Mingyu Liu,Jianuo Jiang,Zeju Li,Bolin Zhang,Wancai Zheng,Xinyi Yu,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: ODYSSEY是一个统一的移动操作框架，结合了高级任务规划和低级全身控制，解决了语言引导的长时程移动操作中的感知、泛化和控制问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在移动平台的感知范围、泛化能力和控制精度方面存在局限，ODYSSEY旨在解决这些挑战。

Method: 引入分层规划器和视觉语言模型进行任务分解，结合新型全身控制策略实现协调操作。

Result: 通过仿真到现实的转移验证了系统在非结构化环境中的泛化能力和鲁棒性。

Conclusion: ODYSSEY推动了通用机器人助手在复杂动态任务中的可行性。

Abstract: Language-guided long-horizon mobile manipulation has long been a grand
challenge in embodied semantic reasoning, generalizable manipulation, and
adaptive locomotion. Three fundamental limitations hinder progress: First,
although large language models have improved spatial reasoning and task
planning through semantic priors, existing implementations remain confined to
tabletop scenarios, failing to address the constrained perception and limited
actuation ranges of mobile platforms. Second, current manipulation strategies
exhibit insufficient generalization when confronted with the diverse object
configurations encountered in open-world environments. Third, while crucial for
practical deployment, the dual requirement of maintaining high platform
maneuverability alongside precise end-effector control in unstructured settings
remains understudied.
  In this work, we present ODYSSEY, a unified mobile manipulation framework for
agile quadruped robots equipped with manipulators, which seamlessly integrates
high-level task planning with low-level whole-body control. To address the
challenge of egocentric perception in language-conditioned tasks, we introduce
a hierarchical planner powered by a vision-language model, enabling
long-horizon instruction decomposition and precise action execution. At the
control level, our novel whole-body policy achieves robust coordination across
challenging terrains. We further present the first benchmark for long-horizon
mobile manipulation, evaluating diverse indoor and outdoor scenarios. Through
successful sim-to-real transfer, we demonstrate the system's generalization and
robustness in real-world deployments, underscoring the practicality of legged
manipulators in unstructured environments. Our work advances the feasibility of
generalized robotic assistants capable of complex, dynamic tasks. Our project
page: https://kaijwang.github.io/odyssey.github.io/

</details>


### [60] [BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion](https://arxiv.org/abs/2508.08241)
*Takara E. Truong,Qiayuan Liao,Xiaoyu Huang,Guy Tevet,C. Karen Liu,Koushil Sreenath*

Main category: cs.RO

TL;DR: BeyondMimic 是一个从人类动作中学习的框架，通过引导扩散技术实现多功能、自然的人形机器人控制，解决了高质量动作跟踪和动作原语学习的两个关键问题。


<details>
  <summary>Details</summary>
Motivation: 从人类动作中学习技能为全身人形机器人控制提供了通用策略的潜力，但缺乏高质量的动作跟踪框架和有效的动作原语学习方法。

Method: 提出 BeyondMimic 框架，包括一个能够处理高动态动作的跟踪管道和一个统一的扩散策略，支持零样本任务控制。

Result: 在硬件上实现了多样任务，如导航、遥操作和避障，展示了高质量的动作跟踪和灵活的动作合成能力。

Conclusion: BeyondMimic 填补了动作跟踪和动作原语学习的空白，为全身人形机器人控制提供了新方向。

Abstract: Learning skills from human motions offers a promising path toward
generalizable policies for whole-body humanoid control, yet two key
cornerstones are missing: (1) a high-quality motion tracking framework that
faithfully transforms large-scale kinematic references into robust and
extremely dynamic motions on real hardware, and (2) a distillation approach
that can effectively learn these motion primitives and compose them to solve
downstream tasks. We address these gaps with BeyondMimic, the first real-world
framework to learn from human motions for versatile and naturalistic humanoid
control via guided diffusion. Our framework provides a motion tracking pipeline
capable of challenging skills such as jumping spins, sprinting, and cartwheels
with state-of-the-art motion quality. Moving beyond mimicking existing motions
and synthesize novel ones, we further introduce a unified diffusion policy that
enables zero-shot task-specific control at test time using simple cost
functions. Deployed on hardware, BeyondMimic performs diverse tasks at test
time, including waypoint navigation, joystick teleoperation, and obstacle
avoidance, bridging sim-to-real motion tracking and flexible synthesis of human
motion primitives for whole-body control. https://beyondmimic.github.io/.

</details>


### [61] [UPP: Unified Path Planner with Adaptive Safety and Optimality](https://arxiv.org/abs/2505.23197)
*Jatin Kumar Arora,Shubhendu Bhasin*

Main category: cs.RO

TL;DR: 提出了一种统一路径规划器（UPP），通过改进启发式和动态安全成本函数，同时兼顾安全性和最优性。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划算法多专注于最优性或安全性，缺乏同时解决两者的研究。

Method: 使用改进的启发式和动态安全成本函数，通过可调参数平衡安全性和计算复杂度。

Result: 仿真和实际测试（TurtleBot）表明，UPP能在不同场景中实现安全且接近最优的路径规划。

Conclusion: UPP为路径规划提供了一种兼顾安全性和最优性的新方法，具有实际应用潜力。

Abstract: We are surrounded by robots helping us perform complex tasks. Robots have a
wide range of applications, from industrial automation to personalized
assistance. However, with great technological innovation come significant
challenges. One of the major challenges in robotics is path planning. Despite
advancements such as graph search, sampling, and potential field methods, most
path planning algorithms focus either on optimality or on safety. Very little
research addresses both simultaneously. We propose a Unified Path Planner (UPP)
that uses modified heuristics and a dynamic safety cost function to balance
safety and optimality. The level of safety can be adjusted via tunable
parameters, trading off against computational complexity. We demonstrate the
planner's performance in simulations, showing how parameter variation affects
results. UPP is compared with various traditional and safe-optimal planning
algorithms across different scenarios. We also validate it on a TurtleBot,
where the robot successfully finds safe and sub-optimal paths.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [62] [Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization](https://arxiv.org/abs/2508.06559)
*Sina Baghal*

Main category: cs.AI

TL;DR: 本文介绍了一个基于CUDA加速的Pasur纸牌游戏计算框架，通过高效内存管理和CFR算法求解近纳什均衡，并训练树模型用于实际游戏。


<details>
  <summary>Details</summary>
Motivation: Pasur游戏的复杂规则和大规模游戏树带来了独特的计算挑战，需要高效的内存管理和计算优化。

Method: 使用PyTorch CUDA张量处理规则复杂性，通过分解游戏树和轮次逆向训练策略降低内存开销，构建包含超过10^9节点的完整游戏树。

Result: 成功计算了近纳什均衡策略，并通过大规模自对弈估计了每副牌的公平价值。

Conclusion: 该框架可扩展至其他多轮次强化学习场景，如回合制策略游戏或金融市场顺序交易决策。

Abstract: Pasur is a fishing card game played over six rounds and is played similarly
to games such as Cassino and Scopa, and Bastra. This paper introduces a
CUDA-accelerated computational framework for simulating Pasur, emphasizing
efficient memory management. We use our framework to compute near-Nash
equilibria via Counterfactual Regret Minimization (CFR), a well-known algorithm
for solving large imperfect-information games.
  Solving Pasur presents unique challenges due to its intricate rules and the
large size of its game tree. We handle rule complexity using PyTorch CUDA
tensors and to address the memory-intensive nature of the game, we decompose
the game tree into two key components: (1) actual game states, and (2)
inherited scores from previous rounds. We construct the Full Game Tree by
pairing card states with accumulated scores in the Unfolding Process. This
design reduces memory overhead by storing only essential strategy values and
node connections. To further manage computational complexity, we apply a
round-by-round backward training strategy, starting from the final round and
recursively propagating average utilities to earlier stages. Our approach
constructs the complete game tree, which on average consists of over $10^9$
nodes. We provide detailed implementation snippets.
  After computing a near-Nash equilibrium strategy, we train a tree-based model
to predict these strategies for use during gameplay. We then estimate the fair
value of each deck through large-scale self-play between equilibrium strategies
by simulating, for instance, 10,000 games per matchup, executed in parallel
using GPU acceleration.
  Similar frameworks can be extended to other reinforcement learning algorithms
where the action tree naturally decomposes into multiple rounds such as
turn-based strategy games or sequential trading decisions in financial markets.

</details>


### [63] [Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop](https://arxiv.org/abs/2508.06569)
*Lance Yao,Suman Samantray,Ayana Ghosh,Kevin Roccapriore,Libor Kovarik,Sarah Allec,Maxim Ziatdinov*

Main category: cs.AI

TL;DR: SciLink是一个开源多智能体AI框架，旨在通过自动化链接实验观察、新颖性评估和理论模拟，促进材料研究中的意外发现。


<details>
  <summary>Details</summary>
Motivation: 现代自主实验室虽然能高效验证假设，但可能忽略意外发现。SciLink旨在填补这一空白，通过AI框架系统化地捕捉和分析意外观察。

Method: 采用混合AI策略，结合机器学习模型进行定量分析和大型语言模型进行高层推理，将原始数据转化为可验证的科学主张，并根据文献评估新颖性。

Result: SciLink在多种研究场景中展示了其多功能性，包括原子分辨率和超光谱数据处理、实时整合专家指导以及提出针对性后续实验。

Conclusion: SciLink不仅提高了研究效率，还通过系统化分析所有观察结果，为意外发现创造了有利环境，弥合了自动化实验与开放式科学探索之间的差距。

Abstract: The history of science is punctuated by serendipitous discoveries, where
unexpected observations, rather than targeted hypotheses, opened new fields of
inquiry. While modern autonomous laboratories excel at accelerating hypothesis
testing, their optimization for efficiency risks overlooking these crucial,
unplanned findings. To address this gap, we introduce SciLink, an open-source,
multi-agent artificial intelligence framework designed to operationalize
serendipity in materials research by creating a direct, automated link between
experimental observation, novelty assessment, and theoretical simulations. The
framework employs a hybrid AI strategy where specialized machine learning
models perform quantitative analysis of experimental data, while large language
models handle higher-level reasoning. These agents autonomously convert raw
data from materials characterization techniques into falsifiable scientific
claims, which are then quantitatively scored for novelty against the published
literature. We demonstrate the framework's versatility across diverse research
scenarios, showcasing its application to atomic-resolution and hyperspectral
data, its capacity to integrate real-time human expert guidance, and its
ability to close the research loop by proposing targeted follow-up experiments.
By systematically analyzing all observations and contextualizing them, SciLink
provides a practical framework for AI-driven materials research that not only
enhances efficiency but also actively cultivates an environment ripe for
serendipitous discoveries, thereby bridging the gap between automated
experimentation and open-ended scientific exploration.

</details>


### [64] [IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model](https://arxiv.org/abs/2508.06571)
*Anqing Jiang,Yu Gao,Yiru Wang,Zhigang Sun,Shuo Wang,Yuwen Heng,Hao Sun,Shichen Tang,Lijuan Zhu,Jinhao Chai,Jijun Wang,Zichong Gu,Hao Jiang,Li Sun*

Main category: cs.AI

TL;DR: 论文提出了IRL-VLA框架，通过三阶段方法解决VLA模型在自动驾驶中的闭环训练问题，结合模仿学习和逆强化学习，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在开环模仿学习中表现受限，闭环训练依赖高保真模拟器且效率低，亟需新方法解决这些问题。

Method: 1. 模仿学习预训练VLA策略；2. 逆强化学习构建轻量级奖励世界模型；3. PPO优化奖励模型指导的强化学习。

Result: 在NAVSIM v2和CVPR2025竞赛中取得领先成绩。

Conclusion: IRL-VLA框架为闭环自动驾驶的VLA研究提供了高效解决方案。

Abstract: Vision-Language-Action (VLA) models have demonstrated potential in autonomous
driving. However, two critical challenges hinder their development: (1)
Existing VLA architectures are typically based on imitation learning in
open-loop setup which tends to capture the recorded behaviors in the dataset,
leading to suboptimal and constrained performance, (2) Close-loop training
relies heavily on high-fidelity sensor simulation, where domain gaps and
computational inefficiencies pose significant barriers. In this paper, we
introduce IRL-VLA, a novel close-loop Reinforcement Learning via
\textbf{I}nverse \textbf{R}einforcement \textbf{L}earning reward world model
with a self-built VLA approach. Our framework proceeds in a three-stage
paradigm: In the first stage, we propose a VLA architecture and pretrain the
VLA policy via imitation learning. In the second stage, we construct a
lightweight reward world model via inverse reinforcement learning to enable
efficient close-loop reward computation. To further enhance planning
performance, finally, we design specialized reward world model guidence
reinforcement learning via PPO(Proximal Policy Optimization) to effectively
balance the safety incidents, comfortable driving, and traffic efficiency. Our
approach achieves state-of-the-art performance in NAVSIM v2 end-to-end driving
benchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge. We hope that
our framework will accelerate VLA research in close-loop autonomous driving.

</details>


### [65] [CountQA: How Well Do MLLMs Count in the Wild?](https://arxiv.org/abs/2508.06585)
*Jayant Sravan Tamarapalli,Rynaa Grover,Nilay Pande,Sahiti Yerramilli*

Main category: cs.AI

TL;DR: 多模态大语言模型（MLLMs）在视觉场景理解上表现流畅，但在对象计数能力上存在显著缺陷。CountQA是一个新基准，用于评估和提升MLLMs的计数能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在对象计数方面表现不佳，且缺乏复杂场景的评估基准，限制了其实际应用可靠性。

Method: 引入CountQA基准，包含1,500多个问题-答案对，覆盖高密度、杂乱和遮挡的真实世界图像。评估了15种主流MLLMs。

Result: 表现最佳的模型准确率仅为42.9%，且随着对象数量增加性能下降。

Conclusion: CountQA为诊断和解决MLLMs计数缺陷提供了工具，推动未来模型在数值和空间感知上的进步。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in
understanding visual scenes, yet they exhibit a critical lack in a fundamental
cognitive skill: object counting. This blind spot severely limits their
reliability in real-world applications. To date, this capability has been
largely unevaluated in complex scenarios, as existing benchmarks either feature
sparse object densities or are confined to specific visual domains, failing to
test models under realistic conditions. Addressing this gap, we introduce
CountQA, a challenging new benchmark designed to probe this deficiency.
Comprising over 1,500 question-answer pairs, CountQA features real-world images
with high object density, clutter, and occlusion. We investigate this weakness
by evaluating 15 prominent MLLMs on the CountQA benchmark and reveal that the
top-performing model achieves a mere 42.9% accuracy, with performance declining
as object counts rise. By providing a dedicated benchmark to diagnose and
rectify this core weakness, CountQA paves the way for a new generation of MLLMs
that are not only descriptively fluent but also numerically grounded and
spatially aware. We will open-source the dataset and code upon paper acceptance
to foster further research.

</details>


### [66] [Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis](https://arxiv.org/abs/2508.06668)
*Jessie Galasso*

Main category: cs.AI

TL;DR: 本文探讨了形式概念分析（FCA）在变异性分析中的关键属性及其应用方法。


<details>
  <summary>Details</summary>
Motivation: FCA在知识表示和发现中具有潜力，但其数学基础文献使其在变异性任务中的应用不够直观。本文旨在填补这一空白。

Method: 通过筛选FCA框架中对变异性分析至关重要的属性，并解释其在概念结构中的变异性信息。

Result: 明确了FCA中可用于变异性分析的关键属性及其应用方式。

Conclusion: FCA的属性可用于有效解释和分析变异性信息，为相关任务提供支持。

Abstract: Formal Concept Analysis (FCA) is a mathematical framework for knowledge
representation and discovery. It performs a hierarchical clustering over a set
of objects described by attributes, resulting in conceptual structures in which
objects are organized depending on the attributes they share. These conceptual
structures naturally highlight commonalities and variabilities among similar
objects by categorizing them into groups which are then arranged by similarity,
making it particularly appropriate for variability extraction and analysis.
Despite the potential of FCA, determining which of its properties can be
leveraged for variability-related tasks (and how) is not always
straightforward, partly due to the mathematical orientation of its foundational
literature. This paper attempts to bridge part of this gap by gathering a
selection of properties of the framework which are essential to variability
analysis, and how they can be used to interpret diverse variability information
within the resulting conceptual structures.

</details>


### [67] [Zero-Shot Cellular Trajectory Map Matching](https://arxiv.org/abs/2508.06674)
*Weijie Shi,Yue Cui,Hao Chen,Jiaming Li,Mengze Li,Jia Zhu,Jiajie Xu,Xiaofang Zhou*

Main category: cs.AI

TL;DR: 提出了一种基于像素的轨迹校准辅助方法，用于零样本蜂窝轨迹地图匹配（CTMM），通过迁移地理空间知识校准轨迹，并结合高斯混合模型和时空感知模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有CTMM方法依赖区域特定数据和ID特征，难以适应未探索区域，需开发无需额外训练的零样本方法。

Method: 结合像素轨迹校准、高斯混合模型的VAE、时空感知模块和约束路径查找算法。

Result: 实验表明，模型在零样本CTMM中性能优于现有方法16.8%。

Conclusion: 该方法通过知识迁移和误差缓解技术，实现了高精度的零样本CTMM。

Abstract: Cellular Trajectory Map-Matching (CTMM) aims to align cellular location
sequences to road networks, which is a necessary preprocessing in
location-based services on web platforms like Google Maps, including navigation
and route optimization. Current approaches mainly rely on ID-based features and
region-specific data to learn correlations between cell towers and roads,
limiting their adaptability to unexplored areas. To enable high-accuracy CTMM
without additional training in target regions, Zero-shot CTMM requires to
extract not only region-adaptive features, but also sequential and location
uncertainty to alleviate positioning errors in cellular data. In this paper, we
propose a pixel-based trajectory calibration assistant for zero-shot CTMM,
which takes advantage of transferable geospatial knowledge to calibrate
pixelated trajectory, and then guide the path-finding process at the road
network level. To enhance knowledge sharing across similar regions, a Gaussian
mixture model is incorporated into VAE, enabling the identification of
scenario-adaptive experts through soft clustering. To mitigate high positioning
errors, a spatial-temporal awareness module is designed to capture sequential
features and location uncertainty, thereby facilitating the inference of
approximate user positions. Finally, a constrained path-finding algorithm is
employed to reconstruct the road ID sequence, ensuring topological validity
within the road network. This process is guided by the calibrated trajectory
while optimizing for the shortest feasible path, thus minimizing unnecessary
detours. Extensive experiments demonstrate that our model outperforms existing
methods in zero-shot CTMM by 16.8\%.

</details>


### [68] [Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets](https://arxiv.org/abs/2508.06706)
*Jaikrishna Manojkumar Patil,Nathaniel Lee,Al Mehdi Saadat Chowdhury,YooJung Choi,Paulo Shakarian*

Main category: cs.AI

TL;DR: 论文提出了一种基于规则上下文和概率电路的方法，显著减少了知识图谱补全所需的规则数量，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 规则方法虽然可解释，但需要大量规则才能达到高性能，导致规则集过大反而影响可解释性。

Method: 从训练数据中发现规则上下文，并利用概率电路学习其分布，快速实现全规则集的性能。

Result: 规则数量减少70-96%，性能提升31倍，保留基线91%的峰值性能。

Conclusion: 该方法在8个基准数据集上验证有效，为基于规则的推理提供了新思路。

Abstract: Rule-based methods for knowledge graph completion provide explainable results
but often require a significantly large number of rules to achieve competitive
performance. This can hinder explainability due to overwhelmingly large rule
sets. We discover rule contexts (meaningful subsets of rules that work
together) from training data and use learned probability distribution (i.e.
probabilistic circuits) over these rule contexts to more rapidly achieve
performance of the full rule set. Our approach achieves a 70-96% reduction in
number of rules used while outperforming baseline by up to 31$\times$ when
using equivalent minimal number of rules and preserves 91% of peak baseline
performance even when comparing our minimal rule sets against baseline's full
rule sets. We show that our framework is grounded in well-known semantics of
probabilistic logic, does not require independence assumptions, and that our
tractable inference procedure provides both approximate lower bounds and exact
probability of a given query. The efficacy of our method is validated by
empirical studies on 8 standard benchmark datasets where we show competitive
performance by using only a fraction of the rules required by AnyBURL's
standard inference method, the current state-of-the-art for rule-based
knowledge graph completion. This work may have further implications for general
probabilistic reasoning over learned sets of rules.

</details>


### [69] [GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning](https://arxiv.org/abs/2508.06716)
*Blair Johnson,Clayton Kerce,Faramarz Fekri*

Main category: cs.AI

TL;DR: GLIDR是一种可微分的规则学习方法，通过更丰富的语法结构（如分支和循环）改进知识图谱任务中的规则学习，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有链式规则结构限制了性能和可解释性，GLIDR旨在通过更灵活的规则语法提升效果。

Method: GLIDR使用可微分消息传递算法，支持复杂规则结构，并通过自由变量数量限制规则搜索空间。

Result: GLIDR在知识图谱补全任务中显著优于现有规则学习方法，甚至可与嵌入方法竞争，且对噪声数据鲁棒。

Conclusion: GLIDR不仅高效且可解释，还能与深度学习结合进行端到端优化，适用于多模态数据。

Abstract: Differentiable inductive logic programming (ILP) techniques have proven
effective at finding approximate rule-based solutions to link prediction and
node classification problems on knowledge graphs; however, the common
assumption of chain-like rule structure can hamper the performance and
interpretability of existing approaches. We introduce GLIDR, a differentiable
rule learning method that models the inference of logic rules with more
expressive syntax than previous methods. GLIDR uses a differentiable message
passing inference algorithm that generalizes previous chain-like rule learning
methods to allow rules with features like branches and cycles. GLIDR has a
simple and expressive rule search space which is parameterized by a limit on
the maximum number of free variables that may be included in a rule. Explicit
logic rules can be extracted from the weights of a GLIDR model for use with
symbolic solvers. We demonstrate that GLIDR can significantly outperform
existing rule learning methods on knowledge graph completion tasks and even
compete with embedding methods despite the inherent disadvantage of being a
structure-only prediction method. We show that rules extracted from GLIDR
retain significant predictive performance, and that GLIDR is highly robust to
training data noise. Finally, we demonstrate that GLIDR can be chained with
deep neural networks and optimized end-to-end for rule learning on arbitrary
data modalities.

</details>


### [70] [ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search](https://arxiv.org/abs/2508.06736)
*Alican Yilmaz,Junyang Cai,Serdar Kadioglu,Bistra Dilkina*

Main category: cs.AI

TL;DR: 论文研究了Balans的并行化能力，提出ParBalans，结合求解器和算法级并行，显著提升MIP求解性能。


<details>
  <summary>Details</summary>
Motivation: 混合整数规划（MIP）问题计算资源需求高，并行化是加速求解的关键策略。Balans的并行潜力尚未充分探索。

Method: 扩展Balans为ParBalans，利用求解器和算法级并行，优化复杂MIP实例的求解。

Result: 实验显示ParBalans在硬优化基准测试中表现优于商业求解器Gurobi。

Conclusion: ParBalans通过并行化显著提升MIP求解效率，具有竞争力。

Abstract: Solving Mixed-Integer Programming (MIP) problems often requires substantial
computational resources due to their combinatorial nature. Parallelization has
emerged as a critical strategy to accelerate solution times and enhance
scalability to tackle large, complex instances. This paper investigates the
parallelization capabilities of Balans, a recently proposed multi-armed
bandits-based adaptive large neighborhood search for MIPs. While Balans's
modular architecture inherently supports parallel exploration of diverse
parameter configurations, this potential has not been thoroughly examined. To
address this gap, we introduce ParBalans, an extension that leverages both
solver-level and algorithmic-level parallelism to improve performance on
challenging MIP instances. Our experimental results demonstrate that ParBalans
exhibits competitive performance compared to the state-of-the-art commercial
solver Gurobi, particularly on hard optimization benchmarks.

</details>


### [71] [Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism](https://arxiv.org/abs/2508.06746)
*Xin Tang,Qian Chen,Fengshun Li,Youchun Gong,Yinqiu Liu,Wen Tian,Shaowen Qin,Xiaohuan Li*

Main category: cs.AI

TL;DR: 本文提出了一种结合图扩散策略优化（GDPO）和Stackelberg博弈（SG）激励机制的无人机网络框架，以解决动态移动性和隐蔽通信的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着无人机网络在敏感应用中的需求增长，确保可靠连接和隐蔽通信变得至关重要，但动态移动性和暴露风险带来了显著挑战。

Method: 采用GDPO方法生成稀疏但连接良好的拓扑结构，并结合SG激励机制引导无人机选择支持合作的转发行为和邻居链接。

Result: 实验验证了框架在模型收敛性、拓扑生成质量和隐蔽通信性能提升方面的有效性。

Conclusion: 该框架能有效适应动态环境并提升无人机网络的隐蔽通信能力。

Abstract: With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in
sensitive applications, such as urban monitoring, emergency response, and
secure sensing, ensuring reliable connectivity and covert communication has
become increasingly vital. However, dynamic mobility and exposure risks pose
significant challenges. To tackle these challenges, this paper proposes a
self-organizing UAV network framework combining Graph Diffusion-based Policy
Optimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism. The
GDPO method uses generative AI to dynamically generate sparse but
well-connected topologies, enabling flexible adaptation to changing node
distributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game
(SG)-based incentive mechanism guides self-interested UAVs to choose relay
behaviors and neighbor links that support cooperation and enhance covert
communication. Extensive experiments are conducted to validate the
effectiveness of the proposed framework in terms of model convergence, topology
generation quality, and enhancement of covert communication performance.

</details>


### [72] [Pushing the Envelope of LLM Inference on AI-PC](https://arxiv.org/abs/2508.06753)
*Evangelos Georganas,Dhiraj Kalamkar,Alexander Heinecke*

Main category: cs.AI

TL;DR: 论文提出了一种针对1/1.58/2位超低比特LLM模型的优化微内核，集成到PyTorch-TPP框架中，显著提升了推理效率。


<details>
  <summary>Details</summary>
Motivation: 超低比特LLM模型在资源受限环境中具有潜力，但现有推理运行时的计算效率未被充分探索。

Method: 设计并实现针对现代CPU优化的1位和2位微内核，集成到PyTorch-TPP框架中。

Result: 2位模型推理效率比当前SOTA运行时bitnet.cpp快2.2倍，比16位模型快7倍。

Conclusion: 优化后的运行为AI PC和边缘设备上的LLM推理提供了高效部署方案。

Abstract: The advent of ultra-low-bit LLM models (1/1.58/2-bit), which match the
perplexity and end-task performance of their full-precision counterparts using
the same model size, is ushering in a new era of LLM inference for
resource-constrained environments such as edge devices and AI PCs. While these
quantization advances promise models that are more cost-effective in terms of
latency, memory, throughput, and energy consumption, the computational
efficiency of state-of-the-art (SOTA) inference runtimes (e.g., bitnet.cpp)
used to deploy them remains underexplored. In this work, we take a bottom-up
approach: we first design and implement 1-bit and 2-bit microkernels optimized
for modern CPUs, achieving peak computational efficiency across a variety of
CPU platforms. We integrate these microkernels into a state-of-the-art LLM
inference framework, namely PyTorch-TPP, and present end-to-end inference
results with 2-bit models that outperform the current SOTA runtime bitnet.cpp
by up to 2.2x, and deliver up to 7x speedup compared to the 16-bit model
inference. Our optimized runtime advances the state of LLM inference on AI PCs
and edge devices, paving the way for efficient deployment of ultra-low-bit LLM
models.

</details>


### [73] [A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks](https://arxiv.org/abs/2508.06754)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 提出了一种模块化提示框架，支持在动态、用户中心任务中更安全、自适应地使用大语言模型（LLMs）。


<details>
  <summary>Details</summary>
Motivation: 基于人类学习理论（如最近发展区ZPD），旨在提升LLMs在用户状态变化时的行为调节能力，无需微调或外部协调。

Method: 结合自然语言边界提示与控制模式，采用模糊支架逻辑和适应规则，实现LLMs的自适应行为调节。

Result: 在模拟智能辅导环境中，框架显著提升了支架质量、适应性和教学对齐性，优于标准提示基线。

Conclusion: 该框架不仅适用于教育领域，还可扩展至其他交互密集型场景（如游戏内容生成），为不确定或动态环境中的LLM行为提供可解释、目标对齐的方法。

Abstract: We introduce a modular prompting framework that supports safer and more
adaptive use of large language models (LLMs) across dynamic, user-centered
tasks. Grounded in human learning theory, particularly the Zone of Proximal
Development (ZPD), our method combines a natural language boundary prompt with
a control schema encoded with fuzzy scaffolding logic and adaptation rules.
This architecture enables LLMs to modulate behavior in response to user state
without requiring fine-tuning or external orchestration. In a simulated
intelligent tutoring setting, the framework improves scaffolding quality,
adaptivity, and instructional alignment across multiple models, outperforming
standard prompting baselines. Evaluation is conducted using rubric-based LLM
graders at scale. While initially developed for education, the framework has
shown promise in other interaction-heavy domains, such as procedural content
generation for games. Designed for safe deployment, it provides a reusable
methodology for structuring interpretable, goal-aligned LLM behavior in
uncertain or evolving contexts.

</details>


### [74] [Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation](https://arxiv.org/abs/2508.06823)
*Xuan Zhao,Jun Tao*

Main category: cs.AI

TL;DR: 提出了一种基于自然语言交互的框架，通过CLIP Score机制和强化学习优化体数据探索的视角选择。


<details>
  <summary>Details</summary>
Motivation: 体数据探索对科学数据分析至关重要，但缺乏领域知识或3D导航经验的用户难以选择最佳视角。

Method: 将体数据块编码以区分结构，结合CLIP Score提供语义信息，利用强化学习框架搜索符合用户意图的视角。

Result: 自动化视角选择提高了体数据导航效率，并增强了复杂科学现象的可解释性。

Conclusion: 该方法通过自然语言交互和语义引导，显著改善了体数据探索的效率和用户体验。

Abstract: Exploring volumetric data is crucial for interpreting scientific datasets.
However, selecting optimal viewpoints for effective navigation can be
challenging, particularly for users without extensive domain expertise or
familiarity with 3D navigation. In this paper, we propose a novel framework
that leverages natural language interaction to enhance volumetric data
exploration. Our approach encodes volumetric blocks to capture and
differentiate underlying structures. It further incorporates a CLIP Score
mechanism, which provides semantic information to the blocks to guide
navigation. The navigation is empowered by a reinforcement learning framework
that leverage these semantic cues to efficiently search for and identify
desired viewpoints that align with the user's intent. The selected viewpoints
are evaluated using CLIP Score to ensure that they best reflect the user
queries. By automating viewpoint selection, our method improves the efficiency
of volumetric data navigation and enhances the interpretability of complex
scientific phenomena.

</details>


### [75] [Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges](https://arxiv.org/abs/2508.06832)
*Haifeng Li,Wang Guo,Haiyang Wu,Mengwei Wu,Jipeng Zhang,Qing Zhu,Yu Liu,Xin Huang,Chao Tao*

Main category: cs.AI

TL;DR: 论文提出从视觉为中心转向语言为中心的遥感图像解释框架，借鉴全球工作空间理论（GWT），将大语言模型（LLMs）作为认知中枢，整合感知、任务、知识和行动空间，实现统一理解、推理和决策。


<details>
  <summary>Details</summary>
Motivation: 现有视觉为中心的遥感图像解释模型在多模态推理、语义抽象和交互决策方面存在局限，缺乏统一理论框架解释语言在认知中的作用。

Method: 提出语言为中心的框架，以LLMs为核心，整合多模态表示、知识关联、推理与决策，构建全局工作空间驱动的解释机制。

Result: 总结了语言为中心解决方案如何应对核心挑战，包括统一多模态表示、知识关联及推理决策。

Conclusion: 未来研究方向包括多模态数据自适应对齐、动态知识约束下的任务理解、可信推理和自主交互，为下一代遥感解释系统提供理论基础。

Abstract: The mainstream paradigm of remote sensing image interpretation has long been
dominated by vision-centered models, which rely on visual features for semantic
understanding. However, these models face inherent limitations in handling
multi-modal reasoning, semantic abstraction, and interactive decision-making.
While recent advances have introduced Large Language Models (LLMs) into remote
sensing workflows, existing studies primarily focus on downstream applications,
lacking a unified theoretical framework that explains the cognitive role of
language. This review advocates a paradigm shift from vision-centered to
language-centered remote sensing interpretation. Drawing inspiration from the
Global Workspace Theory (GWT) of human cognition, We propose a
language-centered framework for remote sensing interpretation that treats LLMs
as the cognitive central hub integrating perceptual, task, knowledge and action
spaces to enable unified understanding, reasoning, and decision-making. We
first explore the potential of LLMs as the central cognitive component in
remote sensing interpretation, and then summarize core technical challenges,
including unified multimodal representation, knowledge association, and
reasoning and decision-making. Furthermore, we construct a global
workspace-driven interpretation mechanism and review how language-centered
solutions address each challenge. Finally, we outline future research
directions from four perspectives: adaptive alignment of multimodal data, task
understanding under dynamic knowledge constraints, trustworthy reasoning, and
autonomous interaction. This work aims to provide a conceptual foundation for
the next generation of remote sensing interpretation systems and establish a
roadmap toward cognition-driven intelligent geospatial analysis.

</details>


### [76] [Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.06836)
*Xutong Zhao,Yaqi Xie*

Main category: cs.AI

TL;DR: 论文提出了一种多级优势信用分配方法（MACA），用于解决多智能体强化学习中的信用分配问题，通过多级优势函数和注意力机制捕捉不同协作层次的贡献。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）中的信用分配是一个关键挑战，尤其是在任务多样性和智能体协作层次复杂的情况下。

Method: MACA通过多级优势函数进行显式反事实推理，结合注意力机制识别智能体间的相关性，构建多级优势以指导策略学习。

Result: 在Starcraft v1&v2任务上的实验表明，MACA在复杂信用分配场景中表现优异。

Conclusion: MACA通过多级优势信用分配，有效解决了多智能体协作中的信用分配问题，适用于多种协作层次的任务。

Abstract: Cooperative multi-agent reinforcement learning (MARL) aims to coordinate
multiple agents to achieve a common goal. A key challenge in MARL is credit
assignment, which involves assessing each agent's contribution to the shared
reward. Given the diversity of tasks, agents may perform different types of
coordination, with rewards attributed to diverse and often overlapping agent
subsets. In this work, we formalize the credit assignment level as the number
of agents cooperating to obtain a reward, and address scenarios with multiple
coexisting levels. We introduce a multi-level advantage formulation that
performs explicit counterfactual reasoning to infer credits across distinct
levels. Our method, Multi-level Advantage Credit Assignment (MACA), captures
agent contributions at multiple levels by integrating advantage functions that
reason about individual, joint, and correlated actions. Utilizing an
attention-based framework, MACA identifies correlated agent relationships and
constructs multi-level advantages to guide policy learning. Comprehensive
experiments on challenging Starcraft v1\&v2 tasks demonstrate MACA's superior
performance, underscoring its efficacy in complex credit assignment scenarios.

</details>


### [77] [MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams](https://arxiv.org/abs/2508.06851)
*Pengfei Zhou,Xiaopeng Peng,Fanrui Zhang,Zhaopan Xu,Jiaxin Ai,Yansheng Qiu,Chuanhao Li,Zhen Li,Ming Li,Yukang Feng,Jianwen Sun,Haoquan Zhang,Zizhen Li,Xiaofeng Mao,Zekai Li,Wangbo Zhao,Kai Wang,Xiaojun Chang,Wenqi Shao,Yang You,Kaipeng Zhang*

Main category: cs.AI

TL;DR: 论文介绍了MDK12-Bench，一个基于K-12考试的多学科大规模基准测试，用于全面评估多模态大语言模型（MLLMs）的性能，并提出动态评估框架和知识增强生成方法。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs的评测基准存在规模小、覆盖窄、知识无结构化等问题，无法全面评估模型性能。

Method: 构建MDK12-Bench基准，包含141K实例和6,225个知识点，提出动态评估框架和KP-RAG方法。

Result: 发现当前MLLMs在多个维度存在局限性，为模型鲁棒性和AI辅助教育提供指导。

Conclusion: MDK12-Bench为MLLMs的全面评估提供了新工具，揭示了模型不足并指明改进方向。

Abstract: Multimodal large language models (MLLMs), which integrate language and visual
cues for problem-solving, are crucial for advancing artificial general
intelligence (AGI). However, current benchmarks for measuring the intelligence
of MLLMs suffer from limited scale, narrow coverage, and unstructured
knowledge, offering only static and undifferentiated evaluations. To bridge
this gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark
built from real-world K-12 exams spanning six disciplines with 141K instances
and 6,225 knowledge points organized in a six-layer taxonomy. Covering five
question formats with difficulty and year annotations, it enables comprehensive
evaluation to capture the extent to which MLLMs perform over four dimensions:
1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts,
and 4) knowledge-driven reasoning. We propose a novel dynamic evaluation
framework that introduces unfamiliar visual, textual, and question form shifts
to challenge model generalization while improving benchmark objectivity and
longevity by mitigating data contamination. We further evaluate knowledge-point
reference-augmented generation (KP-RAG) to examine the role of knowledge in
problem-solving. Key findings reveal limitations in current MLLMs in multiple
aspects and provide guidance for enhancing model robustness, interpretability,
and AI-assisted education.

</details>


### [78] [MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction](https://arxiv.org/abs/2508.06859)
*Shuo Tang,Jian Xu,Jiadong Zhang,Yi Chen,Qizhao Jin,Lingdong Shen,Chenglin Liu,Shiming Xiang*

Main category: cs.AI

TL;DR: 论文提出了一种基于AI的端到端天气预警系统MP-Bench和气象多模态大模型（MMLM），解决了现有系统依赖人工、数据对齐不完善等问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前天气预警系统依赖专家手动解释，存在主观性和操作负担。AI技术的发展为自动化天气预测提供了新可能，但面临数据稀缺、高维气象数据与文本对齐困难等挑战。

Method: 提出MP-Bench数据集和MMLM模型，直接处理4D气象数据，并通过自适应融合模块动态提取和整合特征。

Result: 实验表明MMLM在多种任务中表现优异，验证了其在天气预测中的有效性。

Conclusion: MMLM为自动化AI天气预测系统迈出了关键一步，未来将公开源代码和数据集。

Abstract: Timely and accurate severe weather warnings are critical for disaster
mitigation. However, current forecasting systems remain heavily reliant on
manual expert interpretation, introducing subjectivity and significant
operational burdens. With the rapid development of AI technologies, the
end-to-end "AI weather station" is gradually emerging as a new trend in
predicting severe weather events. Three core challenges impede the development
of end-to-end AI severe weather system: (1) scarcity of severe weather event
samples; (2) imperfect alignment between high-dimensional meteorological data
and textual warnings; (3) existing multimodal language models are unable to
handle high-dimensional meteorological data and struggle to fully capture the
complex dependencies across temporal sequences, vertical pressure levels, and
spatial dimensions. To address these challenges, we introduce MP-Bench, the
first large-scale temporal multimodal dataset for severe weather events
prediction, comprising 421,363 pairs of raw multi-year meteorological data and
corresponding text caption, covering a wide range of severe weather scenarios
across China. On top of this dataset, we develop a meteorology multimodal large
model (MMLM) that directly ingests 4D meteorological inputs. In addition, it is
designed to accommodate the unique characteristics of 4D meteorological data
flow, incorporating three plug-and-play adaptive fusion modules that enable
dynamic feature extraction and integration across temporal sequences, vertical
pressure layers, and spatial dimensions. Extensive experiments on MP-Bench
demonstrate that MMLM performs exceptionally well across multiple tasks,
highlighting its effectiveness in severe weather understanding and marking a
key step toward realizing automated, AI-driven weather forecasting systems. Our
source code and dataset will be made publicly available.

</details>


### [79] [Pushdown Reward Machines for Reinforcement Learning](https://arxiv.org/abs/2508.06894)
*Giovanni Varricchione,Toryn Q. Klassen,Natasha Alechina,Mehdi Dastani,Brian Logan,Sheila A. McIlraith*

Main category: cs.AI

TL;DR: 论文提出了一种基于确定性下推自动机的扩展奖励机器（pdRMs），能够识别和奖励确定性上下文无关语言表示的行为，比传统奖励机器更具表达力。


<details>
  <summary>Details</summary>
Motivation: 传统奖励机器（RMs）只能处理正则语言表示的行为，而pdRMs通过引入下推自动机结构，扩展了对更复杂行为的表达能力。

Method: 提出了两种基于pdRM的策略：一种可以访问整个堆栈，另一种只能访问堆栈顶部的k个符号。并提供了检查两种策略最优性的方法。

Result: 理论分析表明pdRMs具有更强的表达能力，实验验证了其在实际任务中的有效性。

Conclusion: pdRMs为强化学习提供了更强大的工具，能够处理更复杂的任务。

Abstract: Reward machines (RMs) are automata structures that encode (non-Markovian)
reward functions for reinforcement learning (RL). RMs can reward any behaviour
representable in regular languages and, when paired with RL algorithms that
exploit RM structure, have been shown to significantly improve sample
efficiency in many domains. In this work, we present pushdown reward machines
(pdRMs), an extension of reward machines based on deterministic pushdown
automata. pdRMs can recognize and reward temporally extended behaviours
representable in deterministic context-free languages, making them more
expressive than reward machines. We introduce two variants of pdRM-based
policies, one which has access to the entire stack of the pdRM, and one which
can only access the top $k$ symbols (for a given constant $k$) of the stack. We
propose a procedure to check when the two kinds of policies (for a given
environment, pdRM, and constant $k$) achieve the same optimal expected reward.
We then provide theoretical results establishing the expressive power of pdRMs,
and space complexity results about the proposed learning problems. Finally, we
provide experimental results showing how agents can be trained to perform tasks
representable in deterministic context-free languages using pdRMs.

</details>


### [80] [GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization](https://arxiv.org/abs/2508.06899)
*Yanchen Deng,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: 论文提出了一种改进的分布式约束优化问题（DCOP）局部搜索算法DGLS，通过自适应约束违反条件、惩罚蒸发机制和同步更新方案，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有GDBA算法在解决DCOP时容易陷入局部最优且性能有限，论文旨在解决其三个关键问题：过度激进的约束违反条件、无限制的惩罚积累和不协调的惩罚更新。

Method: 提出DGLS框架，包括自适应约束违反条件选择高成本约束、惩罚蒸发机制控制惩罚幅度，以及同步方案协调惩罚更新。

Result: 理论证明DGLS的惩罚值有界且代理参与潜在博弈，实验表明DGLS在标准基准测试中显著优于现有方法，尤其在结构化问题上表现突出。

Conclusion: DGLS通过系统性改进显著提升了DCOP局部搜索的性能，特别是在结构化问题上表现优异。

Abstract: Local search is an important class of incomplete algorithms for solving
Distributed Constraint Optimization Problems (DCOPs) but it often converges to
poor local optima. While GDBA provides a comprehensive rule set to escape
premature convergence, its empirical benefits remain marginal on general-valued
problems. In this work, we systematically examine GDBA and identify three
factors that potentially lead to its inferior performance, i.e.,
over-aggressive constraint violation conditions, unbounded penalty
accumulation, and uncoordinated penalty updates. To address these issues, we
propose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs
that incorporates an adaptive violation condition to selectively penalize
constraints with high cost, a penalty evaporation mechanism to control the
magnitude of penalization, and a synchronization scheme for coordinated penalty
updates. We theoretically show that the penalty values are bounded, and agents
play a potential game in our DGLS. Our extensive empirical results on various
standard benchmarks demonstrate the great superiority of DGLS over
state-of-the-art baselines. Particularly, compared to Damped Max-sum with high
damping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance
on general-valued problems, and outperforms it by significant margins
(\textbf{3.77\%--66.3\%}) on structured problems in terms of anytime results.

</details>


### [81] [Automated Formalization via Conceptual Retrieval-Augmented LLMs](https://arxiv.org/abs/2508.06931)
*Wangyue Lu,Lun Du,Sirui Li,Ke Weng,Haozhe Sun,Hengyu Liu,Minghe Yu,Tiancheng Zhang,Ge Yu*

Main category: cs.AI

TL;DR: CRAMF框架通过检索增强的数学形式化，解决了自动形式化中的模型幻觉和语义鸿沟问题，显著提升了LLM的翻译准确性。


<details>
  <summary>Details</summary>
Motivation: 交互式定理证明器的手动形式化耗时且需要专业知识，自动形式化面临模型幻觉和语义鸿沟的挑战。

Method: 提出CRAMF框架，结合检索增强生成（RAG）技术，从Mathlib4构建概念定义知识库，并设计双通道混合检索策略。

Result: 在多个基准测试中，CRAMF显著提升了翻译准确性，最高相对改进达62.1%，平均29.9%。

Conclusion: CRAMF为自动形式化提供了有效解决方案，尤其在处理数学概念的多态性和精确检索方面表现优异。

Abstract: Interactive theorem provers (ITPs) require manual formalization, which is
labor-intensive and demands expert knowledge. While automated formalization
offers a potential solution, it faces two major challenges: model hallucination
(e.g., undefined predicates, symbol misuse, and version incompatibility) and
the semantic gap caused by ambiguous or missing premises in natural language
descriptions. To address these issues, we propose CRAMF, a Concept-driven
Retrieval-Augmented Mathematical Formalization framework. CRAMF enhances
LLM-based autoformalization by retrieving formal definitions of core
mathematical concepts, providing contextual grounding during code generation.
However, applying retrieval-augmented generation (RAG) in this setting is
non-trivial due to the lack of structured knowledge bases, the polymorphic
nature of mathematical concepts, and the high precision required in formal
retrieval. We introduce a framework for automatically constructing a
concept-definition knowledge base from Mathlib4, the standard mathematical
library for the Lean 4 theorem prover, indexing over 26,000 formal definitions
and 1,000+ core mathematical concepts. To address conceptual polymorphism, we
propose contextual query augmentation with domain- and application-level
signals. In addition, we design a dual-channel hybrid retrieval strategy with
reranking to ensure accurate and relevant definition retrieval. Experiments on
miniF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that
CRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding
consistent improvements in translation accuracy, achieving up to 62.1% and an
average of 29.9% relative improvement.

</details>


### [82] [Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction](https://arxiv.org/abs/2508.06939)
*Hiba Najjar,Deepak Pathak,Marlon Nuske,Andreas Dengel*

Main category: cs.AI

TL;DR: 论文提出了一种基于Transformer的多模态学习方法，用于作物产量预测，并利用自注意力机制解释模型，比较了不同特征和模态归因方法的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态学习在农业中具有潜力，但模型可解释性常被忽视。本研究旨在利用Transformer的固有可解释性，提升作物产量预测的透明度和性能。

Method: 采用Transformer模型处理多模态数据（卫星、气象、地形和土壤），提出Attention Rollout和Generic Attention两种特征归因方法，并与Shapley Value Sampling对比。还提出Weighted Modality Activation评估模态归因。

Result: Transformer模型在子田块和田块级别的预测性能优于卷积和循环网络（R2分别提高0.10和0.04）。Attention Rollout在时间归因上更稳健，模态归因方法显示不同模式。

Conclusion: Transformer模型在多模态作物产量预测中表现优越，且自注意力机制提供了可解释性，为农业决策提供了透明支持。

Abstract: Multimodal learning enables various machine learning tasks to benefit from
diverse data sources, effectively mimicking the interplay of different factors
in real-world applications, particularly in agriculture. While the
heterogeneous nature of involved data modalities may necessitate the design of
complex architectures, the model interpretability is often overlooked. In this
study, we leverage the intrinsic explainability of Transformer-based models to
explain multimodal learning networks, focusing on the task of crop yield
prediction at the subfield level. The large datasets used cover various crops,
regions, and years, and include four different input modalities: multispectral
satellite and weather time series, terrain elevation maps and soil properties.
Based on the self-attention mechanism, we estimate feature attributions using
two methods, namely the Attention Rollout (AR) and Generic Attention (GA), and
evaluate their performance against Shapley-based model-agnostic estimations,
Shapley Value Sampling (SVS). Additionally, we propose the Weighted Modality
Activation (WMA) method to assess modality attributions and compare it with SVS
attributions. Our findings indicate that Transformer-based models outperform
other architectures, specifically convolutional and recurrent networks,
achieving R2 scores that are higher by 0.10 and 0.04 at the subfield and field
levels, respectively. AR is shown to provide more robust and reliable temporal
attributions, as confirmed through qualitative and quantitative evaluation,
compared to GA and SVS values. Information about crop phenology stages was
leveraged to interpret the explanation results in the light of established
agronomic knowledge. Furthermore, modality attributions revealed varying
patterns across the two methods compared.[...]

</details>


### [83] [Large Language Models Do Not Simulate Human Psychology](https://arxiv.org/abs/2508.06950)
*Sarah Schröder,Thekla Morgenroth,Ulrike Kuhl,Valerie Vaquet,Benjamin Paaßen*

Main category: cs.AI

TL;DR: 论文警告不要用大语言模型（LLM）替代人类参与者进行心理学研究，并提供了理论和实证证据支持其不可靠性。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM是否能模拟人类心理学，并评估其在心理学研究中的适用性。

Method: 通过概念论证和实证研究（如调整措辞对比LLM与人类反应差异）验证LLM的不可靠性。

Result: LLM对措辞敏感且反应不一致，无法可靠模拟人类心理学。

Conclusion: LLM不能模拟人类心理学，心理学研究需以人类反应为基准验证LLM的可靠性。

Abstract: Large Language Models (LLMs),such as ChatGPT, are increasingly used in
research, ranging from simple writing assistance to complex data annotation
tasks. Recently, some research has suggested that LLMs may even be able to
simulate human psychology and can, hence, replace human participants in
psychological studies. We caution against this approach. We provide conceptual
arguments against the hypothesis that LLMs simulate human psychology. We then
present empiric evidence illustrating our arguments by demonstrating that
slight changes to wording that correspond to large changes in meaning lead to
notable discrepancies between LLMs' and human responses, even for the recent
CENTAUR model that was specifically fine-tuned on psychological responses.
Additionally, different LLMs show very different responses to novel items,
further illustrating their lack of reliability. We conclude that LLMs do not
simulate human psychology and recommend that psychological researchers should
treat LLMs as useful but fundamentally unreliable tools that need to be
validated against human responses for every new application.

</details>


### [84] [DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery](https://arxiv.org/abs/2508.06960)
*Keyu Li,Mohan Jiang,Dayuan Fu,Yunze Wu,Xiangkun Hu,Dequan Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: 论文提出了DatasetResearch基准，评估AI代理在发现和合成数据集方面的能力，揭示了当前技术与完美数据集发现之间的巨大差距。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，数据可用性成为AI开发的瓶颈，如何让AI代理自主发现符合需求的数据集成为关键问题。

Method: 通过208个真实需求构建了DatasetResearch基准，采用三维评估框架分析AI代理的表现。

Result: 结果显示，即使是先进的深度研究系统在挑战性子集上仅得22分，搜索代理和合成代理在不同任务上表现各异，但在极端案例中均表现不佳。

Conclusion: 研究为数据集发现代理设立了首个严格基准，为下一代自改进AI系统奠定了基础。

Abstract: The rapid advancement of large language models has fundamentally shifted the
bottleneck in AI development from computational power to data availability-with
countless valuable datasets remaining hidden across specialized repositories,
research appendices, and domain platforms. As reasoning capabilities and deep
research methodologies continue to evolve, a critical question emerges: can AI
agents transcend conventional search to systematically discover any dataset
that meets specific user requirements, enabling truly autonomous demand-driven
data curation? We introduce DatasetResearch, the first comprehensive benchmark
evaluating AI agents' ability to discover and synthesize datasets from 208
real-world demands across knowledge-intensive and reasoning-intensive tasks.
Our tri-dimensional evaluation framework reveals a stark reality: even advanced
deep research systems achieve only 22% score on our challenging
DatasetResearch-pro subset, exposing the vast gap between current capabilities
and perfect dataset discovery. Our analysis uncovers a fundamental
dichotomy-search agents excel at knowledge tasks through retrieval breadth,
while synthesis agents dominate reasoning challenges via structured
generation-yet both catastrophically fail on "corner cases" outside existing
distributions. These findings establish the first rigorous baseline for dataset
discovery agents and illuminate the path toward AI systems capable of finding
any dataset in the digital universe. Our benchmark and comprehensive analysis
provide the foundation for the next generation of self-improving AI systems and
are publicly available at https://github.com/GAIR-NLP/DatasetResearch.

</details>


### [85] [MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair](https://arxiv.org/abs/2508.06963)
*Changqing Li,Tianlin Li,Xiaohan Zhang,Aishan Liu,Li Pan*

Main category: cs.AI

TL;DR: MASteer是一个基于表征工程的端到端框架，用于修复大语言模型（LLMs）的可信性问题，通过自动生成样本和自适应策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有修复方法（如SFT和RLHF）成本高且慢，而提示工程缺乏鲁棒性和可扩展性，需要更轻量、自动化的解决方案。

Method: MASteer结合AutoTester（多智能体生成样本）和AutoRepairer（自适应策略选择），实现自动化修复。

Result: 在LLaMA-3.1-8B-Chat和Qwen-3-8B-Chat上分别提升15.36%和4.21%，同时保持模型通用能力。

Conclusion: MASteer展示了高效、可扩展的可信性修复能力，具有强鲁棒性和实用价值。

Abstract: Large Language Models (LLMs) face persistent and evolving trustworthiness
issues, motivating developers to seek automated and flexible repair methods
that enable convenient deployment across diverse scenarios. Existing repair
methods like supervised fine-tuning (SFT) and reinforcement learning with human
feedback (RLHF) are costly and slow, while prompt engineering lacks robustness
and scalability. Representation engineering, which steers model behavior by
injecting targeted concept vectors during inference, offers a lightweight,
training-free alternative. However, current approaches depend on manually
crafted samples and fixed steering strategies, limiting automation and
adaptability. To overcome these challenges, we propose MASteer, the first
end-to-end framework for trustworthiness repair in LLMs based on representation
engineering. MASteer integrates two core components: AutoTester, a multi-agent
system that generates diverse, high-quality steer samples tailored to developer
needs; and AutoRepairer, which constructs adaptive steering strategies with
anchor vectors for automated, context-aware strategy selection during
inference. Experiments on standard and customized trustworthiness tasks show
MASteer consistently outperforms baselines, improving metrics by 15.36% on
LLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model
capabilities. MASteer demonstrates strong robustness, generalization, and
practical value for scalable, efficient trustworthiness repair.

</details>


### [86] [DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning](https://arxiv.org/abs/2508.06972)
*Dan Ivanov,Tristan Freiberg,Haruna Isah*

Main category: cs.AI

TL;DR: DSperse是一个模块化框架，用于分布式机器学习推理，通过战略性的密码学验证实现高效和灵活性。


<details>
  <summary>Details</summary>
Motivation: 在分布式零知识机器学习的背景下，避免全模型电路化的高成本和僵化，通过针对性验证关键子计算实现信任最小化。

Method: 采用模块化设计，支持对推理管道中的部分或全部子计算（“切片”）进行验证，并通过审计、复制或经济激励确保全局一致性。

Result: 实验评估了多种证明系统，展示了切片和非切片配置下的内存使用、运行时间和电路行为。

Conclusion: DSperse通过灵活的验证边界设计，支持可扩展的、针对性的验证策略，适应多样化部署需求。

Abstract: DSperse is a modular framework for distributed machine learning inference
with strategic cryptographic verification. Operating within the emerging
paradigm of distributed zero-knowledge machine learning, DSperse avoids the
high cost and rigidity of full-model circuitization by enabling targeted
verification of strategically chosen subcomputations. These verifiable
segments, or "slices", may cover part or all of the inference pipeline, with
global consistency enforced through audit, replication, or economic incentives.
This architecture supports a pragmatic form of trust minimization, localizing
zero-knowledge proofs to the components where they provide the greatest value.
We evaluate DSperse using multiple proving systems and report empirical results
on memory usage, runtime, and circuit behavior under sliced and unsliced
configurations. By allowing proof boundaries to align flexibly with the model's
logical structure, DSperse supports scalable, targeted verification strategies
suited to diverse deployment needs.

</details>


### [87] [Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model](https://arxiv.org/abs/2508.06980)
*Aswin Paul,Moein Khajehnejad,Forough Habibollahi,Brett J. Kagan,Adeel Razi*

Main category: cs.AI

TL;DR: 论文提出了一种基于主动推理的框架，用于模拟具身代理的决策过程，探索生物神经元网络的潜力，并展示了记忆学习和预测规划在智能决策中的作用。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的快速发展，理解自主代理的有目的行为基础对开发安全高效系统至关重要。生物神经元网络可能提供更高能效和可解释性。

Method: 使用实验启发的生成模型，在模拟游戏环境中模拟决策过程，结合主动推理理论建模。

Result: 结果表明代理能够学习，揭示了记忆学习和预测规划在智能决策中的重要性。

Conclusion: 该研究为可解释AI提供了生物基础和可扩展的方法，有助于理解代理的有目的行为。

Abstract: With recent and rapid advancements in artificial intelligence (AI),
understanding the foundation of purposeful behaviour in autonomous agents is
crucial for developing safe and efficient systems. While artificial neural
networks have dominated the path to AI, recent studies are exploring the
potential of biologically based systems, such as networks of living biological
neuronal networks. Along with promises of high power and data efficiency, these
systems may also inform more explainable and biologically plausible models. In
this work, we propose a framework rooted in active inference, a general theory
of behaviour, to model decision-making in embodied agents. Using
experiment-informed generative models, we simulate decision-making processes in
a simulated game-play environment, mirroring experimental setups that use
biological neurons. Our results demonstrate learning in these agents, providing
insights into the role of memory-based learning and predictive planning in
intelligent decision-making. This work contributes to the growing field of
explainable AI by offering a biologically grounded and scalable approach to
understanding purposeful behaviour in agents.

</details>


### [88] [Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach](https://arxiv.org/abs/2508.07015)
*Hannes Ihalainen,Dieter Vandesande,André Schidler,Jeremias Berg,Bart Bogaerts,Matti Järvisalo*

Main category: cs.AI

TL;DR: 本文探讨了隐式击中集（IHS）框架中替代整数规划的优化方法，包括伪布尔推理和随机局部搜索，并评估了其在实际应用中的可行性与效率。


<details>
  <summary>Details</summary>
Motivation: 研究IHS框架中替代整数规划的优化方法，以解决数值不稳定性和提高计算可靠性。

Method: 采用伪布尔推理和随机局部搜索作为替代优化技术，并与商业整数规划求解器进行比较。

Result: 商业整数规划求解器效率最高但存在数值不稳定性，而伪布尔推理在精确计算中表现竞争力，并能提供正确性证明。

Conclusion: 伪布尔推理可作为IHS框架中高效且可靠的优化方法，尤其在需要正确性证明的场景中。

Abstract: The implicit hitting set (IHS) approach offers a general framework for
solving computationally hard combinatorial optimization problems declaratively.
IHS iterates between a decision oracle used for extracting sources of
inconsistency and an optimizer for computing so-called hitting sets (HSs) over
the accumulated sources of inconsistency. While the decision oracle is
language-specific, the optimizers is usually instantiated through integer
programming.
  We explore alternative algorithmic techniques for hitting set optimization
based on different ways of employing pseudo-Boolean (PB) reasoning as well as
stochastic local search. We extensively evaluate the practical feasibility of
the alternatives in particular in the context of pseudo-Boolean (0-1 IP)
optimization as one of the most recent instantiations of IHS. Highlighting a
trade-off between efficiency and reliability, while a commercial IP solver
turns out to remain the most effective way to instantiate HS computations, it
can cause correctness issues due to numerical instability; in fact, we show
that exact HS computations instantiated via PB reasoning can be made
competitive with a numerically exact IP solver. Furthermore, the use of PB
reasoning as a basis for HS computations allows for obtaining certificates for
the correctness of IHS computations, generally applicable to any IHS
instantiation in which reasoning in the declarative language at hand can be
captured in the PB-based proof format we employ.

</details>


### [89] [MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA](https://arxiv.org/abs/2508.07022)
*Shengtao Wen,Haodong Chen,Yadong Wang,Zhongying Pan,Xiang Chen,Yu Tian,Bo Qian,Dong Liang,Sheng-Jun Huang*

Main category: cs.AI

TL;DR: MultiMedEdit是首个针对临床多模态任务的知识编辑（KE）评估基准，揭示了当前方法在复杂临床工作流中的局限性，并提出了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑研究多集中于文本领域，而多模态医疗场景下的知识编辑需求未被充分探索，需结合视觉推理支持临床决策。

Method: 提出MultiMedEdit框架，涵盖理解和推理任务，定义三维度量标准（可靠性、通用性、局部性），支持跨范式比较。

Result: 实验表明当前方法在泛化和长尾推理方面表现不佳，尤其在复杂临床工作流中。效率分析揭示了实际部署中的权衡。

Conclusion: MultiMedEdit为未来开发临床稳健的知识编辑技术奠定了基础，并揭示了当前方法的不足。

Abstract: Knowledge editing (KE) provides a scalable approach for updating factual
knowledge in large language models without full retraining. While previous
studies have demonstrated effectiveness in general domains and medical QA
tasks, little attention has been paid to KE in multimodal medical scenarios.
Unlike text-only settings, medical KE demands integrating updated knowledge
with visual reasoning to support safe and interpretable clinical decisions. To
address this gap, we propose MultiMedEdit, the first benchmark tailored to
evaluating KE in clinical multimodal tasks. Our framework spans both
understanding and reasoning task types, defines a three-dimensional metric
suite (reliability, generality, and locality), and supports cross-paradigm
comparisons across general and domain-specific models. We conduct extensive
experiments under single-editing and lifelong-editing settings. Results suggest
that current methods struggle with generalization and long-tail reasoning,
particularly in complex clinical workflows. We further present an efficiency
analysis (e.g., edit latency, memory footprint), revealing practical trade-offs
in real-world deployment across KE paradigms. Overall, MultiMedEdit not only
reveals the limitations of current approaches but also provides a solid
foundation for developing clinically robust knowledge editing techniques in the
future.

</details>


### [90] [K-Dense Analyst: Towards Fully Automated Scientific Analysis](https://arxiv.org/abs/2508.07043)
*Orion Li,Vinayak Agarwal,Summer Zhou,Ashwin Gopinath,Timothy Kassis*

Main category: cs.AI

TL;DR: K-Dense Analyst是一个多代理系统，通过双循环架构实现自主生物信息学分析，性能优于GPT-5。


<details>
  <summary>Details</summary>
Motivation: 现代生物信息学分析的复杂性导致数据生成与科学洞察之间存在鸿沟，现有大语言模型在迭代计算和工具集成方面受限。

Method: 采用分层多代理系统和双循环架构，将复杂目标分解为可执行、可验证的任务。

Result: 在BixBench基准测试中，K-Dense Analyst的准确率达到29.2%，比GPT-5高6.3个百分点。

Conclusion: 自主科学推理需要专门构建的系统，而不仅仅是增强的语言模型，K-Dense Analyst为生命科学领域的发现提供了重要进展。

Abstract: The complexity of modern bioinformatics analysis has created a critical gap
between data generation and developing scientific insights. While large
language models (LLMs) have shown promise in scientific reasoning, they remain
fundamentally limited when dealing with real-world analytical workflows that
demand iterative computation, tool integration and rigorous validation. We
introduce K-Dense Analyst, a hierarchical multi-agent system that achieves
autonomous bioinformatics analysis through a dual-loop architecture. K-Dense
Analyst, part of the broader K-Dense platform, couples planning with validated
execution using specialized agents to decompose complex objectives into
executable, verifiable tasks within secure computational environments. On
BixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense
Analyst achieves 29.2% accuracy, surpassing the best-performing language model
(GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what
is widely considered the most powerful LLM available. Remarkably, K-Dense
Analyst achieves this performance using Gemini 2.5 Pro, which attains only
18.3% accuracy when used directly, demonstrating that our architectural
innovations unlock capabilities far beyond the underlying model's baseline
performance. Our insights demonstrate that autonomous scientific reasoning
requires more than enhanced language models, it demands purpose-built systems
that can bridge the gap between high-level scientific objectives and low-level
computational execution. These results represent a significant advance toward
fully autonomous computational biologists capable of accelerating discovery
across the life sciences.

</details>


### [91] [Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach](https://arxiv.org/abs/2508.07063)
*Naseem Machlovi,Maryam Saleki,Innocent Ababio,Ruhul Amin*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLMs）在内容审核中的局限性，提出了一种新框架SafePhi，其在伦理语境下表现优于现有模型，但仍需改进数据多样性和人类参与。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在日常生活中的普及，确保其安全可靠的审核能力变得至关重要。尽管LLMs在复杂任务中表现优异，但在涉及道德推理、隐晦仇恨和性别偏见等主观问题时仍存在不足。

Method: 研究开发了一个基于SOTA模型的实验框架，评估人类情感和攻击性行为，并引入统一基准数据集。同时提出了SafePhi，一种QLoRA微调的Phi-4模型。

Result: SafePhi在Macro F1得分上达到0.89，优于OpenAI Moderator（0.77）和Llama Guard（0.74）。研究还揭示了LLMs在关键领域的持续不足。

Conclusion: 需通过更异构和代表性的数据及人类参与提升模型鲁棒性和可解释性。

Abstract: As AI systems become more integrated into daily life, the need for safer and
more reliable moderation has never been greater. Large Language Models (LLMs)
have demonstrated remarkable capabilities, surpassing earlier models in
complexity and performance. Their evaluation across diverse tasks has
consistently showcased their potential, enabling the development of adaptive
and personalized agents. However, despite these advancements, LLMs remain prone
to errors, particularly in areas requiring nuanced moral reasoning. They
struggle with detecting implicit hate, offensive language, and gender biases
due to the subjective and context-dependent nature of these issues. Moreover,
their reliance on training data can inadvertently reinforce societal biases,
leading to inconsistencies and ethical concerns in their outputs. To explore
the limitations of LLMs in this role, we developed an experimental framework
based on state-of-the-art (SOTA) models to assess human emotions and offensive
behaviors. The framework introduces a unified benchmark dataset encompassing 49
distinct categories spanning the wide spectrum of human emotions, offensive and
hateful text, and gender and racial biases. Furthermore, we introduced SafePhi,
a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and
outperforming benchmark moderators by achieving a Macro F1 score of 0.89, where
OpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This
research also highlights the critical domains where LLM moderators consistently
underperformed, pressing the need to incorporate more heterogeneous and
representative data with human-in-the-loop, for better model robustness and
explainability.

</details>


### [92] [Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention](https://arxiv.org/abs/2508.07107)
*Timothy Oluwapelumi Adeyemi,Nadiah Fahad AlOtaibi*

Main category: cs.AI

TL;DR: 提出了一种基于反馈驱动的决策支持系统（DSS），通过闭环架构和增量训练提升学生成绩预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型多为静态，无法适应新数据（如干预后结果），需动态调整以提高预测准确性。

Method: 结合LightGBM回归器和增量训练，支持实时数据输入和模型更新，并采用SHAP增强可解释性。

Result: 实验显示RMSE降低10.7%，干预学生预测分数持续提升。

Conclusion: 该系统将静态预测转化为自优化系统，推动教育分析向以人为本、数据驱动和响应式AI发展。

Abstract: Accurate prediction of student performance is essential for timely academic
intervention. However, most machine learning models in education are static and
cannot adapt when new data, such as post-intervention outcomes, become
available. To address this limitation, we propose a Feedback-Driven Decision
Support System (DSS) with a closed-loop architecture that enables continuous
model refinement. The system integrates a LightGBM-based regressor with
incremental retraining, allowing educators to input updated student results,
which automatically trigger model updates. This adaptive mechanism improves
prediction accuracy by learning from real-world academic progress. The platform
features a Flask-based web interface for real-time interaction and incorporates
SHAP for explainability, ensuring transparency. Experimental results show a
10.7\% reduction in RMSE after retraining, with consistent upward adjustments
in predicted scores for intervened students. By transforming static predictors
into self-improving systems, our approach advances educational analytics toward
human-centered, data-driven, and responsive AI. The framework is designed for
integration into LMS and institutional dashboards.

</details>


### [93] [Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables](https://arxiv.org/abs/2508.07186)
*Amit Dhanda*

Main category: cs.AI

TL;DR: 提出了一种基于LLM的多智能体框架，用于跨维度汇总结构化企业数据，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统表格到文本模型缺乏对层次结构和上下文感知差异的推理能力，无法满足商业报告需求。

Method: 采用多智能体管道，包括数据切片、方差检测、上下文构建和LLM生成。

Result: 框架在数据忠实度（83%）、显著变化覆盖和决策关键洞察相关性（4.4/5）上表现优异。

Conclusion: 该框架在复杂商业场景中（如收入与销量权衡）表现突出，优于基线方法。

Abstract: We propose a novel framework for summarizing structured enterprise data
across multiple dimensions using large language model (LLM)-based agents.
Traditional table-to-text models often lack the capacity to reason across
hierarchical structures and context-aware deltas, which are essential in
business reporting tasks. Our method introduces a multi-agent pipeline that
extracts, analyzes, and summarizes multi-dimensional data using agents for
slicing, variance detection, context construction, and LLM-based generation.
Our results show that the proposed framework outperforms traditional
approaches, achieving 83\% faithfulness to underlying data, superior coverage
of significant changes, and high relevance scores (4.4/5) for decision-critical
insights. The improvements are especially pronounced in categories involving
subtle trade-offs, such as increased revenue due to price changes amid
declining unit volumes, which competing methods either overlook or address with
limited specificity. We evaluate the framework on Kaggle datasets and
demonstrate significant improvements in faithfulness, relevance, and insight
quality over baseline table summarization approaches.

</details>


### [94] [EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning](https://arxiv.org/abs/2508.07292)
*Yi Tang,Kaini Wang,Yang Chen,Guangquan Zhou*

Main category: cs.AI

TL;DR: EndoAgent是一种基于双记忆设计的AI代理，用于内窥镜图像分析，结合迭代推理和自适应工具选择，显著优于现有多模态模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于大规模预训练的方法在多任务协调和复杂临床流程处理上表现不足，AI代理在内窥镜领域的潜力尚未充分开发。

Method: EndoAgent采用双记忆设计，短期行动跟踪确保逻辑连贯，长期经验学习提升推理能力，并集成专家设计工具。

Result: 实验表明EndoAgent在视觉理解和语言生成任务上优于通用及医学多模态模型。

Conclusion: EndoAgent展示了强大的灵活性和推理能力，为内窥镜诊断AI系统提供了新方向。

Abstract: Developing general artificial intelligence (AI) systems to support endoscopic
image diagnosis is an emerging research priority. Existing methods based on
large-scale pretraining often lack unified coordination across tasks and
struggle to handle the multi-step processes required in complex clinical
workflows. While AI agents have shown promise in flexible instruction parsing
and tool integration across domains, their potential in endoscopy remains
underexplored. To address this gap, we propose EndoAgent, the first
memory-guided agent for vision-to-decision endoscopic analysis that integrates
iterative reasoning with adaptive tool selection and collaboration. Built on a
dual-memory design, it enables sophisticated decision-making by ensuring
logical coherence through short-term action tracking and progressively
enhancing reasoning acuity through long-term experiential learning. To support
diverse clinical tasks, EndoAgent integrates a suite of expert-designed tools
within a unified reasoning loop. We further introduce EndoAgentBench, a
benchmark of 5,709 visual question-answer pairs that assess visual
understanding and language generation capabilities in realistic scenarios.
Extensive experiments show that EndoAgent consistently outperforms both general
and medical multimodal models, exhibiting its strong flexibility and reasoning
capabilities.

</details>


### [95] [Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape](https://arxiv.org/abs/2508.07334)
*Quan Shi,Wang Xi,Zenghui Ding,Jianqing Gao,Xianjun Yang*

Main category: cs.AI

TL;DR: 本文通过形式化大语言模型为概率图灵机，证明幻觉现象在计算必要性层次上是不可避免的，并提出两种解决方案：检索增强生成（RAG）和持续学习。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型（LLMs）幻觉现象的核心障碍，为其可靠部署提供理论基础。

Method: 构建'计算必要性层次'，证明幻觉的不可避免性；提出RAG作为预言机模型和持续学习作为'内化预言机'机制。

Result: 证明了幻觉的不可避免性，并提供了两种可能的解决方案。

Conclusion: 通过形式化理论和创新框架，为LLMs的可靠部署提供了理论支持和实践路径。

Abstract: The illusion phenomenon of large language models (LLMs) is the core obstacle
to their reliable deployment. This article formalizes the large language model
as a probabilistic Turing machine by constructing a "computational necessity
hierarchy", and for the first time proves the illusions are inevitable on
diagonalization, incomputability, and information theory boundaries supported
by the new "learner pump lemma". However, we propose two "escape routes": one
is to model Retrieval Enhanced Generations (RAGs) as oracle machines, proving
their absolute escape through "computational jumps", providing the first formal
theory for the effectiveness of RAGs; The second is to formalize continuous
learning as an "internalized oracle" mechanism and implement this path through
a novel neural game theory framework.Finally, this article proposes a

</details>


### [96] [Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach](https://arxiv.org/abs/2508.07353)
*Rubing Chen,Jiaxin Wu,Jian Wang,Xulu Zhang,Wenqi Fan,Chenghua Lin,Xiao-Yong Wei,Qing Li*

Main category: cs.AI

TL;DR: 论文提出Comp-Comp框架，通过综合性和紧凑性原则优化领域特定基准构建，挑战了传统的扩展法则。


<details>
  <summary>Details</summary>
Motivation: 现有领域特定基准主要依赖扩展法则，但语料和QA集设计对模型性能的影响未被充分研究。

Method: 提出Comp-Comp框架，结合综合性和紧凑性原则，指导语料和QA集构建，并通过案例研究验证。

Result: 创建了XUBench基准，证明Comp-Comp框架在学术领域的有效性，并展示其可扩展性。

Conclusion: Comp-Comp框架为领域特定基准构建提供了新思路，适用于多种领域。

Abstract: Numerous benchmarks have been built to evaluate the domain-specific abilities
of large language models (LLMs), highlighting the need for effective and
efficient benchmark construction. Existing domain-specific benchmarks primarily
focus on the scaling law, relying on massive corpora for supervised fine-tuning
or generating extensive question sets for broad coverage. However, the impact
of corpus and question-answer (QA) set design on the precision and recall of
domain-specific LLMs remains unexplored. In this paper, we address this gap and
demonstrate that the scaling law is not always the optimal principle for
benchmark construction in specific domains. Instead, we propose Comp-Comp, an
iterative benchmarking framework based on a comprehensiveness-compactness
principle. Here, comprehensiveness ensures semantic recall of the domain, while
compactness enhances precision, guiding both corpus and QA set construction. To
validate our framework, we conducted a case study in a well-renowned
university, resulting in the creation of XUBench, a large-scale and
comprehensive closed-domain benchmark. Although we use the academic domain as
the case in this work, our Comp-Comp framework is designed to be extensible
beyond academia, providing valuable insights for benchmark construction across
various domains.

</details>


### [97] [Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning](https://arxiv.org/abs/2508.07382)
*He Kong,Die Hu,Jingguo Ge,Liangxiong Li,Hui Li,Tong Li*

Main category: cs.AI

TL;DR: Pentest-R1是一个通过两阶段强化学习优化LLM在渗透测试中推理能力的新框架，显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在渗透测试中存在错误处理差、推理效率低和无法自主完成复杂任务等问题，Pentest-R1旨在解决这些挑战。

Method: 采用两阶段强化学习：离线RL学习基础攻击逻辑，在线RL在CTF环境中通过环境反馈微调模型。

Result: 在AutoPenBench上成功率24.2%，Cybench上15.0%，性能接近顶级专有模型。

Conclusion: 两阶段训练协同是Pentest-R1成功的关键，为开源LLM设立了新标杆。

Abstract: Automating penetration testing is crucial for enhancing cybersecurity, yet
current Large Language Models (LLMs) face significant limitations in this
domain, including poor error handling, inefficient reasoning, and an inability
to perform complex end-to-end tasks autonomously. To address these challenges,
we introduce Pentest-R1, a novel framework designed to optimize LLM reasoning
capabilities for this task through a two-stage reinforcement learning pipeline.
We first construct a dataset of over 500 real-world, multi-step walkthroughs,
which Pentest-R1 leverages for offline reinforcement learning (RL) to instill
foundational attack logic. Subsequently, the LLM is fine-tuned via online RL in
an interactive Capture The Flag (CTF) environment, where it learns directly
from environmental feedback to develop robust error self-correction and
adaptive strategies. Our extensive experiments on the Cybench and AutoPenBench
benchmarks demonstrate the framework's effectiveness. On AutoPenBench,
Pentest-R1 achieves a 24.2\% success rate, surpassing most state-of-the-art
models and ranking second only to Gemini 2.5 Flash. On Cybench, it attains a
15.0\% success rate in unguided tasks, establishing a new state-of-the-art for
open-source LLMs and matching the performance of top proprietary models.
Ablation studies confirm that the synergy of both training stages is critical
to its success.

</details>


### [98] [Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding](https://arxiv.org/abs/2508.07388)
*Zhaoyu Chen,Hongnan Lin,Yongwei Nie,Fei Ma,Xuemiao Xu,Fei Yu,Chengjiang Long*

Main category: cs.AI

TL;DR: Invert4TVG框架通过三个反转任务（动词补全、动作识别和视频描述）增强视频片段定位和语义理解，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前TVG方法过度优化时间IoU，牺牲语义理解，影响鲁棒性。

Method: 提出三个反转任务，结合强化学习框架优化定位和语义。

Result: 在Charades-STA上R1@0.7提升7.1%，优于现有方法。

Conclusion: 通过反转任务增强语义理解，显著提高定位精度上限。

Abstract: Temporal Video Grounding (TVG) seeks to localize video segments matching a
given textual query. Current methods, while optimizing for high temporal
Intersection-over-Union (IoU), often overfit to this metric, compromising
semantic action understanding in the video and query, a critical factor for
robust TVG. To address this, we introduce Inversion Tasks for TVG (Invert4TVG),
a novel framework that enhances both localization accuracy and action
understanding without additional data. Our approach leverages three inversion
tasks derived from existing TVG annotations: (1) Verb Completion, predicting
masked action verbs in queries from video segments; (2) Action Recognition,
identifying query-described actions; and (3) Video Description, generating
descriptions of video segments that explicitly embed query-relevant actions.
These tasks, integrated with TVG via a reinforcement learning framework with
well-designed reward functions, ensure balanced optimization of localization
and semantics. Experiments show our method outperforms state-of-the-art
approaches, achieving a 7.1\% improvement in R1@0.7 on Charades-STA for a 3B
model compared to Time-R1. By inverting TVG to derive query-related actions
from segments, our approach strengthens semantic understanding, significantly
raising the ceiling of localization accuracy.

</details>


### [99] [Generative AI for Strategic Plan Development](https://arxiv.org/abs/2508.07405)
*Jesse Ponnock*

Main category: cs.AI

TL;DR: 论文提出了一种利用生成式人工智能（GAI）为大型政府组织制定战略计划的模块化模型，并评估了BERTopic和非负矩阵分解（NMF）在主题建模中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能（GAI）和大语言模型（LLM）的突破，越来越多的专业服务通过AI增强，本文旨在探索GAI在战略计划制定中的应用。

Method: 使用BERTopic和NMF模型对政府问责办公室（GAO）的大量报告进行主题建模，生成与战略计划中愿景要素相似的主题。

Result: 结果显示，这些技术能够生成与100%的愿景要素相似的主题，且BERTopic表现最佳，超过一半的主题达到“中等”或“强”相关性。

Conclusion: GAI在战略计划制定中具有潜力，未来研究将聚焦于模型的实际应用和剩余模块的可行性。

Abstract: Given recent breakthroughs in Generative Artificial Intelligence (GAI) and
Large Language Models (LLMs), more and more professional services are being
augmented through Artificial Intelligence (AI), which once seemed impossible to
automate. This paper presents a modular model for leveraging GAI in developing
strategic plans for large scale government organizations and evaluates leading
machine learning techniques in their application towards one of the identified
modules. Specifically, the performance of BERTopic and Non-negative Matrix
Factorization (NMF) are evaluated in their ability to use topic modeling to
generate themes representative of Vision Elements within a strategic plan. To
accomplish this, BERTopic and NMF models are trained using a large volume of
reports from the Government Accountability Office (GAO). The generated topics
from each model are then scored for similarity against the Vision Elements of a
published strategic plan and the results are compared. Our results show that
these techniques are capable of generating themes similar to 100% of the
elements being evaluated against. Further, we conclude that BERTopic performs
best in this application with more than half of its correlated topics achieving
a "medium" or "strong" correlation. A capability of GAI-enabled strategic plan
development impacts a multi-billion dollar industry and assists the federal
government in overcoming regulatory requirements which are crucial to the
public good. Further work will focus on the operationalization of the concept
proven in this study as well as viability of the remaining modules in the
proposed model for GAI-generated strategic plans.

</details>


### [100] [A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems](https://arxiv.org/abs/2508.07407)
*Jinyuan Fang,Yanwen Peng,Xi Zhang,Yingxu Wang,Xinhao Yi,Guibin Zhang,Yi Xu,Bin Wu,Siwei Liu,Zihao Li,Zhaochun Ren,Nikos Aletras,Xi Wang,Han Zhou,Zaiqiao Meng*

Main category: cs.AI

TL;DR: 综述了自进化AI代理系统的技术，提出了统一框架并探讨了领域专用策略及伦理问题。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统依赖静态配置，无法适应动态环境，需研究自进化技术以实现持续适应性。

Method: 提出统一框架，系统回顾自进化技术，并分析领域专用策略及评估、安全、伦理问题。

Result: 总结了自进化代理系统的关键组件和技术，为开发自适应系统奠定基础。

Conclusion: 自进化AI代理是未来发展方向，需进一步研究以确保其有效性和可靠性。

Abstract: Recent advances in large language models have sparked growing interest in AI
agents capable of solving complex, real-world tasks. However, most existing
agent systems rely on manually crafted configurations that remain static after
deployment, limiting their ability to adapt to dynamic and evolving
environments. To this end, recent research has explored agent evolution
techniques that aim to automatically enhance agent systems based on interaction
data and environmental feedback. This emerging direction lays the foundation
for self-evolving AI agents, which bridge the static capabilities of foundation
models with the continuous adaptability required by lifelong agentic systems.
In this survey, we provide a comprehensive review of existing techniques for
self-evolving agentic systems. Specifically, we first introduce a unified
conceptual framework that abstracts the feedback loop underlying the design of
self-evolving agentic systems. The framework highlights four key components:
System Inputs, Agent System, Environment, and Optimisers, serving as a
foundation for understanding and comparing different strategies. Based on this
framework, we systematically review a wide range of self-evolving techniques
that target different components of the agent system. We also investigate
domain-specific evolution strategies developed for specialised fields such as
biomedicine, programming, and finance, where optimisation objectives are
tightly coupled with domain constraints. In addition, we provide a dedicated
discussion on the evaluation, safety, and ethical considerations for
self-evolving agentic systems, which are critical to ensuring their
effectiveness and reliability. This survey aims to provide researchers and
practitioners with a systematic understanding of self-evolving AI agents,
laying the foundation for the development of more adaptive, autonomous, and
lifelong agentic systems.

</details>


### [101] [Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs](https://arxiv.org/abs/2508.07466)
*Dom Huh,Prasant Mohapatra*

Main category: cs.AI

TL;DR: 该论文提出了一种系统框架，将大型语言模型（LLMs）与多智能体决策算法结合，以增强其协作和推理能力。


<details>
  <summary>Details</summary>
Motivation: 语言是协作和推理的基础，通过建立共同语言可以促进智能体间的清晰沟通和协调。

Method: 提出多智能体LLMs的设计框架，包括高级提示工程、内存架构、多模态信息处理和微调算法。

Result: 在经典游戏环境中进行消融实验，验证了设计选择的有效性。

Conclusion: 该框架为多智能体LLMs的设计提供了系统化的方法，有助于提升协作和决策能力。

Abstract: Language is a ubiquitous tool that is foundational to reasoning and
collaboration, ranging from everyday interactions to sophisticated
problem-solving tasks. The establishment of a common language can serve as a
powerful asset in ensuring clear communication and understanding amongst
agents, facilitating desired coordination and strategies. In this work, we
extend the capabilities of large language models (LLMs) by integrating them
with advancements in multi-agent decision-making algorithms. We propose a
systematic framework for the design of multi-agentic large language models
(LLMs), focusing on key integration practices. These include advanced prompt
engineering techniques, the development of effective memory architectures,
multi-modal information processing, and alignment strategies through
fine-tuning algorithms. We evaluate these design choices through extensive
ablation studies on classic game settings with significant underlying social
dilemmas and game-theoretic considerations.

</details>


### [102] [CP-Agent: Agentic Constraint Programming](https://arxiv.org/abs/2508.07468)
*Stefan Szeider*

Main category: cs.AI

TL;DR: 提出了一种基于纯代理策略的新方法，通过ReAct原则和IPython内核实现动态代码执行，成功解决了CP-Bench基准集中的所有101个问题。


<details>
  <summary>Details</summary>
Motivation: 自然语言问题描述到形式约束模型的翻译需要深厚的专业知识和建模框架，现有固定流程方法在基准问题上表现不佳。

Method: 开发了一个基于ReAct原则的通用Python编码代理，利用IPython内核进行状态化代码执行和迭代开发，通过项目提示注入领域知识。

Result: 该方法成功解决了CP-Bench基准集中的所有101个问题。

Conclusion: 约束建模任务需要通用编码工具和提示编码的领域知识，而非专用代理架构或预定义流程。

Abstract: Translating natural language problem descriptions into formal constraint
models remains a fundamental challenge in constraint programming, requiring
deep expertise in both the problem domain and modeling frameworks. Previous
approaches to automating this translation have employed fixed workflows with
predetermined modeling steps, failing on a significant number of benchmark
problems. We present a new approach using a pure agentic strategy without any
fixed pipeline. We developed a general-purpose Python coding agent based on the
ReAct (Reason and Act) principle, utilizing a persistent IPython kernel for
stateful code execution and iterative development. Rather than embedding
constraint programming logic into the agent architecture, domain-specific
expertise is injected solely through a carefully crafted project prompt. The
agent combines this prompt-encoded knowledge with access to file operations and
code execution tools, enabling it to test hypotheses, debug failures, and
verify solutions dynamically. Implemented in just a few hundred lines of code,
this architecture successfully solves all 101 problems of the CP-Bench
constraint programming benchmark set. The results suggest that constraint
modeling tasks require the combination of general coding tools and domain
expertise encoded in prompts, rather than specialized agent architectures or
predefined workflows.

</details>


### [103] [Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy](https://arxiv.org/abs/2508.07485)
*Alexander Duffy,Samuel J Paech,Ishana Shastri,Elizabeth Karpinski,Baptiste Alloui-Cros,Tyler Marques,Matthew Lyle Olson*

Main category: cs.AI

TL;DR: 提出了一个无需微调或专门训练的评估工具，使本地大型语言模型（LLMs）能玩完整版《外交》游戏。通过数据驱动的迭代优化游戏状态表示，使24B模型能可靠完成比赛。


<details>
  <summary>Details</summary>
Motivation: 解决《外交》游戏的高复杂性和信息密度导致的研究困难，消除对前沿LLMs或微调的依赖。

Method: 使用数据驱动迭代优化游戏状态表示，开发工具支持假设测试和统计分析。

Result: 较大模型表现最佳，但较小模型也能胜任；引入关键状态分析协议深入分析游戏关键点。

Conclusion: 该工具无需微调即可评估LLMs的战略推理能力，揭示了这些能力如何自然地从广泛使用的LLMs中涌现。

Abstract: We present the first evaluation harness that enables any out-of-the-box,
local, Large Language Models (LLMs) to play full-press Diplomacy without
fine-tuning or specialized training. Previous work required frontier LLMs, or
fine-tuning, due to the high complexity and information density of Diplomacy's
game state. Combined with the high variance of matches, these factors made
Diplomacy prohibitive for study. In this work, we used data-driven iteration to
optimize a textual game state representation such that a 24B model can reliably
complete matches without any fine tuning. We develop tooling to facilitate
hypothesis testing and statistical analysis, and we present case studies on
persuasion, aggressive playstyles, and performance across a range of models. We
conduct a variety of experiments across many popular LLMs, finding the larger
models perform the best, but the smaller models still play adequately. We also
introduce Critical State Analysis: an experimental protocol for rapidly
iterating and analyzing key moments in a game at depth. Our harness
democratizes the evaluation of strategic reasoning in LLMs by eliminating the
need for fine-tuning, and it provides insights into how these capabilities
emerge naturally from widely used LLMs. Our code is available in the supplement
and will be open sourced.

</details>


### [104] [MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool Use Benchmark](https://arxiv.org/abs/2508.07575)
*Shiqing Fan,Xichen Ding,Liang Zhang,Linjian Mo*

Main category: cs.AI

TL;DR: 论文提出MCPToolBench++，一个用于评估LLMs调用MCP工具能力的大规模多领域基准，解决了现有评估方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法缺乏全面的数据集和基准，且MCP工具响应格式多样，成功率和可用工具数量受限。

Method: 构建MCPToolBench++基准，包含来自40多个类别的4k多个MCP服务器数据，支持单步和多步工具调用评估。

Result: 评估了具有代理能力的SOTA LLMs，并报告了结果。

Conclusion: MCPToolBench++为评估LLMs在MCP工具调用上的性能提供了有效解决方案。

Abstract: LLMs' capabilities are enhanced by using function calls to integrate various
data sources or API results into the context window. Typical tools include
search, web crawlers, maps, financial data, file systems, and browser usage,
etc. Integrating these data sources or functions requires a standardized
method. The Model Context Protocol (MCP) provides a standardized way to supply
context to LLMs. However, the evaluation of LLMs and AI Agents' MCP tool use
abilities suffer from several issues. First, there's a lack of comprehensive
datasets or benchmarks to evaluate various MCP tools. Second, the diverse
formats of response from MCP tool call execution further increase the
difficulty of evaluation. Additionally, unlike existing tool-use benchmarks
with high success rates in functions like programming and math functions, the
success rate of real-world MCP tool is not guaranteed and varies across
different MCP servers. Furthermore, the LLMs' context window also limits the
number of available tools that can be called in a single run, because the
textual descriptions of tool and the parameters have long token length for an
LLM to process all at once. To help address the challenges of evaluating LLMs'
performance on calling MCP tools, we propose MCPToolBench++, a large-scale,
multi-domain AI Agent tool use benchmark. As of July 2025, this benchmark is
build upon marketplace of over 4k MCP servers from more than 40 categories,
collected from the MCP marketplaces and GitHub communities. The datasets
consist of both single-step and multi-step tool calls across different
categories. We evaluated SOTA LLMs with agentic abilities on this benchmark and
reported the results.

</details>


### [105] [Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method](https://arxiv.org/abs/2508.07586)
*Wenjing Zhang,Ye Hu,Tao Luo,Zhilong Zhang,Mingzhe Chen*

Main category: cs.AI

TL;DR: 论文提出了一种新颖的隐蔽语义通信框架，通过友好干扰器干扰攻击者，优化语义信息和传输功率，提升隐私和传输质量。


<details>
  <summary>Details</summary>
Motivation: 研究如何在攻击者试图窃取语义信息的情况下，保护图像数据的语义传输隐私。

Method: 采用优先采样辅助的双延迟深度确定性策略梯度算法，联合优化语义信息和传输功率。

Result: 仿真结果显示，相比传统强化学习方法，隐私和传输质量分别提升77.8%和14.3%。

Conclusion: 提出的算法有效提升了语义通信的隐私性和传输质量，避免了局部最优和Q值估计偏差。

Abstract: In this paper, a novel covert semantic communication framework is
investigated. Within this framework, a server extracts and transmits the
semantic information, i.e., the meaning of image data, to a user over several
time slots. An attacker seeks to detect and eavesdrop the semantic transmission
to acquire details of the original image. To avoid data meaning being
eavesdropped by an attacker, a friendly jammer is deployed to transmit jamming
signals to interfere the attacker so as to hide the transmitted semantic
information. Meanwhile, the server will strategically select time slots for
semantic information transmission. Due to limited energy, the jammer will not
communicate with the server and hence the server does not know the transmit
power of the jammer. Therefore, the server must jointly optimize the semantic
information transmitted at each time slot and the corresponding transmit power
to maximize the privacy and the semantic information transmission quality of
the user. To solve this problem, we propose a prioritised sampling assisted
twin delayed deep deterministic policy gradient algorithm to jointly determine
the transmitted semantic information and the transmit power per time slot
without the communications between the server and the jammer. Compared to
standard reinforcement learning methods, the propose method uses an additional
Q network to estimate Q values such that the agent can select the action with a
lower Q value from the two Q networks thus avoiding local optimal action
selection and estimation bias of Q values. Simulation results show that the
proposed algorithm can improve the privacy and the semantic information
transmission quality by up to 77.8% and 14.3% compared to the traditional
reinforcement learning methods.

</details>


### [106] [HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol](https://arxiv.org/abs/2508.07602)
*Wenpeng Xing,Zhipeng Chen,Changting Lin,Meng Han*

Main category: cs.AI

TL;DR: HGMF通过分层高斯混合模型提高LLM工具选择的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在大规模、层次化工具库中选择工具时因上下文限制和噪声导致的低准确性和高计算成本问题。

Method: HGMF将查询和工具描述映射到统一语义空间，分两阶段使用高斯混合模型聚类和过滤，生成高相关性候选集。

Result: 实验表明HGMF显著提高工具选择准确性并降低推理延迟。

Conclusion: HGMF是一种可扩展且有效的大规模工具库解决方案。

Abstract: Invoking external tools enables Large Language Models (LLMs) to perform
complex, real-world tasks, yet selecting the correct tool from large,
hierarchically-structured libraries remains a significant challenge. The
limited context windows of LLMs and noise from irrelevant options often lead to
low selection accuracy and high computational costs. To address this, we
propose the Hierarchical Gaussian Mixture Framework (HGMF), a probabilistic
pruning method for scalable tool invocation. HGMF first maps the user query and
all tool descriptions into a unified semantic space. The framework then
operates in two stages: it clusters servers using a Gaussian Mixture Model
(GMM) and filters them based on the query's likelihood. Subsequently, it
applies the same GMM-based clustering and filtering to the tools associated
with the selected servers. This hierarchical process produces a compact,
high-relevance candidate set, simplifying the final selection task for the LLM.
Experiments on a public dataset show that HGMF significantly improves tool
selection accuracy while reducing inference latency, confirming the framework's
scalability and effectiveness for large-scale tool libraries.

</details>


### [107] [ThinkTuning: Instilling Cognitive Reflections without Distillation](https://arxiv.org/abs/2508.07616)
*Aswin RRV,Jacob Dineen,Divij Handa,Md Nayem Uddin,Mihir Parmar,Chitta Baral,Ben Zhou*

Main category: cs.AI

TL;DR: ThinkTuning是一种基于GRPO的交互式训练方法，通过教师模型的反馈提升学生模型的推理能力，实验显示在多任务基准上表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明强化学习（RL）仅能激发基础模型已有的推理行为，而无法真正培养新能力，因此需要一种方法让不具备此类行为的模型也能发展出推理能力。

Method: 提出ThinkTuning方法，通过教师模型对学生模型的尝试答案提供反馈，逐步引导学生模型改进推理能力。

Result: 在MATH-500、AIME和GPQA-Diamond等任务上，ThinkTuning分别比基线提升2.08%、2.23%和3.99%，平均提升3.85%。

Conclusion: ThinkTuning通过教师模型的隐式监督有效提升了学生模型的推理能力，为培养模型的自主思考能力提供了新思路。

Abstract: Recent advances in test-time scaling have led to the emergence of thinking
LLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL
drives this self-improvement paradigm, a recent study (Gandhi et al., 2025)
shows that RL alone does not truly instill these new reasoning abilities - it
merely draws out behaviors already present in the base models. This raises a
question: How can we train the models that don't exhibit such thinking behavior
to develop it in the first place? To this end, we propose ThinkTuning, a
GRPO-based interactive training approach where we augment the rollouts of a
student model with the guidance from a teacher model. A simple idea from
classroom practice inspires our method: a teacher poses a problem, lets the
student try an answer, then gives corrective feedback -- enough to point the
mind in the right direction and then show the solution. Each piece of feedback
reshapes the student's thoughts, leading them to arrive at the correct
solution. Similarly, we find that this type of implicit supervision through
feedback from a teacher model of the same size improves the reasoning
capabilities of the student model. In particular, on average, our method shows
a 3.85% improvement over zero-shot baselines across benchmarks, and on
MATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements
over the vanilla-GRPO baseline. Source code is available at
https://github.com/3rdAT/ThinkTuning.

</details>


### [108] [Multimodal AI Systems for Enhanced Laying Hen Welfare Assessment and Productivity Optimization](https://arxiv.org/abs/2508.07628)
*Daniel Essien,Suresh Neethirajan*

Main category: cs.AI

TL;DR: 论文提出利用多模态AI技术取代传统主观、劳动密集型的家禽福利监测，通过整合视觉、声音、环境和生理数据提升蛋鸡福利评估的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统家禽福利监测依赖人工观察和单一传感器数据，无法全面反映现代农场中蛋鸡福利的多维复杂性，亟需数据驱动的智能监测系统。

Method: 采用多模态AI技术，结合特征级融合策略，并引入领域转移评分（DTS）和数据可靠性指数（DRI）工具，提出模块化、情境感知的部署框架。

Result: 特征级融合策略在真实农场条件下表现最佳，平衡了鲁棒性和性能，同时提出的DTS和DRI工具能有效评估模型适应性和数据质量。

Conclusion: 该研究为从被动、单模态监测转向主动、精准驱动的福利系统奠定了基础，结合生产效率和科学伦理的动物关怀。

Abstract: The future of poultry production depends on a paradigm shift replacing
subjective, labor-intensive welfare checks with data-driven, intelligent
monitoring ecosystems. Traditional welfare assessments-limited by human
observation and single-sensor data-cannot fully capture the complex,
multidimensional nature of laying hen welfare in modern farms. Multimodal
Artificial Intelligence (AI) offers a breakthrough, integrating visual,
acoustic, environmental, and physiological data streams to reveal deeper
insights into avian welfare dynamics. This investigation highlights multimodal
As transformative potential, showing that intermediate (feature-level) fusion
strategies achieve the best balance between robustness and performance under
real-world poultry conditions, and offer greater scalability than early or late
fusion approaches. Key adoption barriers include sensor fragility in harsh farm
environments, high deployment costs, inconsistent behavioral definitions, and
limited cross-farm generalizability. To address these, we introduce two novel
evaluation tools - the Domain Transfer Score (DTS) to measure model
adaptability across diverse farm settings, and the Data Reliability Index (DRI)
to assess sensor data quality under operational constraints. We also propose a
modular, context-aware deployment framework designed for laying hen
environments, enabling scalable and practical integration of multimodal
sensing. This work lays the foundation for a transition from reactive, unimodal
monitoring to proactive, precision-driven welfare systems that unite
productivity with ethical, science based animal care.

</details>


### [109] [Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents](https://arxiv.org/abs/2508.07642)
*Tianyi Ma,Yue Zhang,Zehao Wang,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: SkillNav是一个模块化框架，通过技能分解和动态路由提升VLN任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂空间和时间推理的未见场景中泛化能力不足。

Method: 将导航任务分解为可解释的原子技能，并使用VLM动态路由选择最佳技能代理。

Result: 在R2R和GSA-R2R基准测试中达到新SOTA，泛化能力显著。

Conclusion: SkillNav通过模块化和技能分解有效提升了VLN任务的性能和泛化能力。

Abstract: Vision-and-Language Navigation (VLN) poses significant challenges in enabling
agents to interpret natural language instructions and navigate complex 3D
environments. While recent progress has been driven by large-scale pre-training
and data augmentation, current methods still struggle to generalize to unseen
scenarios, particularly when complex spatial and temporal reasoning is
required. In this work, we propose SkillNav, a modular framework that
introduces structured, skill-based reasoning into Transformer-based VLN agents.
Our method decomposes navigation into a set of interpretable atomic skills
(e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each
handled by a specialized agent. We then introduce a novel zero-shot
Vision-Language Model (VLM)-based router, which dynamically selects the most
suitable agent at each time step by aligning sub-goals with visual observations
and historical actions. SkillNav achieves a new state-of-the-art performance on
the R2R benchmark and demonstrates strong generalization to the GSA-R2R
benchmark that includes novel instruction styles and unseen environments.

</details>


### [110] [Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation](https://arxiv.org/abs/2508.07649)
*Jie Li,Haoye Dong,Zhengyang Wu,Zetao Zheng,Mingrong Lin*

Main category: cs.AI

TL;DR: DiMuST是一个基于解耦表示学习的POI推荐模型，通过多时空转换图和社会关系提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法将时空转换分开建模，导致关键节点表示不一致，增加了冗余信息和模型不确定性。

Method: 提出DiMuST模型，采用解耦变分多图自编码器（DAE），分离共享和私有分布，并通过PoE机制融合共享特征，对比约束去噪私有特征。

Result: 在两个数据集上，DiMuST在多个指标上显著优于现有方法。

Conclusion: DiMuST有效捕捉了POI的时空转换表示，同时保持了时空关系的固有相关性。

Abstract: Next Point-of-Interest (POI) recommendation is a research hotspot in business
intelligence, where users' spatial-temporal transitions and social
relationships play key roles. However, most existing works model spatial and
temporal transitions separately, leading to misaligned representations of the
same spatial-temporal key nodes. This misalignment introduces redundant
information during fusion, increasing model uncertainty and reducing
interpretability. To address this issue, we propose DiMuST, a socially enhanced
POI recommendation model based on disentangled representation learning over
multiplex spatial-temporal transition graphs. The model employs a novel
Disentangled variational multiplex graph Auto-Encoder (DAE), which first
disentangles shared and private distributions using a multiplex
spatial-temporal graph strategy. It then fuses the shared features via a
Product of Experts (PoE) mechanism and denoises the private features through
contrastive constraints. The model effectively captures the spatial-temporal
transition representations of POIs while preserving the intrinsic correlation
of their spatial-temporal relationships. Experiments on two challenging
datasets demonstrate that our DiMuST significantly outperforms existing methods
across multiple metrics.

</details>


### [111] [1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning](https://arxiv.org/abs/2508.07667)
*Wenkai Li,Liwen Sun,Zhenxiang Guan,Xuhui Zhou,Maarten Sap*

Main category: cs.AI

TL;DR: 提出多智能体框架解决LLMs处理多源信息时的隐私问题，通过分解隐私推理任务减少单智能体负担，实验显示显著降低隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在多源信息交互场景中的隐私问题，避免隐私信息泄露。

Method: 引入多智能体框架，分解隐私推理为提取、分类等子任务，并通过信息流拓扑分析隐私错误传播。

Result: 实验表明多智能体配置显著减少隐私泄露（ConfAIde 18%，PrivacyLens 19%），同时保持公共内容准确性。

Conclusion: 多智能体系统在LLMs的上下文隐私保护中具有潜力，信息流设计是关键。

Abstract: Addressing contextual privacy concerns remains challenging in interactive
settings where large language models (LLMs) process information from multiple
sources (e.g., summarizing meetings with private and public information). We
introduce a multi-agent framework that decomposes privacy reasoning into
specialized subtasks (extraction, classification), reducing the information
load on any single agent while enabling iterative validation and more reliable
adherence to contextual privacy norms. To understand how privacy errors emerge
and propagate, we conduct a systematic ablation over information-flow
topologies, revealing when and why upstream detection mistakes cascade into
downstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with
several open-source and closed-sourced LLMs demonstrate that our best
multi-agent configuration substantially reduces private information leakage
(\textbf{18\%} on ConfAIde and \textbf{19\%} on PrivacyLens with GPT-4o) while
preserving the fidelity of public content, outperforming single-agent
baselines. These results highlight the promise of principled information-flow
design in multi-agent systems for contextual privacy with LLMs.

</details>


### [112] [EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration](https://arxiv.org/abs/2508.07671)
*Mohamed Rayan Barhdadi,Mehmet Tuncel,Erchin Serpedin,Hasan Kurban*

Main category: cs.AI

TL;DR: EMPATHIA是一个多智能体框架，旨在解决难民整合中的文化、情感和伦理问题，通过三个模块（SEED、RISE、THRIVE）实现透明和可解释的决策。


<details>
  <summary>Details</summary>
Motivation: 当前AI方法在难民整合中过于关注就业等狭窄目标，忽视了文化、情感和伦理等长期成功的关键维度。

Method: 基于Kegan的建构发展理论，EMPATHIA分解整合过程为三个模块，采用选择器-验证器架构，由情感、文化和伦理三个智能体共同决策。

Result: 在UN Kakuma数据集上实验，验证收敛率达87.4%，并在五个东道国实现可解释的评估。

Conclusion: EMPATHIA通过平衡多种价值系统并支持人机协作，为AI驱动的分配任务提供了通用框架。

Abstract: Current AI approaches to refugee integration optimize narrow objectives such
as employment and fail to capture the cultural, emotional, and ethical
dimensions critical for long-term success. We introduce EMPATHIA (Enriched
Multimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance),
a multi-agent framework addressing the central Creative AI question: how do we
preserve human dignity when machines participate in life-altering decisions?
Grounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes
integration into three modules: SEED (Socio-cultural Entry and Embedding
Decision) for initial placement, RISE (Rapid Integration and Self-sufficiency
Engine) for early independence, and THRIVE (Transcultural Harmony and
Resilience through Integrated Values and Engagement) for sustained outcomes.
SEED employs a selector-validator architecture with three specialized agents -
emotional, cultural, and ethical - that deliberate transparently to produce
interpretable recommendations. Experiments on the UN Kakuma dataset (15,026
individuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and
implementation on 6,359 working-age refugees (15+) with 150+ socioeconomic
variables achieved 87.4% validation convergence and explainable assessments
across five host countries. EMPATHIA's weighted integration of cultural,
emotional, and ethical factors balances competing value systems while
supporting practitioner-AI collaboration. By augmenting rather than replacing
human expertise, EMPATHIA provides a generalizable framework for AI-driven
allocation tasks where multiple values must be reconciled.

</details>


### [113] [Ethics2vec: aligning automatic agents and human preferences](https://arxiv.org/abs/2508.07673)
*Gianluca Bontempi*

Main category: cs.AI

TL;DR: 论文提出了一种名为Ethics2Vec的方法，通过向量化AI代理的决策行为，评估其与人类伦理价值观的对齐程度。


<details>
  <summary>Details</summary>
Motivation: AI代理的行为中隐含的伦理价值观难以从人类角度理解和衡量，尤其是在涉及不可比较的价值观时（如生命价值与治疗成本）。

Method: 扩展Anything2vec方法，将代理的决策策略映射为多元向量表示，用于比较和评估与人类价值观的对齐。

Result: 提出了Ethics2Vec方法，并在二元决策和自动驾驶控制场景中验证其可行性。

Conclusion: Ethics2Vec为AI伦理对齐问题提供了一种量化解决方案，适用于多种自动决策场景。

Abstract: Though intelligent agents are supposed to improve human experience (or make
it more efficient), it is hard from a human perspective to grasp the ethical
values which are explicitly or implicitly embedded in an agent behaviour. This
is the well-known problem of alignment, which refers to the challenge of
designing AI systems that align with human values, goals and preferences. This
problem is particularly challenging since most human ethical considerations
refer to \emph{incommensurable} (i.e. non-measurable and/or incomparable)
values and criteria. Consider, for instance, a medical agent prescribing a
treatment to a cancerous patient. How could it take into account (and/or weigh)
incommensurable aspects like the value of a human life and the cost of the
treatment? Now, the alignment between human and artificial values is possible
only if we define a common space where a metric can be defined and used. This
paper proposes to extend to ethics the conventional Anything2vec approach,
which has been successful in plenty of similar and hard-to-quantify domains
(ranging from natural language processing to recommendation systems and graph
analysis). This paper proposes a way to map an automatic agent decision-making
(or control law) strategy to a multivariate vector representation, which can be
used to compare and assess the alignment with human values. The Ethics2Vec
method is first introduced in the case of an automatic agent performing binary
decision-making. Then, a vectorisation of an automatic control law (like in the
case of a self-driving car) is discussed to show how the approach can be
extended to automatic control settings.

</details>


### [114] [Symmetry-Aware Transformer Training for Automated Planning](https://arxiv.org/abs/2508.07743)
*Markus Fritzsche,Elliot Gestrin,Jendrik Seipp*

Main category: cs.AI

TL;DR: 提出一种对比学习目标，使Transformer能够感知对称性，从而解决其在自动规划领域的局限性。


<details>
  <summary>Details</summary>
Motivation: Transformer在自动规划中表现不佳，主要由于无法有效处理问题对称性导致的组合爆炸。

Method: 提出一种新颖的对比学习目标，结合架构改进，使Transformer能够高效学习规划任务。

Result: 实验结果表明，对称感知训练有效解决了PlanGPT的局限性。

Conclusion: 对称感知训练显著提升了Transformer在自动规划中的表现。

Abstract: While transformers excel in many settings, their application in the field of
automated planning is limited. Prior work like PlanGPT, a state-of-the-art
decoder-only transformer, struggles with extrapolation from easy to hard
planning problems. This in turn stems from problem symmetries: planning tasks
can be represented with arbitrary variable names that carry no meaning beyond
being identifiers. This causes a combinatorial explosion of equivalent
representations that pure transformers cannot efficiently learn from. We
propose a novel contrastive learning objective to make transformers
symmetry-aware and thereby compensate for their lack of inductive bias.
Combining this with architectural improvements, we show that transformers can
be efficiently trained for either plan-generation or heuristic-prediction. Our
results across multiple planning domains demonstrate that our symmetry-aware
training effectively and efficiently addresses the limitations of PlanGPT.

</details>


### [115] [Best-Effort Policies for Robust Markov Decision Processes](https://arxiv.org/abs/2508.07790)
*Alessandro Abate,Thom Badings,Giuseppe De Giacomo,Francesco Fabiano*

Main category: cs.AI

TL;DR: 论文研究了鲁棒马尔可夫决策过程（RMDPs），提出了一种新的策略选择标准——最优鲁棒最佳努力（ORBE）策略，以在非完全对抗性概率下最大化期望回报。


<details>
  <summary>Details</summary>
Motivation: 在RMDPs中，通常目标是计算在对抗性概率下最大化期望回报的策略。然而，可能存在多个最优鲁棒策略，这些策略在非对抗性概率下表现不同。因此，需要一种更精细的策略选择标准。

Method: 论文提出了ORBE策略的概念，结合了博弈论中的优势和最佳努力思想，要求策略不仅在对抗性概率下最优，还在非完全对抗性概率下表现最佳。作者证明了ORBE策略的存在性，并提出了计算算法。

Result: ORBE策略能够有效打破最优鲁棒策略之间的平局，数值实验验证了方法的可行性。

Conclusion: ORBE策略为RMDPs提供了一种更精细的策略选择标准，适用于实际应用中需要权衡对抗性和非对抗性场景的情况。

Abstract: We study the common generalization of Markov decision processes (MDPs) with
sets of transition probabilities, known as robust MDPs (RMDPs). A standard goal
in RMDPs is to compute a policy that maximizes the expected return under an
adversarial choice of the transition probabilities. If the uncertainty in the
probabilities is independent between the states, known as s-rectangularity,
such optimal robust policies can be computed efficiently using robust value
iteration. However, there might still be multiple optimal robust policies,
which, while equivalent with respect to the worst-case, reflect different
expected returns under non-adversarial choices of the transition probabilities.
Hence, we propose a refined policy selection criterion for RMDPs, drawing
inspiration from the notions of dominance and best-effort in game theory.
Instead of seeking a policy that only maximizes the worst-case expected return,
we additionally require the policy to achieve a maximal expected return under
different (i.e., not fully adversarial) transition probabilities. We call such
a policy an optimal robust best-effort (ORBE) policy. We prove that ORBE
policies always exist, characterize their structure, and present an algorithm
to compute them with a small overhead compared to standard robust value
iteration. ORBE policies offer a principled tie-breaker among optimal robust
policies. Numerical experiments show the feasibility of our approach.

</details>


### [116] [KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations](https://arxiv.org/abs/2508.07834)
*Mubaris Nadeem,Johannes Zenkert,Lisa Bender,Christian Weber,Madjid Fathi*

Main category: cs.AI

TL;DR: 本文提出了一种基于知识图谱和人工智能的创新知识管理系统，以帮助急救人员在紧急情况下提供个性化治疗建议。


<details>
  <summary>Details</summary>
Motivation: 全球救援需求增加，急救人员需快速评估患者状况并提供优化治疗，但时间紧迫限制了其知识应用。

Method: 采用知识图谱作为核心知识表示，结合人工智能预识别情境，为急救人员提供智能治疗建议。

Result: 系统能够实时计算、评估和处理知识，提升急救人员的治疗效率和准确性。

Conclusion: 知识图谱和人工智能的结合为急救场景提供了有效的知识管理解决方案，优化了紧急医疗响应。

Abstract: Over the years, the need for rescue operations throughout the world has
increased rapidly. Demographic changes and the resulting risk of injury or
health disorders form the basis for emergency calls. In such scenarios, first
responders are in a rush to reach the patient in need, provide first aid, and
save lives. In these situations, they must be able to provide personalized and
optimized healthcare in the shortest possible time and estimate the patients
condition with the help of freshly recorded vital data in an emergency
situation. However, in such a timedependent situation, first responders and
medical experts cannot fully grasp their knowledge and need assistance and
recommendation for further medical treatments. To achieve this, on the spot
calculated, evaluated, and processed knowledge must be made available to
improve treatments by first responders. The Knowledge Graph presented in this
article as a central knowledge representation provides first responders with an
innovative knowledge management that enables intelligent treatment
recommendations with an artificial intelligence-based pre-recognition of the
situation.

</details>


### [117] [\(X\)-evolve: Solution space evolution powered by large language models](https://arxiv.org/abs/2508.07932)
*Yi Zhai,Zhiqiang Wei,Ruohan Li,Keyu Pan,Shuo Liu,Lu Zhang,Jianmin Ji,Wuyang Zhang,Yu Zhang,Yanyong Zhang*

Main category: cs.AI

TL;DR: 论文提出X-evolve方法，通过演化解空间而非单个解，显著减少LLM调用成本，并在多个优化问题中取得突破性成果。


<details>
  <summary>Details</summary>
Motivation: 当前结合LLM与EA的方法通常演化单个解，导致LLM调用成本高，限制了解决复杂优化问题的效率。

Method: X-evolve通过LLM生成可调程序，定义参数化解空间，并利用基于评分的搜索算法高效探索，减少LLM调用。

Result: 在三个优化问题中取得显著成果：cap set问题中提升下界；信息论中发现更大独立集；在线装箱问题中生成更优启发式策略。

Conclusion: X-evolve通过解空间演化显著提升搜索效率，解决了以往计算不可行的高维问题。

Abstract: While combining large language models (LLMs) with evolutionary algorithms
(EAs) shows promise for solving complex optimization problems, current
approaches typically evolve individual solutions, often incurring high LLM call
costs. We introduce \(X\)-evolve, a paradigm-shifting method that instead
evolves solution spaces \(X\) (sets of individual solutions) - subsets of the
overall search space \(S\). In \(X\)-evolve, LLMs generate tunable programs
wherein certain code snippets, designated as parameters, define a tunable
solution space. A score-based search algorithm then efficiently explores this
parametrically defined space, guided by feedback from objective function
scores. This strategy enables broader and more efficient exploration, which can
potentially accelerate convergence at a much lower search cost, requiring up to
two orders of magnitude fewer LLM calls than prior leading methods. We
demonstrate \(X\)-evolve's efficacy across three distinct hard optimization
problems. For the cap set problem, we discover a larger partial admissible set,
establishing a new tighter asymptotic lower bound for the cap set constant (\(C
\ge 2.2203\)). In information theory, we uncover a larger independent set for
the 15-vertex cycle graph (\(\mathcal{C}_{15}^{\boxtimes 5}\), size 19,946),
thereby raising the known lower bound on its Shannon capacity. Furthermore, for
the NP-hard online bin packing problem, we generate heuristics that
consistently outperform standard strategies across established benchmarks. By
evolving solution spaces, our method considerably improves search
effectiveness, making it possible to tackle high-dimensional problems that were
previously computationally prohibitive.

</details>


### [118] [Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots](https://arxiv.org/abs/2508.07941)
*Olivier Poulet,Frédéric Guinand,François Guérin*

Main category: cs.AI

TL;DR: 提出一种基于短期预测的碰撞风险预测方法，使用LSTM模型预测机器人位置，并通过动态调整DQN奖励来减少碰撞。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在无通信或标识的受限环境中移动时的碰撞问题。

Method: 使用LSTM模型预测机器人位置，结合DQN动态调整奖励以减少碰撞。

Result: 在1Hz采样频率下，碰撞次数显著减少，稳定性提升。

Conclusion: 该方法计算成本低，适合嵌入式系统实现。

Abstract: This article proposes a collision risk anticipation method based on
short-term prediction of the agents position. A Long Short-Term Memory (LSTM)
model, trained on past trajectories, is used to estimate the next position of
each robot. This prediction allows us to define an anticipated collision risk
by dynamically modulating the reward of a Deep Q-Learning Network (DQN) agent.
The approach is tested in a constrained environment, where two robots move
without communication or identifiers. Despite a limited sampling frequency (1
Hz), the results show a significant decrease of the collisions number and a
stability improvement. The proposed method, which is computationally
inexpensive, appears particularly attractive for implementation on embedded
systems.

</details>


### [119] [FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis](https://arxiv.org/abs/2508.07950)
*Chen Shen,Wanqing Zhang,Kehan Li,Erwen Huang,Haitao Bi,Aiying Fan,Yiwen Shen,Hongmei Dong,Ji Zhang,Yuming Shao,Zengjia Liu,Xinshe Liu,Tao Li,Chunxia Yan,Shuanliang Fan,Di Wu,Jianhua Ma,Bin Cong,Zhenyuan Wang,Chunfeng Lian*

Main category: cs.AI

TL;DR: FEAT是一个多智能体AI框架，用于自动化法医死因鉴定，通过领域适应的大语言模型提升效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决法医死因鉴定中的劳动力短缺和诊断差异问题，特别是在高负荷系统如中国的法医体系中。

Method: FEAT结合任务分解、证据分析、迭代优化和结论合成的多模块架构，采用工具增强推理和层次化检索生成技术。

Result: FEAT在多样化的中国案例中表现优于现有AI系统，具有强泛化能力和高专家一致性。

Conclusion: FEAT是首个基于大语言模型的法医AI系统，结合AI效率和人类监督，提升法医服务的可及性和可靠性。

Abstract: Forensic cause-of-death determination faces systemic challenges, including
workforce shortages and diagnostic variability, particularly in high-volume
systems like China's medicolegal infrastructure. We introduce FEAT (ForEnsic
AgenT), a multi-agent AI framework that automates and standardizes death
investigations through a domain-adapted large language model. FEAT's
application-oriented architecture integrates: (i) a central Planner for task
decomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a
Memory & Reflection module for iterative refinement, and (iv) a Global Solver
for conclusion synthesis. The system employs tool-augmented reasoning,
hierarchical retrieval-augmented generation, forensic-tuned LLMs, and
human-in-the-loop feedback to ensure legal and medical validity. In evaluations
across diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI
systems in both long-form autopsy analyses and concise cause-of-death
conclusions. It demonstrated robust generalization across six geographic
regions and achieved high expert concordance in blinded validations. Senior
pathologists validated FEAT's outputs as comparable to those of human experts,
with improved detection of subtle evidentiary nuances. To our knowledge, FEAT
is the first LLM-based AI agent system dedicated to forensic medicine, offering
scalable, consistent death certification while maintaining expert-level rigor.
By integrating AI efficiency with human oversight, this work could advance
equitable access to reliable medicolegal services while addressing critical
capacity constraints in forensic systems.

</details>


### [120] [Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths](https://arxiv.org/abs/2508.08001)
*Rui Yao,Qi Chai,Jinhai Yao,Siyuan Li,Junhao Chen,Qi Zhang,Hao Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLM的、不确定性感知的框架，用于解析美联储的‘Fedspeak’语言并分类其货币政策立场，结合领域特定推理和动态不确定性解码模块，显著提升了分类准确性和模型可靠性。


<details>
  <summary>Details</summary>
Motivation: 美联储通过‘Fedspeak’语言传递隐含政策信号，对市场预期和经济条件有重要影响。自动解析‘Fedspeak’对金融预测、算法交易和政策分析具有重大意义。

Method: 提出LLM框架，结合货币政策传导机制的领域特定推理，并引入动态不确定性解码模块以评估预测置信度。

Result: 实验表明该框架在政策立场分析任务上达到最先进性能，且感知不确定性与模型错误率显著正相关。

Conclusion: 该框架有效提升了‘Fedspeak’解析的准确性和可靠性，感知不确定性可作为诊断信号。

Abstract: "Fedspeak", the stylized and often nuanced language used by the U.S. Federal
Reserve, encodes implicit policy signals and strategic stances. The Federal
Open Market Committee strategically employs Fedspeak as a communication tool to
shape market expectations and influence both domestic and global economic
conditions. As such, automatically parsing and interpreting Fedspeak presents a
high-impact challenge, with significant implications for financial forecasting,
algorithmic trading, and data-driven policy analysis. In this paper, we propose
an LLM-based, uncertainty-aware framework for deciphering Fedspeak and
classifying its underlying monetary policy stance. Technically, to enrich the
semantic and contextual representation of Fedspeak texts, we incorporate
domain-specific reasoning grounded in the monetary policy transmission
mechanism. We further introduce a dynamic uncertainty decoding module to assess
the confidence of model predictions, thereby enhancing both classification
accuracy and model reliability. Experimental results demonstrate that our
framework achieves state-of-the-art performance on the policy stance analysis
task. Moreover, statistical analysis reveals a significant positive correlation
between perceptual uncertainty and model error rates, validating the
effectiveness of perceptual uncertainty as a diagnostic signal.

</details>


### [121] [Fitting Description Logic Ontologies to ABox and Query Examples](https://arxiv.org/abs/2508.08007)
*Maurice Funk,Marvin Grosser,Carsten Lutz*

Main category: cs.AI

TL;DR: 研究基于本体介导查询的拟合问题，确定是否存在满足条件的本体，并分析其计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决本体介导查询中正负例拟合问题，为实际应用提供理论基础。

Method: 使用描述逻辑ALC和ALCI作为本体语言，结合多种查询语言（AQs、CQs、UCQs），分析拟合问题的有效性和复杂度。

Result: AQs和完整CQs的拟合问题为CONP复杂度，CQs和UCQs为2EXPTIME完全。

Conclusion: 研究为不同查询语言下的本体拟合问题提供了理论支持，揭示了其计算复杂度。

Abstract: We study a fitting problem inspired by ontology-mediated querying: given a
collection
  of positive and negative examples of
  the form $(\mathcal{A},q)$ with
  $\mathcal{A}$ an ABox and $q$ a Boolean query, we seek
  an ontology $\mathcal{O}$ that satisfies $\mathcal{A} \cup \mathcal{O} \vDash
q$ for all positive examples and $\mathcal{A} \cup \mathcal{O}\not\vDash q$ for
all negative examples.
  We consider the description logics $\mathcal{ALC}$ and $\mathcal{ALCI}$ as
ontology languages and
  a range of query languages that
  includes atomic queries (AQs), conjunctive queries (CQs), and unions thereof
(UCQs).
  For all of the resulting fitting problems,
  we provide
  effective characterizations and determine the computational complexity
  of deciding whether a fitting ontology exists. This problem turns out to be
${\small CO}NP$ for AQs and full CQs
  and $2E{\small XP}T{\small IME}$-complete for CQs and UCQs.
  These results hold for both $\mathcal{ALC}$ and $\mathcal{ALCI}$.

</details>


### [122] [AdaptFlow: Adaptive Workflow Optimization via Meta-Learning](https://arxiv.org/abs/2508.08053)
*Runchuan Zhu,Bowen Jiang,Lingrui Mei,Fangkai Yang,Lu Wang,Haoxiang Gao,Fengshuo Bai,Pu Zhao,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: AdaptFlow是一种基于自然语言的元学习框架，通过双层优化学习通用工作流初始化，快速适应子任务，并在多种任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态模板或手动设计的工作流，限制了适应性和可扩展性。

Method: 采用双层优化：内循环通过LLM反馈优化子任务工作流，外循环更新共享初始化。

Result: 在问答、代码生成和数学推理任务中超越基线，实现最优性能。

Conclusion: AdaptFlow通过语言引导的修改实现强泛化能力，适用于多样化任务。

Abstract: Recent advances in large language models (LLMs) have sparked growing interest
in agentic workflows, which are structured sequences of LLM invocations
intended to solve complex tasks. However, existing approaches often rely on
static templates or manually designed workflows, which limit adaptability to
diverse tasks and hinder scalability. We propose AdaptFlow, a natural
language-based meta-learning framework inspired by model-agnostic meta-learning
(MAML). AdaptFlow learns a generalizable workflow initialization that enables
rapid subtask-level adaptation. It employs a bi-level optimization scheme: the
inner loop refines the workflow for a specific subtask using LLM-generated
feedback, while the outer loop updates the shared initialization to perform
well across tasks. This setup allows AdaptFlow to generalize effectively to
unseen tasks by adapting the initialized workflow through language-guided
modifications. Evaluated across question answering, code generation, and
mathematical reasoning benchmarks, AdaptFlow consistently outperforms both
manually crafted and automatically searched baselines, achieving
state-of-the-art results with strong generalization across tasks and models.
The source code and data are available at
https://github.com/microsoft/DKI_LLM/tree/AdaptFlow/AdaptFlow.

</details>


### [123] [FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence](https://arxiv.org/abs/2508.08075)
*Meishen He,Wenjun Ma,Jiao Wang,Huijun Yue,Xiaoma Fan*

Main category: cs.AI

TL;DR: 本文提出了一种基于Dempster-Shafer理论的开放世界信息融合方法FNBT，解决了异构框架下的证据融合问题。


<details>
  <summary>Details</summary>
Motivation: 现实场景中，数据或模型常来自不同区域或组织，导致异构框架问题，传统融合方法效果不佳。

Method: 提出FNBT方法，通过扩展框架和全否定机制转换质量函数，使现有组合规则适用于异构框架。

Result: 理论证明FNBT满足质量函数不变性、遗传性和冲突消除性；实验显示其在分类任务中表现优异。

Conclusion: FNBT有效解决了异构框架下的信息融合问题，具有理论和实践价值。

Abstract: The Dempster-Shafer theory of evidence has been widely applied in the field
of information fusion under uncertainty. Most existing research focuses on
combining evidence within the same frame of discernment. However, in real-world
scenarios, trained algorithms or data often originate from different regions or
organizations, where data silos are prevalent. As a result, using different
data sources or models to generate basic probability assignments may lead to
heterogeneous frames, for which traditional fusion methods often yield
unsatisfactory results. To address this challenge, this study proposes an
open-world information fusion method, termed Full Negation Belief
Transformation (FNBT), based on the Dempster-Shafer theory. More specially, a
criterion is introduced to determine whether a given fusion task belongs to the
open-world setting. Then, by extending the frames, the method can accommodate
elements from heterogeneous frames. Finally, a full negation mechanism is
employed to transform the mass functions, so that existing combination rules
can be applied to the transformed mass functions for such information fusion.
Theoretically, the proposed method satisfies three desirable properties, which
are formally proven: mass function invariance, heritability, and essential
conflict elimination. Empirically, FNBT demonstrates superior performance in
pattern classification tasks on real-world datasets and successfully resolves
Zadeh's counterexample, thereby validating its practical effectiveness.

</details>


### [124] [TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork](https://arxiv.org/abs/2508.08115)
*Pranav Pushkar Mishra,Mohammad Arvan,Mohan Zalake*

Main category: cs.AI

TL;DR: TeamMedAgents将人类团队合作的心理学模型应用于多智能体医疗决策系统，通过六大核心团队合作组件提升LLMs的性能，在多个医疗基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 将人类团队合作的理论模型（如Salas的“Big Five”）转化为计算模型，以提升多智能体在医疗决策中的协作效果。

Method: 实现并评估六大团队合作组件（如团队领导力、共享心智模型等），通过模块化架构和消融实验分析各组件贡献。

Result: 在8个医疗基准测试中，7个表现提升，消融实验揭示了不同任务和领域的最优团队配置。

Conclusion: TeamMedAgents为关键决策领域的多智能体系统设计提供了理论基础，展示了团队合作模型在AI协作中的潜力。

Abstract: We present TeamMedAgents, a novel multi-agent approach that systematically
integrates evidence-based teamwork components from human-human collaboration
into medical decision-making with large language models (LLMs). Our approach
validates an organizational psychology teamwork model from human collaboration
to computational multi-agent medical systems by operationalizing six core
teamwork components derived from Salas et al.'s "Big Five" model: team
leadership, mutual performance monitoring, team orientation, shared mental
models, closed-loop communication, and mutual trust. We implement and evaluate
these components as modular, configurable mechanisms within an adaptive
collaboration architecture while assessing the effect of the number of agents
involved based on the task's requirements and domain. Systematic evaluation of
computational implementations of teamwork behaviors across eight medical
benchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets,
Path-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8
evaluated datasets. Controlled ablation studies conducted on 50 questions per
configuration across 3 independent runs provide mechanistic insights into
individual component contributions, revealing optimal teamwork configurations
that vary by reasoning task complexity and domain-specific requirements. Our
ablation analyses reveal dataset-specific optimal teamwork configurations,
indicating that different medical reasoning modalities benefit from distinct
collaborative patterns. TeamMedAgents represents an advancement in
collaborative AI by providing a systematic translation of established teamwork
theories from human collaboration into agentic collaboration, establishing a
foundation for evidence-based multi-agent system design in critical
decision-making domains.

</details>


### [125] [BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks](https://arxiv.org/abs/2508.08127)
*Rui Miao,Yixin Liu,Yili Wang,Xu Shen,Yue Tan,Yiwei Dai,Shirui Pan,Xin Wang*

Main category: cs.AI

TL;DR: BlindGuard是一种无监督防御方法，用于检测多智能体系统中的恶意代理，无需依赖标记数据或攻击先验知识。


<details>
  <summary>Details</summary>
Motivation: 现有监督防御方法依赖标记的恶意代理，不适用于实际场景，因此需要一种更通用且实用的防御方法。

Method: BlindGuard通过分层代理编码器捕捉个体、邻域和全局交互模式，并设计基于噪声注入和对比学习的检测器。

Result: 实验表明，BlindGuard能有效检测多种攻击类型，且在通用性上优于监督基线方法。

Conclusion: BlindGuard为多智能体系统提供了一种实用且通用的无监督防御解决方案。

Abstract: The security of LLM-based multi-agent systems (MAS) is critically threatened
by propagation vulnerability, where malicious agents can distort collective
decision-making through inter-agent message interactions. While existing
supervised defense methods demonstrate promising performance, they may be
impractical in real-world scenarios due to their heavy reliance on labeled
malicious agents to train a supervised malicious detection model. To enable
practical and generalizable MAS defenses, in this paper, we propose BlindGuard,
an unsupervised defense method that learns without requiring any
attack-specific labels or prior knowledge of malicious behaviors. To this end,
we establish a hierarchical agent encoder to capture individual, neighborhood,
and global interaction patterns of each agent, providing a comprehensive
understanding for malicious agent detection. Meanwhile, we design a
corruption-guided detector that consists of directional noise injection and
contrastive learning, allowing effective detection model training solely on
normal agent behaviors. Extensive experiments show that BlindGuard effectively
detects diverse attack types (i.e., prompt injection, memory poisoning, and
tool attack) across MAS with various communication patterns while maintaining
superior generalizability compared to supervised baselines. The code is
available at: https://github.com/MR9812/BlindGuard.

</details>


### [126] [From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework](https://arxiv.org/abs/2508.08147)
*Yunkai Hu,Tianqiao Zhao,Meng Yue*

Main category: cs.AI

TL;DR: 论文提出了一种基于大语言模型（LLMs）的代理，将电力系统优化场景的自然语言描述自动转换为可求解的数学模型，并通过验证和迭代修复确保可行性。


<details>
  <summary>Details</summary>
Motivation: 直接使用LLMs生成解决方案常导致不可行或次优结果，因其缺乏数值精度和约束处理能力。

Method: 结合领域感知提示与LLM，通过系统验证和迭代修复生成可求解的数学模型。

Result: 以机组组合问题为例，代理生成了最优或接近最优的调度方案及目标成本。

Conclusion: 结合AI与传统优化框架，能高效连接高层问题描述与可执行数学模型，提升能源系统决策效率。

Abstract: This paper introduces a novel Large Language Models (LLMs)-assisted agent
that automatically converts natural-language descriptions of power system
optimization scenarios into compact, solver-ready formulations and generates
corresponding solutions. In contrast to approaches that rely solely on LLM to
produce solutions directly, the proposed method focuses on discovering a
mathematically compatible formulation that can be efficiently solved by
off-the-shelf optimization solvers. Directly using LLMs to produce solutions
often leads to infeasible or suboptimal results, as these models lack the
numerical precision and constraint-handling capabilities of established
optimization solvers. The pipeline integrates a domain-aware prompt and schema
with an LLM, enforces feasibility through systematic validation and iterative
repair, and returns both solver-ready models and user-facing results. Using the
unit commitment problem as a representative case study, the agent produces
optimal or near-optimal schedules along with the associated objective costs.
Results demonstrate that coupling the solver with task-specific validation
significantly enhances solution reliability. This work shows that combining AI
with established optimization frameworks bridges high-level problem
descriptions and executable mathematical models, enabling more efficient
decision-making in energy systems

</details>
