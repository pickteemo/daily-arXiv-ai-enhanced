{"id": "2507.06373", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.06373", "abs": "https://arxiv.org/abs/2507.06373", "authors": ["Jeremy Fischer", "Ram Krishnamoorthy", "Vishal Kumar", "Mahdi Al-Husseini"], "title": "Digital Wargames to Enhance Military Medical Evacuation Decision-Making", "comment": null, "summary": "Medical evacuation is one of the United States Army's most storied and\ncritical mission sets, responsible for efficiently and expediently evacuating\nthe battlefield ill and injured. Medical evacuation planning involves designing\na robust network of medical platforms and facilities capable of moving and\ntreating large numbers of casualties. Until now, there has not been a medium to\nsimulate these networks in a classroom setting and evaluate both offline\nplanning and online decision-making performance. This work describes the\nMedical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer\nsimulation developed in Unity that replicates battlefield constraints and\nuncertainties. MEWI accurately models patient interactions at casualty\ncollection points, ambulance exchange points, medical treatment facilities, and\nevacuation platforms. Two operational scenarios are introduced: an amphibious\nisland assault in the Pacific and a Eurasian conflict across a sprawling road\nand river network. These scenarios pit students against the clock to save as\nmany casualties as possible while adhering to doctrinal lessons learned during\ndidactic training. We visualize performance data collected from two iterations\nof the MEWI Pacific scenario executed in the United States Army's Medical\nEvacuation Doctrine Course. We consider post-wargame Likert survey data from\nstudent participants and external observer notes to identify key planning\ndecision points, document medical evacuation lessons learned, and quantify\ngeneral utility. Results indicate that MEWI participation substantially\nimproves uptake of medical evacuation lessons learned and co-operative\ndecision-making. MEWI is a substantial step forward in the field of\nhigh-fidelity training tools for medical education, and our study findings\noffer critical insights into improving medical evacuation education and\noperations across the joint force."}
{"id": "2507.06396", "categories": ["cs.AI", "cs.LG", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.06396", "abs": "https://arxiv.org/abs/2507.06396", "authors": ["Mandana Vaziri", "Louis Mandel", "Yuji Watanabe", "Hirokuni Kitahara", "Martin Hirzel", "Anca Sailer"], "title": "Representing Prompting Patterns with PDL: Compliance Agent Case Study", "comment": "ICML 2025 Workshop on Programmatic Representations for Agent Learning", "summary": "Prompt engineering for LLMs remains complex, with existing frameworks either\nhiding complexity behind restrictive APIs or providing inflexible canned\npatterns that resist customization -- making sophisticated agentic programming\nchallenging. We present the Prompt Declaration Language (PDL), a novel approach\nto prompt representation that tackles this fundamental complexity by bringing\nprompts to the forefront, enabling manual and automatic prompt tuning while\ncapturing the composition of LLM calls together with rule-based code and\nexternal tools. By abstracting away the plumbing for such compositions, PDL\naims at improving programmer productivity while providing a declarative\nrepresentation that is amenable to optimization. This paper demonstrates PDL's\nutility through a real-world case study of a compliance agent. Tuning the\nprompting pattern of this agent yielded up to 4x performance improvement\ncompared to using a canned agent and prompt pattern."}
{"id": "2507.06398", "categories": ["cs.AI", "cs.CY", "68T01, 91B26, 93C15"], "pdf": "https://arxiv.org/pdf/2507.06398", "abs": "https://arxiv.org/abs/2507.06398", "authors": ["David Orban"], "title": "Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI", "comment": "13 pages, 2 figures. Revised following peer review", "summary": "This paper investigates the Jolting Technologies Hypothesis, which posits\nsuperexponential growth (increasing acceleration, or a positive third\nderivative) in the development of AI capabilities. We develop a theoretical\nframework and validate detection methodologies through Monte Carlo simulations,\nwhile acknowledging that empirical validation awaits suitable longitudinal\ndata. Our analysis focuses on creating robust tools for future empirical\nstudies and exploring the potential implications should the hypothesis prove\nvalid. The study examines how factors such as shrinking idea-to-action\nintervals and compounding iterative AI improvements drive this jolting pattern.\nBy formalizing jolt dynamics and validating detection methods through\nsimulation, this work provides the mathematical foundation necessary for\nunderstanding potential AI trajectories and their consequences for AGI\nemergence, offering insights for research and policy."}
{"id": "2507.06798", "categories": ["cs.AI", "math.LO"], "pdf": "https://arxiv.org/pdf/2507.06798", "abs": "https://arxiv.org/abs/2507.06798", "authors": ["Uri Andrews", "Luca San Mauro"], "title": "Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)", "comment": "25 pages, accepted at JELIA 2025", "summary": "Dialectical systems are a mathematical formalism for modeling an agent\nupdating a knowledge base seeking consistency. Introduced in the 1970s by\nRoberto Magari, they were originally conceived to capture how a working\nmathematician or a research community refines beliefs in the pursuit of truth.\nDialectical systems also serve as natural models for the belief change of an\nautomated agent, offering a unifying, computable framework for dynamic belief\nmanagement.\n  The literature distinguishes three main models of dialectical systems:\n(d-)dialectical systems based on revising beliefs when they are seen to be\ninconsistent, p-dialectical systems based on revising beliefs based on finding\na counterexample, and q-dialectical systems which can do both. We answer an\nopen problem in the literature by proving that q-dialectical systems are\nstrictly more powerful than p-dialectical systems, which are themselves known\nto be strictly stronger than (d-)dialectical systems. This result highlights\nthe complementary roles of counterexample and contradiction in automated belief\nrevision, and thus also in the reasoning processes of mathematicians and\nresearch communities."}
{"id": "2507.06346", "categories": ["cs.RO", "stat.CO"], "pdf": "https://arxiv.org/pdf/2507.06346", "abs": "https://arxiv.org/abs/2507.06346", "authors": ["Li Zhou", "Elvan Ceyhan"], "title": "Solving the Constrained Random Disambiguation Path Problem via Lagrangian Relaxation and Graph Reduction", "comment": null, "summary": "We study a resource-constrained variant of the Random Disambiguation Path\n(RDP) problem, a generalization of the Stochastic Obstacle Scene (SOS) problem,\nin which a navigating agent must reach a target in a spatial environment\npopulated with uncertain obstacles. Each ambiguous obstacle may be\ndisambiguated at a (possibly) heterogeneous resource cost, subject to a global\ndisambiguation budget. We formulate this constrained planning problem as a\nWeight-Constrained Shortest Path Problem (WCSPP) with risk-adjusted edge costs\nthat incorporate probabilistic blockage and traversal penalties. To solve it,\nwe propose a novel algorithmic framework-COLOGR-combining Lagrangian relaxation\nwith a two-phase vertex elimination (TPVE) procedure. The method prunes\ninfeasible and suboptimal paths while provably preserving the optimal solution,\nand leverages dual bounds to guide efficient search. We establish correctness,\nfeasibility guarantees, and surrogate optimality under mild assumptions. Our\nanalysis also demonstrates that COLOGR frequently achieves zero duality gap and\noffers improved computational complexity over prior constrained path-planning\nmethods. Extensive simulation experiments validate the algorithm's robustness\nacross varying obstacle densities, sensor accuracies, and risk models,\nconsistently outperforming greedy baselines and approaching offline-optimal\nbenchmarks. The proposed framework is broadly applicable to stochastic network\ndesign, mobility planning, and constrained decision-making under uncertainty."}
{"id": "2507.06852", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06852", "abs": "https://arxiv.org/abs/2507.06852", "authors": ["Uri Andrews", "Luca San Mauro"], "title": "SCC-recursiveness in infinite argumentation (extended version)", "comment": "26 pages, accepted at JELIA 2025", "summary": "Argumentation frameworks (AFs) are a foundational tool in artificial\nintelligence for modeling structured reasoning and conflict. SCC-recursiveness\nis a well-known design principle in which the evaluation of arguments is\ndecomposed according to the strongly connected components (SCCs) of the attack\ngraph, proceeding recursively from \"higher\" to \"lower\" components. While\nSCC-recursive semantics such as \\cft and \\stgt have proven effective for finite\nAFs, Baumann and Spanring showed the failure of SCC-recursive semantics to\ngeneralize reliably to infinite AFs due to issues with well-foundedness.\n  We propose two approaches to extending SCC-recursiveness to the infinite\nsetting. We systematically evaluate these semantics using Baroni and Giacomin's\nestablished criteria, showing in particular that directionality fails in\ngeneral. We then examine these semantics' behavior in finitary frameworks,\nwhere we find some of our semantics satisfy directionality. These results\nadvance the theory of infinite argumentation and lay the groundwork for\nreasoning systems capable of handling unbounded or evolving domains."}
{"id": "2507.06397", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06397", "abs": "https://arxiv.org/abs/2507.06397", "authors": ["Michalis Chatzispyrou", "Luke Horgan", "Hyunkil Hwang", "Harish Sathishchandra", "Monika Roznere", "Alberto Quattrini Li", "Philippos Mordohai", "Ioannis Rekleitis"], "title": "Mapping the Catacombs: An Underwater Cave Segment of the Devil's Eye System", "comment": "Presented at the 2025 IEEE ICRA Workshop on Field Robotics", "summary": "This paper presents a framework for mapping underwater caves. Underwater\ncaves are crucial for fresh water resource management, underwater archaeology,\nand hydrogeology. Mapping the cave's outline and dimensions, as well as\ncreating photorealistic 3D maps, is critical for enabling a better\nunderstanding of this underwater domain. In this paper, we present the mapping\nof an underwater cave segment (the catacombs) of the Devil's Eye cave system at\nGinnie Springs, FL. We utilized a set of inexpensive action cameras in\nconjunction with a dive computer to estimate the trajectories of the cameras\ntogether with a sparse point cloud. The resulting reconstructions are utilized\nto produce a one-dimensional retract of the cave passages in the form of the\naverage trajectory together with the boundaries (top, bottom, left, and right).\nThe use of the dive computer enables the observability of the z-dimension in\naddition to the roll and pitch in a visual/inertial framework (SVIn2). In\naddition, the keyframes generated by SVIn2 together with the estimated camera\nposes for select areas are used as input to a global optimization (bundle\nadjustment) framework -- COLMAP -- in order to produce a dense reconstruction\nof those areas. The same cave segment is manually surveyed using the MNemo V2\ninstrument, providing an additional set of measurements validating the proposed\napproach. It is worth noting that with the use of action cameras, the primary\ncomponents of a cave map can be constructed. Furthermore, with the utilization\nof a global optimization framework guided by the results of VI-SLAM package\nSVIn2, photorealistic dense 3D representations of selected areas can be\nreconstructed."}
{"id": "2507.06968", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.06968", "abs": "https://arxiv.org/abs/2507.06968", "authors": ["Li Du", "Hanyu Zhao", "Yiming Ju", "Tengfei Pan"], "title": "Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report", "comment": null, "summary": "Instruction tuning has become a foundation for unlocking the capabilities of\nlarge-scale pretrained models and improving their performance on complex tasks.\nThus, the construction of high-quality instruction datasets is crucial for\nenhancing model performance and generalizability. Although current instruction\ndatasets have reached tens of millions of samples, models finetuned on them may\nstill struggle with complex instruction following and tasks in rare domains.\nThis is primarily due to limited expansion in both ``coverage'' (coverage of\ntask types and knowledge areas) and ``depth'' (instruction complexity) of the\ninstruction set. To address this issue, we propose a systematic instruction\ndata construction framework, which integrates a hierarchical labeling system,\nan informative seed selection algorithm, an evolutionary data synthesis\nprocess, and a model deficiency diagnosis with targeted data generation. These\ncomponents form an iterative closed-loop to continuously enhance the coverage\nand depth of instruction data. Based on this framework, we construct\nInfinityInstruct-Subject, a high-quality dataset containing ~1.5 million\ninstructions. Experiments on multiple foundation models and benchmark tasks\ndemonstrate its effectiveness in improving instruction-following capabilities.\nFurther analyses suggest that InfinityInstruct-Subject shows enlarged coverage\nand depth compared to comparable synthesized instruction datasets. Our work\nlays a theoretical and practical foundation for the efficient, continuous\nevolution of instruction datasets, moving from data quantity expansion to\nqualitative improvement."}
{"id": "2507.06404", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06404", "abs": "https://arxiv.org/abs/2507.06404", "authors": ["Matteo Tiezzi", "Tommaso Apicella", "Carlos Cardenas-Perez", "Giovanni Fregonese", "Stefano Dafarra", "Pietro Morerio", "Daniele Pucci", "Alessio Del Bue"], "title": "Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction", "comment": null, "summary": "Evaluating and comparing the performance of autonomous Humanoid Robots is\nchallenging, as success rate metrics are difficult to reproduce and fail to\ncapture the complexity of robot movement trajectories, critical in Human-Robot\nInteraction and Collaboration (HRIC). To address these challenges, we propose a\ngeneral evaluation framework that measures the quality of Imitation Learning\n(IL) methods by focusing on trajectory performance. We devise the Neural Meta\nEvaluator (NeME), a deep learning model trained to classify actions from robot\njoint trajectories. NeME serves as a meta-evaluator to compare the performance\nof robot control policies, enabling policy evaluation without requiring human\ninvolvement in the loop. We validate our framework on ergoCub, a humanoid\nrobot, using teleoperation data and comparing IL methods tailored to the\navailable platform. The experimental results indicate that our method is more\naligned with the success rate obtained on the robot than baselines, offering a\nreproducible, systematic, and insightful means for comparing the performance of\nmultimodal imitation learning approaches in complex HRI tasks."}
{"id": "2507.06993", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.06993", "abs": "https://arxiv.org/abs/2507.06993", "authors": ["Jieren Deng", "Aleksandar Cvetkovic", "Pak Kiu Chung", "Dragomir Yankov", "Chiqun Zhang"], "title": "The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation", "comment": null, "summary": "Traditional travel-planning systems are often static and fragmented, leaving\nthem ill-equipped to handle real-world complexities such as evolving\nenvironmental conditions and unexpected itinerary disruptions. In this paper,\nwe identify three gaps between existing service providers causing frustrating\nuser experience: intelligent trip planning, precision \"last-100-meter\"\nnavigation, and dynamic itinerary adaptation. We propose three cooperative\nagents: a Travel Planning Agent that employs grid-based spatial grounding and\nmap analysis to help resolve complex multi-modal user queries; a Destination\nAssistant Agent that provides fine-grained guidance for the final navigation\nleg of each journey; and a Local Discovery Agent that leverages image\nembeddings and Retrieval-Augmented Generation (RAG) to detect and respond to\ntrip plan disruptions. With evaluations and experiments, our system\ndemonstrates substantial improvements in query interpretation, navigation\naccuracy, and disruption resilience, underscoring its promise for applications\nfrom urban exploration to emergency response."}
{"id": "2507.06426", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.06426", "abs": "https://arxiv.org/abs/2507.06426", "authors": ["Devin Crowley", "Whitney G. Cole", "Christina M. Hospodar", "Ruiting Shen", "Karen E. Adolph", "Alan Fern"], "title": "Evaluating Robots Like Human Infants: A Case Study of Learned Bipedal Locomotion", "comment": "7 pages, 4 figures, accepted into ICDL 2025 as a contributed paper", "summary": "Typically, learned robot controllers are trained via relatively unsystematic\nregimens and evaluated with coarse-grained outcome measures such as average\ncumulative reward. The typical approach is useful to compare learning\nalgorithms but provides limited insight into the effects of different training\nregimens and little understanding about the richness and complexity of learned\nbehaviors. Likewise, human infants and other animals are \"trained\" via\nunsystematic regimens, but in contrast, developmental psychologists evaluate\ntheir performance in highly-controlled experiments with fine-grained measures\nsuch as success, speed of walking, and prospective adjustments. However, the\nstudy of learned behavior in human infants is limited by the practical\nconstraints of training and testing babies. Here, we present a case study that\napplies methods from developmental psychology to study the learned behavior of\nthe simulated bipedal robot Cassie. Following research on infant walking, we\nsystematically designed reinforcement learning training regimens and tested the\nresulting controllers in simulated environments analogous to those used for\nbabies--but without the practical constraints. Results reveal new insights into\nthe behavioral impact of different training regimens and the development of\nCassie's learned behaviors relative to infants who are learning to walk. This\ninterdisciplinary baby-robot approach provides inspiration for future research\ndesigned to systematically test effects of training on the development of\ncomplex learned robot behaviors."}
{"id": "2507.07017", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.07017", "abs": "https://arxiv.org/abs/2507.07017", "authors": ["Tianyu Zheng", "Tianshun Xing", "Qingshui Gu", "Taoran Liang", "Xingwei Qu", "Xin Zhou", "Yizhi Li", "Zhoufutu Wen", "Chenghua Lin", "Wenhao Huang", "Qian Liu", "Ge Zhang", "Zejun Ma"], "title": "First Return, Entropy-Eliciting Explore", "comment": null, "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning\nabilities of Large Language Models (LLMs) but it struggles with unstable\nexploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a\nstructured exploration framework that identifies high-uncertainty decision\npoints in reasoning trajectories and performs targeted rollouts to construct\nsemantically grounded intermediate feedback. Our method provides targeted\nguidance without relying on dense supervision. Empirical results on\nmathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable\ntraining, produces longer and more coherent responses, and increases the\nproportion of fully correct trajectories. These results highlight the\nframework's effectiveness in improving LLM reasoning through more robust and\nstructured exploration."}
{"id": "2507.06519", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06519", "abs": "https://arxiv.org/abs/2507.06519", "authors": ["Yuhan Liu", "Xinyu Zhang", "Haonan Chang", "Abdeslam Boularias"], "title": "Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies", "comment": "Accepted at IROS2025. Project website:\n  https://jaysparrow.github.io/rit", "summary": "This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where\na robot must repeatedly perform high-precision insertions, such as screwing a\nnut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving\nmillimeter-level accuracy and maintaining consistent performance over multiple\nrepetitions, particularly when factors like nut rotation and friction introduce\nadditional complexity. We propose a sim-to-real framework that integrates a\nreinforcement learning-based insertion policy with a failure forecasting\nmodule. By representing the wrench's pose in the nut's coordinate frame rather\nthan the robot's frame, our approach significantly enhances sim-to-real\ntransferability. The insertion policy, trained in simulation, leverages\nreal-time 6D pose tracking to execute precise alignment, insertion, and\nrotation maneuvers. Simultaneously, a neural network predicts potential\nexecution failures, triggering a simple recovery mechanism that lifts the\nwrench and retries the insertion. Extensive experiments in both simulated and\nreal-world environments demonstrate that our method not only achieves a high\none-time success rate but also robustly maintains performance over long-horizon\nrepetitive tasks."}
{"id": "2507.06519", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06519", "abs": "https://arxiv.org/abs/2507.06519", "authors": ["Yuhan Liu", "Xinyu Zhang", "Haonan Chang", "Abdeslam Boularias"], "title": "Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies", "comment": "Accepted at IROS2025. Project website:\n  https://jaysparrow.github.io/rit", "summary": "This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where\na robot must repeatedly perform high-precision insertions, such as screwing a\nnut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving\nmillimeter-level accuracy and maintaining consistent performance over multiple\nrepetitions, particularly when factors like nut rotation and friction introduce\nadditional complexity. We propose a sim-to-real framework that integrates a\nreinforcement learning-based insertion policy with a failure forecasting\nmodule. By representing the wrench's pose in the nut's coordinate frame rather\nthan the robot's frame, our approach significantly enhances sim-to-real\ntransferability. The insertion policy, trained in simulation, leverages\nreal-time 6D pose tracking to execute precise alignment, insertion, and\nrotation maneuvers. Simultaneously, a neural network predicts potential\nexecution failures, triggering a simple recovery mechanism that lifts the\nwrench and retries the insertion. Extensive experiments in both simulated and\nreal-world environments demonstrate that our method not only achieves a high\none-time success rate but also robustly maintains performance over long-horizon\nrepetitive tasks."}
{"id": "2507.06562", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06562", "abs": "https://arxiv.org/abs/2507.06562", "authors": ["Keita Yoneda", "Kento Kawaharazuka", "Temma Suzuki", "Takahiro Hattori", "Kei Okada"], "title": "KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and Wall Climbing", "comment": "Accepted at IROS2025, website -\n  https://keitayoneda.github.io/kleiyn-chimney-climbing/, YouTube -\n  https://www.youtube.com/watch?v=vDmSfkazAvI", "summary": "In recent years, advancements in hardware have enabled quadruped robots to\noperate with high power and speed, while robust locomotion control using\nreinforcement learning (RL) has also been realized. As a result, expectations\nare rising for the automation of tasks such as material transport and\nexploration in unknown environments. However, autonomous locomotion in rough\nterrains with significant height variations requires vertical movement, and\nrobots capable of performing such movements stably, along with their control\nmethods, have not yet been fully established. In this study, we developed the\nquadruped robot KLEIYN, which features a waist joint, and aimed to expand\nquadruped locomotion by enabling chimney climbing through RL. To facilitate the\nlearning of vertical motion, we introduced Contact-Guided Curriculum Learning\n(CGCL). As a result, KLEIYN successfully climbed walls ranging from 800 mm to\n1000 mm in width at an average speed of 150 mm/s, 50 times faster than\nconventional robots. Furthermore, we demonstrated that the introduction of a\nwaist joint improves climbing performance, particularly enhancing tracking\nability on narrow walls."}
{"id": "2507.06564", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.06564", "abs": "https://arxiv.org/abs/2507.06564", "authors": ["Tianshun Li", "Tianyi Huai", "Zhen Li", "Yichun Gao", "Haoang Li", "Xinhu Zheng"], "title": "SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments", "comment": "8 pages, 9 figures, has been accepted by IROS 2025", "summary": "Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across\nvarious sectors, driven by their mobility and adaptability. This paper\nintroduces SkyVLN, a novel framework integrating vision-and-language navigation\n(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in\ncomplex urban environments. Unlike traditional navigation methods, SkyVLN\nleverages Large Language Models (LLMs) to interpret natural language\ninstructions and visual observations, enabling UAVs to navigate through dynamic\n3D spaces with improved accuracy and robustness. We present a multimodal\nnavigation agent equipped with a fine-grained spatial verbalizer and a history\npath memory mechanism. These components allow the UAV to disambiguate spatial\ncontexts, handle ambiguous instructions, and backtrack when necessary. The\nframework also incorporates an NMPC module for dynamic obstacle avoidance,\nensuring precise trajectory tracking and collision prevention. To validate our\napproach, we developed a high-fidelity 3D urban simulation environment using\nAirSim, featuring realistic imagery and dynamic urban elements. Extensive\nexperiments demonstrate that SkyVLN significantly improves navigation success\nrates and efficiency, particularly in new and unseen environments."}
{"id": "2507.06564", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.06564", "abs": "https://arxiv.org/abs/2507.06564", "authors": ["Tianshun Li", "Tianyi Huai", "Zhen Li", "Yichun Gao", "Haoang Li", "Xinhu Zheng"], "title": "SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments", "comment": "8 pages, 9 figures, has been accepted by IROS 2025", "summary": "Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across\nvarious sectors, driven by their mobility and adaptability. This paper\nintroduces SkyVLN, a novel framework integrating vision-and-language navigation\n(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in\ncomplex urban environments. Unlike traditional navigation methods, SkyVLN\nleverages Large Language Models (LLMs) to interpret natural language\ninstructions and visual observations, enabling UAVs to navigate through dynamic\n3D spaces with improved accuracy and robustness. We present a multimodal\nnavigation agent equipped with a fine-grained spatial verbalizer and a history\npath memory mechanism. These components allow the UAV to disambiguate spatial\ncontexts, handle ambiguous instructions, and backtrack when necessary. The\nframework also incorporates an NMPC module for dynamic obstacle avoidance,\nensuring precise trajectory tracking and collision prevention. To validate our\napproach, we developed a high-fidelity 3D urban simulation environment using\nAirSim, featuring realistic imagery and dynamic urban elements. Extensive\nexperiments demonstrate that SkyVLN significantly improves navigation success\nrates and efficiency, particularly in new and unseen environments."}
{"id": "2507.06625", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06625", "abs": "https://arxiv.org/abs/2507.06625", "authors": ["Shizhe Cai", "Jayadeep Jacob", "Zeya Yin", "Fabio Ramos"], "title": "Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic", "comment": "9 pages, 10 figures", "summary": "Deep reinforcement learning has shown remarkable success in continuous\ncontrol tasks, yet often requires extensive training data, struggles with\ncomplex, long-horizon planning, and fails to maintain safety constraints during\noperation. Meanwhile, Model Predictive Control (MPC) offers explainability and\nconstraint satisfaction, but typically yields only locally optimal solutions\nand demands careful cost function design. This paper introduces the Q-guided\nSTein variational model predictive Actor-Critic (Q-STAC), a novel framework\nthat bridges these approaches by integrating Bayesian MPC with actor-critic\nreinforcement learning through constrained Stein Variational Gradient Descent\n(SVGD). Our method optimizes control sequences directly using learned Q-values\nas objectives, eliminating the need for explicit cost function design while\nleveraging known system dynamics to enhance sample efficiency and ensure\ncontrol signals remain within safe boundaries. Extensive experiments on 2D\nnavigation and robotic manipulation tasks demonstrate that Q-STAC achieves\nsuperior sample efficiency, robustness, and optimality compared to\nstate-of-the-art algorithms, while maintaining the high expressiveness of\npolicy distributions. Experiment videos are available on our website:\nhttps://sites.google.com/view/q-stac"}
{"id": "2507.06574", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06574", "abs": "https://arxiv.org/abs/2507.06574", "authors": ["Thomas Touma", "Ersin Da≈ü", "Erica Tevere", "Martin Feather", "Ksenia Kolcio", "Maurice Prather", "Alberto Candela", "Ashish Goel", "Erik Kramer", "Hari Nayar", "Lorraine Fesq", "Joel W. Burdick"], "title": "AI Space Cortex: An Experimental System for Future Era Space Exploration", "comment": null, "summary": "Our Robust, Explainable Autonomy for Scientific Icy Moon Operations (REASIMO)\neffort contributes to NASA's Concepts for Ocean worlds Life Detection\nTechnology (COLDTech) program, which explores science platform technologies for\nocean worlds such as Europa and Enceladus. Ocean world missions pose\nsignificant operational challenges. These include long communication lags,\nlimited power, and lifetime limitations caused by radiation damage and hostile\nconditions. Given these operational limitations, onboard autonomy will be vital\nfor future Ocean world missions. Besides the management of nominal lander\noperations, onboard autonomy must react appropriately in the event of\nanomalies. Traditional spacecraft rely on a transition into 'safe-mode' in\nwhich non-essential components and subsystems are powered off to preserve\nsafety and maintain communication with Earth. For a severely time-limited Ocean\nworld mission, resolutions to these anomalies that can be executed without\nEarth-in-the-loop communication and associated delays are paramount for\ncompletion of the mission objectives and science goals. To address these\nchallenges, the REASIMO effort aims to demonstrate a robust level of\nAI-assisted autonomy for such missions, including the ability to detect and\nrecover from anomalies, and to perform missions based on pre-trained behaviors\nrather than hard-coded, predetermined logic like all prior space missions. We\ndeveloped an AI-assisted, personality-driven, intelligent framework for control\nof an Ocean world mission by combining a mix of advanced technologies. To\ndemonstrate the capabilities of the framework, we perform tests of autonomous\nsampling operations on a lander-manipulator testbed at the NASA Jet Propulsion\nLaboratory, approximating possible surface conditions such a mission might\nencounter."}
{"id": "2507.06605", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06605", "abs": "https://arxiv.org/abs/2507.06605", "authors": ["Xinyu Wu"], "title": "Growing Trees with an Agent: Accelerating RRTs with Learned, Multi-Step Episodic Exploration", "comment": null, "summary": "Classical sampling-based motion planners like the RRTs suffer from\ninefficiencies, particularly in cluttered or high-dimensional spaces, due to\ntheir reliance on undirected, random sampling. This paper introduces the\nEpisodic RRT, a novel hybrid planning framework that replaces the primitive of\na random point with a learned, multi-step \"exploratory episode\" generated by a\nDeep Reinforcement Learning agent. By making the DRL agent the engine of\nexploration, ERRT transforms the search process from a diffuse, volumetric\nexpansion into a directed, branch-like growth. This paradigm shift yields key\nadvantages: it counters the curse of dimensionality with focused exploration,\nminimizes expensive collision checks by proactively proposing locally valid\npaths, and improves connectivity by generating inherently connected path\nsegments. We demonstrate through extensive empirical evaluation across 2D, 3D,\nand 6D environments that ERRT and its variants consistently and significantly\noutperform their classical counterparts. In a challenging 6D robotic arm\nscenario, ERRT achieves a 98% success rate compared to 19% for RRT, is up to\n107x faster, reduces collision checks by over 99.6%, and finds initial paths\nthat are nearly 50% shorter. Furthermore, its asymptotically optimal variant,\nERRT*, demonstrates vastly superior anytime performance, refining solutions to\nnear-optimality up to 29x faster than standard RRT* in 3D environments. Code:\nhttps://xinyuwuu.github.io/Episodic_RRT/."}
{"id": "2507.06625", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06625", "abs": "https://arxiv.org/abs/2507.06625", "authors": ["Shizhe Cai", "Jayadeep Jacob", "Zeya Yin", "Fabio Ramos"], "title": "Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic", "comment": "9 pages, 10 figures", "summary": "Deep reinforcement learning has shown remarkable success in continuous\ncontrol tasks, yet often requires extensive training data, struggles with\ncomplex, long-horizon planning, and fails to maintain safety constraints during\noperation. Meanwhile, Model Predictive Control (MPC) offers explainability and\nconstraint satisfaction, but typically yields only locally optimal solutions\nand demands careful cost function design. This paper introduces the Q-guided\nSTein variational model predictive Actor-Critic (Q-STAC), a novel framework\nthat bridges these approaches by integrating Bayesian MPC with actor-critic\nreinforcement learning through constrained Stein Variational Gradient Descent\n(SVGD). Our method optimizes control sequences directly using learned Q-values\nas objectives, eliminating the need for explicit cost function design while\nleveraging known system dynamics to enhance sample efficiency and ensure\ncontrol signals remain within safe boundaries. Extensive experiments on 2D\nnavigation and robotic manipulation tasks demonstrate that Q-STAC achieves\nsuperior sample efficiency, robustness, and optimality compared to\nstate-of-the-art algorithms, while maintaining the high expressiveness of\npolicy distributions. Experiment videos are available on our website:\nhttps://sites.google.com/view/q-stac"}
{"id": "2507.06690", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06690", "abs": "https://arxiv.org/abs/2507.06690", "authors": ["Guobin Zhu", "Rui Zhou", "Wenkang Ji", "Hongyin Zhang", "Donglin Wang", "Shiyu Zhao"], "title": "Multi-Task Multi-Agent Reinforcement Learning via Skill Graphs", "comment": "Conditionally accepted by IEEE Robotics and Automation Letters", "summary": "Multi-task multi-agent reinforcement learning (MT-MARL) has recently gained\nattention for its potential to enhance MARL's adaptability across multiple\ntasks. However, it is challenging for existing multi-task learning methods to\nhandle complex problems, as they are unable to handle unrelated tasks and\npossess limited knowledge transfer capabilities. In this paper, we propose a\nhierarchical approach that efficiently addresses these challenges. The\nhigh-level module utilizes a skill graph, while the low-level module employs a\nstandard MARL algorithm. Our approach offers two contributions. First, we\nconsider the MT-MARL problem in the context of unrelated tasks, expanding the\nscope of MTRL. Second, the skill graph is used as the upper layer of the\nstandard hierarchical approach, with training independent of the lower layer,\neffectively handling unrelated tasks and enhancing knowledge transfer\ncapabilities. Extensive experiments are conducted to validate these advantages\nand demonstrate that the proposed method outperforms the latest hierarchical\nMAPPO algorithms. Videos and code are available at\nhttps://github.com/WindyLab/MT-MARL-SG"}
{"id": "2507.06700", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.06700", "abs": "https://arxiv.org/abs/2507.06700", "authors": ["Pranav Pandey", "Ramviyas Parasuraman", "Prashant Doshi"], "title": "Integrating Perceptions: A Human-Centered Physical Safety Model for Human-Robot Interaction", "comment": "Accepted to IEEE RO-MAN 2025 Conference", "summary": "Ensuring safety in human-robot interaction (HRI) is essential to foster user\ntrust and enable the broader adoption of robotic systems. Traditional safety\nmodels primarily rely on sensor-based measures, such as relative distance and\nvelocity, to assess physical safety. However, these models often fail to\ncapture subjective safety perceptions, which are shaped by individual traits\nand contextual factors. In this paper, we introduce and analyze a parameterized\ngeneral safety model that bridges the gap between physical and perceived safety\nby incorporating a personalization parameter, $\\rho$, into the safety\nmeasurement framework to account for individual differences in safety\nperception. Through a series of hypothesis-driven human-subject studies in a\nsimulated rescue scenario, we investigate how emotional state, trust, and robot\nbehavior influence perceived safety. Our results show that $\\rho$ effectively\ncaptures meaningful individual differences, driven by affective responses,\ntrust in task consistency, and clustering into distinct user types.\nSpecifically, our findings confirm that predictable and consistent robot\nbehavior as well as the elicitation of positive emotional states, significantly\nenhance perceived safety. Moreover, responses cluster into a small number of\nuser types, supporting adaptive personalization based on shared safety models.\nNotably, participant role significantly shapes safety perception, and repeated\nexposure reduces perceived safety for participants in the casualty role,\nemphasizing the impact of physical interaction and experiential change. These\nfindings highlight the importance of adaptive, human-centered safety models\nthat integrate both psychological and behavioral dimensions, offering a pathway\ntoward more trustworthy and effective HRI in safety-critical domains."}
{"id": "2507.06710", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06710", "abs": "https://arxiv.org/abs/2507.06710", "authors": ["Zhenyang Liu", "Yikai Wang", "Kuanning Wang", "Longfei Liang", "Xiangyang Xue", "Yanwei Fu"], "title": "Spatial-Temporal Aware Visuomotor Diffusion Policy Learning", "comment": null, "summary": "Visual imitation learning is effective for robots to learn versatile tasks.\nHowever, many existing methods rely on behavior cloning with supervised\nhistorical trajectories, limiting their 3D spatial and 4D spatiotemporal\nawareness. Consequently, these methods struggle to capture the 3D structures\nand 4D spatiotemporal relationships necessary for real-world deployment. In\nthis work, we propose 4D Diffusion Policy (DP4), a novel visual imitation\nlearning method that incorporates spatiotemporal awareness into diffusion-based\npolicies. Unlike traditional approaches that rely on trajectory cloning, DP4\nleverages a dynamic Gaussian world model to guide the learning of 3D spatial\nand 4D spatiotemporal perceptions from interactive environments. Our method\nconstructs the current 3D scene from a single-view RGB-D observation and\npredicts the future 3D scene, optimizing trajectory generation by explicitly\nmodeling both spatial and temporal dependencies. Extensive experiments across\n17 simulation tasks with 173 variants and 3 real-world robotic tasks\ndemonstrate that the 4D Diffusion Policy (DP4) outperforms baseline methods,\nimproving the average simulation task success rate by 16.4% (Adroit), 14%\n(DexArt), and 6.45% (RLBench), and the average real-world robotic task success\nrate by 8.6%."}
{"id": "2507.06747", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.06747", "abs": "https://arxiv.org/abs/2507.06747", "authors": ["Daojie Peng", "Jiahang Cao", "Qiang Zhang", "Jun Ma"], "title": "LOVON: Legged Open-Vocabulary Object Navigator", "comment": "9 pages, 10 figures; Project Page:\n  https://daojiepeng.github.io/LOVON/", "summary": "Object navigation in open-world environments remains a formidable and\npervasive challenge for robotic systems, particularly when it comes to\nexecuting long-horizon tasks that require both open-world object detection and\nhigh-level task planning. Traditional methods often struggle to integrate these\ncomponents effectively, and this limits their capability to deal with complex,\nlong-range navigation missions. In this paper, we propose LOVON, a novel\nframework that integrates large language models (LLMs) for hierarchical task\nplanning with open-vocabulary visual detection models, tailored for effective\nlong-range object navigation in dynamic, unstructured environments. To tackle\nreal-world challenges including visual jittering, blind zones, and temporary\ntarget loss, we design dedicated solutions such as Laplacian Variance Filtering\nfor visual stabilization. We also develop a functional execution logic for the\nrobot that guarantees LOVON's capabilities in autonomous navigation, task\nadaptation, and robust task completion. Extensive evaluations demonstrate the\nsuccessful completion of long-sequence tasks involving real-time detection,\nsearch, and navigation toward open-vocabulary dynamic targets. Furthermore,\nreal-world experiments across different legged robots (Unitree Go2, B2, and\nH1-2) showcase the compatibility and appealing plug-and-play feature of LOVON."}
{"id": "2507.06750", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.06750", "abs": "https://arxiv.org/abs/2507.06750", "authors": ["Tohid Kargar Tasooji", "Ramviyas Parasuraman"], "title": "Distributed Fault-Tolerant Multi-Robot Cooperative Localization in Adversarial Environments", "comment": "Accepted to IROS 2025 Conference", "summary": "In multi-robot systems (MRS), cooperative localization is a crucial task for\nenhancing system robustness and scalability, especially in GPS-denied or\ncommunication-limited environments. However, adversarial attacks, such as\nsensor manipulation, and communication jamming, pose significant challenges to\nthe performance of traditional localization methods. In this paper, we propose\na novel distributed fault-tolerant cooperative localization framework to\nenhance resilience against sensor and communication disruptions in adversarial\nenvironments. We introduce an adaptive event-triggered communication strategy\nthat dynamically adjusts communication thresholds based on real-time sensing\nand communication quality. This strategy ensures optimal performance even in\nthe presence of sensor degradation or communication failure. Furthermore, we\nconduct a rigorous analysis of the convergence and stability properties of the\nproposed algorithm, demonstrating its resilience against bounded adversarial\nzones and maintaining accurate state estimation. Robotarium-based experiment\nresults show that our proposed algorithm significantly outperforms traditional\nmethods in terms of localization accuracy and communication efficiency,\nparticularly in adversarial settings. Our approach offers improved scalability,\nreliability, and fault tolerance for MRS, making it suitable for large-scale\ndeployments in real-world, challenging environments."}
{"id": "2507.06787", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.06787", "abs": "https://arxiv.org/abs/2507.06787", "authors": ["Sean Smith", "Emmanuel Witrant", "Ya-Jun Pan"], "title": "Stream Function-Based Navigation for Complex Quadcopter Obstacle Avoidance", "comment": null, "summary": "This article presents a novel stream function-based navigational control\nsystem for obstacle avoidance, where obstacles are represented as\ntwo-dimensional (2D) rigid surfaces in inviscid, incompressible flows. The\napproach leverages the vortex panel method (VPM) and incorporates safety\nmargins to control the stream function and flow properties around virtual\nsurfaces, enabling navigation in complex, partially observed environments using\nreal-time sensing. To address the limitations of the VPM in managing relative\ndistance and avoiding rapidly accelerating obstacles at close proximity, the\nsystem integrates a model predictive controller (MPC) based on higher-order\ncontrol barrier functions (HOCBF). This integration incorporates VPM trajectory\ngeneration, state estimation, and constraint handling into a receding-horizon\noptimization problem. The 2D rigid surfaces are enclosed using minimum bounding\nellipses (MBEs), while an adaptive Kalman filter (AKF) captures and predicts\nobstacle dynamics, propagating these estimates into the MPC-HOCBF for rapid\navoidance maneuvers. Evaluation is conducted using a PX4-powered Clover drone\nGazebo simulator and real-time experiments involving a COEX Clover quadcopter\nequipped with a 360 degree LiDAR sensor."}
{"id": "2507.06822", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06822", "abs": "https://arxiv.org/abs/2507.06822", "authors": ["Wei Xu", "Yanchao Zhao", "Weichao Guo", "Xinjun Sheng"], "title": "Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand", "comment": "Accepted by 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025). copyright 2025 IEEE. Final version to appear\n  in IEEE Xplore", "summary": "Manipulating articulated tools, such as tweezers or scissors, has rarely been\nexplored in previous research. Unlike rigid tools, articulated tools change\ntheir shape dynamically, creating unique challenges for dexterous robotic\nhands. In this work, we present a hierarchical, goal-conditioned reinforcement\nlearning (GCRL) framework to improve the manipulation capabilities of\nanthropomorphic robotic hands using articulated tools. Our framework comprises\ntwo policy layers: (1) a low-level policy that enables the dexterous hand to\nmanipulate the tool into various configurations for objects of different sizes,\nand (2) a high-level policy that defines the tool's goal state and controls the\nrobotic arm for object-picking tasks. We employ an encoder, trained on\nsynthetic pointclouds, to estimate the tool's affordance states--specifically,\nhow different tool configurations (e.g., tweezer opening angles) enable\ngrasping of objects of varying sizes--from input point clouds, thereby enabling\nprecise tool manipulation. We also utilize a privilege-informed heuristic\npolicy to generate replay buffer, improving the training efficiency of the\nhigh-level policy. We validate our approach through real-world experiments,\nshowing that the robot can effectively manipulate a tweezer-like tool to grasp\nobjects of diverse shapes and sizes with a 70.8 % success rate. This study\nhighlights the potential of RL to advance dexterous robotic manipulation of\narticulated tools."}
{"id": "2507.06824", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06824", "abs": "https://arxiv.org/abs/2507.06824", "authors": ["Gabriel Arslan Waltersson", "Yiannis Karayiannidis"], "title": "Friction Estimation for In-Hand Planar Motion", "comment": null, "summary": "This paper presents a method for online estimation of contact properties\nduring in-hand sliding manipulation with a parallel gripper. We estimate the\nstatic and Coulomb friction as well as the contact radius from tactile\nmeasurements of contact forces and sliding velocities. The method is validated\nin both simulation and real-world experiments. Furthermore, we propose a\nheuristic to deal with fast slip-stick dynamics which can adversely affect the\nestimation."}
{"id": "2507.06884", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06884", "abs": "https://arxiv.org/abs/2507.06884", "authors": ["Dong Bi", "Yongqi Zhao", "Zhengguo Gu", "Tomislav Mihalj", "Jia Hu", "Arno Eichberger"], "title": "Toward a Full-Stack Co-Simulation Platform for Testing of Automated Driving Systems", "comment": "IEEE International Conference on Intelligent Transportation Systems\n  (ITSC) 2025", "summary": "Virtual testing has emerged as an effective approach to accelerate the\ndeployment of automated driving systems. Nevertheless, existing simulation\ntoolchains encounter difficulties in integrating rapid, automated scenario\ngeneration with simulation environments supporting advanced automated driving\ncapabilities. To address this limitation, a full-stack toolchain is presented,\nenabling automatic scenario generation from real-world datasets and efficient\nvalidation through a co-simulation platform based on CarMaker, ROS, and Apollo.\nThe simulation results demonstrate the effectiveness of the proposed toolchain.\nA demonstration video showcasing the toolchain is available at the provided\nlink: https://youtu.be/taJw_-CmSiY."}
{"id": "2507.06905", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06905", "abs": "https://arxiv.org/abs/2507.06905", "authors": ["Wandong Sun", "Luying Feng", "Baoshi Cao", "Yang Liu", "Yaochu Jin", "Zongwu Xie"], "title": "ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation", "comment": null, "summary": "Loco-Manipulation for humanoid robots aims to enable robots to integrate\nmobility with upper-body tracking capabilities. Most existing approaches adopt\nhierarchical architectures that decompose control into isolated upper-body\n(manipulation) and lower-body (locomotion) policies. While this decomposition\nreduces training complexity, it inherently limits coordination between\nsubsystems and contradicts the unified whole-body control exhibited by humans.\nWe demonstrate that a single unified policy can achieve a combination of\ntracking accuracy, large workspace, and robustness for humanoid\nloco-manipulation. We propose the Unified Loco-Manipulation Controller (ULC), a\nsingle-policy framework that simultaneously tracks root velocity, root height,\ntorso rotation, and dual-arm joint positions in an end-to-end manner, proving\nthe feasibility of unified control without sacrificing performance. We achieve\nthis unified control through key technologies: sequence skill acquisition for\nprogressive learning complexity, residual action modeling for fine-grained\ncontrol adjustments, command polynomial interpolation for smooth motion\ntransitions, random delay release for robustness to deploy variations, load\nrandomization for generalization to external disturbances, and\ncenter-of-gravity tracking for providing explicit policy gradients to maintain\nstability. We validate our method on the Unitree G1 humanoid robot with 3-DOF\n(degrees-of-freedom) waist. Compared with strong baselines, ULC shows better\ntracking performance to disentangled methods and demonstrating larger workspace\ncoverage. The unified dual-arm tracking enables precise manipulation under\nexternal loads while maintaining coordinated whole-body control for complex\nloco-manipulation tasks."}
{"id": "2507.06960", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06960", "abs": "https://arxiv.org/abs/2507.06960", "authors": ["Samuel Matloob", "Ayan Dutta", "O. Patrick Kreidl", "Swapnonel Roy", "Ladislau B√∂l√∂ni"], "title": "Bounomodes: the grazing ox algorithm for exploration of clustered anomalies", "comment": null, "summary": "A common class of algorithms for informative path planning (IPP) follows\nboustrophedon (\"as the ox turns\") patterns, which aim to achieve uniform area\ncoverage. However, IPP is often applied in scenarios where anomalies, such as\nplant diseases, pollution, or hurricane damage, appear in clusters. In such\ncases, prioritizing the exploration of anomalous regions over uniform coverage\nis beneficial. This work introduces a class of algorithms referred to as\nbounom\\=odes (\"as the ox grazes\"), which alternates between uniform\nboustrophedon sampling and targeted exploration of detected anomaly clusters.\nWhile uniform sampling can be designed using geometric principles, close\nexploration of clusters depends on the spatial distribution of anomalies and\nmust be learned. In our implementation, the close exploration behavior is\nlearned using deep reinforcement learning algorithms. Experimental evaluations\ndemonstrate that the proposed approach outperforms several established\nbaselines."}
