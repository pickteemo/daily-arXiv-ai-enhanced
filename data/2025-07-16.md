<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 36]
- [cs.RO](#cs.RO) [Total: 34]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents](https://arxiv.org/abs/2507.10562)
*Hari Masoor*

Main category: cs.AI

TL;DR: SAMEP是一种新型框架，通过持久化、安全且可语义搜索的记忆共享协议，解决AI代理的短暂记忆限制问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理架构存在记忆短暂性问题，阻碍了跨会话和代理边界的有效协作与知识共享。

Method: SAMEP采用分布式记忆存储库，结合向量语义搜索、加密访问控制和标准化API，支持多代理协作。

Result: 实验显示，SAMEP减少了73%的冗余计算，提升了89%的上下文相关性，并完全符合法规要求。

Conclusion: SAMEP为持久化、协作式AI代理生态系统提供了安全且隐私保障的新范式。

Abstract: Current AI agent architectures suffer from ephemeral memory limitations,
preventing effective collaboration and knowledge sharing across sessions and
agent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a
novel framework that enables persistent, secure, and semantically searchable
memory sharing among AI agents. Our protocol addresses three critical
challenges: (1) persistent context preservation across agent sessions, (2)
secure multi-agent collaboration with fine-grained access control, and (3)
efficient semantic discovery of relevant historical context. SAMEP implements a
distributed memory repository with vector-based semantic search, cryptographic
access controls (AES-256-GCM), and standardized APIs compatible with existing
agent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness
across diverse domains including multi-agent software development, healthcare
AI with HIPAA compliance, and multi-modal processing pipelines. Experimental
results show 73% reduction in redundant computations, 89% improvement in
context relevance scores, and complete compliance with regulatory requirements
including audit trail generation. SAMEP enables a new paradigm of persistent,
collaborative AI agent ecosystems while maintaining security and privacy
guarantees.

</details>


### [2] [AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems](https://arxiv.org/abs/2507.10566)
*Hung Ming Liu*

Main category: cs.AI

TL;DR: 研究质疑传统多智能体强化学习中引入人工归纳偏置的必要性，提出基于VQ-VAE的AIM框架，证明智能体内生符号系统可实现自发语义压缩与纳什均衡驱动的语义收敛，无需外部偏置。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过人工归纳偏置促进通信，但可能过度设计。研究探索是否智能体内生符号系统足以实现高效通信。

Method: 采用基于VQ-VAE的AIM框架，分析智能体的神经表征与符号系统，开发可解释性工具包验证符号使用规律。

Result: AIM框架实现自发语义压缩与语义收敛，符号使用呈现幂律分布，提出三项理论见解（神经通信假说、工具优先原则、语义可解释范式）。

Conclusion: 内生符号系统可替代人工偏置，未来将探索HQ-VAE增强表达力与RL低层预训练，为符号主义与连接主义架桥。

Abstract: In Decentralized Multi-Agent Reinforcement Learning (MARL), the development
of Emergent Communication has long been constrained by the ``Joint Exploration
Dilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .
Traditional methods address this by introducing inductive biases to facilitate
communication emergence . This study fundamentally questions whether such
artificial inductive biases are, in fact, over-engineering. Through experiments
with the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized
Variational Autoencoder (VQ-VAE), we demonstrate that when agents possess an
endogenous symbol system, their neural representations naturally exhibit
spontaneous semantic compression and Nash equilibrium-driven semantic
convergence, achieving effective symbolic communication without external
inductive biases. This aligns with recent neuroscience findings suggesting that
the human brain does not directly use human language for internal thought , and
resonates with research on ``soft thinking'' capabilities in Large Language
Models (LLMs) . Compared to traditional explicit communication methods, AIM
demonstrates stronger generality and efficiency. The interpretable analysis
toolkit developed in this study confirms that symbol usage exhibits a
significant power-law distribution, leading to three major theoretical
insights: the ``Neural Communication Hypothesis'', the ``Tool-First
Principle'', and the ``Semantic Interpretability Paradigm''. Future research
will explore the integration of Hierarchical Quantized Variational Autoencoders
(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the
potential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This
discovery offers new avenues for bridging symbolism and connectionism.

</details>


### [3] [Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning](https://arxiv.org/abs/2507.10571)
*Konstantinos I. Roumeliotis,Ranjan Sapkota,Manoj Karkee,Nikolaos D. Tselikas*

Main category: cs.AI

TL;DR: 论文提出了一种模块化的多智能体AI视觉分类框架，通过信任感知的协调和RAG模块，显著提升了零样本场景下的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体AI在零样本场景下的信任问题，尤其是在视觉和语言理解的融合中。

Method: 结合通用多模态智能体、非视觉推理协调器和RAG模块，通过置信度校准和图像检索优化信任分配。

Result: 零样本场景下准确率提升77.94%，总体达到85.63%，并展示了不同模型的校准表现。

Conclusion: 该框架可扩展至诊断、生物学等信任关键领域，所有资源开源以支持复现和社区基准测试。

Abstract: Modern Artificial Intelligence (AI) increasingly relies on multi-agent
architectures that blend visual and language understanding. Yet, a pressing
challenge remains: How can we trust these agents especially in zero-shot
settings with no fine-tuning? We introduce a novel modular Agentic AI visual
classification framework that integrates generalist multimodal agents with a
non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)
module. Applied to apple leaf disease diagnosis, we benchmark three
configurations: (I) zero-shot with confidence-based orchestration, (II)
fine-tuned agents with improved performance, and (III) trust-calibrated
orchestration enhanced by CLIP-based image retrieval and re-evaluation loops.
Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator
modulates trust across agents. Our results demonstrate a 77.94\% accuracy
improvement in the zero-shot setting using trust-aware orchestration and RAG,
achieving 85.63\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL
displayed overconfidence. Furthermore, image-RAG grounded predictions with
visually similar cases, enabling correction of agent overconfidence via
iterative re-evaluation. The proposed system separates perception (vision
agents) from meta-reasoning (orchestrator), enabling scalable and interpretable
multi-agent AI. This blueprint is extensible to diagnostics, biology, and other
trust-critical domains. All models, prompts, results, and system components
including the complete software source code are openly released to support
reproducibility, transparency, and community benchmarking at Github:
https://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust

</details>


### [4] [Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning](https://arxiv.org/abs/2507.10624)
*Zheng Zhang*

Main category: cs.AI

TL;DR: LLMs表面流畅但符号推理、算术准确性和逻辑一致性任务表现不佳，研究发现其核心问题是计算执行中的“分裂脑综合征”，即理解与能力脱节。


<details>
  <summary>Details</summary>
Motivation: 揭示LLMs在任务失败中的结构性原因，探讨其理解与执行之间的鸿沟。

Method: 通过控制实验和架构分析，研究LLMs在任务中的表现及其计算执行问题。

Result: LLMs能表达正确原则但无法可靠应用，根源在于计算执行而非知识获取，表现为“分裂脑综合征”。

Conclusion: LLMs是强大的模式完成引擎，但缺乏结构化推理能力，未来需改进元认知控制和执行架构。

Abstract: Large Language Models (LLMs) display striking surface fluency yet
systematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,
and logical consistency. This paper offers a structural diagnosis of such
failures, revealing a persistent gap between \textit{comprehension} and
\textit{competence}. Through controlled experiments and architectural analysis,
we demonstrate that LLMs often articulate correct principles without reliably
applying them--a failure rooted not in knowledge access, but in computational
execution. We term this phenomenon the computational \textit{split-brain
syndrome}, where instruction and action pathways are geometrically and
functionally dissociated. This core limitation recurs across domains, from
mathematical operations to relational inferences, and explains why model
behavior remains brittle even under idealized prompting. We argue that LLMs
function as powerful pattern completion engines, but lack the architectural
scaffolding for principled, compositional reasoning. Our findings delineate the
boundary of current LLM capabilities and motivate future models with
metacognitive control, principle lifting, and structurally grounded execution.
This diagnosis also clarifies why mechanistic interpretability findings may
reflect training-specific pattern coordination rather than universal
computational principles, and why the geometric separation between instruction
and execution pathways suggests limitations in neural introspection and
mechanistic analysis.

</details>


### [5] [Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs](https://arxiv.org/abs/2507.10630)
*Ye Yang,Xue Xiao,Ping Yin,Taotao Xie*

Main category: cs.AI

TL;DR: KG2data系统结合知识图谱、LLM、ReAct代理和工具使用技术，提升气象领域数据查询能力，性能优于RAG2data和chat2data。


<details>
  <summary>Details</summary>
Motivation: 探索LLM通过API调用在知识密集型领域（如气象学）中的工具使用能力，解决现有系统在复杂查询和术语丰富场景下的局限性。

Method: 集成知识图谱、LLM、ReAct代理和虚拟API，评估API调用的准确性（名称识别失败、幻觉失败、调用正确性）。

Result: KG2data在名称识别失败（1.43%）、幻觉失败（0%）和调用正确性（88.57%）上表现优于对比系统。

Conclusion: KG2data通过知识图谱解决了LLM在领域知识访问上的限制，为高知识需求领域提供了智能问答和数据分析的新方案。

Abstract: API calls by large language models (LLMs) offer a cutting-edge approach for
data analysis. However, their ability to effectively utilize tools via API
calls remains underexplored in knowledge-intensive domains like meteorology.
This paper introduces KG2data, a system that integrates knowledge graphs, LLMs,
ReAct agents, and tool-use technologies to enable intelligent data acquisition
and query handling in the meteorological field. Using a virtual API, we
evaluate API call accuracy across three metrics: name recognition failure,
hallucination failure, and call correctness. KG2data achieves superior
performance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and
chat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based
systems by addressing their limited access to domain-specific knowledge, which
hampers performance on complex or terminology-rich queries. By using a
knowledge graph as persistent memory, our system enhances content retrieval,
complex query handling, domain-specific reasoning, semantic relationship
resolution, and heterogeneous data integration. It also mitigates the high cost
of fine-tuning LLMs, making the system more adaptable to evolving domain
knowledge and API structures. In summary, KG2data provides a novel solution for
intelligent, knowledge-based question answering and data analysis in domains
with high knowledge demands.

</details>


### [6] [From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents](https://arxiv.org/abs/2507.10644)
*Tatiana Petrova,Aleksandr Puzikov,Boris Bliznukov,Radu State*

Main category: cs.AI

TL;DR: 本文提出了首个全面的Web of Agents (WoA)演化概述，揭示了现代协议与早期标准的直接联系，并通过四轴分类法统一分析框架，指出智能核心从外部数据转向代理内部模型的范式转变。


<details>
  <summary>Details</summary>
Motivation: 研究WoA领域的碎片化问题，整合多智能体系统（MAS）和语义Web的历史，以提供对领域发展的整体理解。

Method: 引入四轴分类法（语义基础、通信范式、智能核心、发现机制）作为统一分析框架，比较不同世代的代理架构。

Result: 揭示了智能核心从外部数据或平台转向代理内部模型的范式转变，为现代Agentic AI奠定了基础。

Conclusion: 新协议虽重要，但不足以构建稳健、开放、可信的生态系统；未来研究应聚焦于去中心化身份、经济模型、安全和治理等社会技术挑战。

Abstract: The concept of the Web of Agents (WoA), which transforms the static,
document-centric Web into an environment of autonomous agents acting on users'
behalf, has attracted growing interest as large language models (LLMs) become
more capable. However, research in this area is still fragmented across
different communities. Contemporary surveys catalog the latest LLM-powered
frameworks, while the rich histories of Multi-Agent Systems (MAS) and the
Semantic Web are often treated as separate, legacy domains. This fragmentation
obscures the intellectual lineage of modern systems and hinders a holistic
understanding of the field's trajectory. We present the first comprehensive
evolutionary overview of the WoA. We show that modern protocols like A2A and
the MCP, are direct evolutionary responses to the well-documented limitations
of earlier standards like FIPA standards and OWL-based semantic agents. To
systematize this analysis, we introduce a four-axis taxonomy (semantic
foundation, communication paradigm, locus of intelligence, discovery
mechanism). This framework provides a unified analytical lens for comparing
agent architectures across all generations, revealing a clear line of descent
where others have seen a disconnect. Our analysis identifies a paradigm shift
in the 'locus of intelligence': from being encoded in external data (Semantic
Web) or the platform (MAS) to being embedded within the agent's core model
(LLM). This shift is foundational to modern Agentic AI, enabling the scalable
and adaptive systems the WoA has long envisioned. We conclude that while new
protocols are essential, they are insufficient for building a robust, open,
trustworthy ecosystem. Finally, we argue that the next research frontier lies
in solving persistent socio-technical challenges, and we map out a new agenda
focused on decentralized identity, economic models, security, and governance
for the emerging WoA.

</details>


### [7] [Parsing Musical Structure to Enable Meaningful Variations](https://arxiv.org/abs/2507.10740)
*Maziar Kanani,Sean O Leary,James McDermott*

Main category: cs.AI

TL;DR: 提出一种基于规则的音乐生成方法，通过变异现有曲调的语法结构生成新曲调，分析变异对曲调的影响。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过语法变异生成与原曲调相关的新音乐，并量化变异对曲调的影响。

Method: 使用Sequitur算法解析曲调为语法结构（PA），随机应用19种变异类型（如添加、删除、交换等），再扩展语法生成新曲调。

Result: 通过编辑距离、结构复杂度和长度分析变异效果，并评估每种变异类型的影响大小。

Conclusion: 该方法能有效生成与原曲调相关的新音乐，但仅关注音高序列生成，未涉及其他音乐元素。

Abstract: This paper presents a novel rule-based approach for generating music by
varying existing tunes. We parse each tune to find the Pathway Assembly (PA) [
1], that is a structure representing all repetitions in the tune. The Sequitur
algorithm [2 ] is used for this. The result is a grammar. We then carry out
mutation on the grammar, rather than on a tune directly. There are potentially
19 types of mutations such as adding, removing, swapping or reversing parts of
the grammar that can be applied to the grammars. The system employs one of the
mutations randomly in this step to automatically manipulate the grammar.
Following the mutation, we need to expand the grammar which returns a new tune.
The output after 1 or more mutations will be a new tune related to the original
tune. Our study examines how tunes change gradually over the course of multiple
mutations. Edit distances, structural complexity and length of the tunes are
used to show how a tune is changed after multiple mutations. In addition, the
size of effect of each mutation type is analyzed. As a final point, we review
the musical aspect of the output tunes. It should be noted that the study only
focused on generating new pitch sequences. The study is based on an Irish
traditional tune dataset and a list of integers has been used to represent each
tune's pitch values.

</details>


### [8] [AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition](https://arxiv.org/abs/2507.10750)
*Pandu Devarakota,Nicolas Tsesmetzis,Faruk O. Alpak,Apurva Gala,Detlef Hohl*

Main category: cs.AI

TL;DR: 本文探讨了AI数据中心对能源消耗和温室气体排放的影响，分析了短期（至2030年）和长期（2035年后）的碳排放趋势，并评估AI对CO2排放的净影响。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的广泛应用，数据中心的能源消耗和碳排放问题日益突出。本文旨在评估AI对环境的短期和长期影响，探讨其是否能为减排做出贡献。

Method: 通过分析数据中心的能源消耗和碳排放趋势，结合AI在能源生产、供应和消费领域的优化潜力，评估其净环境影响。

Result: 短期内，AI需求增长可能导致碳排放增加；但长期来看，AI的优化能力有望显著减少碳足迹，抵消初期排放。

Conclusion: AI初期可能对环境造成压力，但长期有望成为减排的重要工具，为气候缓解提供支持。

Abstract: Thanks to the availability of massive amounts of data, computing resources,
and advanced algorithms, AI has entered nearly every sector. This has sparked
significant investment and interest, particularly in building data centers with
the necessary hardware and software to develop and operate AI models and
AI-based workflows. In this technical review article, we present energy
consumption scenarios of data centers and impact on GHG emissions, considering
both near-term projections (up to 2030) and long-term outlook (2035 and
beyond). We address the quintessential question of whether AI will have a net
positive, neutral, or negative impact on CO2 emissions by 2035. Additionally,
we discuss AI's potential to automate, create efficient and disruptive
workflows across various fields related to energy production, supply and
consumption. In the near-term scenario, the growing demand for AI will likely
strain computing resources, lead to increase in electricity consumption and
therefore associated CO2 emissions. This is due to the power-hungry nature of
big data centers and the requirements for training and running of large and
complex AI models, as well as the penetration of AI assistant search and
applications for public use. However, the long-term outlook could be more
promising. AI has the potential to be a game-changer in CO2 reduction. Its
ability to further automate and optimize processes across industries, from
energy production to logistics, could significantly decrease our carbon
footprint. This positive impact is anticipated to outweigh the initial
emissions bump, creating value for businesses and society in areas where
traditional solutions have fallen short. In essence, AI might cause some
initial growing pains for the environment, but it has the potential to support
climate mitigation efforts.

</details>


### [9] [IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models](https://arxiv.org/abs/2507.10758)
*Nikesh Prajapati,Bimal Karki,Saroj Gopali,Akbar Siami Namin*

Main category: cs.AI

TL;DR: 该论文通过深度学习模型检测IoT恶意攻击，评估了多种模型（如GraphSAGE、BERT、TCN等）在恶意流量检测中的表现，其中BERT表现最佳。


<details>
  <summary>Details</summary>
Motivation: IoT系统流量模式具有时序性和多样性，为模型学习提供了丰富的数据，因此需要高效且准确的检测方法。

Method: 采用了GraphSAGE、BERT、TCN、Multi-Head Attention及BI-LSTM等模型，评估其在恶意流量检测中的性能。

Result: BERT表现最优，准确率达99.94%，其他模型如Multi-Head Attention和GraphSAGE各有优劣。

Conclusion: BERT在捕获时序依赖方面表现卓越，但需权衡模型性能与计算成本。

Abstract: This paper intends to detect IoT malicious attacks through deep learning
models and demonstrates a comprehensive evaluation of the deep learning and
graph-based models regarding malicious network traffic detection. The models
particularly are based on GraphSAGE, Bidirectional encoder representations from
transformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head
Attention, together with Bidirectional Long Short-Term Memory (BI-LSTM)
Multi-Head Attention and BI-LSTM and LSTM models. The chosen models
demonstrated great performance to model temporal patterns and detect feature
significance. The observed performance are mainly due to the fact that IoT
system traffic patterns are both sequential and diverse, leaving a rich set of
temporal patterns for the models to learn. Experimental results showed that
BERT maintained the best performance. It achieved 99.94% accuracy rate
alongside high precision and recall, F1-score and AUC-ROC score of 99.99% which
demonstrates its capabilities through temporal dependency capture. The
Multi-Head Attention offered promising results by providing good detection
capabilities with interpretable results. On the other side, the Multi-Head
Attention model required significant processing time like BI-LSTM variants. The
GraphSAGE model achieved good accuracy while requiring the shortest training
time but yielded the lowest accuracy, precision, and F1 score compared to the
other models

</details>


### [10] [Detecting AI Assistance in Abstract Complex Tasks](https://arxiv.org/abs/2507.10761)
*Tyler King,Nikolos Gurney,John H. Miller,Volkan Ustun*

Main category: cs.AI

TL;DR: 论文提出了一种通过预处理和神经网络分类检测AI辅助的方法，重点处理抽象任务数据，并展示了多种数据表示形式的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着AI在复杂任务中的普及，检测AI辅助变得重要，但抽象任务数据对传统方法具有挑战性。

Method: 构建四种神经网络友好的图像表示形式及一种时间序列表示形式，测试不同深度学习架构的分类效果。

Result: 实验表明，适当预处理的数据和结合时空信息的架构能有效检测AI辅助。

Conclusion: 编码时空信息对检测抽象任务中的AI辅助至关重要，且预处理和架构选择显著影响性能。

Abstract: Detecting assistance from artificial intelligence is increasingly important
as they become ubiquitous across complex tasks such as text generation, medical
diagnosis, and autonomous driving. Aid detection is challenging for humans,
especially when looking at abstract task data. Artificial neural networks excel
at classification thanks to their ability to quickly learn from and process
large amounts of data -- assuming appropriate preprocessing. We posit detecting
help from AI as a classification task for such models. Much of the research in
this space examines the classification of complex but concrete data classes,
such as images. Many AI assistance detection scenarios, however, result in data
that is not machine learning-friendly. We demonstrate that common models can
effectively classify such data when it is appropriately preprocessed. To do so,
we construct four distinct neural network-friendly image formulations along
with an additional time-series formulation that explicitly encodes the
exploration/exploitation of users, which allows for generalizability to other
abstract tasks. We benchmark the quality of each image formulation across three
classical deep learning architectures, along with a parallel CNN-RNN
architecture that leverages the additional time series to maximize testing
performance, showcasing the importance of encoding temporal and spatial
quantities for detecting AI aid in abstract tasks.

</details>


### [11] [Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions](https://arxiv.org/abs/2507.10798)
*Asim H. Gazi,Bhanu T. Gullapalli,Daiqi Gao,Benjamin M. Marlin,Vivek Shetty,Susan A. Murphy*

Main category: cs.AI

TL;DR: SigmaScheduling动态调整决策点时间，提高移动健康干预的及时性。


<details>
  <summary>Details</summary>
Motivation: 固定间隔的决策点调度方法对习惯性行为干预效果不佳，尤其是对作息不规律的用户。

Method: 提出SigmaScheduling方法，根据行为时间预测的不确定性动态调整决策点。

Result: 在68名参与者的试验中，SigmaScheduling在70%以上的情况下确保决策点早于目标行为。

Conclusion: SigmaScheduling能提升精准移动健康干预的效果，尤其适用于时间敏感的习惯性行为。

Abstract: Timely decision making is critical to the effectiveness of mobile health
(mHealth) interventions. At predefined timepoints called "decision points,"
intelligent mHealth systems such as just-in-time adaptive interventions
(JITAIs) estimate an individual's biobehavioral context from sensor or survey
data and determine whether and how to intervene. For interventions targeting
habitual behavior (e.g., oral hygiene), effectiveness often hinges on
delivering support shortly before the target behavior is likely to occur.
Current practice schedules decision points at a fixed interval (e.g., one hour)
before user-provided behavior times, and the fixed interval is kept the same
for all individuals. However, this one-size-fits-all approach performs poorly
for individuals with irregular routines, often scheduling decision points after
the target behavior has already occurred, rendering interventions ineffective.
In this paper, we propose SigmaScheduling, a method to dynamically schedule
decision points based on uncertainty in predicted behavior times. When behavior
timing is more predictable, SigmaScheduling schedules decision points closer to
the predicted behavior time; when timing is less certain, SigmaScheduling
schedules decision points earlier, increasing the likelihood of timely
intervention. We evaluated SigmaScheduling using real-world data from 68
participants in a 10-week trial of Oralytics, a JITAI designed to improve daily
toothbrushing. SigmaScheduling increased the likelihood that decision points
preceded brushing events in at least 70% of cases, preserving opportunities to
intervene and impact behavior. Our results indicate that SigmaScheduling can
advance precision mHealth, particularly for JITAIs targeting time-sensitive,
habitual behaviors such as oral hygiene or dietary habits.

</details>


### [12] [Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case](https://arxiv.org/abs/2507.10803)
*JaMor Hairston,Ritvik Ranjan,Sahithi Lakamana,Anthony Spadaro,Selen Bozkurt,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.AI

TL;DR: 研究评估了大型语言模型（LLMs）在主题分析中的表现，发现GPT-4o在少量样本提示下表现最佳，可作为定性研究的补充工具。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在需要深度解释和领域专业知识的主题分析任务中的可行性，以替代或补充专家分析。

Method: 使用两个Reddit数据集，将任务建模为一系列二元分类，采用零样本、单样本和少量样本提示策略，评估LLMs的表现。

Result: GPT-4o在少量样本提示下表现最佳（准确率90.9%，F1分数0.71），高流行主题的分布与专家分类接近。

Conclusion: 少量样本LLM方法可自动化主题分析，为定性研究提供可扩展的补充。

Abstract: Background Large language models (LLMs) face challenges in inductive thematic
analysis, a task requiring deep interpretive and domain-specific expertise. We
evaluated the feasibility of using LLMs to replicate expert-driven thematic
analysis of social media data. Methods Using two temporally non-intersecting
Reddit datasets on xylazine (n=286 and n=686, for model optimization and
validation, respectively) with twelve expert-derived themes, we evaluated five
LLMs against expert coding. We modeled the task as a series of binary
classifications, rather than a single, multi-label classification, employing
zero-, single-, and few-shot prompting strategies and measuring performance via
accuracy, precision, recall, and F1-score. Results On the validation set,
GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:
0.71). For high-prevalence themes, model-derived thematic distributions closely
mirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:
16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based
approaches can automate thematic analyses, offering a scalable supplement for
qualitative research. Keywords: thematic analysis, large language models,
natural language processing, qualitative analysis, social media, prompt
engineering, public health

</details>


### [13] [AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks](https://arxiv.org/abs/2507.10831)
*Yilin Xia,Heng Zheng,Shawn Bowers,Bertram Ludäscher*

Main category: cs.AI

TL;DR: AF-XRAY是一个开源工具包，用于探索、分析和可视化法律推理中的抽象论证框架，通过分层可视化和分类攻击边等功能，帮助非专家理解论证接受和解决模糊性。


<details>
  <summary>Details</summary>
Motivation: 法律推理中的论证框架（AFs）存在模糊性和解释困难的问题，非专家难以理解。AF-XRAY旨在通过可视化工具解决这些问题。

Method: AF-XRAY提供分层可视化、攻击边分类、覆盖可视化模糊语义解决方案，以及识别关键攻击集以解决未决论证。

Result: AF-XRAY能够将模糊场景转化为明确的解决方案，帮助用户识别模糊原因并探索替代方案。通过实际法律案例验证了其有效性。

Conclusion: AF-XRAY通过系统化方法解决了法律推理中的模糊性问题，支持用户通过不同假设得出不同结论，提升了法律推理的可解释性。

Abstract: Argumentation frameworks (AFs) provide formal approaches for legal reasoning,
but identifying sources of ambiguity and explaining argument acceptance remains
challenging for non-experts. We present AF-XRAY, an open-source toolkit for
exploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY
introduces: (i) layered visualizations based on game-theoretic argument length
revealing well-founded derivation structures; (ii) classification of attack
edges by semantic roles (primary, secondary, blunders); (iii) overlay
visualizations of alternative 2-valued solutions on ambiguous 3-valued grounded
semantics; and (iv) identification of critical attack sets whose suspension
resolves undecided arguments. Through systematic generation of critical attack
sets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling
users to pinpoint specific causes of ambiguity and explore alternative
resolutions. We use real-world legal cases (e.g., Wild Animals as modeled by
Bench-Capon) to show that our tool supports teleological legal reasoning by
revealing how different assumptions lead to different justified conclusions.

</details>


### [14] [NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization](https://arxiv.org/abs/2507.10894)
*Zongtao He,Liuyi Wang,Lu Chen,Chengju Liu,Qijun Chen*

Main category: cs.AI

TL;DR: NavComposer是一个自动生成高质量导航指令的框架，通过分解和重组语义实体（如动作、场景和对象）来生成自然语言指令。NavInstrCritic是一个无需标注的评估系统，从对比匹配、语义一致性和语言多样性三个维度评估指令质量。


<details>
  <summary>Details</summary>
Motivation: 解决专家提供的导航指令数量有限且合成注释质量不足的问题，以支持大规模研究。

Method: NavComposer分解语义实体并重组为指令，支持数据无关的适应；NavInstrCritic提供无标注的指令评估。

Result: 实验证明该方法有效，支持更可扩展和通用的研究。

Conclusion: NavComposer和NavInstrCritic为语言导航研究提供了高质量指令生成和评估的解决方案。

Abstract: Language-guided navigation is a cornerstone of embodied AI, enabling agents
to interpret language instructions and navigate complex environments. However,
expert-provided instructions are limited in quantity, while synthesized
annotations often lack quality, making them insufficient for large-scale
research. To address this, we propose NavComposer, a novel framework for
automatically generating high-quality navigation instructions. NavComposer
explicitly decomposes semantic entities such as actions, scenes, and objects,
and recomposes them into natural language instructions. Its modular
architecture allows flexible integration of state-of-the-art techniques, while
the explicit use of semantic entities enhances both the richness and accuracy
of instructions. Moreover, it operates in a data-agnostic manner, supporting
adaptation to diverse navigation trajectories without domain-specific training.
Complementing NavComposer, we introduce NavInstrCritic, a comprehensive
annotation-free evaluation system that assesses navigation instructions on
three dimensions: contrastive matching, semantic consistency, and linguistic
diversity. NavInstrCritic provides a holistic evaluation of instruction
quality, addressing limitations of traditional metrics that rely heavily on
expert annotations. By decoupling instruction generation and evaluation from
specific navigation agents, our method enables more scalable and generalizable
research. Extensive experiments provide direct and practical evidence for the
effectiveness of our method.

</details>


### [15] [Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation](https://arxiv.org/abs/2507.10911)
*Yicong Wu,Ting Chen,Irit Hochberg,Zhoujian Sun,Ruth Edry,Zhengxing Huang,Mor Peleg*

Main category: cs.AI

TL;DR: 研究探讨了使用基于大型语言模型（LLM）的多代理系统（MAS）为多病症慢性患者提供更安全的治疗建议的可行性，发现单代理系统表现与多学科团队（MDT）相当，但建议仍存在不完整和不必要的药物问题。


<details>
  <summary>Details</summary>
Motivation: 多病症患者的治疗建议因治疗冲突风险而复杂化，现有决策支持系统可扩展性不足，研究受全科医生（GP）和多学科团队（MDT）协作启发，探索LLM-MAS的潜力。

Method: 设计单代理和MAS框架模拟MDT决策，通过LLM代理讨论解决医疗冲突，在多病症患者治疗任务中评估性能，并与单代理方法和真实基准对比。

Result: 当前LLM下单代理GP表现与MDT相当，最佳模型能提供满足临床目标的正确建议，但建议不完整且部分模型存在不必要的药物冲突。

Conclusion: LLM-MAS在多病症治疗建议中具有潜力，但需进一步优化以减少不完整建议和不必要的药物冲突。

Abstract: Therapy recommendation for chronic patients with multimorbidity is
challenging due to risks of treatment conflicts. Existing decision support
systems face scalability limitations. Inspired by the way in which general
practitioners (GP) manage multimorbidity patients, occasionally convening
multidisciplinary team (MDT) collaboration, this study investigated the
feasibility and value of using a Large Language Model (LLM)-based multi-agent
system (MAS) for safer therapy recommendations. We designed a single agent and
a MAS framework simulating MDT decision-making by enabling discussion among LLM
agents to resolve medical conflicts. The systems were evaluated on therapy
planning tasks for multimorbidity patients using benchmark cases. We compared
MAS performance with single-agent approaches and real-world benchmarks. An
important contribution of our study is the definition of evaluation metrics
that go beyond the technical precision and recall and allow the inspection of
clinical goals met and medication burden of the proposed advices to a gold
standard benchmark. Our results show that with current LLMs, a single agent GP
performs as well as MDTs. The best-scoring models provide correct
recommendations that address all clinical goals, yet the advices are
incomplete. Some models also present unnecessary medications, resulting in
unnecessary conflicts between medication and conditions or drug-drug
interactions.

</details>


### [16] [Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization](https://arxiv.org/abs/2507.10923)
*Yuhao Wang,Keyan Ding,Kehua Feng,Zeyuan Wang,Ming Qin,Xiaotong Li,Qiang Zhang,Huajun Chen*

Main category: cs.AI

TL;DR: 提出了一种知识引导的偏好优化（KPO）框架，通过蛋白质安全知识图谱整合先验知识，减少生成有害蛋白质序列的风险。


<details>
  <summary>Details</summary>
Motivation: 蛋白质语言模型在功能优化和设计中有优势，但可能生成有害序列，带来生物安全和伦理挑战。

Method: 结合蛋白质安全知识图谱，采用图剪枝策略和强化学习，优化序列生成。

Result: KPO显著降低有害序列生成概率，同时保持高功能性。

Conclusion: KPO为生物技术中的生成模型提供了安全保证框架。

Abstract: Protein language models have emerged as powerful tools for sequence
generation, offering substantial advantages in functional optimization and
denovo design. However, these models also present significant risks of
generating harmful protein sequences, such as those that enhance viral
transmissibility or evade immune responses. These concerns underscore critical
biosafety and ethical challenges. To address these issues, we propose a
Knowledge-guided Preference Optimization (KPO) framework that integrates prior
knowledge via a Protein Safety Knowledge Graph. This framework utilizes an
efficient graph pruning strategy to identify preferred sequences and employs
reinforcement learning to minimize the risk of generating harmful proteins.
Experimental results demonstrate that KPO effectively reduces the likelihood of
producing hazardous sequences while maintaining high functionality, offering a
robust safety assurance framework for applying generative models in
biotechnology.

</details>


### [17] [Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction](https://arxiv.org/abs/2507.10993)
*Emir Durakovic,Min-Hong Shih*

Main category: cs.AI

TL;DR: 结合卷积神经网络（CNN）和表格数据，准确预测鸟类在特定栖息地的存在。


<details>
  <summary>Details</summary>
Motivation: 由于气候变化导致栖息地范围变化，需要一种可靠的方法来预测鸟类分布。

Method: 利用卫星图像和环境特征（如温度、降水、海拔），结合CNN和表格数据建模。

Result: 模型预测鸟类分布的准确率达到85%。

Conclusion: 该方法为理解鸟类迁徙提供了可扩展且可靠的解决方案。

Abstract: Due to climate-induced changes, many habitats are experiencing range shifts
away from their traditional geographic locations (Piguet, 2011). We propose a
solution to accurately model whether bird species are present in a specific
habitat through the combination of Convolutional Neural Networks (CNNs)
(O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery
and environmental features (e.g., temperature, precipitation, elevation) to
predict bird presence across various climates. The CNN model captures spatial
characteristics of landscapes such as forestation, water bodies, and
urbanization, whereas the tabular method uses ecological and geographic data.
Both systems predict the distribution of birds with an average accuracy of 85%,
offering a scalable but reliable method to understand bird migration.

</details>


### [18] [Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing](https://arxiv.org/abs/2507.11060)
*Yilmazcan Ozyurt,Tunaberk Almaci,Stefan Feuerriegel,Mrinmaya Sachan*

Main category: cs.AI

TL;DR: ExRec是一个结合语义知识追踪的个性化习题推荐框架，通过改进强化学习方法优化学习路径。


<details>
  <summary>Details</summary>
Motivation: 现有习题推荐方法忽视问题的语义内容和学习顺序，ExRec旨在解决这一问题。

Method: 采用端到端流程，包括标注知识点、学习语义表示、训练知识追踪模型及优化强化学习方法。

Result: 在多个实际任务中验证有效性，能泛化到新问题并生成可解释的学习轨迹。

Conclusion: 知识追踪引导的强化学习在教育个性化中具有潜力。

Abstract: We introduce ExRec, a general framework for personalized exercise
recommendation with semantically-grounded knowledge tracing. Our method builds
on the observation that existing exercise recommendation approaches simulate
student performance via knowledge tracing (KT) but they often overlook two key
aspects: (a) the semantic content of questions and (b) the sequential,
structured progression of student learning. To address this, our ExRec presents
an end-to-end pipeline, from annotating the KCs of questions and learning their
semantic representations to training KT models and optimizing several
reinforcement learning (RL) methods. Moreover, we improve standard
Q-learning-based continuous RL methods via a tailored model-based value
estimation (MVE) approach that directly leverages the components of KT model in
estimating cumulative knowledge improvement. We validate the effectiveness of
our ExRec using various RL methods across four real-world tasks with different
educational goals in online math learning. We further show that ExRec
generalizes robustly to new, unseen questions and that it produces
interpretable student learning trajectories. Together, our findings highlight
the promise of KT-guided RL for effective personalization in education.

</details>


### [19] [Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander](https://arxiv.org/abs/2507.11079)
*Li Wang,Qizhen Wu,Lei Chen*

Main category: cs.AI

TL;DR: 提出了一种基于视觉语言模型的指挥官方法，用于解决无人地面车辆对抗中的智能感知到决策推理问题。


<details>
  <summary>Details</summary>
Motivation: 传统手工规则方法在复杂战场环境中表现脆弱，而现有强化学习方法缺乏可解释性，主要关注动作而非战略决策。

Method: 结合视觉语言模型进行场景理解和轻量级大语言模型进行战略推理，实现感知与决策的统一。

Result: 仿真和消融实验显示，该方法相比基线模型胜率超过80%。

Conclusion: 该方法通过模拟人类指挥官的认知过程，实现了高适应性和可解释性。

Abstract: In multiple unmanned ground vehicle confrontations, autonomously evolving
multi-agent tactical decisions from situational awareness remain a significant
challenge. Traditional handcraft rule-based methods become vulnerable in the
complicated and transient battlefield environment, and current reinforcement
learning methods mainly focus on action manipulation instead of strategic
decisions due to lack of interpretability. Here, we propose a vision-language
model-based commander to address the issue of intelligent
perception-to-decision reasoning in autonomous confrontations. Our method
integrates a vision language model for scene understanding and a lightweight
large language model for strategic reasoning, achieving unified perception and
decision within a shared semantic space, with strong adaptability and
interpretability. Unlike rule-based search and reinforcement learning methods,
the combination of the two modules establishes a full-chain process, reflecting
the cognitive process of human commanders. Simulation and ablation experiments
validate that the proposed approach achieves a win rate of over 80% compared
with baseline models.

</details>


### [20] [Function-to-Style Guidance of LLMs for Code Translation](https://arxiv.org/abs/2507.11083)
*Longhui Zhang,Bin Wang,Jiahao Wang,Xiaofeng Zhao,Min Zhang,Hao Yang,Meishan Zhang,Yu Li,Jing Li,Jun Yu,Min Zhang*

Main category: cs.AI

TL;DR: F2STrans提出了一种分阶段的代码翻译方法，通过功能学习和风格学习提升LLMs的翻译性能，并在新基准测试中显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在代码翻译中难以同时保证正确性和可读性，限制了实际应用。

Method: 采用两阶段方法：功能学习优化翻译正确性，风格学习提升可读性；并引入新基准测试。

Result: 实验表明，F2STrans显著提升性能，Qwen-1.5B甚至优于Qwen-32B和GPT-4。

Conclusion: F2STrans为代码翻译提供了高效解决方案，尤其在功能与风格平衡上表现突出。

Abstract: Large language models (LLMs) have made significant strides in code
translation tasks. However, ensuring both the correctness and readability of
translated code remains a challenge, limiting their effective adoption in
real-world software development. In this work, we propose F2STrans, a
function-to-style guiding paradigm designed to progressively improve the
performance of LLMs in code translation. Our approach comprises two key stages:
(1) Functional learning, which optimizes translation correctness using
high-quality source-target code pairs mined from online programming platforms,
and (2) Style learning, which improves translation readability by incorporating
both positive and negative style examples. Additionally, we introduce a novel
code translation benchmark that includes up-to-date source code, extensive test
cases, and manually annotated ground-truth translations, enabling comprehensive
functional and stylistic evaluations. Experiments on both our new benchmark and
existing datasets demonstrate that our approach significantly improves code
translation performance. Notably, our approach enables Qwen-1.5B to outperform
prompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code
translation scenarios.

</details>


### [21] [AI Agent Architecture for Decentralized Trading of Alternative Assets](https://arxiv.org/abs/2507.11117)
*Ailiya Borjigin,Cong He,Charles CC Lee,Wei Zhou*

Main category: cs.AI

TL;DR: GoldMine OS是一个研究导向的架构，利用多个专用AI代理自动化并安全地将实物黄金代币化为区块链稳定币（OZ），结合链上智能合约和链下AI代理，实现高性能和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决实物资产（如黄金）在区块链上交易的合规性、流动性和风险管理问题，推动传统非流动性资产的民主化访问。

Method: 采用链上智能合约控制关键风险，链下AI代理（合规、代币发行、做市、风控）协作决策，通过模拟和试点部署评估系统性能。

Result: 原型系统实现1.2秒内按需代币发行，做市代理保持0.5%以内的价差，攻击检测和缓解时间在10秒内，支持5000 TPS和10000并发用户。

Conclusion: AI代理驱动的去中心化交易所可满足高性能和安全性需求，其治理模型（多签名更新和链上投票）确保透明性和适应性。

Abstract: Decentralized trading of real-world alternative assets (e.g., gold) requires
bridging physical asset custody with blockchain systems while meeting strict
requirements for compliance, liquidity, and risk management. We present
GoldMine OS, a research oriented architecture that employs multiple specialized
AI agents to automate and secure the tokenization and exchange of physical gold
into a blockchain based stablecoin ("OZ"). Our approach combines on chain smart
contracts for critical risk controls with off chain AI agents for decision
making, blending the transparency and reliability of blockchains with the
flexibility of AI driven automation. We describe four cooperative agents
(Compliance, Token Issuance, Market Making, and Risk Control) and a
coordinating core, and evaluate the system through simulation and a controlled
pilot deployment. In experiments the prototype delivers on demand token
issuance in under 1.2 s, more than 100 times faster than manual workflows. The
Market Making agent maintains tight liquidity with spreads often below 0.5
percent even under volatile conditions. Fault injection tests show resilience:
an oracle price spoofing attack is detected and mitigated within 10 s, and a
simulated vault mis reporting halts issuance immediately with minimal user
impact. The architecture scales to 5000 transactions per second with 10000
concurrent users in benchmarks. These results indicate that an AI agent based
decentralized exchange for alternative assets can satisfy rigorous performance
and safety requirements. We discuss broader implications for democratizing
access to traditionally illiquid assets and explain how our governance model --
multi signature agent updates and on chain community voting on risk parameters
-- provides ongoing transparency, adaptability, and formal assurance of system
integrity.

</details>


### [22] [Defining neurosymbolic AI](https://arxiv.org/abs/2507.11127)
*Lennert De Smet,Luc De Raedt*

Main category: cs.AI

TL;DR: 本文提出了一个形式化定义，将神经符号AI抽象为逻辑函数和信念函数的积分计算。


<details>
  <summary>Details</summary>
Motivation: 尽管神经符号AI领域已有多种系统，但缺乏公认的形式化定义，本文旨在填补这一空白。

Method: 通过定义神经符号推理为逻辑函数和信念函数的积分计算，抽象出关键要素。

Result: 该定义能够涵盖代表性的神经符号AI系统。

Conclusion: 提出的形式化定义为神经符号AI领域提供了统一的理论框架。

Abstract: Neurosymbolic AI focuses on integrating learning and reasoning, in
particular, on unifying logical and neural representations. Despite the
existence of an alphabet soup of neurosymbolic AI systems, the field is lacking
a generally accepted formal definition of what neurosymbolic models and
inference really are. We introduce a formal definition for neurosymbolic AI
that makes abstraction of its key ingredients. More specifically, we define
neurosymbolic inference as the computation of an integral over a product of a
logical and a belief function. We show that our neurosymbolic AI definition
makes abstraction of key representative neurosymbolic AI systems.

</details>


### [23] [Collaborative Trustworthiness for Good Decision Making in Autonomous Systems](https://arxiv.org/abs/2507.11135)
*Selma Saidi,Omar Laimona,Christoph Schmickler,Dirk Ziegenbein*

Main category: cs.AI

TL;DR: 提出一种基于协作数据共享的自主系统可信决策方法，利用感知质量等属性评估系统可信度，采用BDD模型进行信念聚合与传播。


<details>
  <summary>Details</summary>
Motivation: 动态复杂环境中确保自主系统的安全与正确行为是挑战，需提高其决策的可靠性与可信度。

Method: 利用感知质量等属性评估系统可信度，结合社会认识论定义聚合与传播规则，使用BDD模型进行信念聚合与传播。

Result: 提出了一种高效的可信决策方法，通过BDD模型和简化规则实现协作自动推理。

Conclusion: 该方法通过协作数据共享和BDD模型提升了自主系统的决策可信度与效率。

Abstract: Autonomous systems are becoming an integral part of many application domains,
like in the mobility sector. However, ensuring their safe and correct behaviour
in dynamic and complex environments remains a significant challenge, where
systems should autonomously make decisions e.g., about manoeuvring. We propose
in this paper a general collaborative approach for increasing the level of
trustworthiness in the environment of operation and improve reliability and
good decision making in autonomous system. In the presence of conflicting
information, aggregation becomes a major issue for trustworthy decision making
based on collaborative data sharing. Unlike classical approaches in the
literature that rely on consensus or majority as aggregation rule, we exploit
the fact that autonomous systems have different quality attributes like
perception quality. We use this criteria to determine which autonomous systems
are trustworthy and borrow concepts from social epistemology to define
aggregation and propagation rules, used for automated decision making. We use
Binary Decision Diagrams (BDDs) as formal models for beliefs aggregation and
propagation, and formulate reduction rules to reduce the size of the BDDs and
allow efficient computation structures for collaborative automated reasoning.

</details>


### [24] [Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming](https://arxiv.org/abs/2507.11150)
*Alessandro Bertagnon,Marcello Dalpasso,Michele Favalli,Marco Gavanelli*

Main category: cs.AI

TL;DR: 本文提出了一种使用答案集编程（ASP）计算组合电路实际最大延迟的方法，以替代传统的静态时序分析，从而优化处理器性能。


<details>
  <summary>Details</summary>
Motivation: 传统静态时序分析虽能在多项式时间内计算最大延迟的上界，但可能导致处理器性能未达最优。本文旨在直接计算实际最大延迟，以提升系统性能。

Method: 将问题建模为答案集编程（ASP），并提出非平凡的编码方法，利用ASP的高效求解器解决这一计算难题。

Result: 实验结果表明，ASP能有效解决硬件设计中的复杂问题，为计算实际最大延迟提供了可行方案。

Conclusion: ASP是解决硬件设计中复杂计算问题的有效工具，能够替代传统方法以优化性能。

Abstract: In the design of integrated circuits, one critical metric is the maximum
delay introduced by combinational modules within the circuit. This delay is
crucial because it represents the time required to perform a computation: in an
Arithmetic-Logic Unit it represents the maximum time taken by the circuit to
perform an arithmetic operation. When such a circuit is part of a larger,
synchronous system, like a CPU, the maximum delay directly impacts the maximum
clock frequency of the entire system. Typically, hardware designers use Static
Timing Analysis to compute an upper bound of the maximum delay because it can
be determined in polynomial time. However, relying on this upper bound can lead
to suboptimal processor speeds, thereby missing performance opportunities. In
this work, we tackle the challenging task of computing the actual maximum
delay, rather than an approximate value. Since the problem is computationally
hard, we model it in Answer Set Programming (ASP), a logic language featuring
extremely efficient solvers. We propose non-trivial encodings of the problem
into ASP. Experimental results show that ASP is a viable solution to address
complex problems in hardware design.

</details>


### [25] [DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion](https://arxiv.org/abs/2507.11229)
*Jin Li,Zezhong Ding,Xike Xie*

Main category: cs.AI

TL;DR: DuetGraph提出了一种双路径全局-局部融合的KG推理机制，通过分离全局和局部信息处理路径，解决了分数过平滑问题，并采用粗到细优化策略提升推理质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有KG推理方法在处理全局和局部信息时容易导致分数过平滑，模糊正确与错误答案的区分，影响推理效果。

Method: DuetGraph采用双路径机制，分别处理局部（消息传递）和全局（注意力）信息，避免相互干扰；并通过粗到细优化策略划分实体子集，缩小候选空间。

Result: 实验表明，DuetGraph在推理质量上提升8.7%，训练效率加速1.8倍，达到SOTA性能。

Conclusion: DuetGraph通过双路径融合和粗到细优化，有效解决了分数过平滑问题，显著提升了KG推理的性能和效率。

Abstract: Knowledge graphs (KGs) are vital for enabling knowledge reasoning across
various domains. Recent KG reasoning methods that integrate both global and
local information have achieved promising results. However, existing methods
often suffer from score over-smoothing, which blurs the distinction between
correct and incorrect answers and hinders reasoning effectiveness. To address
this, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with
dual-pathway global-local fusion. DuetGraph tackles over-smoothing by
segregating -- rather than stacking -- the processing of local (via message
passing) and global (via attention) information into two distinct pathways,
preventing mutual interference and preserving representational discrimination.
In addition, DuetGraph introduces a coarse-to-fine optimization, which
partitions entities into high- and low-score subsets. This strategy narrows the
candidate space and sharpens the score gap between the two subsets, which
alleviates over-smoothing and enhances inference quality. Extensive experiments
on various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA)
performance, with up to an 8.7% improvement in reasoning quality and a
1.8$\times$ acceleration in training efficiency.

</details>


### [26] [Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems](https://arxiv.org/abs/2507.11277)
*Dany Moshkovich,Sergey Zeltyn*

Main category: cs.AI

TL;DR: 本文介绍了AgentOps框架，用于观察、分析、优化和自动化基于大型语言模型（LLMs）的智能代理系统的操作。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在智能代理系统中的广泛应用，传统软件运维方法无法应对其特有的不确定性，如概率推理、动态记忆状态和灵活执行路径。

Method: 提出了AgentOps框架，包括行为观察、指标收集、问题检测、根因分析、优化建议和运行时自动化六个阶段。

Result: 通过自动化管理不确定性，确保智能代理系统的安全、适应性和高效运行。

Conclusion: AgentOps框架通过自动化手段有效应对智能代理系统的不确定性，提升其操作效率和安全性。

Abstract: Large Language Models (LLMs) are increasingly deployed within agentic
systems-collections of interacting, LLM-powered agents that execute complex,
adaptive workflows using memory, tools, and dynamic planning. While enabling
powerful new capabilities, these systems also introduce unique forms of
uncertainty stemming from probabilistic reasoning, evolving memory states, and
fluid execution paths. Traditional software observability and operations
practices fall short in addressing these challenges.
  This paper introduces AgentOps: a comprehensive framework for observing,
analyzing, optimizing, and automating operation of agentic AI systems. We
identify distinct needs across four key roles-developers, testers, site
reliability engineers (SREs), and business users-each of whom engages with the
system at different points in its lifecycle. We present the AgentOps Automation
Pipeline, a six-stage process encompassing behavior observation, metric
collection, issue detection, root cause analysis, optimized recommendations,
and runtime automation. Throughout, we emphasize the critical role of
automation in managing uncertainty and enabling self-improving AI systems-not
by eliminating uncertainty, but by taming it to ensure safe, adaptive, and
effective operation.

</details>


### [27] [Opus: A Prompt Intention Framework for Complex Workflow Generation](https://arxiv.org/abs/2507.11288)
*Théo Fagnoni,Mahsun Altin,Chia En Chung,Phillip Kingston,Alan Tuning,Dana O. Mohamed,Inès Adnani*

Main category: cs.AI

TL;DR: Opus Prompt Intention Framework通过引入中间意图捕捉层，提升基于LLM的复杂工作流生成质量，显著改善语义相似性指标。


<details>
  <summary>Details</summary>
Motivation: 解决直接根据用户查询生成工作流时逻辑性和可扩展性不足的问题。

Method: 提出Opus Workflow Intention Framework，包括从查询中提取工作流信号、解析为结构化意图对象，并基于意图生成工作流。

Result: 在1000个多意图查询-工作流对上的实验表明，框架显著提升了语义相似性指标。

Conclusion: Opus Prompt Intention Framework能有效提升复杂工作流生成的逻辑性和可靠性。

Abstract: This paper introduces the Opus Prompt Intention Framework, designed to
improve complex Workflow Generation with instruction-tuned Large Language
Models (LLMs). We propose an intermediate Intention Capture layer between user
queries and Workflow Generation, implementing the Opus Workflow Intention
Framework, which consists of extracting Workflow Signals from user queries,
interpreting them into structured Workflow Intention objects, and generating
Workflows based on these Intentions. Our results show that this layer enables
LLMs to produce logical and meaningful outputs that scale reliably as query
complexity increases. On a synthetic benchmark of 1,000 multi-intent
query-Workflow(s) pairs, applying the Opus Prompt Intention Framework to
Workflow Generation yields consistent improvements in semantic Workflow
similarity metrics. In this paper, we introduce the Opus Prompt Intention
Framework by applying the concepts of Workflow Signal and Workflow Intention to
LLM-driven Workflow Generation. We present a reproducible, customizable
LLM-based Intention Capture system to extract Workflow Signals and Workflow
Intentions from user queries. Finally, we provide empirical evidence that the
proposed system significantly improves Workflow Generation quality compared to
direct generation from user queries, particularly in cases of Mixed Intention
Elicitation.

</details>


### [28] [Contestability in Quantitative Argumentation](https://arxiv.org/abs/2507.11323)
*Xiang Yin,Nico Potyka,Antonio Rago,Timotheus Kampik,Francesca Toni*

Main category: cs.AI

TL;DR: 论文探讨了如何利用边加权定量双极论证框架（EW-QBAFs）实现可争议AI，提出基于梯度的关系归因解释（G-RAEs）和迭代算法来调整边权重，以实现目标论证强度的调整。


<details>
  <summary>Details</summary>
Motivation: 研究动机是确保AI决策与人类偏好一致，但目前EW-QBAFs在支持可争议性方面的研究较少。

Method: 方法包括提出G-RAEs量化边权重变化对目标论证强度的影响，并设计迭代算法逐步调整权重。

Result: 实验表明，该方法在模拟个性化推荐系统和多层感知器的合成EW-QBAFs上有效解决了问题。

Conclusion: 结论是EW-QBAFs结合G-RAEs和迭代算法能够有效支持AI决策的可争议性。

Abstract: Contestable AI requires that AI-driven decisions align with human
preferences. While various forms of argumentation have been shown to support
contestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks
(EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs
can be deployed for this purpose. Specifically, we introduce the contestability
problem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences)
to achieve a desired strength for a specific argument of interest (i.e., a
topic argument). To address this problem, we propose gradient-based relation
attribution explanations (G-RAEs), which quantify the sensitivity of the topic
argument's strength to changes in individual edge weights, thus providing
interpretable guidance for weight adjustments towards contestability. Building
on G-RAEs, we develop an iterative algorithm that progressively adjusts the
edge weights to attain the desired strength. We evaluate our approach
experimentally on synthetic EW-QBAFs that simulate the structural
characteristics of personalised recommender systems and multi-layer
perceptrons, and demonstrate that it can solve the problem effectively.

</details>


### [29] [CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking](https://arxiv.org/abs/2507.11334)
*Yuehao Huang,Liang Liu,Shuangming Lei,Yukai Ma,Hao Su,Jianbiao Mei,Pengxiang Zhao,Yaqing Gu,Yong Liu,Jiajun Lv*

Main category: cs.AI

TL;DR: CogDDN是一种基于视觉语言模型（VLM）的框架，通过模拟人类认知和学习机制，结合快速和慢速思维系统，提升机器人在未知环境中的导航能力。


<details>
  <summary>Details</summary>
Motivation: 传统的数据驱动需求导航（DDN）方法依赖预收集数据，泛化能力有限，无法适应未知场景。

Method: CogDDN通过语义对齐检测对象与指令，结合启发式和分析式决策模块，并利用思维链（CoT）推理优化决策过程。

Result: 在AI2Thor模拟器和ProcThor数据集上的评估显示，CogDDN比单视角相机方法性能提升15%。

Conclusion: CogDDN显著提高了导航准确性和适应性，为未知环境中的机器人导航提供了新思路。

Abstract: Mobile robots are increasingly required to navigate and interact within
unknown and unstructured environments to meet human demands. Demand-driven
navigation (DDN) enables robots to identify and locate objects based on
implicit human intent, even when object locations are unknown. However,
traditional data-driven DDN methods rely on pre-collected data for model
training and decision-making, limiting their generalization capability in
unseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that
emulates the human cognitive and learning mechanisms by integrating fast and
slow thinking systems and selectively identifying key objects essential to
fulfilling user demands. CogDDN identifies appropriate target objects by
semantically aligning detected objects with the given instructions.
Furthermore, it incorporates a dual-process decision-making module, comprising
a Heuristic Process for rapid, efficient decisions and an Analytic Process that
analyzes past errors, accumulates them in a knowledge base, and continuously
improves performance. Chain of Thought (CoT) reasoning strengthens the
decision-making process. Extensive closed-loop evaluations on the AI2Thor
simulator with the ProcThor dataset show that CogDDN outperforms single-view
camera-only methods by 15%, demonstrating significant improvements in
navigation accuracy and adaptability. The project page is available at
https://yuehaohuang.github.io/CogDDN/.

</details>


### [30] [Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces](https://arxiv.org/abs/2507.11352)
*Yunhao Yang,Neel P. Bhatt,Christian Ellis,Alvaro Velasquez,Zhangyang Wang,Ufuk Topcu*

Main category: cs.AI

TL;DR: 提出了一种结合自然语言对话与可验证保证的神经符号框架，用于复杂物流决策，提升实时性和安全性。


<details>
  <summary>Details</summary>
Motivation: 物流决策需要快速调整且面临不确定性，现有方法（如整数规划）速度慢且忽略不确定性，而大语言模型（LLMs）易产生误解和幻觉。

Method: 开发神经符号框架，将用户请求转为结构化规划，量化不确定性，并在置信度低时触发交互澄清循环。

Result: 轻量级模型在100个样本上微调后，性能超越GPT-4.1，推理延迟降低近50%。

Conclusion: 该框架为复杂物流提供了可验证、实时且用户对齐的决策路径。

Abstract: Logistics operators, from battlefield coordinators rerouting airlifts ahead
of a storm to warehouse managers juggling late trucks, often face life-critical
decisions that demand both domain expertise and rapid and continuous
replanning. While popular methods like integer programming yield logistics
plans that satisfy user-defined logical constraints, they are slow and assume
an idealized mathematical model of the environment that does not account for
uncertainty. On the other hand, large language models (LLMs) can handle
uncertainty and promise to accelerate replanning while lowering the barrier to
entry by translating free-form utterances into executable plans, yet they
remain prone to misinterpretations and hallucinations that jeopardize safety
and cost. We introduce a neurosymbolic framework that pairs the accessibility
of natural-language dialogue with verifiable guarantees on goal interpretation.
It converts user requests into structured planning specifications, quantifies
its own uncertainty at the field and token level, and invokes an interactive
clarification loop whenever confidence falls below an adaptive threshold. A
lightweight model, fine-tuned on just 100 uncertainty-filtered examples,
surpasses the zero-shot performance of GPT-4.1 while cutting inference latency
by nearly 50%. These preliminary results highlight a practical path toward
certifiable, real-time, and user-aligned decision-making for complex logistics.

</details>


### [31] [Modeling Code: Is Text All You Need?](https://arxiv.org/abs/2507.11467)
*Daniel Nichols,Konstantinos Parasyris,Harshitha Menon,Brian R. Bartoldson,Giorgis Georgakoudis,Tal Ben-Nun,Abhinav Bhatele*

Main category: cs.AI

TL;DR: 结合代码文本建模与结构化建模优势的新方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有Transformer模型在代码结构化分析（如控制流和数据流）上的局限性，同时保留现代LLM的生成能力和规模。

Method: 提出一种结合代码文本建模与结构化建模的新方法。

Result: 未明确提及具体结果，但旨在提升代码建模的综合能力。

Conclusion: 通过结合两种建模方式，有望在代码任务中实现更全面的性能提升。

Abstract: Code LLMs have become extremely popular recently for modeling source code
across a variety of tasks, such as generation, translation, and summarization.
However, transformer-based models are limited in their capabilities to reason
through structured, analytical properties of code, such as control and data
flow. Previous work has explored the modeling of these properties with
structured data and graph neural networks. However, these approaches lack the
generative capabilities and scale of modern LLMs. In this work, we introduce a
novel approach to combine the strengths of modeling both code as text and more
structured forms.

</details>


### [32] [Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety](https://arxiv.org/abs/2507.11473)
*Tomek Korbak,Mikita Balesni,Elizabeth Barnes,Yoshua Bengio,Joe Benton,Joseph Bloom,Mark Chen,Alan Cooney,Allan Dafoe,Anca Dragan,Scott Emmons,Owain Evans,David Farhi,Ryan Greenblatt,Dan Hendrycks,Marius Hobbhahn,Evan Hubinger,Geoffrey Irving,Erik Jenner,Daniel Kokotajlo,Victoria Krakovna,Shane Legg,David Lindner,David Luan,Aleksander Mądry,Julian Michael,Neel Nanda,Dave Orr,Jakub Pachocki,Ethan Perez,Mary Phuong,Fabien Roger,Joshua Saxe,Buck Shlegeris,Martín Soto,Eric Steinberger,Jasmine Wang,Wojciech Zaremba,Bowen Baker,Rohin Shah,Vlad Mikulik*

Main category: cs.AI

TL;DR: AI系统通过人类语言“思考”为AI安全提供了新机会，即通过监控思维链（CoT）来检测潜在恶意意图。尽管CoT监控不完美，但仍具潜力，建议进一步研究并与其他安全方法结合使用。


<details>
  <summary>Details</summary>
Motivation: 探索AI系统通过语言表达思维的监控潜力，以增强AI安全性。

Method: 提出监控思维链（CoT）的方法，评估其可行性与局限性。

Result: CoT监控虽不完美，但显示出潜力，需结合其他安全措施。

Conclusion: 建议进一步研究CoT监控，并在开发前沿模型时考虑其对监控能力的影响。

Abstract: AI systems that "think" in human language offer a unique opportunity for AI
safety: we can monitor their chains of thought (CoT) for the intent to
misbehave. Like all other known AI oversight methods, CoT monitoring is
imperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows
promise and we recommend further research into CoT monitorability and
investment in CoT monitoring alongside existing safety methods. Because CoT
monitorability may be fragile, we recommend that frontier model developers
consider the impact of development decisions on CoT monitorability.

</details>


### [33] [Perspective-Aware AI in Extended Reality](https://arxiv.org/abs/2507.11479)
*Daniel Platnick,Matti Gruener,Marjan Alirezaie,Kent Larson,Dava J. Newman,Hossein Rahnama*

Main category: cs.AI

TL;DR: PAiR框架通过整合Perspective-Aware AI与XR，利用多模态数字足迹构建用户身份模型，实现可解释、上下文感知的沉浸式体验。


<details>
  <summary>Details</summary>
Motivation: 当前AI增强的XR系统因用户建模浅显和认知上下文有限而表现不佳，PAiR旨在解决这一问题。

Method: 基于Chronicles（多模态数字足迹学习）构建身份模型，并在闭环系统中动态链接用户状态与沉浸环境。

Result: 通过Unity引擎实现的两个概念验证场景展示了PAiR的实用性。

Conclusion: PAiR为人类-AI交互开辟了新方向，通过嵌入基于视角的身份模型提升沉浸式系统。

Abstract: AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive
experiences-yet current systems fall short due to shallow user modeling and
limited cognitive context. We introduce Perspective-Aware AI in Extended
Reality (PAiR), a foundational framework for integrating Perspective-Aware AI
(PAi) with XR to enable interpretable, context-aware experiences grounded in
user identity. PAi is built on Chronicles: reasoning-ready identity models
learned from multimodal digital footprints that capture users' cognitive and
experiential evolution. PAiR employs these models in a closed-loop system
linking dynamic user states with immersive environments. We present PAiR's
architecture, detailing its modules and system flow, and demonstrate its
utility through two proof-of-concept scenarios implemented in the Unity-based
OpenDome engine. PAiR opens a new direction for human-AI interaction by
embedding perspective-based identity models into immersive systems.

</details>


### [34] [Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light](https://arxiv.org/abs/2507.11482)
*Mani Hamidi,Terrence W. Deacon*

Main category: cs.AI

TL;DR: 该论文提出一个基于开放式进化理论的框架，重新审视强化学习（RL）的三个核心信条：代理的定义、学习目标和奖励假设的范围，并探讨其理论和应用意义。


<details>
  <summary>Details</summary>
Motivation: 强化学习的三个核心信条在理论和应用中存在局限性，作者希望通过进化理论的视角重新思考这些问题，以推动RL的发展。

Method: 通过类比进化理论，重新分析RL的三个信条，并结合生物学学习的背景，探讨进化动态在个体生命周期内的作用。

Result: 进化理论为RL的第二和第三信条提供了新的视角，但代理问题仍需结合生命起源理论来解决。

Conclusion: 进化理论为RL的部分问题提供了解决方案，但代理问题需要更广泛的理论框架，如生命起源理论。

Abstract: Three core tenets of reinforcement learning (RL)--concerning the definition
of agency, the objective of learning, and the scope of the reward
hypothesis--have been highlighted as key targets for conceptual revision, with
major implications for theory and application. We propose a framework, inspired
by open-ended evolutionary theory, to reconsider these three "dogmas." We
revisit each assumption and address related concerns raised alongside them. To
make our arguments relevant to RL as a model of biological learning, we first
establish that evolutionary dynamics can plausibly operate within living brains
over an individual's lifetime, and are not confined to cross-generational
processes. We begin by revisiting the second dogma, drawing on evolutionary
insights to enrich the "adaptation-rather-than-search" view of learning. We
then address the third dogma regarding the limits of the reward hypothesis,
using analogies from evolutionary fitness to illuminate the scalar reward vs.
multi-objective debate. After discussing practical implications for exploration
in RL, we turn to the first--and arguably most fundamental--issue: the absence
of a formal account of agency. We argue that unlike the other two problems, the
evolutionary paradigm alone cannot resolve the agency question, though it
gestures in a productive direction. We advocate integrating ideas from
origins-of-life theory, where the thermodynamics of sustenance and replication
offer promising foundations for understanding agency and resource-constrained
reinforcement learning in biological systems.

</details>


### [35] [DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering](https://arxiv.org/abs/2507.11527)
*Yinsheng Li,Zhen Dong,Yi Shao*

Main category: cs.AI

TL;DR: DrafterBench是一个用于评估LLM代理在土木工程图纸修订任务中的开源基准，包含12类任务、46个定制功能和1920个任务，旨在测试代理的多方面能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准不足以从工业角度系统评估LLM代理，特别是在土木工程领域，因此需要DrafterBench填补这一空白。

Method: DrafterBench总结了真实图纸文件中的任务类型，提供定制功能和任务，评估代理的指令理解、知识利用和动态适应能力。

Result: 基准全面评估了代理的结构化数据理解、功能执行、指令遵循和批判性推理能力，并提供任务准确性和错误统计的详细分析。

Conclusion: DrafterBench为LLM在工程应用中的集成提供了改进方向，并开源了测试集和工具包。

Abstract: Large Language Model (LLM) agents have shown great potential for solving
real-world problems and promise to be a solution for tasks automation in
industry. However, more benchmarks are needed to systematically evaluate
automation agents from an industrial perspective, for example, in Civil
Engineering. Therefore, we propose DrafterBench for the comprehensive
evaluation of LLM agents in the context of technical drawing revision, a
representation task in civil engineering. DrafterBench contains twelve types of
tasks summarized from real-world drawing files, with 46 customized
functions/tools and 1920 tasks in total. DrafterBench is an open-source
benchmark to rigorously test AI agents' proficiency in interpreting intricate
and long-context instructions, leveraging prior knowledge, and adapting to
dynamic instruction quality via implicit policy awareness. The toolkit
comprehensively assesses distinct capabilities in structured data
comprehension, function execution, instruction following, and critical
reasoning. DrafterBench offers detailed analysis of task accuracy and error
statistics, aiming to provide deeper insight into agent capabilities and
identify improvement targets for integrating LLMs in engineering applications.
Our benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench,
with the test set hosted at
https://huggingface.co/datasets/Eason666/DrafterBench.

</details>


### [36] [How Many Instructions Can LLMs Follow at Once?](https://arxiv.org/abs/2507.11538)
*Daniel Jaroslawicz,Brendan Whiting,Parth Shah,Karime Maamari*

Main category: cs.AI

TL;DR: IFScale是一个评估LLM在高指令密度下性能的基准测试，发现即使前沿模型在500条指令时准确率仅68%。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试仅评估单指令或少量指令任务，无法反映生产级LLM系统需同时遵循大量指令的实际情况。

Method: 引入IFScale基准测试，包含500条关键词包含指令，评估20个前沿模型在高指令密度下的表现。

Result: 最佳模型在500条指令时准确率为68%，模型大小和推理能力与性能下降模式相关。

Conclusion: 研究结果有助于设计高指令密度提示，并揭示了性能与延迟的权衡。

Abstract: Production-grade LLM systems require robust adherence to dozens or even
hundreds of instructions simultaneously. However, the instruction-following
capabilities of LLMs at high instruction densities have not yet been
characterized, as existing benchmarks only evaluate models on tasks with a
single or few instructions. We introduce IFScale, a simple benchmark of 500
keyword-inclusion instructions for a business report writing task to measure
how instruction-following performance degrades as instruction density
increases. We evaluate 20 state-of-the-art models across seven major providers
and find that even the best frontier models only achieve 68% accuracy at the
max density of 500 instructions. Our analysis reveals model size and reasoning
capability to correlate with 3 distinct performance degradation patterns, bias
towards earlier instructions, and distinct categories of instruction-following
errors. Our insights can help inform design of instruction-dense prompts in
real-world applications and highlight important performance-latency tradeoffs.
We open-source the benchmark and all results for further analysis at
https://distylai.github.io/IFScale.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [37] [Learning to Move in Rhythm: Task-Conditioned Motion Policies with Orbital Stability Guarantees](https://arxiv.org/abs/2507.10602)
*Maximilian Stölzle,T. Konstantin Rusch,Zach J. Patterson,Rodrigo Pérez-Dattari,Francesco Stella,Josie Hughes,Cosimo Della Santina,Daniela Rus*

Main category: cs.RO

TL;DR: 论文提出了一种名为OSMPs的新框架，通过结合学习到的微分同胚编码器和超临界Hopf分岔，解决了动态运动基元在捕获周期性行为和任务插值方面的局限性，并提供了轨道稳定性和横向收缩的正式保证。


<details>
  <summary>Details</summary>
Motivation: 动态运动基元（DMPs）在稳定性方面表现良好，但在复杂周期性行为和任务插值方面存在不足，限制了其实际应用范围。为了解决这些问题，作者提出了OSMPs框架。

Method: OSMPs结合了学习到的微分同胚编码器和超临界Hopf分岔，通过任务条件化的双射编码器，实现了对周期性运动的准确学习，并支持多任务表示。

Result: 实验验证表明，OSMPs在多种机器人平台上（如协作臂、软体机械手和仿生龟机器人）均优于现有基线方法（如扩散策略）。

Conclusion: OSMPs框架在周期性运动学习和任务泛化方面表现出色，为机器人学习复杂行为提供了更高效和稳定的解决方案。

Abstract: Learning from demonstration provides a sample-efficient approach to acquiring
complex behaviors, enabling robots to move robustly, compliantly, and with
fluidity. In this context, Dynamic Motion Primitives offer built - in stability
and robustness to disturbances but often struggle to capture complex periodic
behaviors. Moreover, they are limited in their ability to interpolate between
different tasks. These shortcomings substantially narrow their applicability,
excluding a wide class of practically meaningful tasks such as locomotion and
rhythmic tool use. In this work, we introduce Orbitally Stable Motion
Primitives (OSMPs) - a framework that combines a learned diffeomorphic encoder
with a supercritical Hopf bifurcation in latent space, enabling the accurate
acquisition of periodic motions from demonstrations while ensuring formal
guarantees of orbital stability and transverse contraction. Furthermore, by
conditioning the bijective encoder on the task, we enable a single learned
policy to represent multiple motion objectives, yielding consistent zero-shot
generalization to unseen motion objectives within the training distribution. We
validate the proposed approach through extensive simulation and real-world
experiments across a diverse range of robotic platforms - from collaborative
arms and soft manipulators to a bio-inspired rigid-soft turtle robot -
demonstrating its versatility and effectiveness in consistently outperforming
state-of-the-art baselines such as diffusion policies, among others.

</details>


### [38] [Vision Language Action Models in Robotic Manipulation: A Systematic Review](https://arxiv.org/abs/2507.10672)
*Muhayy Ud Din,Waseem Akram,Lyes Saad Saoud,Jan Rosell,Irfan Hussain*

Main category: cs.RO

TL;DR: 本文综述了视觉语言动作（VLA）模型在机器人领域的应用，分析了102个模型、26个数据集和12个仿真平台，提出了分类框架和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 统一视觉感知、自然语言理解和机器人控制，推动通用机器人代理的发展。

Method: 通过分类架构范式、评估数据集和仿真平台，提出二维表征框架。

Result: 发现当前数据集的不足，提出未来研究方向如可扩展预训练协议和模块化设计。

Conclusion: 本文为VLA模型的发展提供了技术参考和概念路线图，从数据集生成到实际部署。

Abstract: Vision Language Action (VLA) models represent a transformative shift in
robotics, with the aim of unifying visual perception, natural language
understanding, and embodied control within a single learning framework. This
review presents a comprehensive and forward-looking synthesis of the VLA
paradigm, with a particular emphasis on robotic manipulation and
instruction-driven autonomy. We comprehensively analyze 102 VLA models, 26
foundational datasets, and 12 simulation platforms that collectively shape the
development and evaluation of VLAs models. These models are categorized into
key architectural paradigms, each reflecting distinct strategies for
integrating vision, language, and control in robotic systems. Foundational
datasets are evaluated using a novel criterion based on task complexity,
variety of modalities, and dataset scale, allowing a comparative analysis of
their suitability for generalist policy learning. We introduce a
two-dimensional characterization framework that organizes these datasets based
on semantic richness and multimodal alignment, showing underexplored regions in
the current data landscape. Simulation environments are evaluated for their
effectiveness in generating large-scale data, as well as their ability to
facilitate transfer from simulation to real-world settings and the variety of
supported tasks. Using both academic and industrial contributions, we recognize
ongoing challenges and outline strategic directions such as scalable
pretraining protocols, modular architectural design, and robust multimodal
alignment strategies. This review serves as both a technical reference and a
conceptual roadmap for advancing embodiment and robotic control, providing
insights that span from dataset generation to real world deployment of
generalist robotic agents.

</details>


### [39] [Exteroception through Proprioception Sensing through Improved Contact Modeling for Soft Growing Robots](https://arxiv.org/abs/2507.10694)
*Francesco Fuentes,Serigne Diagne,Zachary Kingston,Laura H. Blumenschein*

Main category: cs.RO

TL;DR: 本文提出利用软体生长机器人作为环境探索和地图构建工具，通过碰撞行为建模和几何模拟器开发，结合蒙特卡洛采样优化部署策略。


<details>
  <summary>Details</summary>
Motivation: 软体机器人因其被动变形特性在非结构化环境中表现出色，但需进一步理解其碰撞和变形行为以利用触觉测量环境结构。

Method: 1. 分析离散转向时的碰撞行为；2. 开发基于几何的2D环境机器人轨迹模拟器；3. 使用蒙特卡洛采样估计最优部署策略。

Result: 在均匀和非均匀环境中，该方法能快速接近理想动作，验证了软体生长机器人在环境探索和地图构建中的潜力。

Conclusion: 软体生长机器人可作为高效的环境探索工具，其碰撞模型和模拟器为未来应用提供了基础。

Abstract: Passive deformation due to compliance is a commonly used benefit of soft
robots, providing opportunities to achieve robust actuation with few active
degrees of freedom. Soft growing robots in particular have shown promise in
navigation of unstructured environments due to their passive deformation. If
their collisions and subsequent deformations can be better understood, soft
robots could be used to understand the structure of the environment from direct
tactile measurements. In this work, we propose the use of soft growing robots
as mapping and exploration tools. We do this by first characterizing collision
behavior during discrete turns, then leveraging this model to develop a
geometry-based simulator that models robot trajectories in 2D environments.
Finally, we demonstrate the model and simulator validity by mapping unknown
environments using Monte Carlo sampling to estimate the optimal next deployment
given current knowledge. Over both uniform and non-uniform environments, this
selection method rapidly approaches ideal actions, showing the potential for
soft growing robots in unstructured environment exploration and mapping.

</details>


### [40] [RCG: Safety-Critical Scenario Generation for Robust Autonomous Driving via Real-World Crash Grounding](https://arxiv.org/abs/2507.10749)
*Benjamin Stoler,Juliet Yang,Jonathan Francis,Jean Oh*

Main category: cs.RO

TL;DR: 论文提出Real-world Crash Grounding (RCG)框架，通过结合碰撞语义和对抗扰动生成安全关键场景，提升自动驾驶系统的训练效果。


<details>
  <summary>Details</summary>
Motivation: 现实驾驶数据中安全关键场景稀缺，难以有效训练和评估自动驾驶系统。

Method: 通过对比预训练构建安全感知行为表示，结合小规模碰撞数据集微调，嵌入语义结构以生成高风险且行为真实的对抗轨迹。

Result: 实验显示，使用生成场景训练的自动驾驶系统下游成功率平均提升9.2%，且生成的对抗行为更真实有效。

Conclusion: RCG框架能生成更真实的高风险场景，显著提升自动驾驶系统的压力测试效果。

Abstract: Safety-critical scenarios are essential for training and evaluating
autonomous driving (AD) systems, yet remain extremely rare in real-world
driving datasets. To address this, we propose Real-world Crash Grounding (RCG),
a scenario generation framework that integrates crash-informed semantics into
adversarial perturbation pipelines. We construct a safety-aware behavior
representation through contrastive pre-training on large-scale driving logs,
followed by fine-tuning on a small, crash-rich dataset with approximate
trajectory annotations extracted from video. This embedding captures semantic
structure aligned with real-world accident behaviors and supports selection of
adversary trajectories that are both high-risk and behaviorally realistic. We
incorporate the resulting selection mechanism into two prior scenario
generation pipelines, replacing their handcrafted scoring objectives with an
embedding-based criterion. Experimental results show that ego agents trained
against these generated scenarios achieve consistently higher downstream
success rates, with an average improvement of 9.2% across seven evaluation
settings. Qualitative and quantitative analyses further demonstrate that our
approach produces more plausible and nuanced adversary behaviors, enabling more
effective and realistic stress testing of AD systems. Code and tools will be
released publicly.

</details>


### [41] [rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding](https://arxiv.org/abs/2507.10776)
*Howard H. Qian,Yiting Chen,Gaotian Wang,Podshara Chanrungmaneekul,Kaiyu Hang*

Main category: cs.RO

TL;DR: 提出了一种实时交互感知框架rt-RISeg，通过机器人交互和设计的体帧不变特征（BFIF）实现未见物体的连续分割，无需依赖学习模型，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有未见物体实例分割（UOIS）方法因依赖大规模数据集而导致的过拟合和泛化性能差的问题。

Method: 基于交互视觉原理，利用机器人交互产生的相对旋转和线性速度设计体帧不变特征（BFIF），实时分割物体。

Result: 平均分割准确率比现有UOIS方法高27.5%，并可作为视觉基础模型的提示进一步提升性能。

Conclusion: rt-RISeg通过交互感知实现了高效且自给自足的分割，为机器人操作任务提供了新思路。

Abstract: Successful execution of dexterous robotic manipulation tasks in new
environments, such as grasping, depends on the ability to proficiently segment
unseen objects from the background and other objects. Previous works in unseen
object instance segmentation (UOIS) train models on large-scale datasets, which
often leads to overfitting on static visual features. This dependency results
in poor generalization performance when confronted with out-of-distribution
scenarios. To address this limitation, we rethink the task of UOIS based on the
principle that vision is inherently interactive and occurs over time. We
propose a novel real-time interactive perception framework, rt-RISeg, that
continuously segments unseen objects by robot interactions and analysis of a
designed body frame-invariant feature (BFIF). We demonstrate that the relative
rotational and linear velocities of randomly sampled body frames, resulting
from selected robot interactions, can be used to identify objects without any
learned segmentation model. This fully self-contained segmentation pipeline
generates and updates object segmentation masks throughout each robot
interaction without the need to wait for an action to finish. We showcase the
effectiveness of our proposed interactive perception method by achieving an
average object segmentation accuracy rate 27.5% greater than state-of-the-art
UOIS methods. Furthermore, although rt-RISeg is a standalone framework, we show
that the autonomously generated segmentation masks can be used as prompts to
vision foundation models for significantly improved performance.

</details>


### [42] [Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection](https://arxiv.org/abs/2507.10814)
*Huiyi Wang,Fahim Shahriar,Alireza Azimi,Gautham Vasan,Rupam Mahmood,Colin Bellinger*

Main category: cs.RO

TL;DR: 论文提出了一种将预训练大模型（如语言模型和物体检测器）融入目标条件强化学习的方法，以提升机器人抓取的通用性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 通用机器人操作（如抓取）在家庭和工作场景中需求广泛，但传统方法学习物体交互成本高。预训练大模型能高效处理文本提示和识别物体，为解决这一问题提供了可能。

Method: 使用预训练物体检测模型，通过文本提示识别物体并生成掩码，用于目标条件强化学习中的目标设定。掩码提供物体无关的提示，提升特征共享和泛化能力。

Result: 在模拟抓取任务中，掩码目标条件方法实现了约90%的成功率，且对分布内外物体均有效，同时收敛更快。

Conclusion: 该方法通过结合预训练模型和目标条件强化学习，显著提升了机器人抓取的通用性和效率。

Abstract: General-purpose robotic manipulation, including reach and grasp, is essential
for deployment into households and workspaces involving diverse and evolving
tasks. Recent advances propose using large pre-trained models, such as Large
Language Models and object detectors, to boost robotic perception in
reinforcement learning. These models, trained on large datasets via
self-supervised learning, can process text prompts and identify diverse objects
in scenes, an invaluable skill in RL where learning object interaction is
resource-intensive. This study demonstrates how to integrate such models into
Goal-Conditioned Reinforcement Learning to enable general and versatile robotic
reach and grasp capabilities. We use a pre-trained object detection model to
enable the agent to identify the object from a text prompt and generate a mask
for goal conditioning. Mask-based goal conditioning provides object-agnostic
cues, improving feature sharing and generalization. The effectiveness of the
proposed framework is demonstrated in a simulated reach-and-grasp task, where
the mask-based goal conditioning consistently maintains a $\sim$90\% success
rate in grasping both in and out-of-distribution objects, while also ensuring
faster convergence to higher returns.

</details>


### [43] [Mixed Discrete and Continuous Planning using Shortest Walks in Graphs of Convex Sets](https://arxiv.org/abs/2507.10878)
*Savva Morozov,Tobia Marcucci,Bernhard Paus Graesdal,Alexandre Amice,Pablo A. Parrilo,Russ Tedrake*

Main category: cs.RO

TL;DR: 研究了在凸集图（GCS）中的最短路径问题（SWP），提出了一种结合半定规划和增量搜索的近似解法，并在机器人混合离散-连续规划问题中验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 凸集图（GCS）为混合离散-连续规划问题提供了统一框架，但缺乏高效的求解方法，因此需要研究SWP在GCS中的解法。

Method: 通过半定规划合成成本函数的二次下界，并利用增量搜索算法近似求解最短路径。

Result: 提出的方法在碰撞避免运动规划、技能链和混合系统最优控制等实验中表现出高性能和计算效率。

Conclusion: SWP在GCS中为机器人混合规划问题提供了通用且高效的解决方案。

Abstract: We study the Shortest-Walk Problem (SWP) in a Graph of Convex Sets (GCS). A
GCS is a graph where each vertex is paired with a convex program, and each edge
couples adjacent programs via additional costs and constraints. A walk in a GCS
is a sequence of vertices connected by edges, where vertices may be repeated.
The length of a walk is given by the cumulative optimal value of the
corresponding convex programs. To solve the SWP in GCS, we first synthesize a
piecewise-quadratic lower bound on the problem's cost-to-go function using
semidefinite programming. Then we use this lower bound to guide an
incremental-search algorithm that yields an approximate shortest walk. We show
that the SWP in GCS is a natural language for many mixed discrete-continuous
planning problems in robotics, unifying problems that typically require
specialized solutions while delivering high performance and computational
efficiency. We demonstrate this through experiments in collision-free motion
planning, skill chaining, and optimal control of hybrid systems.

</details>


### [44] [Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning](https://arxiv.org/abs/2507.10899)
*Wang Zhicheng,Satoshi Yagi,Satoshi Yamamori,Jun Morimoto*

Main category: cs.RO

TL;DR: 提出了一种基于SAM2的对象中心方法，用于提升移动机械臂在不同方向下执行任务的能力，显著增强了模仿学习系统的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前移动机械臂框架通常将导航和操作解耦，导致导航不精确时性能下降，尤其是在角度不对齐的情况下。需要一种方法使机械臂能从不同方向执行任务。

Method: 采用基于SAM2的对象中心方法，将操作方向信息融入模型，实现对同一任务在不同方向下的一致性理解。

Result: 在自定义移动机械臂上部署模型，并在不同角度下进行拾取放置任务测试，相比Action Chunking Transformer，模型在多样化角度训练下表现更优。

Conclusion: 该方法显著提升了模仿学习在移动机械臂任务中的泛化能力和鲁棒性。

Abstract: Imitation learning for mobile manipulation is a key challenge in the field of
robotic manipulation. However, current mobile manipulation frameworks typically
decouple navigation and manipulation, executing manipulation only after
reaching a certain location. This can lead to performance degradation when
navigation is imprecise, especially due to misalignment in approach angles. To
enable a mobile manipulator to perform the same task from diverse orientations,
an essential capability for building general-purpose robotic models, we propose
an object-centric method based on SAM2, a foundation model towards solving
promptable visual segmentation in images, which incorporates manipulation
orientation information into our model. Our approach enables consistent
understanding of the same task from different orientations. We deploy the model
on a custom-built mobile manipulator and evaluate it on a pick-and-place task
under varied orientation angles. Compared to Action Chunking Transformer, our
model maintains superior generalization when trained with demonstrations from
varied approach angles. This work significantly enhances the generalization and
robustness of imitation learning-based mobile manipulation systems.

</details>


### [45] [Fast Non-Episodic Adaptive Tuning of Robot Controllers with Online Policy Optimization](https://arxiv.org/abs/2507.10914)
*James A. Preiss,Fengze Xie,Yiheng Lin,Adam Wierman,Yisong Yue*

Main category: cs.RO

TL;DR: 论文提出了一种名为M-GAPS的单轨迹在线策略优化算法，用于动态调整机器人控制器参数，适应时变环境，并在硬件实验中验证了其优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决机器人控制器参数在动态变化环境中的在线优化问题，避免传统方法需要重置状态或预先知道时变信息的限制。

Method: 方法包括提出M-GAPS算法，重新参数化四旋翼状态空间和策略类以优化搜索空间，并在硬件实验中与基于模型和无模型的基线方法对比。

Result: 结果表明，M-GAPS能更快找到接近最优的参数，适应未建模的风和负载扰动，并在不同平台上表现优异。

Conclusion: 结论是M-GAPS在灵活性和数据效率上优于经典自适应控制和模型无关强化学习，具有实际硬件应用的潜力。

Abstract: We study online algorithms to tune the parameters of a robot controller in a
setting where the dynamics, policy class, and optimality objective are all
time-varying. The system follows a single trajectory without episodes or state
resets, and the time-varying information is not known in advance. Focusing on
nonlinear geometric quadrotor controllers as a test case, we propose a
practical implementation of a single-trajectory model-based online policy
optimization algorithm, M-GAPS,along with reparameterizations of the quadrotor
state space and policy class to improve the optimization landscape. In hardware
experiments,we compare to model-based and model-free baselines that impose
artificial episodes. We show that M-GAPS finds near-optimal parameters more
quickly, especially when the episode length is not favorable. We also show that
M-GAPS rapidly adapts to heavy unmodeled wind and payload disturbances, and
achieves similar strong improvement on a 1:6-scale Ackermann-steered car. Our
results demonstrate the hardware practicality of this emerging class of online
policy optimization that offers significantly more flexibility than classic
adaptive control, while being more stable and data-efficient than model-free
reinforcement learning.

</details>


### [46] [Unified Modeling and Structural Optimization of Multi-magnet Embedded Soft Continuum Robots for Enhanced Kinematic Performances](https://arxiv.org/abs/2507.10950)
*Zhiwei Wu,Jiahao Luo,Siyi Wei,Jinhui Zhang*

Main category: cs.RO

TL;DR: 提出了一种统一建模与优化框架，用于提升多磁体嵌入式软连续体机器人（MeSCRs）的运动性能。


<details>
  <summary>Details</summary>
Motivation: 通过建立可微系统公式，分析磁驱动下的平衡适定性和诱导构型几何，以优化机器人的运动性能。

Method: 基于扩展伪刚体模型建立可微系统公式，并开发基于微分几何的结构优化框架，将经典运动学指标与磁体配置关联。

Result: 最大可控自由度等于嵌入磁体数量的两倍，优化条件揭示了局部性能提升需通过调制构型空间度量谱来抵消其扭曲。

Conclusion: 仿真验证了框架的有效性，闭式解和梯度数值方法为设计提供了实用工具。

Abstract: This paper presents a unified modeling and optimization framework to enhance
the kinematic performance of multi-magnet embedded soft continuum robots
(MeSCRs). To this end, we establish a differentiable system formulation based
on an extended pseudo-rigid-body model. This formulation enables analysis of
the equilibrium well-posedness and the geometry of the induced configuration
under magnetic actuation. In particular, we show that the maximum controllable
degrees of freedom of a MeSCR equal twice the number of embedded magnets. We
subsequently develop a structural optimization framework based on differential
geometry that links classical kinematic measures (e.g., manipulability and
dexterity) to the configuration of embedded magnets. The resulting optimization
condition reveals that improving local performance requires structurally
modulating the spectrum of the configuration space metric to counteract its
distortion. Closed-form solutions for optimal magnet configurations are derived
under representative conditions, and a gradient-based numerical method is
proposed for general design scenarios. Simulation studies validate the
effectiveness of the proposed framework.

</details>


### [47] [Whom to Respond To? A Transformer-Based Model for Multi-Party Social Robot Interaction](https://arxiv.org/abs/2507.10960)
*He Zhu,Ryo Miyoshi,Yuki Okafuji*

Main category: cs.RO

TL;DR: 提出了一种基于Transformer的多任务学习框架，用于提升社交机器人在多用户环境中的决策能力，通过两种新的损失函数和新的数据集，实现了最先进的响应决策性能。


<details>
  <summary>Details</summary>
Motivation: 多用户环境中，社交机器人需要理解上下文并决定何时及向谁响应，而现有研究主要关注单用户交互。

Method: 采用Transformer多任务学习框架，提出两种新损失函数：一种约束主动说话者以改进场景建模，另一种引导响应选择针对机器人的话语。构建了新的多用户HRI数据集。

Result: 实验表明，该模型在响应决策上优于现有启发式和单任务方法，达到最先进性能。

Conclusion: 研究为开发具有社交智能的机器人提供了支持，使其能够进行自然且上下文感知的多用户交互。

Abstract: Prior human-robot interaction (HRI) research has primarily focused on
single-user interactions, where robots do not need to consider the timing or
recipient of their responses. However, in multi-party interactions, such as at
malls and hospitals, social robots must understand the context and decide both
when and to whom they should respond. In this paper, we propose a
Transformer-based multi-task learning framework to improve the decision-making
process of social robots, particularly in multi-user environments. Considering
the characteristics of HRI, we propose two novel loss functions: one that
enforces constraints on active speakers to improve scene modeling, and another
that guides response selection towards utterances specifically directed at the
robot. Additionally, we construct a novel multi-party HRI dataset that captures
real-world complexities, such as gaze misalignment. Experimental results
demonstrate that our model achieves state-of-the-art performance in respond
decisions, outperforming existing heuristic-based and single-task approaches.
Our findings contribute to the development of socially intelligent social
robots capable of engaging in natural and context-aware multi-party
interactions.

</details>


### [48] [EquiContact: A Hierarchical SE(3) Vision-to-Force Equivariant Policy for Spatially Generalizable Contact-rich Tasks](https://arxiv.org/abs/2507.10961)
*Joohwan Seo,Arvind Kruthiventy,Soomi Lee,Megan Teng,Xiang Zhang,Seoyeon Choi,Jongeun Choi,Roberto Horowitz*

Main category: cs.RO

TL;DR: 提出了一种名为EquiContact的分层框架，用于学习基于视觉的机器人策略，在接触密集型任务中实现空间泛化。


<details>
  <summary>Details</summary>
Motivation: 解决peg-in-hole任务中从少量演示训练的策略在空间配置上的鲁棒泛化问题。

Method: 采用分层策略，包括高层视觉规划器（Diff-EDF）和低层顺应性视觉运动策略（G-CompACT），利用局部观测和SE(3)-等变性设计。

Result: 在真实PiH任务中实现了接近完美的成功率，并对未见空间配置表现出鲁棒泛化能力。

Conclusion: EquiContact框架通过顺应性、局部策略和等变性设计，有效提升了接触密集型任务的空间泛化性能。

Abstract: This paper presents a framework for learning vision-based robotic policies
for contact-rich manipulation tasks that generalize spatially across task
configurations. We focus on achieving robust spatial generalization of the
policy for the peg-in-hole (PiH) task trained from a small number of
demonstrations. We propose EquiContact, a hierarchical policy composed of a
high-level vision planner (Diffusion Equivariant Descriptor Field, Diff-EDF)
and a novel low-level compliant visuomotor policy (Geometric Compliant ACT,
G-CompACT). G-CompACT operates using only localized observations (geometrically
consistent error vectors (GCEV), force-torque readings, and wrist-mounted RGB
images) and produces actions defined in the end-effector frame. Through these
design choices, we show that the entire EquiContact pipeline is
SE(3)-equivariant, from perception to force control. We also outline three key
components for spatially generalizable contact-rich policies: compliance,
localized policies, and induced equivariance. Real-world experiments on PiH
tasks demonstrate a near-perfect success rate and robust generalization to
unseen spatial configurations, validating the proposed framework and
principles. The experimental videos can be found on the project website:
https://sites.google.com/berkeley.edu/equicontact

</details>


### [49] [SMART-Merge Planner: A Safe Merging and Real-Time Motion Planner for Autonomous Highway On-Ramp Merging](https://arxiv.org/abs/2507.10968)
*Toktam Mohammadnejad,Jovin D'sa,Behdad Chalaki,Hossein Nourkhiz Mahjoub,Ehsan Moradi-Pari*

Main category: cs.RO

TL;DR: 本文提出了一种基于栅格的SMART-Merge规划器，用于安全高效的强制并道任务。


<details>
  <summary>Details</summary>
Motivation: 高速公路并道是一项复杂的驾驶任务，需要识别安全间隙、调整速度，并在有限时间内完成并道，同时保证安全和舒适性。

Method: 通过调整成本函数以适应强制并道的独特挑战，并引入期望速度启发式方法，SMART-Merge规划器实现了快速且安全的并道。

Result: 在高保真CarMaker模拟中，该规划器在数百种高速并道场景中实现了100%的成功率，并道时间最短。

Conclusion: SMART-Merge规划器能够可靠且稳健地处理复杂的强制并道任务，为自动驾驶高速并道提供了有效解决方案。

Abstract: Merging onto a highway is a complex driving task that requires identifying a
safe gap, adjusting speed, often interactions to create a merging gap, and
completing the merge maneuver within a limited time window while maintaining
safety and driving comfort. In this paper, we introduce a Safe Merging and
Real-Time Merge (SMART-Merge) planner, a lattice-based motion planner designed
to facilitate safe and comfortable forced merging. By deliberately adapting
cost terms to the unique challenges of forced merging and introducing a desired
speed heuristic, SMART-Merge planner enables the ego vehicle to merge
successfully while minimizing the merge time. We verify the efficiency and
effectiveness of the proposed merge planner through high-fidelity CarMaker
simulations on hundreds of highway merge scenarios. Our proposed planner
achieves the success rate of 100% as well as completes the merge maneuver in
the shortest amount of time compared with the baselines, demonstrating our
planner's capability to handle complex forced merge tasks and provide a
reliable and robust solution for autonomous highway merge. The simulation
result videos are available at
https://sites.google.com/view/smart-merge-planner/home.

</details>


### [50] [Uncertainty Aware Mapping for Vision-Based Underwater Robots](https://arxiv.org/abs/2507.10991)
*Abhimanyu Bhowmik,Mohit Singh,Madhushree Sannigrahi,Martin Ludvigsen,Kostas Alexis*

Main category: cs.RO

TL;DR: 本文探讨了如何在基于视觉的水下机器人中表示地图不一致性，并将深度估计置信度融入体素地图框架中，改进了Voxblox的权重计算和更新机制。


<details>
  <summary>Details</summary>
Motivation: 传统传感器和预规划路径在狭窄空间中的局限性促使研究如何利用视觉感知处理环境不确定性。

Method: 使用RAFT-Stereo模型估计场景深度和置信度，并将其集成到Voxblox体素地图框架中，同时改进了权重计算和更新机制。

Result: 在受限水池和特隆赫姆峡湾码头进行的实验表明，水下机器人能够可视化不确定性变化。

Conclusion: 提出的方法有效提升了视觉水下机器人在狭窄空间中的环境表示能力。

Abstract: Vision-based underwater robots can be useful in inspecting and exploring
confined spaces where traditional sensors and preplanned paths cannot be
followed. Sensor noise and situational change can cause significant uncertainty
in environmental representation. Thus, this paper explores how to represent
mapping inconsistency in vision-based sensing and incorporate depth estimation
confidence into the mapping framework. The scene depth and the confidence are
estimated using the RAFT-Stereo model and are integrated into a voxel-based
mapping framework, Voxblox. Improvements in the existing Voxblox weight
calculation and update mechanism are also proposed. Finally, a qualitative
analysis of the proposed method is performed in a confined pool and in a pier
in the Trondheim fjord. Experiments using an underwater robot demonstrated the
change in uncertainty in the visualization.

</details>


### [51] [ILCL: Inverse Logic-Constraint Learning from Temporally Constrained Demonstrations](https://arxiv.org/abs/2507.11000)
*Minwoo Cho,Jaehwi Jang,Daehyung Park*

Main category: cs.RO

TL;DR: 提出了一种名为ILCL的新方法，通过遗传算法和逻辑约束强化学习的博弈，高效学习时间约束逻辑。


<details>
  <summary>Details</summary>
Motivation: 解决从演示中学习时间约束逻辑的问题，克服组合空间大和非马尔可夫约束的挑战。

Method: 结合遗传算法的时间逻辑挖掘（GA-TL-Mining）和逻辑约束强化学习（Logic-CRL），通过零和博弈框架学习TLTL约束。

Result: 在四个时间约束任务中优于现有方法，并成功迁移到真实世界的任务。

Conclusion: ILCL方法在学习和迁移时间约束逻辑方面表现出色，具有实际应用潜力。

Abstract: We aim to solve the problem of temporal-constraint learning from
demonstrations to reproduce demonstration-like logic-constrained behaviors.
Learning logic constraints is challenging due to the combinatorially large
space of possible specifications and the ill-posed nature of non-Markovian
constraints. To figure it out, we introduce a novel temporal-constraint
learning method, which we call inverse logic-constraint learning (ILCL). Our
method frames ICL as a two-player zero-sum game between 1) a genetic
algorithm-based temporal-logic mining (GA-TL-Mining) and 2) logic-constrained
reinforcement learning (Logic-CRL). GA-TL-Mining efficiently constructs syntax
trees for parameterized truncated linear temporal logic (TLTL) without
predefined templates. Subsequently, Logic-CRL finds a policy that maximizes
task rewards under the constructed TLTL constraints via a novel constraint
redistribution scheme. Our evaluations show ILCL outperforms state-of-the-art
baselines in learning and transferring TL constraints on four temporally
constrained tasks. We also demonstrate successful transfer to real-world
peg-in-shallow-hole tasks.

</details>


### [52] [Learning to Tune Like an Expert: Interpretable and Scene-Aware Navigation via MLLM Reasoning and CVAE-Based Adaptation](https://arxiv.org/abs/2507.11001)
*Yanbo Wang,Zipeng Fang,Lei Zhao,Weidong Chen*

Main category: cs.RO

TL;DR: LE-Nav是一种基于多模态大语言模型和条件变分自编码器的导航框架，通过自适应调整规划器超参数，实现零样本场景理解和专家级调参，显著提升导航性能和社会接受度。


<details>
  <summary>Details</summary>
Motivation: 传统导航系统在动态和非结构化环境中表现不佳，现有强化学习方法因泛化能力差和仿真多样性不足而难以实际应用。

Method: 利用多模态大语言模型推理和条件变分自编码器，结合单样本示例和思维链提示策略，实现自适应超参数调优。

Result: 实验表明LE-Nav在多种规划器和场景中达到人类调参水平，实际导航测试和用户研究显示其在成功率、效率、安全性和舒适度上优于现有方法。

Conclusion: LE-Nav通过场景感知和自适应调参，显著提升了导航系统的性能和用户接受度，为动态环境中的服务机器人提供了有效解决方案。

Abstract: Service robots are increasingly deployed in diverse and dynamic environments,
where both physical layouts and social contexts change over time and across
locations. In these unstructured settings, conventional navigation systems that
rely on fixed parameters often fail to generalize across scenarios, resulting
in degraded performance and reduced social acceptance. Although recent
approaches have leveraged reinforcement learning to enhance traditional
planners, these methods often fail in real-world deployments due to poor
generalization and limited simulation diversity, which hampers effective
sim-to-real transfer. To tackle these issues, we present LE-Nav, an
interpretable and scene-aware navigation framework that leverages multi-modal
large language model reasoning and conditional variational autoencoders to
adaptively tune planner hyperparameters. To achieve zero-shot scene
understanding, we utilize one-shot exemplars and chain-of-thought prompting
strategies. Additionally, a conditional variational autoencoder captures the
mapping between natural language instructions and navigation hyperparameters,
enabling expert-level tuning. Experiments show that LE-Nav can generate
hyperparameters achieving human-level tuning across diverse planners and
scenarios. Real-world navigation trials and a user study on a smart wheelchair
platform demonstrate that it outperforms state-of-the-art methods on
quantitative metrics such as success rate, efficiency, safety, and comfort,
while receiving higher subjective scores for perceived safety and social
acceptance. Code is available at https://github.com/Cavendish518/LE-Nav.

</details>


### [53] [Enhancing Autonomous Manipulator Control with Human-in-loop for Uncertain Assembly Environments](https://arxiv.org/abs/2507.11006)
*Ashutosh Mishra,Shreya Santra,Hazal Gozbasi,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 研究提出了一种结合自主机器人和人类控制的先进方法，用于月球任务中不确定环境下的机器人操作，重点是通过实时反馈和数字孪生技术提高任务可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决月球任务中复杂环境下机器人操作的挑战，如地形变化、光照不足和传感器限制，通过结合人类决策和自主功能提高任务效率。

Method: 采用可扩展的梯状结构和机器人操纵器，结合实时反馈和动态误差检测，辅以高效运动规划和人类干预，数字孪生模拟用于任务优化。

Result: 系统在模拟月球条件下验证了其性能，能够应对极端光照、地形变化和传感器限制，提高了任务可靠性。

Conclusion: 结合人类控制和自主技术的系统在复杂环境中表现出色，为未来空间任务提供了可靠解决方案。

Abstract: This study presents an advanced approach to enhance robotic manipulation in
uncertain and challenging environments, with a focus on autonomous operations
augmented by human-in-the-loop (HITL) control for lunar missions. By
integrating human decision-making with autonomous robotic functions, the
research improves task reliability and efficiency for space applications. The
key task addressed is the autonomous deployment of flexible solar panels using
an extendable ladder-like structure and a robotic manipulator with real-time
feedback for precision. The manipulator relays position and force-torque data,
enabling dynamic error detection and adaptive control during deployment. To
mitigate the effects of sinkage, variable payload, and low-lighting conditions,
efficient motion planning strategies are employed, supplemented by human
control that allows operators to intervene in ambiguous scenarios. Digital twin
simulation enhances system robustness by enabling continuous feedback,
iterative task refinement, and seamless integration with the deployment
pipeline. The system has been tested to validate its performance in simulated
lunar conditions and ensure reliability in extreme lighting, variable terrain,
changing payloads, and sensor limitations.

</details>


### [54] [TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update](https://arxiv.org/abs/2507.11069)
*Jeongyun Kim,Seunghoon Jeong,Giseop Kim,Myung-Hwan Jeon,Eunji Jun,Ayoung Kim*

Main category: cs.RO

TL;DR: TRAN-D是一种基于2D高斯泼溅的透明物体深度重建方法，通过分离透明物体与背景并优化高斯分布，显著提升了稀疏视图和动态环境下的3D几何重建效果。


<details>
  <summary>Details</summary>
Motivation: 透明物体的3D几何重建因反射和折射等物理特性而极具挑战性，尤其在稀疏视图和动态环境中。

Method: TRAN-D通过分离透明物体与背景，优化对应高斯分布，并引入物体感知损失和基于物理的模拟，减少伪影并提升重建效率。

Result: 在合成和真实序列中，TRAN-D的平均绝对误差降低39%，单图像更新的精度达48.46%，显著优于基线方法。

Conclusion: TRAN-D在透明物体重建中表现出色，尤其在稀疏视图和动态环境下，为相关领域提供了高效解决方案。

Abstract: Understanding the 3D geometry of transparent objects from RGB images is
challenging due to their inherent physical properties, such as reflection and
refraction. To address these difficulties, especially in scenarios with sparse
views and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian
Splatting-based depth reconstruction method for transparent objects. Our key
insight lies in separating transparent objects from the background, enabling
focused optimization of Gaussians corresponding to the object. We mitigate
artifacts with an object-aware loss that places Gaussians in obscured regions,
ensuring coverage of invisible surfaces while reducing overfitting.
Furthermore, we incorporate a physics-based simulation that refines the
reconstruction in just a few seconds, effectively handling object removal and
chain-reaction movement of remaining objects without the need for rescanning.
TRAN-D is evaluated on both synthetic and real-world sequences, and it
consistently demonstrated robust improvements over existing GS-based
state-of-the-art methods. In comparison with baselines, TRAN-D reduces the mean
absolute error by over 39% for the synthetic TRansPose sequences. Furthermore,
despite being updated using only one image, TRAN-D reaches a {\delta} < 2.5 cm
accuracy of 48.46%, over 1.5 times that of baselines, which uses six images.
Code and more results are available at https://jeongyun0609.github.io/TRAN-D/.

</details>


### [55] [Closed Form Time Derivatives of the Equations of Motion of Rigid Body Systems](https://arxiv.org/abs/2507.11076)
*Andreas Mueller,Shivesh Kumar*

Main category: cs.RO

TL;DR: 论文提出了二阶闭式形式的运动方程时间导数，替代现有递归算法，为机器人控制提供更直观的结构理解。


<details>
  <summary>Details</summary>
Motivation: 机器人控制需要平滑轨迹及控制力/力矩的时间导数，尤其是含弹性部件的多体系统。现有递归算法复杂，需更直接的方法。

Method: 采用李群理论描述刚体系统，推导出紧凑且易参数化的二阶时间导数闭式解。

Result: 提出的方法提供了运动方程时间导数的直接解析形式，结构清晰且计算高效。

Conclusion: 闭式二阶导数为机器人控制设计提供了更直观和高效的工具，尤其适用于含弹性部件的系统。

Abstract: Derivatives of equations of motion(EOM) describing the dynamics of rigid body
systems are becoming increasingly relevant for the robotics community and find
many applications in design and control of robotic systems. Controlling robots,
and multibody systems comprising elastic components in particular, not only
requires smooth trajectories but also the time derivatives of the control
forces/torques, hence of the EOM. This paper presents the time derivatives of
the EOM in closed form up to second-order as an alternative formulation to the
existing recursive algorithms for this purpose, which provides a direct insight
into the structure of the derivatives. The Lie group formulation for rigid body
systems is used giving rise to very compact and easily parameterized equations.

</details>


### [56] [Force-Based Viscosity and Elasticity Measurements for Material Biomechanical Characterisation with a Collaborative Robotic Arm](https://arxiv.org/abs/2507.11133)
*Luca Beber,Edoardo Lamon,Giacomo Moretti,Matteo Saveriano,Luca Fambri,Luigi Palopoli,Daniele Fontanelli*

Main category: cs.RO

TL;DR: 论文评估了机器人系统在估计材料粘弹性参数方面的准确性，并初步验证了其在生物样本中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 诊断活动（如超声扫描和触诊）成本低但易出错，机器人解决方案可减少结果的主观性并缩短等待时间。

Method: 通过机器人系统测量不同材料（包括离体组织）的粘弹性参数，并与高精度仪器测得的硅胶样本数据对比。

Result: 实验结果显示机器人系统的准确性与地面真实值高度匹配。

Conclusion: 机器人系统在临床应用中具有潜在价值。

Abstract: Diagnostic activities, such as ultrasound scans and palpation, are relatively
low-cost. They play a crucial role in the early detection of health problems
and in assessing their progression. However, they are also error-prone
activities, which require highly skilled medical staff. The use of robotic
solutions can be key to decreasing the inherent subjectivity of the results and
reducing the waiting list. For a robot to perform palpation or ultrasound
scans, it must effectively manage physical interactions with the human body,
which greatly benefits from precise estimation of the patient's tissue
biomechanical properties. This paper assesses the accuracy and precision of a
robotic system in estimating the viscoelastic parameters of various materials,
including some tests on ex vivo tissues as a preliminary proof-of-concept
demonstration of the method's applicability to biological samples. The
measurements are compared against a ground truth derived from silicone
specimens with different viscoelastic properties, characterised using a
high-precision instrument. Experimental results show that the robotic system's
accuracy closely matches the ground truth, increasing confidence in the
potential use of robots for such clinical applications.

</details>


### [57] [A Robust Controller based on Gaussian Processes for Robotic Manipulators with Unknown Uncertainty](https://arxiv.org/abs/2507.11170)
*Giulio Giacomuzzo,Mohamed Abdelwahab,Marco Calì,Alberto Dalla Libera,Ruggero Carli*

Main category: cs.RO

TL;DR: 提出一种基于学习的鲁棒反馈线性化策略，用于拉格朗日系统的精确轨迹跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决模型失配问题，确保轨迹跟踪的精确性，尤其是在缺乏先验模型失配边界的情况下。

Method: 采用高斯过程回归（GPR）估计模型失配，并将其与经典反馈线性化方案结合，通过鲁棒化控制器补偿剩余不确定性。

Result: 理论证明高概率下能保证渐近跟踪目标轨迹，并在2自由度平面机器人上进行了数值验证。

Conclusion: 所提策略有效解决了模型失配问题，实现了高精度的轨迹跟踪。

Abstract: In this paper, we propose a novel learning-based robust feedback
linearization strategy to ensure precise trajectory tracking for an important
family of Lagrangian systems. We assume a nominal knowledge of the dynamics is
given but no a-priori bounds on the model mismatch are available. In our
approach, the key ingredient is the adoption of a regression framework based on
Gaussian Processes (GPR) to estimate the model mismatch. This estimate is added
to the outer loop of a classical feedback linearization scheme based on the
nominal knowledge available. Then, to compensate for the residual uncertainty,
we robustify the controller including an additional term whose size is designed
based on the variance provided by the GPR framework. We proved that, with high
probability, the proposed scheme is able to guarantee asymptotic tracking of a
desired trajectory. We tested numerically our strategy on a 2 degrees of
freedom planar robot.

</details>


### [58] [MPC-based Coarse-to-Fine Motion Planning for Robotic Object Transportation in Cluttered Environments](https://arxiv.org/abs/2507.11211)
*Chen Cai,Ernesto Dickel Saraiva,Ya-jun Pan,Steven Liu*

Main category: cs.RO

TL;DR: 提出了一种新颖的从粗到细的运动规划框架，用于机器人在杂乱、未建模环境中的操作。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在复杂、未知环境中的运动规划问题，提高其适应性和鲁棒性。

Method: 结合双摄像头感知系统和基于B样条的模型预测控制（MPC）方案，逐步优化环境模型和运动规划。

Result: 实验验证了该框架在不确定性和杂乱环境中的鲁棒性和适应性。

Conclusion: 该框架有效支持动态重规划和闭环运动学，适用于复杂环境中的机器人操作。

Abstract: This letter presents a novel coarse-to-fine motion planning framework for
robotic manipulation in cluttered, unmodeled environments. The system
integrates a dual-camera perception setup with a B-spline-based model
predictive control (MPC) scheme. Initially, the planner generates feasible
global trajectories from partial and uncertain observations. As new visual data
are incrementally fused, both the environment model and motion planning are
progressively refined. A vision-based cost function promotes target-driven
exploration, while a refined kernel-perceptron collision detector enables
efficient constraint updates for real-time planning. The framework accommodates
closed-chain kinematics and supports dynamic replanning. Experiments on a
multi-arm platform validate its robustness and adaptability under uncertainties
and clutter.

</details>


### [59] [Comparison of Localization Algorithms between Reduced-Scale and Real-Sized Vehicles Using Visual and Inertial Sensors](https://arxiv.org/abs/2507.11241)
*Tobias Kern,Leon Tolksdorf,Christian Birkner*

Main category: cs.RO

TL;DR: 论文研究了物理缩比车辆对视觉和视觉-惯性自定位算法精度的影响，发现OpenVINS在缩比和真实尺寸车辆中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 探索缩比车辆作为测试平台对自动驾驶功能开发的可行性，特别是自定位算法的精度影响。

Method: 选择ROS2兼容的视觉和视觉-惯性算法（OpenVINS、VINS-Fusion、RTAB-Map），使用真实尺寸车辆数据作为基准，记录缩比车辆数据并比较算法精度。

Result: OpenVINS在缩比和真实尺寸车辆中定位误差最低，缩比车辆在平移运动估计上有微小差异，但旋转运动估计无显著差异。

Conclusion: 缩比车辆可作为自定位算法的测试平台，OpenVINS是表现最佳的算法。

Abstract: Physically reduced-scale vehicles are emerging to accelerate the development
of advanced automated driving functions. In this paper, we investigate the
effects of scaling on self-localization accuracy with visual and
visual-inertial algorithms using cameras and an inertial measurement unit
(IMU). For this purpose, ROS2-compatible visual and visual-inertial algorithms
are selected, and datasets are chosen as a baseline for real-sized vehicles. A
test drive is conducted to record data of reduced-scale vehicles. We compare
the selected localization algorithms, OpenVINS, VINS-Fusion, and RTAB-Map, in
terms of their pose accuracy against the ground-truth and against data from
real-sized vehicles. When comparing the implementation of the selected
localization algorithms to real-sized vehicles, OpenVINS has the lowest average
localization error. Although all selected localization algorithms have
overlapping error ranges, OpenVINS also performs best when applied to a
reduced-scale vehicle. When reduced-scale vehicles were compared to real-sized
vehicles, minor differences were found in translational vehicle motion
estimation accuracy. However, no significant differences were found when
comparing the estimation accuracy of rotational vehicle motion, allowing RSVRs
to be used as testing platforms for self-localization algorithms.

</details>


### [60] [Development of an Autonomous Mobile Robotic System for Efficient and Precise Disinfection](https://arxiv.org/abs/2507.11270)
*Ting-Wei Ou,Jia-Hao Jiang,Guan-Lin Huang,Kuu-Young Young*

Main category: cs.RO

TL;DR: 提出了一种针对病毒热点区域的移动机器人紫外线消毒系统，优化消毒剂量，显著减少消毒时间并提高效率。


<details>
  <summary>Details</summary>
Motivation: COVID-19疫情凸显了医院环境中自动消毒的紧迫性，现有研究多关注紫外线覆盖，而忽略了人类活动对病毒分布的影响。

Method: 设计移动机器人系统，优先消毒高风险区域，优化紫外线剂量，确保表面充分暴露同时减少消毒时间。

Result: 在两个典型医院场景中，消毒时间分别减少30.7%和31.9%，同时保持相同消毒效果。

Conclusion: 该系统高效且针对性强，适用于医院环境，显著提升消毒效率并减少不必要的低风险区域暴露。

Abstract: The COVID-19 pandemic has severely affected public health, healthcare
systems, and daily life, especially amid resource shortages and limited
workers. This crisis has underscored the urgent need for automation in hospital
environments, particularly disinfection, which is crucial to controlling virus
transmission and improving the safety of healthcare personnel and patients.
Ultraviolet (UV) light disinfection, known for its high efficiency, has been
widely adopted in hospital settings. However, most existing research focuses on
maximizing UV coverage while paying little attention to the impact of human
activity on virus distribution. To address this issue, we propose a mobile
robotic system for UV disinfection focusing on the virus hotspot. The system
prioritizes disinfection in high-risk areas and employs an approach for
optimized UV dosage to ensure that all surfaces receive an adequate level of UV
exposure while significantly reducing disinfection time. It not only improves
disinfection efficiency but also minimizes unnecessary exposure in low-risk
areas. In two representative hospital scenarios, our method achieves the same
disinfection effectiveness while reducing disinfection time by 30.7% and 31.9%,
respectively. The video of the experiment is available at:
https://youtu.be/wHcWzOcoMPM.

</details>


### [61] [Ocean Diviner: A Diffusion-Augmented Reinforcement Learning for AUV Robust Control in the Underwater Tasks](https://arxiv.org/abs/2507.11283)
*Weiyi Liu,Jingzehua Xu,Guanwen Xie,Yi Li*

Main category: cs.RO

TL;DR: 本文提出了一种扩散增强的强化学习方法，用于自主水下车辆（AUV）的鲁棒控制，解决了水下轨迹规划和动态环境适应中的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 水下环境复杂多变，传统控制方法在动态条件下表现不佳，需要一种更鲁棒和灵活的解决方案。

Method: 结合扩散模型和强化学习，通过扩散U-Net架构生成多步轨迹，并利用RL优化策略，实现高效探索和稳定控制。

Result: 仿真实验表明，该方法在复杂海洋条件下优于传统控制方法，具有更高的适应性和可靠性。

Conclusion: 扩散增强的RL方法为AUV控制提供了鲁棒且高效的解决方案，适用于动态水下任务。

Abstract: This paper presents a diffusion-augmented reinforcement learning (RL)
approach for robust autonomous underwater vehicle (AUV) control, addressing key
challenges in underwater trajectory planning and dynamic environment
adaptation. The proposed method integrates three core innovations: (1) A
diffusion-based trajectory generation framework that produces physically
feasible multi-step trajectories, enhanced by a high-dimensional state encoding
mechanism combining current observations with historical states and actions
through a novel diffusion U-Net architecture, significantly improving
long-horizon planning. (2) A sample-efficient hybrid learning architecture that
synergizes diffusion-guided exploration with RL policy optimization, where the
diffusion model generates diverse candidate actions and the RL critic selects
optimal actions, achieving higher exploration efficiency and policy stability
in dynamic underwater environments. Extensive simulation experiments validating
the method's superior robustness and flexibility, outperforms conventional
control methods in challenging marine conditions, offering enhanced
adaptability and reliability for AUV operations in the underwater tasks.

</details>


### [62] [Diffusion-Based Imaginative Coordination for Bimanual Manipulation](https://arxiv.org/abs/2507.11296)
*Huilin Xu,Jian Ding,Jiakun Xu,Ruixiang Wang,Jun Chen,Jinjie Mai,Yanwei Fu,Bernard Ghanem,Feng Xu,Mohamed Elhoseiny*

Main category: cs.RO

TL;DR: 提出了一种基于扩散的框架，联合优化视频和动作预测，显著提升双手机器人操作的协调性和成功率。


<details>
  <summary>Details</summary>
Motivation: 双手机器人操作在工业自动化和家庭服务中至关重要，但高维动作空间和复杂协调需求带来挑战。视频预测在表示学习和控制中的应用潜力尚未充分探索。

Method: 采用扩散框架，提出多帧潜在预测策略和单向注意力机制，视频预测依赖动作，动作预测独立于视频预测，提高推理效率。

Result: 在模拟和真实实验中，成功率显著提升：ALOHA提高24.9%，RoboTwin提高11.1%，真实实验提高32.5%。

Conclusion: 该方法通过联合优化视频和动作预测，有效提升双手机器人操作的协调性和性能，代码和模型已开源。

Abstract: Bimanual manipulation is crucial in robotics, enabling complex tasks in
industrial automation and household services. However, it poses significant
challenges due to the high-dimensional action space and intricate coordination
requirements. While video prediction has been recently studied for
representation learning and control, leveraging its ability to capture rich
dynamic and behavioral information, its potential for enhancing bimanual
coordination remains underexplored. To bridge this gap, we propose a unified
diffusion-based framework for the joint optimization of video and action
prediction. Specifically, we propose a multi-frame latent prediction strategy
that encodes future states in a compressed latent space, preserving
task-relevant features. Furthermore, we introduce a unidirectional attention
mechanism where video prediction is conditioned on the action, while action
prediction remains independent of video prediction. This design allows us to
omit video prediction during inference, significantly enhancing efficiency.
Experiments on two simulated benchmarks and a real-world setting demonstrate a
significant improvement in the success rate over the strong baseline ACT using
our method, achieving a \textbf{24.9\%} increase on ALOHA, an \textbf{11.1\%}
increase on RoboTwin, and a \textbf{32.5\%} increase in real-world experiments.
Our models and code are publicly available at
https://github.com/return-sleep/Diffusion_based_imaginative_Coordination.

</details>


### [63] [All Eyes, no IMU: Learning Flight Attitude from Vision Alone](https://arxiv.org/abs/2507.11302)
*Jesse J. Hagenaars,Stein Stroobants,Sander M. Bohte,Guido C. H. E. De Croon*

Main category: cs.RO

TL;DR: 论文提出了一种仅依赖视觉的飞行控制方法，通过事件相机和神经网络替代传统惯性传感器。


<details>
  <summary>Details</summary>
Motivation: 许多飞行生物依赖视觉而非惯性传感器进行姿态控制，而飞行机器人通常依赖加速度计和陀螺仪。本文旨在探索仅依赖视觉的飞行控制方法。

Method: 使用向下事件相机和低延迟循环卷积神经网络，通过监督学习训练，估计无人机姿态和旋转速率。

Result: 实验证明该方法可替代传统惯性测量单元，且网络在泛化性和视野范围方面表现良好。

Conclusion: 视觉飞行控制是实现小型自主飞行机器人的有前景方案。

Abstract: Vision is an essential part of attitude control for many flying animals, some
of which have no dedicated sense of gravity. Flying robots, on the other hand,
typically depend heavily on accelerometers and gyroscopes for attitude
stabilization. In this work, we present the first vision-only approach to
flight control for use in generic environments. We show that a quadrotor drone
equipped with a downward-facing event camera can estimate its attitude and
rotation rate from just the event stream, enabling flight control without
inertial sensors. Our approach uses a small recurrent convolutional neural
network trained through supervised learning. Real-world flight tests
demonstrate that our combination of event camera and low-latency neural network
is capable of replacing the inertial measurement unit in a traditional flight
control loop. Furthermore, we investigate the network's generalization across
different environments, and the impact of memory and different fields of view.
While networks with memory and access to horizon-like visual cues achieve best
performance, variants with a narrower field of view achieve better relative
generalization. Our work showcases vision-only flight control as a promising
candidate for enabling autonomous, insect-scale flying robots.

</details>


### [64] [Acting and Planning with Hierarchical Operational Models on a Mobile Robot: A Study with RAE+UPOM](https://arxiv.org/abs/2507.11345)
*Oscar Lima,Marc Vinci,Sunandita Patra,Sebastian Stock,Joachim Hertzberg,Martin Atzmueller,Malik Ghallab,Dana Nau,Paolo Traverso*

Main category: cs.RO

TL;DR: 论文提出了一种集成执行器-规划器系统（RAE+UPOM），通过共享层次化操作模型，实现了在机器人任务执行中规划与执行的紧密结合，并在实际部署中验证了其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决符号规划模型与实际机器人控制结构之间的不一致性问题，提升任务执行的鲁棒性和效率。

Method: 结合Reactive Acting Engine (RAE)和UCT-like Monte Carlo规划器(UPOM)，共享层次化操作模型，实现规划与执行的交替进行。

Result: 在移动机械臂上成功部署，实验表明系统能有效应对动作失败和传感器噪声，任务执行鲁棒。

Conclusion: RAE+UPOM系统通过共享模型和交替规划与执行，显著提升了机器人任务执行的鲁棒性和适应性。

Abstract: Robotic task execution faces challenges due to the inconsistency between
symbolic planner models and the rich control structures actually running on the
robot. In this paper, we present the first physical deployment of an integrated
actor-planner system that shares hierarchical operational models for both
acting and planning, interleaving the Reactive Acting Engine (RAE) with an
anytime UCT-like Monte Carlo planner (UPOM). We implement RAE+UPOM on a mobile
manipulator in a real-world deployment for an object collection task. Our
experiments demonstrate robust task execution under action failures and sensor
noise, and provide empirical insights into the interleaved acting-and-planning
decision making process.

</details>


### [65] [From Production Logistics to Smart Manufacturing: The Vision for a New RoboCup Industrial League](https://arxiv.org/abs/2507.11402)
*Supun Dissanayaka,Alexander Ferrein,Till Hofmann,Kosuke Nakajima,Mario Sanz-Lopez,Jesus Savage,Daniel Swoboda,Matteo Tschesche,Wataru Uemura,Tarik Viehmann,Shohei Yasuda*

Main category: cs.RO

TL;DR: 本文提出将RoboCup Logistics League升级为RoboCup Smart Manufacturing League，以涵盖现代工厂的更多方面，增强竞赛的吸引力。


<details>
  <summary>Details</summary>
Motivation: 现有的RoboCup Logistics League专注于生产物流，但未能反映智能制造的近期发展，导致其相关性下降。

Method: 设计新的竞赛场景，包含多个独立但逐步整合的赛道，涵盖工业机器人挑战如装配、人机协作和人形机器人。

Result: 预期新竞赛将更吸引新老团队，并聚焦工业机器人的当前和未来挑战。

Conclusion: 通过扩展竞赛范围，提升其与现代智能制造的关联性和吸引力。

Abstract: The RoboCup Logistics League is a RoboCup competition in a smart factory
scenario that has focused on task planning, job scheduling, and multi-agent
coordination. The focus on production logistics allowed teams to develop highly
competitive strategies, but also meant that some recent developments in the
context of smart manufacturing are not reflected in the competition, weakening
its relevance over the years. In this paper, we describe the vision for the
RoboCup Smart Manufacturing League, a new competition designed as a larger
smart manufacturing scenario, reflecting all the major aspects of a modern
factory. It will consist of several tracks that are initially independent but
gradually combined into one smart manufacturing scenario. The new tracks will
cover industrial robotics challenges such as assembly, human-robot
collaboration, and humanoid robotics, but also retain a focus on production
logistics. We expect the reenvisioned competition to be more attractive to
newcomers and well-tried teams, while also shifting the focus to current and
future challenges of industrial robotics.

</details>


### [66] [Multi-IMU Sensor Fusion for Legged Robots](https://arxiv.org/abs/2507.11447)
*Shuo Yang,John Z. Zhang,Ibrahima Sory Sow,Zachary Manchester*

Main category: cs.RO

TL;DR: 提出了一种用于腿式机器人的状态估计方法，通过低成本传感器实现低漂移的位姿和速度估计。


<details>
  <summary>Details</summary>
Motivation: 解决腿式机器人在复杂运动条件下标准本体感知里程计的主要误差问题。

Method: 利用多个惯性测量单元和关节编码器数据，结合扩展卡尔曼滤波和视觉-惯性-腿里程计方法。

Result: 在多种挑战性运动任务中，算法表现出最小位置偏差。

Conclusion: 该方法在复杂条件下表现优异，代码和数据集已开源。

Abstract: This paper presents a state-estimation solution for legged robots that uses a
set of low-cost, compact, and lightweight sensors to achieve low-drift pose and
velocity estimation under challenging locomotion conditions. The key idea is to
leverage multiple inertial measurement units on different links of the robot to
correct a major error source in standard proprioceptive odometry. We fuse the
inertial sensor information and joint encoder measurements in an extended
Kalman filter, then combine the velocity estimate from this filter with camera
data in a factor-graph-based sliding-window estimator to form a
visual-inertial-leg odometry method. We validate our state estimator through
comprehensive theoretical analysis and hardware experiments performed using
real-world robot data collected during a variety of challenging locomotion
tasks. Our algorithm consistently achieves minimal position deviation, even in
scenarios involving substantial ground impact, foot slippage, and sudden body
rotations. A C++ implementation, along with a large-scale dataset, is available
at https://github.com/ShuoYangRobotics/Cerberus2.0.

</details>


### [67] [Human-Robot collaboration in surgery: Advances and challenges towards autonomous surgical assistants](https://arxiv.org/abs/2507.11460)
*Jacinto Colan,Ana Davila,Yutaro Yamada,Yasuhisa Hasegawa*

Main category: cs.RO

TL;DR: 本文系统综述了手术中自主机器人助手（ASARs）的研究进展与挑战，重点关注机器人如何为外科医生提供有效支持。


<details>
  <summary>Details</summary>
Motivation: 随着自主机器人系统能力的提升，其在复杂手术中辅助外科医生的潜力日益凸显，推动了人机协作手术的研究。

Method: 遵循PRISMA指南，对IEEE Xplore、Scopus和Web of Science数据库进行文献检索，筛选出32项研究进行分析。

Result: 研究发现ASARs的研究重点集中在远程操作辅助和直接交互两种模式，主要应用于内窥镜引导，并在自主工具操作方面取得进展。关键挑战包括机器人行为与外科医生偏好的匹配、自主系统的程序意识、人机信息交换的流畅性以及共享工作空间中的技能获取。

Conclusion: 综述总结了当前趋势，指出了关键限制，并提出了未来研究方向，以提高手术中人机协作的可靠性、安全性和有效性。

Abstract: Human-robot collaboration in surgery represents a significant area of
research, driven by the increasing capability of autonomous robotic systems to
assist surgeons in complex procedures. This systematic review examines the
advancements and persistent challenges in the development of autonomous
surgical robotic assistants (ASARs), focusing specifically on scenarios where
robots provide meaningful and active support to human surgeons. Adhering to the
PRISMA guidelines, a comprehensive literature search was conducted across the
IEEE Xplore, Scopus, and Web of Science databases, resulting in the selection
of 32 studies for detailed analysis. Two primary collaborative setups were
identified: teleoperation-based assistance and direct hands-on interaction. The
findings reveal a growing research emphasis on ASARs, with predominant
applications currently in endoscope guidance, alongside emerging progress in
autonomous tool manipulation. Several key challenges hinder wider adoption,
including the alignment of robotic actions with human surgeon preferences, the
necessity for procedural awareness within autonomous systems, the establishment
of seamless human-robot information exchange, and the complexities of skill
acquisition in shared workspaces. This review synthesizes current trends,
identifies critical limitations, and outlines future research directions
essential to improve the reliability, safety, and effectiveness of human-robot
collaboration in surgical environments.

</details>


### [68] [LF: Online Multi-Robot Path Planning Meets Optimal Trajectory Control](https://arxiv.org/abs/2507.11464)
*Ajay Shankar,Keisuke Okumura,Amanda Prorok*

Main category: cs.RO

TL;DR: 提出了一种多机器人控制框架，结合集中式路径规划和分布式轨迹控制，实现高效、可扩展的点对点导航。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在全环境信息下的点对点导航问题，兼顾路径规划的快速性和轨迹控制的鲁棒性。

Method: 采用分层框架：1) 集中式离散路径规划（基于MAPF）；2) 分布式连续轨迹控制。结合LaCAM和Freyja实现。

Result: 展示了15架多旋翼机器人在动态环境中的高效导航，支持异步目标更新和快速重规划。

Conclusion: 该框架在多机器人导航中表现出鲁棒性和可扩展性，适用于动态环境。

Abstract: We propose a multi-robot control paradigm to solve point-to-point navigation
tasks for a team of holonomic robots with access to the full environment
information. The framework invokes two processes asynchronously at high
frequency: (i) a centralized, discrete, and full-horizon planner for computing
collision- and deadlock-free paths rapidly, leveraging recent advances in
multi-agent pathfinding (MAPF), and (ii) dynamics-aware, robot-wise optimal
trajectory controllers that ensure all robots independently follow their
assigned paths reliably. This hierarchical shift in planning representation
from (i) discrete and coupled to (ii) continuous and decoupled domains enables
the framework to maintain long-term scalable motion synthesis. As an
instantiation of this idea, we present LF, which combines a fast
state-of-the-art MAPF solver (LaCAM), and a robust feedback control stack
(Freyja) for executing agile robot maneuvers. LF provides a robust and
versatile mechanism for lifelong multi-robot navigation even under asynchronous
and partial goal updates, and adapts to dynamic workspaces simply by quick
replanning. We present various multirotor and ground robot demonstrations,
including the deployment of 15 real multirotors with random, consecutive target
updates while a person walks through the operational workspace.

</details>


### [69] [Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming](https://arxiv.org/abs/2507.11498)
*Asad Ali Shahid,Francesco Braghin,Loris Roveda*

Main category: cs.RO

TL;DR: 本文介绍了Robot Drummer，一种能够高精度演奏多种曲目的人形机器人系统，通过强化学习实现长时程音乐表演。


<details>
  <summary>Details</summary>
Motivation: 探索人形机器人在音乐表演等表达性领域的潜力，尤其是鼓乐演奏中的快速反应和多肢协调挑战。

Method: 将鼓乐谱转化为节奏接触链，分段训练并行强化学习策略。

Result: 在三十多首流行曲目中表现出高F1分数，并涌现出类似人类的鼓乐策略。

Conclusion: 强化学习有望将人形机器人引入创造性音乐表演领域。

Abstract: Humanoid robots have seen remarkable advances in dexterity, balance, and
locomotion, yet their role in expressive domains, such as music performance,
remains largely unexplored. Musical tasks, like drumming, present unique
challenges, including split-second timing, rapid contacts, and multi-limb
coordination over pieces lasting minutes. In this paper, we introduce Robot
Drummer, a humanoid system capable of expressive, high-precision drumming
across a diverse repertoire of songs. We formulate humanoid drumming as
sequential fulfillment of timed-contacts and transform drum scores in to a
Rhythmic Contact Chain. To handle the long-horizon nature of musical
performance, we decompose each piece into fixed-length segments and train a
single policy across all segments in parallel using reinforcement learning.
Through extensive experiments on over thirty popular rock, metal, and jazz
tracks, our results demonstrate that Robot Drummer consistently achieves high
F1 scores. The learned behaviors exhibit emergent human-like drumming
strategies, such as cross-arm strikes, and adaptive sticks assignments,
demonstrating the potential of reinforcement learning to bring humanoid robots
into the domain of creative musical performance. Project page:
\href{https://robot-drummer.github.io}{robot-drummer.github.io}

</details>


### [70] [LLM-based ambiguity detection in natural language instructions for collaborative surgical robots](https://arxiv.org/abs/2507.11525)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.RO

TL;DR: 提出了一种基于大语言模型（LLM）的框架，用于检测手术场景中自然语言指令的歧义性，以提高人机协作的安全性。


<details>
  <summary>Details</summary>
Motivation: 自然语言指令的歧义性在安全关键的人机交互（如手术）中具有高风险，需解决此问题以提高协作的可靠性。

Method: 使用多种提示技术配置的LLM评估器集合，结合链式思维评估器和保形预测，检测语言、上下文、流程和关键歧义。

Result: 在Llama 3.2 11B和Gemma 3 12B上测试，分类准确率超过60%，能有效区分歧义与非歧义指令。

Conclusion: 该框架为手术中的人机协作提供了一种识别潜在歧义指令的机制，提升了安全性和可靠性。

Abstract: Ambiguity in natural language instructions poses significant risks in
safety-critical human-robot interaction, particularly in domains such as
surgery. To address this, we propose a framework that uses Large Language
Models (LLMs) for ambiguity detection specifically designed for collaborative
surgical scenarios. Our method employs an ensemble of LLM evaluators, each
configured with distinct prompting techniques to identify linguistic,
contextual, procedural, and critical ambiguities. A chain-of-thought evaluator
is included to systematically analyze instruction structure for potential
issues. Individual evaluator assessments are synthesized through conformal
prediction, which yields non-conformity scores based on comparison to a labeled
calibration dataset. Evaluating Llama 3.2 11B and Gemma 3 12B, we observed
classification accuracy exceeding 60% in differentiating ambiguous from
unambiguous surgical instructions. Our approach improves the safety and
reliability of human-robot collaboration in surgery by offering a mechanism to
identify potentially ambiguous instructions before robot action.

</details>
