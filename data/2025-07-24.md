<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 21]
- [cs.RO](#cs.RO) [Total: 38]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Towards Autonomous Sustainability Assessment via Multimodal AI Agents](https://arxiv.org/abs/2507.17012)
*Zhihan Zhang,Alexander Metzger,Yuxuan Mei,Felix Hähnlein,Zachary Englhardt,Tingyu Cheng,Gregory D. Abowd,Shwetak Patel,Adriana Schulz,Vikram Iyer*

Main category: cs.AI

TL;DR: 本文提出了一种使用多模态AI代理的创新生命周期评估(LCA)方法，通过模拟专家与利益相关者的交互，自动计算电子设备的碳排放，将传统需要数周或数月的专家工作时间缩短至1分钟以内。


<details>
  <summary>Details</summary>
Motivation: 传统LCA评估面临数据可用性不足的问题，从产品制造到处置的材料和工艺过程的环境影响数据往往缺失，而近年来对可持续性信息的需求激增，迫切需要一种能够解决数据缺口的新方法。

Method: 开发多模态AI代理系统，模拟LCA专家与产品经理、工程师等利益相关者的交互；采用自定义数据抽象和软件工具从在线文本、维修社区图像和政府认证中提取信息；开发直接环境影响估算方法，通过与相似产品集群比较进行碳足迹估算；构建数据驱动的排放因子生成方法，使用未知材料的属性将其表示为相似材料排放因子的加权和。

Result: AI代理方法将专家工作时间从数周/数月缩短至1分钟以内；在零专有数据情况下，碳足迹估算结果与专家LCA相比误差在19%以内；直接估算方法在笔记本电脑上3毫秒内完成，电子产品MAPE为12.28%；数据驱动排放因子生成方法相比人类专家选择最接近LCA数据库条目的方法，MAPE改善了120.26%。

Conclusion: 研究成功开发了一套完整的AI驱动LCA评估系统，显著提高了评估效率并解决了数据可用性问题，为未来LCA工作流程提供了新的可能性，具有良好的可扩展性和实际应用前景。

Abstract: Interest in sustainability information has surged in recent years. However,
the data required for a life cycle assessment (LCA) that maps the materials and
processes from product manufacturing to disposal into environmental impacts
(EI) are often unavailable. Here we reimagine conventional LCA by introducing
multimodal AI agents that emulate interactions between LCA experts and
stakeholders like product managers and engineers to calculate the
cradle-to-gate (production) carbon emissions of electronic devices. The AI
agents iteratively generate a detailed life-cycle inventory leveraging a custom
data abstraction and software tools that extract information from online text
and images from repair communities and government certifications. This approach
reduces weeks or months of expert time to under one minute and closes data
availability gaps while yielding carbon footprint estimates within 19% of
expert LCAs with zero proprietary data. Additionally, we develop a method to
directly estimate EI by comparing an input to a cluster of products with
similar descriptions and known carbon footprints. This runs in 3 ms on a laptop
with a MAPE of 12.28% on electronic products. Further, we develop a data-driven
method to generate emission factors. We use the properties of an unknown
material to represent it as a weighted sum of emission factors for similar
materials. Compared to human experts picking the closest LCA database entry,
this improves MAPE by 120.26%. We analyze the data and compute scaling of this
approach and discuss its implications for future LCA workflows.

</details>


### [2] [New Mechanisms in Flex Distribution for Bounded Suboptimal Multi-Agent Path Finding](https://arxiv.org/abs/2507.17054)
*Shao-Hung Chan,Thomy Phan,Jiaoyang Li,Sven Koenig*

Main category: cs.AI

TL;DR: 本文针对多智能体路径规划(MAPF)问题，提出了改进的EECBS算法中的flex分配机制，包括基于冲突的flex分配、基于延迟的flex分配和混合策略flex分配，以提高算法效率同时保持有界次优解的保证。


<details>
  <summary>Details</summary>
Motivation: 现有EECBS算法使用贪心flex分配虽然能保证找到有界次优解，但增加阈值可能导致解的成本超出界限，迫使算法在不同路径集合间切换而非解决特定集合的冲突，从而降低效率。

Method: 提出三种新的flex分配机制：1) 基于冲突的flex分配(Conflict-Based Flex Distribution)，按冲突数量比例分配flex；2) 基于延迟的flex分配(Delay-Based Flex Distribution)，估计满足约束所需的延迟；3) 混合策略flex分配(Mixed-Strategy Flex Distribution)，在分层框架中结合前两种方法。

Result: 实验结果表明，所提出的flex分配方法在性能上优于原始的贪心flex分配方法，同时保持了算法的完整性和有界次优性保证。

Conclusion: 新提出的flex分配机制有效改进了EECBS算法的效率，在保持理论保证的前提下，通过更合理的flex分配策略减少了不必要的路径集合切换，提高了冲突解决的效率。

Abstract: Multi-Agent Path Finding (MAPF) is the problem of finding a set of
collision-free paths, one for each agent in a shared environment. Its objective
is to minimize the sum of path costs (SOC), where the path cost of each agent
is defined as the travel time from its start location to its target location.
Explicit Estimation Conflict-Based Search (EECBS) is the leading algorithm for
bounded-suboptimal MAPF, with the SOC of the solution being at most a
user-specified factor $w$ away from optimal. EECBS maintains sets of paths and
a lower bound $LB$ on the optimal SOC. Then, it iteratively selects a set of
paths whose SOC is at most $w \cdot LB$ and introduces constraints to resolve
collisions. For each path in a set, EECBS maintains a lower bound on its
optimal path that satisfies constraints. By finding an individually
bounded-suboptimal path with cost at most a threshold of $w$ times its lower
bound, EECBS guarantees to find a bounded-suboptimal solution. To speed up
EECBS, previous work uses flex distribution to increase the threshold. Though
EECBS with flex distribution guarantees to find a bounded-suboptimal solution,
increasing the thresholds may push the SOC beyond $w \cdot LB$, forcing EECBS
to switch among different sets of paths instead of resolving collisions on a
particular set of paths, and thus reducing efficiency. To address this issue,
we propose Conflict-Based Flex Distribution that distributes flex in proportion
to the number of collisions. We also estimate the delays needed to satisfy
constraints and propose Delay-Based Flex Distribution. On top of that, we
propose Mixed-Strategy Flex Distribution, combining both in a hierarchical
framework. We prove that EECBS with our new flex distribution mechanisms is
complete and bounded-suboptimal. Our experiments show that our approaches
outperform the original (greedy) flex distribution.

</details>


### [3] [LoRA is All You Need for Safety Alignment of Reasoning LLMs](https://arxiv.org/abs/2507.17075)
*Yihao Xue,Baharan Mirzasoleiman*

Main category: cs.AI

TL;DR: 本文提出使用LoRA进行安全对齐微调可以在不损害推理能力的前提下确保大语言模型的安全性，有效解决了"安全税"问题


<details>
  <summary>Details</summary>
Motivation: 当前的安全对齐微调会显著降低大语言模型的推理能力，产生"安全税"现象。需要找到一种既能保证模型安全又不损害推理能力的方法

Method: 使用LoRA（低秩适应）在拒绝数据集上进行监督微调，将安全权重更新限制在低秩空间中，从而最小化对推理权重的干扰。还探索了通过正则化或权重合并来进一步减少权重重叠的方法

Result: 在数学、科学和编程四个基准测试中，LoRA方法产生了高度安全的LLM，安全水平与全模型微调相当，但不会损害推理能力。LoRA相比全模型微调产生的权重更新与初始权重的重叠更小

Conclusion: LoRA微调方法能够有效解决推理能力与安全性之间的权衡问题，为设计更一致改进推理-安全权衡的方法提供了重要启发

Abstract: Reasoning LLMs have demonstrated remarkable breakthroughs in solving complex
problems that were previously out of reach. To ensure LLMs do not assist with
harmful requests, safety alignment fine-tuning is necessary in the
post-training phase. However, safety alignment fine-tuning has recently been
shown to significantly degrade reasoning abilities, a phenomenon known as the
"Safety Tax". In this work, we show that using LoRA for SFT on refusal datasets
effectively aligns the model for safety without harming its reasoning
capabilities. This is because restricting the safety weight updates to a
low-rank space minimizes the interference with the reasoning weights. Our
extensive experiments across four benchmarks covering math, science, and coding
show that this approach produces highly safe LLMs -- with safety levels
comparable to full-model fine-tuning -- without compromising their reasoning
abilities. Additionally, we observe that LoRA induces weight updates with
smaller overlap with the initial weights compared to full-model fine-tuning. We
also explore methods that further reduce such overlap -- via regularization or
during weight merging -- and observe some improvement on certain tasks. We hope
this result motivates designing approaches that yield more consistent
improvements in the reasoning-safety trade-off.

</details>


### [4] [HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study](https://arxiv.org/abs/2507.17118)
*Mandar Pitale,Jelena Frtunikj,Abhinaw Priyadershi,Vasu Singh,Maria Spence*

Main category: cs.AI

TL;DR: 本文提出了HySAFE-AI混合安全架构分析框架，用于评估端到端AI系统（如大语言模型和视觉语言模型）在安全关键领域的安全性，并改进了传统的FMEA和FTA分析方法以适应基础模型的复杂性。


<details>
  <summary>Details</summary>
Motivation: 随着AI在自动驾驶系统和机器人等安全关键领域的广泛应用，特别是端到端单体架构（如大语言模型和视觉语言模型）的兴起，传统的安全分析方法面临挑战，需要适应这些基础模型复杂的潜在表示形成和利用机制。

Method: 研究者回顾了不同的架构解决方案，评估了常见安全分析技术（如FMEA和FTA）的有效性，并针对基础模型的复杂性质改进了这些技术，特别关注潜在表示的形成和利用。在此基础上提出了HySAFE-AI混合安全架构分析框架。

Result: 提出了HySAFE-AI框架，这是一个混合框架，能够将传统方法适配用于评估AI系统的安全性。该框架改进了传统安全分析技术，使其更适用于复杂的基础模型。

Conclusion: 研究为AI安全标准的未来发展提供了指导建议，展示了如何将传统安全分析方法适配到现代AI系统中，并为未来工作提供了方向提示，推动AI安全标准的演进。

Abstract: AI has become integral to safety-critical areas like autonomous driving
systems (ADS) and robotics. The architecture of recent autonomous systems are
trending toward end-to-end (E2E) monolithic architectures such as large
language models (LLMs) and vision language models (VLMs). In this paper, we
review different architectural solutions and then evaluate the efficacy of
common safety analyses such as failure modes and effect analysis (FMEA) and
fault tree analysis (FTA). We show how these techniques can be improved for the
intricate nature of the foundational models, particularly in how they form and
utilize latent representations. We introduce HySAFE-AI, Hybrid Safety
Architectural Analysis Framework for AI Systems, a hybrid framework that adapts
traditional methods to evaluate the safety of AI systems. Lastly, we offer
hints of future work and suggestions to guide the evolution of future AI safety
standards.

</details>


### [5] [Improving LLMs' Generalized Reasoning Abilities by Graph Problems](https://arxiv.org/abs/2507.17168)
*Qifan Zhang,Nuo Chen,Zehua Li,Miao Peng,Jing Tang,Jia Li*

Main category: cs.AI

TL;DR: 本文提出了图问题推理(GPR)方法来增强大语言模型的通用推理能力，创建了首个大规模图推理数据集GraphPile，并训练了GraphMind模型，在数学和非数学推理任务上都取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在新颖复杂问题上推理性能不佳，而领域特定的持续预训练方法缺乏向更广泛推理任务的迁移能力，需要一种能够提升通用推理能力的方法。

Method: 提出图问题推理(GPR)方法，构建了包含109亿个token、涵盖23个图任务的大规模数据集GraphPile，包含思维链、程序思维、执行轨迹和真实世界图数据，并在此基础上训练GraphMind模型。

Result: 在Llama 3、3.1和Gemma 2等基础模型上训练的GraphMind在数学推理任务上准确率提升高达4.9%，在逻辑推理和常识推理等非数学推理任务上改进高达21.2%。

Conclusion: 本研究首次利用图问题推理增强推理模式，创建了首个此类数据集，成功弥合了领域特定预训练与通用推理能力之间的差距，提升了大语言模型的适应性和鲁棒性。

Abstract: Large Language Models (LLMs) have made remarkable strides in reasoning tasks,
yet their performance often falters on novel and complex problems.
Domain-specific continued pretraining (CPT) methods, such as those tailored for
mathematical reasoning, have shown promise but lack transferability to broader
reasoning tasks. In this work, we pioneer the use of Graph Problem Reasoning
(GPR) to enhance the general reasoning capabilities of LLMs. GPR tasks,
spanning pathfinding, network analysis, numerical computation, and topological
reasoning, require sophisticated logical and relational reasoning, making them
ideal for teaching diverse reasoning patterns. To achieve this, we introduce
GraphPile, the first large-scale corpus specifically designed for CPT using GPR
data. Spanning 10.9 billion tokens across 23 graph tasks, the dataset includes
chain-of-thought, program-of-thought, trace of execution, and real-world graph
data. Using GraphPile, we train GraphMind on popular base models Llama 3 and
3.1, as well as Gemma 2, achieving up to 4.9 percent higher accuracy in
mathematical reasoning and up to 21.2 percent improvement in non-mathematical
reasoning tasks such as logical and commonsense reasoning. By being the first
to harness GPR for enhancing reasoning patterns and introducing the first
dataset of its kind, our work bridges the gap between domain-specific
pretraining and universal reasoning capabilities, advancing the adaptability
and robustness of LLMs.

</details>


### [6] [Our Cars Can Talk: How IoT Brings AI to Vehicles](https://arxiv.org/abs/2507.17214)
*Amod Kant Agrawal*

Main category: cs.AI

TL;DR: 本文提出将AI集成到车辆中作为感知平台，通过AI副驾驶实现机器和驾驶员之间的双向交流，从而将车辆维护从被动响应转变为主动预测。


<details>
  <summary>Details</summary>
Motivation: 传统车辆维护模式是被动响应式的，缺乏预测性和智能化。需要利用AI技术将车辆转变为智能感知平台，实现主动预测性维护，并建立机器与驾驶员之间的有效沟通桥梁。

Method: 提出集成AI副驾驶系统的概念框架，该系统能够同时理解机器语言和人类驾驶员语言，作为车辆智能感知平台的核心组件，实现预测性维护和AI驱动的用户交互。

Result: 文章提供了智能车辆系统、预测性维护和AI用户交互的概念性和技术性视角，为该领域的跨学科对话和未来研究方向提供指导框架。

Conclusion: AI副驾驶技术的集成是实现车辆从被动维护向主动预测性维护转变的关键，这种双语言AI系统将推动智能车辆系统、预测性维护和人机交互领域的发展和创新。

Abstract: Bringing AI to vehicles and enabling them as sensing platforms is key to
transforming maintenance from reactive to proactive. Now is the time to
integrate AI copilots that speak both languages: machine and driver. This
article offers a conceptual and technical perspective intended to spark
interdisciplinary dialogue and guide future research and development in
intelligent vehicle systems, predictive maintenance, and AI-powered user
interaction.

</details>


### [7] [Agent Identity Evals: Measuring Agentic Identity](https://arxiv.org/abs/2507.17257)
*Elija Perrier,Michael Timothy Bennett*

Main category: cs.AI

TL;DR: 这篇论文提出了代理身份评估(AIE)框架，用于衡量语言模型代理在时间推移中维持稳定身份的能力，以解决大语言模型固有缺陷对代理可信度和功能性的影响。


<details>
  <summary>Details</summary>
Motivation: 语言模型代理(LMAs)继承了大语言模型的病理特征(无状态性、随机性、对提示敏感性等)，这些特征会破坏代理的可识别性、连续性、持久性和一致性，从而削弱其推理、规划和行动等代理能力，最终影响可靠性、可信度和实用性。

Method: 引入代理身份评估(AIE)框架——一个严格的、统计驱动的经验框架，包含一套新颖的指标来测量LMA系统展现和维持代理身份的程度，包括其能力、属性和从状态扰动中恢复的能力。该框架可以与其他性能、能力和代理鲁棒性测量指标集成。

Result: 提出了可应用于LMA生命周期各个阶段的正式定义和方法，并提供了如何应用这些方法的工作示例。AIE框架可以帮助设计最优的LMA基础设施和支撑结构，如内存和工具。

Conclusion: AIE框架为评估和维持语言模型代理的身份稳定性提供了系统性解决方案，有助于提升代理系统的可信度和代理能力，为设计更可靠的LMA系统提供了理论基础和实践指导。

Abstract: Central to agentic capability and trustworthiness of language model agents
(LMAs) is the extent they maintain stable, reliable, identity over time.
However, LMAs inherit pathologies from large language models (LLMs)
(statelessness, stochasticity, sensitivity to prompts and
linguistically-intermediation) which can undermine their identifiability,
continuity, persistence and consistency. This attrition of identity can erode
their reliability, trustworthiness and utility by interfering with their
agentic capabilities such as reasoning, planning and action. To address these
challenges, we introduce \textit{agent identity evals} (AIE), a rigorous,
statistically-driven, empirical framework for measuring the degree to which an
LMA system exhibit and maintain their agentic identity over time, including
their capabilities, properties and ability to recover from state perturbations.
AIE comprises a set of novel metrics which can integrate with other measures of
performance, capability and agentic robustness to assist in the design of
optimal LMA infrastructure and scaffolding such as memory and tools. We set out
formal definitions and methods that can be applied at each stage of the LMA
life-cycle, and worked examples of how to apply them.

</details>


### [8] [Students' Feedback Requests and Interactions with the SCRIPT Chatbot: Do They Get What They Ask For?](https://arxiv.org/abs/2507.17258)
*Andreas Scholl,Natalie Kiesler*

Main category: cs.AI

TL;DR: 研究者开发了基于ChatGPT-4o-mini的编程学习聊天机器人SCRIPT，通过136名德国大学生的实验评估，发现学生的反馈请求遵循特定序列，机器人响应与学生需求匹配度达75%，为设计AI辅助编程教育工具提供了重要见解。


<details>
  <summary>Details</summary>
Motivation: 现有编程教育中缺乏有效的AI辅助学习工具，需要开发能够为编程新手提供开放式交互和结构化指导的智能聊天机器人，以支持学生在编程学习过程中获得个性化反馈和指导。

Method: 基于ChatGPT-4o-mini开发了SCRIPT聊天机器人，支持开放式交互和预定义提示的结构化指导。通过在德国某大学的编程入门课程中对136名学生进行实验评估，分析学生与SCRIPT的交互方式，重点关注他们的反馈偏好。

Result: 研究发现学生的反馈请求遵循特定的序列模式，聊天机器人的响应与学生请求的反馈类型匹配度达到75%，并且能够遵守系统提示约束。实验结果揭示了学生在解决编程任务时的反馈需求规律。

Conclusion: 研究为设计基于生成式AI的学习支持系统提供了重要见解，强调了在AI辅助工具中平衡指导性和灵活性的挑战。SCRIPT的成功应用展示了AI聊天机器人在编程教育中的潜力，同时指出了未来改进的方向。

Abstract: Building on prior research on Generative AI (GenAI) and related tools for
programming education, we developed SCRIPT, a chatbot based on ChatGPT-4o-mini,
to support novice learners. SCRIPT allows for open-ended interactions and
structured guidance through predefined prompts. We evaluated the tool via an
experiment with 136 students from an introductory programming course at a large
German university and analyzed how students interacted with SCRIPT while
solving programming tasks with a focus on their feedback preferences. The
results reveal that students' feedback requests seem to follow a specific
sequence. Moreover, the chatbot responses aligned well with students' requested
feedback types (in 75%), and it adhered to the system prompt constraints. These
insights inform the design of GenAI-based learning support systems and
highlight challenges in balancing guidance and flexibility in AI-assisted
tools.

</details>


### [9] [Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments](https://arxiv.org/abs/2507.17289)
*Shitong Zhu,Chenhao Fang,Derek Larson,Neel Reddy Pochareddy,Rajeev Rao,Sophie Zeng,Yanqing Peng,Wendy Summer,Alex Goncalves,Arya Pudota,Herve Robert*

Main category: cs.AI

TL;DR: 本文提出了合规大脑助手(CBA)，一个对话式AI助手，通过智能路由机制在快速模式和全代理模式间选择，显著提升企业合规任务效率，在关键词匹配率和LLM评判通过率等指标上大幅超越普通LLM。


<details>
  <summary>Details</summary>
Motivation: 企业环境中合规人员需要处理大量日常合规任务，现有LLM在处理复杂合规查询时存在响应质量和延迟之间的平衡问题，需要一个能够智能处理不同复杂度合规请求的AI助手。

Method: 设计了一个用户查询路由器，能够智能选择处理模式：(1) FastTrack模式：处理只需从知识库检索相关上下文的简单请求；(2) FullAgentic模式：处理需要复合行动和工具调用的复杂请求，能够主动发现各种合规文件中的上下文，并调用其他API/模型。

Result: 与开箱即用的LLM相比，CBA在各种真实世界隐私/合规相关查询上表现显著提升：平均关键词匹配率从41.7%提升到83.7%，LLM评判通过率从20.0%提升到82.0%。基于路由的完整设计在保持相近运行时间的同时，获得了更好的平均匹配率和通过率。

Conclusion: 路由机制成功实现了响应质量和延迟之间的良好平衡，验证了设计假设。CBA通过智能选择处理模式，能够有效提升企业合规任务的处理效率，为企业合规工作提供了实用的AI解决方案。

Abstract: This paper presents Compliance Brain Assistant (CBA), a conversational,
agentic AI assistant designed to boost the efficiency of daily compliance tasks
for personnel in enterprise environments. To strike a good balance between
response quality and latency, we design a user query router that can
intelligently choose between (i) FastTrack mode: to handle simple requests that
only need additional relevant context retrieved from knowledge corpora; and
(ii) FullAgentic mode: to handle complicated requests that need composite
actions and tool invocations to proactively discover context across various
compliance artifacts, and/or involving other APIs/models for accommodating
requests. A typical example would be to start with a user query, use its
description to find a specific entity and then use the entity's information to
query other APIs for curating and enriching the final AI response.
  Our experimental evaluations compared CBA against an out-of-the-box LLM on
various real-world privacy/compliance-related queries targeting various
personas. We found that CBA substantially improved upon the vanilla LLM's
performance on metrics such as average keyword match rate (83.7% vs. 41.7%) and
LLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full
routing-based design against the `fast-track only` and `full-agentic` modes and
found that it had a better average match-rate and pass-rate while keeping the
run-time approximately the same. This finding validated our hypothesis that the
routing mechanism leads to a good trade-off between the two worlds.

</details>


### [10] [Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning](https://arxiv.org/abs/2507.17418)
*Joobin Jin,Seokjun Hong,Gyeongseon Baek,Yeeun Kim,Byeongjoon Noh*

Main category: cs.AI

TL;DR: 提出了Ctx2TrajGen框架，这是一个基于GAIL的上下文感知轨迹生成模型，能够合成真实的城市驾驶行为，解决了微观交通建模中的非线性相互依赖和训练不稳定问题


<details>
  <summary>Details</summary>
Motivation: 精确建模微观车辆轨迹对交通行为分析和自动驾驶系统至关重要，现有方法在处理微观环境中的非线性相互依赖关系和训练不稳定性方面存在局限，同时面临数据稀缺和领域偏移的挑战

Method: 提出Ctx2TrajGen框架，结合生成对抗模仿学习(GAIL)、近端策略优化(PPO)和改进的Wasserstein生成对抗网络(WGAN-GP)，通过显式地对周围车辆和道路几何结构进行条件化建模，生成具有交互感知能力的轨迹

Result: 在无人机捕获的DRIFT数据集上的实验表明，该方法在真实性、行为多样性和上下文保真度方面均优于现有方法，能够有效解决数据稀缺和领域偏移问题

Conclusion: Ctx2TrajGen为微观车辆轨迹生成提供了一个鲁棒的解决方案，能够在无需仿真的情况下生成与真实世界上下文一致的交互感知轨迹，为交通行为分析和自动驾驶系统提供了有效支持

Abstract: Precise modeling of microscopic vehicle trajectories is critical for traffic
behavior analysis and autonomous driving systems. We propose Ctx2TrajGen, a
context-aware trajectory generation framework that synthesizes realistic urban
driving behaviors using GAIL. Leveraging PPO and WGAN-GP, our model addresses
nonlinear interdependencies and training instability inherent in microscopic
settings. By explicitly conditioning on surrounding vehicles and road geometry,
Ctx2TrajGen generates interaction-aware trajectories aligned with real-world
context. Experiments on the drone-captured DRIFT dataset demonstrate superior
performance over existing methods in terms of realism, behavioral diversity,
and contextual fidelity, offering a robust solution to data scarcity and domain
shift without simulation.

</details>


### [11] [An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models](https://arxiv.org/abs/2507.17477)
*Haoran Sun,Zekun Zhang,Shaoning Zeng*

Main category: cs.AI

TL;DR: 提出了一个不确定性驱动的自适应自对齐框架(UDASA)，通过量化输出不确定性并分阶段训练来自动改善大语言模型与人类意图的对齐，无需人工标注即可显著提升模型在多个任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在指令遵循和通用推理方面取得了显著进展，但在没有人工标注的情况下实现与人类意图和安全规范的高质量对齐仍然是一个根本性挑战。现有方法难以在完全自动化的情况下有效提升LLM的对齐性能。

Method: 提出UDASA框架：(1)为每个输入生成多个响应；(2)从语义、事实性和价值对齐三个维度量化输出不确定性；(3)基于不确定性分数构建偏好对；(4)根据不确定性差异将训练样本分为保守、适中、探索三个阶段；(5)在这些阶段中逐步优化模型。此外还进行了一系列预备研究来验证核心设计假设。

Result: 实验结果表明，UDASA在多个任务上优于现有对齐方法，包括无害性、有用性、真实性和受控情感生成，显著提升了模型性能。框架能够在完全自动化的情况下有效改善LLM与人类意图的对齐。

Conclusion: UDASA框架成功解决了在无人工标注情况下提升LLM对齐质量的挑战，通过不确定性量化和分阶段训练策略，实现了模型性能的显著改善，为自动化LLM对齐提供了一种有效的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
instruction following and general-purpose reasoning. However, achieving
high-quality alignment with human intent and safety norms without human
annotations remains a fundamental challenge. In this work, we propose an
Uncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to
improve LLM alignment in a fully automated manner. UDASA first generates
multiple responses for each input and quantifies output uncertainty across
three dimensions: semantics, factuality, and value alignment. Based on these
uncertainty scores, the framework constructs preference pairs and categorizes
training samples into three stages, conservative, moderate, and exploratory,
according to their uncertainty difference. The model is then optimized
progressively across these stages. In addition, we conduct a series of
preliminary studies to validate the core design assumptions and provide strong
empirical motivation for the proposed framework. Experimental results show that
UDASA outperforms existing alignment methods across multiple tasks, including
harmlessness, helpfulness, truthfulness, and controlled sentiment generation,
significantly improving model performance.

</details>


### [12] [LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning](https://arxiv.org/abs/2507.17482)
*Luca Salvatore Lorello,Nikolaos Manginas,Marco Lippi,Stefano Melacci*

Main category: cs.AI

TL;DR: 研究者提出了LTLZinc基准框架，用于生成时序推理和持续学习任务，以评估神经符号AI方法在时间维度上的表现，并发现现有方法存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的神经符号AI方法大多只应用于静态场景，缺乏在时间维度上进行推理的能力，而持续学习中的时序推理是一个很少被探索但具有挑战性的重要问题。

Method: 开发了LTLZinc基准框架，该框架通过线性时序逻辑规范结合MiniZinc约束和任意图像分类数据集，生成表达性丰富的时序推理和持续学习任务，并提供细粒度标注支持多种神经和神经符号训练设置。

Result: 在LTLZinc生成的六个神经符号序列分类任务和四个类持续学习任务上的实验表明，时序学习和推理具有挑战性，并突出了当前最先进方法的局限性。

Conclusion: LTLZinc框架成功揭示了现有神经符号AI和持续学习方法在时序推理方面的不足，为神经符号和持续学习社区提供了有价值的基准工具，有望推动统一时序学习和推理框架的研究发展。

Abstract: Neuro-symbolic artificial intelligence aims to combine neural architectures
with symbolic approaches that can represent knowledge in a human-interpretable
formalism. Continual learning concerns with agents that expand their knowledge
over time, improving their skills while avoiding to forget previously learned
concepts. Most of the existing approaches for neuro-symbolic artificial
intelligence are applied to static scenarios only, and the challenging setting
where reasoning along the temporal dimension is necessary has been seldom
explored. In this work we introduce LTLZinc, a benchmarking framework that can
be used to generate datasets covering a variety of different problems, against
which neuro-symbolic and continual learning methods can be evaluated along the
temporal and constraint-driven dimensions. Our framework generates expressive
temporal reasoning and continual learning tasks from a linear temporal logic
specification over MiniZinc constraints, and arbitrary image classification
datasets. Fine-grained annotations allow multiple neural and neuro-symbolic
training settings on the same generated datasets. Experiments on six
neuro-symbolic sequence classification and four class-continual learning tasks
generated by LTLZinc, demonstrate the challenging nature of temporal learning
and reasoning, and highlight limitations of current state-of-the-art methods.
We release the LTLZinc generator and ten ready-to-use tasks to the
neuro-symbolic and continual learning communities, in the hope of fostering
research towards unified temporal learning and reasoning frameworks.

</details>


### [13] [CQE under Epistemic Dependencies: Algorithms and Experiments (extended version)](https://arxiv.org/abs/2507.17487)
*Lorenzo Marconi,Flavia Ricci,Riccardo Rosati*

Main category: cs.AI

TL;DR: 本文研究了在本体上的受控查询评估(CQE)，通过结合认知依赖(EDs)和最优GA检查器的交集来回答布尔连接查询联合(BUCQs)，证明了该方法在DL-Lite_R本体下具有AC^0数据复杂度，并通过实验验证了实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的受控查询评估框架需要在保证信息安全的同时提供有效的查询回答机制。认知依赖作为新提出的逻辑规则族，需要与最优GA检查器结合来实现既安全又高效的查询处理，特别是对于布尔连接查询联合的处理。

Method: 将认知依赖(EDs)与最优GA检查器的概念结合，重点研究基于所有最优GA检查器交集的方法来回答布尔连接查询联合(BUCQs)。针对EDs的子类和DL-Lite_R本体，设计了详细的一阶重写算法来实现查询回答。

Result: 1) 刻画了基于交集方法的安全性，识别出完整EDs类别仍然保持安全；2) 证明了在EDs子类和DL-Lite_R本体下，BUCQs查询回答的数据复杂度为AC^0；3) 通过两种不同评估场景的实验验证了重写函数的实际可行性。

Conclusion: 基于最优GA检查器交集的受控查询评估方法能够为认知依赖框架提供强安全保证和良好的计算性能。对于特定的EDs子类和DL-Lite_R本体，该方法具有优异的理论复杂度和实际可行性。

Abstract: We investigate Controlled Query Evaluation (CQE) over ontologies, where
information disclosure is regulated by epistemic dependencies (EDs), a family
of logical rules recently proposed for the CQE framework. In particular, we
combine EDs with the notion of optimal GA censors, i.e. maximal sets of ground
atoms that are entailed by the ontology and can be safely revealed. We focus on
answering Boolean unions of conjunctive queries (BUCQs) with respect to the
intersection of all optimal GA censors - an approach that has been shown in
other contexts to ensure strong security guarantees with favorable
computational behavior. First, we characterize the security of this
intersection-based approach and identify a class of EDs (namely, full EDs) for
which it remains safe. Then, for a subclass of EDs and for DL-Lite_R
ontologies, we show that answering BUCQs in the above CQE semantics is in AC^0
in data complexity by presenting a suitable, detailed first-order rewriting
algorithm. Finally, we report on experiments conducted in two different
evaluation scenarios, showing the practical feasibility of our rewriting
function.

</details>


### [14] [Automated Hybrid Grounding Using Structural and Data-Driven Heuristics](https://arxiv.org/abs/2507.17493)
*Alexander Beiser,Markus Hecher,Stefan Woltran*

Main category: cs.AI

TL;DR: 本文提出了自动化混合接地算法，通过数据结构启发式方法解决答案集编程中接地瓶颈问题，自动决定何时使用解耦接地和标准接地


<details>
  <summary>Details</summary>
Motivation: 答案集编程在工业应用中面临接地瓶颈问题，现有的混合接地方法缺乏自动化决策机制来确定何时使用规则体解耦接地和何时使用标准自底向上接地

Method: 开发了基于数据结构启发式的分割算法，该算法能检测何时使用规则体解耦接地和何时使用标准接地。启发式方法基于规则结构和包含实例数据的估计程序

Result: 在原型实现上的实验显示了有前景的结果，在难以接地的场景上显示了改进，而在难以求解的实例上接近了最先进的性能

Conclusion: 自动化混合接地算法能够有效缓解答案集编程中的接地瓶颈问题，通过智能选择接地策略在不同场景下获得性能提升

Abstract: The grounding bottleneck poses one of the key challenges that hinders the
widespread adoption of Answer Set Programming in industry. Hybrid Grounding is
a step in alleviating the bottleneck by combining the strength of standard
bottom-up grounding with recently proposed techniques where rule bodies are
decoupled during grounding. However, it has remained unclear when hybrid
grounding shall use body-decoupled grounding and when to use standard bottom-up
grounding. In this paper, we address this issue by developing automated hybrid
grounding: we introduce a splitting algorithm based on data-structural
heuristics that detects when to use body-decoupled grounding and when standard
grounding is beneficial. We base our heuristics on the structure of rules and
an estimation procedure that incorporates the data of the instance. The
experiments conducted on our prototypical implementation demonstrate promising
results, which show an improvement on hard-to-ground scenarios, whereas on
hard-to-solve instances we approach state-of-the-art performance.

</details>


### [15] [Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning](https://arxiv.org/abs/2507.17512)
*Yu Li,Zhuoshi Pan,Honglin Lin,Mengyuan Sun,Conghui He,Lijun Wu*

Main category: cs.AI

TL;DR: 本研究系统性地探讨了可验证奖励强化学习(RLVR)框架下的多领域推理能力，重点关注数学推理、代码生成和逻辑谜题求解三个核心领域，通过全面的实验分析揭示了领域间相互作用的关键因素和优化策略。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR研究主要集中在单一推理领域（如数学问题、编程或逻辑推理），但现实场景需要多种认知技能的综合应用。然而，强化学习框架下多种推理技能之间的相互作用机制仍然缺乏深入理解，需要系统性研究来填补这一空白。

Method: 采用GRPO算法和Qwen-2.5-7B模型系列进行四个关键实验：(1)评估单领域训练的域内改进和跨域泛化能力；(2)分析跨域联合训练中的相互增强和冲突；(3)比较基础模型和指令模型在相同强化学习配置下的性能差异；(4)深入研究课程学习策略、奖励设计变化和语言特定因素等关键训练细节的影响。

Result: 通过广泛的实验，研究揭示了支配领域相互作用的动力学机制，识别出影响专业化和泛化推理性能的关键因素。实验结果提供了关于多领域推理能力发展的重要见解，包括领域间的相互促进和冲突模式。

Conclusion: 研究为优化强化学习方法提供了宝贵指导，以培养大语言模型的综合性多领域推理能力。这些发现有助于理解如何在RLVR框架下有效整合不同认知技能，为构建更强大的多领域推理系统奠定了理论基础。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing the reasoning capabilities of LLMs. Existing
research has predominantly concentrated on isolated reasoning domains such as
mathematical problem-solving, coding tasks, or logical reasoning. However, real
world reasoning scenarios inherently demand an integrated application of
multiple cognitive skills. Despite this, the interplay among these reasoning
skills under reinforcement learning remains poorly understood. To bridge this
gap, we present a systematic investigation of multi-domain reasoning within the
RLVR framework, explicitly focusing on three primary domains: mathematical
reasoning, code generation, and logical puzzle solving. We conduct a
comprehensive study comprising four key components: (1) Leveraging the GRPO
algorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the
models' in-domain improvements and cross-domain generalization capabilities
when trained on single-domain datasets. (2) Additionally, we examine the
intricate interactions including mutual enhancements and conflicts that emerge
during combined cross-domain training. (3) To further understand the influence
of SFT on RL, we also analyze and compare performance differences between base
and instruct models under identical RL configurations. (4) Furthermore, we
delve into critical RL training details, systematically exploring the impacts
of curriculum learning strategies, variations in reward design, and
language-specific factors. Through extensive experiments, our results offer
significant insights into the dynamics governing domain interactions, revealing
key factors influencing both specialized and generalizable reasoning
performance. These findings provide valuable guidance for optimizing RL
methodologies to foster comprehensive, multi-domain reasoning capabilities in
LLMs.

</details>


### [16] [TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment](https://arxiv.org/abs/2507.17514)
*Athanasios Davvetas,Xenia Ziouvelou,Ypatia Dami,Alexis Kaponis,Konstantina Giouvanopoulou,Michael Papademas*

Main category: cs.AI

TL;DR: 本文介绍了TAI扫描工具，这是一个基于RAG的AI系统自评估工具，专门用于协助遵守AI法案，通过预筛选和评估两个阶段来确定AI系统的风险等级并提供相关合规指导。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏有效的AI系统合规评估工具来帮助组织遵守AI法案的要求，特别是在确定AI系统风险等级和理解相关法律义务方面存在挑战，因此需要开发一个能够以最少输入提供准确评估的自动化工具。

Method: 采用基于检索增强生成(RAG)的两阶段方法：(1)预筛选阶段进行初步评估；(2)详细评估阶段确定AI系统的风险等级。系统通过比较高风险系统的设置来进行推理，并检索相关的AI法案条款来提供合规指导。

Result: 定性评估结果显示该工具在三个不同语义组的用例场景中都能正确预测风险等级，同时成功检索到相关条款。结果解释表明工具的推理主要依赖于与高风险系统设置的比较，这种行为归因于此类系统的部署需要仔细考虑。

Conclusion: TAI扫描工具成功实现了AI系统的自动化风险评估和合规指导，能够准确识别风险等级并提供相关的AI法案条款，为组织遵守AI法案提供了有效的技术支持，验证了基于RAG方法在法律合规评估领域的可行性。

Abstract: This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool
with minimalistic input. The current version of the tool supports the legal TAI
assessment, with a particular emphasis on facilitating compliance with the AI
Act. It involves a two-step approach with a pre-screening and an assessment
phase. The assessment output of the system includes insight regarding the
risk-level of the AI system according to the AI Act, while at the same time
retrieving relevant articles to aid with compliance and notify on their
obligations. Our qualitative evaluation using use-case scenarios yields
promising results, correctly predicting risk levels while retrieving relevant
articles across three distinct semantic groups. Furthermore, interpretation of
results shows that the tool's reasoning relies on comparison with the setting
of high-risk systems, a behaviour attributed to their deployment requiring
careful consideration, and therefore frequently presented within the AI Act.

</details>


### [17] [Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning](https://arxiv.org/abs/2507.17539)
*Xinyao Liu,Diping Song*

Main category: cs.AI

TL;DR: 本文提出了FundusExpert，一个专门用于眼科诊断的多模态大语言模型，通过FundusGen数据集和Fundus-Engine系统实现了定位-诊断推理能力的整合，在眼科问答和报告生成任务中显著超越现有模型性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在医疗诊断领域具有巨大潜力，但在眼科等专业领域面临注释粒度碎片化和临床推理逻辑不一致的关键挑战，这些问题阻碍了精确的跨模态理解能力。

Method: 提出FundusExpert眼科专用多模态大语言模型和FundusGen数据集，通过智能Fundus-Engine系统自动化定位并利用基于MLLM的语义扩展，在单张眼底图像中整合全局疾病分类、局部目标检测和细粒度特征分析。通过构建临床对齐的认知链来指导模型生成可解释的推理路径。

Result: FundusExpert在眼科问答任务中表现最佳，平均准确率比40B MedRegA高26.6%；在零样本报告生成任务中达到77.0%的临床一致性，显著超越GPT-4o的47.6%；发现数据质量与模型能力之间的缩放定律（L ∝ N^0.068）。

Conclusion: 通过整合区域级定位与诊断推理链，该工作开发了一个可扩展的、临床对齐的多模态大语言模型，并探索了缩小特定领域多模态大语言模型中视觉-语言差距的路径，为医疗AI在专业领域的应用提供了有效解决方案。

Abstract: Multimodal large language models (MLLMs) demonstrate significant potential in
the field of medical diagnosis. However, they face critical challenges in
specialized domains such as ophthalmology, particularly the fragmentation of
annotation granularity and inconsistencies in clinical reasoning logic, which
hinder precise cross-modal understanding. This paper introduces FundusExpert,
an ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning
capabilities, along with FundusGen, a dataset constructed through the
intelligent Fundus-Engine system. Fundus-Engine automates localization and
leverages MLLM-based semantic expansion to integrate global disease
classification, local object detection, and fine-grained feature analysis
within a single fundus image. Additionally, by constructing a clinically
aligned cognitive chain, it guides the model to generate interpretable
reasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen,
achieves the best performance in ophthalmic question-answering tasks,
surpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in
zero-shot report generation tasks, achieving a clinical consistency of 77.0%,
significantly outperforming GPT-4o's 47.6%. Furthermore, we reveal a scaling
law between data quality and model capability ($L \propto N^{0.068}$),
demonstrating that the cognitive alignment annotations in FundusGen enhance
data utilization efficiency. By integrating region-level localization with
diagnostic reasoning chains, our work develops a scalable, clinically-aligned
MLLM and explores a pathway toward bridging the visual-language gap in specific
MLLMs. Our project can be found at https://github.com/MeteorElf/FundusExpert.

</details>


### [18] [Simulating multiple human perspectives in socio-ecological systems using large language models](https://arxiv.org/abs/2507.17680)
*Yongchao Zeng,Calum Brown,Ioannis Kyriakou,Ronja Hotz,Mark Rounsevell*

Main category: cs.AI

TL;DR: 研究开发了HoPeS框架，利用大语言模型驱动的代理来模拟不同利益相关者的视角，帮助用户通过角色扮演体验和理解社会生态系统中的多元观点差异


<details>
  <summary>Details</summary>
Motivation: 社会生态系统的理解需要来自不同利益相关者的多元视角洞察，但这些视角往往难以获取。传统方法在探索和整合不同stakeholder观点方面存在局限性，因此需要开发基于仿真的替代方法来探索不同的利益相关者视角

Method: 开发HoPeS（面向人类的视角转换）建模框架，使用大语言模型驱动的代理来代表各种利益相关者；用户可以扮演代理角色来体验视角差异；采用仿真协议作为"脚手架"来简化多视角仿真过程，支持用户反思、转换和整合不同视角；构建原型系统在制度动态和土地利用变化背景下演示HoPeS

Result: 在说明性实验中，用户依次采用系统观察者和研究者的视角，尽管用户努力推荐技术上合理的政策，但由于利益相关者的竞争性倡导，政策建议与实施之间仍存在差异，反映了研究者与政策制定者视角之间的现实错位。用户体验到了作为研究者的主观挫折感和失望感，特别是在试图获得政治影响力的同时保持政治中立的挑战

Conclusion: 尽管存在挫折，用户仍表现出尝试替代叙事框架策略的高度动机，表明该系统在探索不同视角方面的潜力。进一步的系统和协议完善可能会在社会生态仿真中实现新形式的跨学科合作

Abstract: Understanding socio-ecological systems requires insights from diverse
stakeholder perspectives, which are often hard to access. To enable
alternative, simulation-based exploration of different stakeholder
perspectives, we develop the HoPeS (Human-Oriented Perspective Shifting)
modelling framework. HoPeS employs agents powered by large language models
(LLMs) to represent various stakeholders; users can step into the agent roles
to experience perspectival differences. A simulation protocol serves as a
"scaffold" to streamline multiple perspective-taking simulations, supporting
users in reflecting on, transitioning between, and integrating across
perspectives. A prototype system is developed to demonstrate HoPeS in the
context of institutional dynamics and land use change, enabling both
narrative-driven and numerical experiments. In an illustrative experiment, a
user successively adopts the perspectives of a system observer and a researcher
- a role that analyses data from the embedded land use model to inform
evidence-based decision-making for other LLM agents representing various
institutions. Despite the user's effort to recommend technically sound
policies, discrepancies persist between the policy recommendation and
implementation due to stakeholders' competing advocacies, mirroring real-world
misalignment between researcher and policymaker perspectives. The user's
reflection highlights the subjective feelings of frustration and disappointment
as a researcher, especially due to the challenge of maintaining political
neutrality while attempting to gain political influence. Despite this, the user
exhibits high motivation to experiment with alternative narrative framing
strategies, suggesting the system's potential in exploring different
perspectives. Further system and protocol refinement are likely to enable new
forms of interdisciplinary collaboration in socio-ecological simulations.

</details>


### [19] [Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks](https://arxiv.org/abs/2507.17695)
*Ilias Chatzistefanidis,Navid Nikaein*

Main category: cs.AI

TL;DR: 提出了一种结合大语言模型和实时优化算法的共生智能体范式，用于构建可信赖的6G网络自主管理系统，通过输入级和输出级优化器实现精确控制和实时适应。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要从专门化AI向通用人工智能(AGI)驱动的网络转变，现有的LLM智能体在网络管理中存在决策误差和实时性问题，需要一种更可信赖、高效的智能体架构来实现实时网络管理和服务供应。

Method: 设计了共生智能体范式，结合LLM与实时优化算法：(1)输入级优化器为数值精确任务提供有界不确定性引导；(2)输出级优化器在LLM监督下实现自适应实时控制。实现了两种新型智能体：无线接入网优化器和服务等级协议多智能体协商器，并提出了端到端AGI网络架构。

Result: 在5G测试平台上的实验表明，共生智能体比独立LLM智能体减少了5倍的决策错误；小型语言模型在GPU资源开销减少99.9%的情况下达到相似精度，实现82毫秒的近实时循环；多智能体协作在真实测试平台上将RAN过度利用率降低约44%。

Conclusion: 共生智能体范式为下一代AGI驱动的网络系统奠定了基础，在LLM不断发展的过程中保持了系统的适应性、效率和可信赖性，为6G网络的智能化管理提供了可行的解决方案。

Abstract: Large Language Model (LLM)-based autonomous agents are expected to play a
vital role in the evolution of 6G networks, by empowering real-time
decision-making related to management and service provisioning to end-users.
This shift facilitates the transition from a specialized intelligence approach,
where artificial intelligence (AI) algorithms handle isolated tasks, to
artificial general intelligence (AGI)-driven networks, where agents possess
broader reasoning capabilities and can manage diverse network functions. In
this paper, we introduce a novel agentic paradigm that combines LLMs with
real-time optimization algorithms towards Trustworthy AI, defined as symbiotic
agents. Optimizers at the LLM's input-level provide bounded uncertainty
steering for numerically precise tasks, whereas output-level optimizers
supervised by the LLM enable adaptive real-time control. We design and
implement two novel agent types including: (i) Radio Access Network optimizers,
and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We
further propose an end-to-end architecture for AGI networks and evaluate it on
a 5G testbed capturing channel fluctuations from moving vehicles. Results show
that symbiotic agents reduce decision errors fivefold compared to standalone
LLM-based agents, while smaller language models (SLM) achieve similar accuracy
with a 99.9% reduction in GPU resource overhead and in near-real-time loops of
82 ms. A multi-agent demonstration for collaborative RAN on the real-world
testbed highlights significant flexibility in service-level agreement and
resource allocation, reducing RAN over-utilization by approximately 44%.
Drawing on our findings and open-source implementations, we introduce the
symbiotic paradigm as the foundation for next-generation, AGI-driven
networks-systems designed to remain adaptable, efficient, and trustworthy even
as LLMs advance.

</details>


### [20] [Thinking Isn't an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations](https://arxiv.org/abs/2507.17699)
*Zhao Song,Song Yue,Jiahao Zhang*

Main category: cs.AI

TL;DR: 研究发现在引入工具增强（Python解释器和草稿本）后，大型推理模型（LRMs）在各种复杂度任务上都能持续超越非推理模型，挑战了"推理是幻觉"的观点


<details>
  <summary>Details</summary>
Motivation: 针对最近研究声称大型推理模型的逐步思考过程并不能真正增强推理能力，甚至在某些任务上表现不如普通LLM的问题，本研究旨在探究当引入工具增强时，LRM的局限性是否仍然存在

Method: 在三个代表性LLM及其LRM对应版本上引入两种工具增强：Python解释器和草稿本，并在Apple基准推理谜题上进行评估对比

Result: 结果显示，通过适当的工具使用，LRM在所有任务复杂度级别上都持续超越其非推理对应模型

Conclusion: 研究结果挑战了"推理是幻觉"的最新观点，突出了工具增强型LRM在解决复杂问题方面的潜力

Abstract: Large Reasoning Models (LRMs) have become a central focus in today's large
language model (LLM) research, where models are designed to output a
step-by-step thinking process before arriving at a final answer to handle
complex reasoning tasks. Despite their promise, recent empirical studies (e.g.,
[Shojaee et al., 2025] from Apple) suggest that this thinking process may not
actually enhance reasoning ability, where LLMs without explicit reasoning
actually outperform LRMs on tasks with low or high complexity. In this work, we
revisit these findings and investigate whether the limitations of LRMs persist
when tool augmentations are introduced. We incorporate two types of tools,
Python interpreters and scratchpads, and evaluate three representative LLMs and
their LRM counterparts on Apple's benchmark reasoning puzzles. Our results show
that, with proper tool use, LRMs consistently outperform their non-reasoning
counterparts across all levels of task complexity. These findings challenge the
recent narrative that reasoning is an illusion and highlight the potential of
tool-augmented LRMs for solving complex problems.

</details>


### [21] [Online Submission and Evaluation System Design for Competition Operations](https://arxiv.org/abs/2507.17730)
*Zhe Chen,Daniel Harabor,Ryan Hechnenberger,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 本文提出了一个在线竞赛系统，用于自动化处理竞赛的提交和评估过程，解决了传统学术竞赛中组织者管理大量提交以及参与者环境兼容性问题


<details>
  <summary>Details</summary>
Motivation: 研究社区虽然开发了基准数据集来比较算法性能，但跟踪研究进展困难，因为论文发表在不同场所且都声称代表最先进水平。传统的定期竞赛虽然能评估算法性能，但给组织者带来巨大运营负担，需要管理和评估大量提交，且参与者在不同环境中开发解决方案导致评估时出现兼容性问题

Method: 设计并实现了一个在线竞赛系统，该系统能够自动化竞赛的提交和评估过程。系统允许组织者高效管理大量提交，并利用隔离环境来评估提交的解决方案，从而解决兼容性问题

Result: 该系统已经成功应用于多个竞赛，包括基于网格的路径规划竞赛（Grid-Based Pathfinding Competition）和机器人跑步者联盟竞赛（League of Robot Runners competition）

Conclusion: 在线竞赛系统成功解决了传统学术竞赛中的运营负担和技术兼容性问题，为研究社区提供了一个高效的算法性能评估和进展跟踪平台，已在实际竞赛中得到验证

Abstract: Research communities have developed benchmark datasets across domains to
compare the performance of algorithms and techniques However, tracking the
progress in these research areas is not easy, as publications appear in
different venues at the same time, and many of them claim to represent the
state-of-the-art. To address this, research communities often organise periodic
competitions to evaluate the performance of various algorithms and techniques,
thereby tracking advancements in the field. However, these competitions pose a
significant operational burden. The organisers must manage and evaluate a large
volume of submissions. Furthermore, participants typically develop their
solutions in diverse environments, leading to compatibility issues during the
evaluation of their submissions. This paper presents an online competition
system that automates the submission and evaluation process for a competition.
The competition system allows organisers to manage large numbers of submissions
efficiently, utilising isolated environments to evaluate submissions. This
system has already been used successfully for several competitions, including
the Grid-Based Pathfinding Competition and the League of Robot Runners
competition.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [22] [Summarizing Normative Driving Behavior From Large-Scale NDS Datasets for Vehicle System Development](https://arxiv.org/abs/2507.16839)
*Gregory Beale,Gibran Ali*

Main category: cs.RO

TL;DR: 本文提出了一种处理大规模自然驾驶研究数据的方法，用于分析五个关键驾驶行为指标（速度、超速、车道保持、跟车距离和车头时距），并结合道路特征、车辆类型和驾驶员人口统计学特征进行分析，以支持车辆安全系统和智能交通系统的开发。


<details>
  <summary>Details</summary>
Motivation: 为了开发更好的车辆安全系统和智能交通系统，需要量化和理解常态化驾驶行为。现有研究缺乏大规模、多维度的驾驶行为分析方法，特别是缺乏跨群体比较的有效工具。

Method: 使用SHRP 2自然驾驶研究数据集（包含3400多名驾驶员超过3400万英里的驾驶数据），结合车辆数据、GPS数据和前向雷达数据，开发了一套处理和分析大规模自然驾驶数据的方法论。同时开发了交互式在线分析工具，用于可视化和比较不同群体的驾驶行为。

Result: 成功分析了五个关键驾驶指标的行为模式，发现了不同人群间的驾驶行为差异。例如，在65英里/小时限速道路上，16-19岁女性驾驶员超速7.5-15英里/小时的频率略高于同龄男性；年轻驾驶员保持1.5秒以下车头时距的频率高于年长驾驶员。

Conclusion: 该研究提供了一套完整的大规模自然驾驶数据分析方法论，通过量化常态化驾驶行为，为开发更好的车辆系统和更安全的基础设施提供支持，并为自然驾驶研究数据集的跨群体比较分析提供了有效工具。

Abstract: This paper presents a methodology to process large-scale naturalistic driving
studies (NDS) to describe the driving behavior for five vehicle metrics,
including speed, speeding, lane keeping, following distance, and headway,
contextualized by roadway characteristics, vehicle classes, and driver
demographics. Such descriptions of normative driving behaviors can aid in the
development of vehicle safety and intelligent transportation systems. The
methodology is demonstrated using data from the Second Strategic Highway
Research Program (SHRP 2) NDS, which includes over 34 million miles of driving
across more than 3,400 drivers. Summaries of each driving metric were generated
using vehicle, GPS, and forward radar data. Additionally, interactive online
analytics tools were developed to visualize and compare driving behavior across
groups through dynamic data selection and grouping. For example, among drivers
on 65-mph roads for the SHRP 2 NDS, females aged 16-19 exceeded the speed limit
by 7.5 to 15 mph slightly more often than their male counterparts, and younger
drivers maintained headways under 1.5 seconds more frequently than older
drivers. This work supports better vehicle systems and safer infrastructure by
quantifying normative driving behaviors and offers a methodology for analyzing
NDS datasets for cross group comparisons.

</details>


### [23] [AquaChat: An LLM-Guided ROV Framework for Adaptive Inspection of Aquaculture Net Pens](https://arxiv.org/abs/2507.16841)
*Waseem Akram,Muhayy Ud Din,Abdelhaleem Saad,Irfan Hussain*

Main category: cs.RO

TL;DR: 本研究提出了AquaChat，一个集成大语言模型的智能水产养殖网箱检测ROV框架，通过自然语言交互实现自适应的水下检测任务


<details>
  <summary>Details</summary>
Motivation: 传统的水产养殖网箱检测方法依赖预编程任务或人工控制，对动态水下环境和用户特定需求的适应性有限，需要更智能和自适应的检测系统

Method: 设计了多层架构的AquaChat系统：(1)高层规划层使用LLM解释自然语言用户指令并生成符号化任务计划；(2)中层任务管理器将计划转换为ROV控制序列；(3)低层运动控制层精确执行导航和检测任务，并具备实时反馈和事件触发重规划功能

Result: 在模拟和受控水环境中进行验证实验，结果显示任务灵活性、检测精度和操作效率均有显著提升

Conclusion: AquaChat展示了语言AI与海洋机器人技术结合的潜力，能够为可持续水产养殖运营提供智能的、用户交互式的检测系统

Abstract: Inspection of aquaculture net pens is essential for maintaining the
structural integrity, biosecurity, and operational efficiency of fish farming
systems. Traditional inspection approaches rely on pre-programmed missions or
manual control, offering limited adaptability to dynamic underwater conditions
and user-specific demands. In this study, we propose AquaChat, a novel Remotely
Operated Vehicle (ROV) framework that integrates Large Language Models (LLMs)
for intelligent and adaptive net pen inspection. The system features a
multi-layered architecture: (1) a high-level planning layer that interprets
natural language user commands using an LLM to generate symbolic task plans;
(2) a mid-level task manager that translates plans into ROV control sequences;
and (3) a low-level motion control layer that executes navigation and
inspection tasks with precision. Real-time feedback and event-triggered
replanning enhance robustness in challenging aquaculture environments. The
framework is validated through experiments in both simulated and controlled
aquatic environments representative of aquaculture net pens. Results
demonstrate improved task flexibility, inspection accuracy, and operational
efficiency. AquaChat illustrates the potential of integrating language-based AI
with marine robotics to enable intelligent, user-interactive inspection systems
for sustainable aquaculture operations.

</details>


### [24] [Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning](https://arxiv.org/abs/2507.16842)
*Yinan Meng,Kun Qian,Jiong Yang,Renbo Su,Zhenhong Li,Charlie C. L. Wang*

Main category: cs.RO

TL;DR: 本文提出了一种传感器空间模仿学习运动学控制框架(SS-ILKC)，通过双重学习策略和仿真到现实转移机制，实现了软体机械臂在受限环境下的鲁棒运动学控制。


<details>
  <summary>Details</summary>
Motivation: 冗余软体机械臂虽然具有内在顺应性和高自由度，便于安全交互和灵活任务执行，但其有效的运动学控制面临巨大挑战：需要处理未知外部载荷引起的变形，并避免因不当零空间调节导致的执行器饱和问题，特别是在受限环境中。

Method: 提出传感器空间模仿学习运动学控制(SS-ILKC)框架，采用双重学习策略：1)基于强化学习原理的多目标传感器空间控制框架在仿真中训练，为开放空间开发鲁棒控制策略；2)生成对抗模仿学习方法从稀疏专家演示中学习受限空间的有效策略。同时提出预处理的仿真到现实转移机制来缓解仿真与现实的差距并准确表征执行器饱和限制。

Result: 实验结果表明，该方法能够有效控制气动软体机械臂，在未知载荷条件下的受限环境中实现精确的路径跟踪和物体操作。

Conclusion: SS-ILKC框架成功解决了软体机械臂在受限环境下的运动学控制问题，通过双重学习策略和仿真到现实转移机制，实现了在执行器饱和和环境约束条件下的鲁棒控制，为软体机器人在复杂环境中的应用提供了有效解决方案。

Abstract: The intrinsic compliance and high degree of freedom (DoF) of redundant soft
manipulators facilitate safe interaction and flexible task execution. However,
effective kinematic control remains highly challenging, as it must handle
deformations caused by unknown external loads and avoid actuator saturation due
to improper null-space regulation - particularly in confined environments. In
this paper, we propose a Sensor-Space Imitation Learning Kinematic Control
(SS-ILKC) framework to enable robust kinematic control under actuator
saturation and restrictive environmental constraints. We employ a dual-learning
strategy: a multi-goal sensor-space control framework based on reinforcement
learning principle is trained in simulation to develop robust control policies
for open spaces, while a generative adversarial imitation learning approach
enables effective policy learning from sparse expert demonstrations for
confined spaces. To enable zero-shot real-world deployment, a pre-processed
sim-to-real transfer mechanism is proposed to mitigate the
simulation-to-reality gap and accurately characterize actuator saturation
limits. Experimental results demonstrate that our method can effectively
control a pneumatically actuated soft manipulator, achieving precise
path-following and object manipulation in confined environments under unknown
loading conditions.

</details>


### [25] [Analytical Formulation of Autonomous Vehicle Freeway Merging Control with State-Dependent Discharge Rates](https://arxiv.org/abs/2507.16846)
*Qing Tang,Xianbiao Hu*

Main category: cs.RO

TL;DR: 该论文提出了一种自动驾驶车辆多阶段动态汇入控制的分析方法，通过闭式公式推导有效排放率，建立了同时最小化延误和碰撞风险的动态规划模型，在NGSIM数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统排队模型忽略了交叉交通对高速公路汇入点流量的影响，现有基本图无法准确反映拥堵时流量下降的现象，需要建立更准确的动态多阶段汇入控制模型来提升交通效率和安全性。

Method: 首次使用闭式公式分析推导多阶段动态汇入过程中的有效排放率，建立队列长度和交通延误的性能指标，构建碰撞风险定量评估函数，将问题表述为动态规划模型，以汇入位置和速度为决策变量，采用反向归纳求解最小成本方案。

Result: 使用NGSIM数据集验证了推导的有效排放率的准确性，数值实验表明所提出的模型在两个基准算法的对比中表现更优，实现了更高效和更安全的汇入过程。

Conclusion: 该研究成功建立了考虑交叉交通影响的动态多阶段汇入控制模型，通过联合优化延误和碰撞风险，为自动驾驶车辆的高速公路汇入提供了更有效的控制策略，在效率和安全性方面均优于现有方法。

Abstract: The core of the freeway merging control problem lies in dynamic queue
propagation and dissipation linked to merging vehicle behavior. Traditionally,
queuing is modeled through demand-supply interactions with time varying demand
and fixed capacity. However, field observations show flow rates decrease during
congestion at freeway merges due to the impact of intersecting traffic, a
factor overlooked in fundamental diagrams. This manuscript introduces an
analytical approach to characterize and control the dynamic multi-stage merging
of autonomous vehicles, prioritizing traffic efficiency and safety. For the
first time, the effective discharge rate at the merging point, reduced by the
multi-stage dynamic merging process, is analytically derived using a closed
form formulation. Leveraging this expression, performance metrics such as queue
length and traffic delay are derived as the first objective. Additionally, a
crash risk function is established to quantitatively assess potential
collisions during the merging process, serving as the second objective.
Finally, the problem is formulated as a dynamic programming model to jointly
minimize delay and crash risk, with the merging location and speed as decision
variables. Given the terminal state, the ramp vehicle merging task is
formulated as a recursive optimization problem, employing backward induction to
find the minimum cost solution. Numerical experiments using the NGSIM dataset
validate the derived effective discharge rate. The results indicate that the
proposed model outperforms two benchmark algorithms, leading to a more
efficient and safer merging process.

</details>


### [26] [MobileUse: A GUI Agent with Hierarchical Reflection for Autonomous Mobile Operation](https://arxiv.org/abs/2507.16853)
*Ning Li,Xiangmou Qu,Jiamu Zhou,Jun Wang,Muning Wen,Kounianhua Du,Xingyu Lou,Qiuying Peng,Jun Wang,Weinan Zhang*

Main category: cs.RO

TL;DR: 提出了MobileUse，一个用于移动设备GUI自动化的智能代理，通过分层反思架构和主动探索模块解决长期任务执行、错误恢复和冷启动问题，在AndroidWorld和AndroidLab基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在移动场景中面临长期任务执行困难、错误恢复能力不足以及在陌生环境中的冷启动问题，限制了其在真实世界移动设备自动化任务中的应用。

Method: 设计了MobileUse GUI代理，包含两个核心模块：1) 分层反思架构，能够在多个时间尺度上进行自我监控、错误检测和恢复，并采用按需反思策略保持效率；2) 主动探索模块，通过自主规划的探索来丰富代理对环境的理解。

Result: 在AndroidWorld和AndroidLab基准测试中分别达到62.9%和44.2%的成功率，建立了新的最先进性能记录，并发布了可用于物理移动设备自动化任务执行的开箱即用工具包。

Conclusion: MobileUse通过分层反思和主动探索有效解决了移动设备GUI自动化中的关键挑战，在基准测试中取得突破性性能，为实际移动设备自动化应用提供了实用的解决方案。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled the
development of mobile agents that can understand visual inputs and follow user
instructions, unlocking new possibilities for automating complex tasks on
mobile devices. However, applying these models to real-world mobile scenarios
remains a significant challenge due to the long-horizon task execution,
difficulty in error recovery, and the cold-start problem in unfamiliar
environments. To address these challenges, we propose MobileUse, a GUI agent
designed for robust and adaptive mobile task execution. To improve resilience
in long-horizon tasks and dynamic environments, we introduce a hierarchical
reflection architecture that enables the agent to self-monitor, detect, and
recover from errors across multiple temporal scales-ranging from individual
actions to overall task completion-while maintaining efficiency through a
reflection-on-demand strategy. To tackle cold-start issues, we further
introduce a proactive exploration module, which enriches the agent's
understanding of the environment through self-planned exploration. Evaluations
on AndroidWorld and AndroidLab benchmarks demonstrate that MobileUse
establishes new state-of-the-art performance, achieving success rates of 62.9%
and 44.2%, respectively. To facilitate real-world applications, we release an
out-of-the-box toolkit for automated task execution on physical mobile devices,
which is available at https://github.com/MadeAgents/mobile-use.

</details>


### [27] [Leveraging multi-source and heterogeneous signals for fatigue detection](https://arxiv.org/abs/2507.16859)
*Luobin Cui,Yanlai Wu,Tang Ying,Weikai Li*

Main category: cs.RO

TL;DR: 本文提出了一个异构多源疲劳检测框架，能够在传感器受限的真实环境中有效检测疲劳状态，通过利用不同传感器配置的源域知识来提升目标域的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有疲劳检测方法依赖高端传感器和受控环境，在真实世界应用中存在局限性。需要开发一种能够在传感器受限的实际场景中进行有效疲劳监测的方法，同时能够利用来自不同传感器配置环境的知识。

Method: 提出了一个异构多源疲劳检测框架，该框架能够自适应地利用目标域中可用的模态，同时从源域的多样化配置中获益。框架通过跨域知识迁移来处理不同传感器配置之间的差异。

Result: 在真实部署的传感器设置和两个公开数据集上进行的实验表明，该方法具有实用性、鲁棒性和更好的泛化能力，能够在传感器受限的场景中实现有效的疲劳监测。

Conclusion: 该框架为在传感器受限场景中进行有效疲劳监测铺平了实用道路，解决了现有方法在真实世界应用中的局限性问题，为航空、采矿、长途运输等安全关键应用提供了可行的解决方案。

Abstract: Fatigue detection plays a critical role in safety-critical applications such
as aviation, mining, and long-haul transport. However, most existing methods
rely on high-end sensors and controlled environments, limiting their
applicability in real world settings. This paper formally defines a practical
yet underexplored problem setting for real world fatigue detection, where
systems operating with context-appropriate sensors aim to leverage knowledge
from differently instrumented sources including those using impractical sensors
deployed in controlled environments. To tackle this challenge, we propose a
heterogeneous and multi-source fatigue detection framework that adaptively
utilizes the available modalities in the target domain while benefiting from
the diverse configurations present in source domains. Our experiments,
conducted using a realistic field-deployed sensor setup and two publicly
available datasets, demonstrate the practicality, robustness, and improved
generalization of our approach, paving the practical way for effective fatigue
monitoring in sensor-constrained scenarios.

</details>


### [28] [ResKACNNet: A Residual ChebyKAN Network for Inertial Odometry](https://arxiv.org/abs/2507.16865)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Huiru Zheng,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一种基于ResChebyKAN骨干网络和EKSA注意力模块的惯性定位方法，通过切比雪夫多项式建模非线性运动模式，在多个公开数据集上显著降低了轨迹误差


<details>
  <summary>Details</summary>
Motivation: 传统基于CNN的惯性定位方法难以捕获IMU数据中的非线性运动特征和长期依赖关系，限制了定位精度的提升

Method: 提出ResChebyKAN通用骨干网络，利用切比雪夫多项式的非线性逼近能力建模复杂运动模式；引入高效核基自注意力(EKSA)模块捕获上下文信息并增强长期依赖建模

Result: 在RIDI、RoNIN、RNIN-VIO、OxIOD、IMUNet和TLIO等公开数据集上，相比现有基准方法，绝对轨迹误差降低了3.79%到42.32%；实验证明去除加速度数据中的重力分量可显著改善惯性定位性能

Conclusion: 所提出的基于ResChebyKAN和EKSA的惯性定位网络能够有效处理IMU数据的非线性特征和长期依赖，显著提升了惯性定位的精度，为低成本精确定位提供了新的解决方案

Abstract: Inertial Measurement Unit (IMU) has become a key technology for achieving
low-cost and precise positioning. However, traditional CNN-based inertial
positioning methods struggle to capture the nonlinear motion characteristics
and long-term dependencies in IMU data. To address this limitation, we propose
a novel inertial positioning network with a generic backbone called
ResChebyKAN, which leverages the nonlinear approximation capabilities of
Chebyshev polynomials to model complex motion patterns. Additionally, we
introduce an Efficient Kernel-based Self-Attention (EKSA) module to effectively
capture contextual information and enhance long-term dependency modeling.
Experimental results on public datasets (e.g., RIDI, RoNIN, RNIN-VIO, OxIOD,
IMUNet, and TLIO) demonstrate that our method reduces the absolute trajectory
error by 3.79% to 42.32% compared to existing benchmark methods. Furthermore,
we release a preprocessed dataset and empirically show that removing the
gravity component from acceleration data significantly improves inertial
positioning performance.

</details>


### [29] [Multi-agent Reinforcement Learning for Robotized Coral Reef Sample Collection](https://arxiv.org/abs/2507.16941)
*Daniel Correa,Tero Kaarlela,Jose Fuentes,Paulo Padrao,Alain Duran,Leonardo Bobadilla*

Main category: cs.RO

TL;DR: 本文提出了一个强化学习环境，用于开发自主水下机器人珊瑚采样代理，通过软件在环和硬件在环方法，结合数字孪生技术和水下运动捕捉系统，实现了从仿真到现实的零样本迁移策略。


<details>
  <summary>Details</summary>
Motivation: 珊瑚礁保护和研究需要自主水下机器人进行珊瑚采样，这是一项关键但具有挑战性的任务，需要开发能够在复杂水下环境中精确操作的智能控制系统。

Method: 采用强化学习方法，结合软件在环(SIL)和硬件在环(HIL)技术，使用数字孪生在仿真环境中训练AI控制器，并通过水下运动捕捉系统提供实时3D位置和方向反馈，实现数字域和物理域之间的精确同步。

Result: 成功开发了基于强化学习的自主水下机器人控制器，并通过物理实验验证了其有效性，实现了从仿真到现实环境的有效迁移。

Conclusion: 通过结合通用游戏引擎仿真、深度强化学习和实时水下运动捕捉技术，成功实现了有效的零样本仿真到现实迁移策略，为水下机器人珊瑚采样任务提供了创新解决方案。

Abstract: This paper presents a reinforcement learning (RL) environment for developing
an autonomous underwater robotic coral sampling agent, a crucial coral reef
conservation and research task. Using software-in-the-loop (SIL) and
hardware-in-the-loop (HIL), an RL-trained artificial intelligence (AI)
controller is developed using a digital twin (DT) in simulation and
subsequently verified in physical experiments. An underwater motion capture
(MOCAP) system provides real-time 3D position and orientation feedback during
verification testing for precise synchronization between the digital and
physical domains. A key novelty of this approach is the combined use of a
general-purpose game engine for simulation, deep RL, and real-time underwater
motion capture for an effective zero-shot sim-to-real strategy.

</details>


### [30] [RAPTAR: Radar Radiation Pattern Acquisition through Automated Collaborative Robotics](https://arxiv.org/abs/2507.16988)
*Maaz Qureshi,Mohammad Omid Bagheri,Abdelrahman Elbadrawy,William Melek,George Shaker*

Main category: cs.RO

TL;DR: 该研究提出了RAPTAR系统，一个基于协作机器人的便携式自主系统，用于测量集成雷达模块的3D辐射方向图，无需专门的电波暗室设施


<details>
  <summary>Details</summary>
Motivation: 现有探针台技术在片上天线表征方面存在角度覆盖有限、依赖定制硬件、需要频繁手动对准等挑战，且传统测量设置在车辆、无人机、AR/VR头显等真实应用场景中不实用

Method: 采用7自由度Franka协作机器人持有接收探针，在半球空间域内进行无碰撞操作，结合实时运动规划和校准技术，与射频仪器集成进行近场和远场功率测量

Result: 系统校准精度RMS误差低于0.9毫米，角度分辨率可达2.5度，60GHz雷达模块实验扫描与全波电磁仿真真值对比平均绝对误差小于2dB，相比基准方法降低36.5%的平均绝对误差

Conclusion: RAPTAR系统成功实现了高精度、可重复的集成雷达模块3D辐射方向图测量，为多样化实际应用场景中的雷达模块测试提供了实用解决方案

Abstract: Accurate characterization of modern on-chip antennas remains challenging, as
current probe-station techniques offer limited angular coverage, rely on
bespoke hardware, and require frequent manual alignment. This research
introduces RAPTAR (Radiation Pattern Acquisition through Robotic Automation), a
portable, state-of-the-art, and autonomous system based on collaborative
robotics. RAPTAR enables 3D radiation-pattern measurement of integrated radar
modules without dedicated anechoic facilities. The system is designed to
address the challenges of testing radar modules mounted in diverse real-world
configurations, including vehicles, UAVs, AR/VR headsets, and biomedical
devices, where traditional measurement setups are impractical. A
7-degree-of-freedom Franka cobot holds the receiver probe and performs
collision-free manipulation across a hemispherical spatial domain, guided by
real-time motion planning and calibration accuracy with RMS error below 0.9 mm.
The system achieves an angular resolution upto 2.5 degree and integrates
seamlessly with RF instrumentation for near- and far-field power measurements.
Experimental scans of a 60 GHz radar module show a mean absolute error of less
than 2 dB compared to full-wave electromagnetic simulations ground truth.
Benchmarking against baseline method demonstrates 36.5% lower mean absolute
error, highlighting RAPTAR accuracy and repeatability.

</details>


### [31] [Shared Control of Holonomic Wheelchairs through Reinforcement Learning](https://arxiv.org/abs/2507.17055)
*Jannis Bähler,Diego Paez-Granados,Jorge Peña-Queralta*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的智能电动轮椅共享控制方法，能够将用户的2D输入转换为3D运动，在确保安全导航的同时提升用户舒适度并降低认知负担


<details>
  <summary>Details</summary>
Motivation: 现有的全向轮椅共享控制方法往往导致用户体验不直观，未能充分利用全向驱动的潜力，因此需要开发更智能的控制方法来改善用户体验

Method: 采用强化学习方法，在Isaac Gym中训练智能体，将用户的2D输入映射为3D运动输出，比较不同的强化学习架构和奖励函数，并在Gazebo仿真环境中测试

Result: 实现了无碰撞导航，智能调整轮椅朝向，在平滑性方面表现优于或等同于传统非学习方法，成功进行了仿真到真实环境的迁移，首次实现了全向移动平台的强化学习共享控制

Conclusion: 该方法成功提升了全向电动轮椅的用户体验，降低了认知负担，并实现了首个基于强化学习的全向移动平台共享控制的真实世界应用

Abstract: Smart electric wheelchairs can improve user experience by supporting the
driver with shared control. State-of-the-art work showed the potential of
shared control in improving safety in navigation for non-holonomic robots.
However, for holonomic systems, current approaches often lead to unintuitive
behavior for the user and fail to utilize the full potential of omnidirectional
driving. Therefore, we propose a reinforcement learning-based method, which
takes a 2D user input and outputs a 3D motion while ensuring user comfort and
reducing cognitive load on the driver. Our approach is trained in Isaac Gym and
tested in simulation in Gazebo. We compare different RL agent architectures and
reward functions based on metrics considering cognitive load and user comfort.
We show that our method ensures collision-free navigation while smartly
orienting the wheelchair and showing better or competitive smoothness compared
to a previous non-learning-based method. We further perform a sim-to-real
transfer and demonstrate, to the best of our knowledge, the first real-world
implementation of RL-based shared control for an omnidirectional mobility
platform.

</details>


### [32] [Deformable Cluster Manipulation via Whole-Arm Policy Learning](https://arxiv.org/abs/2507.17085)
*Jayadeep Jacob,Wenzheng Zhang,Houston Warren,Paulo Borges,Tirthankar Bandyopadhyay,Fabio Ramos*

Main category: cs.RO

TL;DR: 本文提出了一个结合3D点云和本体感觉触觉指示器的无模型强化学习框架，用于操作可变形物体集群，特别是在电力线清理任务中实现了零样本仿真到现实的策略转移。


<details>
  <summary>Details</summary>
Motivation: 操作可变形物体集群是一个具有广泛适用性的重大挑战，需要接触丰富的全臂交互。现有方法在现实模型合成能力有限、感知不确定性高、缺乏高效的空间抽象等方面存在问题，需要一种新的解决方案来处理这些挑战。

Method: 提出了一个学习无模型策略的新框架，整合两种模态：3D点云和本体感觉触觉指示器，强调具有全身接触感知的操作，超越传统的末端执行器模式。强化学习框架利用分布式状态表示，通过核均值嵌入辅助，实现更好的训练效率和实时推理。此外，还提出了一种新颖的上下文无关遮挡启发式方法来清理目标区域的可变形物体。

Result: 在电力线清理场景中部署该框架，观察到智能体生成了利用多个手臂链节进行去遮挡的创造性策略。实现了零样本仿真到现实的策略转移，使机械臂能够清理具有未知遮挡模式、未见拓扑结构和不确定动力学的真实树枝。

Conclusion: 该框架成功解决了可变形物体集群操作的关键挑战，通过多模态感知和分布式状态表示实现了高效的强化学习训练，并在电力线清理任务中展示了出色的零样本迁移能力，为接触丰富的机器人操作任务提供了新的解决方案。

Abstract: Manipulating clusters of deformable objects presents a substantial challenge
with widespread applicability, but requires contact-rich whole-arm
interactions. A potential solution must address the limited capacity for
realistic model synthesis, high uncertainty in perception, and the lack of
efficient spatial abstractions, among others. We propose a novel framework for
learning model-free policies integrating two modalities: 3D point clouds and
proprioceptive touch indicators, emphasising manipulation with full body
contact awareness, going beyond traditional end-effector modes. Our
reinforcement learning framework leverages a distributional state
representation, aided by kernel mean embeddings, to achieve improved training
efficiency and real-time inference. Furthermore, we propose a novel
context-agnostic occlusion heuristic to clear deformables from a target region
for exposure tasks. We deploy the framework in a power line clearance scenario
and observe that the agent generates creative strategies leveraging multiple
arm links for de-occlusion. Finally, we perform zero-shot sim-to-real policy
transfer, allowing the arm to clear real branches with unknown occlusion
patterns, unseen topology, and uncertain dynamics.

</details>


### [33] [MARSCalib: Multi-robot, Automatic, Robust, Spherical Target-based Extrinsic Calibration in Field and Extraterrestrial Environments](https://arxiv.org/abs/2507.17130)
*Seokhwan Jeong,Hogyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 本文提出了一种基于球形目标的LiDAR-相机外参标定方法，适用于多机器人系统的户外环境，能够处理目标和传感器损坏情况


<details>
  <summary>Details</summary>
Motivation: 现有的LiDAR-相机标定方法在户外环境和多机器人系统中面临挑战，特别是当目标物体和传感器出现损坏时，需要一种鲁棒的标定方法来应对这些实际应用场景

Method: 使用球形目标进行标定，从图像中提取2D椭圆中心，从点云中提取3D球心，然后配对计算变换矩阵。图像处理采用SAM模型分解，设计新算法从损坏球体中提取椭圆并校正透视投影误差；点云处理采用分层加权求和处理噪声点云以准确提取球体

Result: 在多种LiDAR类型（旋转式、固态式、非重复式）和不同相机位置下验证了方法的有效性。球形目标在两种损坏情况下都能被鲁棒检测，性能优于其他目标。在行星测试和野外环境中验证了方法对目标损坏的鲁棒性

Conclusion: 提出的基于球形目标的LiDAR-相机外参标定方法能够在目标和传感器损坏的情况下实现鲁棒标定，适用于多机器人系统的户外环境，为实际应用提供了可靠的解决方案

Abstract: This paper presents a novel spherical target-based LiDAR-camera extrinsic
calibration method designed for outdoor environments with multi-robot systems,
considering both target and sensor corruption. The method extracts the 2D
ellipse center from the image and the 3D sphere center from the pointcloud,
which are then paired to compute the transformation matrix. Specifically, the
image is first decomposed using the Segment Anything Model (SAM). Then, a novel
algorithm extracts an ellipse from a potentially corrupted sphere, and the
extracted center of ellipse is corrected for errors caused by the perspective
projection model. For the LiDAR pointcloud, points on the sphere tend to be
highly noisy due to the absence of flat regions. To accurately extract the
sphere from these noisy measurements, we apply a hierarchical weighted sum to
the accumulated pointcloud. Through experiments, we demonstrated that the
sphere can be robustly detected even under both types of corruption,
outperforming other targets. We evaluated our method using three different
types of LiDARs (spinning, solid-state, and non-repetitive) with cameras
positioned in three different locations. Furthermore, we validated the
robustness of our method to target corruption by experimenting with spheres
subjected to various types of degradation. These experiments were conducted in
both a planetary test and a field environment. Our code is available at
https://github.com/sparolab/MARSCalib.

</details>


### [34] [Dynamic Modeling and Dimensional Optimization of Legged Mechanisms for Construction Robot](https://arxiv.org/abs/2507.17132)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文针对建筑机器人腿部结构进行设计和优化，基于蚂蚁腿部构型设计机器人腿部结构，提出新型结构优化方法，通过拉格朗日方法建立动力学模型并优化几何参数，实现峰值关节扭矩和能耗降低超过20%，为重载高性能建筑机器人设计提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 建筑行业快速发展带来的恶劣工作环境、高强度高风险任务和劳动力短缺问题日益突出，这推动了对低能耗、高机动性和高载荷能力建筑机器人的更高需求。

Method: 基于自然界蚂蚁的腿部构型设计机器人腿部结构；提出新型结构优化方法；使用拉格朗日方法建立腿部动力学模型；结合动力学模型和腿部运动轨迹，制定多个动态评估指标；对各腿段几何参数进行综合优化研究；使用ADAMS进行动态仿真实验验证。

Result: 优化后的腿部结构使峰值关节扭矩和能耗降低超过20%；ADAMS动态仿真实验结果显示优化后各关节驱动功率显著降低，验证了所提策略的有效性和合理性。

Conclusion: 本研究为重载高性能建筑机器人的设计提供了理论基础和技术支持，所提出的仿生设计和优化方法能够有效改善建筑机器人的动态性能、降低能耗并增强承载能力。

Abstract: With the rapid development of the construction industry, issues such as harsh
working environments, high-intensity and high-risk tasks, and labor shortages
have become increasingly prominent. This drives higher demands for construction
robots in terms of low energy consumption, high mobility, and high load
capacity. This paper focuses on the design and optimization of leg structures
for construction robots, aiming to improve their dynamic performance, reduce
energy consumption, and enhance load-bearing capabilities. Firstly, based on
the leg configuration of ants in nature, we design a structure for the robot's
leg. Secondly, we propose a novel structural optimization method. Using the
Lagrangian approach, a dynamic model of the leg was established. Combining the
dynamic model with the leg's motion trajectory, we formulated multiple dynamic
evaluation metrics and conducted a comprehensive optimization study on the
geometric parameters of each leg segment. The results show that the optimized
leg structure reduces peak joint torques and energy consumption by over 20%.
Finally, dynamic simulation experiments were conducted using ADAMS. The results
demonstrate a significant reduction in the driving power of each joint after
optimization, validating the effectiveness and rationality of the proposed
strategy. This study provides a theoretical foundation and technical support
for the design of heavy-load, high-performance construction robots.

</details>


### [35] [Dynamic Parameter Identification of a Curtain Wall Installation Robotic Arm](https://arxiv.org/abs/2507.17136)
*Xiao Liu,Yunxiao Cheng,Weijun Wang,Tianlun Huang,Wei Feng*

Main category: cs.RO

TL;DR: 本文设计了一个液压驱动的幕墙安装机器人臂，并提出了分层递进的动态参数识别方法，通过建立D-H模型和Stribeck摩擦模型，实现了高精度的动态参数识别，理论与实测关节扭矩的残差标准差低于0.4 Nm。


<details>
  <summary>Details</summary>
Motivation: 传统建筑施工方法无法满足现代对效率和质量的需求，幕墙安装作为建筑项目的关键组成部分，需要提高智能化水平。现有方法在动态参数识别方面存在精度不足的问题。

Method: 建立基于实测机器人臂结构参数的D-H模型，集成液压缸动力学构建Stribeck摩擦模型驱动的复合参数系统；设计高信噪比的液压缸位移激励信号，结合傅里叶级数构建满足关节约束的最优激励轨迹；提出分层递进参数识别策略，采用最小二乘估计分别识别和联合标定液压缸和机器人臂的动态参数。

Result: 在机器人臂平台上的实验验证显示，理论与实测关节扭矩之间的残差标准差低于0.4 Nm，实现了液压驱动幕墙安装机器人臂的高精度动态参数识别，获得了各关节的Stribeck模型曲线。

Conclusion: 该研究成功实现了液压驱动幕墙安装机器人臂的高精度动态参数识别，显著提升了幕墙安装作业的智能化水平，为建筑行业的自动化和智能化发展提供了重要技术支撑。

Abstract: In the construction industry, traditional methods fail to meet the modern
demands for efficiency and quality. The curtain wall installation is a critical
component of construction projects. We design a hydraulically driven robotic
arm for curtain wall installation and a dynamic parameter identification
method. We establish a Denavit-Hartenberg (D-H) model based on measured robotic
arm structural parameters and integrate hydraulic cylinder dynamics to
construct a composite parametric system driven by a Stribeck friction model. By
designing high-signal-to-noise ratio displacement excitation signals for
hydraulic cylinders and combining Fourier series to construct optimal
excitation trajectories that satisfy joint constraints, this method effectively
excites the characteristics of each parameter in the minimal parameter set of
the dynamic model of the robotic arm. On this basis, a hierarchical progressive
parameter identification strategy is proposed: least squares estimation is
employed to separately identify and jointly calibrate the dynamic parameters of
both the hydraulic cylinder and the robotic arm, yielding Stribeck model curves
for each joint. Experimental validation on a robotic arm platform demonstrates
residual standard deviations below 0.4 Nm between theoretical and measured
joint torques, confirming high-precision dynamic parameter identification for
the hydraulic-driven curtain wall installation robotic arm. This significantly
contributes to enhancing the intelligence level of curtain wall installation
operations.

</details>


### [36] [Multi-Objective Trajectory Planning for a Robotic Arm in Curtain Wall Installation](https://arxiv.org/abs/2507.17140)
*Xiao Liu,Yunxiao Cheng,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 针对建筑行业劳动力短缺和成本上升问题，研究者提出了一种用于幕墙安装的机械臂多目标轨迹优化方法，设计了集成串联、并联和折叠臂元素的机械臂，并开发了NSGA-III-FO算法来平衡多目标约束，实验验证了该方法的有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 建筑行业面临劳动力短缺和成本上升的挑战，传统单目标轨迹优化方法难以满足复杂建筑环境中施工机器人的多样化需求，因此需要开发能够在复杂环境中高效准确执行任务的建筑机器人多目标轨迹优化方法。

Method: 设计了集成串联、并联和折叠臂元素的幕墙安装机械臂，考虑其物理特性和运动特征；提出了NSGA-III-FO算法（带有聚焦算子的NSGA-III），融合聚焦算子筛选机制来加速算法向帕累托前沿收敛，有效平衡建筑机器人的多目标约束。

Result: 在DTLZ3和WFG3测试函数上进行的十次连续试验中，NSGA-III-FO算法相比NSGA-III、MOEA/D和MSOPS-II算法表现出明显更好的收敛效率；在设计的机械臂平台上进行的两组实验证实了该算法在解决幕墙安装任务多目标轨迹规划问题方面的效率和实用性。

Conclusion: 研究成功开发了用于幕墙安装的建筑机器人多目标轨迹优化方法，NSGA-III-FO算法在理论测试和实际应用中都表现出优异的性能，为建筑行业自动化和效率提升提供了有效的技术解决方案。

Abstract: In the context of labor shortages and rising costs, construction robots are
regarded as the key to revolutionizing traditional construction methods and
improving efficiency and quality in the construction industry. In order to
ensure that construction robots can perform tasks efficiently and accurately in
complex construction environments, traditional single-objective trajectory
optimization methods are difficult to meet the complex requirements of the
changing construction environment. Therefore, we propose a multi-objective
trajectory optimization for the robotic arm used in the curtain wall
installation. First, we design a robotic arm for curtain wall installation,
integrating serial, parallel, and folding arm elements, while considering its
physical properties and motion characteristics. In addition, this paper
proposes an NSGA-III-FO algorithm (NSGA-III with Focused Operator, NSGA-III-FO)
that incorporates a focus operator screening mechanism to accelerate the
convergence of the algorithm towards the Pareto front, thereby effectively
balancing the multi-objective constraints of construction robots. The proposed
algorithm is tested against NSGA-III, MOEA/D, and MSOPS-II in ten consecutive
trials on the DTLZ3 and WFG3 test functions, showing significantly better
convergence efficiency than the other algorithms. Finally, we conduct two sets
of experiments on the designed robotic arm platform, which confirm the
efficiency and practicality of the NSGA-III-FO algorithm in solving
multi-objective trajectory planning problems for curtain wall installation
tasks.

</details>


### [37] [Towards Human-level Intelligence via Human-like Whole-Body Manipulation](https://arxiv.org/abs/2507.17141)
*Guang Gao,Jianan Wang,Jinbo Zuo,Junnan Jiang,Jingfan Zhang,Xianwen Zeng,Yuejiang Zhu,Lianyang Ma,Ke Chen,Minhua Sheng,Ruirui Zhang,Zhaohui An*

Main category: cs.RO

TL;DR: Astribot Suite是一个机器人学习套件，通过安全的机器人硬件、直观的全身遥操作接口和从人类演示中学习的算法，实现了通用日常任务的全身操作能力


<details>
  <summary>Details</summary>
Motivation: 构建通用智能机器人是机器人学的基本目标，需要通过模仿人类进化轨迹来实现——通过与环境的持续交互学习，早期进展由模仿人类行为驱动。这需要解决三个核心挑战：设计安全的人类级别物理能力硬件、开发直观可扩展的全身遥操作接口、创建能从人类演示中学习全身视觉运动策略的算法

Method: 提出Astribot Suite统一框架，整合了三个关键组件：(1)具有人类级别物理能力的安全机器人硬件设计；(2)用于数据收集的直观且可扩展的全身遥操作接口；(3)能够从人类演示中学习全身视觉运动策略的算法

Result: 系统在需要全身协调、广泛可达性、人类级别灵巧性和敏捷性的各种活动中展现了有效性，成功完成了跨多样化环境的通用日常任务

Conclusion: Astribot在机器人本体、遥操作接口和学习管道方面的整合标志着向真实世界通用全身机器人操作迈出的重要一步，为下一代智能机器人奠定了基础

Abstract: Building general-purpose intelligent robots has long been a fundamental goal
of robotics. A promising approach is to mirror the evolutionary trajectory of
humans: learning through continuous interaction with the environment, with
early progress driven by the imitation of human behaviors. Achieving this goal
presents three core challenges: (1) designing safe robotic hardware with
human-level physical capabilities; (2) developing an intuitive and scalable
whole-body teleoperation interface for data collection; and (3) creating
algorithms capable of learning whole-body visuomotor policies from human
demonstrations. To address these challenges in a unified framework, we propose
Astribot Suite, a robot learning suite for whole-body manipulation aimed at
general daily tasks across diverse environments. We demonstrate the
effectiveness of our system on a wide range of activities that require
whole-body coordination, extensive reachability, human-level dexterity, and
agility. Our results show that Astribot's cohesive integration of embodiment,
teleoperation interface, and learning pipeline marks a significant step towards
real-world, general-purpose whole-body robotic manipulation, laying the
groundwork for the next generation of intelligent robots.

</details>


### [38] [Falconry-like palm landing by a flapping-wing drone based on the human gesture interaction and distance-aware flight planning](https://arxiv.org/abs/2507.17144)
*Kazuki Numazato,Keiichiro Kan,Masaki Kitagawa,Yunong Li,Johannes Kubel,Moju Zhao*

Main category: cs.RO

TL;DR: 本研究首次实现了扑翼无人机与人类的接触式交互，提出了一种仿鹰猎人的交互系统，使扑翼无人机能够安全地降落在人类手掌上。


<details>
  <summary>Details</summary>
Motivation: 扑翼无人机具有低噪音和柔性翼等人类友好特性，适合人机交互，但缺乏实际交互研究。受鹰猎人引导猛禽降落在手臂上的启发，将人体视为动态着陆平台，可应用于拥挤或空间受限的环境。

Method: 设计了一种仿鹰猎人的交互系统，开发了考虑人类安全物理和心理因素的轨迹规划方法，包括无人机速度和与用户距离等参数。使用商用扑翼平台实现运动规划并进行实验评估。

Result: 实验结果表明该方法能够实现安全、平滑的手掌着陆交互。成功验证了扑翼无人机在人类手掌上的着陆性能和安全性。

Conclusion: 首次实现了扑翼无人机与人类的接触式交互，证明了仿鹰猎人交互系统的可行性，为人机交互领域开辟了新的研究方向。

Abstract: Flapping-wing drones have attracted significant attention due to their
biomimetic flight. They are considered more human-friendly due to their
characteristics such as low noise and flexible wings, making them suitable for
human-drone interactions. However, few studies have explored the practical
interaction between humans and flapping-wing drones. On establishing a physical
interaction system with flapping-wing drones, we can acquire inspirations from
falconers who guide birds of prey to land on their arms. This interaction
interprets the human body as a dynamic landing platform, which can be utilized
in various scenarios such as crowded or spatially constrained environments.
Thus, in this study, we propose a falconry-like interaction system in which a
flapping-wing drone performs a palm landing motion on a human hand. To achieve
a safe approach toward humans, we design a trajectory planning method that
considers both physical and psychological factors of the human safety such as
the drone's velocity and distance from the user. We use a commercial flapping
platform with our implemented motion planning and conduct experiments to
evaluate the palm landing performance and safety. The results demonstrate that
our approach enables safe and smooth hand landing interactions. To the best of
our knowledge, it is the first time to achieve a contact-based interaction
between flapping-wing drones and humans.

</details>


### [39] [JAM: Keypoint-Guided Joint Prediction after Classification-Aware Marginal Proposal for Multi-Agent Interaction](https://arxiv.org/abs/2507.17152)
*Fangze Lin,Ying He,Fei Yu,Hong Zhang*

Main category: cs.RO

TL;DR: 本文提出了JAM框架，通过两阶段预测（边际预测+联合预测）和关键点引导来改善自动驾驶中多智能体交互轨迹预测的低概率模式生成质量问题


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体联合预测方法在生成低概率模式时质量较差，难以准确预测道路参与者的未来运动轨迹，这对自动驾驶的安全性构成挑战

Method: 提出JAM（keypoint-guided joint prediction after classification-aware marginal proposal）两阶段框架：第一阶段进行边际预测，通过轨迹类型分类鼓励模型学习所有类别轨迹；第二阶段进行联合预测，利用场景上下文和边际提议学习最终联合分布，并引入关键路径点指导联合预测模块

Result: 在Waymo Open Motion数据集上进行了广泛实验，JAM方法取得了竞争性能，在框架比较实验中超越了其他预测框架，在交互轨迹预测任务上达到了最先进的性能

Conclusion: JAM框架通过两阶段设计和关键点引导有效解决了多智能体联合预测中低概率模式生成质量差的问题，在交互轨迹预测任务上取得了最优性能，为自动驾驶中的运动预测提供了有效解决方案

Abstract: Predicting the future motion of road participants is a critical task in
autonomous driving. In this work, we address the challenge of low-quality
generation of low-probability modes in multi-agent joint prediction. To tackle
this issue, we propose a two-stage multi-agent interactive prediction framework
named \textit{keypoint-guided joint prediction after classification-aware
marginal proposal} (JAM). The first stage is modeled as a marginal prediction
process, which classifies queries by trajectory type to encourage the model to
learn all categories of trajectories, providing comprehensive mode information
for the joint prediction module. The second stage is modeled as a joint
prediction process, which takes the scene context and the marginal proposals
from the first stage as inputs to learn the final joint distribution. We
explicitly introduce key waypoints to guide the joint prediction module in
better capturing and leveraging the critical information from the initial
predicted trajectories. We conduct extensive experiments on the real-world
Waymo Open Motion Dataset interactive prediction benchmark. The results show
that our approach achieves competitive performance. In particular, in the
framework comparison experiments, the proposed JAM outperforms other prediction
frameworks and achieves state-of-the-art performance in interactive trajectory
prediction. The code is available at https://github.com/LinFunster/JAM to
facilitate future research.

</details>


### [40] [Reconfigurable Tendon-Driven Robots: Eliminating Inter-segmental Coupling via Independently Lockable Joints](https://arxiv.org/abs/2507.17163)
*Botao Lin,Shuang Song,Jiaole Wang*

Main category: cs.RO

TL;DR: 本文提出了一种可重构拉绳驱动机器人（RTR），通过创新的可锁定关节设计，解决了传统拉绳驱动机器人的段间耦合问题，仅用6个电机实现了7关节机器人的复杂环境操作。


<details>
  <summary>Details</summary>
Motivation: 传统拉绳驱动机器人虽然具有大工作空间和良好机动性，但增加机器人段数会导致段间耦合加剧，需要更复杂的模型和更多电机来实现精确控制，这限制了其实际应用。

Method: 设计了配备创新可锁定关节的可重构拉绳驱动机器人。每个关节的状态（锁定/自由）可通过一对拮抗拉绳独立控制，结构设计无需持续供电维持状态。操作员可选择性驱动目标机器人段，从根本上消除段间耦合。

Result: 通过仿真比较了RTR与传统TDR的工作空间，验证了RTR的优势。建立了RTR的运动学和静力学模型并进行了验证实验。使用7关节RTR原型进行了演示，证明其在复杂环境中的可重构性和运动能力，仅需6个电机的驱动包。

Conclusion: 可重构拉绳驱动机器人通过可锁定关节设计成功解决了传统TDR的段间耦合问题，避免了复杂的段间协调控制需求，在保持大工作空间和机动性的同时显著简化了控制系统，为在复杂环境中的应用提供了有效解决方案。

Abstract: With a slender redundant body, the tendon-driven robot (TDR) has a large
workspace and great maneuverability while working in complex environments. TDR
comprises multiple independently controlled robot segments, each with a set of
driving tendons. While increasing the number of robot segments enhances
dexterity and expands the workspace, this structural expansion also introduces
intensified inter-segmental coupling. Therefore, achieving precise TDR control
requires more complex models and additional motors. This paper presents a
reconfigurable tendon-driven robot (RTR) equipped with innovative lockable
joints. Each joint's state (locked/free) can be individually controlled through
a pair of antagonistic tendons, and its structure eliminates the need for a
continuous power supply to maintain the state. Operators can selectively
actuate the targeted robot segments, and this scheme fundamentally eliminates
the inter-segmental coupling, thereby avoiding the requirement for complex
coordinated control between segments. The workspace of RTR has been simulated
and compared with traditional TDRs' workspace, and RTR's advantages are further
revealed. The kinematics and statics models of the RTR have been derived and
validation experiments have been conducted. Demonstrations have been performed
using a seven-joint RTR prototype to show its reconfigurability and moving
ability in complex environments with an actuator pack comprising only six
motors.

</details>


### [41] [FAST-Calib: LiDAR-Camera Extrinsic Calibration in One Second](https://arxiv.org/abs/2507.17210)
*Chunran Zheng,Fu Zhang*

Main category: cs.RO

TL;DR: 本文提出了FAST-Calib，一种基于定制3D标定板的快速用户友好的激光雷达-相机外参标定工具，支持机械式和固态激光雷达，具有高精度和快速处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的激光雷达-相机外参标定方法存在精度不足、处理速度慢、对不同类型激光雷达适应性差等问题，需要开发一种快速、准确、用户友好的自动化标定工具。

Method: 提出FAST-Calib标定方法，基于定制3D标定板，采用与激光雷达扫描模式无关的高效可靠边缘提取算法，通过椭圆拟合补偿激光雷达光斑扩散引起的边缘膨胀伪影，支持多场景联合优化。

Result: 在三种激光雷达模型(Ouster、Avia、Mid360)上验证，点到点配准误差始终低于6.5mm，总处理时间少于0.7秒，相比现有方法展现出更优的精度和鲁棒性。

Conclusion: FAST-Calib提供了一个高效、准确且基于标定板的自动化标定流程，代码和数据集已开源，为机器人社区提供了实用的激光雷达-相机标定解决方案。

Abstract: This paper proposes FAST-Calib, a fast and user-friendly LiDAR-camera
extrinsic calibration tool based on a custom-made 3D target. FAST-Calib
supports both mechanical and solid-state LiDARs by leveraging an efficient and
reliable edge extraction algorithm that is agnostic to LiDAR scan patterns. It
also compensates for edge dilation artifacts caused by LiDAR spot spread
through ellipse fitting, and supports joint optimization across multiple
scenes. We validate FAST-Calib on three LiDAR models (Ouster, Avia, and
Mid360), each paired with a wide-angle camera. Experimental results demonstrate
superior accuracy and robustness compared to existing methods. With
point-to-point registration errors consistently below 6.5mm and total
processing time under 0.7s, FAST-Calib provides an efficient, accurate, and
target-based automatic calibration pipeline. We have open-sourced our code and
dataset on GitHub to benefit the robotics community.

</details>


### [42] [Optimizing Delivery Logistics: Enhancing Speed and Safety with Drone Technology](https://arxiv.org/abs/2507.17253)
*Maharshi Shastri,Ujjval Shrivastav*

Main category: cs.RO

TL;DR: 本研究开发了一个AI集成的无人机配送系统，采用YOLOv4 Tiny进行目标检测，集成GPS导航和实时通信模块，通过机器学习技术优化路线并提高配送效率，同时解决了电池效率、监管合规和安全等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 随着对快速且经济高效的最后一公里配送解决方案需求不断增长，需要开发先进的无人机物流系统来满足现代配送要求，提高配送效率并降低成本。

Method: 采用YOLOv4 Tiny轻量级模型进行目标检测，使用NEO 6M GPS模块进行导航定位，集成A7670 SIM模块实现实时通信，通过机器学习技术进行路线优化，结合IoT设备和加密协议解决安全问题，并实现面部识别进行收件人身份验证。

Result: 初步研究显示相比传统地面物流配送时间有所改善，通过面部识别实现了高精度的收件人身份验证，系统架构设计完成并进行了初步仿真，目前正在获取实验结果、仿真基准和部署统计数据。

Conclusion: 成功设计了AI集成无人机配送系统的架构，解决了电池效率、监管合规等关键技术挑战，系统在配送效率和安全性方面表现良好，符合FAA、EASA和DGCA等监管标准，但需要进一步的实验验证和全面分析以完善系统性能。

Abstract: The increasing demand for fast and cost effective last mile delivery
solutions has catalyzed significant advancements in drone based logistics. This
research describes the development of an AI integrated drone delivery system,
focusing on route optimization, object detection, secure package handling, and
real time tracking. The proposed system leverages YOLOv4 Tiny for object
detection, the NEO 6M GPS module for navigation, and the A7670 SIM module for
real time communication. A comparative analysis of lightweight AI models and
hardware components is conducted to determine the optimal configuration for
real time UAV based delivery. Key challenges including battery efficiency,
regulatory compliance, and security considerations are addressed through the
integration of machine learning techniques, IoT devices, and encryption
protocols. Preliminary studies demonstrate improvement in delivery time
compared to conventional ground based logistics, along with high accuracy
recipient authentication through facial recognition. The study also discusses
ethical implications and societal acceptance of drone deliveries, ensuring
compliance with FAA, EASA and DGCA regulatory standards. Note: This paper
presents the architecture, design, and preliminary simulation results of the
proposed system. Experimental results, simulation benchmarks, and deployment
statistics are currently being acquired. A comprehensive analysis will be
included in the extended version of this work.

</details>


### [43] [IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception](https://arxiv.org/abs/2507.17445)
*Haichuan Li,Changda Tian,Panos Trahanias,Tomi Westerlund*

Main category: cs.RO

TL;DR: IndoorBEV提出了一种基于掩码的鸟瞰视图方法，用于室内移动机器人的3D点云目标检测，通过将3D场景投影到2D BEV网格来处理遮挡问题，并使用查询解码器预测目标类别和实例掩码，有效捕获静态和动态物体的足迹。


<details>
  <summary>Details</summary>
Motivation: 传统边界框方法在复杂室内3D点云环境中检测多样化目标时存在局限性，特别是在处理不同物体形状、杂乱环境以及静态和动态元素共存的场景时表现不佳，需要一种更鲁棒的方法来解决这些挑战。

Method: 提出IndoorBEV方法，将3D场景投影到2D鸟瞰视图网格中，使用轴紧凑编码器和基于窗口的主干网络从BEV地图中提取丰富的空间特征，然后通过基于查询的解码器头使用学习的目标查询同时预测BEV空间中的目标类别和实例掩码。

Result: 在包含多样化目标类别（包括静态物体和机器人等动态元素）的自定义室内数据集上验证了IndoorBEV的有效性，展示了其在鲁棒室内场景理解方面的潜力，生成的2D BEV结果可直接用于导航、运动预测和规划等下游机器人任务。

Conclusion: IndoorBEV通过基于掩码的鸟瞰视图方法有效解决了室内复杂环境中的目标检测问题，其掩码中心的表述方式能够有效捕获不同形状的静态和动态物体足迹，为边界框回归提供了鲁棒的替代方案，在室内场景理解任务中表现出良好的性能。

Abstract: Detecting diverse objects within complex indoor 3D point clouds presents
significant challenges for robotic perception, particularly with varied object
shapes, clutter, and the co-existence of static and dynamic elements where
traditional bounding box methods falter. To address these limitations, we
propose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor
mobile robots.
  In a BEV method, a 3D scene is projected into a 2D BEV grid which handles
naturally occlusions and provides a consistent top-down view aiding to
distinguish static obstacles from dynamic agents. The obtained 2D BEV results
is directly usable to downstream robotic tasks like navigation, motion
prediction, and planning. Our architecture utilizes an axis compact encoder and
a window-based backbone to extract rich spatial features from this BEV map. A
query-based decoder head then employs learned object queries to concurrently
predict object classes and instance masks in the BEV space. This mask-centric
formulation effectively captures the footprint of both static and dynamic
objects regardless of their shape, offering a robust alternative to bounding
box regression. We demonstrate the effectiveness of IndoorBEV on a custom
indoor dataset featuring diverse object classes including static objects
  and dynamic elements like robots and miscellaneous items, showcasing its
potential for robust indoor scene understanding.

</details>


### [44] [Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning](https://arxiv.org/abs/2507.17275)
*Po-Yen Wu,Cheng-Yu Kuo,Yuki Kadokawa,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 本文提出了一个强化学习框架，通过将工具寿命作为策略优化因素，训练机器人学习既能完成任务又能延长工具使用寿命的策略，在仿真和真实环境中都取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 在不可达环境中，机器人需要使用通用工具完成任务，但这些工具缺乏预定义的使用策略，且寿命对使用方式高度敏感。如何让机器人学会既能完成任务又能延长工具寿命的使用策略是一个基本挑战。

Method: 提出了一个将工具寿命纳入策略优化的强化学习框架。使用有限元分析(FEA)和矿工法则基于累积应力估算剩余使用寿命(RUL)，将RUL整合到RL奖励中指导策略学习。引入自适应奖励归一化(ARN)机制，根据估计的RUL动态调整奖励缩放，确保学习信号稳定。

Result: 在仿真和真实世界的工具使用任务(包括物体移动和开门任务)中验证了方法的有效性。学习到的策略能够持续延长工具寿命(仿真中最高达8.01倍)，并能有效迁移到真实世界环境中。

Conclusion: 该方法成功解决了机器人在使用通用工具时如何平衡任务完成和工具寿命延长的问题，证明了学习寿命导向工具使用策略的实用价值，为机器人在复杂环境中的工具使用提供了新的解决方案。

Abstract: In inaccessible environments with uncertain task demands, robots often rely
on general-purpose tools that lack predefined usage strategies. These tools are
not tailored for particular operations, making their longevity highly sensitive
to how they are used. This creates a fundamental challenge: how can a robot
learn a tool-use policy that both completes the task and prolongs the tool's
lifespan? In this work, we address this challenge by introducing a
reinforcement learning (RL) framework that incorporates tool lifespan as a
factor during policy optimization. Our framework leverages Finite Element
Analysis (FEA) and Miner's Rule to estimate Remaining Useful Life (RUL) based
on accumulated stress, and integrates the RUL into the RL reward to guide
policy learning toward lifespan-guided behavior. To handle the fact that RUL
can only be estimated after task execution, we introduce an Adaptive Reward
Normalization (ARN) mechanism that dynamically adjusts reward scaling based on
estimated RULs, ensuring stable learning signals. We validate our method across
simulated and real-world tool use tasks, including Object-Moving and
Door-Opening with multiple general-purpose tools. The learned policies
consistently prolong tool lifespan (up to 8.01x in simulation) and transfer
effectively to real-world settings, demonstrating the practical value of
learning lifespan-guided tool use strategies.

</details>


### [45] [VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback](https://arxiv.org/abs/2507.17294)
*Jianxin Bi,Kevin Yuchen Ma,Ce Hao,Mike Zheng Shou,Harold Soh*

Main category: cs.RO

TL;DR: VLA-Touch是一种在不微调基础VLA模型的情况下，通过双层次触觉反馈集成来增强通用机器人策略的方法，包括用于高级任务规划的触觉-语言模型和用于接触丰富操作的基于扩散的控制器。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作(VLA)模型缺乏解释和使用触觉信号的能力，这限制了它们在接触丰富任务中的有效性。由于缺少大型多模态数据集，将触觉反馈整合到这些系统中具有挑战性。

Method: 提出VLA-Touch方法，包含两个关键创新：(1)利用预训练触觉-语言模型为高级任务规划提供语义触觉反馈的管道；(2)基于扩散的控制器，用触觉信号细化VLA生成的动作以进行接触丰富的操作。该方法无需微调基础VLA模型。

Result: 通过真实世界实验证明，双层次触觉反馈集成提高了任务规划效率，同时增强了执行精度。代码已开源。

Conclusion: VLA-Touch成功实现了在不修改基础VLA模型的前提下整合触觉反馈，通过高级规划和低级控制的双层次方法有效提升了机器人在接触丰富任务中的表现。

Abstract: Tactile feedback is generally recognized to be crucial for effective
interaction with the physical world. However, state-of-the-art
Vision-Language-Action (VLA) models lack the ability to interpret and use
tactile signals, limiting their effectiveness in contact-rich tasks.
Incorporating tactile feedback into these systems is challenging due to the
absence of large multi-modal datasets. We present VLA-Touch, an approach that
enhances generalist robot policies with tactile sensing \emph{without
fine-tuning} the base VLA. Our method introduces two key innovations: (1) a
pipeline that leverages a pretrained tactile-language model that provides
semantic tactile feedback for high-level task planning, and (2) a
diffusion-based controller that refines VLA-generated actions with tactile
signals for contact-rich manipulation. Through real-world experiments, we
demonstrate that our dual-level integration of tactile feedback improves task
planning efficiency while enhancing execution precision. Code is open-sourced
at \href{https://github.com/jxbi1010/VLA-Touch}{this URL}.

</details>


### [46] [HuNavSim 2.0](https://arxiv.org/abs/2507.17317)
*Miguel Escudero-Jiménez,Noé Pérez-Higueras,Andrés Martínez-Silva,Fernando Caballero,Luis Merino*

Main category: cs.RO

TL;DR: 本文介绍了人类导航仿真器(HuNavSim)的新版本，这是一个开源工具，用于在移动机器人场景中仿真不同的人机导航行为，基于ROS 2框架开发，可与Gazebo或NVidia Isaac Sim等机器人仿真器配合使用。


<details>
  <summary>Details</summary>
Motivation: 为了促进人机感知机器人导航系统在仿真环境中的开发和评估，需要一个能够模拟复杂真实人类行为的仿真工具。

Method: 开发了基于ROS 2框架的人类导航仿真器，可与多种知名机器人仿真器（如Gazebo和NVidia Isaac Sim）集成使用，通过行为树组合扩展的动作和条件集来构建复杂且真实的人类行为。

Result: 新版本改进了多项功能并添加了新特性，特别是扩展了可在行为树中组合的动作和条件集，能够构建更加复杂和真实的人类行为模式。

Conclusion: HuNavSim新版本为人机感知机器人导航系统的仿真开发提供了更强大的工具支持，通过改进的行为树系统能够更好地模拟真实的人类导航行为。

Abstract: This work presents a new iteration of the Human Navigation Simulator
(HuNavSim), a novel open-source tool for the simulation of different
human-agent navigation behaviors in scenarios with mobile robots. The tool,
programmed under the ROS 2 framework, can be used together with different
well-known robotics simulators such as Gazebo or NVidia Isaac Sim. The main
goal is to facilitate the development and evaluation of human-aware robot
navigation systems in simulation. In this new version, several features have
been improved and new ones added, such as the extended set of actions and
conditions that can be combined in Behavior Trees to compound complex and
realistic human behaviors.

</details>


### [47] [Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks](https://arxiv.org/abs/2507.17338)
*Corrado Pezzato,Ozan Çatal,Toon Van de Maele,Riddhi J. Pitliya,Tim Verbelen*

Main category: cs.RO

TL;DR: 研究团队提出了一种分层主动推理架构，用于机器人复杂长期任务控制，在Habitat基准测试中超越了现有最佳方法，首次证明主动推理可以扩展到现代机器人基准的复杂性。


<details>
  <summary>Details</summary>
Motivation: 尽管主动推理在机器人控制领域引起了越来越多的关注，但其在复杂、长期任务中的应用仍未得到测试，需要解决这一空白。

Method: 引入了一个完全分层的主动推理架构，结合高级主动推理模型来选择离散技能，并通过全身主动推理控制器实现这些技能，形成统一的方法框架。

Result: 在Habitat移动操作基准测试中，该方法在三个长期任务上都超越了最先进的基线方法，实现了灵活的技能组合、在线适应性和任务失败恢复能力。

Conclusion: 首次证明了主动推理可以扩展到现代机器人基准的复杂性，为目标导向行为在现实机器人环境中的应用提供了有效解决方案，且无需离线训练。

Abstract: Despite growing interest in active inference for robotic control, its
application to complex, long-horizon tasks remains untested. We address this
gap by introducing a fully hierarchical active inference architecture for
goal-directed behavior in realistic robotic settings. Our model combines a
high-level active inference model that selects among discrete skills realized
via a whole-body active inference controller. This unified approach enables
flexible skill composition, online adaptability, and recovery from task
failures without requiring offline training. Evaluated on the Habitat Benchmark
for mobile manipulation, our method outperforms state-of-the-art baselines
across the three long-horizon tasks, demonstrating for the first time that
active inference can scale to the complexity of modern robotics benchmarks.

</details>


### [48] [An Exploratory Study on Human-Robot Interaction using Semantics-based Situational Awareness](https://arxiv.org/abs/2507.17376)
*Tianshu Ruan,Aniketh Ramesh,Rustam Stolkin,Manolis Chiou*

Main category: cs.RO

TL;DR: 本文研究了高级语义信息对人机团队协作和人机交互的影响，通过灾难响应任务实验发现，语义信息能够减轻操作员工作负荷、提高情境感知信任度并缩短自主性切换反应时间。


<details>
  <summary>Details</summary>
Motivation: 在移动机器人部署的人机团队协作中，高级语义信息的作用尚未得到充分探索。特别是在灾难响应等复杂任务中，操作员面临高工作负荷和压力，需要在机器人和其他任务间快速切换注意力，难以快速建立情境感知能力。

Method: 采用基于语义的框架，在模拟灾难响应任务中评估环境的高级语义信息（即环境中存在多少语义信息）。通过实验测试语义信息对人机团队协作效果的影响，包括工作负荷、情境感知信任度和自主性切换反应时间等指标。

Result: 实验结果表明，高级语义信息能够：1）减轻人类操作员的感知工作负荷；2）提高操作员对情境感知的信任度；3）帮助缩短在需要时切换自主性级别的反应时间。此外，对系统信任度较高的参与者更倾向于在高级语义信息的鼓励下使用远程操作模式。

Conclusion: 高级语义信息在人机团队协作中具有重要价值，能够有效改善人机交互效果。语义框架为复杂环境下的人机协作提供了新的解决方案，特别是在需要快速决策和高效协作的灾难响应等场景中具有显著优势。

Abstract: In this paper, we investigate the impact of high-level semantics (evaluation
of the environment) on Human-Robot Teams (HRT) and Human-Robot Interaction
(HRI) in the context of mobile robot deployments. Although semantics has been
widely researched in AI, how high-level semantics can benefit the HRT paradigm
is underexplored, often fuzzy, and intractable. We applied a semantics-based
framework that could reveal different indicators of the environment (i.e. how
much semantic information exists) in a mock-up disaster response mission. In
such missions, semantics are crucial as the HRT should handle complex
situations and respond quickly with correct decisions, where humans might have
a high workload and stress. Especially when human operators need to shift their
attention between robots and other tasks, they will struggle to build
Situational Awareness (SA) quickly. The experiment suggests that the presented
semantics: 1) alleviate the perceived workload of human operators; 2) increase
the operator's trust in the SA; and 3) help to reduce the reaction time in
switching the level of autonomy when needed. Additionally, we find that
participants with higher trust in the system are encouraged by high-level
semantics to use teleoperation mode more.

</details>


### [49] [Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models](https://arxiv.org/abs/2507.17379)
*Shen Tan,Dong Zhou,Xiangyu Shao,Junqiao Wang,Guanghui Sun*

Main category: cs.RO

TL;DR: 提出了LOVMM框架，结合大语言模型和视觉语言模型，实现基于自然语言指令的开放词汇移动操作，能够处理家庭环境中的各种新颖物体操作任务


<details>
  <summary>Details</summary>
Motivation: 开放词汇移动操作(OVMM)需要处理不同工作空间中的新颖和未见过的物体，这对真实世界的机器人应用来说仍然是一个重大挑战

Method: 提出LOVMM框架，结合大语言模型(LLM)和视觉语言模型(VLM)来处理家庭环境中的各种移动操作任务，能够执行自由形式的自然语言指令

Result: 在复杂家庭环境的仿真实验中展现出强大的零样本泛化能力和多任务学习能力，在多个桌面操作任务中也能泛化并获得比其他最先进方法更好的成功率

Conclusion: LOVMM框架成功解决了开放词汇移动操作的挑战，通过结合LLM和VLM实现了对自然语言指令的理解和执行，在家庭环境和桌面操作任务中都表现出优异的性能

Abstract: Open-vocabulary mobile manipulation (OVMM) that involves the handling of
novel and unseen objects across different workspaces remains a significant
challenge for real-world robotic applications. In this paper, we propose a
novel Language-conditioned Open-Vocabulary Mobile Manipulation framework, named
LOVMM, incorporating the large language model (LLM) and vision-language model
(VLM) to tackle various mobile manipulation tasks in household environments.
Our approach is capable of solving various OVMM tasks with free-form natural
language instructions (e.g. "toss the food boxes on the office room desk to the
trash bin in the corner", and "pack the bottles from the bed to the box in the
guestroom"). Extensive experiments simulated in complex household environments
show strong zero-shot generalization and multi-task learning abilities of
LOVMM. Moreover, our approach can also generalize to multiple tabletop
manipulation tasks and achieve better success rates compared to other
state-of-the-art methods.

</details>


### [50] [Confidence Calibration in Vision-Language-Action Models](https://arxiv.org/abs/2507.17383)
*Thomas P Zollo,Richard Zemel*

Main category: cs.RO

TL;DR: 本研究首次系统性地研究了视觉-语言-动作(VLA)基础模型中的置信度校准问题，提出了提示集成和动作维度Platt标定等方法来提高机器人行为的可信度和不确定性量化能力。


<details>
  <summary>Details</summary>
Motivation: 可信赖的机器人行为不仅需要高任务成功率，还需要机器人能够可靠地量化其成功概率。现有的视觉-语言-动作基础模型缺乏系统性的置信度校准研究，这限制了机器人在实际应用中的可信度。

Method: 1) 对多个数据集和VLA变体进行广泛基准测试，分析任务成功率与校准误差的关系；2) 提出提示集成算法，通过对释义指令的置信度求平均来改善校准；3) 分析任务时间范围内的校准情况；4) 提出动作维度的Platt标定方法，独立重新校准每个动作维度。

Result: 发现任务性能与校准并不冲突；提示集成算法持续改善了校准效果；置信度在取得一定进展后往往最可靠，为风险感知干预提供了自然节点；不同动作维度存在差异性误校准现象。

Conclusion: 通过开发必要的工具和概念理解，研究为使VLA模型既高性能又高可信赖奠定了基础，通过可靠的不确定性量化实现了这一目标。提出的方法为机器人行为的置信度校准提供了有效解决方案。

Abstract: Trustworthy robot behavior requires not only high levels of task success but
also that the robot can reliably quantify how likely it is to succeed. To this
end, we present the first systematic study of confidence calibration in
vision-language-action (VLA) foundation models, which map visual observations
and natural-language instructions to low-level robot motor commands. We begin
with extensive benchmarking to understand the critical relationship between
task success and calibration error across multiple datasets and VLA variants,
finding that task performance and calibration are not in tension. Next, we
introduce prompt ensembles for VLAs, a lightweight, Bayesian-inspired algorithm
that averages confidence across paraphrased instructions and consistently
improves calibration. We further analyze calibration over the task time
horizon, showing that confidence is often most reliable after making some
progress, suggesting natural points for risk-aware intervention. Finally, we
reveal differential miscalibration across action dimensions and propose
action-wise Platt scaling, a method to recalibrate each action dimension
independently to produce better confidence estimates. Our aim in this study is
to begin to develop the tools and conceptual understanding necessary to render
VLAs both highly performant and highly trustworthy via reliable uncertainty
quantification.

</details>


### [51] [The Wilhelm Tell Dataset of Affordance Demonstrations](https://arxiv.org/abs/2507.17401)
*Rachel Ringe,Mihai Pomarlan,Nikolaos Tsiogkas,Stefano De Giorgis,Maria Hedblom,Rainer Malaka*

Main category: cs.RO

TL;DR: 该论文提出了一个新颖的视频数据集，用于训练机器人在家庭环境中识别物体的可供性（affordances），数据集包含第一人称和第三人称视角的任务演示视频，总计约7小时的人类活动记录。


<details>
  <summary>Details</summary>
Motivation: 现有的可供性学习方法主要基于静态图像或形状的标注数据进行训练，缺乏动态的、真实的任务演示数据。机器人在人类环境中操作需要能够感知环境和物体提供的行动可能性，因此需要更好的数据集来训练这种感知能力。

Method: 构建了一个包含常见家庭任务的视频序列数据集，从第一人称和第三人称视角记录任务演示，并提供关于任务中体现的可供性的元数据。数据收集来自多个参与者，旨在训练感知系统识别可供性的表现形式。

Result: 成功收集了约7小时的人类活动记录，数据集涵盖了多种任务执行方式，还能够研究人们为完成任务而进行的准备性操作，如任务空间的安排等。

Conclusion: 该数据集为机器人可供性学习提供了新的资源，特别适用于训练能够识别可供性表现的感知系统，同时为协作服务机器人的研究提供了有价值的数据，包括人类任务准备行为的分析。

Abstract: Affordances - i.e. possibilities for action that an environment or objects in
it provide - are important for robots operating in human environments to
perceive. Existing approaches train such capabilities on annotated static
images or shapes. This work presents a novel dataset for affordance learning of
common household tasks. Unlike previous approaches, our dataset consists of
video sequences demonstrating the tasks from first- and third-person
perspectives, along with metadata about the affordances that are manifested in
the task, and is aimed towards training perception systems to recognize
affordance manifestations. The demonstrations were collected from several
participants and in total record about seven hours of human activity. The
variety of task performances also allows studying preparatory maneuvers that
people may perform for a task, such as how they arrange their task space, which
is also relevant for collaborative service robots.

</details>


### [52] [Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners](https://arxiv.org/abs/2507.17519)
*Kostas Karakontis,Thanos Petsanis,Athanasios Ch. Kapoutsis,Pavlos Ch. Kapoutsis,Elias B. Kosmatopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种模块化算法，将商业二维路径规划器扩展为地形感知的三维规划器，通过调整高度和相机方向来改善无人机集群的覆盖路径规划，特别是在垂直表面和遮挡区域的3D重建效果。


<details>
  <summary>Details</summary>
Motivation: 现有的商业软件中的多无人机覆盖路径规划算法通常只将感兴趣区域视为2D平面，忽略了重要的3D结构特征，这导致3D重建不完整，特别是在遮挡或垂直表面周围存在问题。

Method: 提出了一种模块化算法，可以扩展商业二维路径规划器以实现地形感知规划，通过调整高度和相机方向来优化路径。作为演示，将著名的DARP算法扩展为DARP-3D算法。

Result: 在多个3D环境中进行了仿真测试，并使用大疆硬件进行了真实世界的飞行测试。与基线方法相比，该方法在3D重建方面表现更好，特别是在具有显著垂直特征的区域。

Conclusion: 所提出的模块化算法能够有效地将2D路径规划扩展到3D地形感知规划，显著改善了多无人机系统在复杂3D环境中的覆盖效果和重建质量，并提供了开源实现。

Abstract: Multi-UAV Coverage Path Planning (mCPP) algorithms in popular commercial
software typically treat a Region of Interest (RoI) only as a 2D plane,
ignoring important3D structure characteristics. This leads to incomplete
3Dreconstructions, especially around occluded or vertical surfaces. In this
paper, we propose a modular algorithm that can extend commercial
two-dimensional path planners to facilitate terrain-aware planning by adjusting
altitude and camera orientations. To demonstrate it, we extend the well-known
DARP (Divide Areas for Optimal Multi-Robot Coverage Path Planning) algorithm
and produce DARP-3D. We present simulation results in multiple 3D environments
and a real-world flight test using DJI hardware. Compared to baseline, our
approach consistently captures improved 3D reconstructions, particularly in
areas with significant vertical features. An open-source implementation of the
algorithm is available here:https://github.com/konskara/TerraPlan

</details>


### [53] [InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation](https://arxiv.org/abs/2507.17520)
*Shuai Yang,Hao Li,Yilun Chen,Bin Wang,Yang Tian,Tai Wang,Hanqing Wang,Feng Zhao,Yiyi Liao,Jiangmiao Pang*

Main category: cs.RO

TL;DR: InstructVLA是一个端到端的视觉-语言-动作模型，通过新颖的VLA-IT训练范式，在保持大型视觉语言模型灵活推理能力的同时，实现了领先的机器人操作性能，并在多个基准测试中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作(VLA)模型往往在多模态推理和精确动作生成之间做出牺牲，能力局限于特定任务的操作数据，并且会遭受预训练视觉语言能力的灾难性遗忘。需要开发一个能够同时保持灵活推理和实现高效操作性能的统一模型。

Method: 提出了视觉-语言-动作指令调优(VLA-IT)训练范式，采用混合专家适应的多模态训练方法，在标准VLM语料库和精心策划的65万样本VLA-IT数据集上联合优化文本推理和动作生成能力。

Result: 在域内SimplerEnv任务上比SpatialVLA提升30.5%；在新引入的SimplerEnv-Instruct 80任务基准测试中，比微调的OpenVLA超出92%，比GPT-4o辅助的动作专家超出29%；在多模态任务上超越基线VLM，并展现了推理时缩放能力。

Conclusion: InstructVLA成功弥合了直观可控的人机交互与高效策略学习之间的差距，证明了其在仿真和真实世界环境中的潜力，为机器人领域的视觉-语言-动作集成提供了新的解决方案。

Abstract: To operate effectively in the real world, robots must integrate multimodal
reasoning with precise action generation. However, existing
vision-language-action (VLA) models often sacrifice one for the other, narrow
their abilities to task-specific manipulation data, and suffer catastrophic
forgetting of pre-trained vision-language capabilities. To bridge this gap, we
introduce InstructVLA, an end-to-end VLA model that preserves the flexible
reasoning of large vision-language models (VLMs) while delivering leading
manipulation performance. InstructVLA introduces a novel training paradigm,
Vision-Language-Action Instruction Tuning (VLA-IT), which employs multimodal
training with mixture-of-experts adaptation to jointly optimize textual
reasoning and action generation on both standard VLM corpora and a curated
650K-sample VLA-IT dataset. On in-domain SimplerEnv tasks, InstructVLA achieves
30.5% improvement over SpatialVLA. To evaluate generalization, we introduce
SimplerEnv-Instruct, an 80-task benchmark requiring closed-loop control and
high-level instruction understanding, where it outperforms a fine-tuned OpenVLA
by 92% and an action expert aided by GPT-4o by 29%. Additionally, InstructVLA
surpasses baseline VLMs on multimodal tasks and exhibits inference-time scaling
by leveraging textual reasoning to boost manipulation performance in both
simulated and real-world settings. These results demonstrate InstructVLA's
potential for bridging intuitive and steerable human-robot interaction with
efficient policy learning.

</details>


### [54] [When and Where Localization Fails: An Analysis of the Iterative Closest Point in Evolving Environment](https://arxiv.org/abs/2507.17531)
*Abdel-Raouf Dannaoui,Johann Laconte,Christophe Debain,Francois Pomerleau,Paul Checchin*

Main category: cs.RO

TL;DR: 本文提出了一个高分辨率短期多时序数据集，用于评估自主系统在动态户外环境中的重定位性能，比较了两种ICP算法在不同环境条件下的表现。


<details>
  <summary>Details</summary>
Motivation: 动态户外环境中的鲁棒重定位仍是依赖3D激光雷达的自主系统面临的关键挑战。虽然长期定位已被广泛研究，但发生在数天或数周内的短期环境变化尽管具有实际意义，却仍未得到充分探索。

Method: 构建了一个从2025年2月到4月每周收集的高分辨率短期多时序数据集，涵盖自然和半城市环境。每个会话包括高密度点云地图、360度全景图像和轨迹数据。使用从点云地图导出的投影激光雷达扫描，通过传感器精确遮挡建模，评估两种迭代最近点(ICP)算法变体的对齐精度。

Result: Point-to-Plane ICP算法比Point-to-Point ICP提供了显著更稳定和准确的配准，特别是在稀疏特征或密集植被区域。研究提供了用于评估短期定位鲁棒性的结构化数据集，以及在噪声条件下分析扫描到地图对齐的可重现框架。

Conclusion: 分析强调了局部几何和环境变异性如何影响定位成功率，为设计更具弹性的机器人系统提供了见解。该研究为评估不断变化的户外环境中ICP性能提供了比较评估框架。

Abstract: Robust relocalization in dynamic outdoor environments remains a key challenge
for autonomous systems relying on 3D lidar. While long-term localization has
been widely studied, short-term environmental changes, occurring over days or
weeks, remain underexplored despite their practical significance. To address
this gap, we present a highresolution, short-term multi-temporal dataset
collected weekly from February to April 2025 across natural and semi-urban
settings. Each session includes high-density point cloud maps, 360 deg
panoramic images, and trajectory data. Projected lidar scans, derived from the
point cloud maps and modeled with sensor-accurate occlusions, are used to
evaluate alignment accuracy against the ground truth using two Iterative
Closest Point (ICP) variants: Point-to-Point and Point-to-Plane. Results show
that Point-to-Plane offers significantly more stable and accurate registration,
particularly in areas with sparse features or dense vegetation. This study
provides a structured dataset for evaluating short-term localization
robustness, a reproducible framework for analyzing scan-to-map alignment under
noise, and a comparative evaluation of ICP performance in evolving outdoor
environments. Our analysis underscores how local geometry and environmental
variability affect localization success, offering insights for designing more
resilient robotic systems.

</details>


### [55] [Robot-mediated physical Human-Human Interaction in Neurorehabilitation: a position paper](https://arxiv.org/abs/2507.17561)
*Lorenzo Vianello,Matthew Short,Julia Manczurowsky,Emek Barış Küçüktabak,Francesco Di Tommaso,Alessia Noccaro,Laura Bandini,Shoshana Clark,Alaina Fiorenza,Francesca Lunardini,Alberto Canton,Marta Gandolla,Alessandra L. G. Pedrocchi,Emilia Ambrosini,Manuel Murie-Fernandez,Carmen B. Roman,Jesus Tornero,Natacha Leon,Andrew Sawers,Jim Patton,Domenico Formica,Nevio Luigi Tagliamonte,Georg Rauter,Kilian Baur,Fabian Just,Christopher J. Hasson,Vesna D. Novak,Jose L. Pons*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的神经康复方法——机器人介导的人-人物理交互，将治疗师的临床专业知识与机器人的精确性和重复性相结合，作为传统手法治疗和康复机器人之间的桥梁。


<details>
  <summary>Details</summary>
Motivation: 传统神经康复依赖患者与物理治疗师的直接交互，而现有机器人系统虽能改善物理反馈，但未能充分利用训练有素的治疗师的适应性和临床专业知识。需要一种方法将治疗师的临床专长与机器人的优势相结合。

Method: 提出机器人介导的人-人物理交互框架，使两个个体能够通过机器人设备进行物理交互。该方法包括：统一的分类法来描述机器人介导的康复、基于社会心理学的交互框架，以及使机器人系统成为自然人-人交互无缝促进者的技术方法。

Result: 该框架已在不同研究团队中得到研究，并作为传统手法治疗和康复机器人之间的有前途的连接方式出现，协调了两种方法的优势。多学科团队（包括工程师、医生和物理治疗师）为此研究提供了理论基础。

Conclusion: 机器人介导的人-人物理交互为神经康复提供了一种新的范式，能够整合治疗师的临床专业知识和细致决策能力与机器人的力量、准确性和重复性，代表了康复技术发展的重要方向。

Abstract: Neurorehabilitation conventionally relies on the interaction between a
patient and a physical therapist. Robotic systems can improve and enrich the
physical feedback provided to patients after neurological injury, but they
under-utilize the adaptability and clinical expertise of trained therapists. In
this position paper, we advocate for a novel approach that integrates the
therapist's clinical expertise and nuanced decision-making with the strength,
accuracy, and repeatability of robotics: Robot-mediated physical Human-Human
Interaction. This framework, which enables two individuals to physically
interact through robotic devices, has been studied across diverse research
groups and has recently emerged as a promising link between conventional manual
therapy and rehabilitation robotics, harmonizing the strengths of both
approaches. This paper presents the rationale of a multidisciplinary
team-including engineers, doctors, and physical therapists-for conducting
research that utilizes: a unified taxonomy to describe robot-mediated
rehabilitation, a framework of interaction based on social psychology, and a
technological approach that makes robotic systems seamless facilitators of
natural human-human interaction.

</details>


### [56] [KernelSOS for Global Sampling-Based Optimal Control and Estimation via Semidefinite Programming](https://arxiv.org/abs/2507.17572)
*Antoine Groudiev,Fabian Schramm,Éloïse Berthier,Justin Carpentier,Frederike Dümbgen*

Main category: cs.RO

TL;DR: 本文将核平方和(KernelSOS)框架应用于控制和估计问题的全局优化，展示了其在处理具有不良局部最小值问题上的有效性，特别是在轨迹优化中可作为独立方法或局部求解器的初始化方法使用。


<details>
  <summary>Details</summary>
Motivation: 控制和估计问题经常遇到不良局部最小值的困扰，传统优化方法容易陷入局部最优解。虽然全局优化理论和数值方法已有发展，但需要一个能够结合多项式优化中平方和方法的理论基础与机器学习中核方法表达能力的强大框架来解决这类问题。

Method: 采用核平方和(KernelSOS)框架，这是一个结合了多项式优化社区平方和方法潜力与机器学习中广泛使用的核方法表达能力的优化框架。该方法基于样本，可以应用于非多项式和非参数化的问题表述，并能够处理将集成模拟器视为黑盒的轨迹优化问题。

Result: KernelSOS在控制和估计领域的多个问题上表现良好。在估计问题上，该方法与其他平方和方法具有竞争力，同时适用于非多项式和非参数化问题。在轨迹优化问题中，KernelSOS既可以作为独立方法使用，也可以作为局部求解器的强大初始化方法，有助于发现更好的解决方案。

Conclusion: 核平方和框架为解决控制和估计中的全局优化问题提供了一个有效的工具，特别是在处理具有不良局部最小值的复杂优化问题时。该方法的样本化特性和对非多项式问题的适用性使其在实际应用中具有广阔前景，既可独立使用也可与现有局部优化方法结合使用以获得更好的优化结果。

Abstract: Global optimization has gained attraction over the past decades, thanks to
the development of both theoretical foundations and efficient numerical
routines to cope with optimization problems of various complexities. Among
recent methods, Kernel Sum of Squares (KernelSOS) appears as a powerful
framework, leveraging the potential of sum of squares methods from the
polynomial optimization community with the expressivity of kernel methods
widely used in machine learning. This paper applies the kernel sum of squares
framework for solving control and estimation problems, which exhibit poor local
minima. We demonstrate that KernelSOS performs well on a selection of problems
from both domains. In particular, we show that KernelSOS is competitive with
other sum of squares approaches on estimation problems, while being applicable
to non-polynomial and non-parametric formulations. The sample-based nature of
KernelSOS allows us to apply it to trajectory optimization problems with an
integrated simulator treated as a black box, both as a standalone method and as
a powerful initialization method for local solvers, facilitating the discovery
of better solutions.

</details>


### [57] [Event Detection for Active Lower Limb Prosthesis](https://arxiv.org/abs/2507.17649)
*J. D. Clark,P. Ellison*

Main category: cs.RO

TL;DR: 该研究探索了在假肢膝关节设计中使用双髁膝关节和十字韧带拉伸来改善步态事件检测的准确性，发现韧带拉伸模式可以作为预测步态关键时刻的有效指标。


<details>
  <summary>Details</summary>
Motivation: 准确的事件检测是半被动和动力假肢成功设计的关键。传统的销钉关节简化设计会丢失膝关节的复杂运动学行为（包括平移和旋转），影响步态特征。因此需要研究十字韧带拉伸在事件检测中的作用。

Method: 使用双髁膝关节设计，由前后十字韧带类似物约束。通过与韧带平行的LVDT传感器记录Russell膝关节的韧带拉伸情况。在跑步机上以3种不同速度采集数据，通过韧带拉伸来表征膝关节运动学特性。

Result: 发现十字韧带拉伸存在速度依赖性，主要出现在步态周期的5%和80%（后十字韧带和前十字韧带）。循环轮廓随速度保持一致，在90%和95%处的转折点特征可作为初始接触的预测前兆，同样的转折点可用于预测足底平放。

Conclusion: 双髁膝关节设计的使用可以改善步态周期中事件的检测，从而提高动力假肢后续控制器的准确性。韧带拉伸模式为假肢控制系统提供了新的生物力学反馈机制。

Abstract: Accurate event detection is key to the successful design of semi-passive and
powered prosthetics. Kinematically, the natural knee is complex, with
translation and rotation components that have a substantial impact on gait
characteristics. When simplified to a pin joint, some of this behaviour is
lost. This study investigates the role of cruciate ligament stretch in event
detection. A bicondylar knee design was used, constrained by analogues of the
anterior and posterior cruciate ligaments. This offers the ability to
characterize knee kinematics by the stretch of the ligaments. The ligament
stretch was recorded using LVDTs parallel to the ligaments of the Russell knee
on a bent knee crutch. Which was used to capture data on a treadmill at 3
speeds. This study finds speed dependence within the stretch of the cruciate
ligaments, prominently around 5\% and 80\% of the gait cycle for the posterior
and anterior. The cycle profile remains consistent with speed; therefore, other
static events such as the turning point feature at around 90\% and 95\% of the
cycle, for the posterior and anterior, respectively, could be used as a
predictive precursor for initial contact. Likewise at 90\% and 95\%, another
pair of turning points that in this case could be used to predict foot flat.
This concludes that the use of a bicondylar knee design could improve the
detection of events during the gait cycle, and therefore could increase the
accuracy of subsequent controllers for powered prosthetics.

</details>


### [58] [Safety Assurance for Quadrotor Kinodynamic Motion Planning](https://arxiv.org/abs/2507.17679)
*Theodoros Tavoulareas,Marzia Cescon*

Main category: cs.RO

TL;DR: 本文提出了一种结合运行时安全保障的无人机运动规划方法，通过采样几何规划器生成无碰撞路径，并设计低层安全保障滤波器确保控制输入满足系统运行约束，在Crazyflie 2.0无人机仿真中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有运动规划技术虽能生成无碰撞轨迹，但在规划过程中未考虑系统的安全运行区域，可能导致部署时违反安全约束，进而造成系统损坏、环境污染甚至人员伤亡。随着自主无人机在搜救、检查、配送等民用场景中的广泛应用，确保安全运行变得至关重要。

Method: 提出了一种双层运动规划架构：1）高层使用基于采样的几何规划器在用户定义空间内确定无碰撞路径；2）低层设计安全保障滤波器，为用于轨迹跟踪的线性二次调节器(LQR)控制输入提供安全保证，确保满足系统运行约束。该方法将运行时安全保障融入到动力学运动规划方案中。

Result: 在限制性3D仿真环境中使用Crazyflie 2.0无人机模型验证了所提方法的有效性。实验结果表明该方法能够在保证无碰撞导航的同时，满足系统的安全运行约束。

Conclusion: 通过将运行时安全保障机制集成到运动规划框架中，该方法成功解决了传统运动规划技术忽视系统安全运行区域的问题。双层架构设计既保证了路径的无碰撞性，又确保了控制输入满足安全约束，为自主无人机的安全部署提供了有效解决方案。

Abstract: Autonomous drones have gained considerable attention for applications in
real-world scenarios, such as search and rescue, inspection, and delivery. As
their use becomes ever more pervasive in civilian applications, failure to
ensure safe operation can lead to physical damage to the system, environmental
pollution, and even loss of human life. Recent work has demonstrated that
motion planning techniques effectively generate a collision-free trajectory
during navigation. However, these methods, while creating the motion plans, do
not inherently consider the safe operational region of the system, leading to
potential safety constraints violation during deployment. In this paper, we
propose a method that leverages run time safety assurance in a kinodynamic
motion planning scheme to satisfy the system's operational constraints. First,
we use a sampling-based geometric planner to determine a high-level
collision-free path within a user-defined space. Second, we design a low-level
safety assurance filter to provide safety guarantees to the control input of a
Linear Quadratic Regulator (LQR) designed with the purpose of trajectory
tracking. We demonstrate our proposed approach in a restricted 3D simulation
environment using a model of the Crazyflie 2.0 drone.

</details>


### [59] [CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation](https://arxiv.org/abs/2507.17727)
*Robel Mamo,Taeyeong Choi*

Main category: cs.RO

TL;DR: 本文提出了一种名为Crop-Aligned Cutout (CA-Cut)的新型数据增强方法，通过在作物行周围空间分布地遮蔽随机区域来改善农业视觉导航模型的鲁棒性，在玉米田数据集上实现了高达36.9%的预测误差降低。


<details>
  <summary>Details</summary>
Motivation: 现有的农业视觉导航方法需要大量训练数据，而数据收集成本高昂。传统的数据增强技术（如颜色抖动、高斯模糊等）在复杂的作物覆盖环境中表现不佳，特别是在面临频繁遮挡、杂物和作物间距不均匀的情况下，可能导致性能次优。

Method: 提出了Crop-Aligned Cutout (CA-Cut)方法，该方法在输入图像中沿作物行两侧空间分布地遮蔽随机区域，迫使训练模型在细粒度信息被遮挡时仍能捕获高级上下文特征。通过消融研究确定了遮罩数量、每个遮罩的大小以及遮罩的空间分布等关键参数。

Result: 在公开玉米田数据集上的大量实验表明，基于遮罩的增强方法能有效模拟遮挡情况，显著提高视觉导航中语义关键点预测的鲁棒性。CA-Cut方法在预测准确性和跨环境泛化能力方面都有显著提升，预测误差最多降低了36.9%。

Conclusion: 将遮罩分布偏向作物行的CA-Cut方法对于增强预测准确性和跨不同环境的泛化能力至关重要。这种新颖的数据增强策略为农业视觉导航提供了一种有效的解决方案，特别是在处理复杂的作物覆盖环境时表现出色。

Abstract: State-of-the-art visual under-canopy navigation methods are designed with
deep learning-based perception models to distinguish traversable space from
crop rows. While these models have demonstrated successful performance, they
require large amounts of training data to ensure reliability in real-world
field deployment. However, data collection is costly, demanding significant
human resources for in-field sampling and annotation. To address this
challenge, various data augmentation techniques are commonly employed during
model training, such as color jittering, Gaussian blur, and horizontal flip, to
diversify training data and enhance model robustness. In this paper, we
hypothesize that utilizing only these augmentation techniques may lead to
suboptimal performance, particularly in complex under-canopy environments with
frequent occlusions, debris, and non-uniform spacing of crops. Instead, we
propose a novel augmentation method, so-called Crop-Aligned Cutout (CA-Cut)
which masks random regions out in input images that are spatially distributed
around crop rows on the sides to encourage trained models to capture high-level
contextual features even when fine-grained information is obstructed. Our
extensive experiments with a public cornfield dataset demonstrate that
masking-based augmentations are effective for simulating occlusions and
significantly improving robustness in semantic keypoint predictions for visual
navigation. In particular, we show that biasing the mask distribution toward
crop rows in CA-Cut is critical for enhancing both prediction accuracy and
generalizability across diverse environments achieving up to a 36.9% reduction
in prediction error. In addition, we conduct ablation studies to determine the
number of masks, the size of each mask, and the spatial distribution of masks
to maximize overall performance.

</details>
