<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 25]
- [cs.AI](#cs.AI) [Total: 23]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Learning to Prune Branches in Modern Tree-Fruit Orchards](https://arxiv.org/abs/2507.23015)
*Abhinav Jain,Cindy Grimm,Stefan Lee*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的闭环控制机器人修剪系统，用于高效修剪果树，无需完整3D重建，仅需光学流图像。


<details>
  <summary>Details</summary>
Motivation: 传统果树修剪劳动密集且效率低，需要自动化解决方案。

Method: 使用果园模拟训练控制器，仅依赖腕部摄像头的光学流图像，实现零样本迁移。

Result: 在仿真和实际环境中实现30%的成功率，约为理想规划器性能的一半。

Conclusion: 该方法展示了机器人修剪的潜力，但仍有提升空间。

Abstract: Dormant tree pruning is labor-intensive but essential to maintaining modern
highly-productive fruit orchards. In this work we present a closed-loop
visuomotor controller for robotic pruning. The controller guides the cutter
through a cluttered tree environment to reach a specified cut point and ensures
the cutters are perpendicular to the branch. We train the controller using a
novel orchard simulation that captures the geometric distribution of branches
in a target apple orchard configuration. Unlike traditional methods requiring
full 3D reconstruction, our controller uses just optical flow images from a
wrist-mounted camera. We deploy our learned policy in simulation and the
real-world for an example V-Trellis envy tree with zero-shot transfer,
achieving a 30% success rate -- approximately half the performance of an oracle
planner.

</details>


### [2] [A Certifably Correct Algorithm for Generalized Robot-World and Hand-Eye Calibration](https://arxiv.org/abs/2507.23045)
*Emmett Wise,Pushyami Kaveti,Qilong Chen,Wenhao Wang,Hanumant Singh,Jonathan Kelly,David M. Rosen,Matthew Giamou*

Main category: cs.RO

TL;DR: 提出了一种快速且全局最优的算法，用于解决广义的机器人-世界和手眼标定（RWHEC）问题，支持多传感器和目标姿态的同时估计，并适用于单目相机。


<details>
  <summary>Details</summary>
Motivation: 多传感器平台的自动外参标定是一个基础问题，需要高效、通用且减少人工干预的解决方案。

Method: 引入了一种广义RWHEC问题的新算法，支持多传感器和目标姿态的同时估计，适用于单目相机，并提供了全局最优性保证。

Result: 算法性能优于现有方法，并提供了新的可识别性标准和全局最优性保证。

Conclusion: 该算法在多传感器标定中表现出色，提供了开源实现，适用于实际应用。

Abstract: Automatic extrinsic sensor calibration is a fundamental problem for
multi-sensor platforms. Reliable and general-purpose solutions should be
computationally efficient, require few assumptions about the structure of the
sensing environment, and demand little effort from human operators. Since the
engineering effort required to obtain accurate calibration parameters increases
with the number of sensors deployed, robotics researchers have pursued methods
requiring few assumptions about the sensing environment and minimal effort from
human operators. In this work, we introduce a fast and certifiably globally
optimal algorithm for solving a generalized formulation of the
$\textit{robot-world and hand-eye calibration}$ (RWHEC) problem. The
formulation of RWHEC presented is "generalized" in that it supports the
simultaneous estimation of multiple sensor and target poses, and permits the
use of monocular cameras that, alone, are unable to measure the scale of their
environments. In addition to demonstrating our method's superior performance
over existing solutions, we derive novel identifiability criteria and establish
$\textit{a priori}$ guarantees of global optimality for problem instances with
bounded measurement errors. We also introduce a complementary Lie-algebraic
local solver for RWHEC and compare its performance with our global method and
prior art. Finally, we provide a free and open-source implementation of our
algorithms and experiments.

</details>


### [3] [In-between Motion Generation Based Multi-Style Quadruped Robot Locomotion](https://arxiv.org/abs/2507.23053)
*Yuanhao Chen,Liu Zhao,Ji Ma,Peng Lu*

Main category: cs.RO

TL;DR: 提出了一种基于多风格四足机器人运动生成的框架，结合运动生成与模仿学习，提升运动多样性与控制器性能。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人因参考运动数据多样性不足而面临的运动能力受限问题。

Method: 采用CVAE生成多风格运动序列，结合物理约束与相位流形连续性；使用对抗运动先验算法验证数据有效性。

Result: 显著提升速度跟踪性能与控制器稳定性，成功在真实机器人上实现多种步态。

Conclusion: 框架能生成并执行复杂运动，验证了其在真实场景中的有效性。

Abstract: Quadruped robots face persistent challenges in achieving versatile locomotion
due to limitations in reference motion data diversity. To address these
challenges, this approach introduces an in-between motion generation based
multi-style quadruped robot locomotion framework, integrating synergistic
advances in motion generation and imitation learning. Our approach establishes
a unified pipeline addressing two fundamental aspects: First, we propose a CVAE
based motion generator, synthesizing multi-style dynamically feasible
locomotion sequences between arbitrary start and end states. By embedding
physical constraints and leveraging joint poses based phase manifold
continuity, this component produces physically plausible motions spanning
multiple gait modalities while ensuring kinematic compatibility with robotic
morphologies. Second, we adopt the adversarial motion priors algorithm. We
validate the effectiveness of generated motion data in enhancing controller
stability and improving velocity tracking performance. The proposed framework
demonstrates significant improvements in velocity tracking and deployment
stability. We successfully deploy the framework on a real-world quadruped
robot, and the experimental validation confirms the framework's capability to
generate and execute complex motion profiles, including gallop, tripod,
trotting and pacing.

</details>


### [4] [Beyond Rigid AI: Towards Natural Human-Machine Symbiosis for Interoperative Surgical Assistance](https://arxiv.org/abs/2507.23088)
*Lalithkumar Seenivasan,Jiru Xu,Roger D. Soberanis Mukul,Hao Ding,Grayson Byrd,Yu-Chun Ku,Jose L. Porras,Masaru Ishii,Mathias Unberath*

Main category: cs.RO

TL;DR: 提出了一种新型感知代理，结合语音提示、LLM、SAM和跟踪模型，提升手术中人机交互的自然性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有AI解决方案在动态手术环境中缺乏灵活性，限制了自然交互，需依赖大量预训练和固定类别。

Method: 利用语音集成提示工程LLM、SAM和跟踪模型，结合记忆库和两种新机制，实现实时手术辅助。

Result: 定量分析显示性能与手动提示策略相当，定性分析展示了分割新元素的灵活性。

Conclusion: 感知代理通过自然交互和克服刚性，使AI在动态手术环境中的实时辅助更接近现实。

Abstract: Emerging surgical data science and robotics solutions, especially those
designed to provide assistance in situ, require natural human-machine
interfaces to fully unlock their potential in providing adaptive and intuitive
aid. Contemporary AI-driven solutions remain inherently rigid, offering limited
flexibility and restricting natural human-machine interaction in dynamic
surgical environments. These solutions rely heavily on extensive task-specific
pre-training, fixed object categories, and explicit manual-prompting. This work
introduces a novel Perception Agent that leverages speech-integrated
prompt-engineered large language models (LLMs), segment anything model (SAM),
and any-point tracking foundation models to enable a more natural human-machine
interaction in real-time intraoperative surgical assistance. Incorporating a
memory repository and two novel mechanisms for segmenting unseen elements,
Perception Agent offers the flexibility to segment both known and unseen
elements in the surgical scene through intuitive interaction. Incorporating the
ability to memorize novel elements for use in future surgeries, this work takes
a marked step towards human-machine symbiosis in surgical procedures. Through
quantitative analysis on a public dataset, we show that the performance of our
agent is on par with considerably more labor-intensive manual-prompting
strategies. Qualitatively, we show the flexibility of our agent in segmenting
novel elements (instruments, phantom grafts, and gauze) in a custom-curated
dataset. By offering natural human-machine interaction and overcoming rigidity,
our Perception Agent potentially brings AI-based real-time assistance in
dynamic surgical environments closer to reality.

</details>


### [5] [Benchmarking Massively Parallelized Multi-Task Reinforcement Learning for Robotics Tasks](https://arxiv.org/abs/2507.23172)
*Vira Joshi,Zifan Xu,Bo Liu,Peter Stone,Amy Zhang*

Main category: cs.RO

TL;DR: MTBench是一个大规模并行化的多任务强化学习基准，包含50个操作任务和20个运动任务，用于评估MTRL算法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有MTRL研究主要局限于低并行化环境下的离策略方法，而大规模并行化可以加速数据收集并提升性能。

Method: 使用GPU加速模拟器IsaacGym实现MTBench，结合四种基础RL算法和七种先进MTRL算法进行评估。

Result: 实验表明MTBench能高效评估MTRL方法，同时揭示了大规模并行化带来的新挑战。

Conclusion: MTBench为MTRL研究提供了统一框架，并展示了大规模并行化的潜力。

Abstract: Multi-task Reinforcement Learning (MTRL) has emerged as a critical training
paradigm for applying reinforcement learning (RL) to a set of complex
real-world robotic tasks, which demands a generalizable and robust policy. At
the same time, \emph{massively parallelized training} has gained popularity,
not only for significantly accelerating data collection through GPU-accelerated
simulation but also for enabling diverse data collection across multiple tasks
by simulating heterogeneous scenes in parallel. However, existing MTRL research
has largely been limited to off-policy methods like SAC in the
low-parallelization regime. MTRL could capitalize on the higher asymptotic
performance of on-policy algorithms, whose batches require data from the
current policy, and as a result, take advantage of massive parallelization
offered by GPU-accelerated simulation. To bridge this gap, we introduce a
massively parallelized $\textbf{M}$ulti-$\textbf{T}$ask $\textbf{Bench}$mark
for robotics (MTBench), an open-sourced benchmark featuring a broad
distribution of 50 manipulation tasks and 20 locomotion tasks, implemented
using the GPU-accelerated simulator IsaacGym. MTBench also includes four base
RL algorithms combined with seven state-of-the-art MTRL algorithms and
architectures, providing a unified framework for evaluating their performance.
Our extensive experiments highlight the superior speed of evaluating MTRL
approaches using MTBench, while also uncovering unique challenges that arise
from combining massive parallelism with MTRL. Code is available at
$\href{https://github.com/Viraj-Joshi/MTBench}{
https://github.com/Viraj-Joshi/MTBench}$

</details>


### [6] [Quadratic Programming-Based Posture Manipulation and Thrust-vectoring for Agile Dynamic Walking on Narrow Pathways](https://arxiv.org/abs/2507.23203)
*Chenghao Wang,Eric Sihite,Kaushik Venkatesh Krishnamurthy,Shreyansh Pitroda,Adarsh Salagame,Alireza Ramezani,Morteza Gharib*

Main category: cs.RO

TL;DR: 本文研究了四足机器人Husky Beta在窄路径行走中的稳定性，通过推进器辅助控制实现动态平衡。


<details>
  <summary>Details</summary>
Motivation: 提升四足机器人在复杂环境中的稳定性和运动可塑性，尤其是窄路径行走和动态平衡。

Method: 基于质心动力学模型设计控制器，结合推进器和足部接触力输入，使用QP求解器和模型预测控制框架。

Result: 模拟研究表明，推进器辅助能有效提升机器人在窄路径行走和侧向推力恢复中的稳定性。

Conclusion: 推进器辅助控制是提升四足机器人动态平衡和复杂环境适应性的有效方法。

Abstract: There has been significant advancement in legged robot's agility where they
can show impressive acrobatic maneuvers, such as parkour. These maneuvers rely
heavily on posture manipulation. To expand the stability and locomotion
plasticity, we use the multi-modal ability in our legged-aerial platform, the
Husky Beta, to perform thruster-assisted walking. This robot has thrusters on
each of its sagittal knee joints which can be used to stabilize its frontal
dynamic as it walks. In this work, we perform a simulation study of quadruped
narrow-path walking with Husky $\beta$, where the robot will utilize its
thrusters to stably walk on a narrow path. The controller is designed based on
a centroidal dynamics model with thruster and foot ground contact forces as
inputs. These inputs are regulated using a QP solver to be used in a model
predictive control framework. In addition to narrow-path walking, we also
perform a lateral push-recovery simulation to study how the thrusters can be
used to stabilize the frontal dynamics.

</details>


### [7] [Simulation-based planning of Motion Sequences for Automated Procedure Optimization in Multi-Robot Assembly Cells](https://arxiv.org/abs/2507.23270)
*Loris Schneider,Marc Ungen,Elias Huber,Jan-Felix Klein*

Main category: cs.RO

TL;DR: 提出了一种基于仿真的方法，用于优化可重构多机器人单元的运动序列，以减少装配时间。


<details>
  <summary>Details</summary>
Motivation: 可重构多机器人单元能应对波动的装配需求，但其配置的反复规划带来了新的挑战，尤其是如何生成优化的、协调的多机器人运动序列。

Method: 将装配步骤分为任务相关的核心操作和连接遍历操作，核心操作固定，遍历操作可优化。采用分解式运动规划策略，结合采样启发式、树搜索和无梯度优化等技术。

Result: 提出的方法生成了高效且无碰撞的多机器人装配流程，性能优于基于分散式机器人个体运动规划的基线方法。

Conclusion: 通过仿真实验验证了该方法的有效性，为多机器人装配提供了优化解决方案。

Abstract: Reconfigurable multi-robot cells offer a promising approach to meet
fluctuating assembly demands. However, the recurrent planning of their
configurations introduces new challenges, particularly in generating optimized,
coordinated multi-robot motion sequences that minimize the assembly duration.
This work presents a simulation-based method for generating such optimized
sequences. The approach separates assembly steps into task-related core
operations and connecting traverse operations. While core operations are
constrained and predetermined, traverse operations offer substantial
optimization potential. Scheduling the core operations is formulated as an
optimization problem, requiring feasible traverse operations to be integrated
using a decomposition-based motion planning strategy. Several solution
techniques are explored, including a sampling heuristic, tree-based search and
gradient-free optimization. For motion planning, a decomposition method is
proposed that identifies specific areas in the schedule, which can be solved
independently with modified centralized path planning algorithms. The proposed
method generates efficient and collision-free multi-robot assembly procedures
that outperform a baseline relying on decentralized, robot-individual motion
planning. Its effectiveness is demonstrated through simulation experiments.

</details>


### [8] [GSFusion:Globally Optimized LiDAR-Inertial-Visual Mapping for Gaussian Splatting](https://arxiv.org/abs/2507.23273)
*Jaeseok Park,Chanoh Park,Minsu Kim,Soohwan Kim*

Main category: cs.RO

TL;DR: GSFusion是一种结合LiDAR、惯性和视觉的在线映射系统，解决了3D高斯泼溅（3DGS）在稀疏数据和全局对齐方面的挑战，提升了渲染质量和建图效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于相机传感器（包括RGB-D）的3DGS方法存在计算负载高、在低纹理或光照差环境中失效、操作范围短等问题，而LiDAR虽为替代方案，但其与3DGS结合时面临全局对齐和高优化时间的挑战。

Method: GSFusion通过全局位姿图优化中的surfel-to-surfel约束确保高精度地图一致性，采用像素感知的高斯初始化策略处理稀疏数据，并使用有界sigmoid约束防止高斯增长失控。

Result: 在公开和自有数据集上的实验表明，GSFusion在渲染质量和建图效率上优于现有3DGS SLAM系统。

Conclusion: GSFusion通过融合LiDAR、惯性和视觉数据，有效解决了3DGS在稀疏数据和全局对齐中的问题，实现了高质量的实时映射。

Abstract: While 3D Gaussian Splatting (3DGS) has revolutionized photorealistic mapping,
conventional approaches based on camera sensor, even RGB-D, suffer from
fundamental limitations such as high computational load, failure in
environments with poor texture or illumination, and short operational ranges.
LiDAR emerges as a robust alternative, but its integration with 3DGS introduces
new challenges, such as the need for exceptional global alignment for
photorealistic quality and prolonged optimization times caused by sparse data.
To address these challenges, we propose GSFusion, an online
LiDAR-Inertial-Visual mapping system that ensures high-precision map
consistency through a surfel-to-surfel constraint in the global pose-graph
optimization. To handle sparse data, our system employs a pixel-aware Gaussian
initialization strategy for efficient representation and a bounded sigmoid
constraint to prevent uncontrolled Gaussian growth. Experiments on public and
our datasets demonstrate our system outperforms existing 3DGS SLAM systems in
terms of rendering quality and map-building efficiency.

</details>


### [9] [Whisker-based Active Tactile Perception for Contour Reconstruction](https://arxiv.org/abs/2507.23305)
*Yixuan Dang,Qinyang Xu,Yu Zhang,Xiangtong Yao,Liding Zhang,Zhenshan Bing,Florian Roehrbein,Alois Knoll*

Main category: cs.RO

TL;DR: 论文提出了一种基于磁感应的触须传感器及其主动控制策略，用于精确跟踪物体轮廓并重建表面形状。


<details>
  <summary>Details</summary>
Motivation: 触须传感器在机器人感知中缺乏基于直接接触信息的主动控制，导致难以精确重建物体轮廓。

Method: 设计了磁感应触须传感器，利用梯度下降和贝叶斯滤波提取接触点位置，并通过B样条曲线预测表面曲率以优化传感器姿态。

Result: 算法能有效跟踪物体并实现亚毫米级精度的轮廓重建。

Conclusion: 通过仿真和实物实验验证了方法的有效性，适用于机器人触觉感知任务。

Abstract: Perception using whisker-inspired tactile sensors currently faces a major
challenge: the lack of active control in robots based on direct contact
information from the whisker. To accurately reconstruct object contours, it is
crucial for the whisker sensor to continuously follow and maintain an
appropriate relative touch pose on the surface. This is especially important
for localization based on tip contact, which has a low tolerance for sharp
surfaces and must avoid slipping into tangential contact. In this paper, we
first construct a magnetically transduced whisker sensor featuring a compact
and robust suspension system composed of three flexible spiral arms. We develop
a method that leverages a characterized whisker deflection profile to directly
extract the tip contact position using gradient descent, with a Bayesian filter
applied to reduce fluctuations. We then propose an active motion control policy
to maintain the optimal relative pose of the whisker sensor against the object
surface. A B-Spline curve is employed to predict the local surface curvature
and determine the sensor orientation. Results demonstrate that our algorithm
can effectively track objects and reconstruct contours with sub-millimeter
accuracy. Finally, we validate the method in simulations and real-world
experiments where a robot arm drives the whisker sensor to follow the surfaces
of three different objects.

</details>


### [10] [Assessing the Alignment of Automated Vehicle Decisions with Human Reasons](https://arxiv.org/abs/2507.23324)
*Lucas Elbert Suryana,Saeed Rahmani,Simeon Craig Calvert,Arkady Zgonnikov,Bart van Arem*

Main category: cs.RO

TL;DR: 论文提出了一种基于原因的轨迹评估框架，用于解决自动驾驶车辆在伦理挑战场景中的决策问题，通过量化人类代理的原因（如法规遵从性）来评估候选轨迹的匹配度。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在常规驾驶场景中常面临伦理冲突（如法规与舒适性的权衡），现有规划系统依赖刚性规则，难以平衡这些冲突。

Method: 提出一种基于原因的轨迹评估框架，量化人类代理的原因，并通过可调权重和平衡函数评估轨迹的伦理对齐性。

Result: 通过真实世界启发的超车场景，展示了框架如何揭示法规、效率和舒适性之间的冲突。

Conclusion: 该框架为评估日常场景中的伦理对齐提供了透明工具，是实现自动驾驶车辆有意义人类控制（MHC）的实用步骤。

Abstract: A key challenge in deploying automated vehicles (AVs) is ensuring they make
appropriate decisions in ethically challenging everyday driving situations.
While much attention has been paid to rare, high-stakes dilemmas such as
trolley problems, similar tensions also arise in routine scenarios, such as
navigating empty intersections, where multiple human considerations, including
legality and comfort, often conflict. Current AV planning systems typically
rely on rigid rules, which struggle to balance these competing considerations
and can lead to behaviour that misaligns with human expectations. This paper
proposes a novel reasons-based trajectory evaluation framework that
operationalises the tracking condition of Meaningful Human Control (MHC). The
framework models the reasons of human agents, such as regulatory compliance, as
quantifiable functions and evaluates how well candidate AV trajectories align
with these reasons. By assigning adjustable weights to agent priorities and
integrating a balance function to discourage the exclusion of any agent, the
framework supports interpretable decision evaluation. Through a
real-world-inspired overtaking scenario, we show how this approach reveals
tensions, for instance between regulatory compliance, efficiency, and comfort.
The framework functions as a modular evaluation layer over existing planning
algorithms. It offers a transparent tool for assessing ethical alignment in
everyday scenarios and provides a practical step toward implementing MHC in
real-world AV deployment.

</details>


### [11] [Learning to Drift with Individual Wheel Drive: Maneuvering Autonomous Vehicle at the Handling Limits](https://arxiv.org/abs/2507.23339)
*Yihan Zhou,Yiwen Lu,Bo Yang,Jiayun Li,Yilin Mo*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的框架，通过GPU加速并行仿真和系统领域随机化，解决了仿真到现实的差距，实现了精确的漂移控制。


<details>
  <summary>Details</summary>
Motivation: 漂移控制在紧急情况下至关重要，但现有强化学习方法在仿真到现实转移时表现不佳。

Method: 采用GPU加速并行仿真和系统领域随机化，结合自定义的1/10比例独立轮驱动RC车平台。

Result: 在多种场景下实现了精确的轨迹跟踪和可控的侧滑角，仿真和现实环境均表现良好。

Conclusion: 该框架有效解决了仿真到现实的差距，为漂移控制提供了实用解决方案。

Abstract: Drifting, characterized by controlled vehicle motion at high sideslip angles,
is crucial for safely handling emergency scenarios at the friction limits.
While recent reinforcement learning approaches show promise for drifting
control, they struggle with the significant simulation-to-reality gap, as
policies that perform well in simulation often fail when transferred to
physical systems. In this paper, we present a reinforcement learning framework
with GPU-accelerated parallel simulation and systematic domain randomization
that effectively bridges the gap. The proposed approach is validated on both
simulation and a custom-designed and open-sourced 1/10 scale Individual Wheel
Drive (IWD) RC car platform featuring independent wheel speed control.
Experiments across various scenarios from steady-state circular drifting to
direction transitions and variable-curvature path following demonstrate that
our approach achieves precise trajectory tracking while maintaining controlled
sideslip angles throughout complex maneuvers in both simulated and real-world
environments.

</details>


### [12] [Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile Robots in Agricultural Applications](https://arxiv.org/abs/2507.23350)
*Mahmoud Ghorab,Matthias Lorenzen*

Main category: cs.RO

TL;DR: 论文提出了一种结合DTSP全局路径规划和NMPC局部控制的导航框架，用于农业环境中自主移动机器人的高效导航。


<details>
  <summary>Details</summary>
Motivation: 农业环境中需要自主移动机器人高效导航，同时满足路径最短和曲率约束以避免土壤和植被破坏。

Method: 结合Dubins旅行商问题（DTSP）的全局路径规划和非线性模型预测控制（NMPC）的局部路径规划与控制。

Result: 仿真分析显示，该框架生成的路径更平滑、更短，比解耦方法减少了约16%的路径长度，NMPC控制器能准确引导机器人到达目标点。

Conclusion: 该框架在农业环境中具有高效自主导航的潜力。

Abstract: There is a growing demand for autonomous mobile robots capable of navigating
unstructured agricultural environments. Tasks such as weed control in meadows
require efficient path planning through an unordered set of coordinates while
minimizing travel distance and adhering to curvature constraints to prevent
soil damage and protect vegetation. This paper presents an integrated
navigation framework combining a global path planner based on the Dubins
Traveling Salesman Problem (DTSP) with a Nonlinear Model Predictive Control
(NMPC) strategy for local path planning and control. The DTSP generates a
minimum-length, curvature-constrained path that efficiently visits all targets,
while the NMPC leverages this path to compute control signals to accurately
reach each waypoint. The system's performance was validated through comparative
simulation analysis on real-world field datasets, demonstrating that the
coupled DTSP-based planner produced smoother and shorter paths, with a
reduction of about 16% in the provided scenario, compared to decoupled methods.
Based thereon, the NMPC controller effectively steered the robot to the desired
waypoints, while locally optimizing the trajectory and ensuring adherence to
constraints. These findings demonstrate the potential of the proposed framework
for efficient autonomous navigation in agricultural environments.

</details>


### [13] [Quantifying and Visualizing Sim-to-Real Gaps: Physics-Guided Regularization for Reproducibility](https://arxiv.org/abs/2507.23445)
*Yuta Kawachi*

Main category: cs.RO

TL;DR: 论文提出了一种基于物理引导增益正则化的方法，通过测量机器人的有效比例增益并惩罚神经控制器在训练中的偏差，结合参数条件化，成功缩小了仿真到现实的差距。


<details>
  <summary>Details</summary>
Motivation: 传统域随机化方法在仿真与现实差距较大时失效，尤其是对高齿轮比机器人。论文受PID控制器启发，试图通过增益正则化和参数条件化解决这一问题。

Method: 通过实际实验测量机器人的有效比例增益，并在训练中惩罚神经控制器的局部输入输出敏感度偏差。同时，控制器根据当前设备参数进行条件化。

Result: 在带有110:1齿轮箱的两轮平衡机器人上，增益正则化和参数条件化的RNN在硬件中的角度稳定时间与仿真结果接近，而纯域随机化策略则表现出持续振荡和显著差距。

Conclusion: 该方法为缩小仿真与现实差距提供了一种轻量级、可复现的框架，适用于低成本机器人硬件。

Abstract: Simulation-to-real transfer using domain randomization for robot control
often relies on low-gear-ratio, backdrivable actuators, but these approaches
break down when the sim-to-real gap widens. Inspired by the traditional PID
controller, we reinterpret its gains as surrogates for complex, unmodeled plant
dynamics. We then introduce a physics-guided gain regularization scheme that
measures a robot's effective proportional gains via simple real-world
experiments. Then, we penalize any deviation of a neural controller's local
input-output sensitivities from these values during training. To avoid the
overly conservative bias of naive domain randomization, we also condition the
controller on the current plant parameters. On an off-the-shelf two-wheeled
balancing robot with a 110:1 gearbox, our gain-regularized,
parameter-conditioned RNN achieves angular settling times in hardware that
closely match simulation. At the same time, a purely domain-randomized policy
exhibits persistent oscillations and a substantial sim-to-real gap. These
results demonstrate a lightweight, reproducible framework for closing
sim-to-real gaps on affordable robotic hardware.

</details>


### [14] [H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation](https://arxiv.org/abs/2507.23523)
*Hongzhe Bi,Lingxuan Wu,Tianwei Lin,Hengkai Tan,Zhizhong Su,Hang Su,Jun Zhu*

Main category: cs.RO

TL;DR: H-RDT利用人类操作数据增强机器人操作能力，通过两阶段训练（人类数据预训练和机器人数据微调），在仿真和真实实验中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人模仿学习中大规模高质量演示数据稀缺的问题，利用人类操作数据的丰富行为先验提升机器人策略学习。

Method: 采用两阶段训练：1）大规模人类操作数据预训练；2）机器人数据微调，结合扩散变换器架构和流匹配技术。

Result: H-RDT在仿真和真实实验中分别比从头训练提升13.9%和40.5%，优于Pi0和RDT等现有方法。

Conclusion: 人类操作数据可作为学习机器人操作策略的强大基础，H-RDT验证了这一假设。

Abstract: Imitation learning for robotic manipulation faces a fundamental challenge:
the scarcity of large-scale, high-quality robot demonstration data. Recent
robotic foundation models often pre-train on cross-embodiment robot datasets to
increase data scale, while they face significant limitations as the diverse
morphologies and action spaces across different robot embodiments make unified
training challenging. In this paper, we present H-RDT (Human to Robotics
Diffusion Transformer), a novel approach that leverages human manipulation data
to enhance robot manipulation capabilities. Our key insight is that large-scale
egocentric human manipulation videos with paired 3D hand pose annotations
provide rich behavioral priors that capture natural manipulation strategies and
can benefit robotic policy learning. We introduce a two-stage training
paradigm: (1) pre-training on large-scale egocentric human manipulation data,
and (2) cross-embodiment fine-tuning on robot-specific data with modular action
encoders and decoders. Built on a diffusion transformer architecture with 2B
parameters, H-RDT uses flow matching to model complex action distributions.
Extensive evaluations encompassing both simulation and real-world experiments,
single-task and multitask scenarios, as well as few-shot learning and
robustness assessments, demonstrate that H-RDT outperforms training from
scratch and existing state-of-the-art methods, including Pi0 and RDT, achieving
significant improvements of 13.9% and 40.5% over training from scratch in
simulation and real-world experiments, respectively. The results validate our
core hypothesis that human manipulation data can serve as a powerful foundation
for learning bimanual robotic manipulation policies.

</details>


### [15] [A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving](https://arxiv.org/abs/2507.23540)
*Yi Zhang,Erik Leo Haß,Kuo-Yi Chao,Nenad Petrovic,Yinglei Song,Chengdong Wu,Alois Knoll*

Main category: cs.RO

TL;DR: 提出了一种统一的感知-语言-动作（PLA）框架，结合多传感器融合和语言模型，提升自动驾驶的适应性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶系统在复杂开放环境中的适应性、鲁棒性和可解释性问题。

Method: 采用多传感器融合（相机、LiDAR、雷达）和GPT-4.1增强的视觉-语言-动作（VLA）架构。

Result: 在城市交叉路口场景中表现出优越的轨迹跟踪、速度预测和自适应规划能力。

Conclusion: 语言增强的认知框架有望提升自动驾驶的安全性、可解释性和可扩展性。

Abstract: Autonomous driving systems face significant challenges in achieving
human-like adaptability, robustness, and interpretability in complex,
open-world environments. These challenges stem from fragmented architectures,
limited generalization to novel scenarios, and insufficient semantic extraction
from perception. To address these limitations, we propose a unified
Perception-Language-Action (PLA) framework that integrates multi-sensor fusion
(cameras, LiDAR, radar) with a large language model (LLM)-augmented
Vision-Language-Action (VLA) architecture, specifically a GPT-4.1-powered
reasoning core. This framework unifies low-level sensory processing with
high-level contextual reasoning, tightly coupling perception with natural
language-based semantic understanding and decision-making to enable
context-aware, explainable, and safety-bounded autonomous driving. Evaluations
on an urban intersection scenario with a construction zone demonstrate superior
performance in trajectory tracking, speed prediction, and adaptive planning.
The results highlight the potential of language-augmented cognitive frameworks
for advancing the safety, interpretability, and scalability of autonomous
driving systems.

</details>


### [16] [User Experience Estimation in Human-Robot Interaction Via Multi-Instance Learning of Multimodal Social Signals](https://arxiv.org/abs/2507.23544)
*Ryo Miyoshi,Yuki Okafuji,Takuya Iwamoto,Junya Nakanishi,Jun Baba*

Main category: cs.RO

TL;DR: 提出了一种基于多模态社交信号（面部表情和语音）的Transformer模型，用于评估人机交互中的用户体验（UX），并通过多实例学习框架捕捉短期和长期交互模式，优于传统方法和人类评估者。


<details>
  <summary>Details</summary>
Motivation: 社会机器人需根据用户状态调整行为，而现有UX评估方法多关注单一维度（如情感或参与度），缺乏对多维度UX的综合评估。

Method: 构建UX数据集，开发基于Transformer的模型，利用面部表情和语音信号，结合多实例学习框架捕捉交互的时空动态。

Result: 实验表明，该方法在UX评估上优于第三方人类评估者和传统方法。

Conclusion: 多模态信号和时空动态捕捉能更全面地评估UX，为机器人行为调整提供更准确的依据。

Abstract: In recent years, the demand for social robots has grown, requiring them to
adapt their behaviors based on users' states. Accurately assessing user
experience (UX) in human-robot interaction (HRI) is crucial for achieving this
adaptability. UX is a multi-faceted measure encompassing aspects such as
sentiment and engagement, yet existing methods often focus on these
individually. This study proposes a UX estimation method for HRI by leveraging
multimodal social signals. We construct a UX dataset and develop a
Transformer-based model that utilizes facial expressions and voice for
estimation. Unlike conventional models that rely on momentary observations, our
approach captures both short- and long-term interaction patterns using a
multi-instance learning framework. This enables the model to capture temporal
dynamics in UX, providing a more holistic representation. Experimental results
demonstrate that our method outperforms third-party human evaluators in UX
estimation.

</details>


### [17] [Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study](https://arxiv.org/abs/2507.23589)
*Kai Goebel,Patrik Zips*

Main category: cs.RO

TL;DR: 本文系统评估了当前先进语言模型在机器人任务规划中的表现，发现其在简单任务中表现良好，但在复杂场景中仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在生成结构化、可执行机器人任务规划中的潜力与局限性。

Method: 直接使用PDDL文件和问题文件提示多种语言模型，并与Fast Downward规划器在多个基准测试中比较性能。

Result: 模型在简单任务中表现良好，但在复杂场景（如资源管理、状态跟踪和约束遵守）中表现不佳。

Conclusion: 未来研究应结合语言模型与传统规划器，以提高机器人规划的可靠性和扩展性。

Abstract: Recent advancements in Large Language Models have sparked interest in their
potential for robotic task planning. While these models demonstrate strong
generative capabilities, their effectiveness in producing structured and
executable plans remains uncertain. This paper presents a systematic evaluation
of a broad spectrum of current state of the art language models, each directly
prompted using Planning Domain Definition Language domain and problem files,
and compares their planning performance with the Fast Downward planner across a
variety of benchmarks. In addition to measuring success rates, we assess how
faithfully the generated plans translate into sequences of actions that can
actually be executed, identifying both strengths and limitations of using these
models in this setting. Our findings show that while the models perform well on
simpler planning tasks, they continue to struggle with more complex scenarios
that require precise resource management, consistent state tracking, and strict
constraint compliance. These results underscore fundamental challenges in
applying language models to robotic planning in real world environments. By
outlining the gaps that emerge during execution, we aim to guide future
research toward combined approaches that integrate language models with
classical planners in order to enhance the reliability and scalability of
planning in autonomous robotics.

</details>


### [18] [Human-Exoskeleton Kinematic Calibration to Improve Hand Tracking for Dexterous Teleoperation](https://arxiv.org/abs/2507.23592)
*Haiyun Zhang,Stefano Dalla Gasperina,Saad N. Yousaf,Toshimitsu Tsuboi,Tetsuya Narita,Ashish D. Deshpande*

Main category: cs.RO

TL;DR: 提出了一种基于冗余关节传感和残差加权优化的手部外骨骼标定框架，显著提高了跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 解决手部外骨骼因用户解剖差异和穿戴不一致导致的跟踪误差问题。

Method: 使用冗余关节传感和残差加权优化策略估计虚拟链接参数，并通过运动捕捉数据调优成本函数权重。

Result: 在七名受试者中，关节和指尖跟踪误差显著降低，运动保真度提高。

Conclusion: 该框架适用于闭环运动学和最小传感的外骨骼设计，为高保真遥操作和示范学习应用奠定了基础。

Abstract: Hand exoskeletons are critical tools for dexterous teleoperation and
immersive manipulation interfaces, but achieving accurate hand tracking remains
a challenge due to user-specific anatomical variability and donning
inconsistencies. These issues lead to kinematic misalignments that degrade
tracking performance and limit applicability in precision tasks. We propose a
subject-specific calibration framework for exoskeleton-based hand tracking that
uses redundant joint sensing and a residual-weighted optimization strategy to
estimate virtual link parameters. Implemented on the Maestro exoskeleton, our
method improves joint angle and fingertip position estimation across users with
varying hand geometries. We introduce a data-driven approach to empirically
tune cost function weights using motion capture ground truth, enabling more
accurate and consistent calibration across participants. Quantitative results
from seven subjects show substantial reductions in joint and fingertip tracking
errors compared to uncalibrated and evenly weighted models. Qualitative
visualizations using a Unity-based virtual hand further confirm improvements in
motion fidelity. The proposed framework generalizes across exoskeleton designs
with closed-loop kinematics and minimal sensing, and lays the foundation for
high-fidelity teleoperation and learning-from-demonstration applications.

</details>


### [19] [DRACo-SLAM2: Distributed Robust Acoustic Communication-efficient SLAM for Imaging Sonar EquippedUnderwater Robot Teams with Object Graph Matching](https://arxiv.org/abs/2507.23629)
*Yewei Huang,John McConnell,Xi Lin,Brendan Englot*

Main category: cs.RO

TL;DR: DRACo-SLAM2是一个用于水下机器人团队的多波束成像声纳分布式SLAM框架，通过对象图表示和匹配优化了闭环检测效率。


<details>
  <summary>Details</summary>
Motivation: 改进原有DRACo-SLAM框架，适应水下环境需求，解决多机器人闭环检测中的几何信息依赖和误差共享问题。

Method: 引入对象图表示声纳地图，提出增量GCM方法替代PCM，优化邻近闭环场景的配准误差处理。

Result: 在仿真和真实数据集上验证了方法的有效性。

Conclusion: DRACo-SLAM2通过对象图和增量GCM显著提升了水下多机器人SLAM的性能。

Abstract: We present DRACo-SLAM2, a distributed SLAM framework for underwater robot
teams equipped with multibeam imaging sonar. This framework improves upon the
original DRACo-SLAM by introducing a novel representation of sonar maps as
object graphs and utilizing object graph matching to achieve time-efficient
inter-robot loop closure detection without relying on prior geometric
information. To better-accommodate the needs and characteristics of underwater
scan matching, we propose incremental Group-wise Consistent Measurement Set
Maximization (GCM), a modification of Pairwise Consistent Measurement Set
Maximization (PCM), which effectively handles scenarios where nearby
inter-robot loop closures share similar registration errors. The proposed
approach is validated through extensive comparative analyses on simulated and
real-world datasets.

</details>


### [20] [DuLoc: Life-Long Dual-Layer Localization in Changing and Dynamic Expansive Scenarios](https://arxiv.org/abs/2507.23660)
*Haoxuan Jiang,Peicong Qian,Yusen Xie,Xiaocong Li,Ming Liu,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出了一种名为DuLoc的LiDAR定位方法，结合LiDAR-惯性里程计与离线地图定位，通过恒定速度运动模型减少噪声，实现了在动态环境中的高精度定位。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR定位方法在重复性、精度和环境适应性方面存在不足，尤其是在长期环境变化下表现不佳。

Method: 提出DuLoc方法，紧密耦合LiDAR-惯性里程计与离线地图定位，引入恒定速度运动模型，并整合全局地图与实时局部地图。

Result: 在超大规模港口环境中进行了2856小时的实验，结果表明DuLoc优于其他先进LiDAR定位系统。

Conclusion: DuLoc在动态和大规模室外环境中表现出卓越的鲁棒性和准确性。

Abstract: LiDAR-based localization serves as a critical component in autonomous
systems, yet existing approaches face persistent challenges in balancing
repeatability, accuracy, and environmental adaptability. Traditional point
cloud registration methods relying solely on offline maps often exhibit limited
robustness against long-term environmental changes, leading to localization
drift and reliability degradation in dynamic real-world scenarios. To address
these challenges, this paper proposes DuLoc, a robust and accurate localization
method that tightly couples LiDAR-inertial odometry with offline map-based
localization, incorporating a constant-velocity motion model to mitigate
outlier noise in real-world scenarios. Specifically, we develop a LiDAR-based
localization framework that seamlessly integrates a prior global map with
dynamic real-time local maps, enabling robust localization in unbounded and
changing environments. Extensive real-world experiments in ultra unbounded port
that involve 2,856 hours of operational data across 32 Intelligent Guided
Vehicles (IGVs) are conducted and reported in this study. The results attained
demonstrate that our system outperforms other state-of-the-art LiDAR
localization systems in large-scale changing outdoor environments.

</details>


### [21] [Stereo 3D Gaussian Splatting SLAM for Outdoor Urban Scenes](https://arxiv.org/abs/2507.23677)
*Xiaohan Li,Ziren Gong,Fabio Tosi,Matteo Poggi,Stefano Mattoccia,Dong Liu,Jun Wu*

Main category: cs.RO

TL;DR: BGS-SLAM是首个基于双目RGB图像的3D高斯泼溅SLAM系统，专为户外场景设计，无需LiDAR或主动传感器，通过预训练的深度立体网络和多损失策略优化3D高斯表示。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS-SLAM系统主要针对室内环境并依赖主动深度传感器，缺乏适用于大规模户外场景的解决方案。

Method: 使用双目RGB图像，结合预训练的深度立体网络估计深度，并通过多损失策略优化3D高斯表示。

Result: 在多个数据集上验证，BGS-SLAM在复杂户外环境中表现出更高的跟踪精度和建图性能。

Conclusion: BGS-SLAM填补了户外3DGS-SLAM的空白，展示了无需主动传感器的优越性能。

Abstract: 3D Gaussian Splatting (3DGS) has recently gained popularity in SLAM
applications due to its fast rendering and high-fidelity representation.
However, existing 3DGS-SLAM systems have predominantly focused on indoor
environments and relied on active depth sensors, leaving a gap for large-scale
outdoor applications. We present BGS-SLAM, the first binocular 3D Gaussian
Splatting SLAM system designed for outdoor scenarios. Our approach uses only
RGB stereo pairs without requiring LiDAR or active sensors. BGS-SLAM leverages
depth estimates from pre-trained deep stereo networks to guide 3D Gaussian
optimization with a multi-loss strategy enhancing both geometric consistency
and visual quality. Experiments on multiple datasets demonstrate that BGS-SLAM
achieves superior tracking accuracy and mapping performance compared to other
3DGS-based solutions in complex outdoor environments.

</details>


### [22] [villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models](https://arxiv.org/abs/2507.23682)
*Xiaoyu Chen,Hangxing Wei,Pushi Zhang,Chuheng Zhang,Kaixin Wang,Yanjiang Guo,Rushuai Yang,Yucen Wang,Xinquan Xiao,Li Zhao,Jianyu Chen,Jiang Bian*

Main category: cs.RO

TL;DR: ViLLA-X是一种新型视觉-语言-潜在动作框架，通过改进潜在动作的学习和整合方式，提升了机器人操作策略的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何更好地将潜在动作（视觉变化的抽象表示）整合到视觉-语言-动作模型中，以提升机器人操作策略的泛化性。

Method: 提出ViLLA-X框架，改进潜在动作的学习和预训练整合方式。

Result: 在仿真环境（SIMPLER和LIBERO）和真实机器人（夹爪和灵巧手操作）中表现优异。

Conclusion: ViLLA-X为未来研究提供了坚实基础，展示了潜在动作模型在机器人操作中的潜力。

Abstract: Visual-Language-Action (VLA) models have emerged as a popular paradigm for
learning robot manipulation policies that can follow language instructions and
generalize to novel scenarios. Recent work has begun to explore the
incorporation of latent actions, an abstract representation of visual change
between two frames, into VLA pre-training. In this paper, we introduce villa-X,
a novel Visual-Language-Latent-Action (ViLLA) framework that advances latent
action modeling for learning generalizable robot manipulation policies. Our
approach improves both how latent actions are learned and how they are
incorporated into VLA pre-training. Together, these contributions enable
villa-X to achieve superior performance across simulated environments including
SIMPLER and LIBERO, as well as on two real-world robot setups including gripper
and dexterous hand manipulation. We believe the ViLLA paradigm holds
significant promise, and that our villa-X provides a strong foundation for
future research.

</details>


### [23] [Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents](https://arxiv.org/abs/2507.23698)
*Shaofei Cai,Zhancun Mu,Haiwen Xia,Bowei Zhang,Anji Liu,Yitao Liang*

Main category: cs.RO

TL;DR: 本文探讨了RL在视觉运动代理中的泛化能力，通过在Minecraft中实现零样本泛化，展示了RL在3D环境中的潜力。


<details>
  <summary>Details</summary>
Motivation: RL在语言建模中表现优异，但在视觉运动代理中尚未完全实现泛化能力，主要挑战是模型容易过拟合特定任务或环境。

Method: 提出跨视图目标规范作为统一的多任务目标空间，并在Minecraft中自动化任务合成以支持大规模多任务RL训练。

Result: 实验表明RL将交互成功率提升4倍，并实现零样本泛化，包括在真实环境中。

Conclusion: RL在3D模拟环境中的训练潜力巨大，尤其是支持大规模任务生成的环境，可显著提升视觉运动代理的空间推理能力。

Abstract: While Reinforcement Learning (RL) has achieved remarkable success in language
modeling, its triumph hasn't yet fully translated to visuomotor agents. A
primary challenge in RL models is their tendency to overfit specific tasks or
environments, thereby hindering the acquisition of generalizable behaviors
across diverse settings. This paper provides a preliminary answer to this
challenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can
achieve zero-shot generalization to unseen worlds. Specifically, we explore
RL's potential to enhance generalizable spatial reasoning and interaction
capabilities in 3D worlds. To address challenges in multi-task RL
representation, we analyze and establish cross-view goal specification as a
unified multi-task goal space for visuomotor policies. Furthermore, to overcome
the significant bottleneck of manual task design, we propose automated task
synthesis within the highly customizable Minecraft environment for large-scale
multi-task RL training, and we construct an efficient distributed RL framework
to support this. Experimental results show RL significantly boosts interaction
success rates by $4\times$ and enables zero-shot generalization of spatial
reasoning across diverse environments, including real-world settings. Our
findings underscore the immense potential of RL training in 3D simulated
environments, especially those amenable to large-scale task generation, for
significantly advancing visuomotor agents' spatial reasoning.

</details>


### [24] [Design of a bioinspired robophysical antenna for insect-scale tactile perception and navigation](https://arxiv.org/abs/2507.23719)
*Parker McDonnell,Lingsheng Meng,Hari Krishna Hariprasad,Alexander Hedrick,Eduardo Miscles,Samuel Gilinsky,Jean-Michel Mongeau,Kaushik Jayaram*

Main category: cs.RO

TL;DR: 研究人员受美洲蟑螂触角的启发，开发了一种名为CITRAS的轻量化、低功耗触觉传感器，用于微型机器人，实现了高精度的环境感知和导航功能。


<details>
  <summary>Details</summary>
Motivation: 微型机器人在复杂环境中的自主感知和导航受限于现有传感器的尺寸、重量和功耗，而生物触角的高效触觉感知为解决这一问题提供了灵感。

Method: 通过仿生设计，开发了一种多段式、柔性的层压传感器（CITRAS），内置电容式角度传感器，能够在被动弯曲时精确测量环境刺激。

Result: CITRAS在静态和动态弯曲下的角度测量误差分别为0.79度和3.58度，并能预测距离、估计间隙宽度和区分表面纹理，误差率低。

Conclusion: CITRAS为微型机器人提供了多功能触觉感知能力，有望提升其在复杂环境中的自主探索和避障能力。

Abstract: The American cockroach (Periplaneta americana) uses its soft antennae to
guide decision making by extracting rich tactile information from tens of
thousands of distributed mechanosensors. Although tactile sensors enable
robust, autonomous perception and navigation in natural systems, replicating
these capabilities in insect-scale robots remains challenging due to stringent
size, weight, and power constraints that limit existing sensor technologies. To
overcome these limitations, we introduce CITRAS (Cockroach Inspired Tactile
Robotic Antenna Sensor), a bioinspired, multi-segmented, compliant laminate
sensor with embedded capacitive angle sensors. CITRAS is compact (73.7x15.6x2.1
mm), lightweight (491 mg), and low-power (32 mW), enabling seamless integration
with miniature robotic platforms. The segmented compliant structure passively
bends in response to environmental stimuli, achieving accurate hinge angle
measurements with maximum errors of just 0.79 degree (quasistatic bending) and
3.58 degree (dynamic bending). Experimental evaluations demonstrate CITRAS'
multifunctional tactile perception capabilities: predicting base-to-tip
distances with 7.75 % error, estimating environmental gap widths with 6.73 %
error, and distinguishing surface textures through differential sensor
response. The future integration of this bioinspired tactile antenna in
insect-scale robots addresses critical sensing gaps, promising enhanced
autonomous exploration, obstacle avoidance, and environmental mapping in
complex, confined environments.

</details>


### [25] [Distributed AI Agents for Cognitive Underwater Robot Autonomy](https://arxiv.org/abs/2507.23735)
*Markus Buchholz,Ignacio Carlucho,Michele Grimaldi,Yvan R. Petillot*

Main category: cs.RO

TL;DR: UROSA是一种基于ROS 2框架的分布式AI架构，通过多模态感知、自适应推理和动态任务规划，提升水下机器人的认知自主性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂不可预测环境中机器人认知自主性的挑战。

Method: 利用分布式大型语言模型AI代理，结合检索增强生成、强化学习和动态ROS 2节点生成。

Result: 在仿真和实际部署中表现出优于传统规则架构的适应性和可靠性。

Conclusion: UROSA不仅推动水下自主性发展，还为通用认知机器人框架提供了可扩展、安全的解决方案。

Abstract: Achieving robust cognitive autonomy in robots navigating complex,
unpredictable environments remains a fundamental challenge in robotics. This
paper presents Underwater Robot Self-Organizing Autonomy (UROSA), a
groundbreaking architecture leveraging distributed Large Language Model AI
agents integrated within the Robot Operating System 2 (ROS 2) framework to
enable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA
decentralises cognition into specialised AI agents responsible for multimodal
perception, adaptive reasoning, dynamic mission planning, and real-time
decision-making. Central innovations include flexible agents dynamically
adapting their roles, retrieval-augmented generation utilising vector databases
for efficient knowledge management, reinforcement learning-driven behavioural
optimisation, and autonomous on-the-fly ROS 2 node generation for runtime
functional extensibility. Extensive empirical validation demonstrates UROSA's
promising adaptability and reliability through realistic underwater missions in
simulation and real-world deployments, showing significant advantages over
traditional rule-based architectures in handling unforeseen scenarios,
environmental uncertainties, and novel mission objectives. This work not only
advances underwater autonomy but also establishes a scalable, safe, and
versatile cognitive robotics framework capable of generalising to a diverse
array of real-world applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [26] [Unifying Post-hoc Explanations of Knowledge Graph Completions](https://arxiv.org/abs/2507.22951)
*Alessandro Lonardi,Samy Badreddine,Tarek R. Besold,Pablo Sanchez Martin*

Main category: cs.AI

TL;DR: 本文提出了一种统一的知识图谱补全（KGC）后解释性方法，通过多目标优化框架平衡解释的有效性和简洁性，并改进了评估协议。


<details>
  <summary>Details</summary>
Motivation: 当前KGC后解释性缺乏形式化和一致的评估，阻碍了研究的可重复性和跨研究比较。

Method: 提出一个通用框架，通过多目标优化统一现有后解释性算法，并改进评估协议（如MRR和Hits@k）。

Result: 框架统一了现有方法，评估协议得到实证支持，强调了以用户为中心的查询解释能力。

Conclusion: 通过统一方法和改进评估标准，旨在提升KGC解释性研究的可重复性和影响力。

Abstract: Post-hoc explainability for Knowledge Graph Completion (KGC) lacks
formalization and consistent evaluations, hindering reproducibility and
cross-study comparisons. This paper argues for a unified approach to post-hoc
explainability in KGC. First, we propose a general framework to characterize
post-hoc explanations via multi-objective optimization, balancing their
effectiveness and conciseness. This unifies existing post-hoc explainability
algorithms in KGC and the explanations they produce. Next, we suggest and
empirically support improved evaluation protocols using popular metrics like
Mean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of
interpretability as the ability of explanations to address queries meaningful
to end-users. By unifying methods and refining evaluation standards, this work
aims to make research in KGC explainability more reproducible and impactful.

</details>


### [27] [Data Readiness for Scientific AI at Scale](https://arxiv.org/abs/2507.23018)
*Wesley Brewer,Patrick Widener,Valentine Anantharaj,Feiyi Wang,Tom Beck,Arjun Shankar,Sarp Oral*

Main category: cs.AI

TL;DR: 本文探讨了数据准备（DRAI）原则在领导级科学数据集上的应用，提出一个针对高性能计算环境的二维准备框架，用于指导AI训练数据的标准化处理。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决科学数据在AI训练中的预处理挑战，尤其是针对跨领域的大规模数据集。

Method: 方法包括分析四个代表性领域的数据工作流，并提出一个结合数据准备级别和处理阶段的两维框架。

Result: 结果是一个成熟度矩阵，用于评估科学数据的AI准备状态，并指导基础设施开发。

Conclusion: 结论强调了该框架对跨领域、可扩展和可重复AI科学应用的重要性。

Abstract: This paper examines how Data Readiness for AI (DRAI) principles apply to
leadership-scale scientific datasets used to train foundation models. We
analyze archetypal workflows across four representative domains - climate,
nuclear fusion, bio/health, and materials - to identify common preprocessing
patterns and domain-specific constraints. We introduce a two-dimensional
readiness framework composed of Data Readiness Levels (raw to AI-ready) and
Data Processing Stages (ingest to shard), both tailored to high performance
computing (HPC) environments. This framework outlines key challenges in
transforming scientific data for scalable AI training, emphasizing
transformer-based generative models. Together, these dimensions form a
conceptual maturity matrix that characterizes scientific data readiness and
guides infrastructure development toward standardized, cross-domain support for
scalable and reproducible AI for science.

</details>


### [28] [FairReason: Balancing Reasoning and Social Bias in MLLMs](https://arxiv.org/abs/2507.23067)
*Zhenyu Pan,Yutong Zhang,Jianshu Zhang,Haoran Lu,Haozheng Luo,Yuwei Han,Philip S. Yu,Manling Li,Han Liu*

Main category: cs.AI

TL;DR: 多模态大语言模型（MLLMs）在多种任务和模态中表现优异，但推理能力的提升常伴随社会偏见的增加。本研究评估了三种偏见缓解策略，发现强化学习结合1:4的偏见与推理样本比例能在减少偏见的同时保留大部分推理能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何在提升MLLMs推理能力的同时有效缓解其输出的社会偏见，解决两者之间的潜在权衡问题。

Method: 比较三种偏见缓解策略（监督微调、知识蒸馏、基于规则的强化学习），并通过调整偏见与推理样本比例分析权衡关系。

Result: 强化学习结合1:4的样本比例能减少10%的偏见，同时保留88%的原始推理准确性。

Conclusion: 研究为平衡MLLMs的公平性与能力提供了具体指导，强化学习是有效的折中方案。

Abstract: Multimodal Large Language Models (MLLMs) already achieve state-of-the-art
results across a wide range of tasks and modalities. To push their reasoning
ability further, recent studies explore advanced prompting schemes and
post-training fine-tuning. Although these techniques improve logical accuracy,
they frequently leave the models' outputs burdened with pronounced social
biases. Clarifying how reasoning gains interact with bias mitigation-and
whether the two objectives inherently trade off-therefore remains an open and
pressing research problem. Our study begins by benchmarking three
bias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation
(KD), and rule-based reinforcement learning (RL)-under identical conditions,
establishing their baseline strengths and weaknesses. Building on these
results, we vary the proportion of debias-focused and reasoning-centric samples
within each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps
reveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement
learning cuts stereotype scores by 10% while retaining 88% of the model's
original reasoning accuracy, offering concrete guidance for balancing fairness
and capability in MLLMs.

</details>


### [29] [Moravec's Paradox: Towards an Auditory Turing Test](https://arxiv.org/abs/2507.23091)
*David Noever,Forrest McKee*

Main category: cs.AI

TL;DR: 当前AI系统在人类轻松完成的听觉任务上表现极差，失败率超过93%。研究通过听觉图灵测试揭示了AI在选择性注意力、噪声鲁棒性和上下文适应方面的不足。


<details>
  <summary>Details</summary>
Motivation: 受Moravec悖论启发，研究旨在量化AI与人类在听觉任务上的差距，并探索失败原因。

Method: 设计了包含917个挑战的听觉图灵测试，覆盖七类任务，评估了GPT-4和Whisper等先进模型。

Result: AI模型平均准确率仅6.9%，远低于人类的52%，暴露了其在复杂听觉场景处理中的缺陷。

Conclusion: 研究提出了诊断框架，强调需整合选择性注意力、物理音频理解和上下文感知的新方法。

Abstract: This research work demonstrates that current AI systems fail catastrophically
on auditory tasks that humans perform effortlessly. Drawing inspiration from
Moravec's paradox (i.e., tasks simple for humans often prove difficult for
machines, and vice versa), we introduce an auditory Turing test comprising 917
challenges across seven categories: overlapping speech, speech in noise,
temporal distortion, spatial audio, coffee-shop noise, phone distortion, and
perceptual illusions. Our evaluation of state-of-the-art audio models including
GPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate
exceeding 93%, with even the best-performing model achieving only 6.9% accuracy
on tasks that humans solved at 7.5 times higher success (52%). These results
expose focusing failures in how AI systems process complex auditory scenes,
particularly in selective attention, noise robustness, and contextual
adaptation. Our benchmark not only quantifies the human-machine auditory gap
but also provides insights into why these failures occur, suggesting that
current architectures lack fundamental mechanisms for human-like auditory scene
analysis. The traditional design of audio CAPTCHAs highlights common filters
that humans evolved but machines fail to select in multimodal language models.
This work establishes a diagnostic framework for measuring progress toward
human-level machine listening and highlights the need for novel approaches
integrating selective attention, physics-based audio understanding, and
context-aware perception into multimodal AI systems.

</details>


### [30] [Argumentatively Coherent Judgmental Forecasting](https://arxiv.org/abs/2507.23163)
*Deniz Gorur,Antonio Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 论文提出并形式化定义了‘论证一致性’属性，要求预测者的推理与预测一致。通过实验验证，过滤不一致预测能提升人类和LLM预测的准确性，但用户实验显示用户通常不遵循这一属性。


<details>
  <summary>Details</summary>
Motivation: 研究论证结构对预测的影响，提出‘论证一致性’以提升预测准确性。

Method: 形式化定义‘论证一致性’，并设计实验评估其对人类和LLM预测的影响，同时通过用户实验验证其接受度。

Result: 过滤不一致预测显著提升人类和LLM的预测准确性，但用户实验显示用户通常不遵循这一属性。

Conclusion: 论证一致性对提升预测准确性有实际价值，但需在群体预测中引入机制过滤不一致意见。

Abstract: Judgmental forecasting employs human opinions to make predictions about
future events, rather than exclusively historical data as in quantitative
forecasting. When these opinions form an argumentative structure around
forecasts, it is useful to study the properties of the forecasts from an
argumentative perspective. In this paper, we advocate and formally define a
property of argumentative coherence, which, in essence, requires that a
forecaster's reasoning is coherent with their forecast. We then conduct three
evaluations with our notion of coherence. First, we assess the impact of
enforcing coherence on human forecasters as well as on Large Language Model
(LLM)-based forecasters, given that they have recently shown to be competitive
with human forecasters. In both cases, we show that filtering out incoherent
predictions improves forecasting accuracy consistently, supporting the
practical value of coherence in both human and LLM-based forecasting. Then, via
crowd-sourced user experiments, we show that, despite its apparent
intuitiveness and usefulness, users do not generally align with this coherence
property. This points to the need to integrate, within argumentation-based
judgmental forecasting, mechanisms to filter out incoherent opinions before
obtaining group forecasting predictions.

</details>


### [31] [Tractable Responsibility Measures for Ontology-Mediated Query Answering](https://arxiv.org/abs/2507.23191)
*Meghyn Bienvenu,Diego Figueira,Pierre Lafourcade*

Main category: cs.AI

TL;DR: 本文研究了基于Shapley值的责任评分（WSMS）在ontology-mediated查询回答中的计算复杂度，发现其在某些查询类中具有多项式数据复杂度，而在其他情况下则表现出计算困难。


<details>
  <summary>Details</summary>
Motivation: 量化查询答案中各事实的贡献是解释性数据库研究的重要问题，本文旨在探索WSMS责任评分在不同查询和本体语言中的计算复杂度。

Method: 利用数据库领域的结果，分析WSMS责任评分在first-order-rewritable查询类中的多项式数据复杂度，并研究其在其他查询类中的计算困难性。

Result: 研究发现，WSMS在first-order-rewritable查询类中具有多项式数据复杂度，但在某些情况下（如支持合取的本体语言）表现出计算困难。

Conclusion: 通过结构限制的查询类，可以在DL-Lite方言中实现高效的WSMS计算，为实际应用提供了理论支持。

Abstract: Recent work on quantitative approaches to explaining query answers employs
responsibility measures to assign scores to facts in order to quantify their
respective contributions to obtaining a given answer. In this paper, we study
the complexity of computing such responsibility scores in the setting of
ontology-mediated query answering, focusing on a very recently introduced
family of Shapley-value-based responsibility measures defined in terms of
weighted sums of minimal supports (WSMS). By exploiting results from the
database setting, we can show that such measures enjoy polynomial data
complexity for classes of ontology-mediated queries that are
first-order-rewritable, whereas the problem becomes "shP"-hard when the
ontology language can encode reachability queries (via axioms like $\exists R.
A \sqsubseteq A$). To better understand the tractability frontier, we next
explore the combined complexity of WSMS computation. We prove that
intractability applies already to atomic queries if the ontology language
supports conjunction, as well as to unions of `well-behaved' conjunctive
queries, even in the absence of an ontology. By contrast, our study yields
positive results for common DL-Lite dialects: by means of careful analysis, we
identify classes of structurally restricted conjunctive queries (which
intuitively disallow undesirable interactions between query atoms) that admit
tractable WSMS computation.

</details>


### [32] [Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification](https://arxiv.org/abs/2507.23197)
*Yuke Liao,Blaise Genest,Kuldeep Meel,Shaan Aryaman*

Main category: cs.AI

TL;DR: 论文提出了一种新的解决方案感知ReLU评分方法（SAS），通过选择少量关键ReLU变量，显著减少了二元变量的使用，提升了验证效率。


<details>
  <summary>Details</summary>
Motivation: 处理复杂实例时，传统方法效率低下，需要改进ReLU变量的选择策略以减少计算成本。

Method: 结合了解决方案感知ReLU评分（SAS）和全局ReLU评分（GS），并采用混合MILP方法，先使用α,β-CROWN快速解决简单实例，再处理部分MILP。

Result: SAS将二元变量数量减少约6倍，同时保持准确性；混合MILP方法将未解决实例数量降低40%，运行时间合理。

Conclusion: SAS和混合MILP方法显著提升了验证效率和准确性，适用于大规模神经网络。

Abstract: To handle complex instances, we revisit a divide-and-conquer approach to
break down the complexity: instead of few complex BaB calls, we rely on many
small {\em partial} MILP calls. The crucial step is to select very few but very
important ReLUs to treat using (costly) binary variables. The previous attempts
were suboptimal in that respect. To select these important ReLU variables, we
propose a novel {\em solution-aware} ReLU scoring ({\sf SAS}), as well as adapt
the BaB-SR and BaB-FSB branching functions as {\em global} ReLU scoring ({\sf
GS}) functions. We compare them theoretically as well as experimentally, and
{\sf SAS} is more efficient at selecting a set of variables to open using
binary variables. Compared with previous attempts, SAS reduces the number of
binary variables by around 6 times, while maintaining the same level of
accuracy. Implemented in {\em Hybrid MILP}, calling first $\alpha,\beta$-CROWN
with a short time-out to solve easier instances, and then partial MILP,
produces a very accurate yet efficient verifier, reducing by up to $40\%$ the
number of undecided instances to low levels ($8-15\%$), while keeping a
reasonable runtime ($46s-417s$ on average per instance), even for fairly large
CNNs with 2 million parameters.

</details>


### [33] [How Far Are AI Scientists from Changing the World?](https://arxiv.org/abs/2507.23276)
*Qiujie Xie,Yixuan Weng,Minjun Zhu,Fuchen Shen,Shulin Huang,Zhen Lin,Jiahui Zhou,Zilan Mao,Zijie Yang,Linyi Yang,Jian Wu,Yue Zhang*

Main category: cs.AI

TL;DR: 综述探讨了AI科学家系统在推动科学发现中的潜力，分析了当前成就、瓶颈及未来目标。


<details>
  <summary>Details</summary>
Motivation: 评估AI科学家系统是否能改变世界并重塑科研范式。

Method: 通过前瞻性综述，全面分析AI科学家系统的现状和关键组件。

Result: 识别了当前系统的局限性和实现突破性发现所需的关键要素。

Conclusion: 希望该综述能帮助明确AI科学家系统的现状、不足及终极目标。

Abstract: The emergence of large language models (LLMs) is propelling automated
scientific discovery to the next level, with LLM-based Artificial Intelligence
(AI) Scientist systems now taking the lead in scientific research. Several
influential works have already appeared in the field of AI Scientist systems,
with AI-generated research papers having been accepted at the ICLR 2025
workshop, suggesting that a human-level AI Scientist capable of uncovering
phenomena previously unknown to humans, may soon become a reality. In this
survey, we focus on the central question: How far are AI scientists from
changing the world and reshaping the scientific research paradigm? To answer
this question, we provide a prospect-driven review that comprehensively
analyzes the current achievements of AI Scientist systems, identifying key
bottlenecks and the critical components required for the emergence of a
scientific agent capable of producing ground-breaking discoveries that solve
grand challenges. We hope this survey will contribute to a clearer
understanding of limitations of current AI Scientist systems, showing where we
are, what is missing, and what the ultimate goals for scientific AI should be.

</details>


### [34] [AI Must not be Fully Autonomous](https://arxiv.org/abs/2507.23330)
*Tosin Adewumi,Lama Alkhaled,Florent Imbert,Hui Han,Nudrat Habib,Karl Löwenmark*

Main category: cs.AI

TL;DR: 论文主张AI不应完全自主，提出3级自主AI分类，强调人类监督的必要性，并提供理论和证据支持。


<details>
  <summary>Details</summary>
Motivation: 探讨AI完全自主的风险，尤其是超级智能（ASI）可能带来的威胁，主张人类监督的重要性。

Method: 通过理论分析（自主性、AI和智能体理论）、12个论点、6个反驳及其回应，以及15个AI价值错位案例支持观点。

Result: 提出3级自主AI分类，强调人类监督对风险缓解的关键作用。

Conclusion: AI不应完全自主，人类监督是确保AI安全发展的必要条件。

Abstract: Autonomous Artificial Intelligence (AI) has many benefits. It also has many
risks. In this work, we identify the 3 levels of autonomous AI. We are of the
position that AI must not be fully autonomous because of the many risks,
especially as artificial superintelligence (ASI) is speculated to be just
decades away. Fully autonomous AI, which can develop its own objectives, is at
level 3 and without responsible human oversight. However, responsible human
oversight is crucial for mitigating the risks. To ague for our position, we
discuss theories of autonomy, AI and agents. Then, we offer 12 distinct
arguments and 6 counterarguments with rebuttals to the counterarguments. We
also present 15 pieces of recent evidence of AI misaligned values and other
risks in the appendix.

</details>


### [35] [DSBC : Data Science task Benchmarking with Context engineering](https://arxiv.org/abs/2507.23336)
*Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Giulio Martini,Suman Debnath,Hamza Farooq*

Main category: cs.AI

TL;DR: 论文提出了一种针对数据科学代理的全面基准测试，评估了三种LLM模型在不同方法下的表现，揭示了性能差异和实际部署中的关键因素。


<details>
  <summary>Details</summary>
Motivation: 尽管数据科学代理在自动化分析任务中迅速普及，但缺乏系统性基准评估其效能和局限性。

Method: 通过商业应用观察用户交互，设计了反映真实场景的基准测试，评估了三种LLM模型（Claude-4.0-Sonnet、Gemini-2.5-Flash、OpenAI-o4-Mini）在三种方法（零样本上下文工程、多步上下文工程、SmolAgent）下的表现。

Result: 研究发现不同模型和方法之间存在显著性能差异，并探讨了温度参数对结果的影响。

Conclusion: 提出的基准数据集和评估框架为未来研究更鲁棒和高效的数据科学代理奠定了基础。

Abstract: Recent advances in large language models (LLMs) have significantly impacted
data science workflows, giving rise to specialized data science agents designed
to automate analytical tasks. Despite rapid adoption, systematic benchmarks
evaluating the efficacy and limitations of these agents remain scarce. In this
paper, we introduce a comprehensive benchmark specifically crafted to reflect
real-world user interactions with data science agents by observing usage of our
commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,
Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with
context engineering, multi-step with context engineering, and with SmolAgent.
Our benchmark assesses performance across a diverse set of eight data science
task categories, additionally exploring the sensitivity of models to common
prompting issues, such as data leakage and slightly ambiguous instructions. We
further investigate the influence of temperature parameters on overall and
task-specific outcomes for each model and approach. Our findings reveal
distinct performance disparities among the evaluated models and methodologies,
highlighting critical factors that affect practical deployment. The benchmark
dataset and evaluation framework introduced herein aim to provide a foundation
for future research of more robust and effective data science agents.

</details>


### [36] [LLM4Rail: An LLM-Augmented Railway Service Consulting Platform](https://arxiv.org/abs/2507.23377)
*Zhuo Li,Xianghuai Deng,Chiwei Feng,Hanmeng Li,Shenjie Wang,Haichao Zhang,Teng Jia,Conlin Chen,Louis Linchun Wu,Jia Wang*

Main category: cs.AI

TL;DR: LLM4Rail是一个基于大语言模型（LLM）的铁路服务平台，通过QTAO提示框架和CRFD-25数据集，提供个性化铁路服务。


<details>
  <summary>Details</summary>
Motivation: 满足日益增长的个性化铁路服务需求。

Method: 提出QTAO提示框架，结合语言推理与任务导向行动，并构建CRFD-25数据集支持个性化餐饮推荐。

Result: 开发了LLM4Rail平台，能够提供精准的铁路服务咨询和餐饮推荐。

Conclusion: LLM4Rail通过LLM和QTAO框架有效提升了铁路服务的个性化和准确性。

Abstract: Large language models (LLMs) have significantly reshaped different walks of
business. To meet the increasing demands for individualized railway service, we
develop LLM4Rail - a novel LLM-augmented railway service consulting platform.
Empowered by LLM, LLM4Rail can provide custom modules for ticketing, railway
food & drink recommendations, weather information, and chitchat. In LLM4Rail,
we propose the iterative "Question-Thought-Action-Observation (QTAO)" prompting
framework. It meticulously integrates verbal reasoning with task-oriented
actions, that is, reasoning to guide action selection, to effectively retrieve
external observations relevant to railway operation and service to generate
accurate responses. To provide personalized onboard dining services, we first
construct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible
takeout dataset tailored for railway services. CRFD-25 covers a wide range of
signature dishes categorized by cities, cuisines, age groups, and spiciness
levels. We further introduce an LLM-based zero-shot conversational recommender
for railway catering. To address the unconstrained nature of open
recommendations, the feature similarity-based post-processing step is
introduced to ensure all the recommended items are aligned with CRFD-25
dataset.

</details>


### [37] [Chatting with your ERP: A Recipe](https://arxiv.org/abs/2507.23429)
*Jorge Ruiz Gómez,Lidia Andrés Susinos,Jorge Alamo Olivé,Sonia Rey Osorno,Manuel Luis Gonzalez Hernández*

Main category: cs.AI

TL;DR: 论文提出了一种基于大型语言模型（LLM）的代理，用于与工业级ERP系统交互，通过双代理架构提升SQL查询生成的可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言查询转换为可执行SQL语句的可靠性问题，适用于工业级ERP系统。

Method: 采用双代理架构，结合推理和批判阶段，利用开源权重LLM生成SQL查询。

Result: 代理能够可靠地将自然语言查询转换为SQL语句，适用于工业环境。

Conclusion: 双代理架构显著提升了查询生成的可靠性，为LLM在工业应用中的落地提供了可行方案。

Abstract: This paper presents the design, implementation, and evaluation behind a Large
Language Model (LLM) agent that chats with an industrial production-grade ERP
system. The agent is capable of interpreting natural language queries and
translating them into executable SQL statements, leveraging open-weight LLMs. A
novel dual-agent architecture combining reasoning and critique stages was
proposed to improve query generation reliability.

</details>


### [38] [Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation](https://arxiv.org/abs/2507.23440)
*Mingzhe Li,Xin Lu,Yanyan Zhao*

Main category: cs.AI

TL;DR: 提出了一种名为Self-Foveate的创新方法，通过多级聚焦技术提升指令合成的多样性和难度，减少对人力的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统指令合成方法依赖人工标注且多样性不足，现有自动化方法在多样性和难度上仍有局限。

Method: 采用“Micro-Scatter-Macro”多级聚焦技术，指导LLM从无监督文本中挖掘细粒度信息。

Result: 在多个无监督语料库和模型架构上的实验验证了方法的有效性和优越性。

Conclusion: Self-Foveate显著提升了指令合成的多样性和难度，为LLM训练提供了高效解决方案。

Abstract: Large language models (LLMs) with instruction following capabilities have
demonstrated impressive problem-solving abilities. While synthesizing
instructional data from unsupervised text has become a common approach for
training such models, conventional methods rely heavily on human effort for
data annotation. Although existing automated synthesis paradigms have
alleviated this constraint, they still exhibit significant limitations in
ensuring adequate diversity and difficulty of synthesized instructions. To
address these challenges, we propose Self-Foveate, an innovative LLM-driven
method for instruction synthesis. This approach introduces a
"Micro-Scatter-Macro" multi-level foveation methodology that effectively guides
the LLM to deeply excavate fine-grained information embedded in unsupervised
text, thereby enhancing both the diversity and difficulty of synthesized
instructions. Comprehensive experiments across multiple unsupervised corpora
and diverse model architectures validate the effectiveness and superiority of
our proposed method. We publicly release our data and codes:
https://github.com/Mubuky/Self-Foveate

</details>


### [39] [Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery](https://arxiv.org/abs/2507.23488)
*Kacper Kadziolka,Saber Salehkaleybar*

Main category: cs.AI

TL;DR: 研究发现，基于推理的大语言模型在因果发现任务中表现优于传统方法，通过模块化上下文管道进一步提升了性能。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在因果推理任务中的潜力，解决传统模型在数据扰动下的过拟合和性能随机性问题。

Method: 使用OpenAI的o系列和DeepSeek-R模型，结合Tree-of-Thoughts和Chain-of-Thoughts方法，设计模块化上下文管道。

Result: 推理模型在Corr2Cause基准测试中表现显著优于传统方法，模块化管道带来近三倍的性能提升。

Conclusion: 高级推理模型在因果发现中具有显著优势，但需结合结构化上下文框架以最大化其潜力，为跨领域应用提供通用蓝图。

Abstract: Causal inference remains a fundamental challenge for large language models.
Recent advances in internal reasoning with large language models have sparked
interest in whether state-of-the-art reasoning models can robustly perform
causal discovery-a task where conventional models often suffer from severe
overfitting and near-random performance under data perturbations. We study
causal discovery on the Corr2Cause benchmark using the emergent OpenAI's
o-series and DeepSeek-R model families and find that these reasoning-first
architectures achieve significantly greater native gains than prior approaches.
To capitalize on these strengths, we introduce a modular in-context pipeline
inspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding
nearly three-fold improvements over conventional baselines. We further probe
the pipeline's impact by analyzing reasoning chain length, complexity, and
conducting qualitative and quantitative comparisons between conventional and
reasoning models. Our findings suggest that while advanced reasoning models
represent a substantial leap forward, carefully structured in-context
frameworks are essential to maximize their capabilities and offer a
generalizable blueprint for causal discovery across diverse domains.

</details>


### [40] [Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification](https://arxiv.org/abs/2507.23497)
*David A Kelly,Hana Chockler*

Main category: cs.AI

TL;DR: 论文提出因果解释方法，弥补逻辑解释在图像分类器中的不足，具有形式化严谨性且适用于黑盒算法。


<details>
  <summary>Details</summary>
Motivation: 现有图像分类器解释方法缺乏形式化严谨性，而逻辑解释虽严谨但假设条件严格，不适用于图像分类器。

Method: 提出因果解释方法，证明其形式化性质，引入对比性因果解释和置信度感知的完整因果解释。

Result: 实验表明不同模型在充分性、对比性和完整性上表现不同，算法高效且完全黑盒。

Conclusion: 因果解释兼具形式化严谨性和实用性，适用于图像分类器。

Abstract: Existing algorithms for explaining the outputs of image classifiers are based
on a variety of approaches and produce explanations that lack formal rigor. On
the other hand, logic-based explanations are formally and rigorously defined
but their computability relies on strict assumptions about the model that do
not hold on image classifiers.
  In this paper, we show that causal explanations, in addition to being
formally and rigorously defined, enjoy the same formal properties as
logic-based ones, while still lending themselves to black-box algorithms and
being a natural fit for image classifiers. We prove formal properties of causal
explanations and introduce contrastive causal explanations for image
classifiers. Moreover, we augment the definition of explanation with confidence
awareness and introduce complete causal explanations: explanations that are
classified with exactly the same confidence as the original image.
  We implement our definitions, and our experimental results demonstrate that
different models have different patterns of sufficiency, contrastiveness, and
completeness. Our algorithms are efficiently computable, taking on average 6s
per image on a ResNet50 model to compute all types of explanations, and are
totally black-box, needing no knowledge of the model, no access to model
internals, no access to gradient, nor requiring any properties, such as
monotonicity, of the model.

</details>


### [41] [DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer](https://arxiv.org/abs/2507.23554)
*Ruoyu Wang,Junda Wu,Yu Xia,Tong Yu,Ryan A. Rossi,Julian McAuley,Lina Yao*

Main category: cs.AI

TL;DR: 论文提出DICE框架，通过动态选择上下文示例提升LLM代理的性能，解决了现有方法依赖启发式或任务特定设计的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于ICL的LLM代理在复杂推理和工具使用任务中表现优异，但性能对示例选择高度敏感，缺乏通用且理论支持的选择标准。

Method: 提出DICE框架，通过因果视角分解演示知识为可转移和不可转移部分，并提出逐步选择标准，确保性能提升。

Result: 实验表明DICE在多样化领域中有效且通用，能显著提升代理性能。

Conclusion: DICE是一种无需额外训练成本的通用解决方案，强调了上下文感知示例选择对LLM代理的重要性。

Abstract: Large language model-based agents, empowered by in-context learning (ICL),
have demonstrated strong capabilities in complex reasoning and tool-use tasks.
However, existing works have shown that the effectiveness of ICL is highly
sensitive to the choice of demonstrations, with suboptimal examples often
leading to unstable or degraded performance. While prior work has explored
example selection, including in some agentic or multi-step settings, existing
approaches typically rely on heuristics or task-specific designs and lack a
general, theoretically grounded criterion for what constitutes an effective
demonstration across reasoning steps. Therefore, it is non-trivial to develop a
principled, general-purpose method for selecting demonstrations that
consistently benefit agent performance. In this paper, we address this
challenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a
theoretically grounded ICL framework for agentic tasks that selects the most
relevant demonstrations at each step of reasoning. Our approach decomposes
demonstration knowledge into transferable and non-transferable components
through a causal lens, showing how the latter can introduce spurious
dependencies that impair generalization. We further propose a stepwise
selection criterion with a formal guarantee of improved agent performance.
Importantly, DICE is a general, framework-agnostic solution that can be
integrated as a plug-in module into existing agentic frameworks without any
additional training cost. Extensive experiments across diverse domains
demonstrate our method's effectiveness and generality, highlighting the
importance of principled, context-aware demo selection for robust and efficient
LLM agents.

</details>


### [42] [Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI](https://arxiv.org/abs/2507.23565)
*Botao Zhu,Xianbin Wang,Dusit Niyato*

Main category: cs.AI

TL;DR: 提出了一种基于语义信任链的自主信任编排方法，利用智能代理和超图技术优化分布式协作中的信任评估。


<details>
  <summary>Details</summary>
Motivation: 分布式协作中，复杂的任务、动态的设备资源以及频繁的信任评估增加了资源消耗，影响协作效率。

Method: 采用智能代理和超图技术，通过历史数据在设备空闲期进行信任评估，并利用信任语义超图实现分层管理和多跳协作。

Result: 实验证明该方法实现了资源高效的信任评估。

Conclusion: 提出的方法在减少资源消耗的同时，提高了信任评估的效率和准确性。

Abstract: In collaborative systems, the effective completion of tasks hinges on
task-specific trust evaluations of potential devices for distributed
collaboration. However, the complexity of tasks, the spatiotemporal dynamism of
distributed device resources, and the inevitable assessment overhead
dramatically increase the complexity and resource consumption of the trust
evaluation process. As a result, ill-timed or overly frequent trust evaluations
can reduce utilization rate of constrained resources, negatively affecting
collaborative task execution. To address this challenge, this paper proposes an
autonomous trust orchestration method based on a new concept of semantic
chain-of-trust. Our technique employs agentic AI and hypergraph to establish
and maintain trust relationships among devices. By leveraging its strengths in
autonomous perception, task decomposition, and semantic reasoning, we propose
agentic AI to perceive device states and autonomously perform trust evaluations
of collaborators based on historical performance data only during device idle
periods, thereby enabling efficient utilization of distributed resources. In
addition, agentic AI performs task-specific trust evaluations on collaborator
resources by analyzing the alignment between resource capabilities and task
requirements. Moreover, by maintaining a trust hypergraph embedded with trust
semantics for each device, agentic AI enables hierarchical management of
collaborators and identifies collaborators requiring trust evaluation based on
trust semantics, thereby achieving a balance between overhead and trust
accuracy. Furthermore, local trust hypergraphs from multiple devices can be
chained together to support multi-hop collaboration, enabling efficient
coordination in large-scale systems. Experimental results demonstrate that the
proposed method achieves resource-efficient trust evaluation.

</details>


### [43] [MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying](https://arxiv.org/abs/2507.23633)
*Qian Zhao,Zhuo Sun,Bin Guo,Zhiwen Yu*

Main category: cs.AI

TL;DR: 提出了一种基于策略引导的代理辅助记忆回忆方法，通过设计策略将原始查询转化为富含线索的查询，提升记忆回忆效果。


<details>
  <summary>Details</summary>
Motivation: 传统方法受限于记忆模块大小，无法完整获取记忆，影响回忆性能。受记忆理论启发，提出通过有效线索主动激活记忆。

Method: 设计了5W Recall Map分类记忆查询场景，定义15种策略模式，结合蒙特卡洛树搜索优化策略选择和响应生成。

Result: 实验表明MemoCue在回忆灵感上优于基于LLM的方法17.74%，人类评估也验证了其优势。

Conclusion: MemoCue通过策略引导和优化算法显著提升了记忆回忆效果，具有实际应用潜力。

Abstract: Agent-assisted memory recall is one critical research problem in the field of
human-computer interaction. In conventional methods, the agent can retrieve
information from its equipped memory module to help the person recall
incomplete or vague memories. The limited size of memory module hinders the
acquisition of complete memories and impacts the memory recall performance in
practice. Memory theories suggest that the person's relevant memory can be
proactively activated through some effective cues. Inspired by this, we propose
a novel strategy-guided agent-assisted memory recall method, allowing the agent
to transform an original query into a cue-rich one via the judiciously designed
strategy to help the person recall memories. To this end, there are two key
challenges. (1) How to choose the appropriate recall strategy for diverse
forgetting scenarios with distinct memory-recall characteristics? (2) How to
obtain the high-quality responses leveraging recall strategies, given only
abstract and sparsely annotated strategy patterns? To address the challenges,
we propose a Recall Router framework. Specifically, we design a 5W Recall Map
to classify memory queries into five typical scenarios and define fifteen
recall strategy patterns across the corresponding scenarios. We then propose a
hierarchical recall tree combined with the Monte Carlo Tree Search algorithm to
optimize the selection of strategy and the generation of strategy responses. We
construct an instruction tuning dataset and fine-tune multiple open-source
large language models (LLMs) to develop MemoCue, an agent that excels in
providing memory-inspired responses. Experiments on three representative
datasets show that MemoCue surpasses LLM-based methods by 17.74% in recall
inspiration. Further human evaluation highlights its advantages in
memory-recall applications.

</details>


### [44] [Personalized Education with Ranking Alignment Recommendation](https://arxiv.org/abs/2507.23664)
*Haipeng Liu,Yuxuan Liu,Ting Long*

Main category: cs.AI

TL;DR: 论文提出了一种名为RAR的个性化问题推荐方法，通过将协作思想融入探索机制，解决了传统强化学习方法在训练中探索效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法将个性化问题推荐建模为马尔可夫决策过程并使用强化学习解决，但在训练中难以高效探索，无法为每个学生找到最佳问题。

Method: 提出Ranking Alignment Recommendation (RAR)，将协作思想融入探索机制，以在有限训练轮次内实现更高效的探索。

Result: 实验表明，RAR显著提高了推荐性能，且该框架可应用于任何基于强化学习的问题推荐系统。

Conclusion: RAR通过改进探索机制，有效提升了推荐效果，具有广泛适用性。

Abstract: Personalized question recommendation aims to guide individual students
through questions to enhance their mastery of learning targets. Most previous
methods model this task as a Markov Decision Process and use reinforcement
learning to solve, but they struggle with efficient exploration, failing to
identify the best questions for each student during training. To address this,
we propose Ranking Alignment Recommendation (RAR), which incorporates
collaborative ideas into the exploration mechanism, enabling more efficient
exploration within limited training episodes. Experiments show that RAR
effectively improves recommendation performance, and our framework can be
applied to any RL-based question recommender. Our code is available in
https://github.com/wuming29/RAR.git.

</details>


### [45] [TextQuests: How Good are LLMs at Text-Based Video Games?](https://arxiv.org/abs/2507.23701)
*Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks*

Main category: cs.AI

TL;DR: TextQuests是一个基于交互式小说的基准测试，旨在评估AI代理在长上下文推理和自主探索环境中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能充分评估AI代理在自主探索环境中的长期推理能力，因此需要更全面的测试工具。

Method: 利用Infocom交互式小说游戏作为测试环境，设计TextQuests基准测试，禁止外部工具使用，专注于内在推理能力。

Result: TextQuests提供了一个有效的测试平台，能够评估AI代理在长上下文和探索性任务中的表现。

Conclusion: TextQuests填补了现有基准测试的空白，推动了AI代理在复杂环境中的自主推理能力发展。

Abstract: Evaluating AI agents within complex, interactive environments that mirror
real-world challenges is critical for understanding their practical
capabilities. While existing agent benchmarks effectively assess skills like
tool use or performance on structured tasks, they often do not fully capture an
agent's ability to operate autonomously in exploratory environments that demand
sustained, self-directed reasoning over a long and growing context. To spur the
development of agents capable of more robust intrinsic reasoning over long
horizons, we introduce TextQuests, a benchmark based on the Infocom suite of
interactive fiction games. These text-based adventures, which can take human
players over 30 hours and require hundreds of precise actions to solve, serve
as an effective proxy for evaluating AI agents on focused, stateful tasks. The
benchmark is specifically designed to assess an LLM agent's capacity for
self-contained problem-solving by precluding the use of external tools, thereby
focusing on intrinsic long-context reasoning capabilities in an exploratory
environment characterized by the need for trial-and-error learning and
sustained problem-solving within a single interactive session. We release
TextQuests at https://textquests.ai.

</details>


### [46] [Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving](https://arxiv.org/abs/2507.23726)
*Luoxin Chen,Jinming Gu,Liankai Huang,Wenhao Huang,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Kaijing Ma,Cheng Ren,Jiawei Shen,Wenlei Shi,Tong Sun,He Sun,Jiahui Wang,Siran Wang,Zhihong Wang,Chenrui Wei,Shufa Wei,Yonghui Wu,Yuchen Wu,Yihang Xia,Huajian Xin,Fan Yang,Huaiyuan Ying,Hongyi Yuan,Zheng Yuan,Tianyang Zhan,Chi Zhang,Yue Zhang,Ge Zhang,Tianyun Zhao,Jianqiu Zhao,Yichi Zhou,Thomas Hanwen Zhu*

Main category: cs.AI

TL;DR: Seed-Prover是一种基于强化学习和形式化验证的定理证明模型，通过迭代优化证明过程，显著提升了IMO级数学问题的解决能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在数学推理中表现优异，但在定理证明方面因缺乏明确的监督信号而受限，形式化验证语言如Lean提供了有效监督。

Method: 提出Seed-Prover模型，结合Lean的反馈、已证明引理和自我总结迭代优化证明；设计三种推理策略支持深度和广度推理；引入Seed-Geometry解决几何问题。

Result: Seed-Prover在IMO问题中达到78.1%的证明率，显著优于现有方法；在IMO 2025中完全证明了5/6的问题。

Conclusion: Seed-Prover展示了形式化验证与长链推理结合的有效性，推动了自动数学推理的进步。

Abstract: LLMs have demonstrated strong mathematical reasoning abilities by leveraging
reinforcement learning with long chain-of-thought, yet they continue to
struggle with theorem proving due to the lack of clear supervision signals when
solely using natural language. Dedicated domain-specific languages like Lean
provide clear supervision via formal verification of proofs, enabling effective
training through reinforcement learning. In this work, we propose
\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover
can iteratively refine its proof based on Lean feedback, proved lemmas, and
self-summarization. To solve IMO-level contest problems, we design three
test-time inference strategies that enable both deep and broad reasoning.
Seed-Prover proves $78.1\%$ of formalized past IMO problems, saturates MiniF2F,
and achieves over 50\% on PutnamBench, outperforming the previous
state-of-the-art by a large margin. To address the lack of geometry support in
Lean, we introduce a geometry reasoning engine \textbf{Seed-Geometry}, which
outperforms previous formal geometry engines. We use these two systems to
participate in IMO 2025 and fully prove 5 out of 6 problems. This work
represents a significant advancement in automated mathematical reasoning,
demonstrating the effectiveness of formal verification with long
chain-of-thought reasoning.

</details>


### [47] [CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks](https://arxiv.org/abs/2507.23751)
*Ping Yu,Jack Lanchantin,Tianlu Wang,Weizhe Yuan,Olga Golovneva,Ilia Kulikov,Sainbayar Sukhbaatar,Jason Weston,Jing Xu*

Main category: cs.AI

TL;DR: CoT-Self-Instruct是一种合成数据生成方法，通过Chain-of-Thought（CoT）引导LLMs生成高质量合成提示，显著提升推理和指令跟随任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有训练数据集在复杂推理和指令跟随任务中表现不足的问题。

Method: 基于种子任务，利用CoT引导LLMs生成合成提示，并通过自动指标过滤高质量数据。

Result: 在可验证推理任务（如MATH500等）和非可验证指令跟随任务（如AlpacaEval 2.0等）中表现优于现有数据集。

Conclusion: CoT-Self-Instruct能有效生成高质量合成数据，提升LLMs在复杂任务中的表现。

Abstract: We propose CoT-Self-Instruct, a synthetic data generation method that
instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the
given seed tasks, and then to generate a new synthetic prompt of similar
quality and complexity for use in LLM training, followed by filtering for
high-quality data with automatic metrics. In verifiable reasoning, our
synthetic data significantly outperforms existing training datasets, such as
s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For
non-verifiable instruction-following tasks, our method surpasses the
performance of human or standard self-instruct prompts on both AlpacaEval 2.0
and Arena-Hard.

</details>


### [48] [SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model](https://arxiv.org/abs/2507.23773)
*Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing*

Main category: cs.AI

TL;DR: SimuRA是一种基于世界模型的通用AI代理架构，通过模拟规划克服自回归LLM的局限性，在复杂任务中表现显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理多为单一任务设计，缺乏通用性和可扩展性，且受限于自回归LLM的固有缺陷。人类通过心理模拟进行推理，启发研究者提出更通用的代理架构。

Method: SimuRA基于环境中最优代理的理论框架，利用LLM实现通用世界模型，通过自然语言潜在空间进行灵活规划。

Result: 在网页浏览任务中，SimuRA将航班搜索成功率从0%提升至32.2%，基于世界模型的规划比自回归规划优势高达124%。

Conclusion: SimuRA展示了世界模型模拟作为推理范式的优势，为训练单一通用LLM代理提供了可能性，并已发布为公开研究演示。

Abstract: AI agents built on large language models (LLMs) hold enormous promise, but
current practice focuses on a one-task-one-agent approach, which not only falls
short of scalability and generality, but also suffers from the fundamental
limitations of autoregressive LLMs. On the other hand, humans are general
agents who reason by mentally simulating the outcomes of their actions and
plans. Moving towards a more general and powerful AI agent, we introduce
SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based
on a principled formulation of optimal agent in any environment, \modelname
overcomes the limitations of autoregressive reasoning by introducing a world
model for planning via simulation. The generalized world model is implemented
using LLM, which can flexibly plan in a wide range of environments using the
concept-rich latent space of natural language. Experiments on difficult web
browsing tasks show that \modelname improves the success of flight search from
0\% to 32.2\%. World-model-based planning, in particular, shows consistent
advantage of up to 124\% over autoregressive planning, demonstrating the
advantage of world model simulation as a reasoning paradigm. We are excited
about the possibility for training a single, general agent model based on LLMs
that can act superintelligently in all environments. To start, we make SimuRA,
a web-browsing agent built on \modelname with pretrained LLMs, available as a
research demo for public testing.

</details>
