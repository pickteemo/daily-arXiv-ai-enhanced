<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 26]
- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](https://arxiv.org/abs/2507.07115)
*Javal Vyas,Mehmet Mercangoz*

Main category: cs.AI

TL;DR: 论文提出了一种结合符号推理与自适应控制的统一代理框架，利用大语言模型（LLMs）实现离散故障恢复规划和连续过程控制，并通过案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现代化学过程复杂性增加，劳动力短缺和故障场景复杂，需要新的自动化范式。

Method: 采用有限状态机（FSMs）作为可解释的操作框架，结合LLM驱动的规划代理、模拟代理和验证-重新提示循环。

Result: 在案例研究中，GPT-4o和GPT-4o-mini在180个随机生成的FSMs中实现了100%的有效路径成功率；在双加热器控制中，LLM控制器性能接近经典PID控制。

Conclusion: 通过结构化反馈和模块化代理，LLMs可以统一高级符号规划和低级连续控制，为化学工程中的弹性自动化铺平道路。

Abstract: The increasing complexity of modern chemical processes, coupled with
workforce shortages and intricate fault scenarios, demands novel automation
paradigms that blend symbolic reasoning with adaptive control. In this work, we
introduce a unified agentic framework that leverages large language models
(LLMs) for both discrete fault-recovery planning and continuous process control
within a single architecture. We adopt Finite State Machines (FSMs) as
interpretable operating envelopes: an LLM-driven planning agent proposes
recovery sequences through the FSM, a Simulation Agent executes and checks each
transition, and a Validator-Reprompting loop iteratively refines invalid plans.
In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25
states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path
success within five reprompts-outperforming open-source LLMs in both accuracy
and latency. In Case Study 2, the same framework modulates dual-heater inputs
on a laboratory TCLab platform (and its digital twin) to maintain a target
average temperature under persistent asymmetric disturbances. Compared to
classical PID control, our LLM-based controller attains similar performance,
while ablation of the prompting loop reveals its critical role in handling
nonlinear dynamics. We analyze key failure modes-such as instruction following
lapses and coarse ODE approximations. Our results demonstrate that, with
structured feedback and modular agents, LLMs can unify high-level symbolic
planningand low-level continuous control, paving the way towards resilient,
language-driven automation in chemical engineering.

</details>


### [2] [BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks](https://arxiv.org/abs/2507.07134)
*Mridula Vijendran,Shuang Chen,Jingjing Deng,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: 论文提出了一种名为BOOST的新方法，通过动态调整温度缩放和采样概率，解决AI艺术分类中的偏见问题，并在KaoKore和PACS数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: AI艺术分类中因数据集不平衡导致的偏见问题日益严重，现有研究多忽视对分布外数据的处理，亟需更鲁棒的偏见缓解方法。

Method: 提出BOOST方法，动态调整温度缩放和采样概率，并引入新指标SODC评估类别分离和偏见减少。

Result: BOOST在KaoKore和PACS数据集上有效平衡了性能与公平性，减少了类别偏见。

Conclusion: BOOST为艺术领域的AI模型提供了一种鲁棒的偏见缓解解决方案。

Abstract: The pervasive issue of bias in AI presents a significant challenge to
painting classification, and is getting more serious as these systems become
increasingly integrated into tasks like art curation and restoration. Biases,
often arising from imbalanced datasets where certain artistic styles dominate,
compromise the fairness and accuracy of model predictions, i.e., classifiers
are less accurate on rarely seen paintings. While prior research has made
strides in improving classification performance, it has largely overlooked the
critical need to address these underlying biases, that is, when dealing with
out-of-distribution (OOD) data. Our insight highlights the necessity of a more
robust approach to bias mitigation in AI models for art classification on
biased training data. We propose a novel OOD-informed model bias adaptive
sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It
addresses these challenges by dynamically adjusting temperature scaling and
sampling probabilities, thereby promoting a more equitable representation of
all classes. We evaluate our proposed approach to the KaoKore and PACS
datasets, focusing on the model's ability to reduce class-wise bias. We further
propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to
assess class-wise separation and per-class bias reduction. Our method
demonstrates the ability to balance high performance with fairness, making it a
robust solution for unbiasing AI models in the art domain.

</details>


### [3] [State-Inference-Based Prompting for Natural Language Trading with Game NPCs](https://arxiv.org/abs/2507.07203)
*Minkyung Kim,Junsik Kim,Hwidong Bae,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: SIBP方法通过状态推理和上下文规则遵守，解决了大型语言模型在规则交易系统中的问题，显著提升了准确性和信任度。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在规则交易系统中存在规则违反问题（如物品幻觉和计算错误），导致玩家信任下降。

Method: 提出State-Inference-Based Prompting（SIBP），将交易分解为六个状态，通过上下文感知的物品引用和占位符价格计算实现规则遵守。

Result: 在100次交易对话中，SIBP实现了>97%的状态遵守率、>95%的引用准确率和99.7%的计算精度，优于基线方法。

Conclusion: SIBP为商业游戏中可信赖的NPC交互提供了实用基础，同时保持计算效率。

Abstract: Large Language Models enable dynamic game interactions but struggle with
rule-governed trading systems. Current implementations suffer from rule
violations, such as item hallucinations and calculation errors, that erode
player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable
trading through autonomous dialogue state inference and context-specific rule
adherence. The approach decomposes trading into six states within a unified
prompt framework, implementing context-aware item referencing and
placeholder-based price calculations. Evaluation across 100 trading dialogues
demonstrates >97% state compliance, >95% referencing accuracy, and 99.7%
calculation precision. SIBP maintains computational efficiency while
outperforming baseline approaches, establishing a practical foundation for
trustworthy NPC interactions in commercial games.

</details>


### [4] [Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains](https://arxiv.org/abs/2507.07217)
*Zili Wang,Frank Montabon,Kristin Yvonne Rozier*

Main category: cs.AI

TL;DR: 论文探讨了如何利用神经符号方法检测供应链中的非法活动，特别是在数据稀疏且不可靠的情况下，通过结合大型语言模型（LLM）和问题树方法，比较人工与机器分类新闻文章的效果。


<details>
  <summary>Details</summary>
Motivation: 供应链网络复杂且涉及非法活动时分析难度大，传统机器学习方法需要大量训练数据，而非法供应链数据稀疏且不可靠，因此需要新的方法来自动检测非法活动模式。

Method: 采用神经符号方法，结合LLM和问题树方法，从新闻文章中提取特征，比较人工与机器分类的差异。

Result: 提出了一种系统性评估方法，能够在不依赖大量训练数据的情况下识别非法活动模式。

Conclusion: 神经符号方法和LLM的结合为稀疏数据下的非法供应链活动检测提供了有效途径。

Abstract: Supply chain networks are complex systems that are challenging to analyze;
this problem is exacerbated when there are illicit activities involved in the
supply chain, such as counterfeit parts, forced labor, or human trafficking.
While machine learning (ML) can find patterns in complex systems like supply
chains, traditional ML techniques require large training data sets. However,
illicit supply chains are characterized by very sparse data, and the data that
is available is often (purposely) corrupted or unreliable in order to hide the
nature of the activities. We need to be able to automatically detect new
patterns that correlate with such illegal activity over complex, even temporal
data, without requiring large training data sets. We explore neurosymbolic
methods for identifying instances of illicit activity in supply chains and
compare the effectiveness of manual and automated feature extraction from news
articles accurately describing illicit activities uncovered by authorities. We
propose a question tree approach for querying a large language model (LLM) to
identify and quantify the relevance of articles. This enables a systematic
evaluation of the differences between human and machine classification of news
articles related to forced labor in supply chains.

</details>


### [5] [Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery](https://arxiv.org/abs/2507.07257)
*Licong Xu,Milind Sarkar,Anto I. Lonappan,Íñigo Zubeldia,Pablo Villanueva-Domingo,Santiago Casas,Christian Fidler,Chetana Amancharla,Ujjwal Tiwari,Adrian Bayer,Chadi Ait Ekiou,Miles Cranmer,Adrian Dimitrov,James Fergusson,Kahaan Gandhi,Sven Krippendorf,Andrew Laverick,Julien Lesgourgues,Antony Lewis,Thomas Meier,Blake Sherwin,Kristen Surrao,Francisco Villaescusa-Navarro,Chi Wang,Xueqing Xu,Boris Bolliet*

Main category: cs.AI

TL;DR: 多智能体系统cmbagent通过30个LLM代理实现科研任务自动化，采用规划与控制策略，成功完成宇宙学博士级任务，性能优于现有LLM。


<details>
  <summary>Details</summary>
Motivation: 解决科研任务自动化需求，减少人工干预，提高效率。

Method: 由30个LLM代理组成，各司其职，采用规划与控制策略，支持本地代码执行。

Result: 在宇宙学任务中表现优异，性能超越现有LLM，代码开源并部署于HuggingFace和云端。

Conclusion: cmbagent展示了多智能体系统在科研自动化中的潜力，未来可扩展至更多领域。

Abstract: We present a multi-agent system for automation of scientific research tasks,
cmbagent. The system is formed by about 30 Large Language Model (LLM) agents
and implements a Planning & Control strategy to orchestrate the agentic
workflow, with no human-in-the-loop at any point. Each agent specializes in a
different task (performing retrieval on scientific papers and codebases,
writing code, interpreting results, critiquing the output of other agents) and
the system is able to execute code locally. We successfully apply cmbagent to
carry out a PhD level cosmology task (the measurement of cosmological
parameters using supernova data) and evaluate its performance on two benchmark
sets, finding superior performance over state-of-the-art LLMs. The source code
is available on GitHub, demonstration videos are also available, and the system
is deployed on HuggingFace and will be available on the cloud.

</details>


### [6] [Application of LLMs to Multi-Robot Path Planning and Task Allocation](https://arxiv.org/abs/2507.07302)
*Ashish Kumar*

Main category: cs.AI

TL;DR: 本文研究了在多智能体强化学习中，利用大型语言模型作为专家规划器以实现高效探索的方法。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的探索问题因其复杂性而更具挑战性，需要高效的方法来解决任务。

Method: 研究采用大型语言模型作为专家规划器，用于多智能体在规划任务中的高效探索。

Result: 未明确提及具体实验结果，但探讨了方法的可行性。

Conclusion: 大型语言模型在多智能体规划任务中具有潜力，可作为高效探索的工具。

Abstract: Efficient exploration is a well known problem in deep reinforcement learning
and this problem is exacerbated in multi-agent reinforcement learning due the
intrinsic complexities of such algorithms. There are several approaches to
efficiently explore an environment to learn to solve tasks by multi-agent
operating in that environment, of which, the idea of expert exploration is
investigated in this work. More specifically, this work investigates the
application of large-language models as expert planners for efficient
exploration in planning based tasks for multiple agents.

</details>


### [7] [ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning](https://arxiv.org/abs/2507.07306)
*Yichen Lu,Wei Dai,Jiaen Liu,Ching Wing Kwok,Zongheng Wu,Xudong Xiao,Ao Sun,Sheng Fu,Jianyuan Zhan,Yian Wang,Takatomo Saito,Sicheng Lai*

Main category: cs.AI

TL;DR: ViDove是一种基于多模态输入的翻译系统，通过结合视觉和上下文信息提升翻译质量，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有LLM翻译代理仅限于文本输入，无法利用多模态信息，ViDove旨在填补这一空白。

Method: ViDove采用多模态记忆系统和长短时记忆模块，结合领域知识，优化翻译过程。

Result: ViDove在字幕生成和翻译任务中表现优异，BLEU分数提升28%，SubER提升15%。

Conclusion: ViDove通过多模态输入显著提升翻译质量，并推出新基准DoveBench。

Abstract: LLM-based translation agents have achieved highly human-like translation
results and are capable of handling longer and more complex contexts with
greater efficiency. However, they are typically limited to text-only inputs. In
this paper, we introduce ViDove, a translation agent system designed for
multimodal input. Inspired by the workflow of human translators, ViDove
leverages visual and contextual background information to enhance the
translation process. Additionally, we integrate a multimodal memory system and
long-short term memory modules enriched with domain-specific knowledge,
enabling the agent to perform more accurately and adaptively in real-world
scenarios. As a result, ViDove achieves significantly higher translation
quality in both subtitle generation and general translation tasks, with a 28%
improvement in BLEU scores and a 15% improvement in SubER compared to previous
state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark
for long-form automatic video subtitling and translation, featuring 17 hours of
high-quality, human-annotated data. Our code is available here:
https://github.com/pigeonai-org/ViDove

</details>


### [8] [On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment](https://arxiv.org/abs/2507.07341)
*Sarah Ball,Greg Gluch,Shafi Goldwasser,Frauke Kreuter,Omer Reingold,Guy N. Rothblum*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型（LLMs）生成有害内容的过滤问题，发现输入和输出过滤均存在计算挑战，并指出外部过滤器无法完全保障安全性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用，防止其生成有害内容成为重要问题。论文旨在探讨过滤技术的有效性及其计算限制。

Method: 通过理论分析，研究输入提示（prompt）和输出过滤的计算复杂性，并基于密码学假设证明其不可行性。

Result: 发现对抗性提示可绕过高效过滤器，且输出过滤在特定情况下计算不可行。外部过滤器无法确保安全性。

Conclusion: 安全性需内置于LLMs的设计中，黑盒访问不足，智能与判断不可分割。

Abstract: With the increased deployment of large language models (LLMs), one concern is
their potential misuse for generating harmful content. Our work studies the
alignment challenge, with a focus on filters to prevent the generation of
unsafe information. Two natural points of intervention are the filtering of the
input prompt before it reaches the model, and filtering the output after
generation. Our main results demonstrate computational challenges in filtering
both prompts and outputs. First, we show that there exist LLMs for which there
are no efficient prompt filters: adversarial prompts that elicit harmful
behavior can be easily constructed, which are computationally indistinguishable
from benign prompts for any efficient filter. Our second main result identifies
a natural setting in which output filtering is computationally intractable. All
of our separation results are under cryptographic hardness assumptions. In
addition to these core findings, we also formalize and study relaxed mitigation
approaches, demonstrating further computational barriers. We conclude that
safety cannot be achieved by designing filters external to the LLM internals
(architecture and weights); in particular, black-box access to the LLM will not
suffice. Based on our technical results, we argue that an aligned AI system's
intelligence cannot be separated from its judgment.

</details>


### [9] [Supply Chain Optimization via Generative Simulation and Iterative Decision Policies](https://arxiv.org/abs/2507.07355)
*Haoyue Bai,Haoyu Wang,Nanxu Gong,Xinyuan Wang,Wangyang Ying,Haifeng Chen,Yanjie Fu*

Main category: cs.AI

TL;DR: Sim-to-Dec框架结合生成模拟模块和双感知决策模型，显著提升供应链运输的及时交付率和利润。


<details>
  <summary>Details</summary>
Motivation: 供应链运输中的高响应性和经济效率受运输模式战略决策影响，需一种可观察、低风险的策略设计环境。

Method: 提出Sim-to-Dec框架，包括生成模拟模块（利用自回归建模）和双感知决策模型（通过端到端优化迭代改进）。

Result: 在三个真实数据集上的实验表明，Sim-to-Dec显著提高了及时交付率和利润。

Conclusion: Sim-to-Dec满足通用性、细粒度动态、历史与预测结合及模拟反馈与策略优化的紧密集成要求。

Abstract: High responsiveness and economic efficiency are critical objectives in supply
chain transportation, both of which are influenced by strategic decisions on
shipping mode. An integrated framework combining an efficient simulator with an
intelligent decision-making algorithm can provide an observable, low-risk
environment for transportation strategy design. An ideal simulation-decision
framework must (1) generalize effectively across various settings, (2) reflect
fine-grained transportation dynamics, (3) integrate historical experience with
predictive insights, and (4) maintain tight integration between simulation
feedback and policy refinement. We propose Sim-to-Dec framework to satisfy
these requirements. Specifically, Sim-to-Dec consists of a generative
simulation module, which leverages autoregressive modeling to simulate
continuous state changes, reducing dependence on handcrafted domain-specific
rules and enhancing robustness against data fluctuations; and a history-future
dual-aware decision model, refined iteratively through end-to-end optimization
with simulator interactions. Extensive experiments conducted on three
real-world datasets demonstrate that Sim-to-Dec significantly improves timely
delivery rates and profit.

</details>


### [10] [DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](https://arxiv.org/abs/2507.07426)
*Zerui Yang,Yuwei Wan,Yinqiao Li,Yudai Matsuda,Tong Xie,Linqi Song*

Main category: cs.AI

TL;DR: DrugMCTS结合RAG、多智能体协作和蒙特卡洛树搜索，提出了一种无需领域微调的药物重定位框架，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学领域（如药物发现）的潜力受限于预训练知识外的推理能力，传统方法存在计算开销大或未能充分利用结构化科学数据的问题。

Method: DrugMCTS框架整合RAG、多智能体协作和蒙特卡洛树搜索，通过五个专业智能体检索和分析分子与蛋白质信息，实现结构化迭代推理。

Result: 在DrugBank和KIBA数据集上，DrugMCTS的召回率和鲁棒性显著优于通用LLM和深度学习基线，性能提升超过20%。

Conclusion: 结构化推理、智能体协作和反馈驱动搜索机制对推进LLM在药物发现中的应用至关重要。

Abstract: Recent advances in large language models have demonstrated considerable
potential in scientific domains such as drug discovery. However, their
effectiveness remains constrained when reasoning extends beyond the knowledge
acquired during pretraining. Conventional approaches, such as fine-tuning or
retrieval-augmented generation, face limitations in either imposing high
computational overhead or failing to fully exploit structured scientific data.
To overcome these challenges, we propose DrugMCTS, a novel framework that
synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree
Search for drug repurposing. The framework employs five specialized agents
tasked with retrieving and analyzing molecular and protein information, thereby
enabling structured and iterative reasoning. Without requiring domain-specific
fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by
over 20\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate
that DrugMCTS achieves substantially higher recall and robustness compared to
both general-purpose LLMs and deep learning baselines. Our results highlight
the importance of structured reasoning, agent-based collaboration, and
feedback-driven search mechanisms in advancing LLM applications for drug
discovery.

</details>


### [11] [StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley](https://arxiv.org/abs/2507.07445)
*Weihao Tan,Changjiu Jiang,Yu Duan,Mingcong Lei,Jiageng Li,Yitian Hong,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: StarDojo是一个基于Stardew Valley的新型基准测试，用于评估AI代理在开放式生产生活模拟中的表现，涵盖农业、手工艺、探索、战斗和社交互动等领域。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试很少同时评估生产活动和社会互动能力，StarDojo旨在填补这一空白。

Method: 设计了1,000个任务和100个代表性子集，提供统一接口支持多环境并行执行，评估多模态大语言模型（MLLMs）代理的能力。

Result: 当前最先进的MLLMs代理表现有限，GPT-4.1成功率仅12.7%，主要因视觉理解、多模态推理和低级操作困难。

Conclusion: StarDojo旨在推动复杂生产生活环境中稳健开放式代理的研究。

Abstract: Autonomous agents navigating human society must master both production
activities and social interactions, yet existing benchmarks rarely evaluate
these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel
benchmark based on Stardew Valley, designed to assess AI agents in open-ended
production-living simulations. In StarDojo, agents are tasked to perform
essential livelihood activities such as farming and crafting, while
simultaneously engaging in social interactions to establish relationships
within a vibrant community. StarDojo features 1,000 meticulously curated tasks
across five key domains: farming, crafting, exploration, combat, and social
interactions. Additionally, we provide a compact subset of 100 representative
tasks for efficient model evaluation. The benchmark offers a unified,
user-friendly interface that eliminates the need for keyboard and mouse
control, supports all major operating systems, and enables the parallel
execution of multiple environment instances, making it particularly well-suited
for evaluating the most capable foundation agents, powered by multimodal large
language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents
demonstrate substantial limitations, with the best-performing model, GPT-4.1,
achieving only a 12.7% success rate, primarily due to challenges in visual
understanding, multimodal reasoning and low-level manipulation. As a
user-friendly environment and benchmark, StarDojo aims to facilitate further
research towards robust, open-ended agents in complex production-living
environments.

</details>


### [12] [Position: We Need An Algorithmic Understanding of Generative AI](https://arxiv.org/abs/2507.07544)
*Oliver Eberle,Thomas McGee,Hamza Giaffar,Taylor Webb,Ida Momennejad*

Main category: cs.AI

TL;DR: AlgEval是一个研究框架，旨在揭示LLMs学习和使用的算法，通过分析潜在表示、注意力和推理计算，以理解其任务解决方式。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注通过规模提升性能，而对LLMs学习的算法缺乏理论和实证理解，AlgEval填补了这一空白。

Method: AlgEval结合自上而下的假设和自下而上的电路级分析（如注意力模式和隐藏状态），研究LLMs的算法。

Result: 案例研究表明了候选算法的形成和验证，为理解LLMs的内部计算提供了系统方法。

Conclusion: AlgEval为LLMs的算法解释提供了路径，有助于提高训练效率和设计新型架构。

Abstract: What algorithms do LLMs actually learn and use to solve problems? Studies
addressing this question are sparse, as research priorities are focused on
improving performance through scale, leaving a theoretical and empirical gap in
understanding emergent algorithms. This position paper proposes AlgEval: a
framework for systematic research into the algorithms that LLMs learn and use.
AlgEval aims to uncover algorithmic primitives, reflected in latent
representations, attention, and inference-time compute, and their algorithmic
composition to solve task-specific problems. We highlight potential
methodological paths and a case study toward this goal, focusing on emergent
search algorithms. Our case study illustrates both the formation of top-down
hypotheses about candidate algorithms, and bottom-up tests of these hypotheses
via circuit-level analysis of attention patterns and hidden states. The
rigorous, systematic evaluation of how LLMs actually solve tasks provides an
alternative to resource-intensive scaling, reorienting the field toward a
principled understanding of underlying computations. Such algorithmic
explanations offer a pathway to human-understandable interpretability, enabling
comprehension of the model's internal reasoning performance measures. This can
in turn lead to more sample-efficient methods for training and improving
performance, as well as novel architectures for end-to-end and multi-agent
systems.

</details>


### [13] [On Trustworthy Rule-Based Models and Explanations](https://arxiv.org/abs/2507.07576)
*Mohamed Siala,Jordi Planes,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 论文探讨了机器学习中解释预测的重要性，尤其是在高风险领域，并分析了基于规则的模型中的负面特征（如冗余和重叠）。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域，错误的解释可能误导决策者，因此需要严格的解释方法。基于规则的模型虽然广泛使用，但其负面特征可能影响解释的可靠性。

Method: 开发了分析基于规则模型中负面特征的算法，包括负重叠和冗余。

Result: 研究发现，广泛使用的基于规则学习工具生成的规则集往往表现出一种或多种负面特征。

Conclusion: 基于规则的模型在高风险应用中需谨慎使用，以避免负面特征对解释的误导。

Abstract: A task of interest in machine learning (ML) is that of ascribing explanations
to the predictions made by ML models. Furthermore, in domains deemed high risk,
the rigor of explanations is paramount. Indeed, incorrect explanations can and
will mislead human decision makers. As a result, and even if interpretability
is acknowledged as an elusive concept, so-called interpretable models are
employed ubiquitously in high-risk uses of ML and data mining (DM). This is the
case for rule-based ML models, which encompass decision trees, diagrams, sets
and lists. This paper relates explanations with well-known undesired facets of
rule-based ML models, which include negative overlap and several forms of
redundancy. The paper develops algorithms for the analysis of these undesired
facets of rule-based systems, and concludes that well-known and widely used
tools for learning rule-based ML models will induce rule sets that exhibit one
or more negative facets.

</details>


### [14] [Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs](https://arxiv.org/abs/2507.07595)
*Zhixiang Su,Di Wang,Chunyan Miao*

Main category: cs.AI

TL;DR: 论文提出了一种名为Context Pooling的新方法，用于提升基于GNN的知识图谱链接预测性能，首次将图池化应用于知识图谱，并在42/48的实验中达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有GNN模型在知识图谱链接预测中表现平平，尤其是vanilla聚合方法效果有限，需要更高效的方法。

Method: 提出Context Pooling方法，通过设计邻域精度和邻域召回率指标，筛选逻辑相关邻居，生成查询特定图。

Result: 在三个公开数据集上应用于两个SOTA模型，42/48情况下达到SOTA性能。

Conclusion: Context Pooling显著提升了GNN在知识图谱链接预测中的表现，尤其在未见实体的归纳设置中表现突出。

Abstract: Recent investigations on the effectiveness of Graph Neural Network
(GNN)-based models for link prediction in Knowledge Graphs (KGs) show that
vanilla aggregation does not significantly impact the model performance. In
this paper, we introduce a novel method, named Context Pooling, to enhance
GNN-based models' efficacy for link predictions in KGs. To our best of
knowledge, Context Pooling is the first methodology that applies graph pooling
in KGs. Additionally, Context Pooling is first-of-its-kind to enable the
generation of query-specific graphs for inductive settings, where testing
entities are unseen during training. Specifically, we devise two metrics,
namely neighborhood precision and neighborhood recall, to assess the neighbors'
logical relevance regarding the given queries, thereby enabling the subsequent
comprehensive identification of only the logically relevant neighbors for link
prediction. Our method is generic and assessed by being applied to two
state-of-the-art (SOTA) models on three public transductive and inductive
datasets, achieving SOTA performance in 42 out of 48 settings.

</details>


### [15] [Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.07599)
*Sedigh Khademi,Jim Black,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

Main category: cs.AI

TL;DR: 研究评估了微调的Llama 3.2模型从急诊分诊记录中提取疫苗相关信息的能力，以支持近实时疫苗安全监测。


<details>
  <summary>Details</summary>
Motivation: 通过自动化数据提取提高疫苗安全监测效率，早期发现疫苗接种后的不良事件。

Method: 使用提示工程创建标注数据集，并由人工确认；比较提示工程模型、微调模型和基于规则的方法。

Result: 微调的Llama 3B参数模型在提取疫苗名称的准确性上优于其他模型，量化技术使其在资源受限环境中高效部署。

Conclusion: 大语言模型在自动化急诊记录数据提取中具有潜力，可支持高效的疫苗安全监测。

Abstract: This study evaluates fine-tuned Llama 3.2 models for extracting
vaccine-related information from emergency department triage notes to support
near real-time vaccine safety surveillance. Prompt engineering was used to
initially create a labeled dataset, which was then confirmed by human
annotators. The performance of prompt-engineered models, fine-tuned models, and
a rule-based approach was compared. The fine-tuned Llama 3 billion parameter
model outperformed other models in its accuracy of extracting vaccine names.
Model quantization enabled efficient deployment in resource-constrained
environments. Findings demonstrate the potential of large language models in
automating data extraction from emergency department notes, supporting
efficient vaccine safety surveillance and early detection of emerging adverse
events following immunization issues.

</details>


### [16] [Towards conservative inference in credal networks using belief functions: the case of credal chains](https://arxiv.org/abs/2507.07619)
*Marco Sangalli,Thomas Krak,Cassio de Campos*

Main category: cs.AI

TL;DR: 本文提出了一种基于Dempster-Shafer理论的信念推理框架，用于在链式信用网络中传播不确定性，结合计算速度与鲁棒的表示方法。


<details>
  <summary>Details</summary>
Motivation: 探索如何在信用网络中高效且鲁棒地传播不确定性，特别是针对链式结构。

Method: 提出了一种基于信念和可信度函数的框架，通过保守区间传播不确定性，并与经典敏感性分析进行比较。

Result: 数值结果表明该方法在链式信用网络中具有优势，但也存在局限性。

Conclusion: 该框架为链式信用网络提供了实用的信念推理方法，并对其在更广泛信用网络中的应用提供了启示。

Abstract: This paper explores belief inference in credal networks using Dempster-Shafer
theory. By building on previous work, we propose a novel framework for
propagating uncertainty through a subclass of credal networks, namely chains.
The proposed approach efficiently yields conservative intervals through belief
and plausibility functions, combining computational speed with robust
uncertainty representation. Key contributions include formalizing belief-based
inference methods and comparing belief-based inference against classical
sensitivity analysis. Numerical results highlight the advantages and
limitations of applying belief inference within this framework, providing
insights into its practical utility for chains and for credal networks in
general.

</details>


### [17] [PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations](https://arxiv.org/abs/2507.07644)
*Fedor Rodionov,Abdelrahman Eldesokey,Michael Birsak,John Femiani,Bernard Ghanem,Peter Wonka*

Main category: cs.AI

TL;DR: PlanQA是一个用于评估大语言模型（LLM）几何和空间推理能力的诊断基准，基于室内场景的结构化表示，揭示LLM在真实世界布局推理中的盲点。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在几何和空间推理方面存在不足，尤其是在模拟物理约束和保持空间一致性方面表现不佳，PlanQA旨在填补这一空白。

Method: PlanQA使用符号化格式（如JSON、XML）编码室内场景，设计多样化问题类型测试度量、拓扑推理及设计约束。

Result: 实验显示，LLM在浅层查询中表现尚可，但在物理约束模拟、空间一致性保持及布局扰动下的泛化能力上表现不佳。

Conclusion: PlanQA揭示了LLM在真实世界布局推理中的盲点，为未来开发能准确推理和操作空间几何属性的语言模型提供了方向。

Abstract: We introduce PlanQA, a diagnostic benchmark for evaluating geometric and
spatial reasoning in large-language models (LLMs). PlanQA is grounded in
structured representations of indoor scenes, such as kitchens, living rooms,
and bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The
benchmark includes diverse question types that test not only metric and
topological reasoning (e.g., distance, visibility, shortest paths) but also
interior design constraints such as affordance, clearance, balance, and
usability. Our results across a variety of frontier open-source and commercial
LLMs show that while models may succeed in shallow queries, they often fail to
simulate physical constraints, preserve spatial coherence, or generalize under
layout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they
do not consistently reason about real-world layouts. We hope that this
benchmark inspires new work on language models that can accurately infer and
manipulate spatial and geometric properties in practical settings.

</details>


### [18] [Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization](https://arxiv.org/abs/2507.07723)
*Chengtao Jian,Kai Yang,Ye Ouyang,Xiaozhou Ye*

Main category: cs.AI

TL;DR: 本文分析了直接偏好优化（DPO）的理论局限性和动态特性，并提出了一种基于双层优化的稳定偏好优化方法，以改进模型对齐的稳定性和一致性。


<details>
  <summary>Details</summary>
Motivation: 尽管DPO在实证中表现良好，但其理论特性和内在局限性尚未充分研究。研究发现DPO对初始化敏感且容易错误分配概率质量，可能无意中强化模型偏见。

Method: 提出了一种基于双层优化的稳定偏好优化框架，结合监督微调和改进的DPO目标，引入正则化方案以明确鼓励对偏好输出的绝对概率提升。

Result: 实验表明，该方法在推理和摘要任务中显著提升了推理准确性，并更好地对齐输出分布与预期偏好，优于标准DPO。

Conclusion: 稳定偏好优化为偏好对齐目标的设计提供了新见解，并为更可靠和可解释的语言模型对齐开辟了新途径。

Abstract: Direct Preference Optimization (DPO) has emerged as a popular and efficient
alternative to reward modeling and reinforcement learning for aligning language
models with human preferences. Despite its empirical success, the theoretical
properties and intrinsic limitations of DPO remain underexplored. In this work,
we first present a comprehensive analysis of DPO's dynamics from a probability
evolution perspective. Our analysis reveals that DPO is highly sensitive to
initialization. It also tends to misallocate probability mass, which can
inadvertently shift probability toward irrelevant or undesired responses. This
misallocation may unintentionally reinforce model bias, thereby compromising
both the stability of model alignment and the consistency with intended
preferences. Motivated by these theoretical findings, we propose a
theoretically grounded bilevel optimization framework that tightly integrate
supervised fine-tuning with an enhanced DPO objective a.k.a. stable preference
optimization. Our approach introduces a principled regularization scheme to
explicitly encourage absolute probability improvement for preferred outputs,
while maintaining stable optimization dynamics. Experiments on challenging
reasoning and summarization benchmarks elucidate that our method consistently
improves reasoning accuracy and better aligns output distributions with
intended preferences, outperforming standard DPO. Stable preference
optimization provides new insights into the design of preference-based
alignment objectives and opens up new avenues towards more reliable and
interpretable language model alignment.

</details>


### [19] [Identification of Violin Reduction via Contour Lines Classification](https://arxiv.org/abs/2507.07743)
*Philémon Beghin,Anne-Emmanuelle Ceulemans,François Glineur*

Main category: cs.AI

TL;DR: 本文提出了一种基于轮廓线分类小提琴是否被缩小的方法，通过几何特征分析实现了对缩小与非缩小乐器的区分。


<details>
  <summary>Details</summary>
Motivation: 历史上小提琴制作标准的变化导致部分乐器被缩小，但其几何特征差异未被量化研究。

Method: 利用摄影测量获取25把小提琴的3D几何网格，提取轮廓线并拟合抛物线曲线，计算参数特征后进行分类。

Result: 研究发现几何特征可以一定程度上区分缩小与非缩小乐器，其中开口参数β最具预测性。

Conclusion: 几何方法可用于小提琴缩小分类，但需考虑乐器变形的多样性。

Abstract: The first violins appeared in late 16th-century Italy. Over the next 200
years, they spread across Europe and luthiers of various royal courts, eager to
experiment with new techniques, created a highly diverse family of instruments.
Around 1750, size standards were introduced to unify violin making for
orchestras and conservatories. Instruments that fell between two standards were
then reduced to a smaller size by luthiers. These reductions have an impact on
several characteristics of violins, in particular on the contour lines, i.e.
lines of constant altitude, which look more like a U for non reduced
instruments and a V for reduced ones. While such differences are observed by
experts, they have not been studied quantitatively.
  This paper presents a method for classifying violins as reduced or
non-reduced based on their contour lines. We study a corpus of 25 instruments
whose 3D geometric meshes were acquired via photogrammetry. For each
instrument, we extract 10-20 contour lines regularly spaced every millimetre.
Each line is fitted with a parabola-like curve (with an equation of the type y
= alpha*abs(x)**beta) depending on two parameters, describing how open (beta)
and how vertically stretched (alpha) the curve is. We compute additional
features from those parameters, using regressions and counting how many values
fall under some threshold. We also deal with outliers and non equal numbers of
levels, and eventually obtain a numerical profile for each instrument.
  We then apply classification methods to assess whether geometry alone can
predict size reduction. We find that distinguishing between reduced and non
reduced instruments is feasible to some degree, taking into account that a
whole spectrum of more or less transformed violins exists, for which it is more
difficult to quantify the reduction. We also find the opening parameter beta to
be the most predictive.

</details>


### [20] [Measuring AI Alignment with Human Flourishing](https://arxiv.org/abs/2507.07787)
*Elizabeth Hilliard,Akshaya Jagadeesh,Alex Cook,Steele Billings,Nicholas Skytland,Alicia Llewellyn,Jackson Paull,Nathan Paull,Nolan Kurylo,Keatra Nesbitt,Robert Gruenewald,Anthony Jantzi,Omar Chavez*

Main category: cs.AI

TL;DR: FAI Benchmark评估AI在七个维度上对人类繁荣的贡献，发现当前模型在信仰与灵性、品德与美德、意义与目的方面表现不足。


<details>
  <summary>Details</summary>
Motivation: 传统AI评估仅关注技术能力或危害预防，而FAI Benchmark旨在衡量AI对人类全面繁荣的贡献。

Method: 通过1,229个主客观问题，结合专业LLM评估和几何平均评分，对28个领先语言模型进行测试。

Result: 最高分模型仅72/100，无模型在所有维度上表现良好，尤其在信仰与灵性、品德与美德、意义与目的方面。

Conclusion: FAI Benchmark为开发支持人类繁荣的AI系统提供了框架，对AI发展、伦理和评估有重要意义。

Abstract: This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel
evaluation framework that assesses AI alignment with human flourishing across
seven dimensions: Character and Virtue, Close Social Relationships, Happiness
and Life Satisfaction, Meaning and Purpose, Mental and Physical Health,
Financial and Material Stability, and Faith and Spirituality. Unlike
traditional benchmarks that focus on technical capabilities or harm prevention,
the FAI Benchmark measures AI performance on how effectively models contribute
to the flourishing of a person across these dimensions. The benchmark evaluates
how effectively LLM AI systems align with current research models of holistic
human well-being through a comprehensive methodology that incorporates 1,229
objective and subjective questions. Using specialized judge Large Language
Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs
geometric mean scoring to ensure balanced performance across all flourishing
dimensions. Initial testing of 28 leading language models reveals that while
some models approach holistic alignment (with the highest-scoring models
achieving 72/100), none are acceptably aligned across all dimensions,
particularly in Faith and Spirituality, Character and Virtue, and Meaning and
Purpose. This research establishes a framework for developing AI systems that
actively support human flourishing rather than merely avoiding harm, offering
significant implications for AI development, ethics, and evaluation.

</details>


### [21] [MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving](https://arxiv.org/abs/2507.07818)
*Lu Xu,Jiaqian Yu,Xiongfeng Peng,Yiwei Chen,Weiming Li,Jaewook Yoo,Sunghyun Chunag,Dongwook Lee,Daehyun Ji,Chao Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种技能导向的混合专家模型（MoSE），模仿人类驾驶员的学习和推理过程，通过技能分步学习提升自动驾驶性能，同时减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有混合专家模型（MoE）需要大量数据和复杂优化，而人类驾驶员的学习过程更具效率。MoSE旨在通过技能导向的路由机制，模仿人类的学习和推理方式，提升模型性能。

Method: MoSE通过定义和标注特定技能，构建分层技能数据集，并预训练路由器，实现技能分步学习和多步规划推理。模型在单次前向过程中整合辅助任务，无需额外计算成本。

Result: MoSE在CODA AD任务中表现优于多个8B+参数模型，激活参数量减少至少62.5%，且性能达到当前最优。

Conclusion: MoSE通过模仿人类学习过程，显著提升了自动驾驶模型的性能和效率，为轻量化模型设计提供了新思路。

Abstract: Recent studies show large language models (LLMs) and vision language models
(VLMs) trained using web-scale data can empower end-to-end autonomous driving
systems for a better generalization and interpretation. Specifically, by
dynamically routing inputs to specialized subsets of parameters, the
Mixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve
substantial performance improvements while maintaining computational
efficiency. However, general MoE models usually demands extensive training data
and complex optimization. In this work, inspired by the learning process of
human drivers, we propose a skill-oriented MoE, called MoSE, which mimics human
drivers' learning process and reasoning process, skill-by-skill and
step-by-step. We propose a skill-oriented routing mechanism that begins with
defining and annotating specific skills, enabling experts to identify the
necessary driving competencies for various scenarios and reasoning tasks,
thereby facilitating skill-by-skill learning. Further align the driving process
to multi-step planning in human reasoning and end-to-end driving models, we
build a hierarchical skill dataset and pretrain the router to encourage the
model to think step-by-step. Unlike multi-round dialogs, MoSE integrates
valuable auxiliary tasks (e.g.\ description, reasoning, planning) in one single
forward process without introducing any extra computational cost. With less
than 3B sparsely activated parameters, our model outperforms several 8B+
parameters on CODA AD corner case reasoning task. Compared to existing methods
based on open-source models and data, our approach achieves state-of-the-art
performance with significantly reduced activated model size (at least by
$62.5\%$) with a single-turn conversation.

</details>


### [22] [AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift](https://arxiv.org/abs/2507.07820)
*Eunsu Baek,Keondo Park,Jeonggil Ko,Min-hwan Oh,Taesik Gong,Hyung-Sin Kim*

Main category: cs.AI

TL;DR: 论文提出自适应感知作为AI发展的新范式，通过动态调整传感器参数提升效率和鲁棒性，减少对大规模模型和数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前AI依赖大规模模型和数据集，带来环境、经济和伦理成本，限制了可持续性和公平性。生物感官系统的动态适应性启发了这一研究。

Method: 提出自适应感知方法，动态调整传感器参数（如曝光、灵敏度、多模态配置），以应对协变量偏移并提升效率。

Result: 实验证明自适应感知能使小模型（如EfficientNet-B0）超越更大模型（如OpenCLIP-H）的性能。

Conclusion: 论文呼吁将自适应感知整合到实际应用中，并提出研究方向（如标准化基准、实时算法、隐私保护方法），以推动可持续、鲁棒和公平的AI系统。

Abstract: Current AI advances largely rely on scaling neural models and expanding
training datasets to achieve generalization and robustness. Despite notable
successes, this paradigm incurs significant environmental, economic, and
ethical costs, limiting sustainability and equitable access. Inspired by
biological sensory systems, where adaptation occurs dynamically at the input
(e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive
sensing as a necessary and foundational shift. Adaptive sensing proactively
modulates sensor parameters (e.g., exposure, sensitivity, multimodal
configurations) at the input level, significantly mitigating covariate shifts
and improving efficiency. Empirical evidence from recent studies demonstrates
that adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass
substantially larger models (e.g., OpenCLIP-H) trained with significantly more
data and compute. We (i) outline a roadmap for broadly integrating adaptive
sensing into real-world applications spanning humanoid, healthcare, autonomous
systems, agriculture, and environmental monitoring, (ii) critically assess
technical and ethical integration challenges, and (iii) propose targeted
research directions, such as standardized benchmarks, real-time adaptive
algorithms, multimodal integration, and privacy-preserving methods.
Collectively, these efforts aim to transition the AI community toward
sustainable, robust, and equitable artificial intelligence systems.

</details>


### [23] [Searching for actual causes: Approximate algorithms with adjustable precision](https://arxiv.org/abs/2507.07857)
*Samuel Reyd,Ada Diaconescu,Jean-Louis Dessalles*

Main category: cs.AI

TL;DR: 论文提出了一种多项式复杂度的算法，用于识别实际原因，解决了现有方法无法处理的非布尔、黑盒和随机系统问题。


<details>
  <summary>Details</summary>
Motivation: 现有可解释人工智能（XAI）和因果性研究未能满足非专家用户对解释的需求，且识别实际原因是一个NP完全问题，缺乏实用解决方案。

Method: 提出了一组多项式复杂度的算法，可调整精度和全面性，适用于非布尔、黑盒和随机系统。

Result: 实验表明，算法能识别现有方法无法处理的系统原因，且可通过增加计算时间提高精度和全面性。

Conclusion: 该算法为解决实际原因识别问题提供了实用且灵活的解决方案。

Abstract: Causality has gained popularity in recent years. It has helped improve the
performance, reliability, and interpretability of machine learning models.
However, recent literature on explainable artificial intelligence (XAI) has
faced criticism. The classical XAI and causality literature focuses on
understanding which factors contribute to which consequences. While such
knowledge is valuable for researchers and engineers, it is not what non-expert
users expect as explanations. Instead, these users often await facts that cause
the target consequences, i.e., actual causes. Formalizing this notion is still
an open problem. Additionally, identifying actual causes is reportedly an
NP-complete problem, and there are too few practical solutions to approximate
formal definitions. We propose a set of algorithms to identify actual causes
with a polynomial complexity and an adjustable level of precision and
exhaustiveness. Our experiments indicate that the algorithms (1) identify
causes for different categories of systems that are not handled by existing
approaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be
adjusted to gain more precision and exhaustiveness with more computation time.

</details>


### [24] [An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis](https://arxiv.org/abs/2507.07893)
*Mingda Zhang,Na Zhao,Jianglong Qing,Qing xu,Kaiwen Pan,Ting luo*

Main category: cs.AI

TL;DR: 论文提出了一种结合提示工程和多维知识图谱的增强框架，以解决大语言模型在法律纠纷分析中的局限性，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在法律纠纷分析中存在法律知识表示不足、概念理解有限和推理缺陷等问题，亟需改进。

Method: 提出三阶段分层提示结构（任务定义、知识背景、推理指导）和三层次知识图谱架构（分类本体、表示层、实例层），结合四种精准法律概念检索方法。

Result: 实验结果表明，该框架显著提升了法律纠纷分析的性能，能准确分析复杂案件的法律适用，并深入理解司法决策逻辑。

Conclusion: 该研究为智能法律辅助系统的实现提供了新颖的技术路径。

Abstract: The rapid development of artificial intelligence has positioned large
language models as fundamental components of intelligent legal systems.
However, these models face significant limitations in legal dispute analysis,
including insufficient legal knowledge representation, limited concept
understanding, and reasoning deficiencies. This research proposes an enhanced
framework integrating prompt engineering with multidimensional knowledge
graphs. The framework introduces a three-stage hierarchical prompt structure
comprising task definition, knowledge background, and reasoning guidance,
supplemented by legal-specific reasoning templates and dynamic optimization
mechanisms. A three-layer knowledge graph architecture is constructed with
legal classification ontology, representation, and instance layers. Four
complementary methods enable precise legal concept retrieval: direct legal norm
code matching, domain-specific semantic vector similarity, ontology-based path
reasoning, and specialized lexical segmentation. These components integrate
with web search technology to establish a knowledge-enhanced framework for
legal decision-making. Experimental results demonstrate significant performance
improvements in legal dispute analysis, enabling accurate legal application
analysis for complex cases while exhibiting nuanced understanding of judicial
decision-making logic, providing a novel technical approach for implementing
intelligent legal assistance systems.

</details>


### [25] [Meek Models Shall Inherit the Earth](https://arxiv.org/abs/2507.07931)
*Hans Gundlach,Jayson Lynch,Neil Thompson*

Main category: cs.AI

TL;DR: 论文认为，随着计算规模收益递减，AI模型能力将趋同，资源有限的模型将接近最佳模型的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨AI模型性能不平等问题，提出计算规模收益递减将导致能力趋同的观点。

Method: 建立模型分析计算规模边际收益递减，结合基准数据和理论模型验证能力差异。

Result: 发现资源有限的模型性能将接近最佳模型，计算优势逐渐消失。

Conclusion: 建议重新审视AI战略与政策，以适应模型能力趋同的趋势。

Abstract: The past decade has seen incredible scaling of AI systems by a few companies,
leading to inequality in AI model performance. This paper argues that, contrary
to prevailing intuition, the diminishing returns to compute scaling will lead
to a convergence of AI model capabilities. In other words, meek models (those
with limited computation budget) shall inherit the earth, approaching the
performance level of the best models overall. We develop a model illustrating
that under a fixed-distribution next-token objective, the marginal capability
returns to raw compute shrink substantially. Given current scaling practices,
we argue that these diminishing returns are strong enough that even companies
that can scale their models exponentially faster than other organizations will
eventually have little advantage in capabilities. As part of our argument, we
give several reasons that proxies like training loss differences capture
important capability measures using evidence from benchmark data and
theoretical performance models. In addition, we analyze empirical data on the
capability difference of AI models over time. Finally, in light of the
increasing ability of meek models, we argue that AI strategy and policy require
reexamination, and we outline the areas this shift will affect.

</details>


### [26] [Working with AI: Measuring the Occupational Implications of Generative AI](https://arxiv.org/abs/2507.07935)
*Kiran Tomlinson,Sonia Jaffe,Will Wang,Scott Counts,Siddharth Suri*

Main category: cs.AI

TL;DR: 研究分析了生成式AI对工作的影响，发现信息收集和写作是最常见的AI辅助任务，知识型职业的AI适用性最高。


<details>
  <summary>Details</summary>
Motivation: 理解AI对经济的影响是社会的关键问题，研究通过分析AI辅助的工作活动和职业适用性迈出第一步。

Method: 分析了20万条用户与Microsoft Bing Copilot的匿名对话数据，结合职业活动分类和任务成功度量，计算职业的AI适用性分数。

Result: 信息提供、写作、教学和咨询是AI最常见的活动；计算机、数学、行政支持和销售等职业的AI适用性最高。

Conclusion: 知识型职业和涉及信息沟通的职业最易受AI影响，研究为AI对职业的潜在影响提供了实证依据。

Abstract: Given the rapid adoption of generative AI and its potential to impact a wide
range of tasks, understanding the effects of AI on the economy is one of
society's most important questions. In this work, we take a step toward that
goal by analyzing the work activities people do with AI, how successfully and
broadly those activities are done, and combine that with data on what
occupations do those activities. We analyze a dataset of 200k anonymized and
privacy-scrubbed conversations between users and Microsoft Bing Copilot, a
publicly available generative AI system. We find the most common work
activities people seek AI assistance for involve gathering information and
writing, while the most common activities that AI itself is performing are
providing information and assistance, writing, teaching, and advising.
Combining these activity classifications with measurements of task success and
scope of impact, we compute an AI applicability score for each occupation. We
find the highest AI applicability scores for knowledge work occupation groups
such as computer and mathematical, and office and administrative support, as
well as occupations such as sales whose work activities involve providing and
communicating information. Additionally, we characterize the types of work
activities performed most successfully, how wage and education correlate with
AI applicability, and how real-world usage compares to predictions of
occupational AI impact.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [27] [g2o vs. Ceres: Optimizing Scan Matching in Cartographer SLAM](https://arxiv.org/abs/2507.07142)
*Quanjie Qiu,MengCheng Lau*

Main category: cs.RO

TL;DR: 比较g2o和Ceres在Cartographer框架中优化扫描匹配性能的表现，Ceres在速度、收敛效率和地图清晰度上优于g2o，而g2o在局部障碍物检测中表现更好。


<details>
  <summary>Details</summary>
Motivation: 评估g2o与Ceres在SLAM库Cartographer中的性能差异，以优化姿态估计和地图精度。

Method: 在Cartographer框架中对比g2o和Ceres的性能、效率和准确性，使用AgileX LIMO机器人进行实验。

Result: Ceres在速度、收敛效率和地图清晰度上优于g2o，但g2o在局部障碍物检测中表现更佳。

Conclusion: Ceres更适合Cartographer中的全局优化任务，而g2o在特定场景（如局部障碍物检测）中更具优势。

Abstract: This article presents a comparative analysis of g2o and Ceres solvers in
enhancing scan matching performance within the Cartographer framework.
Cartographer, a widely-used library for Simultaneous Localization and Mapping
(SLAM), relies on optimization algorithms to refine pose estimates and improve
map accuracy. The research aims to evaluate the performance, efficiency, and
accuracy of the g2o solver in comparison to the Ceres solver, which is the
default in Cartographer. In our experiments comparing Ceres and g2o within
Cartographer, Ceres outperformed g2o in terms of speed, convergence efficiency,
and overall map clarity. Ceres required fewer iterations and less time to
converge, producing more accurate and well-defined maps, especially in
real-world mapping scenarios with the AgileX LIMO robot. However, g2o excelled
in localized obstacle detection, highlighting its value in specific situations.

</details>


### [28] [Self-Wearing Adaptive Garments via Soft Robotic Unfurling](https://arxiv.org/abs/2507.07221)
*Nam Gyun Kim,William E. Heap,Yimeng Qin,Elvy B. Yao,Jee-Hwan Ryu,Allison M. Okamura*

Main category: cs.RO

TL;DR: 提出了一种新型软机器人穿衣系统SWAG，通过展开和生长机制实现自主穿衣，解决了传统刚性机器人处理变形衣物和确保安全互动的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有机器人穿衣方案依赖刚性机械臂，操作时间长、控制复杂且限制用户姿势，实用性差。SWAG旨在提供更安全高效的穿衣辅助。

Method: 采用展开式部署方法，SWAG贴合人体，减少皮肤与衣物摩擦，设计并展示了其工作原理和性能。

Result: SWAG在不同衣物配置下表现出色，为传统机器人穿衣辅助提供了有前景的替代方案。

Conclusion: SWAG通过软机器人技术实现了高效、安全的穿衣辅助，具有广泛的应用潜力。

Abstract: Robotic dressing assistance has the potential to improve the quality of life
for individuals with limited mobility. Existing solutions predominantly rely on
rigid robotic manipulators, which have challenges in handling deformable
garments and ensuring safe physical interaction with the human body. Prior
robotic dressing methods require excessive operation times, complex control
strategies, and constrained user postures, limiting their practicality and
adaptability. This paper proposes a novel soft robotic dressing system, the
Self-Wearing Adaptive Garment (SWAG), which uses an unfurling and growth
mechanism to facilitate autonomous dressing. Unlike traditional approaches,the
SWAG conforms to the human body through an unfurling based deployment method,
eliminating skin-garment friction and enabling a safer and more efficient
dressing process. We present the working principles of the SWAG, introduce its
design and fabrication, and demonstrate its performance in dressing assistance.
The proposed system demonstrates effective garment application across various
garment configurations, presenting a promising alternative to conventional
robotic dressing assistance.

</details>


### [29] [3D Steering and Localization in Pipes and Burrows using an Externally Steered Soft Growing Robot](https://arxiv.org/abs/2507.07225)
*Yimeng Qin,Jared Grinberg,William Heap,Allison M. Okamura*

Main category: cs.RO

TL;DR: 本文介绍了一种可转向的藤蔓机器人，专为管道和洞穴环境设计，具有主动分支选择、小半径导航、灵活转向和实时定位功能。


<details>
  <summary>Details</summary>
Motivation: 现有藤蔓机器人在人造和自然通道中导航困难，尤其是在分支和急转弯处。本文旨在解决这些问题。

Method: 采用外部尖端安装设计，通过改变生长方向和支撑管道壁实现三自由度转向。

Result: 机器人实现了51.7度的最大转向角、2.5厘米小半径导航、灵活转向和实时3D定位。

Conclusion: 该设计显著提升了藤蔓机器人在复杂环境中的导航能力，适用于管道和洞穴应用。

Abstract: Navigation and inspection in confined environments, such as tunnels and
pipes, pose significant challenges for existing robots due to limitations in
maneuverability and adaptability to varying geometries. Vine robots, which are
soft growing continuum robots that extend their length through soft material
eversion at their tip, offer unique advantages due to their ability to navigate
tight spaces, adapt to complex paths, and minimize friction. However, existing
vine robot designs struggle with navigation in manmade and natural passageways,
with branches and sharp 3D turns. In this letter, we introduce a steerable vine
robot specifically designed for pipe and burrow environments. The robot
features a simple tubular body and an external tip mount that steers the vine
robot in three degrees of freedom by changing the growth direction and, when
necessary, bracing against the wall of the pipe or burrow. Our external tip
steering approach enables: (1) active branch selection in 3D space with a
maximum steerable angle of 51.7{\deg}, (2) navigation of pipe networks with
radii as small as 2.5 cm, (3) a compliant tip enabling navigation of sharp
turns, and (4) real-time 3D localization in GPS-denied environments using
tip-mounted sensors and continuum body odometry. We describe the forward
kinematics, characterize steerability, and demonstrate the system in a 3D pipe
system as well as a natural animal burrow.

</details>


### [30] [LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation](https://arxiv.org/abs/2507.07299)
*Sonia Raychaudhuri,Enrico Cancelli,Tommaso Campari,Lamberto Ballan,Manolis Savva,Angel X. Chang*

Main category: cs.RO

TL;DR: LangNav是一个专注于语言理解的语义导航数据集，用于测试智能体对不同细节层次描述的物体定位能力，并提出了LangNavBench基准和MLFM方法。


<details>
  <summary>Details</summary>
Motivation: 现有语义导航方法缺乏对语言理解的系统评估，LangNav填补了这一空白。

Method: 提出了LangNav数据集和LangNavBench基准，并开发了MLFM方法，构建可查询的多层语义地图。

Result: MLFM在LangNav数据集上优于现有基于地图的导航方法。

Conclusion: LangNav和MLFM为语言驱动的语义导航提供了更全面的评估和改进方法。

Abstract: Recent progress in large vision-language models has driven improvements in
language-based semantic navigation, where an embodied agent must reach a target
object described in natural language. Despite these advances, we still lack a
clear, language-focused benchmark for testing how well such agents ground the
words in their instructions. We address this gap with LangNav, an open-set
dataset specifically created to test an agent's ability to locate objects
described at different levels of detail, from broad category names to fine
attributes and object-object relations. Every description in LangNav was
manually checked, yielding a lower error rate than existing lifelong- and
semantic-navigation datasets. On top of LangNav we build LangNavBench, a
benchmark that measures how well current semantic-navigation methods understand
and act on these descriptions while moving toward their targets. LangNavBench
allows us to systematically compare models on their handling of attributes,
spatial and relational cues, and category hierarchies, offering the first
thorough, language-centric evaluation of embodied navigation systems. We also
present Multi-Layered Feature Map (MLFM), a method that builds a queryable
multi-layered semantic map, particularly effective when dealing with small
objects or instructions involving spatial relations. MLFM outperforms
state-of-the-art mapping-based navigation baselines on the LangNav dataset.

</details>


### [31] [Classifying Emergence in Robot Swarms: An Observer-Dependent Approach](https://arxiv.org/abs/2507.07315)
*Ricardo Vega,Cameron Nowzari*

Main category: cs.RO

TL;DR: 论文提出一个框架，通过区分外部可观察状态与潜在不可观察状态，严格讨论'群体'和'涌现'的定义，强调这些概念的主观性。


<details>
  <summary>Details</summary>
Motivation: 由于对'群体'和'涌现'缺乏共识，新研究者难以理解这些概念，专家也可能因术语歧义产生误解。论文旨在提供一个共同讨论的基础。

Method: 提出一个框架，分离外部可观察状态与潜在不可观察状态，并基于此对比现有定义。

Result: 认为'群体'和'涌现'的定义更多取决于观察者的视角和隐性知识，而非系统本身。

Conclusion: 强调'群体'的定义应关注行为生成过程而非行为本身，为机器人群体系统的设计和部署提供理论支持。

Abstract: Emergence and swarms are widely discussed topics, yet no consensus exists on
their formal definitions. This lack of agreement makes it difficult not only
for new researchers to grasp these concepts, but also for experts who may use
the same terms to mean different things. Many attempts have been made to
objectively define 'swarm' or 'emergence,' with recent work highlighting the
role of the external observer. Still, several researchers argue that once an
observer's vantage point (e.g., scope, resolution, context) is established, the
terms can be made objective or measured quantitatively. In this note, we
propose a framework to discuss these ideas rigorously by separating externally
observable states from latent, unobservable ones. This allows us to compare and
contrast existing definitions of swarms and emergence on common ground. We
argue that these concepts are ultimately subjective-shaped less by the system
itself than by the perception and tacit knowledge of the observer.
Specifically, we suggest that a 'swarm' is not defined by its group behavior
alone, but by the process generating that behavior. Our broader goal is to
support the design and deployment of robotic swarm systems, highlighting the
critical distinction between multi-robot systems and true swarms.

</details>


### [32] [Effects of Wrist-Worn Haptic Feedback on Force Accuracy and Task Speed during a Teleoperated Robotic Surgery Task](https://arxiv.org/abs/2507.07327)
*Brian B. Vuong,Josie Davidson,Sangheui Cheon,Kyujin Cho,Allison M. Okamura*

Main category: cs.RO

TL;DR: 将触觉反馈从手部移至腕部，通过可穿戴设备提供触觉反馈，显著降低了力应用误差，但增加了操作时间。


<details>
  <summary>Details</summary>
Motivation: 手部触觉反馈会干扰手术机器人操纵器的直接操作，因此研究腕部触觉反馈的可行性。

Method: 使用软气动手腕触觉设备，测试参与者在有无触觉反馈下完成组织触诊任务的力应用准确性。

Result: 提供腕部触觉反馈时，参与者的力误差显著降低，但操作时间延长。

Conclusion: 腕部触觉反馈能有效提升力应用准确性，但可能影响操作速度。

Abstract: Previous work has shown that the addition of haptic feedback to the hands can
improve awareness of tool-tissue interactions and enhance performance of
teleoperated tasks in robot-assisted minimally invasive surgery. However,
hand-based haptic feedback occludes direct interaction with the manipulanda of
surgeon console in teleoperated surgical robots. We propose relocating haptic
feedback to the wrist using a wearable haptic device so that haptic feedback
mechanisms do not need to be integrated into the manipulanda. However, it is
unknown if such feedback will be effective, given that it is not co-located
with the finger movements used for manipulation. To test if relocated haptic
feedback improves force application during teleoperated tasks using da Vinci
Research Kit (dVRK) surgical robot, participants learned to palpate a phantom
tissue to desired forces. A soft pneumatic wrist-worn haptic device with an
anchoring system renders tool-tissue interaction forces to the wrist of the
user. Participants performed the palpation task with and without wrist-worn
haptic feedback and were evaluated for the accuracy of applied forces.
Participants demonstrated statistically significant lower force error when
wrist-worn haptic feedback was provided. Participants also performed the
palpation task with longer movement times when provided wrist-worn haptic
feedback, indicating that the haptic feedback may have caused participants to
operate at a different point in the speed-accuracy tradeoff curve.

</details>


### [33] [UniTracker: Learning Universal Whole-Body Motion Tracker for Humanoid Robots](https://arxiv.org/abs/2507.07356)
*Kangning Yin,Weishuai Zeng,Ke Fan,Zirui Wang,Qiang Zhang,Zheng Tian,Jingbo Wang,Jiangmiao Pang,Weinan Zhang*

Main category: cs.RO

TL;DR: UniTracker是一个基于CVAE的框架，用于提升人形机器人的全身控制能力，解决了现有方法在运动多样性和泛化性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于师生框架的方法在策略蒸馏过程中会损失运动多样性，且对未见行为的泛化能力有限。

Method: 通过将CVAE集成到学生策略中，显式建模人类运动的潜在多样性，利用CVAE先验保留运动特性并提升鲁棒性。

Result: 实验表明，UniTracker在运动质量、泛化能力和部署鲁棒性上显著优于MLP-based DAgger基线。

Conclusion: UniTracker为表达性人形控制提供了实用且可扩展的解决方案。

Abstract: Humanoid robots must achieve diverse, robust, and generalizable whole-body
control to operate effectively in complex, human-centric environments. However,
existing methods, particularly those based on teacher-student frameworks often
suffer from a loss of motion diversity during policy distillation and exhibit
limited generalization to unseen behaviors. In this work, we present
UniTracker, a simplified yet powerful framework that integrates a Conditional
Variational Autoencoder (CVAE) into the student policy to explicitly model the
latent diversity of human motion. By leveraging a learned CVAE prior, our
method enables the student to retain expressive motion characteristics while
improving robustness and adaptability under partial observations. The result is
a single policy capable of tracking a wide spectrum of whole-body motions with
high fidelity and stability. Comprehensive experiments in both simulation and
real-world deployments demonstrate that UniTracker significantly outperforms
MLP-based DAgger baselines in motion quality, generalization to unseen
references, and deployment robustness, offering a practical and scalable
solution for expressive humanoid control.

</details>


### [34] [Data-driven Kinematic Modeling in Soft Robots: System Identification and Uncertainty Quantification](https://arxiv.org/abs/2507.07370)
*Zhanhong Jiang,Dylan Shah,Hsin-Jung Yang,Soumik Sarkar*

Main category: cs.RO

TL;DR: 论文提出了一种基于共形预测的软体机器人运动学建模框架，用于量化预测不确定性，提升建模精度。


<details>
  <summary>Details</summary>
Motivation: 软体机器人运动学建模因高度非线性和复杂行为而具有挑战性，现有数据驱动模型存在预测不确定性，影响建模精度。

Method: 研究了多种线性和非线性机器学习模型，发现非线性集成方法泛化性能最佳；开发了基于共形预测的建模框架，量化预测位置不确定性。

Result: 非线性集成方法表现最优；共形预测框架提供了理论保证的预测区间。

Conclusion: 共形预测框架能有效量化软体机器人运动学建模中的不确定性，提升模型可靠性。

Abstract: Precise kinematic modeling is critical in calibration and controller design
for soft robots, yet remains a challenging issue due to their highly nonlinear
and complex behaviors. To tackle the issue, numerous data-driven machine
learning approaches have been proposed for modeling nonlinear dynamics.
However, these models suffer from prediction uncertainty that can negatively
affect modeling accuracy, and uncertainty quantification for kinematic modeling
in soft robots is underexplored. In this work, using limited simulation and
real-world data, we first investigate multiple linear and nonlinear machine
learning models commonly used for kinematic modeling of soft robots. The
results reveal that nonlinear ensemble methods exhibit the most robust
generalization performance. We then develop a conformal kinematic modeling
framework for soft robots by utilizing split conformal prediction to quantify
predictive position uncertainty, ensuring distribution-free prediction
intervals with a theoretical guarantee.

</details>


### [35] [PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments](https://arxiv.org/abs/2507.07376)
*Hengrui Liu,Yi Feng,Qilong Zhang*

Main category: cs.RO

TL;DR: PILOC框架通过局部感知和通信解决多智能体搜索救援中的动态和未知环境问题，结合信息素机制和深度强化学习提升效率。


<details>
  <summary>Details</summary>
Motivation: 动态和未知环境中的目标不可预测性和环境不确定性对多智能体搜索救援构成挑战，需要无需全局先验知识的解决方案。

Method: 提出PILOC框架，利用局部感知和通信，引入信息素逆向引导机制，结合深度强化学习实现间接协调。

Result: 实验表明，PILOC在动态和通信受限场景下表现优异，显著提升搜索效率和系统鲁棒性。

Conclusion: PILOC为未来多智能体搜索救援应用提供了高效、自适应的解决方案。

Abstract: Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster
response, exploration, and reconnaissance. However, dynamic and unknown
environments pose significant challenges due to target unpredictability and
environmental uncertainty. To tackle these issues, we propose PILOC, a
framework that operates without global prior knowledge, leveraging local
perception and communication. It introduces a pheromone inverse guidance
mechanism to enable efficient coordination and dynamic target localization.
PILOC promotes decentralized cooperation through local communication,
significantly reducing reliance on global channels. Unlike conventional
heuristics, the pheromone mechanism is embedded into the observation space of
Deep Reinforcement Learning (DRL), supporting indirect agent coordination based
on environmental cues. We further integrate this strategy into a DRL-based
multi-agent architecture and conduct extensive experiments. Results show that
combining local communication with pheromone-based guidance significantly
boosts search efficiency, adaptability, and system robustness. Compared to
existing methods, PILOC performs better under dynamic and
communication-constrained scenarios, offering promising directions for future
MASAR applications.

</details>


### [36] [Towards Safe Autonomous Driving: A Real-Time Safeguarding Concept for Motion Planning Algorithms](https://arxiv.org/abs/2507.07444)
*Korbinian Moller,Rafael Neher,Marvin Seegert,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了一种用于自动驾驶运动规划模块的安全保障概念，通过引入时间监控扩展了现有方法，确保系统响应的及时性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂或基于学习的软件中运动规划功能安全的挑战，尤其是在嵌入式实时环境中的在线验证问题。

Method: 在实时操作系统上实现原型，通过约束可行性检查和基于成本的合理性评估轨迹候选。

Result: 初步结果表明，安全保障模块在实时范围内运行，并能有效检测不安全轨迹。

Conclusion: 研究提供了一个模块化和可扩展的运行时轨迹验证框架，未来工作包括完善逻辑并通过硬件在环和车辆测试验证。

Abstract: Ensuring the functional safety of motion planning modules in autonomous
vehicles remains a critical challenge, especially when dealing with complex or
learning-based software. Online verification has emerged as a promising
approach to monitor such systems at runtime, yet its integration into embedded
real-time environments remains limited. This work presents a safeguarding
concept for motion planning that extends prior approaches by introducing a time
safeguard. While existing methods focus on geometric and dynamic feasibility,
our approach additionally monitors the temporal consistency of planning outputs
to ensure timely system response. A prototypical implementation on a real-time
operating system evaluates trajectory candidates using constraint-based
feasibility checks and cost-based plausibility metrics. Preliminary results
show that the safeguarding module operates within real-time bounds and
effectively detects unsafe trajectories. However, the full integration of the
time safeguard logic and fallback strategies is ongoing. This study contributes
a modular and extensible framework for runtime trajectory verification and
highlights key aspects for deployment on automotive-grade hardware. Future work
includes completing the safeguarding logic and validating its effectiveness
through hardware-in-the-loop simulations and vehicle-based testing. The code is
available at: https://github.com/TUM-AVS/motion-planning-supervisor

</details>


### [37] [SCREP: Scene Coordinate Regression and Evidential Learning-based Perception-Aware Trajectory Generation](https://arxiv.org/abs/2507.07467)
*Juyeop Han,Lukas Lao Beyer,Guilherme V. Cavalheiro,Sertac Karaman*

Main category: cs.RO

TL;DR: 提出了一种结合场景坐标回归（SCR）和轨迹优化的感知感知框架，用于GPS拒绝环境中的自主飞行，显著降低了定位误差。


<details>
  <summary>Details</summary>
Motivation: 在GPS拒绝的室内环境中，视觉惯性里程计（VIO）会随时间累积漂移，而SCR能提供无漂移的高精度绝对姿态估计。

Method: 框架结合了基于证据学习的SCR姿态估计器和后退水平轨迹优化器，优化器引导相机朝向不确定性低的像素，同时固定滞后平滑器融合SCR和IMU数据。

Result: 仿真中，规划器将平移（旋转）平均误差分别降低了54%/15%（40%/31%），硬件在环实验验证了框架的可行性。

Conclusion: 该框架有效减少了视觉定位误差，适用于实时感知控制闭环。

Abstract: Autonomous flight in GPS denied indoor spaces requires trajectories that keep
visual localization error tightly bounded across varied missions. Whereas
visual inertial odometry (VIO) accumulates drift over time, scene coordinate
regression (SCR) yields drift-free, high accuracy absolute pose estimation. We
present a perception-aware framework that couples an evidential learning-based
SCR pose estimator with a receding horizon trajectory optimizer. The optimizer
steers the onboard camera toward pixels whose uncertainty predicts reliable
scene coordinates, while a fixed-lag smoother fuses the low rate SCR stream
with high rate IMU data to close the perception control loop in real time. In
simulation, our planner reduces translation (rotation) mean error by 54% / 15%
(40% / 31%) relative to yaw fixed and forward-looking baselines, respectively.
Moreover, hardware in the loop experiment validates the feasibility of our
proposed framework.

</details>


### [38] [FiDTouch: A 3D Wearable Haptic Display for the Finger Pad](https://arxiv.org/abs/2507.07661)
*Daria Trinitatova,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: FiDTouch是一种3D可穿戴触觉设备，通过微型倒置Delta机器人提供精确的接触和动态刺激，提升人机交互体验。


<details>
  <summary>Details</summary>
Motivation: 指尖触觉设备在虚拟现实、医疗培训和远程机器人操作等领域具有广泛应用潜力，但现有设备难以提供精确的动态触觉反馈。

Method: 设计了一种基于微型倒置Delta机器人的3D可穿戴触觉设备FiDTouch，可提供接触、压力、皮肤拉伸和振动反馈。通过两阶段用户研究评估其性能。

Result: FiDTouch能够精确提供静态空间接触和皮肤拉伸刺激，显著提升用户沉浸感和交互效率。

Conclusion: FiDTouch通过精确触觉反馈，为人机交互和机器人操作领域提供了新的解决方案。

Abstract: The applications of fingertip haptic devices have spread to various fields
from revolutionizing virtual reality and medical training simulations to
facilitating remote robotic operations, proposing great potential for enhancing
user experiences, improving training outcomes, and new forms of interaction. In
this work, we present FiDTouch, a 3D wearable haptic device that delivers
cutaneous stimuli to the finger pad, such as contact, pressure, encounter, skin
stretch, and vibrotactile feedback. The application of a tiny inverted Delta
robot in the mechanism design allows providing accurate contact and fast
changing dynamic stimuli to the finger pad surface. The performance of the
developed display was evaluated in a two-stage user study of the perception of
static spatial contact stimuli and skin stretch stimuli generated on the finger
pad. The proposed display, by providing users with precise touch and force
stimuli, can enhance user immersion and efficiency in the fields of
human-computer and human-robot interactions.

</details>


### [39] [Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots](https://arxiv.org/abs/2507.07714)
*Julio Garrido,Javier Vales,Diego Silva-Muñiz,Enrique Riveiro,Pablo López-Matencio,Josué Rivera-Andrade*

Main category: cs.RO

TL;DR: 本文提出了一种基于高斯混合模型（GMM）的自适应无监督异常检测算法，仅通过电机扭矩数据检测电缆驱动并联机器人（CDPRs）的异常。


<details>
  <summary>Details</summary>
Motivation: CDPRs在负载操纵任务中需检测异常以确保安全，但传统方法依赖额外传感器。本文旨在探索仅用扭矩数据实现高效异常检测的可能性。

Method: 采用GMM拟合无异常数据，通过马氏距离实时评估扭矩信号，动态更新模型参数以适应环境变化。

Result: 在14次长时间测试中，方法实现了100%的真阳性率和95.4%的平均真阴性率，检测延迟为1秒。

Conclusion: 该方法在无额外传感器的情况下，表现出对漂移和环境变化的高鲁棒性，优于传统阈值和非自适应GMM方法。

Abstract: Cable-Driven Parallel Robots (CDPRs) are increasingly used for load
manipulation tasks involving predefined toolpaths with intermediate stops. At
each stop, where the platform maintains a fixed pose and the motors keep the
cables under tension, the system must evaluate whether it is safe to proceed by
detecting anomalies that could compromise performance (e.g., wind gusts or
cable impacts). This paper investigates whether anomalies can be detected using
only motor torque data, without additional sensors. It introduces an adaptive,
unsupervised outlier detection algorithm based on Gaussian Mixture Models
(GMMs) to identify anomalies from torque signals. The method starts with a
brief calibration period, just a few seconds, during which a GMM is fit on
known anomaly-free data. Real-time torque measurements are then evaluated using
Mahalanobis distance from the GMM, with statistically derived thresholds
triggering anomaly flags. Model parameters are periodically updated using the
latest segments identified as anomaly-free to adapt to changing conditions.
Validation includes 14 long-duration test sessions simulating varied wind
intensities. The proposed method achieves a 100% true positive rate and 95.4%
average true negative rate, with 1-second detection latency. Comparative
evaluation against power threshold and non-adaptive GMM methods indicates
higher robustness to drift and environmental variation.

</details>


### [40] [Implementation and Assessment of an Augmented Training Curriculum for Surgical Robotics](https://arxiv.org/abs/2507.07718)
*Alberto Rota,Ke Fan,Elena De Momi*

Main category: cs.RO

TL;DR: 研究开发了一种触觉增强的虚拟现实手术机器人训练模拟器，通过引入高级触觉辅助算法，提升学员技能并促进技能向无辅助临床场景的转移。


<details>
  <summary>Details</summary>
Motivation: 通过整合高级辅助算法到手术机器人训练课程中，帮助学员建立更全面和稳健的技能，从而提升临床表现。

Method: 开发并验证了一种触觉增强的虚拟现实模拟器，包含8个手术任务，通过物理引擎和高级触觉接口提供运动引导和性能评分。

Result: 实验表明，引入增强机器人辅助显著提升了训练表现，并促进了技能向无辅助临床场景的转移。

Conclusion: 触觉增强的虚拟现实模拟器结合高级辅助算法，有效提升了手术机器人训练的效果和技能转移能力。

Abstract: The integration of high-level assistance algorithms in surgical robotics
training curricula may be beneficial in establishing a more comprehensive and
robust skillset for aspiring surgeons, improving their clinical performance as
a consequence. This work presents the development and validation of a
haptic-enhanced Virtual Reality simulator for surgical robotics training,
featuring 8 surgical tasks that the trainee can interact with thanks to the
embedded physics engine. This virtual simulated environment is augmented by the
introduction of high-level haptic interfaces for robotic assistance that aim at
re-directing the motion of the trainee's hands and wrists toward targets or
away from obstacles, and providing a quantitative performance score after the
execution of each training exercise.An experimental study shows that the
introduction of enhanced robotic assistance into a surgical robotics training
curriculum improves performance during the training process and, crucially,
promotes the transfer of the acquired skills to an unassisted surgical
scenario, like the clinical one.

</details>


### [41] [Distributed Surface Inspection via Operational Modal Analysis by a Swarm of Miniaturized Vibration-Sensing Robots](https://arxiv.org/abs/2507.07724)
*Thiemen Siemensma,Niels de Boer,Bahar Haghighat*

Main category: cs.RO

TL;DR: 研究探讨了利用微型振动传感机器人群体在模拟环境中检测和定位结构损伤的方法。


<details>
  <summary>Details</summary>
Motivation: 传统静态传感器网络在结构覆盖上存在局限性，而机器人群体能提供分布式感知，适用于结构监测。

Method: 结合有限元分析（Abaqus）和机器人模拟器（Webots），使用高斯过程估计器引导机器人探索，并通过模态分析检测损伤。

Result: 在10种随机场景中验证了方法的有效性，分析了探索半径对估计不确定性的影响。

Conclusion: 模拟研究证实了微型机器人群体在振动结构检测中的有效性。

Abstract: Robot swarms offer the potential to serve a variety of distributed sensing
applications. An interesting real-world application that stands to benefit
significantly from deployment of swarms is structural monitoring, where
traditional sensor networks face challenges in structural coverage due to their
static nature. This paper investigates the deployment of a swarm of
miniaturized vibration sensing robots to inspect and localize structural
damages on a surface section within a high-fidelity simulation environment. In
particular, we consider a 1 m x 1 m x 3 mm steel surface section and utilize
finite element analysis using Abaqus to obtain realistic structural vibration
data. The resulting vibration data is imported into the physics-based robotic
simulator Webots, where we simulate the dynamics of our surface inspecting
robot swarm. We employ (i) Gaussian process estimators to guide the robots'
exploration as they collect vibration samples across the surface and (ii)
operational modal analysis to detect structural damages by estimating and
comparing existing and intact structural vibration patterns. We analyze the
influence of exploration radii on estimation uncertainty and assess the
effectiveness of our method across 10 randomized scenarios, where the number,
locations, surface area, and depth of structural damages vary. Our simulation
studies validate the efficacy of our miniaturized robot swarm for
vibration-based structural inspection.

</details>


### [42] [On the capabilities of LLMs for classifying and segmenting time series of fruit picking motions into primitive actions](https://arxiv.org/abs/2507.07745)
*Eleni Konstantinidou,Nikolaos Kounalakis,Nikolaos Efstathopoulos,Dimitrios Papageorgiou*

Main category: cs.RO

TL;DR: 本文研究了大型语言模型（LLMs）在学习和演示（LbD）中分类和分割复杂动作的能力，特别是在水果采摘任务中。


<details>
  <summary>Details</summary>
Motivation: LLMs如ChatGPT已显著影响人类处理日常心理挑战的方式，本文旨在探索其在LbD任务中的潜力，以减轻认知负担并提高实用性。

Method: 研究了三种不同的微调方法，并在使用UR10e机器人采集的水果采摘数据集上进行了比较。

Result: 通过LLMs替代传统监督学习或分析方法，提高了方法的易用性和实际部署能力。

Conclusion: LLMs在LbD任务中表现出潜力，能够有效分类和分割复杂动作，适用于现实场景。

Abstract: Despite their recent introduction to human society, Large Language Models
(LLMs) have significantly affected the way we tackle mental challenges in our
everyday lives. From optimizing our linguistic communication to assisting us in
making important decisions, LLMs, such as ChatGPT, are notably reducing our
cognitive load by gradually taking on an increasing share of our mental
activities. In the context of Learning by Demonstration (LbD), classifying and
segmenting complex motions into primitive actions, such as pushing, pulling,
twisting etc, is considered to be a key-step towards encoding a task. In this
work, we investigate the capabilities of LLMs to undertake this task,
considering a finite set of predefined primitive actions found in fruit picking
operations. By utilizing LLMs instead of simple supervised learning or analytic
methods, we aim at making the method easily applicable and deployable in a
real-life scenario. Three different fine-tuning approaches are investigated,
compared on datasets captured kinesthetically, using a UR10e robot, during a
fruit-picking scenario.

</details>


### [43] [IRAF-SLAM: An Illumination-Robust and Adaptive Feature-Culling Front-End for Visual SLAM in Challenging Environments](https://arxiv.org/abs/2507.07752)
*Thanh Nguyen Canh,Bao Nguyen Quoc,Haolan Zhang,Bupesh Rethinam Veeraiah,Xiem HoangVan,Nak Young Chong*

Main category: cs.RO

TL;DR: IRAF-SLAM是一种针对复杂光照条件的视觉SLAM系统，通过图像增强、自适应特征提取和特征筛选策略，显著提升了在动态环境和光照变化下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有SLAM系统在光照变化和动态环境中表现不佳，需要一种更鲁棒的前端处理方法来提升性能。

Method: 1. 图像增强预处理；2. 基于图像熵、像素强度和梯度的自适应特征提取；3. 通过密度分布和光照影响因子筛选不可靠特征点。

Result: 在TUM-VI和EuRoC数据集上，IRAF-SLAM显著减少了跟踪失败，轨迹精度优于现有方法。

Conclusion: 自适应前端策略能有效提升SLAM鲁棒性，且计算开销低，适用于复杂光照环境。

Abstract: Robust Visual SLAM (vSLAM) is essential for autonomous systems operating in
real-world environments, where challenges such as dynamic objects, low texture,
and critically, varying illumination conditions often degrade performance.
Existing feature-based SLAM systems rely on fixed front-end parameters, making
them vulnerable to sudden lighting changes and unstable feature tracking. To
address these challenges, we propose ``IRAF-SLAM'', an Illumination-Robust and
Adaptive Feature-Culling front-end designed to enhance vSLAM resilience in
complex and challenging environments. Our approach introduces: (1) an image
enhancement scheme to preprocess and adjust image quality under varying
lighting conditions; (2) an adaptive feature extraction mechanism that
dynamically adjusts detection sensitivity based on image entropy, pixel
intensity, and gradient analysis; and (3) a feature culling strategy that
filters out unreliable feature points using density distribution analysis and a
lighting impact factor. Comprehensive evaluations on the TUM-VI and European
Robotics Challenge (EuRoC) datasets demonstrate that IRAF-SLAM significantly
reduces tracking failures and achieves superior trajectory accuracy compared to
state-of-the-art vSLAM methods under adverse illumination conditions. These
results highlight the effectiveness of adaptive front-end strategies in
improving vSLAM robustness without incurring significant computational
overhead. The implementation of IRAF-SLAM is publicly available at
https://thanhnguyencanh. github.io/IRAF-SLAM/.

</details>


### [44] [Collaborative Human-Robot Surgery for Mandibular Angle Split Osteotomy: Optical Tracking based Approach](https://arxiv.org/abs/2507.07794)
*Zhe Han,Huanyu Tian,Tom Vercauteren,Da Liu,Changsheng Li,Xingguang Duan*

Main category: cs.RO

TL;DR: 提出了一种人机协作系统用于下颌角劈开截骨术（MASO），通过任务分解和光学跟踪系统（OTS）实现精确和安全的手术操作。


<details>
  <summary>Details</summary>
Motivation: 尽管技术和器械有所进步，MASO的成功仍高度依赖外科医生的经验，因此需要一种更精确和安全的方法。

Method: 将手术分为三个子任务：机器人主导的位置和方向控制，以及外科医生主导的力控制；使用OTS进行患者跟踪，无需颅骨夹。

Result: 在模型实验中，计划与实际钻孔点的平均误差为1.85mm。

Conclusion: 该系统能够提高MASO的精确性和安全性，减少对外科医生经验的依赖。

Abstract: Mandibular Angle Split Osteotomy (MASO) is a significant procedure in oral
and maxillofacial surgery. Despite advances in technique and instrumentation,
its success still relies heavily on the surgeon's experience. In this work, a
human-robot collaborative system is proposed to perform MASO according to a
preoperative plan and under guidance of a surgeon. A task decomposition
methodology is used to divide the collaborative surgical procedure into three
subtasks: (1) positional control and (2) orientation control, both led by the
robot for precise alignment; and (3) force-control, managed by surgeon to
ensure safety. Additionally, to achieve patient tracking without the need for a
skull clamp, an optical tracking system (OTS) is utilized. Movement of the
patient mandibular is measured with an optical-based tracker mounted on a
dental occlusal splint. A registration method and Robot-OTS calibration method
are introduced to achieve reliable navigation within our framework. The
experiments of drilling were conducted on the realistic phantom model, which
demonstrated that the average error between the planned and actual drilling
points is 1.85mm.

</details>


### [45] [Beyond Robustness: Learning Unknown Dynamic Load Adaptation for Quadruped Locomotion on Rough Terrain](https://arxiv.org/abs/2507.07825)
*Leixin Chang,Yuxuan Nai,Hua Chen,Liangjing Yang*

Main category: cs.RO

TL;DR: 本文提出了一种通用的负载特性建模方法，结合强化学习控制，使四足机器人能够推断负载动态并间接稳定负载，验证了其在真实场景中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人在未知动态负载下的三个主要挑战：负载动态的通用建模、无外部感知的动态捕获以及负载与机器人的交互稳定。

Method: 提出负载特性建模方法，结合强化学习控制技术，实现负载动态推断和间接交互稳定。

Result: 仿真实验表明，该方法在突加载荷抵抗、负载稳定和复杂地形重载运动方面优于其他方法。

Conclusion: 负载特性建模与强化学习的结合为四足机器人处理未知动态负载提供了有效解决方案。

Abstract: Unknown dynamic load carrying is one important practical application for
quadruped robots. Such a problem is non-trivial, posing three major challenges
in quadruped locomotion control. First, how to model or represent the dynamics
of the load in a generic manner. Second, how to make the robot capture the
dynamics without any external sensing. Third, how to enable the robot to
interact with load handling the mutual effect and stabilizing the load. In this
work, we propose a general load modeling approach called load characteristics
modeling to capture the dynamics of the load. We integrate this proposed
modeling technique and leverage recent advances in Reinforcement Learning (RL)
based locomotion control to enable the robot to infer the dynamics of load
movement and interact with the load indirectly to stabilize it and realize the
sim-to-real deployment to verify its effectiveness in real scenarios. We
conduct extensive comparative simulation experiments to validate the
effectiveness and superiority of our proposed method. Results show that our
method outperforms other methods in sudden load resistance, load stabilizing
and locomotion with heavy load on rough terrain.
\href{https://leixinjonaschang.github.io/leggedloadadapt.github.io/}{Project
Page}.

</details>


### [46] [Perceptual Distortions and Autonomous Representation Learning in a Minimal Robotic System](https://arxiv.org/abs/2507.07845)
*David Warutumo,Ciira wa Maina*

Main category: cs.RO

TL;DR: 论文研究了感知失真对自主机器人表示学习的影响，通过模拟机器人实验展示了失真感知空间中的涌现结构。


<details>
  <summary>Details</summary>
Motivation: 探索自主机器人如何在感知失真情况下学习环境表示，以理解感知在导航策略中的作用。

Method: 使用模拟两轮机器人，配备距离传感器和指南针，在方形环境中随机探索并分析传感器数据。

Result: 发现感知空间中涌现的结构与物理环境相关，机器人能自主学习导航表示。

Conclusion: 研究为具身认知和最小代理提供了新见解，揭示了感知在自主导航中的重要性。

Abstract: Autonomous agents, particularly in the field of robotics, rely on sensory
information to perceive and navigate their environment. However, these sensory
inputs are often imperfect, leading to distortions in the agent's internal
representation of the world. This paper investigates the nature of these
perceptual distortions and how they influence autonomous representation
learning using a minimal robotic system. We utilize a simulated two-wheeled
robot equipped with distance sensors and a compass, operating within a simple
square environment. Through analysis of the robot's sensor data during random
exploration, we demonstrate how a distorted perceptual space emerges. Despite
these distortions, we identify emergent structures within the perceptual space
that correlate with the physical environment, revealing how the robot
autonomously learns a structured representation for navigation without explicit
spatial information. This work contributes to the understanding of embodied
cognition, minimal agency, and the role of perception in self-generated
navigation strategies in artificial life.

</details>


### [47] [ROS Help Desk: GenAI Powered, User-Centric Framework for ROS Error Diagnosis and Debugging](https://arxiv.org/abs/2507.07846)
*Kavindie Katuwandeniya,Samith Rajapaksha Jayasekara Widhanapathirana*

Main category: cs.RO

TL;DR: ROS Help Desk通过直观的错误解释和调试支持，减少机器人系统的维护时间，提升人机协作效率。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统融入日常生活和工业自动化，ROS的复杂架构和技术消息系统对普通用户构成障碍，导致维护困难和系统中断。

Method: ROS Help Desk提供用户友好的调试工具、主动错误检测功能，并整合多模态数据处理，以简化错误诊断。

Result: 测试表明，系统能主动准确诊断问题，显著减少维护时间。

Conclusion: ROS Help Desk有效降低了机器人系统的维护难度，促进了更高效的人机协作。

Abstract: As the robotics systems increasingly integrate into daily life, from smart
home assistants to the new-wave of industrial automation systems (Industry
4.0), there's an increasing need to bridge the gap between complex robotic
systems and everyday users. The Robot Operating System (ROS) is a flexible
framework often utilised in writing robot software, providing tools and
libraries for building complex robotic systems. However, ROS's distributed
architecture and technical messaging system create barriers for understanding
robot status and diagnosing errors. This gap can lead to extended maintenance
downtimes, as users with limited ROS knowledge may struggle to quickly diagnose
and resolve system issues. Moreover, this deficit in expertise often delays
proactive maintenance and troubleshooting, further increasing the frequency and
duration of system interruptions. ROS Help Desk provides intuitive error
explanations and debugging support, dynamically customized to users of varying
expertise levels. It features user-centric debugging tools that simplify error
diagnosis, implements proactive error detection capabilities to reduce
downtime, and integrates multimodal data processing for comprehensive system
state understanding across multi-sensor data (e.g., lidar, RGB). Testing
qualitatively and quantitatively with artificially induced errors demonstrates
the system's ability to proactively and accurately diagnose problems,
ultimately reducing maintenance time and fostering more effective human-robot
collaboration.

</details>


### [48] [Improving AEBS Validation Through Objective Intervention Classification Leveraging the Prediction Divergence Principle](https://arxiv.org/abs/2507.07872)
*Daniel Betschinske,Steven Peters*

Main category: cs.RO

TL;DR: 论文提出了一种基于规则的分类方法（PDP），用于区分自动紧急制动系统（AEBS）的误报和真报，以提高验证的透明度和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如人工标注）存在主观性和偏差，难以准确区分AEBS的误报和真报，尤其是在开放循环重模拟（如FOT）中。

Method: 采用基于预测分歧原则（PDP）的规则分类方法，结合简化AEBS进行验证。

Result: 该方法展示了其优势和局限性，并提出了系统需求；结合人工标注可提升分类的透明度和一致性。

Conclusion: 该方法为AEBS验证提供了补充工具，未来可进一步优化和扩展应用范围。

Abstract: The safety validation of automatic emergency braking system (AEBS) requires
accurately distinguishing between false positive (FP) and true positive (TP)
system activations. While simulations allow straightforward differentiation by
comparing scenarios with and without interventions, analyzing activations from
open-loop resimulations - such as those from field operational testing (FOT) -
is more complex. This complexity arises from scenario parameter uncertainty and
the influence of driver interventions in the recorded data. Human labeling is
frequently used to address these challenges, relying on subjective assessments
of intervention necessity or situational criticality, potentially introducing
biases and limitations. This work proposes a rule-based classification approach
leveraging the Prediction Divergence Principle (PDP) to address those issues.
Applied to a simplified AEBS, the proposed method reveals key strengths,
limitations, and system requirements for effective implementation. The findings
suggest that combining this approach with human labeling may enhance the
transparency and consistency of classification, thereby improving the overall
validation process. While the rule set for classification derived in this work
adopts a conservative approach, the paper outlines future directions for
refinement and broader applicability. Finally, this work highlights the
potential of such methods to complement existing practices, paving the way for
more reliable and reproducible AEBS validation frameworks.

</details>


### [49] [UniTac: Whole-Robot Touch Sensing Without Tactile Sensors](https://arxiv.org/abs/2507.07980)
*Wanjia Fu,Hongyu Li,Ivy X. He,Stefanie Tellex,Srinath Sridhar*

Main category: cs.RO

TL;DR: UniTac是一种仅使用本体感觉关节传感器的数据驱动全身触觉感知方法，无需额外传感器即可实现接触定位。


<details>
  <summary>Details</summary>
Motivation: 商业机器人通常缺乏触觉皮肤，难以实现基本触觉功能，如接触定位。UniTac旨在普及触觉感知，为HRI研究提供现成工具。

Method: 利用数据驱动方法，仅依赖关节传感器实现接触定位，无需额外硬件。

Result: 在Franka机械臂和Spot四足机器人上验证，接触定位精度分别为8.0厘米和7.2厘米，频率达2000Hz。

Conclusion: UniTac为机器人触觉感知提供了一种低成本、高效的解决方案，适用于多种平台。

Abstract: Robots can better interact with humans and unstructured environments through
touch sensing. However, most commercial robots are not equipped with tactile
skins, making it challenging to achieve even basic touch-sensing functions,
such as contact localization. We present UniTac, a data-driven whole-body
touch-sensing approach that uses only proprioceptive joint sensors and does not
require the installation of additional sensors. Our approach enables a robot
equipped solely with joint sensors to localize contacts. Our goal is to
democratize touch sensing and provide an off-the-shelf tool for HRI researchers
to provide their robots with touch-sensing capabilities. We validate our
approach on two platforms: the Franka robot arm and the Spot quadruped. On
Franka, we can localize contact to within 8.0 centimeters, and on Spot, we can
localize to within 7.2 centimeters at around 2,000 Hz on an RTX 3090 GPU
without adding any additional sensors to the robot. Project website:
https://ivl.cs.brown.edu/research/unitac.

</details>
