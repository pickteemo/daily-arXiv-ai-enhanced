<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 28]
- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization](https://arxiv.org/abs/2508.05731)
*Yuhang Liu,Zeyu Liu,Shuanghe Zhu,Pengxiang Li,Congkai Xie,Jiasheng Wang,Xueyu Hu,Xiaotian Han,Jianbo Yuan,Xinyao Wang,Shengyu Zhang,Hongxia Yang,Fei Wu*

Main category: cs.AI

TL;DR: 论文提出了一种名为AEPO的新策略优化框架，通过多答案生成策略和自适应探索奖励函数，解决了MLLMs在GUI操作中语义对齐的探索瓶颈问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在GUI操作中面临语义对齐的挑战，现有方法在探索效率上存在瓶颈。

Method: 提出自适应探索策略优化（AEPO），结合多答案生成策略和理论驱动的自适应探索奖励函数（AER）。

Result: AEPO训练的模型在多个GUI基准测试中达到新SOTA，相对基线提升高达9.0%。

Conclusion: AEPO有效解决了语义对齐的探索问题，为MLLMs在GUI操作中的应用提供了新思路。

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has propelled the
development of autonomous agents that operate on Graphical User Interfaces
(GUIs) using pure visual input. A fundamental challenge is robustly grounding
natural language instructions. This requires a precise spatial alignment, which
accurately locates the coordinates of each element, and, more critically, a
correct semantic alignment, which matches the instructions to the functionally
appropriate UI element. Although Reinforcement Learning with Verifiable Rewards
(RLVR) has proven to be effective at improving spatial alignment for these
MLLMs, we find that inefficient exploration bottlenecks semantic alignment,
which prevent models from learning difficult semantic associations. To address
this exploration problem, we present Adaptive Exploration Policy Optimization
(AEPO), a new policy optimization framework. AEPO employs a multi-answer
generation strategy to enforce broader exploration, which is then guided by a
theoretically grounded Adaptive Exploration Reward (AER) function derived from
first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B
and InfiGUI-G1-7B, establish new state-of-the-art results across multiple
challenging GUI grounding benchmarks, achieving significant relative
improvements of up to 9.0% against the naive RLVR baseline on benchmarks
designed to test generalization and semantic understanding. Resources are
available at https://github.com/InfiXAI/InfiGUI-G1.

</details>


### [2] [A Framework for Inherently Safer AGI through Language-Mediated Active Inference](https://arxiv.org/abs/2508.05766)
*Bo Wen*

Main category: cs.AI

TL;DR: 提出了一种结合主动推理与大型语言模型的新型框架，旨在开发安全的通用人工智能（AGI），通过透明信念表示和层次化价值对齐实现核心设计的安全性。


<details>
  <summary>Details</summary>
Motivation: 传统AI安全方法（如事后可解释性和奖励工程）存在根本性局限，需在系统核心设计中集成安全性。

Method: 采用多智能体系统，基于主动推理原则自组织，通过自然语言表示信念和偏好，实现层次化安全约束。

Result: 提出具体安全机制，包括信念与偏好的语言分离、资源感知的自由能最小化及模块化智能体结构。

Conclusion: 该框架为AGI开发提供了一条更安全的发展路径，并提出了基于ARC基准的验证实验。

Abstract: This paper proposes a novel framework for developing safe Artificial General
Intelligence (AGI) by combining Active Inference principles with Large Language
Models (LLMs). We argue that traditional approaches to AI safety, focused on
post-hoc interpretability and reward engineering, have fundamental limitations.
We present an architecture where safety guarantees are integrated into the
system's core design through transparent belief representations and
hierarchical value alignment. Our framework leverages natural language as a
medium for representing and manipulating beliefs, enabling direct human
oversight while maintaining computational tractability. The architecture
implements a multi-agent system where agents self-organize according to Active
Inference principles, with preferences and safety constraints flowing through
hierarchical Markov blankets. We outline specific mechanisms for ensuring
safety, including: (1) explicit separation of beliefs and preferences in
natural language, (2) bounded rationality through resource-aware free energy
minimization, and (3) compositional safety through modular agent structures.
The paper concludes with a research agenda centered on the Abstraction and
Reasoning Corpus (ARC) benchmark, proposing experiments to validate our
framework's safety properties. Our approach offers a path toward AGI
development that is inherently safer, rather than retrofitted with safety
measures.

</details>


### [3] [Whither symbols in the era of advanced neural networks?](https://arxiv.org/abs/2508.05776)
*Thomas L. Griffiths,Brenden M. Lake,R. Thomas McCoy,Ellie Pavlick,Taylor W. Webb*

Main category: cs.AI

TL;DR: 现代神经网络表现出类似人类思维的组合、创新和快速学习能力，削弱了人类认知过程是符号化的论点，但符号系统在描述人类思维解决的抽象问题中仍起重要作用。


<details>
  <summary>Details</summary>
Motivation: 探讨神经网络是否具备类似人类思维的符号化能力，并重新评估符号系统在人类思维中的作用。

Method: 通过分析现代神经网络的表现，对比人类思维的符号化特征。

Result: 神经网络表现出类似人类思维的组合和创新能力，但符号系统在问题抽象中仍不可或缺。

Conclusion: 提出研究人类思维符号基础的新议程，强调符号系统与神经网络的互补性。

Abstract: Some of the strongest evidence that human minds should be thought about in
terms of symbolic systems has been the way they combine ideas, produce novelty,
and learn quickly. We argue that modern neural networks -- and the artificial
intelligence systems built upon them -- exhibit similar abilities. This
undermines the argument that the cognitive processes and representations used
by human minds are symbolic, although the fact that these neural networks are
typically trained on data generated by symbolic systems illustrates that such
systems play an important role in characterizing the abstract problems that
human minds have to solve. This argument leads us to offer a new agenda for
research on the symbolic basis of human thought.

</details>


### [4] [Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making](https://arxiv.org/abs/2508.05792)
*Kausik Lakkaraju,Siva Likitha Valluru,Biplav Srivastava*

Main category: cs.AI

TL;DR: H-XAI是一个统一框架，结合因果评级与传统XAI方法，支持交互式、多方法的解释过程，满足不同利益相关者的需求。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法主要服务于开发者，缺乏对多样化利益相关者需求的支持。H-XAI旨在填补这一空白，提供更全面的解释工具。

Method: H-XAI整合因果评级与传统XAI方法，支持交互式提问、假设测试，并对比随机和偏置基线。

Result: 通过两个案例研究（信用风险分类和金融时间序列预测），验证了H-XAI的通用性和实用性。

Conclusion: H-XAI通过结合因果评级和后验解释，填补了现有XAI方法的不足，满足个体和模型层面的需求。

Abstract: Current eXplainable AI (XAI) methods largely serve developers, often focusing
on justifying model outputs rather than supporting diverse stakeholder needs. A
recent shift toward Evaluative AI reframes explanation as a tool for hypothesis
testing, but still focuses primarily on operational organizations. We introduce
Holistic-XAI (H-XAI), a unified framework that integrates causal rating methods
with traditional XAI methods to support explanation as an interactive,
multi-method process. H-XAI allows stakeholders to ask a series of questions,
test hypotheses, and compare model behavior against automatically constructed
random and biased baselines. It combines instance-level and global
explanations, adapting to each stakeholder's goals, whether understanding
individual decisions, assessing group-level bias, or evaluating robustness
under perturbations. We demonstrate the generality of our approach through two
case studies spanning six scenarios: binary credit risk classification and
financial time-series forecasting. H-XAI fills critical gaps left by existing
XAI methods by combining causal ratings and post-hoc explanations to answer
stakeholder-specific questions at both the individual decision level and the
overall model level.

</details>


### [5] [Safety of Embodied Navigation: A Survey](https://arxiv.org/abs/2508.05855)
*Zixia Wang,Jia Hu,Ronghui Mu*

Main category: cs.AI

TL;DR: 本文综述了具身导航中的安全问题，分析了攻击策略、防御机制和评估方法，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和具身AI的发展，具身导航在关键应用中的安全性问题日益突出，需全面研究以确保系统安全。

Method: 通过综合分析现有安全挑战、缓解技术、数据集和评估指标，探讨未解决问题和未来方向。

Result: 提出了潜在攻击方法、缓解策略、可靠评估技术和验证框架的研究方向。

Conclusion: 本文为未来研究提供了指导，旨在开发更安全可靠的具身导航系统，同时提升社会安全和工业效率。

Abstract: As large language models (LLMs) continue to advance and gain influence, the
development of embodied AI has accelerated, drawing significant attention,
particularly in navigation scenarios. Embodied navigation requires an agent to
perceive, interact with, and adapt to its environment while moving toward a
specified target in unfamiliar settings. However, the integration of embodied
navigation into critical applications raises substantial safety concerns. Given
their deployment in dynamic, real-world environments, ensuring the safety of
such systems is critical. This survey provides a comprehensive analysis of
safety in embodied navigation from multiple perspectives, encompassing attack
strategies, defense mechanisms, and evaluation methodologies. Beyond conducting
a comprehensive examination of existing safety challenges, mitigation
technologies, and various datasets and metrics that assess effectiveness and
robustness, we explore unresolved issues and future research directions in
embodied navigation safety. These include potential attack methods, mitigation
strategies, more reliable evaluation techniques, and the implementation of
verification frameworks. By addressing these critical gaps, this survey aims to
provide valuable insights that can guide future research toward the development
of safer and more reliable embodied navigation systems. Furthermore, the
findings of this study have broader implications for enhancing societal safety
and increasing industrial efficiency.

</details>


### [6] [Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning](https://arxiv.org/abs/2508.05888)
*Sahil Bansal,Sai Shruthi Sistla,Aarti Arikatala,Sebastian Schreiber*

Main category: cs.AI

TL;DR: 提出了一种基于知识图谱（KG）的工具检索框架，通过捕捉工具间的语义关系和功能依赖，提升多步骤任务中的工具选择准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅依赖用户查询与工具描述的相似性，限制了多步骤请求的检索准确性，因此需要一种更全面的方法。

Method: 利用知识图谱中的1-hop ego工具图集合建模工具间的直接和间接连接，实现更全面的工具选择。

Result: 在合成数据集上，该方法在Complete Recall指标上达到91.85%的工具覆盖率，优于非KG基线（89.26%）。

Conclusion: KG的结构信息为纯相似性匹配提供了补充信号，特别适用于需要顺序工具组合的查询。

Abstract: Effective tool retrieval is essential for AI agents to select from a vast
array of tools when identifying and planning actions in the context of complex
user queries. Despite its central role in planning, this aspect remains
underexplored in the literature. Traditional approaches rely primarily on
similarities between user queries and tool descriptions, which significantly
limits retrieval accuracy, specifically when handling multi-step user requests.
To address these limitations, we propose a Knowledge Graph (KG)-based tool
retrieval framework that captures the semantic relationships between tools and
their functional dependencies. Our retrieval algorithm leverages ensembles of
1-hop ego tool graphs to model direct and indirect connections between tools,
enabling more comprehensive and contextual tool selection for multi-step tasks.
We evaluate our approach on a synthetically generated internal dataset across
six defined user classes, extending previous work on coherent dialogue
synthesis and too retrieval benchmarks. Results demonstrate that our tool
graph-based method achieves 91.85% tool coverage on the micro-average Complete
Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid
retrieval, the strongest non-KG baseline in our experiments. These findings
support our hypothesis that the structural information in the KG provides
complementary signals to pure similarity matching, particularly for queries
requiring sequential tool composition.

</details>


### [7] [Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making](https://arxiv.org/abs/2508.05996)
*Kaitao Chen,Mianxin Liu,Daoming Zong,Chaoyue Ding,Shaohao Rui,Yankai Jiang,Mu Zhou,Xiaosong Wang*

Main category: cs.AI

TL;DR: 提出MedOrch框架，通过LLM中介协调多VLM专家代理，提升医疗多模态决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有多代理研究局限于语言任务，多模态场景下VLM协作能力不足，需解决错误输出和指令跟随问题。

Method: 采用LLM中介代理协调多个VLM专家代理，利用开源VLM实现异构模型协作。

Result: 在五个医疗视觉问答基准上验证，协作性能超越单一代理，无需额外训练。

Conclusion: 中介引导的多代理协作可推动医疗多模态智能发展，代码将开源。

Abstract: Complex medical decision-making involves cooperative workflows operated by
different clinicians. Designing AI multi-agent systems can expedite and augment
human-level clinical decision-making. Existing multi-agent researches primarily
focus on language-only tasks, yet their extension to multimodal scenarios
remains challenging. A blind combination of diverse vision-language models
(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are
less capable in instruction following and importantly self-reflection, compared
to large language models (LLMs) of comparable sizes. This disparity largely
constrains VLMs' ability in cooperative workflows. In this study, we propose
MedOrch, a mediator-guided multi-agent collaboration framework for medical
multimodal decision-making. MedOrch employs an LLM-based mediator agent that
enables multiple VLM-based expert agents to exchange and reflect on their
outputs towards collaboration. We utilize multiple open-source general-purpose
and domain-specific VLMs instead of costly GPT-series models, revealing the
strength of heterogeneous models. We show that the collaboration within
distinct VLM-based agents can surpass the capabilities of any individual agent.
We validate our approach on five medical vision question answering benchmarks,
demonstrating superior collaboration performance without model training. Our
findings underscore the value of mediator-guided multi-agent collaboration in
advancing medical multimodal intelligence. Our code will be made publicly
available.

</details>


### [8] [Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning](https://arxiv.org/abs/2508.06042)
*Daechul Ahn,San Kim,Jonghyun Choi*

Main category: cs.AI

TL;DR: 论文提出了一种名为HIMA的分层多智能体框架，通过模仿学习和元控制器（Strategic Planner）解决LLM在动态长时任务（如《星际争霸II》）中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在动态、长时任务（如《星际争霸II》）中表现不佳，难以应对资源约束和部分可观测环境下的战场变化。

Method: 采用分层多智能体框架HIMA，结合模仿学习训练专用智能体（如空中支援或防御机动），并由元控制器SP协调生成适应性计划。

Result: HIMA在战略清晰度、适应性和计算效率上优于现有方法，验证了专用模仿模块与元级协调结合的潜力。

Conclusion: HIMA框架展示了通过专用模仿模块与元控制器结合，开发更鲁棒、通用AI智能体的可能性。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive action
sequence prediction capabilities but often struggle with dynamic, long-horizon
tasks such as real-time strategic games. In a game such as StarCraftII (SC2),
agents need to manage resource constraints and adapt to evolving battlefield
situations in a partially observable environment. This often overwhelms
exisiting LLM-based approaches. To address these challenges, we propose a
hierarchical multi-agent framework that employs specialized imitation learning
agents under a meta-controller called Strategic Planner (SP). By expert
demonstrations, each specialized agent learns a distinctive strategy, such as
aerial support or defensive maneuvers, and produces coherent, structured
multistep action sequences. The SP then orchestrates these proposals into a
single, environmentally adaptive plan that ensures local decisions aligning
with long-term strategies. We call this HIMA (Hierarchical Imitation
Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that
encompasses all race match combinations in SC2. Our empirical results show that
HIMA outperforms state of the arts in strategic clarity, adaptability, and
computational efficiency, underscoring the potential of combining specialized
imitation modules with meta-level orchestration to develop more robust,
general-purpose AI agents.

</details>


### [9] [LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences](https://arxiv.org/abs/2508.06060)
*Sankarshan Damle,Boi Faltings*

Main category: cs.AI

TL;DR: 论文提出了一个双用途框架，利用参与式预算（PB）评估大型语言模型（LLMs）在资源分配和推理能力方面的表现。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在结构化资源分配任务中的能力，并解决现有评测方法因数据污染和静态性带来的局限性。

Method: 通过三种提示策略（贪婪选择、直接优化和爬山式改进）让LLMs在预算约束下选择项目子集，并对比效用最大化基准。还测试LLMs能否从自然语言输入推断结构化偏好。

Result: 结果表明提示设计对性能有重要影响，LLMs在机制设计中处理非结构化输入方面具有潜力。

Conclusion: LLMs在资源分配和偏好推断任务中表现出潜力，提示设计是关键因素。

Abstract: Large Language Models (LLMs) are increasingly expected to handle complex
decision-making tasks, yet their ability to perform structured resource
allocation remains underexplored. Evaluating their reasoning is also difficult
due to data contamination and the static nature of existing benchmarks. We
present a dual-purpose framework leveraging Participatory Budgeting (PB) both
as (i) a practical setting for LLM-based resource allocation and (ii) an
adaptive benchmark for evaluating their reasoning capabilities. We task LLMs
with selecting project subsets under feasibility (e.g., budget) constraints via
three prompting strategies: greedy selection, direct optimization, and a
hill-climbing-inspired refinement. We benchmark LLMs' allocations against a
utility-maximizing oracle. Interestingly, we also test whether LLMs can infer
structured preferences from natural-language voter input or metadata, without
explicit votes. By comparing allocations based on inferred preferences to those
from ground-truth votes, we evaluate LLMs' ability to extract preferences from
open-ended input. Our results underscore the role of prompt design and show
that LLMs hold promise for mechanism design with unstructured inputs.

</details>


### [10] [Don't Forget Imagination!](https://arxiv.org/abs/2508.06062)
*Evgenii E. Vityaev,Andrei Mantsivoda*

Main category: cs.AI

TL;DR: 本文呼吁重视认知想象力在人工智能中的关键作用，并提出语义模型作为模拟认知想象力的工具。


<details>
  <summary>Details</summary>
Motivation: 认知想象力在人类思维中扮演重要角色，但当前AI领域对其重视不足，导致推理和决策能力受限。

Method: 提出语义模型，一种基于概率因果关系的数学模型，能够学习并确保想象上下文的连贯性。

Result: 语义模型能够模拟认知想象力，支持一致且可操作的想象上下文。

Conclusion: 认知想象力是AI未来的重要突破方向，语义模型为实现这一目标提供了可行路径。

Abstract: Cognitive imagination is a type of imagination that plays a key role in human
thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to
mentally visualize coherent and holistic systems of concepts and causal links
that serve as semantic contexts for reasoning, decision making and prediction.
Our position is that the role of cognitive imagination is still greatly
underestimated, and this creates numerous problems and diminishes the current
capabilities of AI. For instance, when reasoning, humans rely on imaginary
contexts to retrieve background info. They also constantly return to the
context for semantic verification that their reasoning is still reasonable.
Thus, reasoning without imagination is blind. This paper is a call for greater
attention to cognitive imagination as the next promising breakthrough in
artificial intelligence. As an instrument for simulating cognitive imagination,
we propose semantic models -- a new approach to mathematical models that can
learn, like neural networks, and are based on probabilistic causal
relationships. Semantic models can simulate cognitive imagination because they
ensure the consistency of imaginary contexts and implement a glass-box approach
that allows the context to be manipulated as a holistic and coherent system of
interrelated facts glued together with causal relations.

</details>


### [11] [A Generic Complete Anytime Beam Search for Optimal Decision Tree](https://arxiv.org/abs/2508.06064)
*Harold Silvère Kiossou,Siegfried Nijssen,Pierre Schaus*

Main category: cs.AI

TL;DR: CA-DL8.5是一种通用的、完整的、随时可用的波束搜索算法，扩展了DL8.5框架，统一了现有的随时策略，并通过模块化设计整合多种启发式和松弛机制。


<details>
  <summary>Details</summary>
Motivation: 解决现有精确算法在未完成搜索时难以快速找到高质量决策树的问题，并系统比较现有随时扩展方法的相对有效性。

Method: 提出CA-DL8.5算法，结合DL8.5的高效剪枝和缓存技术，采用基于重启的波束搜索逐步放宽剪枝标准。

Result: 实验表明，基于LDS启发式的CA-DL8.5在随时性能上表现最佳，优于其他变体和Blossom算法。

Conclusion: CA-DL8.5为决策树学习提供了通用框架，支持多样启发式，并通过实验验证了其优越性。

Abstract: Finding an optimal decision tree that minimizes classification error is known
to be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic
programming guarantee optimality, they often suffer from poor anytime behavior
-- meaning they struggle to find high-quality decision trees quickly when the
search is stopped before completion -- due to unbalanced search space
exploration. To address this, several anytime extensions of exact methods have
been proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not
been systematically compared, making it difficult to assess their relative
effectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and
anytime beam search algorithm that extends the DL8.5 framework and unifies some
existing anytime strategies. In particular, CA-DL8.5 generalizes previous
approaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various
heuristics and relaxation mechanisms through a modular design. The algorithm
reuses DL8.5's efficient branch-and-bound pruning and trie-based caching,
combined with a restart-based beam search that gradually relaxes pruning
criteria to improve solution quality over time. Our contributions are twofold:
(1) We introduce this new generic framework for exact and anytime decision tree
learning, enabling the incorporation of diverse heuristics and search
strategies; (2) We conduct a rigorous empirical comparison of several
instantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k
heuristics -- using an anytime evaluation metric called the primal gap
integral. Experimental results on standard classification benchmarks show that
CA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime
performance, outperforming both other CA-DL8.5 variants and the Blossom
algorithm while maintaining completeness and optimality guarantees.

</details>


### [12] [ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception](https://arxiv.org/abs/2508.06074)
*Siyi Lu,Run Liu,Dongsheng Yang,Lei He*

Main category: cs.AI

TL;DR: 论文提出了一种基于深度强化学习（DRL）和鸟瞰图（BEV）感知的新型自动驾驶方法，通过结合BEV感知和Mamba框架的时空特征提取网络，提升了实时决策能力。


<details>
  <summary>Details</summary>
Motivation: 传统模块化方法存在错误传播和协调问题，端到端学习系统则面临计算瓶颈，因此需要一种既能简化设计又能提升性能的解决方案。

Method: 提出Mamba-BEV模型，结合BEV感知和Mamba框架进行时空特征建模，并进一步提出ME³-BEV框架，用于端到端DRL。

Result: 在CARLA模拟器上的实验表明，ME³-BEV在碰撞率和轨迹精度等多项指标上优于现有模型。

Conclusion: ME³-BEV为实时自动驾驶提供了一种高效且可解释的解决方案。

Abstract: Autonomous driving systems face significant challenges in perceiving complex
environments and making real-time decisions. Traditional modular approaches,
while offering interpretability, suffer from error propagation and coordination
issues, whereas end-to-end learning systems can simplify the design but face
computational bottlenecks. This paper presents a novel approach to autonomous
driving using deep reinforcement learning (DRL) that integrates bird's-eye view
(BEV) perception for enhanced real-time decision-making. We introduce the
\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction
network that combines BEV-based perception with the Mamba framework for
temporal feature modeling. This integration allows the system to encode vehicle
surroundings and road features in a unified coordinate system and accurately
model long-range dependencies. Building on this, we propose the
\texttt{ME$^3$-BEV} framework, which utilizes the \texttt{Mamba-BEV} model as a
feature input for end-to-end DRL, achieving superior performance in dynamic
urban driving scenarios. We further enhance the interpretability of the model
by visualizing high-dimensional features through semantic segmentation,
providing insight into the learned representations. Extensive experiments on
the CARLA simulator demonstrate that \texttt{ME$^3$-BEV} outperforms existing
models across multiple metrics, including collision rate and trajectory
accuracy, offering a promising solution for real-time autonomous driving.

</details>


### [13] [Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2](https://arxiv.org/abs/2508.06091)
*Stan P Hauke,Przemysław Andrzej Wałęga*

Main category: cs.AI

TL;DR: 本文解决了图神经网络（GNNs）逻辑表达能力是否完全由C2逻辑描述的问题，证明其表达能力严格超过C2。


<details>
  <summary>Details</summary>
Motivation: 研究GNNs的逻辑表达能力，解决Barceló等人提出的未解问题。

Method: 通过理论分析，比较GNNs与C2逻辑的表达能力。

Result: 证明GNNs的逻辑表达能力严格超过C2逻辑。

Conclusion: 该研究不仅对GNNs有重要意义，还为无穷逻辑的表达能力提供了新见解。

Abstract: In recent years, there has been growing interest in understanding the
expressive power of graph neural networks (GNNs) by relating them to logical
languages. This research has been been initialised by an influential result of
Barcel\'o et al. (2020), who showed that the graded modal logic (or a guarded
fragment of the logic C2), characterises the logical expressiveness of
aggregate-combine GNNs. As a ``challenging open problem'' they left the
question whether full C2 characterises the logical expressiveness of
aggregate-combine-readout GNNs. This question has remained unresolved despite
several attempts. In this paper, we solve the above open problem by proving
that the logical expressiveness of aggregate-combine-readout GNNs strictly
exceeds that of C2. This result holds over both undirected and directed graphs.
Beyond its implications for GNNs, our work also leads to purely logical
insights on the expressive power of infinitary logics.

</details>


### [14] [PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion](https://arxiv.org/abs/2508.06110)
*Yiran Rex Ma*

Main category: cs.AI

TL;DR: PanelTR框架通过LLM代理科学家的结构化科学方法提升表格推理能力，无需依赖标注数据或复杂数据增强。


<details>
  <summary>Details</summary>
Motivation: 解决表格推理任务中依赖标注数据和复杂数据增强的问题，以及LLMs在此类任务中表现不佳的局限性。

Method: PanelTR框架利用五个科学家角色进行独立调查、自我审查和协作同行评审，实现语义级迁移。

Result: 在四个基准测试中，PanelTR优于普通LLMs，并与完全监督模型相当，且无需训练数据。

Conclusion: 结构化科学方法可有效处理复杂任务，并在零样本情境下实现灵活的语义理解。

Abstract: Table reasoning, including tabular QA and fact verification, often depends on
annotated data or complex data augmentation, limiting flexibility and
generalization. LLMs, despite their versatility, often underperform compared to
simple supervised models. To approach these issues, we introduce PanelTR, a
framework utilizing LLM agent scientists for robust table reasoning through a
structured scientific approach. PanelTR's workflow involves agent scientists
conducting individual investigations, engaging in self-review, and
participating in collaborative peer-review discussions. This process, driven by
five scientist personas, enables semantic-level transfer without relying on
data augmentation or parametric optimization. Experiments across four
benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully
supervised models, all while remaining independent of training data. Our
findings indicate that structured scientific methodology can effectively handle
complex tasks beyond table reasoning with flexible semantic understanding in a
zero-shot context.

</details>


### [15] [SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges](https://arxiv.org/abs/2508.06111)
*Dewi S. W. Gould,Bruno Mlodozeniec,Samuel F. Brown*

Main category: cs.AI

TL;DR: SKATE是一种新型评估框架，利用LLM相互生成和解决可验证任务，实现自动化、可扩展且客观的模型评估。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法依赖领域专业知识，难以适应LLM的快速发展，需要一种更通用且可扩展的评估方法。

Method: SKATE框架将评估视为游戏，LLM既作为任务生成者又作为解决者，通过生成可验证任务（如代码输出预测）进行互评。

Result: 实验表明，SKATE能有效区分模型能力，发现模型自我偏好行为，并自动揭示模型间的细粒度差异。

Conclusion: SKATE为通用、可扩展的LLM评估框架提供了重要进展，能够跟上模型发展的步伐。

Abstract: Evaluating the capabilities and risks of foundation models is paramount, yet
current methods demand extensive domain expertise, hindering their scalability
as these models rapidly evolve. We introduce SKATE: a novel evaluation
framework in which large language models (LLMs) compete by generating and
solving verifiable tasks for one another. Our core insight is to treat
evaluation as a game: models act as both task-setters and solvers, incentivized
to create questions which highlight their own strengths while exposing others'
weaknesses. SKATE offers several key advantages, balancing scalability,
open-endedness, and objectivity. It is fully automated, data-free, and
scalable, requiring no human input or domain expertise. By using verifiable
tasks rather than LLM judges, scoring is objective. Unlike domain-limited
programmatically-generated benchmarks (e.g. chess-playing or spatial
reasoning), having LLMs creatively pose challenges enables open-ended and
scalable evaluation. As a proof of concept, we introduce LLM-set
code-output-prediction (COP) challenges as a verifiable and extensible
framework in which to test our approach. Using a TrueSkill-based ranking
system, we evaluate six frontier LLMs and find that: (1) weaker models can
reliably differentiate and score stronger ones, (2) LLM-based systems are
capable of self-preferencing behavior, generating questions that align with
their own capabilities, and (3) SKATE automatically surfaces fine-grained
capability differences between models. Our findings are an important step
towards general, scalable evaluation frameworks which can keep pace with LLM
progress.

</details>


### [16] [Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem](https://arxiv.org/abs/2508.06129)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux*

Main category: cs.AI

TL;DR: 本文通过可解释AI分析VRP解决方案质量预测模型的敏感性，提出统一框架以评估特征重要性，为改进元启发式算法提供指导。


<details>
  <summary>Details</summary>
Motivation: 传统元启发式算法依赖人工设计，机器学习方法能利用组合优化问题的结构特征，提升算法效率。本研究进一步探索模型决策机制。

Method: 使用多种分类器模型预测VRP解决方案质量，结合可解释AI进行敏感性分析，提出特征重要性排名框架。

Result: 特征重要性因模型而异，但某些特征始终是强预测因子。统一框架能跨场景评估特征影响。

Conclusion: 特征重要性分析为元启发式算法设计提供新思路，有望提升VRP求解效率。

Abstract: The Vehicle Routing Problem (VRP) is a complex optimization problem with
numerous real-world applications, mostly solved using metaheuristic algorithms
due to its $\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely
on human-crafted designs developed through empirical studies. However, recent
research shows that machine learning methods can be used the structural
characteristics of solutions in combinatorial optimization, thereby aiding in
designing more efficient algorithms, particularly for solving VRP. Building on
this advancement, this study extends the previous research by conducting a
sensitivity analysis using multiple classifier models that are capable of
predicting the quality of VRP solutions. Hence, by leveraging explainable AI,
this research is able to extend the understanding of how these models make
decisions. Finally, our findings indicate that while feature importance varies,
certain features consistently emerge as strong predictors. Furthermore, we
propose a unified framework able of ranking feature impact across different
scenarios to illustrate this finding. These insights highlight the potential of
feature importance analysis as a foundation for developing a guidance mechanism
of metaheuristic algorithms for solving the VRP.

</details>


### [17] [Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications](https://arxiv.org/abs/2508.06145)
*Byeonghun Bang,Jongsuk Yoon,Dong-Jin Chang,Seho Park,Yong Oh Lee*

Main category: cs.AI

TL;DR: 该研究通过引入检索增强生成（RAG）框架，显著提升了大型语言模型（LLMs）在药物禁忌领域的准确性，减少了处方决策中的不确定性。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在医疗领域的应用，特别是在药物禁忌方面，需要高准确性和可靠性。

Method: 使用OpenAI的GPT-4o-mini作为基础模型，结合text-embedding-3-small模型和Langchain，构建混合检索系统，并利用公开的DUR数据。

Result: RAG框架显著提升了模型准确性，年龄组、妊娠和联合用药的禁忌信息准确率分别达到0.94、0.87和0.89。

Conclusion: RAG框架能有效增强LLMs在药物禁忌领域的表现，为临床决策提供更可靠的支持。

Abstract: The versatility of large language models (LLMs) has been explored across
various sectors, but their application in healthcare poses challenges,
particularly in the domain of pharmaceutical contraindications where accurate
and reliable information is required. This study enhances the capability of
LLMs to address contraindications effectively by implementing a Retrieval
Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base
model, and the text-embedding-3-small model for embeddings, our approach
integrates Langchain to orchestrate a hybrid retrieval system with re-ranking.
This system leverages Drug Utilization Review (DUR) data from public databases,
focusing on contraindications for specific age groups, pregnancy, and
concomitant drug use. The dataset includes 300 question-answer pairs across
three categories, with baseline model accuracy ranging from 0.49 to 0.57.
Post-integration of the RAG pipeline, we observed a significant improvement in
model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications
related to age groups, pregnancy, and concomitant drug use, respectively. The
results indicate that augmenting LLMs with a RAG framework can substantially
reduce uncertainty in prescription and drug intake decisions by providing more
precise and reliable drug contraindication information.

</details>


### [18] [Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution](https://arxiv.org/abs/2508.06225)
*Zailong Tian,Zhuoheng Han,Yanzhe Chen,Haozhe Xu,Xi Yang,richeng xuan,Hongfeng Wang,Lizi Liao*

Main category: cs.AI

TL;DR: 论文提出从准确性为中心转向置信度驱动的LLM评估系统，引入TH-Score量化过度自信现象，并提出LLM-as-a-Fuser框架提升可靠性和校准。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估系统过于关注准确性，忽视了置信度校准的重要性，导致实际部署中可靠性不足。

Method: 提出TH-Score量化过度自信现象，并设计LLM-as-a-Fuser框架，通过集成方法提升置信度校准。

Result: 实验表明，该方法显著改善了校准效果，实现了自适应、置信度驱动的评估，可靠性和准确性优于基线。

Conclusion: 置信度驱动的LLM评估系统更可靠，LLM-as-a-Fuser框架为实际部署提供了风险感知的解决方案。

Abstract: Large Language Models (LLMs) are widely used as automated judges, where
practical value depends on both accuracy and trustworthy, risk-aware judgments.
Existing approaches predominantly focus on accuracy, overlooking the necessity
of well-calibrated confidence, which is vital for adaptive and reliable
evaluation pipelines. In this work, we advocate a shift from accuracy-centric
evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing
the necessity of well-calibrated confidence for trustworthy and adaptive
evaluation. We systematically identify the **Overconfidence Phenomenon** in
current LLM-as-a-Judges, where predicted confidence significantly overstates
actual correctness, undermining reliability in practical deployment. To
quantify this phenomenon, we introduce **TH-Score**, a novel metric measuring
confidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an
ensemble framework that transforms LLMs into reliable, risk-aware evaluators.
Extensive experiments demonstrate that our approach substantially improves
calibration and enables adaptive, confidence-driven evaluation pipelines,
achieving superior reliability and accuracy compared to existing baselines.

</details>


### [19] [GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines](https://arxiv.org/abs/2508.06226)
*Yumeng Fu,Jiayin Zhu,Lingling Zhang,Bo Zhao,Shaoxuan Ma,Yushun Zhang,Yanrui Wu,Wenjun Wu*

Main category: cs.AI

TL;DR: GeoLaux基准测试填补了现有MLLM几何能力评估的空白，重点关注辅助线构建和长步推理，揭示了模型在复杂推理中的表现下降和辅助线意识不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试忽视辅助线构建和细粒度过程评估，无法全面评估MLLM的长步推理能力。

Method: 提出GeoLaux基准测试，包含2,186道几何题，设计五维评估策略（答案正确性、过程正确性、过程质量、辅助线影响、错误原因）。

Result: 实验显示模型在长步推理中表现显著下降，证明题中易走捷径，且缺乏辅助线意识。

Conclusion: GeoLaux可作为评估MLLM几何推理能力的基准，并指导能力提升。

Abstract: Geometry problem solving (GPS) requires models to master diagram
comprehension, logical reasoning, knowledge application, numerical computation,
and auxiliary line construction. This presents a significant challenge for
Multimodal Large Language Models (MLLMs). However, existing benchmarks for
evaluating MLLM geometry skills overlook auxiliary line construction and lack
fine-grained process evaluation, making them insufficient for assessing MLLMs'
long-step reasoning abilities. To bridge these gaps, we present the GeoLaux
benchmark, comprising 2,186 geometry problems, incorporating both calculation
and proving questions. Notably, the problems require an average of 6.51
reasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary
line construction. Building on the dataset, we design a novel five-dimensional
evaluation strategy assessing answer correctness, process correctness, process
quality, auxiliary line impact, and error causes. Extensive experiments on 13
leading MLLMs (including thinking models and non-thinking models) yield three
pivotal findings: First, models exhibit substantial performance degradation in
extended reasoning steps (nine models demonstrate over 50% performance drop).
Second, compared to calculation problems, MLLMs tend to take shortcuts when
solving proving problems. Third, models lack auxiliary line awareness, and
enhancing this capability proves particularly beneficial for overall geometry
reasoning improvement. These findings establish GeoLaux as both a benchmark for
evaluating MLLMs' long-step geometric reasoning with auxiliary lines and a
guide for capability advancement. Our dataset and code are included in
supplementary materials and will be released.

</details>


### [20] [Learning Logical Rules using Minimum Message Length](https://arxiv.org/abs/2508.06230)
*Ruben Sharma,Sebastijan Dumančić,Ross D. King,Andrew Cropper*

Main category: cs.AI

TL;DR: 提出了一种贝叶斯归纳逻辑编程方法，通过最小消息长度程序从噪声数据中学习，平衡假设复杂性和数据拟合。


<details>
  <summary>Details</summary>
Motivation: 统一概率和逻辑学习是AI的关键挑战。

Method: 使用先验和似然函数，前者偏好更通用的程序，后者偏好准确程序。

Result: 在游戏和药物设计等多个领域显著优于现有方法，尤其是最小描述长度程序学习方法。

Conclusion: 该方法数据高效，对示例平衡不敏感，甚至能从纯正例中学习。

Abstract: Unifying probabilistic and logical learning is a key challenge in AI. We
introduce a Bayesian inductive logic programming approach that learns minimum
message length programs from noisy data. Our approach balances hypothesis
complexity and data fit through priors, which explicitly favour more general
programs, and a likelihood that favours accurate programs. Our experiments on
several domains, including game playing and drug design, show that our method
significantly outperforms previous methods, notably those that learn minimum
description length programs. Our results also show that our approach is
data-efficient and insensitive to example balance, including the ability to
learn from exclusively positive examples.

</details>


### [21] [Symmetry breaking for inductive logic programming](https://arxiv.org/abs/2508.06263)
*Andrew Cropper,David M. Cerna,Matti Järvisalo*

Main category: cs.AI

TL;DR: 提出一种方法，通过打破假设空间中的对称性来优化归纳逻辑编程的搜索效率。


<details>
  <summary>Details</summary>
Motivation: 归纳逻辑编程需要搜索庞大的假设空间，且存在大量逻辑等效假设，导致搜索效率低下。

Method: 采用答案集编程实现对称性打破的方法。

Result: 在视觉推理和游戏等多个领域的实验中，求解时间从超过一小时缩短至仅17秒。

Conclusion: 该方法显著提高了归纳逻辑编程的搜索效率。

Abstract: The goal of inductive logic programming is to search for a hypothesis that
generalises training data and background knowledge. The challenge is searching
vast hypothesis spaces, which is exacerbated because many logically equivalent
hypotheses exist. To address this challenge, we introduce a method to break
symmetries in the hypothesis space. We implement our idea in answer set
programming. Our experiments on multiple domains, including visual reasoning
and game playing, show that our approach can reduce solving times from over an
hour to just 17 seconds.

</details>


### [22] [LLM Robustness Leaderboard v1 --Technical report](https://arxiv.org/abs/2508.06296)
*Pierre Peigné - Lefebvre,Quentin Feuillade-Montixi,Tom David,Nicolas Miailhe*

Main category: cs.AI

TL;DR: PRISM Eval开发了行为诱导工具BET，通过动态对抗优化实现100%攻击成功率，并提出细粒度鲁棒性指标，揭示不同模型攻击难度差异显著。


<details>
  <summary>Details</summary>
Motivation: 评估和提升大型语言模型（LLM）的鲁棒性，识别漏洞并推动社区分布式评估。

Method: 使用BET工具进行自动化红队测试，结合动态对抗优化和细粒度鲁棒性指标分析。

Result: BET对41个LLM中的37个实现100%攻击成功率，攻击难度差异达300倍以上。

Conclusion: 研究为LLM鲁棒性评估提供了实用工具和指标，支持社区协作提升AI安全性。

Abstract: This technical report accompanies the LLM robustness leaderboard published by
PRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior
Elicitation Tool (BET), an AI system performing automated red-teaming through
Dynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR)
against 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we
propose a fine-grained robustness metric estimating the average number of
attempts required to elicit harmful behaviors, revealing that attack difficulty
varies by over 300-fold across models despite universal vulnerability. We
introduce primitive-level vulnerability analysis to identify which jailbreaking
techniques are most effective for specific hazard categories. Our collaborative
evaluation with trusted third parties from the AI Safety Network demonstrates
practical pathways for distributed robustness assessment across the community.

</details>


### [23] [A "good regulator theorem" for embodied agents](https://arxiv.org/abs/2508.06326)
*Nathaniel Virgo,Martin Biehl,Manuel Baltieri,Matteo Capucci*

Main category: cs.AI

TL;DR: 论文探讨了Conant和Ashby的定理在更广泛系统中的适用性，提出了一种新的‘信念更新’模型概念，强调观察者在模型定义中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究Conant和Ashby定理的局限性，并探索如何在更广泛的系统中定义‘模型’。

Method: 通过引入‘信念更新’的概念，将模型定义为观察者对系统的解释。

Result: 提出了一种更广泛适用的定理，解决了原有定理的局限性。

Conclusion: 模型的定义需要观察者的参与，且适用于更广泛的系统，包括经典控制理论和内部状态调节。

Abstract: In a classic paper, Conant and Ashby claimed that "every good regulator of a
system must be a model of that system." Artificial Life has produced many
examples of systems that perform tasks with apparently no model in sight; these
suggest Conant and Ashby's theorem doesn't easily generalise beyond its
restricted setup. Nevertheless, here we show that a similar intuition can be
fleshed out in a different way: whenever an agent is able to perform a
regulation task, it is possible for an observer to interpret it as having
"beliefs" about its environment, which it "updates" in response to sensory
input. This notion of belief updating provides a notion of model that is more
sophisticated than Conant and Ashby's, as well as a theorem that is more
broadly applicable. However, it necessitates a change in perspective, in that
the observer plays an essential role in the theory: models are not a mere
property of the system but are imposed on it from outside. Our theorem holds
regardless of whether the system is regulating its environment in a classic
control theory setup, or whether it's regulating its own internal state; the
model is of its environment either way. The model might be trivial, however,
and this is how the apparent counterexamples are resolved.

</details>


### [24] [AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games](https://arxiv.org/abs/2508.06348)
*Mille Mei Zhen Loo,Gert Luzkov,Paolo Burelli*

Main category: cs.AI

TL;DR: 提出了一种基于Transformer的机器学习模型AntiCheatPT_256，用于检测《CS2》中的作弊行为，并公开了数据集CS2CD。模型在测试集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 在线游戏作弊破坏游戏体验，现有反作弊系统难以在不侵犯用户隐私的情况下应对不断演变的作弊手段。

Method: 使用CS2CD数据集（795场比赛）生成90,707个上下文窗口，并通过数据增强解决类别不平衡问题，训练Transformer模型。

Result: 模型在未增强测试集上准确率达89.17%，AUC为93.36%。

Conclusion: 该方法强调可重复性和实际应用性，为数据驱动的作弊检测研究提供了坚实基础。

Abstract: Cheating in online video games compromises the integrity of gaming
experiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face
significant challenges in keeping pace with evolving cheating methods without
imposing invasive measures on users' systems. This paper presents
AntiCheatPT\_256, a transformer-based machine learning model designed to detect
cheating behaviour in Counter-Strike 2 using gameplay data. To support this, we
introduce and publicly release CS2CD: A labelled dataset of 795 matches. Using
this dataset, 90,707 context windows were created and subsequently augmented to
address class imbalance. The transformer model, trained on these windows,
achieved an accuracy of 89.17\% and an AUC of 93.36\% on an unaugmented test
set. This approach emphasizes reproducibility and real-world applicability,
offering a robust baseline for future research in data-driven cheat detection.

</details>


### [25] [From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI](https://arxiv.org/abs/2508.06352)
*Christian Meske,Justin Brenne,Erdi Uenal,Sabahat Oelcer,Ayseguel Doganguen*

Main category: cs.AI

TL;DR: 本文提出“解释性AI”作为可解释AI（XAI）的补充范式，通过生成式AI能力提供上下文推理支持，而非仅关注算法透明性。


<details>
  <summary>Details</summary>
Motivation: 当前XAI方法过于抽象且缺乏适应性，未能有效支持用户理解。本文旨在通过解释性AI提升人类决策支持。

Method: 提出八维概念模型，结合叙事沟通、自适应个性化和渐进披露原则，并通过医疗领域的快速情境设计方法进行实证验证。

Result: 用户更偏好上下文敏感的多模态解释，而非技术透明性。

Conclusion: 解释性AI为以用户为中心的AI解释方法提供了研究议程，强调跨领域和文化背景的应用。

Abstract: Current explainable AI (XAI) approaches prioritize algorithmic transparency
and present explanations in abstract, non-adaptive formats that often fail to
support meaningful end-user understanding. This paper introduces "Explanatory
AI" as a complementary paradigm that leverages generative AI capabilities to
serve as explanatory partners for human understanding rather than providers of
algorithmic transparency. While XAI reveals algorithmic decision processes for
model validation, Explanatory AI addresses contextual reasoning to support
human decision-making in sociotechnical contexts. We develop a definition and
systematic eight-dimensional conceptual model distinguishing Explanatory AI
through narrative communication, adaptive personalization, and progressive
disclosure principles. Empirical validation through Rapid Contextual Design
methodology with healthcare professionals demonstrates that users consistently
prefer context-sensitive, multimodal explanations over technical transparency.
Our findings reveal the practical urgency for AI systems designed for human
comprehension rather than algorithmic introspection, establishing a
comprehensive research agenda for advancing user-centered AI explanation
approaches across diverse domains and cultural contexts.

</details>


### [26] [Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned](https://arxiv.org/abs/2508.06368)
*Claudia dAmato,Giuseppe Rubini,Francesco Didio,Donato Francioso,Fatima Zahra Amara,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 论文提出两种构建法律知识图谱的方法，填补法律领域知识图谱的空白，并验证其在暴力侵害妇女案件中的应用。


<details>
  <summary>Details</summary>
Motivation: 法律决策需要全面的立法背景知识和最新的法律案例信息，但法律领域的知识图谱较少。

Method: 采用两种互补方法：系统化的自底向上方法和基于大型语言模型的新方案，结合结构化数据提取、本体开发和语义丰富。

Result: 构建了针对暴力侵害妇女案件的法律知识图谱，并通过能力问题验证其有效性。

Conclusion: 该知识图谱可提升法律信息的可访问性，支持复杂查询，并为预测性司法机器学习工具提供知识支持。

Abstract: Legal decision-making process requires the availability of comprehensive and
detailed legislative background knowledge and up-to-date information on legal
cases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a
valuable tool to facilitate access to legal information, to be queried and
exploited for the purpose, and to enable advanced reasoning and machine
learning applications. Indeed, legal KGs may act as knowledge intensive
component to be used by pre-dictive machine learning solutions supporting the
decision process of the legal expert. Nevertheless, a few KGs can be found in
the legal domain. To fill this gap, we developed a legal KG targeting legal
cases of violence against women, along with clear adopted methodologies.
Specifically, the paper introduces two complementary approaches for automated
legal KG construction; a systematic bottom-up approach, customized for the
legal domain, and a new solution leveraging Large Language Models. Starting
from legal sentences publicly available from the European Court of Justice, the
solutions integrate structured data extraction, ontology development, and
semantic enrichment to produce KGs tailored for legal cases involving violence
against women. After analyzing and comparing the results of the two approaches,
the developed KGs are validated via suitable competency questions. The obtained
KG may be impactful for multiple purposes: can improve the accessibility to
legal information both to humans and machine, can enable complex queries and
may constitute an important knowledge component to be possibly exploited by
machine learning tools tailored for predictive justice.

</details>


### [27] [The Fair Game: Auditing & Debiasing AI Algorithms Over Time](https://arxiv.org/abs/2508.06443)
*Debabrota Basu,Udvas Das*

Main category: cs.AI

TL;DR: 论文提出了一种动态机制“Fair Game”，通过结合审计员和去偏算法，利用强化学习实现机器学习算法的公平性，并随时间调整其预测。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习的定义多为观察性，且在实际应用中存在冲突和局限性，无法适应动态社会环境。因此，需要一种能够动态调整公平目标的机制。

Method: 提出“Fair Game”框架，将审计员和去偏算法通过强化学习循环结合，动态调整公平目标。

Result: “Fair Game”能够模拟社会伦理和法律框架的演变，提供灵活且适应性强的公平机器学习系统。

Conclusion: “Fair Game”为公平机器学习提供了一种动态、适应性强的解决方案，适用于部署前后的系统。

Abstract: An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify
different types of bias (also known as unfairness) exhibited in the predictions
of ML algorithms, and to design new algorithms to mitigate them. Often, the
definitions of bias used in the literature are observational, i.e. they use the
input and output of a pre-trained algorithm to quantify a bias under concern.
In reality,these definitions are often conflicting in nature and can only be
deployed if either the ground truth is known or only in retrospect after
deploying the algorithm. Thus,there is a gap between what we want Fair ML to
achieve and what it does in a dynamic social environment. Hence, we propose an
alternative dynamic mechanism,"Fair Game",to assure fairness in the predictions
of an ML algorithm and to adapt its predictions as the society interacts with
the algorithm over time. "Fair Game" puts together an Auditor and a Debiasing
algorithm in a loop around an ML algorithm. The "Fair Game" puts these two
components in a loop by leveraging Reinforcement Learning (RL). RL algorithms
interact with an environment to take decisions, which yields new observations
(also known as data/feedback) from the environment and in turn, adapts future
decisions. RL is already used in algorithms with pre-fixed long-term fairness
goals. "Fair Game" provides a unique framework where the fairness goals can be
adapted over time by only modifying the auditor and the different biases it
quantifies. Thus,"Fair Game" aims to simulate the evolution of ethical and
legal frameworks in the society by creating an auditor which sends feedback to
a debiasing algorithm deployed around an ML system. This allows us to develop a
flexible and adaptive-over-time framework to build Fair ML systems pre- and
post-deployment.

</details>


### [28] [What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting](https://arxiv.org/abs/2508.06454)
*Joshua Caiata,Ben Armstrong,Kate Larson*

Main category: cs.AI

TL;DR: 提出数据驱动框架评估多赢家投票规则在实际偏好分布中违反公理的频率，并通过神经网络优化传统规则。


<details>
  <summary>Details</summary>
Motivation: 研究多赢家投票规则在不同偏好分布下的公理表现，摆脱最坏情况分析的二元视角。

Method: 提出数据驱动框架，分析投票规则与公理表现的关系，并利用神经网络优化。

Result: 神经网络作为投票规则优于传统规则，能减少公理违反。

Conclusion: 数据驱动方法可为新投票系统设计提供支持，推动社会选择领域的数据驱动研究。

Abstract: Committee-selection problems arise in many contexts and applications, and
there has been increasing interest within the social choice research community
on identifying which properties are satisfied by different multi-winner voting
rules. In this work, we propose a data-driven framework to evaluate how
frequently voting rules violate axioms across diverse preference distributions
in practice, shifting away from the binary perspective of axiom satisfaction
given by worst-case analysis. Using this framework, we analyze the relationship
between multi-winner voting rules and their axiomatic performance under several
preference distributions. We then show that neural networks, acting as voting
rules, can outperform traditional rules in minimizing axiom violations. Our
results suggest that data-driven approaches to social choice can inform the
design of new voting systems and support the continuation of data-driven
research in social choice.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [29] [GPU-Accelerated Barrier-Rate Guided MPPI Control for Tractor-Trailer Systems](https://arxiv.org/abs/2508.05773)
*Keyvan Majd,Hardik Parwana,Bardh Hoxha,Steven Hong,Hideki Okamoto,Georgios Fainekos*

Main category: cs.RO

TL;DR: BR-MPPI方法通过嵌入CBF约束改进MPPI控制，提升复杂环境中铰接车辆的导航能力，实验显示其在停车场景中优于传统MPPI方法。


<details>
  <summary>Details</summary>
Motivation: 铰接车辆（如拖车、堆场卡车等）在拥挤环境中倒车和机动时面临挑战，需一种更鲁棒的控制方法。

Method: BR-MPPI将CBF约束直接嵌入路径积分更新中，引导采样分布朝向无碰撞且动态可行的轨迹。

Result: 在高保真CarMaker模拟器中，BR-MPPI在12米拖车倒车和前进停车任务中表现优于传统MPPI，控制频率超过100Hz。

Conclusion: BR-MPPI通过改进采样策略和嵌入CBF约束，显著提升了铰接车辆在复杂环境中的导航鲁棒性和性能。

Abstract: Articulated vehicles such as tractor-trailers, yard trucks, and similar
platforms must often reverse and maneuver in cluttered spaces where pedestrians
are present. We present how Barrier-Rate guided Model Predictive Path Integral
(BR-MPPI) control can solve navigation in such challenging environments.
BR-MPPI embeds Control Barrier Function (CBF) constraints directly into the
path-integral update. By steering the importance-sampling distribution toward
collision-free, dynamically feasible trajectories, BR-MPPI enhances the
exploration strength of MPPI and improves robustness of resulting trajectories.
The method is evaluated in the high-fidelity CarMaker simulator on a 12 [m]
tractor-trailer tasked with reverse and forward parking in a parking lot.
BR-MPPI computes control inputs in above 100 [Hz] on a single GPU (for
scenarios with eight obstacles) and maintains better parking clearance than a
standard MPPI baseline and an MPPI with collision cost baseline.

</details>


### [30] [Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction](https://arxiv.org/abs/2508.05838)
*Ahmad Farooq,Kamran Iqbal*

Main category: cs.RO

TL;DR: 论文提出了一种结合视觉基础模型与强化学习的新方法，显著提升了模拟环境中对象的交互能力。


<details>
  <summary>Details</summary>
Motivation: 通过整合视觉基础模型（如SAM和YOLOv5）与强化学习（PPO），旨在提升智能体在复杂环境中的感知与交互能力。

Method: 结合Segment Anything Model (SAM)和YOLOv5作为感知模块，使用PPO算法在AI2-THOR模拟环境中训练智能体。

Result: 实验显示，相比基线方法，对象交互成功率提升52.5%，导航效率提升33%，平均累积奖励增加68%。

Conclusion: 研究表明，视觉基础模型与强化学习的结合在复杂机器人任务中具有巨大潜力，为更先进的自主智能体铺平了道路。

Abstract: This paper presents a novel approach that integrates vision foundation models
with reinforcement learning to enhance object interaction capabilities in
simulated environments. By combining the Segment Anything Model (SAM) and
YOLOv5 with a Proximal Policy Optimization (PPO) agent operating in the
AI2-THOR simulation environment, we enable the agent to perceive and interact
with objects more effectively. Our comprehensive experiments, conducted across
four diverse indoor kitchen settings, demonstrate significant improvements in
object interaction success rates and navigation efficiency compared to a
baseline agent without advanced perception. The results show a 68% increase in
average cumulative reward, a 52.5% improvement in object interaction success
rate, and a 33% increase in navigation efficiency. These findings highlight the
potential of integrating foundation models with reinforcement learning for
complex robotic tasks, paving the way for more sophisticated and capable
autonomous agents.

</details>


### [31] [Modular Vacuum-Based Fixturing System for Adaptive Disassembly Workspace Integration](https://arxiv.org/abs/2508.05936)
*Haohui Pan,Takuya Kiyokawa,Tomoki Ishikura,Shingo Hamada,Genichiro Matsuda,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出了一种基于模块化真空夹具的系统，利用软气球夹持器适应复杂几何形状，提高拆卸小家电的成功率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统刚性夹具难以适应小家电的复杂曲面几何形状，导致拆卸任务效率低下。

Method: 开发了稳定性感知规划框架，通过采样目标物体底面、筛选接触点并评估支撑配置，结合气球夹持器实现稳定支撑。

Result: 实验表明，该方法在螺丝拆卸任务中比传统刚性夹具具有更高的成功率和稳定性。

Conclusion: 模块化真空夹具系统为复杂几何形状物体的拆卸提供了更高效、稳定的解决方案。

Abstract: The disassembly of small household appliances poses significant challenges
due to their complex and curved geometries, which render traditional rigid
fixtures inadequate. In this paper, we propose a modular vacuum-based fixturing
system that leverages commercially available balloon-type soft grippers to
conform to arbitrarily shaped surfaces and provide stable support during
screw-removal tasks. To enable a reliable deployment of the system, we develop
a stability-aware planning framework that samples the bottom surface of the
target object, filters candidate contact points based on geometric continuity,
and evaluates support configurations using convex hull-based static stability
criteria. We compare the quality of object placement under different numbers
and configurations of balloon hands. In addition, real-world experiments were
conducted to compare the success rates of traditional rigid fixtures with our
proposed system. The results demonstrate that our method consistently achieves
higher success rates and superior placement stability during screw removal
tasks.

</details>


### [32] [Affordance-Guided Dual-Armed Disassembly Teleoperation for Mating Parts](https://arxiv.org/abs/2508.05937)
*Gen Sako,Takuya Kiyokawa,Kensuke Harada,Tomoki Ishikura,Naoya Miyaji,Genichiro Matsuda*

Main category: cs.RO

TL;DR: 提出了一种基于感知引导的远程操作系统，用于解决机器人拆卸配合零件时的灵活操作和内部结构可见性问题。


<details>
  <summary>Details</summary>
Motivation: 配合零件的非破坏性拆卸在机器人操作中具有挑战性，主要由于灵活操作需求和内部结构不可见性。

Method: 系统通过虚拟环境可视化可行抓取位姿和拆卸方向，并采用混合控制器（位置与阻抗控制）以减少负载下的位置跟踪误差。

Result: 实验验证了系统的有效性，任务成功率提高且物体位姿偏差减少。

Conclusion: 该系统为配合零件的拆卸任务提供了一种直观且高效的解决方案。

Abstract: Robotic non-destructive disassembly of mating parts remains challenging due
to the need for flexible manipulation and the limited visibility of internal
structures. This study presents an affordance-guided teleoperation system that
enables intuitive human demonstrations for dual-arm fix-and-disassemble tasks
for mating parts. The system visualizes feasible grasp poses and disassembly
directions in a virtual environment, both derived from the object's geometry,
to address occlusions and structural complexity. To prevent excessive position
tracking under load when following the affordance, we integrate a hybrid
controller that combines position and impedance control into the teleoperated
disassembly arm. Real-world experiments validate the effectiveness of the
proposed system, showing improved task success rates and reduced object pose
deviation.

</details>


### [33] [Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution](https://arxiv.org/abs/2508.05941)
*Zhanyi Sun,Shuran Song*

Main category: cs.RO

TL;DR: LPB框架通过将专家演示的潜在嵌入作为隐式屏障，分离安全与不安全状态，提升视觉运动策略的鲁棒性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 解决行为克隆中因协变量偏移导致的策略脆弱性问题，避免依赖人工修正或数据增强。

Method: 结合扩散策略和动态模型，前者基于专家数据，后者利用专家和次优策略数据预测未来状态并优化其保持在专家分布内。

Result: 模拟和实际实验表明，LPB提升了策略鲁棒性和数据效率，无需额外人工干预。

Conclusion: LPB为有限专家数据下的可靠操作提供了高效且鲁棒的解决方案。

Abstract: Visuomotor policies trained via behavior cloning are vulnerable to covariate
shift, where small deviations from expert trajectories can compound into
failure. Common strategies to mitigate this issue involve expanding the
training distribution through human-in-the-loop corrections or synthetic data
augmentation. However, these approaches are often labor-intensive, rely on
strong task assumptions, or compromise the quality of imitation. We introduce
Latent Policy Barrier, a framework for robust visuomotor policy learning.
Inspired by Control Barrier Functions, LPB treats the latent embeddings of
expert demonstrations as an implicit barrier separating safe, in-distribution
states from unsafe, out-of-distribution (OOD) ones. Our approach decouples the
role of precise expert imitation and OOD recovery into two separate modules: a
base diffusion policy solely on expert data, and a dynamics model trained on
both expert and suboptimal policy rollout data. At inference time, the dynamics
model predicts future latent states and optimizes them to stay within the
expert distribution. Both simulated and real-world experiments show that LPB
improves both policy robustness and data efficiency, enabling reliable
manipulation from limited expert data and without additional human correction
or annotation.

</details>


### [34] [Social and Telepresence Robots for Accessibility and Inclusion in Small Museums](https://arxiv.org/abs/2508.05946)
*Nello Balossino,Rossana Damiano,Cristina Gena,Alberto Lillo,Anna Maria Marras,Claudio Mattutino,Antonio Pizzo,Alessia Prin,Fabiana Vernero*

Main category: cs.RO

TL;DR: ROBSO-PM项目旨在通过社交机器人和远程社交机器人提升小型博物馆的可访问性，重点关注感知、文化和认知障碍。


<details>
  <summary>Details</summary>
Motivation: 许多博物馆存在可访问性障碍，尤其是在低人口密度地区，项目希望通过技术手段改善这一问题。

Method: 项目以三个博物馆为案例研究，探索机器人作为导览工具和远程访问工具的应用，涉及讲故事、机器人个性、共情等技术。

Result: 机器人可用于支持包容性参观和远程访问，研究重点包括角色定义和自主性。

Conclusion: 社交机器人有望提升小型博物馆的可访问性，尤其在感知和文化障碍方面。

Abstract: There are still many museums that present accessibility barriers,
particularly regarding perceptual, cultural, and cognitive aspects. This is
especially evident in low-density population areas. The aim of the ROBSO-PM
project is to improve the accessibility of small museums through the use of
social robots and social telepresence robots, focusing on three museums as case
studies: the Museum of the Holy Shroud in Turin, a small but globally known
institution, and two lesser known mountain museums: the Museum of the Champlas
du Col Carnival and the Pragelato Museum of Alpine Peoples' Costumes and
Traditions. The project explores two main applications for robots: as guides
supporting inclusive visits for foreign or disabled visitors, and as
telepresence tools allowing people with limited mobility to access museums
remotely. From a research perspective, key topics include storytelling, robot
personality, empathy, personalization, and, in the case of telepresence,
collaboration between the robot and the person, with clearly defined roles and
autonomy.

</details>


### [35] [Dynamical Trajectory Planning of Disturbance Consciousness for Air-Land Bimodal Unmanned Aerial Vehicles](https://arxiv.org/abs/2508.05972)
*Shaoting Liu,Zhou Liu*

Main category: cs.RO

TL;DR: 本文提出了一种扰动感知的轨迹规划框架，用于提升空陆双模车辆在复杂环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 结合空中和地面移动的优势，空陆双模车辆在复杂环境中具有潜力，但环境扰动会影响轨迹规划的鲁棒性。

Method: 提出了一种扰动感知的规划框架，包括实时扰动估计、路径搜索和轨迹优化，并引入扰动自适应安全边界调整机制。

Result: 实验验证了方法的有效性，在跟踪精度、任务效率和能量性能方面均有提升。

Conclusion: 该方法能够适应不同地形和操作条件，显著提升了双模车辆的运动规划鲁棒性。

Abstract: Air-land bimodal vehicles provide a promising solution for navigating complex
environments by combining the flexibility of aerial locomotion with the energy
efficiency of ground mobility. To enhance the robustness of trajectory planning
under environmental disturbances, this paper presents a disturbance-aware
planning framework that incorporates real-time disturbance estimation into both
path searching and trajectory optimization. A key component of the framework is
a disturbance-adaptive safety boundary adjustment mechanism, which dynamically
modifies the vehicle's feasible dynamic boundaries based on estimated
disturbances to ensure trajectory feasibility. Leveraging the dynamics model of
the bimodal vehicle, the proposed approach achieves adaptive and reliable
motion planning across different terrains and operating conditions. A series of
real-world experiments and benchmark comparisons on a custom-built platform
validate the effectiveness and robustness of the method, demonstrating
improvements in tracking accuracy, task efficiency, and energy performance
under both ground and aerial disturbances.

</details>


### [36] [ReNiL: Relative Neural Inertial Locator with Any-Scale Bayesian Inference](https://arxiv.org/abs/2508.06053)
*Kaixuan Wu,Yuanzhuo Xu,Zejun Zhang,Weiping Zhu,Steve Drew,Xiaoguang Niu*

Main category: cs.RO

TL;DR: ReNiL是一个贝叶斯深度学习框架，用于高效、准确且具有不确定性感知的行人惯性定位，通过IPDPs和ASLE技术实现多尺度运动适应和一致的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 现有学习型方法依赖固定滑动窗口，难以适应多样化运动尺度和步频，且不确定性估计不一致，限制了实际应用。

Method: ReNiL引入IPDPs在关键路径点估计运动，结合ASLE网络（融合自监督与贝叶斯回归）和运动感知方向滤波器，支持任意尺度的IMU序列推理。

Result: 在RoNIN-ds和WUDataset上，ReNiL在位移精度和不确定性一致性上达到SOTA，优于TLIO、CTIN等方法，同时降低计算量。

Conclusion: ReNiL为移动和IoT定位提供了可扩展、不确定性感知的基础，展示了实际应用的鲁棒性和实用性。

Abstract: Pedestrian inertial localization is key for mobile and IoT services because
it provides infrastructure-free positioning. Yet most learning-based methods
depend on fixed sliding-window integration, struggle to adapt to diverse motion
scales and cadences, and yield inconsistent uncertainty, limiting real-world
use. We present ReNiL, a Bayesian deep-learning framework for accurate,
efficient, and uncertainty-aware pedestrian localization. ReNiL introduces
Inertial Positioning Demand Points (IPDPs) to estimate motion at contextually
meaningful waypoints instead of dense tracking, and supports inference on IMU
sequences at any scale so cadence can match application needs. It couples a
motion-aware orientation filter with an Any-Scale Laplace Estimator (ASLE), a
dual-task network that blends patch-based self-supervision with Bayesian
regression. By modeling displacements with a Laplace distribution, ReNiL
provides homogeneous Euclidean uncertainty that integrates cleanly with other
sensors. A Bayesian inference chain links successive IPDPs into consistent
trajectories. On RoNIN-ds and a new WUDataset covering indoor and outdoor
motion from 28 participants, ReNiL achieves state-of-the-art displacement
accuracy and uncertainty consistency, outperforming TLIO, CTIN, iMoT, and RoNIN
variants while reducing computation. Application studies further show
robustness and practicality for mobile and IoT localization, making ReNiL a
scalable, uncertainty-aware foundation for next-generation positioning.

</details>


### [37] [Incremental Language Understanding for Online Motion Planning of Robot Manipulators](https://arxiv.org/abs/2508.06095)
*Mitchell Abrams,Thies Oelerich,Christian Hartl-Nesic,Andreas Kugi,Matthias Scheutz*

Main category: cs.RO

TL;DR: 提出了一种基于推理的增量解析器，结合在线运动规划算法，实现机器人对动态语言输入的实时适应。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设指令完全明确，导致修正或澄清时需停止并重新规划，效率低下。

Method: 引入增量解析器，维护多个候选解析，结合符号推理与在线运动规划。

Result: 系统能实时调整运动计划，适应目标位姿、约束或任务目标的动态变化。

Conclusion: 增量语言理解与实时运动规划的结合提升了人机协作的自然性和流畅性。

Abstract: Human-robot interaction requires robots to process language incrementally,
adapting their actions in real-time based on evolving speech input. Existing
approaches to language-guided robot motion planning typically assume fully
specified instructions, resulting in inefficient stop-and-replan behavior when
corrections or clarifications occur. In this paper, we introduce a novel
reasoning-based incremental parser which integrates an online motion planning
algorithm within the cognitive architecture. Our approach enables continuous
adaptation to dynamic linguistic input, allowing robots to update motion plans
without restarting execution. The incremental parser maintains multiple
candidate parses, leveraging reasoning mechanisms to resolve ambiguities and
revise interpretations when needed. By combining symbolic reasoning with online
motion planning, our system achieves greater flexibility in handling speech
corrections and dynamically changing constraints. We evaluate our framework in
real-world human-robot interaction scenarios, demonstrating online adaptions of
goal poses, constraints, or task objectives. Our results highlight the
advantages of integrating incremental language understanding with real-time
motion planning for natural and fluid human-robot collaboration. The
experiments are demonstrated in the accompanying video at
www.acin.tuwien.ac.at/42d5.

</details>


### [38] [Bounding Distributional Shifts in World Modeling through Novelty Detection](https://arxiv.org/abs/2508.06096)
*Eric Jing,Abdeslam Boularias*

Main category: cs.RO

TL;DR: 提出了一种基于变分自编码器的新颖性检测方法，以提高模型规划对学习世界模型质量的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉世界模型对训练质量敏感，需要近乎完整的动作和状态空间覆盖以防止推理时发散。

Method: 使用变分自编码器作为新颖性检测器，确保规划中的动作轨迹不偏离训练数据分布。

Result: 在模拟机器人环境中实验，结果表明该方法在数据效率上优于现有技术。

Conclusion: 该方法显著提升了模型规划对训练数据分布的鲁棒性和数据效率。

Abstract: Recent work on visual world models shows significant promise in latent state
dynamics obtained from pre-trained image backbones. However, most of the
current approaches are sensitive to training quality, requiring near-complete
coverage of the action and state space during training to prevent divergence
during inference. To make a model-based planning algorithm more robust to the
quality of the learned world model, we propose in this work to use a
variational autoencoder as a novelty detector to ensure that proposed action
trajectories during planning do not cause the learned model to deviate from the
training data distribution. To evaluate the effectiveness of this approach, a
series of experiments in challenging simulated robot environments was carried
out, with the proposed method incorporated into a model-predictive control
policy loop extending the DINO-WM architecture. The results clearly show that
the proposed method improves over state-of-the-art solutions in terms of data
efficiency.

</details>


### [39] [Beyond Constant Parameters: Hyper Prediction Models and HyperMPC](https://arxiv.org/abs/2508.06181)
*Jan Węgrzynowski,Piotr Kicki,Grzegorz Czechmanowski,Maciej Krupka,Krzysztof Walas*

Main category: cs.RO

TL;DR: 提出了一种基于时间依赖动态模型的Hyper Prediction Model（HyperPM），用于解决梯度MPC中动态模型的局限性，显著减少了长期预测误差。


<details>
  <summary>Details</summary>
Motivation: 现有梯度MPC中的动态模型受限于计算复杂性和状态表示，无法准确预测未建模的动态现象。

Method: 通过神经网络学习时间变化的模型参数，将未建模动态投影到时间依赖的动态模型中，保持计算效率和鲁棒性。

Result: 在F1TENTH自动驾驶赛车等挑战性系统中，HyperPM显著减少了长期预测误差，并在MPC框架（HyperMPC）中优于现有技术。

Conclusion: HyperPM通过时间依赖的动态模型提升了MPC的性能，适用于复杂系统的控制。

Abstract: Model Predictive Control (MPC) is among the most widely adopted and reliable
methods for robot control, relying critically on an accurate dynamics model.
However, existing dynamics models used in the gradient-based MPC are limited by
computational complexity and state representation. To address this limitation,
we propose the Hyper Prediction Model (HyperPM) - a novel approach in which we
project the unmodeled dynamics onto a time-dependent dynamics model. This
time-dependency is captured through time-varying model parameters, whose
evolution over the MPC prediction horizon is learned using a neural network.
Such formulation preserves the computational efficiency and robustness of the
base model while equipping it with the capacity to anticipate previously
unmodeled phenomena. We evaluated the proposed approach on several challenging
systems, including real-world F1TENTH autonomous racing, and demonstrated that
it significantly reduces long-horizon prediction errors. Moreover, when
integrated within the MPC framework (HyperMPC), our method consistently
outperforms existing state-of-the-art techniques.

</details>


### [40] [Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model](https://arxiv.org/abs/2508.06206)
*Hanqing Wang,Shaoyang Wang,Yiming Zhong,Zemin Yang,Jiamin Wang,Zhiqing Cui,Jiahao Yuan,Yifan Han,Mingyu Liu,Yuexin Ma*

Main category: cs.RO

TL;DR: Affordance-R1是一个统一的affordance grounding框架，结合了认知链式思维（CoT）和强化学习（GRPO），提升了跨领域泛化和显式推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型因缺乏链式思维推理能力，忽视了不同对象间的affordance共享，限制了泛化和推理能力。

Method: 提出Affordance-R1框架，设计包含格式、感知和认知奖励的affordance函数，并构建高质量数据集ReasonAff。

Result: 模型在零样本泛化和推理能力上表现优异，超越现有方法，并展示开放世界泛化能力。

Conclusion: Affordance-R1首次将GRPO强化学习与推理结合，推动了affordance推理领域的发展。

Abstract: Affordance grounding focuses on predicting the specific regions of objects
that are associated with the actions to be performed by robots. It plays a
vital role in the fields of human-robot interaction, human-object interaction,
embodied manipulation, and embodied perception. Existing models often neglect
the affordance shared among different objects because they lack the
Chain-of-Thought(CoT) reasoning abilities, limiting their out-of-domain (OOD)
generalization and explicit reasoning capabilities. To address these
challenges, we propose Affordance-R1, the first unified affordance grounding
framework that integrates cognitive CoT guided Group Relative Policy
Optimization (GRPO) within a reinforcement learning paradigm. Specifically, we
designed a sophisticated affordance function, which contains format,
perception, and cognition rewards to effectively guide optimization directions.
Furthermore, we constructed a high-quality affordance-centric reasoning
dataset, ReasonAff, to support training. Trained exclusively via reinforcement
learning with GRPO and without explicit reasoning data, Affordance-R1 achieves
robust zero-shot generalization and exhibits emergent test-time reasoning
capabilities. Comprehensive experiments demonstrate that our model outperforms
well-established methods and exhibits open-world generalization. To the best of
our knowledge, Affordance-R1 is the first to integrate GRPO-based RL with
reasoning into affordance reasoning. The code of our method and our dataset is
released on https://github.com/hq-King/Affordance-R1.

</details>


### [41] [Computer Vision-based Adaptive Control for Back Exoskeleton Performance Optimization](https://arxiv.org/abs/2508.06207)
*Andrea Dal Prete,Seyram Ofori,Chan Yon Sin,Ashwin Narayan,Francesco Braghin,Marta Gandolla,Haoyong Yu*

Main category: cs.RO

TL;DR: 研究提出了一种基于肌肉活动减少、不适感和用户偏好的优化空间，开发了实时负载估计的自适应控制方法，显著降低了背部肌肉激活峰值。


<details>
  <summary>Details</summary>
Motivation: 解决背部外骨骼支持策略优化和自适应控制的挑战，以提高其工业应用效果。

Method: 构建优化空间，结合肌肉活动、不适感和用户偏好；开发基于视觉的自适应控制管道，实时估计负载并动态调整支持。

Result: 实验显示自适应控制将峰值背部肌肉激活降低23%，准确率超80%，且用户偏好和舒适度得到保持。

Conclusion: 验证了智能、上下文感知控制在工业外骨骼中的潜力，为动态支持调制提供了有效框架。

Abstract: Back exoskeletons can reduce musculoskeletal strain, but their effectiveness
depends on support modulation and adaptive control. This study addresses two
challenges: defining optimal support strategies and developing adaptive control
based on payload estimation. We introduce an optimization space based on muscle
activity reduction, perceived discomfort, and user preference, constructing
functions to identify optimal strategies. Experiments with 12 subjects revealed
optimal operating regions, highlighting the need for dynamic modulation. Based
on these insights, we developed a vision-based adaptive control pipeline that
estimates payloads in real-time by enhancing exoskeleton contextual
understanding, minimising latency and enabling support adaptation within the
defined optimisation space. Validation with 12 more subjects showed over 80%
accuracy and improvements across all metrics. Compared to static control,
adaptive modulation reduced peak back muscle activation by up to 23% while
preserving user preference and minimising discomfort. These findings validate
the proposed framework and highlight the potential of intelligent,
context-aware control in industrial exoskeletons.

</details>


### [42] [REBot: Reflexive Evasion Robot for Instantaneous Dynamic Obstacle Avoidance](https://arxiv.org/abs/2508.06229)
*Zihao Xu,Ce Hao,Chunzheng Wang,Kuankuan Sima,Fan Shi,Jin Song Dong*

Main category: cs.RO

TL;DR: 本文提出了一种名为REBot的控制框架，用于四足机器人在动态障碍物环境中的实时反射性避障。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖导航轨迹重规划，反应时间不足，无法应对快速接近的障碍物，因此需要一种低延迟的反射性避障能力。

Method: REBot结合避障策略和恢复策略，采用有限状态机设计，并通过精心设计的学习课程、正则化和自适应奖励实现鲁棒避障。

Result: 实验表明，REBot在避障成功率、能效和对快速移动障碍物的鲁棒性方面均有显著提升。

Conclusion: REBot为四足机器人提供了高效的实时反射性避障解决方案。

Abstract: Dynamic obstacle avoidance (DOA) is critical for quadrupedal robots operating
in environments with moving obstacles or humans. Existing approaches typically
rely on navigation-based trajectory replanning, which assumes sufficient
reaction time and leading to fails when obstacles approach rapidly. In such
scenarios, quadrupedal robots require reflexive evasion capabilities to perform
instantaneous, low-latency maneuvers. This paper introduces Reflexive Evasion
Robot (REBot), a control framework that enables quadrupedal robots to achieve
real-time reflexive obstacle avoidance. REBot integrates an avoidance policy
and a recovery policy within a finite-state machine. With carefully designed
learning curricula and by incorporating regularization and adaptive rewards,
REBot achieves robust evasion and rapid stabilization in instantaneous DOA
tasks. We validate REBot through extensive simulations and real-world
experiments, demonstrating notable improvements in avoidance success rates,
energy efficiency, and robustness to fast-moving obstacles. Videos and appendix
are available on https://rebot-2025.github.io/.

</details>


### [43] [ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints](https://arxiv.org/abs/2508.06266)
*Zezeng Li,Rui Yang,Ruochen Chen,ZhongXuan Luo,Liming Chen*

Main category: cs.RO

TL;DR: 提出了一种自适应扩散策略（ADP），通过几何流形约束和解析引导初始化优化扩散策略，提升机器人操作的泛化能力和效率。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略在动作生成中忽略了几何和控制结构的先验知识，限制了性能和泛化能力。

Method: ADP引入几何流形约束和解析引导初始化，优化扩散过程，无需重新训练。

Result: 在RLBench、CALVIN和真实数据集上，ADP（ADPro）提升了成功率、泛化能力和采样效率，执行速度提升25%，成功率提高9%。

Conclusion: ADP通过引入几何和初始化约束，显著提升了扩散策略的性能和适应性。

Abstract: Diffusion policies have recently emerged as a powerful class of visuomotor
controllers for robot manipulation, offering stable training and expressive
multi-modal action modeling. However, existing approaches typically treat
action generation as an unconstrained denoising process, ignoring valuable a
priori knowledge about geometry and control structure. In this work, we propose
the Adaptive Diffusion Policy (ADP), a test-time adaptation method that
introduces two key inductive biases into the diffusion. First, we embed a
geometric manifold constraint that aligns denoising updates with task-relevant
subspaces, leveraging the fact that the relative pose between the end-effector
and target scene provides a natural gradient direction, and guiding denoising
along the geodesic path of the manipulation manifold. Then, to reduce
unnecessary exploration and accelerate convergence, we propose an analytically
guided initialization: rather than sampling from an uninformative prior, we
compute a rough registration between the gripper and target scenes to propose a
structured initial noisy action. ADP is compatible with pre-trained diffusion
policies and requires no retraining, enabling test-time adaptation that tailors
the policy to specific tasks, thereby enhancing generalization across novel
tasks and environments. Experiments on RLBench, CALVIN, and real-world dataset
show that ADPro, an implementation of ADP, improves success rates,
generalization, and sampling efficiency, achieving up to 25% faster execution
and 9% points over strong diffusion baselines.

</details>


### [44] [EcBot: Data-Driven Energy Consumption Open-Source MATLAB Library for Manipulators](https://arxiv.org/abs/2508.06276)
*Juan Heredia,Christian Schlette,Mikkel Baun Kjærgaard*

Main category: cs.RO

TL;DR: 提出了一种基于Matlab的开源库，用于自动生成机械臂的能耗模型，解决了现有模型主要针对传统工业机器人且精度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有机械臂能耗模型多针对传统工业机器人且精度不足，需更普适且准确的解决方案。

Method: 利用Denavit-Hartenberg参数、连杆质量、质心位置等输入，结合数据驱动方法（需实际运行数据），开发开源Matlab库。

Result: 在四种轻量级机器人上验证，训练集RMSE为1.42-2.80 W，测试集为1.45-5.25 W。

Conclusion: 该方法有效提升了机械臂能耗模型的普适性和准确性。

Abstract: Existing literature proposes models for estimating the electrical power of
manipulators, yet two primary limitations prevail. First, most models are
predominantly tested using traditional industrial robots. Second, these models
often lack accuracy. To address these issues, we introduce an open source
Matlab-based library designed to automatically generate \ac{ec} models for
manipulators. The necessary inputs for the library are Denavit-Hartenberg
parameters, link masses, and centers of mass. Additionally, our model is
data-driven and requires real operational data, including joint positions,
velocities, accelerations, electrical power, and corresponding timestamps. We
validated our methodology by testing on four lightweight robots sourced from
three distinct manufacturers: Universal Robots, Franka Emika, and Kinova. The
model underwent testing, and the results demonstrated an RMSE ranging from 1.42
W to 2.80 W for the training dataset and from 1.45 W to 5.25 W for the testing
dataset.

</details>


### [45] [Mitigating Undesired Conditions in Flexible Production with Product-Process-Resource Asset Knowledge Graphs](https://arxiv.org/abs/2508.06278)
*Petr Novak,Stefan Biffl,Marek Obitko,Petr Kadera*

Main category: cs.RO

TL;DR: 提出了一种基于语义模型PPR-AKG的方法，用于分析和缓解工业4.0中柔性CPPS的不良条件，结合LLM提供自然语言交互。


<details>
  <summary>Details</summary>
Motivation: 工业4.0的灵活性导致传统质量保证机制失效，需要新的方法来分析和处理不良条件。

Method: 基于PPR模型构建PPR-AKG语义模型，结合OWL本体和LLM技术，提供自然语言接口。

Result: 在电动汽车电池再制造案例中，PPR-AKG有效支持资源分配和不良条件的识别与缓解。

Conclusion: PPR-AKG模型及其与LLM的结合为柔性CPPS提供了高效的知识表示和交互方式。

Abstract: Contemporary industrial cyber-physical production systems (CPPS) composed of
robotic workcells face significant challenges in the analysis of undesired
conditions due to the flexibility of Industry 4.0 that disrupts traditional
quality assurance mechanisms. This paper presents a novel industry-oriented
semantic model called Product-Process-Resource Asset Knowledge Graph (PPR-AKG),
which is designed to analyze and mitigate undesired conditions in flexible
CPPS. Built on top of the well-proven Product-Process-Resource (PPR) model
originating from ISA-95 and VDI-3682, a comprehensive OWL ontology addresses
shortcomings of conventional model-driven engineering for CPPS, particularly
inadequate undesired condition and error handling representation. The
integration of semantic technologies with large language models (LLMs) provides
intuitive interfaces for factory operators, production planners, and engineers
to interact with the entire model using natural language. Evaluation with the
use case addressing electric vehicle battery remanufacturing demonstrates that
the PPR-AKG approach efficiently supports resource allocation based on
explicitly represented capabilities as well as identification and mitigation of
undesired conditions in production. The key contributions include (1) a
holistic PPR-AKG model capturing multi-dimensional production knowledge, and
(2) the useful combination of the PPR-AKG with LLM-based chatbots for human
interaction.

</details>


### [46] [Situationally-aware Path Planning Exploiting 3D Scene Graphs](https://arxiv.org/abs/2508.06283)
*Saad Ejaz,Marco Giberna,Muhammad Shaheer,Jose Andres Millan-Romera,Ali Tourani,Paul Kremer,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: S-Path利用3D场景图的语义结构提升路径规划效率，通过两阶段规划和子问题分解实现高效且可解释的路径规划。


<details>
  <summary>Details</summary>
Motivation: 3D场景图的语义结构未被充分利用以提升路径规划的效率和可解释性。

Method: S-Path采用两阶段规划：先在语义图上搜索高层路径，再分解为并行子问题，并引入重规划机制优化效率。

Result: 实验显示S-Path平均减少5.7倍规划时间，路径最优性与传统方法相当，复杂场景表现更优。

Conclusion: S-Path是高效且可解释的路径规划方法，适用于室内3D场景图环境。

Abstract: 3D Scene Graphs integrate both metric and semantic information, yet their
structure remains underutilized for improving path planning efficiency and
interpretability. In this work, we present S-Path, a situationally-aware path
planner that leverages the metric-semantic structure of indoor 3D Scene Graphs
to significantly enhance planning efficiency. S-Path follows a two-stage
process: it first performs a search over a semantic graph derived from the
scene graph to yield a human-understandable high-level path. This also
identifies relevant regions for planning, which later allows the decomposition
of the problem into smaller, independent subproblems that can be solved in
parallel. We also introduce a replanning mechanism that, in the event of an
infeasible path, reuses information from previously solved subproblems to
update semantic heuristics and prioritize reuse to further improve the
efficiency of future planning attempts. Extensive experiments on both
real-world and simulated environments show that S-Path achieves average
reductions of 5.7x in planning time while maintaining comparable path
optimality to classical sampling-based planners and surpassing them in complex
scenarios, making it an efficient and interpretable path planner for
environments represented by indoor 3D Scene Graphs.

</details>


### [47] [Real-Time 3D Vision-Language Embedding Mapping](https://arxiv.org/abs/2508.06291)
*Christian Rauch,Björn Ellensohn,Linus Nwankwo,Vedant Dave,Elmar Rueckert*

Main category: cs.RO

TL;DR: 提出了一种将2D视觉语言模型嵌入到实时、高精度的3D表示中的方法，结合局部嵌入掩码策略和置信度加权3D集成，实现了任务无关的语义3D表示。


<details>
  <summary>Details</summary>
Motivation: 为机器人任务提供高精度的语义3D表示，支持自然语言交互。

Method: 采用局部嵌入掩码策略和置信度加权3D集成，优化嵌入分布和3D表示。

Result: 在真实场景中验证了方法的有效性，提升了目标定位精度和实时性能。

Conclusion: 该方法适用于多种交互式机器人任务，仅需原始图像数据。

Abstract: A metric-accurate semantic 3D representation is essential for many robotic
tasks. This work proposes a simple, yet powerful, way to integrate the 2D
embeddings of a Vision-Language Model in a metric-accurate 3D representation at
real-time. We combine a local embedding masking strategy, for a more distinct
embedding distribution, with a confidence-weighted 3D integration for more
reliable 3D embeddings. The resulting metric-accurate embedding representation
is task-agnostic and can represent semantic concepts on a global multi-room, as
well as on a local object-level. This enables a variety of interactive robotic
applications that require the localisation of objects-of-interest via natural
language. We evaluate our approach on a variety of real-world sequences and
demonstrate that these strategies achieve a more accurate object-of-interest
localisation while improving the runtime performance in order to meet our
real-time constraints. We further demonstrate the versatility of our approach
in a variety of interactive handheld, mobile robotics and manipulation tasks,
requiring only raw image data.

</details>


### [48] [Evaluating Robot Program Performance with Power Consumption Driven Metrics in Lightweight Industrial Robots](https://arxiv.org/abs/2508.06295)
*Juan Heredia,Emil Stubbe Kolvig-Raun,Sune Lundo Sorensen,Mikkel Baun Kjaergaard*

Main category: cs.RO

TL;DR: 提出了一种基于机器人电力能耗的新型框架，从体现视角评估机器人程序性能，替代传统CPU指标。


<details>
  <summary>Details</summary>
Motivation: 传统CPU指标忽视了代码对机器人物理行为的影响，需从能耗角度更全面评估性能。

Method: 采用归一化指标（能量利用系数、能量转换指标、可靠性系数）和机器人磨损指标，分析任务执行中的能耗效率与可靠性。

Result: 通过UR5e机器人实验案例，比较四种程序策略，揭示各策略优缺点，为优化编程提供依据。

Conclusion: 基于能耗的体现视角方法提升了机器人性能，支持可持续制造和成本降低等工业目标。

Abstract: The code performance of industrial robots is typically analyzed through CPU
metrics, which overlook the physical impact of code on robot behavior. This
study introduces a novel framework for assessing robot program performance from
an embodiment perspective by analyzing the robot's electrical power profile.
Our approach diverges from conventional CPU based evaluations and instead
leverages a suite of normalized metrics, namely, the energy utilization
coefficient, the energy conversion metric, and the reliability coefficient, to
capture how efficiently and reliably energy is used during task execution.
Complementing these metrics, the established robot wear metric provides further
insight into long term reliability. Our approach is demonstrated through an
experimental case study in machine tending, comparing four programs with
diverse strategies using a UR5e robot. The proposed metrics directly compare
and categorize different robot programs, regardless of the specific task, by
linking code performance to its physical manifestation through power
consumption patterns. Our results reveal the strengths and weaknesses of each
strategy, offering actionable insights for optimizing robot programming
practices. Enhancing energy efficiency and reliability through this embodiment
centric approach not only improves individual robot performance but also
supports broader industrial objectives such as sustainable manufacturing and
cost reduction.

</details>


### [49] [Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators](https://arxiv.org/abs/2508.06313)
*Amir Hossein Barjini,Mohammad Bahari,Mahdi Hejrati,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文提出了一种用于全电动重型机械臂的统一系统级建模与控制框架，结合了增强的代理模型和自适应虚拟分解控制（VDC）架构，实现了高精度的实时控制。


<details>
  <summary>Details</summary>
Motivation: 开发一种模块化、实时控制的全电动重型机械臂（HDRM），以支持下一代移动工作机器的部署。

Method: 采用代理增强的电动线性执行器（EMLA）模型，结合神经网络训练和扩展的VDC架构，并引入自然适应律。通过Lyapunov稳定性证明，实现分层控制结构。

Result: 在多域仿真和实验验证中，控制器实现了亚厘米级的笛卡尔跟踪精度。

Conclusion: 代理增强的EMLA模型与VDC方法结合，能够实现全电动HDRM的模块化实时控制，适用于未来移动工作机器。

Abstract: This paper presents a unified system-level modeling and control framework for
an all-electric heavy-duty robotic manipulator (HDRM) driven by
electromechanical linear actuators (EMLAs). A surrogate-enhanced actuator
model, combining integrated electromechanical dynamics with a neural network
trained on a dedicated testbed, is integrated into an extended virtual
decomposition control (VDC) architecture augmented by a natural adaptation law.
The derived analytical HDRM model supports a hierarchical control structure
that seamlessly maps high-level force and velocity objectives to real-time
actuator commands, accompanied by a Lyapunov-based stability proof. In
multi-domain simulations of both cubic and a custom planar triangular
trajectory, the proposed adaptive modular controller achieves sub-centimeter
Cartesian tracking accuracy. Experimental validation of the same 1-DoF platform
under realistic load emulation confirms the efficacy of the proposed control
strategy. These findings demonstrate that a surrogate-enhanced EMLA model
embedded in the VDC approach can enable modular, real-time control of an
all-electric HDRM, supporting its deployment in next-generation mobile working
machines.

</details>


### [50] [Towards Balanced Behavior Cloning from Imbalanced Datasets](https://arxiv.org/abs/2508.06319)
*Sagar Parekh,Heramb Nemlekar,Dylan P. Losey*

Main category: cs.RO

TL;DR: 论文提出了一种解决模仿学习中数据不平衡问题的方法，通过重新加权数据集中的状态-动作对，提升策略性能。


<details>
  <summary>Details</summary>
Motivation: 人类演示的数据集通常不平衡，导致现有模仿学习方法过度关注高频子任务，忽略低频但重要的行为。

Method: 分析数据不平衡对策略的影响，提出多种自动重新加权数据集的算法，并引入一种新的元梯度重新平衡算法。

Result: 实验证明，重新平衡数据集能显著提升模仿学习算法的性能，无需额外数据收集。

Conclusion: 数据重新平衡是解决模仿学习数据不平衡问题的有效方法，新算法克服了现有方法的局限性。

Abstract: Robots should be able to learn complex behaviors from human demonstrations.
In practice, these human-provided datasets are inevitably imbalanced: i.e., the
human demonstrates some subtasks more frequently than others. State-of-the-art
methods default to treating each element of the human's dataset as equally
important. So if -- for instance -- the majority of the human's data focuses on
reaching a goal, and only a few state-action pairs move to avoid an obstacle,
the learning algorithm will place greater emphasis on goal reaching. More
generally, misalignment between the relative amounts of data and the importance
of that data causes fundamental problems for imitation learning approaches. In
this paper we analyze and develop learning methods that automatically account
for mixed datasets. We formally prove that imbalanced data leads to imbalanced
policies when each state-action pair is weighted equally; these policies
emulate the most represented behaviors, and not the human's complex, multi-task
demonstrations. We next explore algorithms that rebalance offline datasets
(i.e., reweight the importance of different state-action pairs) without human
oversight. Reweighting the dataset can enhance the overall policy performance.
However, there is no free lunch: each method for autonomously rebalancing
brings its own pros and cons. We formulate these advantages and disadvantages,
helping other researchers identify when each type of approach is most
appropriate. We conclude by introducing a novel meta-gradient rebalancing
algorithm that addresses the primary limitations behind existing approaches.
Our experiments show that dataset rebalancing leads to better downstream
learning, improving the performance of general imitation learning algorithms
without requiring additional data collection. See our project website:
https://collab.me.vt.edu/data_curation/.

</details>


### [51] [L2Calib: $SE(3)$-Manifold Reinforcement Learning for Robust Extrinsic Calibration with Degenerate Motion Resilience](https://arxiv.org/abs/2508.06330)
*Baorun Li,Chengrui Zhu,Siyi Du,Bingran Chen,Jie Ren,Wenfei Wang,Yong Liu,Jiajun Lv*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的外参标定框架，通过决策问题直接优化SE(3)外参，提升里程计精度，无需结构化目标或高质量初始外参。


<details>
  <summary>Details</summary>
Motivation: 现有外参标定方法依赖结构化目标或完全激励数据，限制了实际应用；在线标定因弱激励导致估计不可靠。

Method: 将外参标定建模为决策问题，利用Bingham分布建模3D旋转，引入轨迹对齐奖励机制和自动数据选择模块。

Result: 在无人机、无人车和手持设备上的实验表明，该方法优于传统优化方法，在弱激励条件下仍能实现高精度标定。

Conclusion: 该框架简化了多样机器人平台的部署，支持从常规操作数据中实现标定，代码已开源。

Abstract: Extrinsic calibration is essential for multi-sensor fusion, existing methods
rely on structured targets or fully-excited data, limiting real-world
applicability. Online calibration further suffers from weak excitation, leading
to unreliable estimates. To address these limitations, we propose a
reinforcement learning (RL)-based extrinsic calibration framework that
formulates extrinsic calibration as a decision-making problem, directly
optimizes $SE(3)$ extrinsics to enhance odometry accuracy. Our approach
leverages a probabilistic Bingham distribution to model 3D rotations, ensuring
stable optimization while inherently retaining quaternion symmetry. A
trajectory alignment reward mechanism enables robust calibration without
structured targets by quantitatively evaluating estimated tightly-coupled
trajectory against a reference trajectory. Additionally, an automated data
selection module filters uninformative samples, significantly improving
efficiency and scalability for large-scale datasets. Extensive experiments on
UAVs, UGVs, and handheld platforms demonstrate that our method outperforms
traditional optimization-based approaches, achieving high-precision calibration
even under weak excitation conditions. Our framework simplifies deployment on
diverse robotic platforms by eliminating the need for high-quality initial
extrinsics and enabling calibration from routine operating data. The code is
available at https://github.com/APRIL-ZJU/learn-to-calibrate.

</details>


### [52] [V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles](https://arxiv.org/abs/2508.06404)
*Abdullah Zareh Andaryan,Michael G. H. Bell,Mohsen Ramezani,Glenn Geers*

Main category: cs.RO

TL;DR: V*是一种基于图的运动规划器，通过将速度和方向作为显式状态变量整合到时空速度网格中，直接生成动态可行的轨迹，避免了传统方法的解耦和后处理平滑。


<details>
  <summary>Details</summary>
Motivation: 在结构化环境中，自动驾驶车辆需要能够生成时间最优、无碰撞且满足动态和运动学约束的轨迹。传统方法通常解耦空间搜索和动态可行性，或依赖后处理平滑，导致效率低下或轨迹不可行。

Method: V*采用六边形离散化策略，动态生成图结构，结合数学建模的转向动力学和几何剪枝策略，确保轨迹的动态可行性。

Result: 仿真研究表明，V*能够在复杂动态环境中生成安全、高效的轨迹，具备时间推理能力，如等待行为和动态协调。

Conclusion: V*通过直接整合动态和运动学约束，显著提升了轨迹规划的效率和可行性，适用于复杂动态环境。

Abstract: Autonomous vehicle navigation in structured environments requires planners
capable of generating time-optimal, collision-free trajectories that satisfy
dynamic and kinematic constraints. We introduce V*, a graph-based motion
planner that represents speed and direction as explicit state variables within
a discretised space-time-velocity lattice. Unlike traditional methods that
decouple spatial search from dynamic feasibility or rely on post-hoc smoothing,
V* integrates both motion dimensions directly into graph construction through
dynamic graph generation during search expansion. To manage the complexity of
high-dimensional search, we employ a hexagonal discretisation strategy and
provide formal mathematical proofs establishing optimal waypoint spacing and
minimal node redundancy under constrained heading transitions for
velocity-aware motion planning. We develop a mathematical formulation for
transient steering dynamics in the kinematic bicycle model, modelling steering
angle convergence with exponential behaviour, and deriving the relationship for
convergence rate parameters. This theoretical foundation, combined with
geometric pruning strategies that eliminate expansions leading to infeasible
steering configurations, enables V* to evaluate dynamically admissible
manoeuvres, ensuring each trajectory is physically realisable without further
refinement. We further demonstrate V*'s performance in simulation studies with
cluttered and dynamic environments involving moving obstacles, showing its
ability to avoid conflicts, yield proactively, and generate safe, efficient
trajectories with temporal reasoning capabilities for waiting behaviours and
dynamic coordination.

</details>


### [53] [Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation](https://arxiv.org/abs/2508.06426)
*Youguang Xing,Xu Luo,Junlin Xie,Lianli Gao,Hengtao Shen,Jingkuan Song*

Main category: cs.RO

TL;DR: 论文探讨了通用机器人策略在训练数据分布外泛化能力不足的原因，发现‘捷径学习’是主要障碍，并提出数据集收集和增强策略以改善泛化能力。


<details>
  <summary>Details</summary>
Motivation: 通用机器人策略在大规模数据集（如OXE）上训练表现良好，但在数据分布外泛化能力有限，研究旨在找出原因并提出解决方案。

Method: 通过理论和实证分析，识别了导致捷径学习的两个主要因素：子数据集内多样性不足和子数据集间分布差异大。

Result: 发现数据集结构和收集方式是泛化能力受限的关键，并提出数据增强策略可有效减少捷径学习。

Conclusion: 优化数据集收集策略和采用数据增强技术可提升通用机器人策略的泛化能力，尤其在无法获取新数据时。

Abstract: Generalist robot policies trained on large-scale datasets such as Open
X-Embodiment (OXE) demonstrate strong performance across a wide range of tasks.
However, they often struggle to generalize beyond the distribution of their
training data. In this paper, we investigate the underlying cause of this
limited generalization capability. We identify shortcut learning -- the
reliance on task-irrelevant features -- as a key impediment to generalization.
Through comprehensive theoretical and empirical analysis, we uncover two
primary contributors to shortcut learning: (1) limited diversity within
individual sub-datasets, and (2) significant distributional disparities across
sub-datasets, leading to dataset fragmentation. These issues arise from the
inherent structure of large-scale datasets like OXE, which are typically
composed of multiple sub-datasets collected independently across varied
environments and embodiments. Our findings provide critical insights into
dataset collection strategies that can reduce shortcut learning and enhance the
generalization ability of generalist robot policies. Moreover, in scenarios
where acquiring new large-scale data is impractical, we demonstrate that
carefully selected robotic data augmentation strategies can effectively reduce
shortcut learning in existing offline datasets, thereby improving
generalization capabilities of generalist robot policies, e.g., $\pi_0$, in
both simulation and real-world environments. More information at
https://lucky-light-sun.github.io/proj/shortcut-learning-in-grps/.

</details>
