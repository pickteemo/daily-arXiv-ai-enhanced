{"id": "2508.14214", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14214", "abs": "https://arxiv.org/abs/2508.14214", "authors": ["Mattson Ogg", "Chace Ashcraft", "Ritwik Bose", "Raphael Norman-Tenazas", "Michael Wolmetz"], "title": "Large Language Models are Highly Aligned with Human Ratings of Emotional Stimuli", "comment": null, "summary": "Emotions exert an immense influence over human behavior and cognition in both\ncommonplace and high-stress tasks. Discussions of whether or how to integrate\nlarge language models (LLMs) into everyday life (e.g., acting as proxies for,\nor interacting with, human agents), should be informed by an understanding of\nhow these tools evaluate emotionally loaded stimuli or situations. A model's\nalignment with human behavior in these cases can inform the effectiveness of\nLLMs for certain roles or interactions. To help build this understanding, we\nelicited ratings from multiple popular LLMs for datasets of words and images\nthat were previously rated for their emotional content by humans. We found that\nwhen performing the same rating tasks, GPT-4o responded very similarly to human\nparticipants across modalities, stimuli and most rating scales (r = 0.9 or\nhigher in many cases). However, arousal ratings were less well aligned between\nhuman and LLM raters, while happiness ratings were most highly aligned. Overall\nLLMs aligned better within a five-category (happiness, anger, sadness, fear,\ndisgust) emotion framework than within a two-dimensional (arousal and valence)\norganization. Finally, LLM ratings were substantially more homogenous than\nhuman ratings. Together these results begin to describe how LLM agents\ninterpret emotional stimuli and highlight similarities and differences among\nbiological and artificial intelligence in key behavioral domains.", "AI": {"tldr": "GPT-4o\u5728\u60c5\u611f\u8bc4\u5206\u4efb\u52a1\u4e2d\u4e0e\u4eba\u7c7b\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u4f46\u5728\u5524\u9192\u5ea6\u8bc4\u5206\u4e0a\u5dee\u5f02\u8f83\u5927\uff0c\u5e78\u798f\u5ea6\u8bc4\u5206\u6700\u4e00\u81f4\u3002LLM\u8bc4\u5206\u6bd4\u4eba\u7c7b\u66f4\u540c\u8d28\u5316\uff0c\u5728\u4e94\u7c7b\u60c5\u611f\u6846\u67b6\u4e2d\u6bd4\u4e8c\u7ef4\u60c5\u611f\u7ef4\u5ea6\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u4e86\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u8bc4\u4f30\u60c5\u611f\u523a\u6fc0\uff0c\u4e3aLLM\u5728\u65e5\u5e38\u751f\u6d3b\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u53c2\u8003\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u60c5\u611f\u8ba4\u77e5\u65b9\u9762\u4e0e\u4eba\u7c7b\u884c\u4e3a\u7684\u5bf9\u9f50\u7a0b\u5ea6\u3002", "method": "\u4f7f\u7528\u4eba\u7c7b\u5148\u524d\u8bc4\u5b9a\u7684\u60c5\u611f\u8bcd\u6c47\u548c\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u8ba9\u591a\u4e2a\u6d41\u884cLLM\u8fdb\u884c\u76f8\u540c\u8bc4\u5206\u4efb\u52a1\uff0c\u6bd4\u8f83GPT-4o\u7b49\u6a21\u578b\u4e0e\u4eba\u7c7b\u53c2\u4e0e\u8005\u7684\u8bc4\u5206\u4e00\u81f4\u6027\u3002", "result": "GPT-4o\u5728\u5927\u591a\u6570\u8bc4\u5206\u7ef4\u5ea6\u4e0a\u4e0e\u4eba\u7c7b\u9ad8\u5ea6\u76f8\u5173\uff08r\u22650.9\uff09\uff0c\u4f46\u5524\u9192\u5ea6\u8bc4\u5206\u4e00\u81f4\u6027\u8f83\u5dee\uff0c\u5e78\u798f\u5ea6\u8bc4\u5206\u6700\u4e00\u81f4\u3002LLM\u5728\u4e94\u7c7b\u60c5\u611f\u6846\u67b6\u4e2d\u6bd4\u4e8c\u7ef4\u60c5\u611f\u7ef4\u5ea6\u8868\u73b0\u66f4\u597d\uff0c\u4e14\u8bc4\u5206\u6bd4\u4eba\u7c7b\u66f4\u540c\u8d28\u5316\u3002", "conclusion": "LLM\u5728\u60c5\u611f\u523a\u6fc0\u89e3\u91ca\u65b9\u9762\u663e\u793a\u51fa\u4e0e\u4eba\u7c7b\u667a\u80fd\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\uff0c\u4e3aLLM\u5728\u60c5\u611f\u76f8\u5173\u89d2\u8272\u4e2d\u7684\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u4f46\u9700\u8981\u6ce8\u610f\u8bc4\u5206\u540c\u8d28\u5316\u548c\u7279\u5b9a\u60c5\u611f\u7ef4\u5ea6\u5dee\u5f02\u7684\u95ee\u9898\u3002"}}
{"id": "2508.14294", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14294", "abs": "https://arxiv.org/abs/2508.14294", "authors": ["Maria Leonor Pacheco", "Fabio Somenzi", "Dananjay Srinivas", "Ashutosh Trivedi"], "title": "Explaining Hitori Puzzles: Neurosymbolic Proof Staging for Sequential Decisions", "comment": null, "summary": "We propose a neurosymbolic approach to the explanation of complex sequences\nof decisions that combines the strengths of decision procedures and Large\nLanguage Models (LLMs). We demonstrate this approach by producing explanations\nfor the solutions of Hitori puzzles. The rules of Hitori include local\nconstraints that are effectively explained by short resolution proofs. However,\nthey also include a connectivity constraint that is more suitable for visual\nexplanations. Hence, Hitori provides an excellent testing ground for a flexible\ncombination of SAT solvers and LLMs. We have implemented a tool that assists\nhumans in solving Hitori puzzles, and we present experimental evidence of its\neffectiveness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u51b3\u7b56\u7a0b\u5e8f\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u91ca\u590d\u6742\u51b3\u7b56\u5e8f\u5217\uff0c\u5e76\u4ee5Hitori\u6570\u72ec\u8c1c\u9898\u4e3a\u4f8b\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027", "motivation": "Hitori\u8c1c\u9898\u5305\u542b\u5c40\u90e8\u7ea6\u675f\u548c\u8fde\u901a\u6027\u7ea6\u675f\uff0c\u524d\u8005\u9002\u5408\u7528\u7b80\u77ed\u89e3\u6790\u8bc1\u660e\u89e3\u91ca\uff0c\u540e\u8005\u66f4\u9002\u5408\u89c6\u89c9\u89e3\u91ca\uff0c\u8fd9\u4e3aSAT\u6c42\u89e3\u5668\u548cLLM\u7684\u7075\u6d3b\u7ec4\u5408\u63d0\u4f9b\u4e86\u7406\u60f3\u7684\u6d4b\u8bd5\u5e73\u53f0", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408SAT\u6c42\u89e3\u5668\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u5177\uff0cSAT\u6c42\u89e3\u5668\u5904\u7406\u5c40\u90e8\u7ea6\u675f\u7684\u89e3\u6790\u8bc1\u660e\uff0cLLM\u751f\u6210\u8fde\u901a\u6027\u7ea6\u675f\u7684\u89c6\u89c9\u89e3\u91ca", "result": "\u5b9e\u73b0\u4e86\u8f85\u52a9\u4eba\u7c7b\u89e3\u51b3Hitori\u8c1c\u9898\u7684\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027", "conclusion": "\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u6210\u529f\u7ed3\u5408\u4e86\u51b3\u7b56\u7a0b\u5e8f\u548cLLM\u7684\u4f18\u52bf\uff0c\u4e3a\u590d\u6742\u51b3\u7b56\u5e8f\u5217\u7684\u89e3\u91ca\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2508.14410", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14410", "abs": "https://arxiv.org/abs/2508.14410", "authors": ["Beinuo Yang", "Qishen Zhou", "Junyi Li", "Xingchen Su", "Simon Hu"], "title": "Automated Optimization Modeling through Expert-Guided Large Language Model Reasoning", "comment": null, "summary": "Optimization Modeling (OM) is essential for solving complex decision-making\nproblems. However, the process remains time-consuming and error-prone, heavily\nrelying on domain experts. While Large Language Models (LLMs) show promise in\naddressing these challenges through their natural language understanding and\nreasoning capabilities, current approaches face three critical limitations:\nhigh benchmark labeling error rates reaching up to 42\\%, narrow evaluation\nscope that only considers optimal values, and computational inefficiency due to\nheavy reliance on multi-agent systems or model fine-tuning. In this work, we\nfirst enhance existing datasets through systematic error correction and more\ncomprehensive annotation. Additionally, we introduce LogiOR, a new optimization\nmodeling benchmark from the logistics domain, containing more complex problems\nwith standardized annotations. Furthermore, we present ORThought, a novel\nframework that leverages expert-level optimization modeling principles through\nchain-of-thought reasoning to automate the OM process. Through extensive\nempirical evaluation, we demonstrate that ORThought outperforms existing\napproaches, including multi-agent frameworks, with particularly significant\nadvantages on complex optimization problems. Finally, we provide a systematic\nanalysis of our method, identifying critical success factors and failure modes,\nproviding valuable insights for future research on LLM-based optimization\nmodeling.", "AI": {"tldr": "\u63d0\u51fa\u4e86ORThought\u6846\u67b6\uff0c\u901a\u8fc7\u601d\u7ef4\u94fe\u63a8\u7406\u81ea\u52a8\u5316\u4f18\u5316\u5efa\u6a21\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u65b9\u6cd5\u7684\u9ad8\u9519\u8bef\u7387\u3001\u8bc4\u4f30\u8303\u56f4\u7a84\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5e76\u5728\u590d\u6742\u4f18\u5316\u95ee\u9898\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f18\u5316\u5efa\u6a21\u8fc7\u7a0b\u8017\u65f6\u4e14\u6613\u9519\uff0c\u4e25\u91cd\u4f9d\u8d56\u9886\u57df\u4e13\u5bb6\u3002\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u63a8\u7406\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u57fa\u51c6\u6807\u6ce8\u9519\u8bef\u7387\u9ad8\uff08\u8fbe42%\uff09\u3001\u8bc4\u4f30\u8303\u56f4\u7a84\uff08\u4ec5\u8003\u8651\u6700\u4f18\u503c\uff09\u4ee5\u53ca\u8ba1\u7b97\u6548\u7387\u4f4e\uff08\u4f9d\u8d56\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6216\u6a21\u578b\u5fae\u8c03\uff09\u4e09\u5927\u5c40\u9650\u6027\u3002", "method": "\u9996\u5148\u901a\u8fc7\u7cfb\u7edf\u9519\u8bef\u6821\u6b63\u548c\u66f4\u5168\u9762\u7684\u6807\u6ce8\u589e\u5f3a\u73b0\u6709\u6570\u636e\u96c6\uff1b\u5f15\u5165\u7269\u6d41\u9886\u57df\u7684\u65b0\u4f18\u5316\u5efa\u6a21\u57fa\u51c6LogiOR\uff0c\u5305\u542b\u66f4\u590d\u6742\u7684\u95ee\u9898\u548c\u6807\u51c6\u5316\u6807\u6ce8\uff1b\u63d0\u51faORThought\u6846\u67b6\uff0c\u5229\u7528\u4e13\u5bb6\u7ea7\u4f18\u5316\u5efa\u6a21\u539f\u5219\u901a\u8fc7\u601d\u7ef4\u94fe\u63a8\u7406\u81ea\u52a8\u5316\u4f18\u5316\u5efa\u6a21\u8fc7\u7a0b\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\uff0cORThought\u5728\u590d\u6742\u4f18\u5316\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u4f18\u4e8e\u5305\u62ec\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5728\u5185\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u65b9\u6cd5\u7684\u7cfb\u7edf\u5206\u6790\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u6210\u529f\u56e0\u7d20\u548c\u5931\u8d25\u6a21\u5f0f\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u4f18\u5316\u5efa\u6a21\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2508.14415", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14415", "abs": "https://arxiv.org/abs/2508.14415", "authors": ["Qiang Zhang", "Pei Yan", "Yijia Xu", "Chuanpo Fu", "Yong Fang", "Yang Liu"], "title": "The Agent Behavior: Model, Governance and Challenges in the AI Digital Age", "comment": null, "summary": "Advancements in AI have led to agents in networked environments increasingly\nmirroring human behavior, thereby blurring the boundary between artificial and\nhuman actors in specific contexts. This shift brings about significant\nchallenges in trust, responsibility, ethics, security and etc. The difficulty\nin supervising of agent behaviors may lead to issues such as data contamination\nand unclear accountability. To address these challenges, this paper proposes\nthe \"Network Behavior Lifecycle\" model, which divides network behavior into 6\nstages and systematically analyzes the behavioral differences between humans\nand agents at each stage. Based on these insights, the paper further introduces\nthe \"Agent for Agent (A4A)\" paradigm and the \"Human-Agent Behavioral Disparity\n(HABD)\" model, which examine the fundamental distinctions between human and\nagent behaviors across 5 dimensions: decision mechanism, execution efficiency,\nintention-behavior consistency, behavioral inertia, and irrational patterns.\nThe effectiveness of the model is verified through real-world cases such as red\nteam penetration and blue team defense. Finally, the paper discusses future\nresearch directions in dynamic cognitive governance architecture, behavioral\ndisparity quantification, and meta-governance protocol stacks, aiming to\nprovide a theoretical foundation and technical roadmap for secure and\ntrustworthy human-agent collaboration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7f51\u7edc\u884c\u4e3a\u751f\u547d\u5468\u671f\u6a21\u578b\u548cA4A\u8303\u5f0f\uff0c\u901a\u8fc76\u9636\u6bb5\u5206\u6790\u548c5\u7ef4\u5ea6\u5dee\u5f02\u6a21\u578b\u6765\u533a\u5206\u4eba\u7c7b\u4e0eAI\u4ee3\u7406\u884c\u4e3a\uff0c\u89e3\u51b3\u4fe1\u4efb\u3001\u8d23\u4efb\u548c\u5b89\u5168\u6311\u6218\u3002", "motivation": "AI\u4ee3\u7406\u5728\u7f51\u7edc\u73af\u5883\u4e2d\u8d8a\u6765\u8d8a\u50cf\u4eba\u7c7b\u884c\u4e3a\uff0c\u5bfc\u81f4\u4fe1\u4efb\u3001\u8d23\u4efb\u3001\u4f26\u7406\u548c\u5b89\u5168\u7b49\u65b9\u9762\u7684\u76d1\u7ba1\u56f0\u96be\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u533a\u5206\u548c\u76d1\u7763\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u7f51\u7edc\u884c\u4e3a\u751f\u547d\u5468\u671f\u6a21\u578b\uff086\u9636\u6bb5\u5206\u6790\uff09\u3001Agent for Agent\u8303\u5f0f\uff08A4A\uff09\u548c\u4eba\u7c7b-\u4ee3\u7406\u884c\u4e3a\u5dee\u5f02\u6a21\u578b\uff08HABD\uff0c5\u4e2a\u7ef4\u5ea6\uff1a\u51b3\u7b56\u673a\u5236\u3001\u6267\u884c\u6548\u7387\u3001\u610f\u56fe-\u884c\u4e3a\u4e00\u81f4\u6027\u3001\u884c\u4e3a\u60ef\u6027\u548c\u975e\u7406\u6027\u6a21\u5f0f\uff09\u3002", "result": "\u901a\u8fc7\u7ea2\u961f\u6e17\u900f\u548c\u84dd\u961f\u9632\u5fa1\u7b49\u5b9e\u9645\u6848\u4f8b\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u6709\u6548\u533a\u5206\u548c\u76d1\u7763\u4eba\u7c7b\u4e0eAI\u4ee3\u7406\u884c\u4e3a\u3002", "conclusion": "\u4e3a\u5b89\u5168\u53ef\u4fe1\u7684\u4eba\u673a\u534f\u4f5c\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u6280\u672f\u8def\u7ebf\u56fe\uff0c\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u52a8\u6001\u8ba4\u77e5\u6cbb\u7406\u67b6\u6784\u3001\u884c\u4e3a\u5dee\u5f02\u91cf\u5316\u548c\u5143\u6cbb\u7406\u534f\u8bae\u6808\u3002"}}
{"id": "2508.14096", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14096", "abs": "https://arxiv.org/abs/2508.14096", "authors": ["Zhanxi Xie", "Baili Lu", "Yanzhao Gu", "Zikun Li", "Junhao Wei", "Ngai Cheong"], "title": "Research on UAV Applications in Public Administration: Based on an Improved RRT Algorithm", "comment": null, "summary": "This study investigates the application of unmanned aerial vehicles (UAVs) in\npublic management, focusing on optimizing path planning to address challenges\nsuch as energy consumption, obstacle avoidance, and airspace constraints. As\nUAVs transition from 'technical tools' to 'governance infrastructure', driven\nby advancements in low-altitude economy policies and smart city demands,\nefficient path planning becomes critical. The research proposes an enhanced\nRapidly-exploring Random Tree algorithm (dRRT), incorporating four strategies:\nTarget Bias (to accelerate convergence), Dynamic Step Size (to balance\nexploration and obstacle navigation), Detour Priority (to prioritize horizontal\ndetours over vertical ascents), and B-spline smoothing (to enhance path\nsmoothness). Simulations in a 500 m3 urban environment with randomized\nbuildings demonstrate dRRT's superiority over traditional RRT, A*, and Ant\nColony Optimization (ACO). Results show dRRT achieves a 100\\% success rate with\nan average runtime of 0.01468s, shorter path lengths, fewer waypoints, and\nsmoother trajectories (maximum yaw angles <45{\\deg}). Despite improvements,\nlimitations include increased computational overhead from added mechanisms and\npotential local optima due to goal biasing. The study highlights dRRT's\npotential for efficient UAV deployment in public management scenarios like\nemergency response and traffic monitoring, while underscoring the need for\nintegration with real-time obstacle avoidance frameworks. This work contributes\nto interdisciplinary advancements in urban governance, robotics, and\ncomputational optimization.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u6539\u8fdb\u7684dRRT\u7b97\u6cd5\uff0c\u901a\u8fc7\u56db\u79cd\u7b56\u7565\u4f18\u5316\u65e0\u4eba\u673a\u8def\u5f84\u89c4\u5212\uff0c\u5728\u4eff\u771f\u73af\u5883\u4e2d\u76f8\u6bd4\u4f20\u7edf\u7b97\u6cd5\u8868\u73b0\u66f4\u4f18\uff0c\u6210\u529f\u7387\u8fbe100%\uff0c\u8fd0\u884c\u65f6\u95f4\u4ec50.01468\u79d2\uff0c\u8def\u5f84\u66f4\u77ed\u66f4\u5e73\u6ed1\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u4ece'\u6280\u672f\u5de5\u5177'\u5411'\u6cbb\u7406\u57fa\u7840\u8bbe\u65bd'\u8f6c\u578b\uff0c\u4f4e\u7a7a\u7ecf\u6d4e\u653f\u7b56\u548c\u667a\u6167\u57ce\u5e02\u9700\u6c42\u63a8\u52a8\u4e0b\uff0c\u9ad8\u6548\u7684\u8def\u5f84\u89c4\u5212\u5bf9\u516c\u5171\u7ba1\u7406\u5e94\u7528\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u89e3\u51b3\u80fd\u8017\u3001\u907f\u969c\u548c\u7a7a\u57df\u9650\u5236\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u589e\u5f3a\u578b\u5feb\u901f\u63a2\u7d22\u968f\u673a\u6811\u7b97\u6cd5(dRRT)\uff0c\u5305\u542b\u56db\u79cd\u7b56\u7565\uff1a\u76ee\u6807\u504f\u5411\u52a0\u901f\u6536\u655b\u3001\u52a8\u6001\u6b65\u957f\u5e73\u8861\u63a2\u7d22\u4e0e\u907f\u969c\u3001\u7ed5\u884c\u4f18\u5148\u9009\u62e9\u6c34\u5e73\u7ed5\u884c\u800c\u975e\u5782\u76f4\u722c\u5347\u3001B\u6837\u6761\u5e73\u6ed1\u63d0\u5347\u8def\u5f84\u5e73\u6ed1\u5ea6\u3002\u5728500\u7acb\u65b9\u7c73\u57ce\u5e02\u73af\u5883\u8fdb\u884c\u968f\u673a\u5efa\u7b51\u4eff\u771f\u6d4b\u8bd5\u3002", "result": "dRRT\u76f8\u6bd4\u4f20\u7edfRRT\u3001A*\u548c\u8681\u7fa4\u7b97\u6cd5\u8868\u73b0\u66f4\u4f18\uff1a100%\u6210\u529f\u7387\uff0c\u5e73\u5747\u8fd0\u884c\u65f6\u95f40.01468\u79d2\uff0c\u8def\u5f84\u957f\u5ea6\u66f4\u77ed\uff0c\u822a\u70b9\u66f4\u5c11\uff0c\u8f68\u8ff9\u66f4\u5e73\u6ed1\uff08\u6700\u5927\u504f\u822a\u89d2<45\u5ea6\uff09\u3002", "conclusion": "dRRT\u5728\u516c\u5171\u7ba1\u7406\u573a\u666f\u5982\u5e94\u6025\u54cd\u5e94\u548c\u4ea4\u901a\u76d1\u63a7\u4e2d\u5177\u6709\u9ad8\u6548\u90e8\u7f72\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u8ba1\u7b97\u5f00\u9500\u589e\u52a0\u548c\u76ee\u6807\u504f\u5411\u53ef\u80fd\u5bfc\u81f4\u5c40\u90e8\u6700\u4f18\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e0e\u5b9e\u65f6\u907f\u969c\u6846\u67b6\u96c6\u6210\u3002\u8be5\u7814\u7a76\u63a8\u52a8\u4e86\u57ce\u5e02\u6cbb\u7406\u3001\u673a\u5668\u4eba\u548c\u8ba1\u7b97\u4f18\u5316\u7684\u8de8\u5b66\u79d1\u53d1\u5c55\u3002"}}
{"id": "2508.14564", "categories": ["cs.AI", "cs.CL", "cs.HC", "I.2.9; I.2.10; I.2.7; J.4"], "pdf": "https://arxiv.org/pdf/2508.14564", "abs": "https://arxiv.org/abs/2508.14564", "authors": ["Luca Annese", "Sabrina Patania", "Silvia Serino", "Tom Foulsham", "Silvia Rossi", "Azzurra Ruggeri", "Dimitri Ognibene"], "title": "Who Sees What? Structured Thought-Action Sequences for Epistemic Reasoning in LLMs", "comment": "Accepted at ICSR25", "summary": "Recent advances in large language models (LLMs) and reasoning frameworks have\nopened new possibilities for improving the perspective -taking capabilities of\nautonomous agents. However, tasks that involve active perception, collaborative\nreasoning, and perspective taking (understanding what another agent can see or\nknows) pose persistent challenges for current LLM-based systems. This study\ninvestigates the potential of structured examples derived from transformed\nsolution graphs generated by the Fast Downward planner to improve the\nperformance of LLM-based agents within a ReAct framework. We propose a\nstructured solution-processing pipeline that generates three distinct\ncategories of examples: optimal goal paths (G-type), informative node paths\n(E-type), and step-by-step optimal decision sequences contrasting alternative\nactions (L-type). These solutions are further converted into ``thought-action''\nexamples by prompting an LLM to explicitly articulate the reasoning behind each\ndecision. While L-type examples slightly reduce clarification requests and\noverall action steps, they do not yield consistent improvements. Agents are\nsuccessful in tasks requiring basic attentional filtering but struggle in\nscenarios that required mentalising about occluded spaces or weighing the costs\nof epistemic actions. These findings suggest that structured examples alone are\ninsufficient for robust perspective-taking, underscoring the need for explicit\nbelief tracking, cost modelling, and richer environments to enable socially\ngrounded collaboration in LLM-based agents.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u89c4\u5212\u5668\u751f\u6210\u7684\u7ed3\u6784\u5316\u793a\u4f8b\u6765\u63d0\u5347LLM\u667a\u80fd\u4f53\u5728\u89c6\u89d2\u611f\u77e5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u867d\u7136L\u578b\u793a\u4f8b\u80fd\u7565\u5fae\u51cf\u5c11\u6f84\u6e05\u8bf7\u6c42\u548c\u884c\u52a8\u6b65\u9aa4\uff0c\u4f46\u7ed3\u6784\u5316\u793a\u4f8b\u672c\u8eab\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u7a33\u5065\u7684\u89c6\u89d2\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u4e3b\u52a8\u611f\u77e5\u3001\u534f\u4f5c\u63a8\u7406\u548c\u89c6\u89d2\u611f\u77e5\uff08\u7406\u89e3\u5176\u4ed6\u667a\u80fd\u4f53\u80fd\u770b\u5230\u6216\u77e5\u9053\u4ec0\u4e48\uff09\u7684\u4efb\u52a1\u4e2d\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7ed3\u6784\u5316\u793a\u4f8b\u63d0\u5347LLM\u667a\u80fd\u4f53\u7684\u89c6\u89d2\u611f\u77e5\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u89e3\u51b3\u65b9\u6848\u5904\u7406\u6d41\u7a0b\uff0c\u4f7f\u7528Fast Downward\u89c4\u5212\u5668\u751f\u6210\u4e09\u79cd\u7c7b\u578b\u7684\u793a\u4f8b\uff1a\u6700\u4f18\u76ee\u6807\u8def\u5f84(G\u578b)\u3001\u4fe1\u606f\u8282\u70b9\u8def\u5f84(E\u578b)\u548c\u5bf9\u6bd4\u66ff\u4ee3\u884c\u52a8\u7684\u9010\u6b65\u6700\u4f18\u51b3\u7b56\u5e8f\u5217(L\u578b)\uff0c\u5e76\u901a\u8fc7LLM\u5c06\u8fd9\u4e9b\u89e3\u51b3\u65b9\u6848\u8f6c\u6362\u4e3a\"\u601d\u8003-\u884c\u52a8\"\u793a\u4f8b\u3002", "result": "L\u578b\u793a\u4f8b\u80fd\u7565\u5fae\u51cf\u5c11\u6f84\u6e05\u8bf7\u6c42\u548c\u603b\u4f53\u884c\u52a8\u6b65\u9aa4\uff0c\u4f46\u672a\u5e26\u6765\u4e00\u81f4\u6027\u7684\u6539\u8fdb\u3002\u667a\u80fd\u4f53\u5728\u9700\u8981\u57fa\u672c\u6ce8\u610f\u529b\u8fc7\u6ee4\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u6210\u529f\uff0c\u4f46\u5728\u9700\u8981\u5fc3\u7406\u5316\u906e\u6321\u7a7a\u95f4\u6216\u6743\u8861\u8ba4\u77e5\u884c\u52a8\u6210\u672c\u7684\u573a\u666f\u4e2d\u8868\u73b0\u6323\u624e\u3002", "conclusion": "\u7ed3\u6784\u5316\u793a\u4f8b\u672c\u8eab\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u7a33\u5065\u7684\u89c6\u89d2\u611f\u77e5\uff0c\u9700\u8981\u660e\u786e\u7684\u4fe1\u5ff5\u8ffd\u8e2a\u3001\u6210\u672c\u5efa\u6a21\u548c\u66f4\u4e30\u5bcc\u7684\u73af\u5883\u6765\u652f\u6301LLM\u667a\u80fd\u4f53\u7684\u793e\u4f1a\u5316\u534f\u4f5c\u80fd\u529b\u3002"}}
{"id": "2508.14098", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14098", "abs": "https://arxiv.org/abs/2508.14098", "authors": ["Pranay Dugar", "Mohitvishnu S. Gadde", "Jonah Siekmann", "Yesh Godse", "Aayam Shrestha", "Alan Fern"], "title": "No More Marching: Learning Humanoid Locomotion for Short-Range SE(2) Targets", "comment": null, "summary": "Humanoids operating in real-world workspaces must frequently execute\ntask-driven, short-range movements to SE(2) target poses. To be practical,\nthese transitions must be fast, robust, and energy efficient. While\nlearning-based locomotion has made significant progress, most existing methods\noptimize for velocity-tracking rather than direct pose reaching, resulting in\ninefficient, marching-style behavior when applied to short-range tasks. In this\nwork, we develop a reinforcement learning approach that directly optimizes\nhumanoid locomotion for SE(2) targets. Central to this approach is a new\nconstellation-based reward function that encourages natural and efficient\ntarget-oriented movement. To evaluate performance, we introduce a benchmarking\nframework that measures energy consumption, time-to-target, and footstep count\non a distribution of SE(2) goals. Our results show that the proposed approach\nconsistently outperforms standard methods and enables successful transfer from\nsimulation to hardware, highlighting the importance of targeted reward design\nfor practical short-range humanoid locomotion.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4eba\u5f62\u673a\u5668\u4ebaSE(2)\u76ee\u6807\u4f4d\u59ff\u5230\u8fbe\u65b9\u6cd5\uff0c\u901a\u8fc7\u661f\u5ea7\u5f0f\u5956\u52b1\u51fd\u6570\u4f18\u5316\u77ed\u8ddd\u79bb\u8fd0\u52a8\u7684\u80fd\u91cf\u6548\u7387\u548c\u65f6\u95f4\u6548\u7387", "motivation": "\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u4f18\u5316\u901f\u5ea6\u8ddf\u8e2a\u800c\u975e\u76f4\u63a5\u4f4d\u59ff\u5230\u8fbe\uff0c\u5bfc\u81f4\u77ed\u8ddd\u79bb\u4efb\u52a1\u4e2d\u51fa\u73b0\u4f4e\u6548\u7684\u8e0f\u6b65\u5f0f\u884c\u4e3a\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5b9e\u7528\u7684\u4eba\u5f62\u673a\u5668\u4eba\u77ed\u8ddd\u79bb\u8fd0\u52a8\u65b9\u6cd5", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u91c7\u7528\u65b0\u7684\u661f\u5ea7\u5f0f\u5956\u52b1\u51fd\u6570\u6765\u9f13\u52b1\u81ea\u7136\u9ad8\u6548\u7684\u76ee\u6807\u5bfc\u5411\u8fd0\u52a8\uff0c\u5e76\u5efa\u7acb\u4e86\u5305\u542b\u80fd\u8017\u3001\u5230\u8fbe\u65f6\u95f4\u548c\u6b65\u6570\u6307\u6807\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6", "result": "\u8be5\u65b9\u6cd5\u5728SE(2)\u76ee\u6807\u5206\u5e03\u4e0a consistently\u4f18\u4e8e\u6807\u51c6\u65b9\u6cd5\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u4eff\u771f\u5230\u786c\u4ef6\u7684\u8fc1\u79fb\uff0c\u8bc1\u660e\u4e86\u9488\u5bf9\u6027\u5956\u52b1\u8bbe\u8ba1\u7684\u91cd\u8981\u6027", "conclusion": "\u9488\u5bf9\u6027\u7684\u5956\u52b1\u8bbe\u8ba1\u5bf9\u4e8e\u5b9e\u7528\u77ed\u8ddd\u79bb\u4eba\u5f62\u673a\u5668\u4eba\u8fd0\u52a8\u81f3\u5173\u91cd\u8981\uff0c\u8be5\u65b9\u6cd5\u5728\u80fd\u91cf\u6d88\u8017\u3001\u65f6\u95f4\u6548\u7387\u548c\u8fd0\u52a8\u81ea\u7136\u6027\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd"}}
{"id": "2508.14644", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14644", "abs": "https://arxiv.org/abs/2508.14644", "authors": ["Chendong Song", "Zihan Wang", "Frederick Pu", "Haiming Wang", "Xiaohan Lin", "Junqi Liu", "Jia Li", "Zhengying Liu"], "title": "LeanGeo: Formalizing Competitional Geometry problems in Lean", "comment": "28 pages", "summary": "Geometry problems are a crucial testbed for AI reasoning capabilities. Most\nexisting geometry solving systems cannot express problems within a unified\nframework, thus are difficult to integrate with other mathematical fields.\nBesides, since most geometric proofs rely on intuitive diagrams, verifying\ngeometry problems is particularly challenging. To address these gaps, we\nintroduce LeanGeo, a unified formal system for formalizing and solving\ncompetition-level geometry problems within the Lean 4 theorem prover. LeanGeo\nfeatures a comprehensive library of high-level geometric theorems with Lean's\nfoundational logic, enabling rigorous proof verification and seamless\nintegration with Mathlib. We also present LeanGeo-Bench, a formal geometry\nbenchmark in LeanGeo, comprising problems from the International Mathematical\nOlympiad (IMO) and other advanced sources. Our evaluation demonstrates the\ncapabilities and limitations of state-of-the-art Large Language Models on this\nbenchmark, highlighting the need for further advancements in automated\ngeometric reasoning. We open source the theorem library and the benchmark of\nLeanGeo at https://github.com/project-numina/LeanGeo/tree/master.", "AI": {"tldr": "LeanGeo\u662f\u4e00\u4e2a\u57fa\u4e8eLean 4\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u7edf\u4e00\u51e0\u4f55\u95ee\u9898\u5f62\u5f0f\u5316\u7cfb\u7edf\uff0c\u5305\u542b\u9ad8\u7ea7\u51e0\u4f55\u5b9a\u7406\u5e93\u548c\u51e0\u4f55\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51e0\u4f55\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u51e0\u4f55\u6c42\u89e3\u7cfb\u7edf\u96be\u4ee5\u7edf\u4e00\u8868\u8fbe\u51e0\u4f55\u95ee\u9898\uff0c\u4e14\u7531\u4e8e\u51e0\u4f55\u8bc1\u660e\u4f9d\u8d56\u76f4\u89c2\u56fe\u8868\uff0c\u9a8c\u8bc1\u51e0\u4f55\u95ee\u9898\u7279\u522b\u56f0\u96be\u3002\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u7684\u5f62\u5f0f\u5316\u6846\u67b6\u6765\u6574\u5408\u51e0\u4f55\u4e0e\u5176\u4ed6\u6570\u5b66\u9886\u57df\u3002", "method": "\u5728Lean 4\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u6784\u5efaLeanGeo\u7cfb\u7edf\uff0c\u5305\u542b\u5168\u9762\u7684\u9ad8\u7ea7\u51e0\u4f55\u5b9a\u7406\u5e93\uff0c\u4e0eMathlib\u65e0\u7f1d\u96c6\u6210\uff0c\u5e76\u521b\u5efaLeanGeo-Bench\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff08\u5305\u542bIMO\u7b49\u9ad8\u7ea7\u51e0\u4f55\u95ee\u9898\uff09\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5b58\u5728\u80fd\u529b\u548c\u5c40\u9650\u6027\uff0c\u51f8\u663e\u4e86\u81ea\u52a8\u51e0\u4f55\u63a8\u7406\u9886\u57df\u9700\u8981\u8fdb\u4e00\u6b65\u53d1\u5c55\u7684\u9700\u6c42\u3002", "conclusion": "LeanGeo\u4e3a\u51e0\u4f55\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u548c\u6c42\u89e3\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u5f00\u6e90\u4e86\u5b9a\u7406\u5e93\u548c\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u4e3a\u51e0\u4f55\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u548c\u8bc4\u4f30\u6807\u51c6\u3002"}}
{"id": "2508.14099", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14099", "abs": "https://arxiv.org/abs/2508.14099", "authors": ["Michal Ciebielski", "Victor Dh\u00e9din", "Majid Khadiv"], "title": "Task and Motion Planning for Humanoid Loco-manipulation", "comment": null, "summary": "This work presents an optimization-based task and motion planning (TAMP)\nframework that unifies planning for locomotion and manipulation through a\nshared representation of contact modes. We define symbolic actions as contact\nmode changes, grounding high-level planning in low-level motion. This enables a\nunified search that spans task, contact, and motion planning while\nincorporating whole-body dynamics, as well as all constraints between the\nrobot, the manipulated object, and the environment. Results on a humanoid\nplatform show that our method can generate a broad range of physically\nconsistent loco-manipulation behaviors over long action sequences requiring\ncomplex reasoning. To the best of our knowledge, this is the first work that\nenables the resolution of an integrated TAMP formulation with fully acyclic\nplanning and whole body dynamics with actuation constraints for the humanoid\nloco-manipulation problem.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4f18\u5316\u7684\u4efb\u52a1\u4e0e\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u63a5\u89e6\u6a21\u5f0f\u8868\u793a\u7edf\u4e00\u5904\u7406\u79fb\u52a8\u548c\u64cd\u4f5c\u89c4\u5212\uff0c\u5b9e\u73b0\u7b26\u53f7\u52a8\u4f5c\u4e0e\u63a5\u89e6\u6a21\u5f0f\u53d8\u5316\u5173\u8054\uff0c\u652f\u6301\u5305\u542b\u5168\u8eab\u52a8\u529b\u5b66\u548c\u7ea6\u675f\u7684\u7edf\u4e00\u641c\u7d22\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u7edf\u4e00\u5904\u7406\u4eba\u5f62\u673a\u5668\u4eba\u7684\u79fb\u52a8\u548c\u64cd\u4f5c\u4efb\u52a1\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6574\u5408\u4efb\u52a1\u89c4\u5212\u3001\u63a5\u89e6\u89c4\u5212\u548c\u8fd0\u52a8\u89c4\u5212\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u540c\u65f6\u8003\u8651\u5168\u8eab\u52a8\u529b\u5b66\u548c\u5404\u79cd\u7ea6\u675f\u6761\u4ef6\u3002", "method": "\u5b9a\u4e49\u7b26\u53f7\u52a8\u4f5c\u4e3a\u63a5\u89e6\u6a21\u5f0f\u53d8\u5316\uff0c\u5c06\u9ad8\u5c42\u89c4\u5212\u4e0e\u5e95\u5c42\u8fd0\u52a8\u5173\u8054\uff0c\u5efa\u7acb\u7edf\u4e00\u7684\u641c\u7d22\u6846\u67b6\uff0c\u6574\u5408\u4efb\u52a1\u89c4\u5212\u3001\u63a5\u89e6\u89c4\u5212\u548c\u8fd0\u52a8\u89c4\u5212\uff0c\u5305\u542b\u5168\u8eab\u52a8\u529b\u5b66\u3001\u673a\u5668\u4eba\u3001\u64cd\u4f5c\u5bf9\u8c61\u548c\u73af\u5883\u4e4b\u95f4\u7684\u6240\u6709\u7ea6\u675f\u3002", "result": "\u5728\u4eba\u5f62\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u9a8c\u8bc1\uff0c\u80fd\u591f\u751f\u6210\u5e7f\u6cdb\u7684\u7269\u7406\u4e00\u81f4\u79fb\u52a8\u64cd\u4f5c\u884c\u4e3a\uff0c\u5904\u7406\u9700\u8981\u590d\u6742\u63a8\u7406\u7684\u957f\u52a8\u4f5c\u5e8f\u5217\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u80fd\u591f\u89e3\u51b3\u96c6\u6210TAMP\u516c\u5f0f\u7684\u5de5\u4f5c\uff0c\u5b9e\u73b0\u4e86\u5b8c\u5168\u65e0\u73af\u89c4\u5212\u548c\u5305\u542b\u9a71\u52a8\u7ea6\u675f\u7684\u5168\u8eab\u52a8\u529b\u5b66\uff0c\u4e3a\u4eba\u5f62\u673a\u5668\u4eba\u79fb\u52a8\u64cd\u4f5c\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.14654", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14654", "abs": "https://arxiv.org/abs/2508.14654", "authors": ["Peilin Ji", "Xiao Xue", "Simeng Wang", "Wenhao Yan"], "title": "Entropy-Constrained Strategy Optimization in Urban Floods: A Multi-Agent Framework with LLM and Knowledge Graph Integration", "comment": "17 pages including appendix, 6 figures", "summary": "In recent years, the increasing frequency of extreme urban rainfall events\nhas posed significant challenges to emergency scheduling systems. Urban\nflooding often leads to severe traffic congestion and service disruptions,\nthreatening public safety and mobility. However, effective decision making\nremains hindered by three key challenges: (1) managing trade-offs among\ncompeting goals (e.g., traffic flow, task completion, and risk mitigation)\nrequires dynamic, context-aware strategies; (2) rapidly evolving environmental\nconditions render static rules inadequate; and (3) LLM-generated strategies\nfrequently suffer from semantic instability and execution inconsistency.\nExisting methods fail to align perception, global optimization, and multi-agent\ncoordination within a unified framework. To tackle these challenges, we\nintroduce H-J, a hierarchical multi-agent framework that integrates\nknowledge-guided prompting, entropy-constrained generation, and feedback-driven\noptimization. The framework establishes a closed-loop pipeline spanning from\nmulti-source perception to strategic execution and continuous refinement. We\nevaluate H-J on real-world urban topology and rainfall data under three\nrepresentative conditions: extreme rainfall, intermittent bursts, and daily\nlight rain. Experiments show that H-J outperforms rule-based and\nreinforcement-learning baselines in traffic smoothness, task success rate, and\nsystem robustness. These findings highlight the promise of uncertainty-aware,\nknowledge-constrained LLM-based approaches for enhancing resilience in urban\nflood response.", "AI": {"tldr": "H-J\u662f\u4e00\u4e2a\u5206\u5c42\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u5f15\u5bfc\u63d0\u793a\u3001\u71b5\u7ea6\u675f\u751f\u6210\u548c\u53cd\u9988\u9a71\u52a8\u4f18\u5316\u6765\u89e3\u51b3\u57ce\u5e02\u6d2a\u6c34\u5e94\u6025\u8c03\u5ea6\u4e2d\u7684\u591a\u76ee\u6807\u6743\u8861\u3001\u52a8\u6001\u73af\u5883\u9002\u5e94\u548cLLM\u7b56\u7565\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u6781\u7aef\u57ce\u5e02\u964d\u96e8\u4e8b\u4ef6\u9891\u53d1\u5bfc\u81f4\u4ea4\u901a\u62e5\u5835\u548c\u670d\u52a1\u4e2d\u65ad\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u611f\u77e5\u3001\u5168\u5c40\u4f18\u5316\u548c\u591a\u667a\u80fd\u4f53\u534f\u8c03\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u51b3\u7b56\u7b56\u7565\u3002", "method": "\u63d0\u51faH-J\u5206\u5c42\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u6574\u5408\u77e5\u8bc6\u5f15\u5bfc\u63d0\u793a\u3001\u71b5\u7ea6\u675f\u751f\u6210\u548c\u53cd\u9988\u9a71\u52a8\u4f18\u5316\uff0c\u5efa\u7acb\u4ece\u591a\u6e90\u611f\u77e5\u5230\u7b56\u7565\u6267\u884c\u7684\u95ed\u73af\u7ba1\u9053\u3002", "result": "\u5728\u771f\u5b9e\u57ce\u5e02\u62d3\u6251\u548c\u964d\u96e8\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cH-J\u5728\u4ea4\u901a\u6d41\u7545\u5ea6\u3001\u4efb\u52a1\u6210\u529f\u7387\u548c\u7cfb\u7edf\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u548c\u77e5\u8bc6\u7ea6\u675f\u7684LLM\u65b9\u6cd5\u6709\u671b\u589e\u5f3a\u57ce\u5e02\u6d2a\u6c34\u54cd\u5e94\u7684\u97e7\u6027\u3002"}}
{"id": "2508.14100", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14100", "abs": "https://arxiv.org/abs/2508.14100", "authors": ["Nilay Kushawaha", "Carlo Alessi", "Lorenzo Fruzzetti", "Egidio Falotico"], "title": "Domain Translation of a Soft Robotic Arm using Conditional Cycle Generative Adversarial Network", "comment": "Accepted at IEEE International Conference on Robotic Systems and\n  Applications", "summary": "Deep learning provides a powerful method for modeling the dynamics of soft\nrobots, offering advantages over traditional analytical approaches that require\nprecise knowledge of the robot's structure, material properties, and other\nphysical characteristics. Given the inherent complexity and non-linearity of\nthese systems, extracting such details can be challenging. The mappings learned\nin one domain cannot be directly transferred to another domain with different\nphysical properties. This challenge is particularly relevant for soft robots,\nas their materials gradually degrade over time. In this paper, we introduce a\ndomain translation framework based on a conditional cycle generative\nadversarial network (CCGAN) to enable knowledge transfer from a source domain\nto a target domain. Specifically, we employ a dynamic learning approach to\nadapt a pose controller trained in a standard simulation environment to a\ndomain with tenfold increased viscosity. Our model learns from input pressure\nsignals conditioned on corresponding end-effector positions and orientations in\nboth domains. We evaluate our approach through trajectory-tracking experiments\nacross five distinct shapes and further assess its robustness under noise\nperturbations and periodicity tests. The results demonstrate that CCGAN-GP\neffectively facilitates cross-domain skill transfer, paving the way for more\nadaptable and generalizable soft robotic controllers.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6761\u4ef6\u5faa\u73af\u751f\u6210\u5bf9\u6297\u7f51\u7edc(CCGAN)\u7684\u9886\u57df\u8f6c\u6362\u6846\u67b6\uff0c\u89e3\u51b3\u8f6f\u673a\u5668\u4eba\u52a8\u529b\u5b66\u5efa\u6a21\u4e2d\u8de8\u9886\u57df\u77e5\u8bc6\u8fc1\u79fb\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6750\u6599\u7279\u6027\u53d8\u5316(\u5982\u7c98\u5ea6\u589e\u52a010\u500d)\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u63a7\u5236\u5668\u7684\u6709\u6548\u8fc1\u79fb\u3002", "motivation": "\u8f6f\u673a\u5668\u4eba\u6750\u6599\u4f1a\u968f\u65f6\u95f4\u9010\u6e10\u9000\u5316\uff0c\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u9700\u8981\u7cbe\u786e\u7684\u7269\u7406\u7279\u6027\u77e5\u8bc6\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u4e00\u4e2a\u9886\u57df\u5b66\u4e60\u7684\u6620\u5c04\u65e0\u6cd5\u76f4\u63a5\u8fc1\u79fb\u5230\u5177\u6709\u4e0d\u540c\u7269\u7406\u7279\u6027\u7684\u5176\u4ed6\u9886\u57df\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u5faa\u73af\u751f\u6210\u5bf9\u6297\u7f51\u7edc(CCGAN)\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u5b66\u4e60\u65b9\u6cd5\u5c06\u6807\u51c6\u4eff\u771f\u73af\u5883\u4e2d\u8bad\u7ec3\u7684\u59ff\u6001\u63a7\u5236\u5668\u9002\u914d\u5230\u7c98\u5ea6\u589e\u52a010\u500d\u7684\u76ee\u6807\u9886\u57df\uff0c\u6a21\u578b\u5b66\u4e60\u57fa\u4e8e\u672b\u7aef\u6267\u884c\u5668\u4f4d\u7f6e\u548c\u65b9\u5411\u7684\u8f93\u5165\u538b\u529b\u4fe1\u53f7\u3002", "result": "\u5728\u4e94\u79cd\u4e0d\u540c\u5f62\u72b6\u7684\u8f68\u8ff9\u8ddf\u8e2a\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u566a\u58f0\u6270\u52a8\u548c\u5468\u671f\u6027\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u4e86\u826f\u597d\u7684\u9c81\u68d2\u6027\uff0cCCGAN-GP\u6210\u529f\u5b9e\u73b0\u4e86\u8de8\u9886\u57df\u6280\u80fd\u8fc1\u79fb\u3002", "conclusion": "CCGAN-GP\u6846\u67b6\u4e3a\u8f6f\u673a\u5668\u4eba\u63a7\u5236\u5668\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3\u8f6f\u673a\u5668\u4eba\u6750\u6599\u9000\u5316\u5e26\u6765\u7684\u63a7\u5236\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.14704", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.14704", "abs": "https://arxiv.org/abs/2508.14704", "authors": ["Ziyang Luo", "Zhiqi Shen", "Wenzhuo Yang", "Zirui Zhao", "Prathyusha Jwalapuram", "Amrita Saha", "Doyen Sahoo", "Silvio Savarese", "Caiming Xiong", "Junnan Li"], "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "comment": "Website: https://mcp-universe.github.io", "summary": "The Model Context Protocol has emerged as a transformative standard for\nconnecting large language models to external data sources and tools, rapidly\ngaining adoption across major AI providers and development platforms. However,\nexisting benchmarks are overly simplistic and fail to capture real application\nchallenges such as long-horizon reasoning and large, unfamiliar tool spaces. To\naddress this critical gap, we introduce MCP-Universe, the first comprehensive\nbenchmark specifically designed to evaluate LLMs in realistic and hard tasks\nthrough interaction with real-world MCP servers. Our benchmark encompasses 6\ncore domains spanning 11 different MCP servers: Location Navigation, Repository\nManagement, Financial Analysis, 3D Design, Browser Automation, and Web\nSearching. To ensure rigorous evaluation, we implement execution-based\nevaluators, including format evaluators for agent format compliance, static\nevaluators for time-invariant content matching, and dynamic evaluators that\nautomatically retrieve real-time ground truth for temporally sensitive tasks.\nThrough extensive evaluation of leading LLMs, we find that even SOTA models\nsuch as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit\nsignificant performance limitations. In addition, our benchmark poses a\nsignificant long-context challenge for LLM agents, as the number of input\ntokens increases rapidly with the number of interaction steps. Moreover, it\nintroduces an unknown-tools challenge, as LLM agents often lack familiarity\nwith the precise usage of the MCP servers. Notably, enterprise-level agents\nlike Cursor cannot achieve better performance than standard ReAct frameworks.\nBeyond evaluation, we open-source our extensible evaluation framework with UI\nsupport, enabling researchers and practitioners to seamlessly integrate new\nagents and MCP servers while fostering innovation in the rapidly evolving MCP\necosystem.", "AI": {"tldr": "MCP-Universe\u662f\u9996\u4e2a\u4e13\u95e8\u8bc4\u4f30LLM\u901a\u8fc7MCP\u670d\u52a1\u5668\u4ea4\u4e92\u5904\u7406\u771f\u5b9e\u590d\u6742\u4efb\u52a1\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u6db5\u76d66\u4e2a\u6838\u5fc3\u9886\u57df11\u4e2a\u670d\u52a1\u5668\uff0c\u53d1\u73b0\u5373\u4f7f\u662fSOTA\u6a21\u578b\u4e5f\u5b58\u5728\u663e\u8457\u6027\u80fd\u9650\u5236", "motivation": "\u73b0\u6709\u57fa\u51c6\u8fc7\u4e8e\u7b80\u5355\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u5e94\u7528\u6311\u6218\uff0c\u5982\u957f\u7a0b\u63a8\u7406\u548c\u5927\u89c4\u6a21\u964c\u751f\u5de5\u5177\u7a7a\u95f4\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9MCP\u534f\u8bae\u7684\u771f\u5b9e\u8bc4\u4f30\u57fa\u51c6", "method": "\u6784\u5efa\u5305\u542b6\u4e2a\u9886\u57df11\u4e2aMCP\u670d\u52a1\u5668\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u5b9e\u73b0\u6267\u884c\u5f0f\u8bc4\u4f30\u5668\uff08\u683c\u5f0f\u8bc4\u4f30\u5668\u3001\u9759\u6001\u8bc4\u4f30\u5668\u3001\u52a8\u6001\u8bc4\u4f30\u5668\uff09\uff0c\u81ea\u52a8\u68c0\u7d22\u5b9e\u65f6\u771f\u5b9e\u6570\u636e", "result": "\u9876\u7ea7\u6a21\u578b\u8868\u73b0\u6709\u9650\uff08GPT-5:43.72%, Grok-4:33.33%, Claude-4.0-Sonnet:29.44%\uff09\uff0c\u9762\u4e34\u957f\u4e0a\u4e0b\u6587\u548c\u672a\u77e5\u5de5\u5177\u6311\u6218\uff0c\u4f01\u4e1a\u7ea7\u4ee3\u7406\u6027\u80fd\u4e0d\u4f18\u4e8e\u6807\u51c6ReAct\u6846\u67b6", "conclusion": "MCP-Universe\u586b\u8865\u4e86\u5173\u952e\u8bc4\u4f30\u7a7a\u767d\uff0c\u5f00\u6e90\u7684\u53ef\u6269\u5c55\u6846\u67b6\u652f\u6301\u65b0\u4ee3\u7406\u548c\u670d\u52a1\u5668\u96c6\u6210\uff0c\u63a8\u52a8MCP\u751f\u6001\u7cfb\u7edf\u521b\u65b0"}}
{"id": "2508.14105", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14105", "abs": "https://arxiv.org/abs/2508.14105", "authors": ["Jahid Chowdhury Choton", "John Woods", "William Hsu"], "title": "Efficient Environment Design for Multi-Robot Navigation via Continuous Control", "comment": "12 pages, 3 figures, conference", "summary": "Multi-robot navigation and path planning in continuous state and action\nspaces with uncertain environments remains an open challenge. Deep\nReinforcement Learning (RL) is one of the most popular paradigms for solving\nthis task, but its real-world application has been limited due to sample\ninefficiency and long training periods. Moreover, the existing works using RL\nfor multi-robot navigation lack formal guarantees while designing the\nenvironment. In this paper, we introduce an efficient and highly customizable\nenvironment for continuous-control multi-robot navigation, where the robots\nmust visit a set of regions of interest (ROIs) by following the shortest paths.\nThe task is formally modeled as a Markov Decision Process (MDP). We describe\nthe multi-robot navigation task as an optimization problem and relate it to\nfinding an optimal policy for the MDP. We crafted several variations of the\nenvironment and measured the performance using both gradient and non-gradient\nbased RL methods: A2C, PPO, TRPO, TQC, CrossQ and ARS. To show real-world\napplicability, we deployed our environment to a 3-D agricultural field with\nuncertainties using the CoppeliaSim robot simulator and measured the robustness\nby running inference on the learned models. We believe our work will guide the\nresearchers on how to develop MDP-based environments that are applicable to\nreal-world systems and solve them using the existing state-of-the-art RL\nmethods with limited resources and within reasonable time periods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u6548\u53ef\u5b9a\u5236\u7684\u591a\u673a\u5668\u4eba\u5bfc\u822a\u73af\u5883\uff0c\u5728\u8fde\u7eed\u72b6\u6001\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u89e3\u51b3\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u7684\u8def\u5f84\u89c4\u5212\u95ee\u9898\uff0c\u4f7f\u7528\u591a\u79cdRL\u65b9\u6cd5\u8fdb\u884c\u6d4b\u8bd5\u5e76\u9a8c\u8bc1\u4e86\u5b9e\u9645\u5e94\u7528\u6027\u3002", "motivation": "\u591a\u673a\u5668\u4eba\u5728\u8fde\u7eed\u72b6\u6001\u52a8\u4f5c\u7a7a\u95f4\u548c\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u4e0e\u8def\u5f84\u89c4\u5212\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\uff0c\u73b0\u6709\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u3001\u8bad\u7ec3\u65f6\u95f4\u957f\u4e14\u7f3a\u4e4f\u5f62\u5f0f\u5316\u4fdd\u8bc1\u7684\u95ee\u9898\u3002", "method": "\u5c06\u591a\u673a\u5668\u4eba\u5bfc\u822a\u4efb\u52a1\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(MDP)\uff0c\u8bbe\u8ba1\u4f18\u5316\u95ee\u9898\u5e76\u5173\u8054\u5230\u5bfb\u627eMDP\u7684\u6700\u4f18\u7b56\u7565\u3002\u521b\u5efa\u4e86\u591a\u4e2a\u73af\u5883\u53d8\u4f53\uff0c\u4f7f\u7528A2C\u3001PPO\u3001TRPO\u3001TQC\u3001CrossQ\u548cARS\u7b49\u68af\u5ea6\u4e0e\u975e\u68af\u5ea6RL\u65b9\u6cd5\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u5728CoppeliaSim\u673a\u5668\u4eba\u6a21\u62df\u5668\u4e2d\u90e8\u7f72\u52303D\u519c\u4e1a\u7530\u95f4\u73af\u5883\u8fdb\u884c\u5b9e\u9645\u5e94\u7528\u9a8c\u8bc1\uff0c\u901a\u8fc7\u5bf9\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u63a8\u7406\u6d4b\u8bd5\u6765\u6d4b\u91cf\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5f00\u53d1\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7cfb\u7edf\u7684MDP\u73af\u5883\u7684\u65b9\u6cd5\u6307\u5bfc\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5728\u6709\u9650\u8d44\u6e90\u548c\u5408\u7406\u65f6\u95f4\u5185\u4f7f\u7528\u73b0\u6709\u6700\u5148\u8fdbRL\u65b9\u6cd5\u89e3\u51b3\u591a\u673a\u5668\u4eba\u5bfc\u822a\u95ee\u9898\u3002"}}
{"id": "2508.14710", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14710", "abs": "https://arxiv.org/abs/2508.14710", "authors": ["Swantje Plambeck", "Ali Salamati", "Eyke Huellermeier", "Goerschwin Fey"], "title": "Data-Driven Probabilistic Evaluation of Logic Properties with PAC-Confidence on Mealy Machines", "comment": null, "summary": "Cyber-Physical Systems (CPS) are complex systems that require powerful models\nfor tasks like verification, diagnosis, or debugging. Often, suitable models\nare not available and manual extraction is difficult. Data-driven approaches\nthen provide a solution to, e.g., diagnosis tasks and verification problems\nbased on data collected from the system. In this paper, we consider CPS with a\ndiscrete abstraction in the form of a Mealy machine. We propose a data-driven\napproach to determine the safety probability of the system on a finite horizon\nof n time steps. The approach is based on the Probably Approximately Correct\n(PAC) learning paradigm. Thus, we elaborate a connection between discrete logic\nand probabilistic reachability analysis of systems, especially providing an\nadditional confidence on the determined probability. The learning process\nfollows an active learning paradigm, where new learning data is sampled in a\nguided way after an initial learning set is collected. We validate the approach\nwith a case study on an automated lane-keeping system.", "AI": {"tldr": "\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u57fa\u4e8ePAC\u5b66\u4e60\u7406\u8bba\uff0c\u4f30\u8ba1\u8ba1\u7b97\u673a\u7269\u7406\u7cfb\u7edf\u5728\u6709\u9650\u65f6\u95f4\u7a97\u53e3\u5185\u7684\u5b89\u5168\u6982\u7387\uff0c\u5e76\u63d0\u4f9b\u7edf\u8ba1\u4fe1\u5fc3", "motivation": "\u8ba1\u7b97\u673a\u7269\u7406\u7cfb\u7edf(CPS)\u7684\u590d\u6742\u6027\u4f7f\u5f97\u624b\u52a8\u63d0\u53d6\u6a21\u578b\u56f0\u96be\uff0c\u9700\u8981\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u6765\u89e3\u51b3\u9a8c\u8bc1\u3001\u8bca\u65ad\u7b49\u4efb\u52a1", "method": "\u5c06CPS\u62bd\u8c61\u4e3aMealy\u673a\uff0c\u91c7\u7528\u57fa\u4e8ePAC\u5b66\u4e60\u7406\u8bba\u7684\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6307\u5bfc\u6027\u91c7\u6837\u83b7\u53d6\u5b66\u4e60\u6570\u636e", "result": "\u5728\u81ea\u52a8\u8f66\u9053\u4fdd\u6301\u7cfb\u7edf\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u80fd\u591f\u4f30\u8ba1\u7cfb\u7edf\u5728\u6709\u9650\u65f6\u95f4\u7a97\u53e3\u5185\u7684\u5b89\u5168\u6982\u7387", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aCPS\u7684\u6982\u7387\u6027\u5b89\u5168\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u6570\u636e\u9a71\u52a8\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u6982\u7387\u7ea6\u7b80\u6b63\u786e\u5b66\u4e60\u7406\u8bba\u63d0\u4f9b\u4e86\u4fe1\u5fc3\u4fdd\u969c"}}
{"id": "2508.14120", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14120", "abs": "https://arxiv.org/abs/2508.14120", "authors": ["Yuhang Lin", "Yijia Xie", "Jiahong Xie", "Yuehao Huang", "Ruoyu Wang", "Jiajun Lv", "Yukai Ma", "Xingxing Zuo"], "title": "SimGenHOI: Physically Realistic Whole-Body Humanoid-Object Interaction via Generative Modeling and Reinforcement Learning", "comment": null, "summary": "Generating physically realistic humanoid-object interactions (HOI) is a\nfundamental challenge in robotics. Existing HOI generation approaches, such as\ndiffusion-based models, often suffer from artifacts such as implausible\ncontacts, penetrations, and unrealistic whole-body actions, which hinder\nsuccessful execution in physical environments. To address these challenges, we\nintroduce SimGenHOI, a unified framework that combines the strengths of\ngenerative modeling and reinforcement learning to produce controllable and\nphysically plausible HOI. Our HOI generative model, based on Diffusion\nTransformers (DiT), predicts a set of key actions conditioned on text prompts,\nobject geometry, sparse object waypoints, and the initial humanoid pose. These\nkey actions capture essential interaction dynamics and are interpolated into\nsmooth motion trajectories, naturally supporting long-horizon generation. To\nensure physical realism, we design a contact-aware whole-body control policy\ntrained with reinforcement learning, which tracks the generated motions while\ncorrecting artifacts such as penetration and foot sliding. Furthermore, we\nintroduce a mutual fine-tuning strategy, where the generative model and the\ncontrol policy iteratively refine each other, improving both motion realism and\ntracking robustness. Extensive experiments demonstrate that SimGenHOI generates\nrealistic, diverse, and physically plausible humanoid-object interactions,\nachieving significantly higher tracking success rates in simulation and\nenabling long-horizon manipulation tasks. Code will be released upon acceptance\non our project page: https://xingxingzuo.github.io/simgen_hoi.", "AI": {"tldr": "SimGenHOI\u662f\u4e00\u4e2a\u7ed3\u5408\u751f\u6210\u5efa\u6a21\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u53ef\u63a7\u4e14\u7269\u7406\u5408\u7406\u7684\u4eba\u5f62\u673a\u5668\u4eba-\u7269\u4f53\u4ea4\u4e92\u52a8\u4f5c\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u4e0d\u5408\u7406\u7684\u63a5\u89e6\u3001\u7a7f\u900f\u548c\u5168\u8eab\u52a8\u4f5c\u7b49\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u5f62\u673a\u5668\u4eba-\u7269\u4f53\u4ea4\u4e92\u751f\u6210\u65b9\u6cd5\uff08\u5982\u57fa\u4e8e\u6269\u6563\u7684\u6a21\u578b\uff09\u7ecf\u5e38\u51fa\u73b0\u4e0d\u5408\u7406\u7684\u63a5\u89e6\u3001\u7a7f\u900f\u548c\u4e0d\u771f\u5b9e\u7684\u5168\u8eab\u52a8\u4f5c\u7b49\u4f2a\u5f71\uff0c\u963b\u788d\u4e86\u5728\u7269\u7406\u73af\u5883\u4e2d\u7684\u6210\u529f\u6267\u884c\u3002", "method": "\u57fa\u4e8e\u6269\u6563\u53d8\u6362\u5668\uff08DiT\uff09\u7684\u751f\u6210\u6a21\u578b\u9884\u6d4b\u5173\u952e\u52a8\u4f5c\uff0c\u7ed3\u5408\u63a5\u89e6\u611f\u77e5\u7684\u5168\u8eab\u63a7\u5236\u7b56\u7565\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u91c7\u7528\u76f8\u4e92\u5fae\u8c03\u7b56\u7565\u8fed\u4ee3\u4f18\u5316\u751f\u6210\u6a21\u578b\u548c\u63a7\u5236\u7b56\u7565\u3002", "result": "SimGenHOI\u80fd\u591f\u751f\u6210\u771f\u5b9e\u3001\u591a\u6837\u4e14\u7269\u7406\u5408\u7406\u7684\u4eba\u5f62\u673a\u5668\u4eba-\u7269\u4f53\u4ea4\u4e92\uff0c\u5728\u6a21\u62df\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u8ddf\u8e2a\u6210\u529f\u7387\uff0c\u5e76\u652f\u6301\u957f\u65f6\u7a0b\u64cd\u4f5c\u4efb\u52a1\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86\u751f\u6210\u5efa\u6a21\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u52bf\uff0c\u4e3a\u4eba\u5f62\u673a\u5668\u4eba-\u7269\u4f53\u4ea4\u4e92\u751f\u6210\u63d0\u4f9b\u4e86\u7269\u7406\u771f\u5b9e\u4e14\u53ef\u63a7\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.14802", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.14802", "abs": "https://arxiv.org/abs/2508.14802", "authors": ["Siyuan Song", "Harvey Lederman", "Jennifer Hu", "Kyle Mahowald"], "title": "Privileged Self-Access Matters for Introspection in AI", "comment": null, "summary": "Whether AI models can introspect is an increasingly important practical\nquestion. But there is no consensus on how introspection is to be defined.\nBeginning from a recently proposed ''lightweight'' definition, we argue instead\nfor a thicker one. According to our proposal, introspection in AI is any\nprocess which yields information about internal states through a process more\nreliable than one with equal or lower computational cost available to a third\nparty. Using experiments where LLMs reason about their internal temperature\nparameters, we show they can appear to have lightweight introspection while\nfailing to meaningfully introspect per our proposed definition.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8AI\u6a21\u578b\u662f\u5426\u80fd\u5185\u7701\uff0c\u63d0\u51fa\u4e86\u6bd4\u73b0\u6709\"\u8f7b\u91cf\u7ea7\"\u5b9a\u4e49\u66f4\"\u539a\u91cd\"\u7684\u5185\u7701\u5b9a\u4e49\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660eLLMs\u867d\u7136\u770b\u4f3c\u5177\u5907\u8f7b\u91cf\u7ea7\u5185\u7701\u80fd\u529b\uff0c\u4f46\u65e0\u6cd5\u8fbe\u5230\u4f5c\u8005\u63d0\u51fa\u7684\u66f4\u4e25\u683c\u7684\u5185\u7701\u6807\u51c6\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u662f\u5426\u80fd\u5185\u7701\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u5b9e\u8df5\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5bf9\"\u5185\u7701\"\u7684\u7edf\u4e00\u5b9a\u4e49\u3002\u4f5c\u8005\u65e8\u5728\u63d0\u51fa\u4e00\u4e2a\u66f4\u4e25\u683c\u3001\u66f4\u6709\u610f\u4e49\u7684\u5185\u7701\u5b9a\u4e49\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5185\u7701\u5b9a\u4e49\uff1a\u4efb\u4f55\u80fd\u901a\u8fc7\u6bd4\u7b2c\u4e09\u65b9\u53ef\u7528\u65b9\u6cd5\u66f4\u53ef\u9760\u4e14\u8ba1\u7b97\u6210\u672c\u76f8\u5f53\u6216\u66f4\u4f4e\u7684\u8fc7\u7a0b\u6765\u83b7\u53d6\u5185\u90e8\u72b6\u6001\u4fe1\u606f\u7684\u8fc7\u7a0b\u3002\u901a\u8fc7\u8ba9LLMs\u63a8\u7406\u5176\u5185\u90e8\u6e29\u5ea6\u53c2\u6570\u7684\u5b9e\u9a8c\u6765\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u867d\u7136LLMs\u8868\u9762\u4e0a\u8868\u73b0\u51fa\u8f7b\u91cf\u7ea7\u5185\u7701\u80fd\u529b\uff0c\u4f46\u65e0\u6cd5\u6ee1\u8db3\u4f5c\u8005\u63d0\u51fa\u7684\u66f4\u4e25\u683c\u7684\u5185\u7701\u5b9a\u4e49\u6807\u51c6\u3002", "conclusion": "\u9700\u8981\u91c7\u7528\u66f4\u4e25\u683c\u7684\u5185\u7701\u5b9a\u4e49\u6765\u51c6\u786e\u8bc4\u4f30AI\u6a21\u578b\u7684\u5185\u7701\u80fd\u529b\uff0c\u5f53\u524dLLMs\u7684\u5185\u7701\u80fd\u529b\u6709\u9650\uff0c\u65e0\u6cd5\u8fbe\u5230\u6709\u610f\u4e49\u7684\u81ea\u7701\u6c34\u5e73\u3002"}}
{"id": "2508.14185", "categories": ["cs.RO", "cs.SY", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.14185", "abs": "https://arxiv.org/abs/2508.14185", "authors": ["Evanns Morales-Cuadrado", "Luke Baird", "Yorai Wardi", "Samuel Coogan"], "title": "Lightweight Tracking Control for Computationally Constrained Aerial Systems with the Newton-Raphson Method", "comment": null, "summary": "We investigate the performance of a lightweight tracking controller, based on\na flow version of the Newton-Raphson method, applied to a miniature blimp and a\nmid-size quadrotor. This tracking technique has been shown to enjoy theoretical\nguarantees of performance and has been applied with success in simulation\nstudies and on mobile robots with simple motion models. This paper investigates\nthe technique through real-world flight experiments on aerial hardware\nplatforms subject to realistic deployment and onboard computational\nconstraints. The technique's performance is assessed in comparison with the\nestablished control frameworks of feedback linearization for the blimp, and\nnonlinear model predictive control for both quadrotor and blimp. The\nperformance metrics under consideration are (i) root mean square error of\nflight trajectories with respect to target trajectories, (ii) algorithms'\ncomputation times, and (iii) CPU energy consumption associated with the control\nalgorithms. The experimental findings show that the Newton-Raphson flow-based\ntracking controller achieves comparable or superior tracking performance to the\nbaseline methods with substantially reduced computation time and energy\nexpenditure.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u57fa\u4e8e\u725b\u987f-\u62c9\u5f17\u68ee\u6d41\u65b9\u6cd5\u7684\u8f7b\u91cf\u7ea7\u8ddf\u8e2a\u63a7\u5236\u5668\uff0c\u5728\u5fae\u578b\u98de\u8247\u548c\u4e2d\u578b\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u5728\u8ba1\u7b97\u65f6\u95f4\u548c\u80fd\u8017\u65b9\u9762\u6709\u663e\u8457\u4f18\u52bf", "motivation": "\u7814\u7a76\u8f7b\u91cf\u7ea7\u8ddf\u8e2a\u63a7\u5236\u5668\u5728\u771f\u5b9e\u98de\u884c\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u7684\u673a\u8f7d\u7cfb\u7edf\u4e0a\u7684\u9002\u7528\u6027", "method": "\u4f7f\u7528\u57fa\u4e8e\u725b\u987f-\u62c9\u5f17\u68ee\u6d41\u65b9\u6cd5\u7684\u8ddf\u8e2a\u63a7\u5236\u5668\uff0c\u4e0e\u53cd\u9988\u7ebf\u6027\u5316\uff08\u98de\u8247\uff09\u548c\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08\u56db\u65cb\u7ffc\u548c\u98de\u8247\uff09\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c", "result": "\u725b\u987f-\u62c9\u5f17\u68ee\u6d41\u63a7\u5236\u5668\u5728\u8ddf\u8e2a\u6027\u80fd\u4e0a\u4e0e\u57fa\u51c6\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u540c\u65f6\u8ba1\u7b97\u65f6\u95f4\u548cCPU\u80fd\u8017\u5927\u5e45\u964d\u4f4e", "conclusion": "\u8be5\u8f7b\u91cf\u7ea7\u63a7\u5236\u5668\u5728\u4fdd\u8bc1\u8ddf\u8e2a\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u9002\u5408\u5728\u8d44\u6e90\u53d7\u9650\u7684\u7a7a\u4e2d\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u90e8\u7f72"}}
{"id": "2508.14235", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14235", "abs": "https://arxiv.org/abs/2508.14235", "authors": ["Omar Mostafa", "Nikolaos Evangeliou", "Anthony Tzes"], "title": "SLAM-based Safe Indoor Exploration Strategy", "comment": "5 pages, 8 figures. Published in the 2025 11th International\n  Conference on Automation, Robotics, and Applications (ICARA)", "summary": "This paper suggests a 2D exploration strategy for a planar space cluttered\nwith obstacles. Rather than using point robots capable of adjusting their\nposition and altitude instantly, this research is tailored to classical agents\nwith circular footprints that cannot control instantly their pose. Inhere, a\nself-balanced dual-wheeled differential drive system is used to explore the\nplace. The system is equipped with linear accelerometers and angular\ngyroscopes, a 3D-LiDAR, and a forward-facing RGB-D camera. The system performs\nRTAB-SLAM using the IMU and the LiDAR, while the camera is used for loop\nclosures. The mobile agent explores the planar space using a safe skeleton\napproach that places the agent as far as possible from the static obstacles.\nDuring the exploration strategy, the heading is towards any offered openings of\nthe space. This space exploration strategy has as its highest priority the\nagent's safety in avoiding the obstacles followed by the exploration of\nundetected space. Experimental studies with a ROS-enabled mobile agent are\npresented indicating the path planning strategy while exploring the space.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6709\u969c\u788d\u7269\u7684\u5e73\u9762\u7a7a\u95f4\u76842D\u63a2\u7d22\u7b56\u7565\uff0c\u4f7f\u7528\u53cc\u8f6e\u5dee\u901f\u9a71\u52a8\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b89\u5168\u9aa8\u67b6\u65b9\u6cd5\u8fdb\u884c\u63a2\u7d22\uff0c\u4f18\u5148\u8003\u8651\u907f\u969c\u5b89\u5168\u6027\u548c\u672a\u63a2\u6d4b\u7a7a\u95f4\u7684\u63a2\u7d22\u3002", "motivation": "\u7814\u7a76\u9488\u5bf9\u5177\u6709\u5706\u5f62\u8db3\u8ff9\u4e14\u4e0d\u80fd\u5373\u65f6\u63a7\u5236\u59ff\u6001\u7684\u4f20\u7edf\u4ee3\u7406\uff0c\u5728\u5145\u6ee1\u969c\u788d\u7269\u7684\u5e73\u9762\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u5b89\u5168\u6709\u6548\u7684\u63a2\u7d22\uff0c\u800c\u4e0d\u662f\u4f7f\u7528\u80fd\u591f\u5373\u65f6\u8c03\u6574\u4f4d\u7f6e\u548c\u9ad8\u5ea6\u7684\u70b9\u673a\u5668\u4eba\u3002", "method": "\u91c7\u7528\u81ea\u5e73\u8861\u53cc\u8f6e\u5dee\u901f\u9a71\u52a8\u7cfb\u7edf\uff0c\u914d\u5907\u7ebf\u6027\u52a0\u901f\u5ea6\u8ba1\u3001\u89d2\u901f\u5ea6\u9640\u87ba\u4eea\u30013D-LiDAR\u548c\u524d\u7f6eRGB-D\u76f8\u673a\u3002\u4f7f\u7528IMU\u548cLiDAR\u8fdb\u884cRTAB-SLAM\uff0c\u76f8\u673a\u7528\u4e8e\u95ed\u73af\u68c0\u6d4b\u3002\u63a2\u7d22\u7b56\u7565\u91c7\u7528\u5b89\u5168\u9aa8\u67b6\u65b9\u6cd5\uff0c\u4f7f\u4ee3\u7406\u5c3d\u53ef\u80fd\u8fdc\u79bb\u9759\u6001\u969c\u788d\u7269\uff0c\u671d\u5411\u7a7a\u95f4\u4e2d\u7684\u5f00\u53e3\u65b9\u5411\u524d\u8fdb\u3002", "result": "\u901a\u8fc7ROS\u79fb\u52a8\u4ee3\u7406\u8fdb\u884c\u4e86\u5b9e\u9a8c\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u5728\u63a2\u7d22\u7a7a\u95f4\u65f6\u7684\u8def\u5f84\u89c4\u5212\u7b56\u7565\u3002", "conclusion": "\u8be5\u7a7a\u95f4\u63a2\u7d22\u7b56\u7565\u4ee5\u4ee3\u7406\u7684\u907f\u969c\u5b89\u5168\u4e3a\u6700\u9ad8\u4f18\u5148\u7ea7\uff0c\u5176\u6b21\u662f\u672a\u63a2\u6d4b\u7a7a\u95f4\u7684\u63a2\u7d22\uff0c\u4e3a\u4f20\u7edf\u79fb\u52a8\u4ee3\u7406\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u63a2\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.14258", "categories": ["cs.RO", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2508.14258", "abs": "https://arxiv.org/abs/2508.14258", "authors": ["Daegyun Choi", "Alhim Vera", "Donghoon Kim"], "title": "Adapting Biological Reflexes for Dynamic Reorientation in Space Manipulator Systems", "comment": "18 pages, 11 figures, 2025 AAS/AIAA Astrodynamics Specialist\n  Conference", "summary": "Robotic arms mounted on spacecraft, known as space manipulator systems\n(SMSs), are critical for enabling on-orbit assembly, satellite servicing, and\ndebris removal. However, controlling these systems in microgravity remains a\nsignificant challenge due to the dynamic coupling between the manipulator and\nthe spacecraft base. This study explores the potential of using biological\ninspiration to address this issue, focusing on animals, particularly lizards,\nthat exhibit mid-air righting reflexes. Based on similarities between SMSs and\nthese animals in terms of behavior, morphology, and environment, their\nair-righting motion trajectories are extracted from high-speed video recordings\nusing computer vision techniques. These trajectories are analyzed within a\nmulti-objective optimization framework to identify the key behavioral goals and\nassess their relative importance. The resulting motion profiles are then\napplied as reference trajectories for SMS control, with baseline controllers\nused to track them. The findings provide a step toward translating evolved\nanimal behaviors into interpretable, adaptive control strategies for space\nrobotics, with implications for improving maneuverability and robustness in\nfuture missions.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ece\u8725\u8734\u7b49\u52a8\u7269\u7684\u7a7a\u4e2d\u7ffb\u6b63\u53cd\u5c04\u4e2d\u83b7\u53d6\u7075\u611f\uff0c\u901a\u8fc7\u8ba1\u7b97\u673a\u89c6\u89c9\u63d0\u53d6\u8fd0\u52a8\u8f68\u8ff9\uff0c\u5e76\u5e94\u7528\u4e8e\u7a7a\u95f4\u673a\u68b0\u81c2\u7cfb\u7edf\u7684\u63a7\u5236\u4f18\u5316", "motivation": "\u89e3\u51b3\u7a7a\u95f4\u673a\u68b0\u81c2\u7cfb\u7edf\u5728\u5fae\u91cd\u529b\u73af\u5883\u4e0b\u7684\u63a7\u5236\u96be\u9898\uff0c\u7279\u522b\u662f\u673a\u68b0\u81c2\u4e0e\u822a\u5929\u5668\u57fa\u5ea7\u4e4b\u95f4\u7684\u52a8\u6001\u8026\u5408\u95ee\u9898", "method": "\u4f7f\u7528\u9ad8\u901f\u89c6\u9891\u8bb0\u5f55\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\u63d0\u53d6\u52a8\u7269\u7a7a\u4e2d\u7ffb\u6b63\u8fd0\u52a8\u8f68\u8ff9\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\u5206\u6790\u884c\u4e3a\u76ee\u6807\uff0c\u5e76\u5c06\u7ed3\u679c\u4f5c\u4e3a\u53c2\u8003\u8f68\u8ff9\u5e94\u7528\u4e8e\u7a7a\u95f4\u673a\u68b0\u81c2\u63a7\u5236", "result": "\u6210\u529f\u5c06\u52a8\u7269\u8fdb\u5316\u884c\u4e3a\u8f6c\u5316\u4e3a\u53ef\u89e3\u91ca\u7684\u81ea\u9002\u5e94\u63a7\u5236\u7b56\u7565\uff0c\u4e3a\u7a7a\u95f4\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u6539\u8fdb\u673a\u52a8\u6027\u548c\u9c81\u68d2\u6027\u7684\u65b9\u6cd5", "conclusion": "\u751f\u7269\u542f\u53d1\u65b9\u6cd5\u4e3a\u7a7a\u95f4\u673a\u5668\u4eba\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u672a\u6765\u4efb\u52a1\u4e2d\u7684\u673a\u52a8\u6027\u548c\u9c81\u68d2\u6027\u6709\u671b\u5f97\u5230\u663e\u8457\u63d0\u5347"}}
{"id": "2508.14355", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14355", "abs": "https://arxiv.org/abs/2508.14355", "authors": ["Guodong Yao", "Hao Wang", "Qing Chang"], "title": "D$^2$-LIO: Enhanced Optimization for LiDAR-IMU Odometry Considering Directional Degeneracy", "comment": "7 page, 2 figures", "summary": "LiDAR-inertial odometry (LIO) plays a vital role in achieving accurate\nlocalization and mapping, especially in complex environments. However, the\npresence of LiDAR feature degeneracy poses a major challenge to reliable state\nestimation. To overcome this issue, we propose an enhanced LIO framework that\nintegrates adaptive outlier-tolerant correspondence with a scan-to-submap\nregistration strategy. The core contribution lies in an adaptive outlier\nremoval threshold, which dynamically adjusts based on point-to-sensor distance\nand the motion amplitude of platform. This mechanism improves the robustness of\nfeature matching in varying conditions. Moreover, we introduce a flexible\nscan-to-submap registration method that leverages IMU data to refine pose\nestimation, particularly in degenerate geometric configurations. To further\nenhance localization accuracy, we design a novel weighting matrix that fuses\nIMU preintegration covariance with a degeneration metric derived from the\nscan-to-submap process. Extensive experiments conducted in both indoor and\noutdoor environments-characterized by sparse or degenerate features-demonstrate\nthat our method consistently outperforms state-of-the-art approaches in terms\nof both robustness and accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u578b\u6fc0\u5149\u96f7\u8fbe-\u60ef\u6027\u91cc\u7a0b\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5f02\u5e38\u503c\u5bb9\u5fcd\u5bf9\u5e94\u548c\u626b\u63cf\u5230\u5b50\u56fe\u914d\u51c6\u7b56\u7565\uff0c\u89e3\u51b3\u4e86LiDAR\u7279\u5f81\u9000\u5316\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "motivation": "LiDAR-\u60ef\u6027\u91cc\u7a0b\u8ba1\u5728\u590d\u6742\u73af\u5883\u4e2d\u5bf9\u7cbe\u786e\u5b9a\u4f4d\u548c\u5efa\u56fe\u81f3\u5173\u91cd\u8981\uff0c\u4f46LiDAR\u7279\u5f81\u9000\u5316\u95ee\u9898\u4e25\u91cd\u5f71\u54cd\u4e86\u72b6\u6001\u4f30\u8ba1\u7684\u53ef\u9760\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u81ea\u9002\u5e94\u5f02\u5e38\u503c\u53bb\u9664\u9608\u503c\uff08\u6839\u636e\u70b9\u4f20\u611f\u5668\u8ddd\u79bb\u548c\u5e73\u53f0\u8fd0\u52a8\u5e45\u5ea6\u52a8\u6001\u8c03\u6574\uff09\uff0c\u7ed3\u5408\u7075\u6d3b\u7684\u626b\u63cf\u5230\u5b50\u56fe\u914d\u51c6\u65b9\u6cd5\uff0c\u5229\u7528IMU\u6570\u636e\u4f18\u5316\u4f4d\u59ff\u4f30\u8ba1\uff0c\u5e76\u8bbe\u8ba1\u4e86\u878d\u5408IMU\u9884\u79ef\u5206\u534f\u65b9\u5dee\u548c\u9000\u5316\u5ea6\u91cf\u7684\u65b0\u578b\u6743\u91cd\u77e9\u9635\u3002", "result": "\u5728\u5ba4\u5185\u5916\u7a00\u758f\u6216\u9000\u5316\u7279\u5f81\u73af\u5883\u4e2d\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762 consistently\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u589e\u5f3a\u578bLIO\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u5f02\u5e38\u503c\u5904\u7406\u548c\u626b\u63cf\u5230\u5b50\u56fe\u914d\u51c6\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86LiDAR\u7279\u5f81\u9000\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b9a\u4f4d\u6027\u80fd\u548c\u7cfb\u7edf\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.14635", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14635", "abs": "https://arxiv.org/abs/2508.14635", "authors": ["Jo\u00e3o Vitor de Carvalho Silva", "Douglas G. Macharet"], "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "comment": null, "summary": "The ability to coordinate actions across multiple agents is critical for\nsolving complex, real-world problems. Large Language Models (LLMs) have shown\nstrong capabilities in communication, planning, and reasoning, raising the\nquestion of whether they can also support effective collaboration in\nmulti-agent settings. In this work, we investigate the use of LLM agents to\nsolve a structured victim rescue task that requires division of labor,\nprioritization, and cooperative planning. Agents operate in a fully known\ngraph-based environment and must allocate resources to victims with varying\nneeds and urgency levels. We systematically evaluate their performance using a\nsuite of coordination-sensitive metrics, including task success rate, redundant\nactions, room conflicts, and urgency-weighted efficiency. This study offers new\ninsights into the strengths and failure modes of LLMs in physically grounded\nmulti-agent collaboration tasks, contributing to future benchmarks and\narchitectural improvements.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8LLM\u667a\u80fd\u4f53\u5728\u591a\u667a\u80fd\u4f53\u6551\u63f4\u4efb\u52a1\u4e2d\u7684\u534f\u4f5c\u80fd\u529b\uff0c\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u5176\u5728\u5206\u5de5\u3001\u4f18\u5148\u7ea7\u6392\u5e8f\u548c\u5408\u4f5c\u89c4\u5212\u65b9\u9762\u7684\u8868\u73b0\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6c9f\u901a\u3001\u89c4\u5212\u548c\u63a8\u7406\u65b9\u9762\u5c55\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u9700\u8981\u9a8c\u8bc1\u5176\u5728\u9700\u8981\u7269\u7406\u57fa\u7840\u534f\u4f5c\u7684\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u662f\u5426\u4e5f\u80fd\u6709\u6548\u652f\u6301\u5408\u4f5c\u3002", "method": "\u4f7f\u7528LLM\u667a\u80fd\u4f53\u5728\u5b8c\u5168\u5df2\u77e5\u7684\u56fe\u57fa\u73af\u5883\u4e2d\u6267\u884c\u7ed3\u6784\u5316\u53d7\u5bb3\u8005\u6551\u63f4\u4efb\u52a1\uff0c\u8bc4\u4f30\u5176\u5728\u8d44\u6e90\u5206\u914d\u3001\u5206\u5de5\u5408\u4f5c\u548c\u7d27\u6025\u4f18\u5148\u7ea7\u5904\u7406\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u901a\u8fc7\u534f\u8c03\u654f\u611f\u6027\u6307\u6807\uff08\u4efb\u52a1\u6210\u529f\u7387\u3001\u5197\u4f59\u884c\u52a8\u3001\u623f\u95f4\u51b2\u7a81\u548c\u7d27\u6025\u52a0\u6743\u6548\u7387\uff09\u7cfb\u7edf\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u7684\u534f\u4f5c\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u5728\u7269\u7406\u57fa\u7840\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u548c\u5931\u8d25\u6a21\u5f0f\uff0c\u4e3a\u672a\u6765\u57fa\u51c6\u6d4b\u8bd5\u548c\u67b6\u6784\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2508.14379", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14379", "abs": "https://arxiv.org/abs/2508.14379", "authors": ["Chia-Han Yeh", "Tse-Sheng Nan", "Risto Vuorio", "Wei Hung", "Hung-Yen Wu", "Shao-Hua Sun", "Ping-Chun Hsieh"], "title": "Action-Constrained Imitation Learning", "comment": "Published in ICML 2025", "summary": "Policy learning under action constraints plays a central role in ensuring\nsafe behaviors in various robot control and resource allocation applications.\nIn this paper, we study a new problem setting termed Action-Constrained\nImitation Learning (ACIL), where an action-constrained imitator aims to learn\nfrom a demonstrative expert with larger action space. The fundamental challenge\nof ACIL lies in the unavoidable mismatch of occupancy measure between the\nexpert and the imitator caused by the action constraints. We tackle this\nmismatch through \\textit{trajectory alignment} and propose DTWIL, which\nreplaces the original expert demonstrations with a surrogate dataset that\nfollows similar state trajectories while adhering to the action constraints.\nSpecifically, we recast trajectory alignment as a planning problem and solve it\nvia Model Predictive Control, which aligns the surrogate trajectories with the\nexpert trajectories based on the Dynamic Time Warping (DTW) distance. Through\nextensive experiments, we demonstrate that learning from the dataset generated\nby DTWIL significantly enhances performance across multiple robot control tasks\nand outperforms various benchmark imitation learning algorithms in terms of\nsample efficiency. Our code is publicly available at\nhttps://github.com/NYCU-RL-Bandits-Lab/ACRL-Baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u4f5c\u7ea6\u675f\u6a21\u4eff\u5b66\u4e60\uff08ACIL\uff09\u65b9\u6cd5DTWIL\uff0c\u901a\u8fc7\u8f68\u8ff9\u5bf9\u9f50\u548c\u52a8\u6001\u65f6\u95f4\u89c4\u6574\u8ddd\u79bb\u6765\u89e3\u51b3\u4e13\u5bb6\u4e0e\u6a21\u4eff\u8005\u4e4b\u95f4\u7684\u52a8\u4f5c\u7a7a\u95f4\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5728\u673a\u5668\u4eba\u63a7\u5236\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5728\u673a\u5668\u4eba\u63a7\u5236\u548c\u8d44\u6e90\u5206\u914d\u7b49\u5e94\u7528\u4e2d\uff0c\u786e\u4fdd\u5b89\u5168\u884c\u4e3a\u9700\u8981\u5b66\u4e60\u5e26\u6709\u52a8\u4f5c\u7ea6\u675f\u7684\u7b56\u7565\u3002\u5f53\u6a21\u4eff\u8005\u52a8\u4f5c\u7a7a\u95f4\u5c0f\u4e8e\u4e13\u5bb6\u65f6\uff0c\u4f1a\u5bfc\u81f4\u5360\u7528\u5ea6\u91cf\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faDTWIL\u65b9\u6cd5\uff0c\u5c06\u8f68\u8ff9\u5bf9\u9f50\u91cd\u65b0\u8868\u8ff0\u4e3a\u89c4\u5212\u95ee\u9898\uff0c\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\u548c\u52a8\u6001\u65f6\u95f4\u89c4\u6574\uff08DTW\uff09\u8ddd\u79bb\u6765\u751f\u6210\u9075\u5faa\u7c7b\u4f3c\u72b6\u6001\u8f68\u8ff9\u4f46\u7b26\u5408\u52a8\u4f5c\u7ea6\u675f\u7684\u66ff\u4ee3\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528DTWIL\u751f\u6210\u7684\u6570\u636e\u96c6\u5b66\u4e60\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u591a\u4e2a\u673a\u5668\u4eba\u63a7\u5236\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5728\u6837\u672c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u5404\u79cd\u57fa\u51c6\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\u3002", "conclusion": "DTWIL\u901a\u8fc7\u6709\u6548\u7684\u8f68\u8ff9\u5bf9\u9f50\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u52a8\u4f5c\u7ea6\u675f\u6a21\u4eff\u5b66\u4e60\u4e2d\u7684\u5360\u7528\u5ea6\u91cf\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e3a\u5b89\u5168\u673a\u5668\u4eba\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.14380", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14380", "abs": "https://arxiv.org/abs/2508.14380", "authors": ["Nicole Fronda", "Phil Smith", "Bardh Hoxha", "Yash Pant", "Houssam Abbas"], "title": "Fair-CoPlan: Negotiated Flight Planning with Fair Deconfliction for Urban Air Mobility", "comment": "Accepted to IEEE International Conference on Intelligent\n  Transportation Systems (ITSC) 2025", "summary": "Urban Air Mobility (UAM) is an emerging transportation paradigm in which\nUncrewed Aerial Systems (UAS) autonomously transport passengers and goods in\ncities. The UAS have different operators with different, sometimes competing\ngoals, yet must share the airspace. We propose a negotiated, semi-distributed\nflight planner that optimizes UAS' flight lengths {\\em in a fair manner}.\nCurrent flight planners might result in some UAS being given disproportionately\nshorter flight paths at the expense of others. We introduce Fair-CoPlan, a\nplanner in which operators and a Provider of Service to the UAM (PSU) together\ncompute \\emph{fair} flight paths. Fair-CoPlan has three steps: First, the PSU\nconstrains take-off and landing choices for flights based on capacity at and\naround vertiports. Then, operators plan independently under these constraints.\nFinally, the PSU resolves any conflicting paths, optimizing for path length\nfairness. By fairly spreading the cost of deconfliction Fair-CoPlan encourages\nwider participation in UAM, ensures safety of the airspace and the areas below\nit, and promotes greater operator flexibility. We demonstrate Fair-CoPlan\nthrough simulation experiments and find fairer outcomes than a non-fair planner\nwith minor delays as a trade-off.", "AI": {"tldr": "Fair-CoPlan\u662f\u4e00\u4e2a\u7528\u4e8e\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a(UAM)\u7684\u516c\u5e73\u534f\u5546\u5f0f\u98de\u884c\u89c4\u5212\u5668\uff0c\u901a\u8fc7\u8fd0\u8425\u5546\u548c\u670d\u52a1\u63d0\u4f9b\u5546\u534f\u4f5c\u8ba1\u7b97\u516c\u5e73\u7684\u98de\u884c\u8def\u5f84\uff0c\u5728\u8def\u5f84\u957f\u5ea6\u516c\u5e73\u6027\u548c\u8f7b\u5fae\u5ef6\u8fdf\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861", "motivation": "\u5f53\u524d\u98de\u884c\u89c4\u5212\u5668\u53ef\u80fd\u5bfc\u81f4\u67d0\u4e9b\u65e0\u4eba\u673a\u83b7\u5f97\u4e0d\u6210\u6bd4\u4f8b\u7684\u77ed\u8def\u5f84\uff0c\u800c\u727a\u7272\u5176\u4ed6\u65e0\u4eba\u673a\u7684\u5229\u76ca\uff0c\u9700\u8981\u4e00\u79cd\u516c\u5e73\u7684\u65b9\u5f0f\u6765\u4f18\u5316\u98de\u884c\u8def\u5f84\u957f\u5ea6", "method": "\u4e09\u6b65\u6cd5\uff1a1)\u670d\u52a1\u63d0\u4f9b\u5546\u57fa\u4e8e\u5782\u76f4\u8d77\u964d\u573a\u5bb9\u91cf\u7ea6\u675f\u8d77\u964d\u9009\u62e9\uff1b2)\u8fd0\u8425\u5546\u5728\u7ea6\u675f\u4e0b\u72ec\u7acb\u89c4\u5212\uff1b3)\u670d\u52a1\u63d0\u4f9b\u5546\u89e3\u51b3\u8def\u5f84\u51b2\u7a81\uff0c\u4f18\u5316\u8def\u5f84\u957f\u5ea6\u516c\u5e73\u6027", "result": "\u4eff\u771f\u5b9e\u9a8c\u663e\u793a\u6bd4\u975e\u516c\u5e73\u89c4\u5212\u5668\u4ea7\u751f\u66f4\u516c\u5e73\u7684\u7ed3\u679c\uff0c\u4ee5\u8f7b\u5fae\u5ef6\u8fdf\u4e3a\u4ee3\u4ef7", "conclusion": "Fair-CoPlan\u901a\u8fc7\u516c\u5e73\u5206\u644a\u51b2\u7a81\u89e3\u51b3\u6210\u672c\uff0c\u9f13\u52b1\u66f4\u5e7f\u6cdb\u53c2\u4e0eUAM\uff0c\u786e\u4fdd\u7a7a\u57df\u5b89\u5168\uff0c\u5e76\u63d0\u5347\u8fd0\u8425\u5546\u7075\u6d3b\u6027"}}
{"id": "2508.14381", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14381", "abs": "https://arxiv.org/abs/2508.14381", "authors": ["Nicole Fronda", "Bardh Hoxha", "Houssam Abbas"], "title": "FiReFly: Fair Distributed Receding Horizon Planning for Multiple UAVs", "comment": "Accepted to IEEE International Conference on Intelligent\n  Transportation Systems (ITSC) 2025", "summary": "We propose injecting notions of fairness into multi-robot motion planning.\nWhen robots have competing interests, it is important to optimize for some kind\nof fairness in their usage of resources. In this work, we explore how the\nrobots' energy expenditures might be fairly distributed among them, while\nmaintaining mission success. We formulate a distributed fair motion planner and\nintegrate it with safe controllers in a algorithm called FiReFly. For simulated\nreach-avoid missions, FiReFly produces fairer trajectories and improves mission\nsuccess rates over a non-fair planner. We find that real-time performance is\nachievable up to 15 UAVs, and that scaling up to 50 UAVs is possible with\ntrade-offs between runtime and fairness improvements.", "AI": {"tldr": "\u5728\u591a\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u4e2d\u6ce8\u5165\u516c\u5e73\u6027\u6982\u5ff5\uff0c\u63d0\u51faFiReFly\u7b97\u6cd5\uff0c\u5728\u6a21\u62df\u7684\u5230\u8fbe-\u89c4\u907f\u4efb\u52a1\u4e2d\u4ea7\u751f\u66f4\u516c\u5e73\u7684\u8f68\u8ff9\u5e76\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387", "motivation": "\u5f53\u673a\u5668\u4eba\u5b58\u5728\u7ade\u4e89\u5229\u76ca\u65f6\uff0c\u9700\u8981\u4f18\u5316\u8d44\u6e90\u4f7f\u7528\u7684\u516c\u5e73\u6027\uff0c\u7279\u522b\u662f\u80fd\u91cf\u6d88\u8017\u7684\u516c\u5e73\u5206\u914d\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6210\u529f", "method": "\u5236\u5b9a\u5206\u5e03\u5f0f\u516c\u5e73\u8fd0\u52a8\u89c4\u5212\u5668\uff0c\u5e76\u4e0e\u5b89\u5168\u63a7\u5236\u5668\u96c6\u6210\uff0c\u5f62\u6210FiReFly\u7b97\u6cd5", "result": "FiReFly\u4ea7\u751f\u66f4\u516c\u5e73\u7684\u8f68\u8ff9\uff0c\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5b9e\u65f6\u6027\u80fd\u53ef\u8fbe15\u4e2a\u65e0\u4eba\u673a\uff0c\u6269\u5c55\u523050\u4e2a\u65e0\u4eba\u673a\u9700\u8981\u5728\u8fd0\u884c\u65f6\u95f4\u548c\u516c\u5e73\u6027\u6539\u8fdb\u4e4b\u95f4\u6743\u8861", "conclusion": "\u5728\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u5f15\u5165\u516c\u5e73\u6027\u6982\u5ff5\u662f\u53ef\u884c\u7684\uff0cFiReFly\u7b97\u6cd5\u80fd\u6709\u6548\u5b9e\u73b0\u516c\u5e73\u7684\u80fd\u91cf\u6d88\u8017\u5206\u914d\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6027\u80fd"}}
{"id": "2508.14383", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14383", "abs": "https://arxiv.org/abs/2508.14383", "authors": ["Haitong Ma", "Bo Dai", "Zhaolin Ren", "Yebin Wang", "Na Li"], "title": "Offline Imitation Learning upon Arbitrary Demonstrations by Pre-Training Dynamics Representations", "comment": "7 pages, 5 figures", "summary": "Limited data has become a major bottleneck in scaling up offline imitation\nlearning (IL). In this paper, we propose enhancing IL performance under limited\nexpert data by introducing a pre-training stage that learns dynamics\nrepresentations, derived from factorizations of the transition dynamics. We\nfirst theoretically justify that the optimal decision variable of offline IL\nlies in the representation space, significantly reducing the parameters to\nlearn in the downstream IL. Moreover, the dynamics representations can be\nlearned from arbitrary data collected with the same dynamics, allowing the\nreuse of massive non-expert data and mitigating the limited data issues. We\npresent a tractable loss function inspired by noise contrastive estimation to\nlearn the dynamics representations at the pre-training stage. Experiments on\nMuJoCo demonstrate that our proposed algorithm can mimic expert policies with\nas few as a single trajectory. Experiments on real quadrupeds show that we can\nleverage pre-trained dynamics representations from simulator data to learn to\nwalk from a few real-world demonstrations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u9884\u8bad\u7ec3\u5b66\u4e60\u52a8\u6001\u8868\u793a\u6765\u63d0\u5347\u6709\u9650\u4e13\u5bb6\u6570\u636e\u4e0b\u7684\u79bb\u7ebf\u6a21\u4eff\u5b66\u4e60\u6027\u80fd\uff0c\u7406\u8bba\u8bc1\u660e\u6700\u4f18\u51b3\u7b56\u53d8\u91cf\u4f4d\u4e8e\u8868\u793a\u7a7a\u95f4\u4e2d\uff0c\u53ef\u663e\u8457\u51cf\u5c11\u4e0b\u6e38IL\u53c2\u6570\u5b66\u4e60\u91cf\uff0c\u5b9e\u9a8c\u663e\u793a\u4ec5\u9700\u5355\u6761\u8f68\u8ff9\u5373\u53ef\u6a21\u4eff\u4e13\u5bb6\u7b56\u7565", "motivation": "\u6709\u9650\u6570\u636e\u5df2\u6210\u4e3a\u6269\u5c55\u79bb\u7ebf\u6a21\u4eff\u5b66\u4e60\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u9700\u8981\u89e3\u51b3\u4e13\u5bb6\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898", "method": "\u5f15\u5165\u9884\u8bad\u7ec3\u9636\u6bb5\u5b66\u4e60\u52a8\u6001\u8868\u793a\uff08\u6765\u81ea\u8f6c\u79fb\u52a8\u6001\u7684\u5206\u89e3\uff09\uff0c\u4f7f\u7528\u566a\u58f0\u5bf9\u6bd4\u4f30\u8ba1\u7684\u635f\u5931\u51fd\u6570\uff0c\u53ef\u4ece\u4efb\u610f\u540c\u52a8\u6001\u6570\u636e\u4e2d\u5b66\u4e60\u8868\u793a", "result": "MuJoCo\u5b9e\u9a8c\u663e\u793a\u4ec5\u9700\u5355\u6761\u8f68\u8ff9\u5373\u53ef\u6a21\u4eff\u4e13\u5bb6\u7b56\u7565\uff0c\u771f\u5b9e\u56db\u8db3\u673a\u5668\u4eba\u5b9e\u9a8c\u8868\u660e\u53ef\u5229\u7528\u6a21\u62df\u5668\u9884\u8bad\u7ec3\u8868\u793a\u4ece\u5c11\u91cf\u771f\u5b9e\u6f14\u793a\u4e2d\u5b66\u4e60\u884c\u8d70", "conclusion": "\u52a8\u6001\u8868\u793a\u9884\u8bad\u7ec3\u80fd\u6709\u6548\u7f13\u89e3\u79bb\u7ebf\u6a21\u4eff\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u9650\u5236\u95ee\u9898\uff0c\u5b9e\u73b0\u4ece\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u5b66\u4e60"}}
{"id": "2508.14387", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14387", "abs": "https://arxiv.org/abs/2508.14387", "authors": ["Yuxiao Zhu", "Junfeng Chen", "Xintong Zhang", "Meng Guo", "Zhongkui Li"], "title": "DEXTER-LLM: Dynamic and Explainable Coordination of Multi-Robot Systems in Unknown Environments via Large Language Models", "comment": "submitted to IROS 2025", "summary": "Online coordination of multi-robot systems in open and unknown environments\nfaces significant challenges, particularly when semantic features detected\nduring operation dynamically trigger new tasks. Recent large language model\n(LLMs)-based approaches for scene reasoning and planning primarily focus on\none-shot, end-to-end solutions in known environments, lacking both dynamic\nadaptation capabilities for online operation and explainability in the\nprocesses of planning. To address these issues, a novel framework (DEXTER-LLM)\nfor dynamic task planning in unknown environments, integrates four modules: (i)\na mission comprehension module that resolves partial ordering of tasks\nspecified by natural languages or linear temporal logic formulas (LTL); (ii) an\nonline subtask generator based on LLMs that improves the accuracy and\nexplainability of task decomposition via multi-stage reasoning; (iii) an\noptimal subtask assigner and scheduler that allocates subtasks to robots via\nsearch-based optimization; and (iv) a dynamic adaptation and human-in-the-loop\nverification module that implements multi-rate, event-based updates for both\nsubtasks and their assignments, to cope with new features and tasks detected\nonline. The framework effectively combines LLMs' open-world reasoning\ncapabilities with the optimality of model-based assignment methods,\nsimultaneously addressing the critical issue of online adaptability and\nexplainability. Experimental evaluations demonstrate exceptional performances,\nwith 100% success rates across all scenarios, 160 tasks and 480 subtasks\ncompleted on average (3 times the baselines), 62% less queries to LLMs during\nadaptation, and superior plan quality (2 times higher) for compound tasks.\nProject page at https://tcxm.github.io/DEXTER-LLM/", "AI": {"tldr": "DEXTER-LLM\u662f\u4e00\u4e2a\u7528\u4e8e\u672a\u77e5\u73af\u5883\u4e2d\u52a8\u6001\u4efb\u52a1\u89c4\u5212\u7684\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u4e86LLM\u7684\u5f00\u653e\u4e16\u754c\u63a8\u7406\u80fd\u529b\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u5728\u7ebf\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u573a\u666f\u63a8\u7406\u548c\u89c4\u5212\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5df2\u77e5\u73af\u5883\u7684\u4e00\u6b21\u6027\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\uff0c\u7f3a\u4e4f\u5728\u7ebf\u64cd\u4f5c\u7684\u52a8\u6001\u9002\u5e94\u80fd\u529b\u548c\u89c4\u5212\u8fc7\u7a0b\u7684\u53ef\u89e3\u91ca\u6027", "method": "\u96c6\u6210\u56db\u4e2a\u6a21\u5757\uff1a\u4efb\u52a1\u7406\u89e3\u6a21\u5757\u3001\u57fa\u4e8eLLM\u7684\u5728\u7ebf\u5b50\u4efb\u52a1\u751f\u6210\u5668\u3001\u6700\u4f18\u5b50\u4efb\u52a1\u5206\u914d\u5668\u548c\u8c03\u5ea6\u5668\u3001\u52a8\u6001\u9002\u5e94\u548c\u4eba\u673a\u9a8c\u8bc1\u6a21\u5757", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a100%\u6210\u529f\u7387\uff0c\u5e73\u5747\u5b8c\u6210160\u4e2a\u4efb\u52a1\u548c480\u4e2a\u5b50\u4efb\u52a1\uff08\u57fa\u7ebf3\u500d\uff09\uff0c\u9002\u5e94\u8fc7\u7a0b\u4e2dLLM\u67e5\u8be2\u51cf\u5c1162%\uff0c\u590d\u5408\u4efb\u52a1\u89c4\u5212\u8d28\u91cf\u63d0\u9ad82\u500d", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u7ed3\u5408\u4e86LLM\u7684\u5f00\u653e\u4e16\u754c\u63a8\u7406\u80fd\u529b\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u5206\u914d\u65b9\u6cd5\u7684\u6700\u4f18\u6027\uff0c\u540c\u65f6\u89e3\u51b3\u4e86\u5728\u7ebf\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u5173\u952e\u95ee\u9898"}}
{"id": "2508.14441", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14441", "abs": "https://arxiv.org/abs/2508.14441", "authors": ["Yijin Chen", "Wenqiang Xu", "Zhenjun Yu", "Tutian Tang", "Yutong Li", "Siqiong Yao", "Cewu Lu"], "title": "FBI: Learning Dexterous In-hand Manipulation with Dynamic Visuotactile Shortcut Policy", "comment": null, "summary": "Dexterous in-hand manipulation is a long-standing challenge in robotics due\nto complex contact dynamics and partial observability. While humans synergize\nvision and touch for such tasks, robotic approaches often prioritize one\nmodality, therefore limiting adaptability. This paper introduces Flow Before\nImitation (FBI), a visuotactile imitation learning framework that dynamically\nfuses tactile interactions with visual observations through motion dynamics.\nUnlike prior static fusion methods, FBI establishes a causal link between\ntactile signals and object motion via a dynamics-aware latent model. FBI\nemploys a transformer-based interaction module to fuse flow-derived tactile\nfeatures with visual inputs, training a one-step diffusion policy for real-time\nexecution. Extensive experiments demonstrate that the proposed method\noutperforms the baseline methods in both simulation and the real world on two\ncustomized in-hand manipulation tasks and three standard dexterous manipulation\ntasks. Code, models, and more results are available in the website\nhttps://sites.google.com/view/dex-fbi.", "AI": {"tldr": "FBI\u662f\u4e00\u4e2a\u89c6\u89c9\u89e6\u89c9\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8fd0\u52a8\u52a8\u529b\u5b66\u52a8\u6001\u878d\u5408\u89e6\u89c9\u4ea4\u4e92\u548c\u89c6\u89c9\u89c2\u5bdf\uff0c\u89e3\u51b3\u4e86\u7075\u5de7\u624b\u5185\u64cd\u4f5c\u7684\u6311\u6218\u3002", "motivation": "\u7075\u5de7\u624b\u5185\u64cd\u4f5c\u7531\u4e8e\u590d\u6742\u7684\u63a5\u89e6\u52a8\u529b\u5b66\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u4e00\u76f4\u662f\u673a\u5668\u4eba\u5b66\u7684\u6311\u6218\u3002\u4eba\u7c7b\u80fd\u591f\u534f\u540c\u4f7f\u7528\u89c6\u89c9\u548c\u89e6\u89c9\u5b8c\u6210\u6b64\u7c7b\u4efb\u52a1\uff0c\u800c\u673a\u5668\u4eba\u65b9\u6cd5\u5f80\u5f80\u53ea\u4f18\u5148\u8003\u8651\u4e00\u79cd\u6a21\u6001\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u3002", "method": "FBI\u901a\u8fc7\u52a8\u6001\u611f\u77e5\u6f5c\u5728\u6a21\u578b\u5efa\u7acb\u89e6\u89c9\u4fe1\u53f7\u4e0e\u7269\u4f53\u8fd0\u52a8\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u4f7f\u7528\u57fa\u4e8etransformer\u7684\u4ea4\u4e92\u6a21\u5757\u5c06\u57fa\u4e8e\u6d41\u7684\u89e6\u89c9\u7279\u5f81\u4e0e\u89c6\u89c9\u8f93\u5165\u878d\u5408\uff0c\u8bad\u7ec3\u4e00\u6b65\u6269\u6563\u7b56\u7565\u8fdb\u884c\u5b9e\u65f6\u6267\u884c\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u5b9a\u5236\u7684\u624b\u5185\u64cd\u4f5c\u4efb\u52a1\u548c\u4e09\u4e2a\u6807\u51c6\u7075\u5de7\u64cd\u4f5c\u4efb\u52a1\u4e0a\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u4e2d\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FBI\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u878d\u5408\u89c6\u89c9\u548c\u89e6\u89c9\u4fe1\u606f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u673a\u5668\u4eba\u7075\u5de7\u64cd\u4f5c\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u878d\u5408\u5728\u590d\u6742\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.14542", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14542", "abs": "https://arxiv.org/abs/2508.14542", "authors": ["Weize Li", "Zhengxiao Han", "Lixin Xu", "Xiangyu Chen", "Harrison Bounds", "Chenrui Zhang", "Yifan Xu"], "title": "Taming VR Teleoperation and Learning from Demonstration for Multi-Task Bimanual Table Service Manipulation", "comment": "Technical report of First-place/Champion solution at IEEE ICRA 2025\n  What Bimanuals Can Do (WBCD) Challenge - Table Services Track", "summary": "This technical report presents the champion solution of the Table Service\nTrack in the ICRA 2025 What Bimanuals Can Do (WBCD) competition. We tackled a\nseries of demanding tasks under strict requirements for speed, precision, and\nreliability: unfolding a tablecloth (deformable-object manipulation), placing a\npizza onto the table (pick-and-place), and opening and closing a food container\nwith the lid. Our solution combines VR-based teleoperation and Learning from\nDemonstrations (LfD) to balance robustness and autonomy. Most subtasks were\nexecuted through high-fidelity remote teleoperation, while the pizza placement\nwas handled by an ACT-based policy trained from 100 in-person teleoperated\ndemonstrations with randomized initial configurations. By carefully integrating\nscoring rules, task characteristics, and current technical capabilities, our\napproach achieved both high efficiency and reliability, ultimately securing the\nfirst place in the competition.", "AI": {"tldr": "ICRA 2025 WBCD\u7ade\u8d5b\u684c\u9762\u670d\u52a1\u8d5b\u9053\u51a0\u519b\u65b9\u6848\uff0c\u7ed3\u5408VR\u9065\u64cd\u4f5c\u548c\u6a21\u4eff\u5b66\u4e60\uff0c\u5b8c\u6210\u684c\u5e03\u5c55\u5f00\u3001\u62ab\u8428\u653e\u7f6e\u548c\u98df\u54c1\u5bb9\u5668\u5f00\u5173\u7b49\u4efb\u52a1\uff0c\u83b7\u5f97\u7b2c\u4e00\u540d", "motivation": "\u89e3\u51b3\u684c\u9762\u670d\u52a1\u4efb\u52a1\u4e2d\u5bf9\u901f\u5ea6\u3001\u7cbe\u5ea6\u548c\u53ef\u9760\u6027\u7684\u4e25\u683c\u8981\u6c42\uff0c\u5e73\u8861\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u9c81\u68d2\u6027\u548c\u81ea\u4e3b\u6027", "method": "\u7ed3\u5408VR\u9065\u64cd\u4f5c\u548c\u6a21\u4eff\u5b66\u4e60\uff08LfD\uff09\uff0c\u5927\u90e8\u5206\u5b50\u4efb\u52a1\u901a\u8fc7\u9ad8\u4fdd\u771f\u8fdc\u7a0b\u9065\u64cd\u4f5c\u5b8c\u6210\uff0c\u62ab\u8428\u653e\u7f6e\u4efb\u52a1\u4f7f\u7528\u57fa\u4e8eACT\u7684\u7b56\u7565\uff0c\u901a\u8fc7100\u6b21\u73b0\u573a\u9065\u64cd\u4f5c\u6f14\u793a\u8bad\u7ec3", "result": "\u65b9\u6848\u5b9e\u73b0\u4e86\u9ad8\u6548\u7387\u548c\u9ad8\u53ef\u9760\u6027\uff0c\u5728ICRA 2025 WBCD\u7ade\u8d5b\u684c\u9762\u670d\u52a1\u8d5b\u9053\u4e2d\u83b7\u5f97\u7b2c\u4e00\u540d", "conclusion": "\u901a\u8fc7\u7cbe\u5fc3\u6574\u5408\u8bc4\u5206\u89c4\u5219\u3001\u4efb\u52a1\u7279\u6027\u548c\u5f53\u524d\u6280\u672f\u80fd\u529b\uff0c\u7ed3\u5408\u9065\u64cd\u4f5c\u548c\u6a21\u4eff\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u590d\u6742\u684c\u9762\u670d\u52a1\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272"}}
{"id": "2508.14554", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14554", "abs": "https://arxiv.org/abs/2508.14554", "authors": ["Xinkai Liang", "Yigu Ge", "Yangxi Shi", "Haoyu Yang", "Xu Cao", "Hao Fang"], "title": "EAROL: Environmental Augmented Perception-Aware Planning and Robust Odometry via Downward-Mounted Tilted LiDAR", "comment": "Accepted by 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025). This work has been submitted to the IEEE for\n  possible publication", "summary": "To address the challenges of localization drift and perception-planning\ncoupling in unmanned aerial vehicles (UAVs) operating in open-top scenarios\n(e.g., collapsed buildings, roofless mazes), this paper proposes EAROL, a novel\nframework with a downward-mounted tilted LiDAR configuration (20{\\deg}\ninclination), integrating a LiDAR-Inertial Odometry (LIO) system and a\nhierarchical trajectory-yaw optimization algorithm. The hardware innovation\nenables constraint enhancement via dense ground point cloud acquisition and\nforward environmental awareness for dynamic obstacle detection. A\ntightly-coupled LIO system, empowered by an Iterative Error-State Kalman Filter\n(IESKF) with dynamic motion compensation, achieves high level 6-DoF\nlocalization accuracy in feature-sparse environments. The planner, augmented by\nenvironment, balancing environmental exploration, target tracking precision,\nand energy efficiency. Physical experiments demonstrate 81% tracking error\nreduction, 22% improvement in perceptual coverage, and near-zero vertical drift\nacross indoor maze and 60-meter-scale outdoor scenarios. This work proposes a\nhardware-algorithm co-design paradigm, offering a robust solution for UAV\nautonomy in post-disaster search and rescue missions. We will release our\nsoftware and hardware as an open-source package for the community. Video:\nhttps://youtu.be/7av2ueLSiYw.", "AI": {"tldr": "EAROL\u662f\u4e00\u4e2a\u9488\u5bf9\u5f00\u653e\u573a\u666f\u65e0\u4eba\u673a\u7684\u65b0\u578b\u6846\u67b6\uff0c\u91c7\u7528\u4e0b\u503e20\u5ea6LiDAR\u914d\u7f6e\uff0c\u7ed3\u5408\u6fc0\u5149\u60ef\u6027\u91cc\u7a0b\u8ba1\u548c\u5206\u5c42\u8f68\u8ff9\u4f18\u5316\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u5b9a\u4f4d\u6f02\u79fb\u548c\u611f\u77e5-\u89c4\u5212\u8026\u5408\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u65e0\u4eba\u673a\u5728\u5f00\u653e\u573a\u666f\uff08\u5982\u5012\u584c\u5efa\u7b51\u3001\u65e0\u9876\u8ff7\u5bab\uff09\u4e2d\u9762\u4e34\u7684\u5b9a\u4f4d\u6f02\u79fb\u548c\u611f\u77e5-\u89c4\u5212\u8026\u5408\u6311\u6218\uff0c\u4e3a\u707e\u540e\u641c\u6551\u4efb\u52a1\u63d0\u4f9b\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u786c\u4ef6\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\uff1a\u4e0b\u503e20\u5ea6LiDAR\u914d\u7f6e\u5b9e\u73b0\u5bc6\u96c6\u5730\u9762\u70b9\u4e91\u91c7\u96c6\u548c\u524d\u65b9\u73af\u5883\u611f\u77e5\uff1b\u7d27\u8026\u5408LIO\u7cfb\u7edf\u4f7f\u7528\u8fed\u4ee3\u8bef\u5dee\u72b6\u6001\u5361\u5c14\u66fc\u6ee4\u6ce2\uff1b\u5206\u5c42\u8f68\u8ff9-\u504f\u822a\u4f18\u5316\u7b97\u6cd5\u5e73\u8861\u73af\u5883\u63a2\u7d22\u3001\u76ee\u6807\u8ddf\u8e2a\u548c\u80fd\u6548\u3002", "result": "\u7269\u7406\u5b9e\u9a8c\u663e\u793a\uff1a\u8ddf\u8e2a\u8bef\u5dee\u51cf\u5c1181%\uff0c\u611f\u77e5\u8986\u76d6\u7387\u63d0\u534722%\uff0c\u5728\u5ba4\u5185\u8ff7\u5bab\u548c60\u7c73\u5c3a\u5ea6\u5ba4\u5916\u573a\u666f\u4e2d\u5b9e\u73b0\u8fd1\u96f6\u5782\u76f4\u6f02\u79fb\u3002", "conclusion": "\u63d0\u51fa\u4e86\u786c\u4ef6\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u8303\u5f0f\uff0c\u4e3a\u65e0\u4eba\u673a\u5728\u707e\u540e\u641c\u6551\u4efb\u52a1\u4e2d\u7684\u81ea\u4e3b\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c06\u5f00\u6e90\u8f6f\u4ef6\u548c\u786c\u4ef6\u3002"}}
{"id": "2508.14610", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14610", "abs": "https://arxiv.org/abs/2508.14610", "authors": ["Junzhi Li", "Teng Long", "Jingliang Sun", "Jianxin Zhong"], "title": "TRUST-Planner: Topology-guided Robust Trajectory Planner for AAVs with Uncertain Obstacle Spatial-temporal Avoidance", "comment": null, "summary": "Despite extensive developments in motion planning of autonomous aerial\nvehicles (AAVs), existing frameworks faces the challenges of local minima and\ndeadlock in complex dynamic environments, leading to increased collision risks.\nTo address these challenges, we present TRUST-Planner, a topology-guided\nhierarchical planning framework for robust spatial-temporal obstacle avoidance.\nIn the frontend, a dynamic enhanced visible probabilistic roadmap (DEV-PRM) is\nproposed to rapidly explore topological paths for global guidance. The backend\nutilizes a uniform terminal-free minimum control polynomial (UTF-MINCO) and\ndynamic distance field (DDF) to enable efficient predictive obstacle avoidance\nand fast parallel computation. Furthermore, an incremental multi-branch\ntrajectory management framework is introduced to enable spatio-temporal\ntopological decision-making, while efficiently leveraging historical\ninformation to reduce replanning time. Simulation results show that\nTRUST-Planner outperforms baseline competitors, achieving a 96\\% success rate\nand millisecond-level computation efficiency in tested complex environments.\nReal-world experiments further validate the feasibility and practicality of the\nproposed method.", "AI": {"tldr": "TRUST-Planner\u662f\u4e00\u4e2a\u62d3\u6251\u5f15\u5bfc\u7684\u5206\u5c42\u89c4\u5212\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u81ea\u4e3b\u98de\u884c\u5668\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5c40\u90e8\u6700\u5c0f\u503c\u548c\u6b7b\u9501\u95ee\u9898\uff0c\u901a\u8fc7\u524d\u7aefDEV-PRM\u548c\u540e\u7aefUTF-MINCO+DDF\u5b9e\u73b0\u9ad8\u6548\u907f\u969c\u548c\u5e76\u884c\u8ba1\u7b97\u3002", "motivation": "\u73b0\u6709\u81ea\u4e3b\u98de\u884c\u5668\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u9762\u4e34\u5c40\u90e8\u6700\u5c0f\u503c\u548c\u6b7b\u9501\u6311\u6218\uff0c\u5bfc\u81f4\u78b0\u649e\u98ce\u9669\u589e\u52a0\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u65f6\u7a7a\u907f\u969c\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u89c4\u5212\u6846\u67b6\uff1a\u524d\u7aef\u4f7f\u7528\u52a8\u6001\u589e\u5f3a\u53ef\u89c1\u6982\u7387\u8def\u7ebf\u56fe(DEV-PRM)\u5feb\u901f\u63a2\u7d22\u62d3\u6251\u8def\u5f84\uff1b\u540e\u7aef\u91c7\u7528\u7edf\u4e00\u65e0\u7ec8\u7aef\u6700\u5c0f\u63a7\u5236\u591a\u9879\u5f0f(UTF-MINCO)\u548c\u52a8\u6001\u8ddd\u79bb\u573a(DDF)\u5b9e\u73b0\u9884\u6d4b\u6027\u907f\u969c\uff1b\u5f15\u5165\u589e\u91cf\u591a\u5206\u652f\u8f68\u8ff9\u7ba1\u7406\u6846\u67b6\u8fdb\u884c\u65f6\u7a7a\u62d3\u6251\u51b3\u7b56\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793aTRUST-Planner\u5728\u590d\u6742\u73af\u5883\u4e2d\u8fbe\u523096%\u7684\u6210\u529f\u7387\u548c\u6beb\u79d2\u7ea7\u8ba1\u7b97\u6548\u7387\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff1b\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "TRUST-Planner\u901a\u8fc7\u62d3\u6251\u5f15\u5bfc\u7684\u5206\u5c42\u89c4\u5212\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u4e3b\u98de\u884c\u5668\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u89c4\u5212\u6311\u6218\uff0c\u5177\u6709\u9ad8\u6210\u529f\u7387\u548c\u5b9e\u65f6\u8ba1\u7b97\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.14636", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14636", "abs": "https://arxiv.org/abs/2508.14636", "authors": ["Sanjeev Ramkumar Sudha", "Marija Popovi\u0107", "Erlend M. Coates"], "title": "An Informative Planning Framework for Target Tracking and Active Mapping in Dynamic Environments with ASVs", "comment": "Submitted to IEEE Robotics and Automation Letters (RA-L)", "summary": "Mobile robot platforms are increasingly being used to automate information\ngathering tasks such as environmental monitoring. Efficient target tracking in\ndynamic environments is critical for applications such as search and rescue and\npollutant cleanups. In this letter, we study active mapping of floating targets\nthat drift due to environmental disturbances such as wind and currents. This is\na challenging problem as it involves predicting both spatial and temporal\nvariations in the map due to changing conditions. We propose an informative\npath planning framework to map an arbitrary number of moving targets with\ninitially unknown positions in dynamic environments. A key component of our\napproach is a spatiotemporal prediction network that predicts target position\ndistributions over time. We propose an adaptive planning objective for target\ntracking that leverages these predictions. Simulation experiments show that our\nproposed planning objective improves target tracking performance compared to\nexisting methods that consider only entropy reduction as the planning\nobjective. Finally, we validate our approach in field tests using an autonomous\nsurface vehicle, showcasing its ability to track targets in real-world\nmonitoring scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u52a8\u6001\u73af\u5883\u4e2d\u79fb\u52a8\u76ee\u6807\u4e3b\u52a8\u6620\u5c04\u7684\u4fe1\u606f\u8def\u5f84\u89c4\u5212\u6846\u67b6\uff0c\u5305\u542b\u65f6\u7a7a\u9884\u6d4b\u7f51\u7edc\u548c\u81ea\u9002\u5e94\u89c4\u5212\u76ee\u6807\uff0c\u5728\u4eff\u771f\u548c\u5b9e\u5730\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u79fb\u52a8\u673a\u5668\u4eba\u5728\u73af\u5883\u76d1\u6d4b\u7b49\u4efb\u52a1\u4e2d\u9700\u8981\u9ad8\u6548\u8ddf\u8e2a\u52a8\u6001\u76ee\u6807\uff0c\u4f46\u6f02\u6d6e\u76ee\u6807\u53d7\u73af\u5883\u5e72\u6270\uff08\u98ce\u3001\u6c34\u6d41\uff09\u800c\u6f02\u79fb\uff0c\u6d89\u53ca\u65f6\u7a7a\u53d8\u5316\u7684\u9884\u6d4b\uff0c\u8fd9\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898", "method": "\u63d0\u51fa\u4fe1\u606f\u8def\u5f84\u89c4\u5212\u6846\u67b6\uff0c\u5305\u542b\u65f6\u7a7a\u9884\u6d4b\u7f51\u7edc\u6765\u9884\u6d4b\u76ee\u6807\u4f4d\u7f6e\u5206\u5e03\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u4ee5\u53ca\u81ea\u9002\u5e94\u89c4\u5212\u76ee\u6807\u7528\u4e8e\u76ee\u6807\u8ddf\u8e2a", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u4ec5\u8003\u8651\u71b5\u51cf\u7684\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u51fa\u7684\u89c4\u5212\u76ee\u6807\u63d0\u9ad8\u4e86\u76ee\u6807\u8ddf\u8e2a\u6027\u80fd\u3002\u901a\u8fc7\u81ea\u4e3b\u6c34\u9762\u8f66\u8f86\u8fdb\u884c\u5b9e\u5730\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5728\u771f\u5b9e\u76d1\u6d4b\u573a\u666f\u4e2d\u7684\u8ddf\u8e2a\u80fd\u529b", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u6620\u5c04\u52a8\u6001\u73af\u5883\u4e2d\u4efb\u610f\u6570\u91cf\u521d\u59cb\u4f4d\u7f6e\u672a\u77e5\u7684\u79fb\u52a8\u76ee\u6807\uff0c\u5728\u52a8\u6001\u73af\u5883\u76d1\u6d4b\u5e94\u7528\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c"}}
{"id": "2508.14661", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14661", "abs": "https://arxiv.org/abs/2508.14661", "authors": ["Alexander Raab", "Stephan Weiss", "Alessandro Fornasier", "Christian Brommer", "Abdalrahman Ibrahim"], "title": "Consistent Pose Estimation of Unmanned Ground Vehicles through Terrain-Aided Multi-Sensor Fusion on Geometric Manifolds", "comment": null, "summary": "Aiming to enhance the consistency and thus long-term accuracy of Extended\nKalman Filters for terrestrial vehicle localization, this paper introduces the\nManifold Error State Extended Kalman Filter (M-ESEKF). By representing the\nrobot's pose in a space with reduced dimensionality, the approach ensures\nfeasible estimates on generic smooth surfaces, without introducing artificial\nconstraints or simplifications that may degrade a filter's performance. The\naccompanying measurement models are compatible with common loosely- and\ntightly-coupled sensor modalities and also implicitly account for the ground\ngeometry. We extend the formulation by introducing a novel correction scheme\nthat embeds additional domain knowledge into the sensor data, giving more\naccurate uncertainty approximations and further enhancing filter consistency.\nThe proposed estimator is seamlessly integrated into a validated modular state\nestimation framework, demonstrating compatibility with existing\nimplementations. Extensive Monte Carlo simulations across diverse scenarios and\ndynamic sensor configurations show that the M-ESEKF outperforms classical\nfilter formulations in terms of consistency and stability. Moreover, it\neliminates the need for scenario-specific parameter tuning, enabling its\napplication in a variety of real-world settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86M-ESEKF\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u5728\u964d\u7ef4\u6d41\u5f62\u7a7a\u95f4\u4e2d\u8868\u793a\u673a\u5668\u4eba\u4f4d\u59ff\uff0c\u63d0\u9ad8\u4e86\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5728\u9646\u5730\u8f66\u8f86\u5b9a\u4f4d\u4e2d\u7684\u4e00\u81f4\u6027\u548c\u957f\u671f\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5728\u9646\u5730\u8f66\u8f86\u5b9a\u4f4d\u4e2d\u5b58\u5728\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u9700\u8981\u589e\u5f3a\u5176\u957f\u671f\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u4f7f\u7528\u6d41\u5f62\u8bef\u5dee\u72b6\u6001\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2(M-ESEKF)\uff0c\u5728\u964d\u7ef4\u7a7a\u95f4\u4e2d\u8868\u793a\u4f4d\u59ff\uff0c\u5e76\u5f15\u5165\u65b0\u9896\u7684\u6821\u6b63\u65b9\u6848\u5d4c\u5165\u9886\u57df\u77e5\u8bc6\u5230\u4f20\u611f\u5668\u6570\u636e\u4e2d\u3002", "result": "\u5e7f\u6cdb\u7684\u8499\u7279\u5361\u6d1b\u6a21\u62df\u663e\u793a\uff0cM-ESEKF\u5728\u4e00\u81f4\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u4f18\u4e8e\u7ecf\u5178\u6ee4\u6ce2\u5668\uff0c\u4e14\u65e0\u9700\u573a\u666f\u7279\u5b9a\u7684\u53c2\u6570\u8c03\u4f18\u3002", "conclusion": "M-ESEKF\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u5404\u79cd\u5b9e\u9645\u573a\u666f\u4e2d\u5b9e\u73b0\u66f4\u51c6\u786e\u548c\u4e00\u81f4\u7684\u8f66\u8f86\u5b9a\u4f4d\u3002"}}
{"id": "2508.14763", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14763", "abs": "https://arxiv.org/abs/2508.14763", "authors": ["Sagar Parekh", "Casey Grothoff", "Ryan Wright", "Robin White", "Dylan P. Losey"], "title": "Safe and Transparent Robots for Human-in-the-Loop Meat Processing", "comment": null, "summary": "Labor shortages have severely affected the meat processing sector. Automated\ntechnology has the potential to support the meat industry, assist workers, and\nenhance job quality. However, existing automation in meat processing is highly\nspecialized, inflexible, and cost intensive. Instead of forcing manufacturers\nto buy a separate device for each step of the process, our objective is to\ndevelop general-purpose robotic systems that work alongside humans to perform\nmultiple meat processing tasks. Through a recently conducted survey of industry\nexperts, we identified two main challenges associated with integrating these\ncollaborative robots alongside human workers. First, there must be measures to\nensure the safety of human coworkers; second, the coworkers need to understand\nwhat the robot is doing. This paper addresses both challenges by introducing a\nsafety and transparency framework for general-purpose meat processing robots.\nFor safety, we implement a hand-detection system that continuously monitors\nnearby humans. This system can halt the robot in situations where the human\ncomes into close proximity of the operating robot. We also develop an\ninstrumented knife equipped with a force sensor that can differentiate contact\nbetween objects such as meat, bone, or fixtures. For transparency, we introduce\na method that detects the robot's uncertainty about its performance and uses an\nLED interface to communicate that uncertainty to the human. Additionally, we\ndesign a graphical interface that displays the robot's plans and allows the\nhuman to provide feedback on the planned cut. Overall, our framework can ensure\nsafe operation while keeping human workers in-the-loop about the robot's\nactions which we validate through a user study.", "AI": {"tldr": "\u5f00\u53d1\u7528\u4e8e\u8089\u7c7b\u52a0\u5de5\u7684\u5b89\u5168\u900f\u660e\u534f\u4f5c\u673a\u5668\u4eba\u6846\u67b6\uff0c\u89e3\u51b3\u4eba\u529b\u77ed\u7f3a\u95ee\u9898\uff0c\u901a\u8fc7\u624b\u90e8\u68c0\u6d4b\u7cfb\u7edf\u548c\u4eea\u5668\u5316\u5200\u5177\u786e\u4fdd\u5b89\u5168\uff0c\u901a\u8fc7LED\u548c\u56fe\u5f62\u754c\u9762\u63d0\u4f9b\u900f\u660e\u5ea6", "motivation": "\u8089\u7c7b\u52a0\u5de5\u884c\u4e1a\u9762\u4e34\u4e25\u91cd\u4eba\u529b\u77ed\u7f3a\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u8bbe\u5907\u9ad8\u5ea6\u4e13\u4e1a\u5316\u3001\u4e0d\u7075\u6d3b\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u5f00\u53d1\u901a\u7528\u534f\u4f5c\u673a\u5668\u4eba\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u5171\u540c\u5de5\u4f5c", "method": "\u5efa\u7acb\u5b89\u5168\u4e0e\u900f\u660e\u5ea6\u6846\u67b6\uff1a1\uff09\u624b\u90e8\u68c0\u6d4b\u7cfb\u7edf\u76d1\u63a7\u9644\u8fd1\u4eba\u7c7b\u5e76\u505c\u6b62\u673a\u5668\u4eba\uff1b2\uff09\u914d\u5907\u529b\u4f20\u611f\u5668\u7684\u4eea\u5668\u5316\u5200\u5177\u533a\u5206\u63a5\u89e6\u5bf9\u8c61\uff1b3\uff09LED\u754c\u9762\u4f20\u8fbe\u673a\u5668\u4eba\u4e0d\u786e\u5b9a\u6027\uff1b4\uff09\u56fe\u5f62\u754c\u9762\u663e\u793a\u673a\u5668\u4eba\u8ba1\u5212\u5e76\u5141\u8bb8\u4eba\u7c7b\u53cd\u9988", "result": "\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u786e\u4fdd\u5b89\u5168\u64cd\u4f5c\uff0c\u540c\u65f6\u8ba9\u4eba\u7c7b\u5de5\u4eba\u4e86\u89e3\u673a\u5668\u4eba\u7684\u884c\u52a8", "conclusion": "\u8be5\u5b89\u5168\u900f\u660e\u6846\u67b6\u4e3a\u901a\u7528\u8089\u7c7b\u52a0\u5de5\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u786e\u4fdd\u5b89\u5168\u7684\u540c\u65f6\u4fdd\u6301\u4eba\u7c7b\u5de5\u4eba\u7684\u53c2\u4e0e\u548c\u77e5\u60c5"}}
