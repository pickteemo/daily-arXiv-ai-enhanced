<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 42]
- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [From Reasoning to Super-Intelligence: A Search-Theoretic Perspective](https://arxiv.org/abs/2507.15865)
*Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: 本文提出了"勤奋学习者"(Diligent Learner)范式，通过深度优先搜索和验证器指导来改进大语言模型的链式思维推理学习，解决了现有方法在复杂推理任务上的失效问题。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思维(CoT)推理方法如监督微调、强化学习、思维树等在复杂推理任务上经常失效，且缺乏坚实的理论基础。核心障碍包括分布漂移、缺乏嵌入式搜索和指数级推理成本。

Method: 提出"勤奋学习者"学习范式，将推理明确建模为由验证器指导的深度优先搜索过程，支持失败时的回溯机制。该方法能够从自然出现的不完整CoT数据中学习。

Result: 在两个温和且现实的假设条件下，理论证明了勤奋学习者能够高效地从CoT数据中学习，而现有方法在此条件下会失效。该框架为构建可扩展且可靠的推理系统提供了路径。

Conclusion: 勤奋学习者范式为开发具有鲁棒性和可解释性问题解决能力的大型推理模型(LRMs)铺平了道路，能够在自然出现的不完整数据上进行训练，解决了现有CoT学习方法的核心限制。

Abstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing
the problem-solving capabilities of large language models (LLMs). However, the
theoretical foundations of learning from CoT data remain underdeveloped, and
existing approaches -- such as Supervised Fine-Tuning (SFT), Reinforcement
Learning (RL), Tree-of-Thoughts (ToT), and Monte Carlo Tree Search (MCTS) --
often fail on complex reasoning tasks. In this work, we identify core obstacles
that hinder effective CoT learning, including distribution drift, lack of
embedded search, and exponential inference costs. We introduce the Diligent
Learner, a new learning paradigm that explicitly models reasoning as a
depth-first search guided by a validator and supports backtracking upon
failure. Under two mild and realistic assumptions, we prove that the Diligent
Learner can efficiently learn from CoT data while existing methods fail to do
so. This framework offers a path toward building scalable and reliable
reasoning systems trained on naturally occurring, incomplete data -- paving the
way for the development of Large Reasoning Models (LRMs) with robust,
interpretable problem-solving abilities.

</details>


### [2] [Purchase and Production Optimization in a Meat Processing Plant](https://arxiv.org/abs/2507.15866)
*Marek Vlk,Premysl Sucha,Jaroslaw Rudy,Radoslaw Idzikowski*

Main category: cs.AI

TL;DR: 本文针对肉类加工企业的材料采购和加工优化问题，提出了基于整数线性规划的迭代方法，在考虑最小订购量和替代方案最小百分比等实际约束下，能够快速找到最优解决方案。


<details>
  <summary>Details</summary>
Motivation: 食品生产行业，特别是肉类生产部门面临诸多挑战，欧盟能源危机的爆发更是雪上加霜。因此，高效利用投入材料是影响此类企业盈利的关键因素。现有文献主要关注供应链管理，而忽视了生产阶段的优化问题。

Method: 设计了基于整数线性规划的简单迭代方法来解决实际问题实例。该方法考虑了材料处理的替代方式、不同到期日期的材料库存，以及最小订购量和替代方案最小百分比等在当前文献中被广泛忽视的额外约束条件。

Result: 使用肉类加工公司的真实数据进行测试，算法能够在几秒钟内为所有考虑的用例找到最优解。该方法还能够缓解由于数据值范围广泛而导致的数值问题，这些问题在商业求解器中曾经遇到过。

Conclusion: 证明了最小订购量和替代方案最小百分比这两个约束条件都使问题变为NP难问题。提出的迭代方法不仅能够使用开源整数线性规划求解器解决实际问题，还具有快速求解和避免数值问题的优势。

Abstract: The food production industry, especially the meat production sector, faces
many challenges that have even escalated due to the recent outbreak of the
energy crisis in the European Union. Therefore, efficient use of input
materials is an essential aspect affecting the profit of such companies. This
paper addresses an optimization problem concerning the purchase and subsequent
material processing we solved for a meat processing company. Unlike the
majority of existing papers, we do not concentrate on how this problem concerns
supply chain management, but we focus purely on the production stage. The
problem involves the concept of alternative ways of material processing, stock
of material with different expiration dates, and extra constraints widely
neglected in the current literature, namely, the minimum order quantity and the
minimum percentage in alternatives. We prove that each of these two constraints
makes the problem \mbox{$\mathcal{NP}$-hard}, and hence we design a simple
iterative approach based on integer linear programming that allows us to solve
real-life instances even using an open-source integer linear programming
solver. Another advantage of this approach is that it mitigates numerical
issues, caused by the extensive range of data values, we experienced with a
commercial solver. The results obtained using real data from the meat
processing company showed that our algorithm can find the optimum solution in a
few seconds for all considered use cases.

</details>


### [3] [Why Braking? Scenario Extraction and Reasoning Utilizing LLM](https://arxiv.org/abs/2507.15874)
*Yin Wu,Daniel Slieter,Vivek Subramanian,Ahmed Abouelazm,Robin Bohn,J. Marius Zöllner*

Main category: cs.AI

TL;DR: 本文提出了一个基于大语言模型(LLM)的框架来理解和分析驾驶场景中的制动事件，通过双路径场景检索方法能够识别已知场景和未知的分布外场景，在Argoverse 2数据集上的实验表明该方法优于基于规则的基线方法。


<details>
  <summary>Details</summary>
Motivation: 随着ADAS设备车辆数量增长，驾驶数据急剧增加，但大多数数据只是常规驾驶行为。在庞大数据集中识别和理解安全关键的边缘案例仍然是重大挑战。制动事件特别能指示潜在危险情况，因此研究的核心问题是：车辆为什么制动？现有方法主要依赖基于规则的启发式方法，在高速公路等简单环境中有效，但在复杂城市环境中缺乏泛化能力。

Method: 提出了一个利用大语言模型(LLM)进行场景理解和推理的新框架。该方法在低级数值信号和自然语言描述之间建立桥梁，使LLM能够解释和分类驾驶场景。提出了双路径场景检索方法，支持基于类别的已知场景搜索和基于嵌入的未知分布外(OOD)场景检索。在Argoverse 2传感器数据集上策划场景注释以便于评估。

Result: 实验结果表明，该方法优于基于规则的基线方法，并且在分布外(OOD)场景中具有良好的泛化能力。该框架能够有效地识别和分类驾驶场景中的制动事件，特别是在复杂的城市环境中表现出色。

Conclusion: 研究成功开发了一个基于LLM的驾驶场景理解框架，有效解决了传统基于规则方法在复杂环境中泛化能力不足的问题。通过双路径检索机制，该方法不仅能处理已知场景，还能识别未知的边缘案例，为自动驾驶安全关键场景的识别和理解提供了新的解决方案。

Abstract: The growing number of ADAS-equipped vehicles has led to a dramatic increase
in driving data, yet most of them capture routine driving behavior. Identifying
and understanding safety-critical corner cases within this vast dataset remains
a significant challenge. Braking events are particularly indicative of
potentially hazardous situations, motivating the central question of our
research: Why does a vehicle brake? Existing approaches primarily rely on
rule-based heuristics to retrieve target scenarios using predefined condition
filters. While effective in simple environments such as highways, these methods
lack generalization in complex urban settings. In this paper, we propose a
novel framework that leverages Large Language Model (LLM) for scenario
understanding and reasoning. Our method bridges the gap between low-level
numerical signals and natural language descriptions, enabling LLM to interpret
and classify driving scenarios. We propose a dual-path scenario retrieval that
supports both category-based search for known scenarios and embedding-based
retrieval for unknown Out-of-Distribution (OOD) scenarios. To facilitate
evaluation, we curate scenario annotations on the Argoverse 2 Sensor Dataset.
Experimental results show that our method outperforms rule-based baselines and
generalizes well to OOD scenarios.

</details>


### [4] [Differential Multimodal Transformers](https://arxiv.org/abs/2507.15875)
*Jerry Li,Timothy Oh,Joseph Hoang,Vardhit Veeramachaneni*

Main category: cs.AI

TL;DR: 本文将差分注意力机制扩展到文本-视觉模型PaliGemma中，通过LoRA微调方法减少噪声信息检索和幻觉问题，提升小语言模型在多模态任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 小语言模型虽然高效且能力不断增长，但在引入视觉等额外模态时，会因为噪声信息加剧有限上下文窗口的挑战。现有研究表明Transformer注意力机制经常过度关注无关上下文，因此需要改进注意力机制来解决这一问题。

Method: 将原本为纯文本模型设计的差分注意力机制扩展到文本-视觉模型PaliGemma中，使用LoRA方法对PaliGemma 3B模型进行微调，并实验了各种参数设置和配置来集成差分注意力机制。

Result: 实验证明差分注意力机制可以成功适配并集成到现有模型的微调过程中，能够增强噪声信息检索能力和问答性能，有效减少幻觉问题。

Conclusion: 差分注意力机制可以有效地应用于多模态模型的微调中，通过改善注意力分配来减少对无关信息的关注，从而提升模型在处理包含视觉信息的任务时的准确性和可靠性。

Abstract: Small language models have gained significant popularity due to their
efficiency and growing capabilities. However, incorporating additional
modalities, such as vision, can exacerbate the challenge of limited context
windows by introducing noise. Recent studies have highlighted that Transformer
attention mechanisms often disproportionately focus on irrelevant contexts. In
this work, we extend the Differential Attention mechanism, originally designed
for text-only models, to the text-vision model PaliGemma. Our aim is to
evaluate its ability to mitigate noisy information retrieval and reduce
hallucinations. To this end, we fine-tuned the PaliGemma 3B model using LoRA,
incorporating Differential Attention, and experimented with various parameter
settings and configurations. We demonstrate that Differential Attention can be
adapted and integrated into the fine-tuning of existing models to enhance noisy
information retrieval and question-answering capabilities.

</details>


### [5] [Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach](https://arxiv.org/abs/2507.15876)
*Eric Benhamou,Jean-Jacques Ohana,Alban Etienne,Béatrice Guez,Ethan Setrouk,Thomas Jacquot*

Main category: cs.AI

TL;DR: 本文通过贝叶斯图模型动态分解CTA收益，研究短期趋势、长期趋势和市场贝塔因子对策略风险调整收益的影响


<details>
  <summary>Details</summary>
Motivation: 商品交易顾问(CTA)历史上依赖不同时间跨度的趋势跟踪规则，但短期与长期趋势系统的相对优势和相互作用仍存在争议，需要深入研究不同时间跨度趋势策略的影响机制

Method: 采用贝叶斯图模型动态分解CTA收益，将收益分解为短期趋势、长期趋势和市场贝塔三个因子，并分析不同时间跨度组合对策略表现的影响

Result: 通过动态分解方法成功识别出CTA收益中的短期趋势、长期趋势和市场贝塔因子，并揭示了不同时间跨度组合如何影响策略的风险调整收益表现

Conclusion: 不同时间跨度趋势策略的组合方式显著影响CTA策略的风险调整收益，为理解和优化CTA策略提供了新的视角和实证证据

Abstract: Commodity Trading Advisors (CTAs) have historically relied on trend-following
rules that operate on vastly different horizons from long-term breakouts that
capture major directional moves to short-term momentum signals that thrive in
fast-moving markets. Despite a large body of work on trend following, the
relative merits and interactions of short-versus long-term trend systems remain
controversial. This paper adds to the debate by (i) dynamically decomposing CTA
returns into short-term trend, long-term trend and market beta factors using a
Bayesian graphical model, and (ii) showing how the blend of horizons shapes the
strategy's risk-adjusted performance.

</details>


### [6] [Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning](https://arxiv.org/abs/2507.15877)
*Simon Ouellette*

Main category: cs.AI

TL;DR: 研究在ARC-AGI领域比较了神经程序合成和测试时微调方法的组合泛化能力，发现执行引导的神经程序合成在组合新解决方案方面表现最佳


<details>
  <summary>Details</summary>
Motivation: 探索在开放世界问题域中不同方法的分布外泛化能力，特别是在ARC-AGI这种需要组合泛化能力才能成功的任务中比较神经程序合成和测试时微调的效果

Method: 在ARC-AGI领域进行受控的组合泛化实验，比较神经程序合成和测试时微调(TTFT)方法，使用执行引导的神经程序合成作为主要研究方法

Result: 执行引导的神经程序合成在组合新解决方案的能力上优于所有参考算法；测试时微调在ARC-AGI上的成功主要源于激发大语言模型原本无法直接依赖的分布内知识

Conclusion: 神经程序合成方法在需要组合泛化的开放世界问题中表现更优，而测试时微调的效果主要来自于更好地利用已有知识而非真正的分布外泛化

Abstract: We run a controlled compositional generalization experiment in the ARC-AGI
domain: an open-world problem domain in which the ability to generalize
out-of-distribution is, by design, an essential characteristic for success. We
compare neural program synthesis and test-time fine-tuning approaches on this
experiment. We find that execution-guided neural program synthesis outperforms
all reference algorithms in its ability to compose novel solutions. Our
empirical findings also suggest that the success of TTFT on ARC-AGI lies mainly
in eliciting in-distribution knowledge that the LLM otherwise fails to rely on
directly.

</details>


### [7] [The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture](https://arxiv.org/abs/2507.15880)
*Andy E. Williams*

Main category: cs.AI

TL;DR: 这篇论文提出了递归一致性原理(RCP)，认为智能系统要想有效扩展必须在递归推理过程中保持结构一致性，并介绍了功能智能模型(FMI)作为满足该原理的唯一已知算子，旨在解决AI对齐、幻觉和不稳定性等问题。


<details>
  <summary>Details</summary>
Motivation: 复杂系统在扩展过程中面临一致性脆弱的问题，缺乏高阶结构来确保语义一致性。现有AI系统普遍存在错位、幻觉和不稳定性等问题，这些都是结构一致性缺失的症状。需要找到一个能够在任何规模下保持语义结构和推理一致性的基础原理。

Method: 1. 正式定义递归一致性原理(RCP)：对于任何N阶推理系统，语义一致性只能通过递归可评估的泛化算子来保持；2. 提出功能智能模型(FMI)作为满足RCP的最小可组合架构；3. FMI包含内部函数(评估、建模、适应、稳定、分解、桥接)和外部函数(存储、回忆、系统1和系统2推理)；4. 通过数学证明展示缺乏FMI的系统在扩展时会出现递归一致性崩溃。

Result: 证明了FMI是唯一能够在任何规模下满足递归一致性原理的已知算子。研究表明，缺乏FMI架构的系统在扩展时必然会经历递归一致性崩溃，而常见的AI问题如错位、幻觉和不稳定性都是这种结构一致性丧失的症状。该模型能够在推理和协调层面保持语义结构。

Conclusion: 递归一致性原理为构建可靠、可对齐的智能系统提供了理论基础。该工作对AI对齐领域产生重大影响，倡导从行为约束转向结构一致性的范式转变。通过采用FMI架构，可以为安全可泛化、鲁棒一致的大规模AI系统提供实现路径，从根本上解决当前AI系统的结构性问题。

Abstract: Intelligence-biological, artificial, or collective-requires structural
coherence across recursive reasoning processes to scale effectively. As complex
systems grow, coherence becomes fragile unless a higher-order structure ensures
semantic consistency. This paper introduces the Recursive Coherence Principle
(RCP): a foundational constraint stating that for any reasoning system of order
N, composed of systems operating over conceptual spaces of order N-1, semantic
coherence is preserved only by a recursively evaluable generalization operator
that spans and aligns those lower-order conceptual spaces. Crucially, this
coherence enables structural alignment. Without recursive coherence, no system
can reliably preserve goals, meanings, or reasoning consistency at scale. We
formally define the Functional Model of Intelligence (FMI) as the only known
operator capable of satisfying the RCP at any scale. The FMI is a minimal,
composable architecture with internal functions (evaluation, modeling,
adaptation, stability, decomposition, bridging) and external functions
(storage, recall, System 1 and System 2 reasoning) vital for preserving
semantic structure across inference and coordination layers. We prove that any
system lacking the FMI will experience recursive coherence breakdown as it
scales, arguing that common AI issues like misalignment, hallucination, and
instability are symptoms of this structural coherence loss. Unlike other
foundational principles, RCP uniquely captures the internal, recursive dynamics
needed for coherent, alignable intelligence, modeling semantic coherence under
recursion. This work significantly impacts AI alignment, advocating a shift
from behavioral constraints to structural coherence, and offers a pathway for
safely generalizable, robustly coherent AI at scale.

</details>


### [8] [ADEPTS: A Capability Framework for Human-Centered Agent Design](https://arxiv.org/abs/2507.15885)
*Pierluca D'Oro,Caley Drooff,Joy Chen,Joseph Tighe*

Main category: cs.AI

TL;DR: 本文提出了ADEPTS框架，这是一个面向用户的AI智能体能力框架，旨在为AI智能体开发提供统一指导，使其在日常使用中更加可理解、可控制和可信任。


<details>
  <summary>Details</summary>
Motivation: 当前AI智能体开发指导分散且缺乏统一性：UX启发式关注界面行为，工程分类法描述内部管道，伦理检查表涉及高层治理，但缺乏简洁的面向用户的词汇来定义智能体应具备的基本能力。需要一个跨学科的整体方法来开发、监控和讨论智能体驱动的用户体验所需的能力。

Method: 基于六个以人为中心的智能体设计原则，开发了ADEPTS能力框架。该框架定义了一套核心的面向用户的能力，位于技术开发和体验开发的接口处，补充现有框架和分类法，为AI研究者、设计师、工程师和政策审查者提供可操作的指导。

Result: ADEPTS框架成功将复杂的AI-UX需求浓缩为一个紧凑的框架，提供了统一的指导语言，帮助团队明确AI智能体应具备的基本能力，使智能体在日常使用中表现出可理解性、可控制性和可信任性。

Conclusion: ADEPTS框架有潜力加速用户相关智能体能力的改进，简化利用这些能力的体验设计，并为跟踪和讨论AI智能体发展进展提供共同语言。该框架为AI智能体的人机交互设计提供了重要的理论基础和实践指导。

Abstract: Large language models have paved the way to powerful and flexible AI agents,
assisting humans by increasingly integrating into their daily life. This
flexibility, potential, and growing adoption demands a holistic and
cross-disciplinary approach to developing, monitoring and discussing the
capabilities required for agent-driven user experiences. However, current
guidance on human-centered AI agent development is scattered: UX heuristics
focus on interface behaviors, engineering taxonomies describe internal
pipelines, and ethics checklists address high-level governance. There is no
concise, user-facing vocabulary that tells teams what an agent should
fundamentally be able to do. We introduce ADEPTS, a capability framework
defining a set of core user-facing capabilities to provide unified guidance
around the development of AI agents. ADEPTS is based on six principles for
human-centered agent design, that express the minimal, user-facing capabilities
an AI agent should demonstrate to be understandable, controllable and
trustworthy in everyday use. ADEPTS complements existing frameworks and
taxonomies; differently from them, it sits at the interface between technical
and experience development. By presenting ADEPTS, we aim to condense complex
AI-UX requirements into a compact framework that is actionable guidance for AI
researchers, designers, engineers, and policy reviewers alike. We believe
ADEPTS has the potential of accelerating the improvement of user-relevant agent
capabilities, of easing the design of experiences that take advantage of those
capabilities, and of providing a shared language to track and discuss progress
around the development of AI agents.

</details>


### [9] [Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture](https://arxiv.org/abs/2507.15895)
*Lisa Dargasz*

Main category: cs.AI

TL;DR: 本研究提出了基于推理的人工道德智能体(RBAMAs)，通过扩展强化学习架构来实现基于规范推理的道德决策，使智能体能够学习推理理论并在执行任务时遵守道德义务。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能自主智能体(如人形机器人、自动驾驶汽车)即将从实验室原型转向真实世界应用，迫切需要确保这些系统能够道德地行为。当前缺乏一个具体可部署的框架来开发满足关键道德要求的人工道德智能体。

Method: 通过扩展强化学习架构构建基于推理的人工道德智能体(RBAMAs)。该方法为智能体配备学习推理理论的能力，使其能够处理道德相关命题并推导道德义务，通过基于案例的反馈进行学习，并在执行指定任务时调整行为以确保符合道德义务。

Result: 研究首次实现了RBAMA并通过初步实验展示了其潜力。该架构能够增强智能体行为的道德正当性、道德稳健性和道德可信性。

Conclusion: RBAMAs提供了一个具体可部署的框架用于开发满足关键道德要求的人工道德智能体。该扩展架构通过基于声音规范推理的道德决策机制，为解决计算机科学与哲学交叉领域的挑战提供了有效方案。

Abstract: Reinforcement Learning is a machine learning methodology that has
demonstrated strong performance across a variety of tasks. In particular, it
plays a central role in the development of artificial autonomous agents. As
these agents become increasingly capable, market readiness is rapidly
approaching, which means those agents, for example taking the form of humanoid
robots or autonomous cars, are poised to transition from laboratory prototypes
to autonomous operation in real-world environments. This transition raises
concerns leading to specific requirements for these systems - among them, the
requirement that they are designed to behave ethically. Crucially, research
directed toward building agents that fulfill the requirement to behave
ethically - referred to as artificial moral agents(AMAs) - has to address a
range of challenges at the intersection of computer science and philosophy.
This study explores the development of reason-based artificial moral agents
(RBAMAs). RBAMAs are build on an extension of the reinforcement learning
architecture to enable moral decision-making based on sound normative
reasoning, which is achieved by equipping the agent with the capacity to learn
a reason-theory - a theory which enables it to process morally relevant
propositions to derive moral obligations - through case-based feedback. They
are designed such that they adapt their behavior to ensure conformance to these
obligations while they pursue their designated tasks. These features contribute
to the moral justifiability of the their actions, their moral robustness, and
their moral trustworthiness, which proposes the extended architecture as a
concrete and deployable framework for the development of AMAs that fulfills key
ethical desiderata. This study presents a first implementation of an RBAMA and
demonstrates the potential of RBAMAs in initial experiments.

</details>


### [10] [Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation](https://arxiv.org/abs/2507.15901)
*Joydeep Chandra,Satyam Kumar Navneet*

Main category: cs.AI

TL;DR: 本文分析了家庭环境中的主动智能代理系统，探讨了从反应式向主动式自主转变所带来的隐私、公平性和用户控制等伦理挑战，并为开发透明、包容、可信赖的家庭自动化智能代理提供了概念基础和实用建议。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在家庭环境中的应用日益普及，特别是主动自主代理的出现，虽然带来了舒适和便利，但同时也产生了重要的伦理挑战。特别是对于老年人、儿童和神经多样性群体等脆弱用户群体，面临着更高的监控、偏见和隐私风险，迫切需要建立负责任的创新框架和治理实践。

Method: 研究采用了综合性的分析方法，包括：(1)审查负责任创新框架；(2)应用以人为中心的设计原则；(3)分析治理实践；(4)利用自然语言处理技术进行社交媒体分析；(5)采用参与式和包容性方法论；(6)重点研究脆弱用户群体的特殊需求和风险。

Result: 研究提出了智能家居系统的关键设计要求，包括：定制化的可解释性机制、细粒度的同意机制、强大的覆盖控制功能。通过数据驱动的洞察和自然语言处理分析，识别了特定用户需求和伦理关切。为脆弱用户群体提供了针对性的保护措施和设计建议。

Conclusion: 本研究为开发透明、包容和可信赖的家庭自动化智能代理系统提供了重要的概念基础和实践指导。强调了在智能家居发展中必须优先考虑用户隐私、公平性和自主控制权，特别是要关注和保护脆弱用户群体的权益，以实现技术创新与伦理责任的平衡。

Abstract: The implementation of Artificial Intelligence (AI) in household environments,
especially in the form of proactive autonomous agents, brings about
possibilities of comfort and attention as well as it comes with intra or
extramural ethical challenges. This article analyzes agentic AI and its
applications, focusing on its move from reactive to proactive autonomy,
privacy, fairness and user control. We review responsible innovation
frameworks, human-centered design principles, and governance practices to
distill practical guidance for ethical smart home systems. Vulnerable user
groups such as elderly individuals, children, and neurodivergent who face
higher risks of surveillance, bias, and privacy risks were studied in detail in
context of Agentic AI. Design imperatives are highlighted such as tailored
explainability, granular consent mechanisms, and robust override controls,
supported by participatory and inclusive methodologies. It was also explored
how data-driven insights, including social media analysis via Natural Language
Processing(NLP), can inform specific user needs and ethical concerns. This
survey aims to provide both a conceptual foundation and suggestions for
developing transparent, inclusive, and trustworthy agentic AI in household
automation.

</details>


### [11] [Does More Inference-Time Compute Really Help Robustness?](https://arxiv.org/abs/2507.15974)
*Tong Wu,Chong Xiang,Jiachen T. Wang,Weichen Yu,Chawin Sitawarin,Vikash Sehwag,Prateek Mittal*

Main category: cs.AI

TL;DR: 本文研究了推理时计算扩展对语言模型鲁棒性的影响，发现当中间推理步骤对攻击者可见时，增加推理计算反而会降低模型的鲁棒性，揭示了一个逆向扩展定律


<details>
  <summary>Details</summary>
Motivation: 先前研究表明增加推理时计算可以提升大型专有推理模型的鲁棒性，但这些研究隐含假设中间推理步骤对攻击者是隐藏的。本文旨在检验这一假设，并探讨当推理步骤暴露时对模型安全性的影响

Method: 使用预算强制策略在小规模开源模型（如DeepSeek R1、Qwen3、Phi-reasoning）上验证推理时扩展的效果；通过放宽"中间推理步骤对攻击者隐藏"的假设，实验验证当推理步骤可见时推理计算对鲁棒性的影响；分析实际部署场景中的安全风险

Result: 验证了小规模开源模型也能从推理时扩展中受益；发现并验证了逆向扩展定律：当中间推理步骤对攻击者可见时，增加推理时计算会持续降低模型鲁棒性；识别了即使隐藏推理链的模型仍然容易受到攻击的实际场景

Conclusion: 推理时扩展的鲁棒性收益很大程度上依赖于对抗设置和部署环境。建议从业者在安全敏感的实际应用中使用推理时扩展之前，应仔细权衡这些微妙的权衡关系

Abstract: Recently, Zaremba et al. demonstrated that increasing inference-time
computation improves robustness in large proprietary reasoning LLMs. In this
paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1,
Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a
simple budget forcing strategy. More importantly, we reveal and critically
examine an implicit assumption in prior work: intermediate reasoning steps are
hidden from adversaries. By relaxing this assumption, we identify an important
security risk, intuitively motivated and empirically verified as an inverse
scaling law: if intermediate reasoning steps become explicitly accessible,
increased inference-time computation consistently reduces model robustness.
Finally, we discuss practical scenarios where models with hidden reasoning
chains are still vulnerable to attacks, such as models with tool-integrated
reasoning and advanced reasoning extraction attacks. Our findings collectively
demonstrate that the robustness benefits of inference-time scaling depend
heavily on the adversarial setting and deployment context. We urge
practitioners to carefully weigh these subtle trade-offs before applying
inference-time scaling in security-sensitive, real-world applications.

</details>


### [12] [Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network](https://arxiv.org/abs/2507.16020)
*Xi Yang,Jiachen Wang,Song Han,Suining He*

Main category: cs.AI

TL;DR: 本文提出BikeMAN神经网络模型，通过多层次时空注意力机制预测整个城市自行车共享系统中所有站点的交通流量，在纽约市700多个站点的1000万次出行数据上验证了模型的高精度预测能力。


<details>
  <summary>Details</summary>
Motivation: 城市微出行资源（如共享单车）因站点级需求与供给不平衡导致系统维护困难，现有方法在预测整个共享单车系统的站点级交通流量方面存在挑战，主要由于时空复杂性和站点数量庞大的问题。

Method: 提出BikeMAN多层次时空注意力神经网络，包含编码器和解码器结构，采用两种注意力机制：一种表示系统中各站点特征间的空间相关性，另一种描述站点交通的时间特征。

Result: 在纽约市共享单车系统的1000多万次出行数据（超过700个站点）上进行实验验证，该网络在预测城市所有站点的自行车交通流量方面表现出高精度。

Conclusion: BikeMAN模型成功解决了整个共享单车系统站点级交通预测的挑战，通过多层次时空注意力机制有效捕获了系统的复杂时空特征，为共享单车系统的高效运营提供了有力支撑。

Abstract: Efficient use of urban micromobility resources such as bike sharing is
challenging due to the unbalanced station-level demand and supply, which causes
the maintenance of the bike sharing systems painstaking. Prior efforts have
been made on accurate prediction of bike traffics, i.e., demand/pick-up and
return/drop-off, to achieve system efficiency. However, bike station-level
traffic prediction is difficult because of the spatial-temporal complexity of
bike sharing systems. Moreover, such level of prediction over entire bike
sharing systems is also challenging due to the large number of bike stations.
To fill this gap, we propose BikeMAN, a multi-level spatio-temporal attention
neural network to predict station-level bike traffic for entire bike sharing
systems. The proposed network consists of an encoder and a decoder with an
attention mechanism representing the spatial correlation between features of
bike stations in the system and another attention mechanism describing the
temporal characteristic of bike station traffic. Through experimental study on
over 10 millions trips of bike sharing systems (> 700 stations) of New York
City, our network showed high accuracy in predicting the bike station traffic
of all stations in the city.

</details>


### [13] [From Logic to Language: A Trust Index for Problem Solving with LLMs](https://arxiv.org/abs/2507.16028)
*Tehseen Rug,Felix Böhmer,Tessa Pfattheicher*

Main category: cs.AI

TL;DR: 该论文提出了一个统一框架来理解和对比经典计算与大语言模型在问题解决方面的不同范式，引入了向量值信任指数Q来评估自然语言解决方案的质量，并提出了两个统计质量维度来衡量LLM解决方案的鲁棒性和主观价值。


<details>
  <summary>Details</summary>
Motivation: 经典计算基于形式逻辑系统，擅长处理可用明确规则描述的问题，但对于充满歧义性、动态环境和主观语境的人类问题却无能为力。大语言模型的出现代表了根本性转变，使计算系统能够使用自然语言处理这些以前无法触及的领域。

Method: 论文定义并划分了形式语言与自然语言可解决的问题空间，引入了向量值信任指数Q来反映解决方案质量，区分形式解决方案的二元正确性和自然语言解决方案的连续适当性谱。提出了两个统计质量维度：标准化双语义熵（衡量鲁棒性和概念多样性）和情感价值（将主观评价映射为可量化指标）。

Result: 建立了一个统一框架来理解经典计算和LLM问题解决范式的差异，成功定义了评估自然语言解决方案质量的新方法，包括信任指数Q和两个统计质量维度，为LLM时代的问题解决提供了更严格的理论基础。

Conclusion: 该工作为理解LLM时代问题解决的能力、局限性和内在本质提供了更严格的理论框架，为评估和优化自然语言计算系统的性能奠定了基础。

Abstract: Classical computation, grounded in formal, logical systems, has been the
engine of technological progress for decades, excelling at problems that can be
described with unambiguous rules. This paradigm, however, leaves a vast ocean
of human problems -- those characterized by ambiguity, dynamic environments,
and subjective context -- largely untouched. The advent of Large Language
Models (LLMs) represents a fundamental shift, enabling computational systems to
engage with this previously inaccessible domain using natural language. This
paper introduces a unified framework to understand and contrast these
problem-solving paradigms. We define and delineate the problem spaces
addressable by formal languages versus natural language. While solutions to the
former problem class can be evaluated using binary quality measures, the latter
requires a much more nuanced definition of approximate solution space taking
into account the vagueness, subjectivity and ambiguity inherent to natural
language. We therefore introduce a vector-valued trust index Q, which reflects
solution quality and distinguishes the binary correctness of formal solutions
from the continuous adequacy spectrum characteristic of natural language
solutions. Within this framework, we propose two statistical quality
dimensions. Normalized bi-semantic entropy measures robustness and conceptual
diversity of LLM answers given semantic variation in problem formulations.
Emotional valence maps subjective valuation of a solution to a quantifiable
metric that can be maximized by invoking statistical measures. The concepts
introduced in this work will provide a more rigorous understanding of the
capabilities, limitations, and inherent nature of problem-solving in the age of
LLMs.

</details>


### [14] [A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)](https://arxiv.org/abs/2507.16067)
*Jeroen Spaans,Jesse Heyninck*

Main category: cs.AI

TL;DR: 本文提出了一个统一的约束逻辑编程扩展框架，支持在子句体中使用否定，并基于近似不动点理论提供语义学，统一了现有的各种CLP扩展方法。


<details>
  <summary>Details</summary>
Motivation: 现有的约束逻辑编程(CLP)扩展虽然支持模糊约束满足、不确定性或否定等特性，但都没有研究在子句体中允许否定的情况。需要一个统一的框架来整合这些扩展并支持更具表达力的语言特性。

Method: 使用半环作为统一抽象来扩展CLP，基于近似不动点理论框架为包含体否定的程序提供语义学，并详细分析半环性质对结果语义的影响。

Result: 成功构建了一个统一框架，该框架能够捕获现有的各种CLP扩展方法，同时支持在子句体中使用否定，提供了完整的语义学定义和半环性质的影响分析。

Conclusion: 提供了一个统一的CLP扩展框架，不仅整合了现有方法，还通过支持体否定扩展了语言的表达能力，为约束逻辑编程领域提供了更强大和灵活的理论基础。

Abstract: Constraint Logic Programming (CLP) is a logic programming formalism used to
solve problems requiring the consideration of constraints, like resource
allocation and automated planning and scheduling. It has previously been
extended in various directions, for example to support fuzzy constraint
satisfaction, uncertainty, or negation, with different notions of semiring
being used as a unifying abstraction for these generalizations. None of these
extensions have studied clauses with negation allowed in the body. We
investigate an extension of CLP which unifies many of these extensions and
allows negation in the body. We provide semantics for such programs, using the
framework of approximation fixpoint theory, and give a detailed overview of the
impacts of properties of the semirings on the resulting semantics. As such, we
provide a unifying framework that captures existing approaches and allows
extending them with a more expressive language.

</details>


### [15] [Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization](https://arxiv.org/abs/2507.16110)
*Shengchao Liu,Hannan Xu,Yan Ai,Huanxin Li,Yoshua Bengio,Harry Guo*

Main category: cs.AI

TL;DR: 研究者开发了ChatBattery框架，利用大语言模型的推理能力进行电池材料发现，成功设计并合成了三种新型锂离子电池正极材料，容量分别提升了28.8%、25.2%和18.5%


<details>
  <summary>Details</summary>
Motivation: 大语言模型的推理能力主要在数学和编程问题上得到验证，但在特定领域应用（如电池发现）方面的潜力尚未充分探索。研究者希望将推理能力扩展到材料设计领域

Method: 提出ChatBattery智能体框架，将领域知识整合到大语言模型中，引导其在材料设计中进行更有效的推理。该框架采用推理驱动的方法进行材料发现

Result: 成功识别、合成并表征了三种新型锂离子电池正极材料，相比广泛使用的NMC811正极材料，实际容量分别提升了28.8%、25.2%和18.5%

Conclusion: ChatBattery展示了从设计到合成再到表征的完整AI驱动循环，证明了AI驱动推理在革命性材料发现方面的变革潜力，为LLM驱动的材料发明平台开辟了新路径

Abstract: Large language models (LLMs) leverage chain-of-thought (CoT) techniques to
tackle complex problems, representing a transformative breakthrough in
artificial intelligence (AI). However, their reasoning capabilities have
primarily been demonstrated in solving math and coding problems, leaving their
potential for domain-specific applications-such as battery discovery-largely
unexplored. Inspired by the idea that reasoning mirrors a form of guided
search, we introduce ChatBattery, a novel agentic framework that integrates
domain knowledge to steer LLMs toward more effective reasoning in materials
design. Using ChatBattery, we successfully identify, synthesize, and
characterize three novel lithium-ion battery cathode materials, which achieve
practical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over
the widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this
discovery, ChatBattery paves a new path by showing a successful LLM-driven and
reasoning-based platform for battery materials invention. This complete
AI-driven cycle-from design to synthesis to characterization-demonstrates the
transformative potential of AI-driven reasoning in revolutionizing materials
discovery.

</details>


### [16] [TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task](https://arxiv.org/abs/2507.16126)
*Michael R. Bock,Kara Molisee,Zachary Ozer,Sumit Shah*

Main category: cs.AI

TL;DR: 研究者提出了TaxCalcBench基准来测试AI模型计算个人所得税的能力，发现最先进的模型在简化样本集上的成功率不到三分之一，主要问题包括误用税表、计算错误和资格判断错误。


<details>
  <summary>Details</summary>
Motivation: 目前尚无AI能够准确处理美国个人所得税计算这一复杂任务。该任务需要理解大量英文文本并运用相关知识进行精确计算，因此需要建立专门的基准来评估模型在此方面的能力。

Method: 提出TaxCalcBench基准测试，用于评估模型在给定所有必要信息的情况下计算个人所得税申报表的能力。通过在简化样本集上测试最先进的模型来分析其表现。

Result: 最先进的模型在计算联邦所得税申报表方面的成功率不到三分之一。模型存在三个主要问题：持续误用税表、在税务计算中出现错误、以及错误判断资格条件。

Conclusion: 研究发现当前大语言模型在个人所得税计算任务上表现不佳，需要额外的基础设施支持才能将LLMs有效应用于个人所得税计算任务。

Abstract: Can AI file your taxes? Not yet. Calculating US personal income taxes is a
task that requires building an understanding of vast amounts of English text
and using that knowledge to carefully compute results. We propose TaxCalcBench,
a benchmark for determining models' abilities to calculate personal income tax
returns given all of the necessary information. Our experiment shows that
state-of-the-art models succeed in calculating less than a third of federal
income tax returns even on this simplified sample set. Our analysis concludes
that models consistently misuse tax tables, make errors in tax calculation, and
incorrectly determine eligibility. Our findings point to the need for
additional infrastructure to apply LLMs to the personal income tax calculation
task.

</details>


### [17] [SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting](https://arxiv.org/abs/2507.16145)
*Shuhao Mei,Yongchao Long,Shan Cao,Xiaobo Han,Shijia Geng,Jinbo Sun,Yuxi Zhou,Shenda Hong*

Main category: cs.AI

TL;DR: 研究团队开发了SpiroLLM，这是首个能够理解肺功能图的多模态大语言模型，用于慢性阻塞性肺病(COPD)诊断，在23.4万人的英国生物银行数据集上达到0.8980的AUROC，并能生成可解释的诊断报告。


<details>
  <summary>Details</summary>
Motivation: 当前COPD诊断的AI模型只能输出分类结果而无法提供诊断依据，现有大语言模型又无法理解肺功能图，这严重限制了临床信任度和应用。因此需要开发能够理解肺功能图并提供可解释诊断的模型。

Method: 提出SpiroLLM多模态大语言模型，使用SpiroEncoder从呼吸曲线中提取形态学特征，通过SpiroProjector将这些特征与肺功能测试数值在统一潜在空间中对齐，最终使大语言模型能够生成综合诊断报告。

Result: 在英国生物银行23.4万人数据集上，SpiroLLM达到0.8980的诊断AUROC（95% CI: 0.8820-0.9132）。在缺失核心数据的鲁棒性测试中，保持100%有效响应率，远超仅文本模型的13.4%，展现了多模态设计的优越性。

Conclusion: 这项工作证明了生理信号与大语言模型深度融合的巨大潜力，为下一代可解释且可靠的临床决策支持工具建立了新的范式，为COPD等呼吸系统疾病的智能诊断提供了重要突破。

Abstract: Chronic Obstructive Pulmonary Disease (COPD), a major chronic respiratory
disease with persistent airflow limitation, is a leading global cause of
disability and mortality. Respiratory spirogram time series, routinely
collected during pulmonary function tests (PFTs), play a critical role in the
early detection of repsiratory diseases and in monitoring lung function over
time. However, most current AI models for COPD diagnosis are limited to
outputting classification results without providing a rationale for their
diagnostic process, while current Large Language Models (LLMs) cannot
understand spirograms yet, which severely limits their clinical trust and
adoption. To tackle this challenge, we leverage a cohort of 234,028 individuals
from the UK Biobank (UKB) to propose SpiroLLM, the first multimodal large
language model that can understand spirogram. The model extracts morphological
features from respiratory curves via a SpiroEncoder and aligns them with PFT
numerical values in a unified latent space using a SpiroProjector, ultimately
empowering a large language model to generate a comprehensive diagnostic
report. Experimental results confirm that SpiroLLM achieved a diagnostic AUROC
of 0.8980 (95% CI: 0.8820-0.9132). In a robustness test with missing core data,
it maintained a 100% valid response rate, far surpassing the 13.4% of a
text-only model and showcasing the superiority of its multimodal design. This
work demonstrates the substantial potential of deeply fusing physiological
signals with large language models, establishing a new paradigm for the next
generation of interpretable and reliable clinical decision support tools.

</details>


### [18] [Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)](https://arxiv.org/abs/2507.16184)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 本文发现了一个名为Agentic Flow的AI智能体架构意外地融合了四个重要心智理论的结构特征，包括卡尼曼的双系统理论、弗里斯顿的预测处理理论、明斯基的心智社会理论和克拉克的延展心智理论，并提出PEACE元架构来描述这种设计层面的规律性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型存在局限性，需要更好的智能体架构来解决多步推理任务。同时，作者发现实际的AI系统设计可能自然地体现认知理论的结构特征，这为理解智能体架构提供了新的视角。

Method: 设计了Agentic Flow架构，包含检索、认知、控制、记忆和行动五个相互依赖的模块，形成循环认知回路。通过与基线LLM智能体在多步推理任务上的对比实验来评估系统性能。提出PEACE元架构作为描述性框架来捕获设计层面的规律性。

Result: 结构化智能体在任务成功率上达到95.8%，表现出强约束遵循能力，而基线系统成功率仅为62.3%。实验结果展示了理论结构如何通过实际设计选择而非自上而下的理论指导自然涌现。

Conclusion: 本文作为立场论文，探索性地反思了实现过程如何能够浮现认知理论的潜在结构回声，但并不主张理论统一。PEACE提供了理解受现实世界实现需求塑造的架构的共享词汇表，为AI智能体设计提供了新的理论视角。

Abstract: We report the discovery of a structural convergence across four influential
theories of mind: Kahneman's dual-system theory, Friston's predictive
processing, Minsky's society of mind, and Clark's extended mind-emerging
unintentionally within a practical AI agent architecture called Agentic Flow.
Designed to address limitations in large language models (LLMs), Agentic Flow
comprises five interdependent modules such as Retrieval, Cognition, Control,
Memory, and Action arranged in a recurrent cognitive loop. Although originally
inspired only by Minsky and Clark, the system's structure retrospectively
aligns with computational motifs found in all four theories, including
predictive modeling, associative recall, and error-sensitive control.
  To assess this convergence, we conducted comparative experiments with
baseline LLM agents on multi-step reasoning tasks. The structured agent
achieved 95.8% task success and exhibited strong constraint adherence, while
the baseline system succeeded 62.3% of the time. These results were not aimed
at proving superiority, but at illustrating how theoretical structures may
emerge through practical design choices rather than top-down theory.
  We introduce PEACE as a descriptive meta-architecture that captures
design-level regularities observed in Agentic Flow. Not intended as a new
theory, PEACE provides a shared vocabulary for understanding architectures
shaped by real-world implementation demands. This paper should be read as a
position paper - an exploratory reflection on how implementation can surface
latent structural echoes of cognitive theory, without asserting theoretical
unification.

</details>


### [19] [CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks](https://arxiv.org/abs/2507.16204)
*Li-Hsiang Shen,Jyun-Jhe Huang*

Main category: cs.AI

TL;DR: 本文提出了一种由多功能可重构智能表面(MF-RIS)赋能的天-空-地一体化网络架构，通过联合优化网络参数和MF-RIS配置来最大化长期能效，并设计了CHIMERA深度强化学习框架来解决这一复杂的非凸优化问题。


<details>
  <summary>Details</summary>
Motivation: 解决低轨卫星在阴影区域的能量短缺问题，同时考虑天-空-地一体化网络中通信和计算的能耗，需要一种能够同时反射、放大和收集无线能量的智能表面技术来提升网络的长期能效。

Method: 提出了多功能可重构智能表面(MF-RIS)架构，能够同时进行信号反射、放大和能量收集；设计了压缩混合智能双模型增强多智能体深度强化学习(CHIMERA)框架，集成了语义状态-动作压缩和参数化共享机制来高效探索复杂动作空间。

Result: 仿真结果表明，所提出的CHIMERA方案在能效方面显著优于传统基准方法（包括固定配置或非能量收集MF-RIS、传统RIS、无RIS情况），以及集中式和多智能体深度强化学习基线方法；SAGIN-MF-RIS架构由于其互补覆盖特性，相比单独的卫星、空中或地面部署具有显著优势。

Conclusion: 提出的天-空-地一体化网络与多功能可重构智能表面相结合的架构能够有效解决低轨卫星能量短缺问题，通过CHIMERA深度强化学习框架实现了系统长期能效的最大化，为未来6G网络的发展提供了重要的技术方案。

Abstract: A space-air-ground integrated network (SAGIN) architecture is proposed,
empowered by multi-functional reconfigurable intelligent surfaces (MF-RIS)
capable of simultaneously reflecting, amplifying, and harvesting wireless
energy. The MF-RIS plays a pivotal role in addressing the energy shortages of
low-Earth orbit (LEO) satellites operating in shadowed regions, while
explicitly accounting for both communication and computing energy consumption
across the SAGIN nodes. To maximize the long-term energy efficiency (EE), we
formulate a joint optimization problem over the MF-RIS parameters, including
signal amplification, phase-shifts, energy harvesting ratio, and active element
selection as well as the SAGIN parameters of beamforming vectors, high-altitude
platform station (HAPS) deployment, user association, and computing capability.
The formulated problem is highly non-convex and non-linear and contains mixed
discrete-continuous parameters. To tackle this, we conceive a compressed hybrid
intelligence for twin-model enhanced multi-agent deep reinforcement learning
(CHIMERA) framework, which integrates semantic state-action compression and
parametrized sharing under hybrid reinforcement learning to efficiently explore
suitable complex actions. The simulation results have demonstrated that the
proposed CHIMERA scheme substantially outperforms the conventional benchmarks,
including fixed-configuration or non-harvesting MF-RIS, traditional RIS, and
no-RIS cases, as well as centralized and multi-agent deep reinforcement
learning baselines in terms of the highest EE. Moreover, the proposed
SAGIN-MF-RIS architecture achieves superior EE performance due to its
complementary coverage, offering notable advantages over either standalone
satellite, aerial, or ground-only deployments.

</details>


### [20] [Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design](https://arxiv.org/abs/2507.16226)
*Dong Ben,Hui Feng,Qian Wang*

Main category: cs.AI

TL;DR: 本文研究了在可信执行环境(TEE)中部署大语言模型(LLM)用于电路设计任务的性能评估，重点关注Intel TDX技术的应用效果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在电路设计中应用广泛，但其训练数据和模型属于机密知识产权需要保护。现有TEE实现不能高效支持资源密集型的LLM，因此需要评估TEE环境下LLM的性能表现。

Method: 构建了三种实验环境：基于TEE的、仅CPU的和CPU-GPU混合实现，使用Intel Trust Domain Extensions (TDX)技术，通过每秒token数评估性能。测试了不同模型包括蒸馏模型和量化模型，并使用SoC设计任务测试台进行验证。

Result: 蒸馏模型(如DeepSeek)由于参数较少在性能上表现最佳，适合资源受限设备。量化模型(4位和8位量化)相比FP16模型性能提升可达3倍。对于参数较少的模型如DeepSeek-r1-1.5B，TDX实现在安全环境中的计算性能超过CPU版本。

Conclusion: 研究验证了在资源受限系统上高效部署轻量级LLM用于半导体CAD应用的可行性，为在保护知识产权的同时实现高性能LLM推理提供了解决方案。

Abstract: Large Language Models (LLMs) are increasingly used in circuit design tasks
and have typically undergone multiple rounds of training. Both the trained
models and their associated training data are considered confidential
intellectual property (IP) and must be protected from exposure. Confidential
Computing offers a promising solution to protect data and models through
Trusted Execution Environments (TEEs). However, existing TEE implementations
are not designed to support the resource-intensive nature of LLMs efficiently.
In this work, we first present a comprehensive evaluation of the LLMs within a
TEE-enabled confidential computing environment, specifically utilizing Intel
Trust Domain Extensions (TDX). We constructed experiments on three
environments: TEE-based, CPU-only, and CPU-GPU hybrid implementations, and
evaluated their performance in terms of tokens per second.
  Our first observation is that distilled models, i.e., DeepSeek, surpass other
models in performance due to their smaller parameters, making them suitable for
resource-constrained devices. Also, in the quantized models such as 4-bit
quantization (Q4) and 8-bit quantization (Q8), we observed a performance gain
of up to 3x compared to FP16 models. Our findings indicate that for fewer
parameter sets, such as DeepSeek-r1-1.5B, the TDX implementation outperforms
the CPU version in executing computations within a secure environment. We
further validate the results using a testbench designed for SoC design tasks.
These validations demonstrate the potential of efficiently deploying
lightweight LLMs on resource-constrained systems for semiconductor CAD
applications.

</details>


### [21] [Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery](https://arxiv.org/abs/2507.16229)
*Bo Wen,Chen Wang,Qiwei Han,Raquel Norel,Julia Liu,Thaddeus Stappenbeck,Jeffrey L. Rogers*

Main category: cs.AI

TL;DR: 本研究通过Agent PULSE试点项目，展示了基于大语言模型的语音AI助手在医疗保健中的应用，特别是在服务不足人群的预防性护理和持续患者监测方面的巨大潜力和经济效益。


<details>
  <summary>Details</summary>
Motivation: 解决数字医疗服务中的经济和可及性差距，特别是在传统人工干预经济上不可行的情况下，为服务不足的人群提供成本效益高的医疗保健服务。

Method: 开发并试点测试Agent PULSE（患者理解和联络支持引擎）——一个由IBM研究院、克利夫兰诊所基金会和摩尔豪斯医学院合作开发的基于大语言模型的语音AI助手系统，并建立经济模型分析其成本效益。

Result: 在33名炎症性肠病患者的试点研究中，70%的患者表示接受AI驱动的监测，37%的患者更偏好AI监测而非传统方式。成本效用分析显示在常规监测任务中具有巨大的潜在节约效果。

Conclusion: 基于语音的AI代理不仅能够提高医疗保健的可扩展性和效率，还能改善患者参与度和可及性。通过解决当前限制并使AI发展与伦理和监管框架保持一致，语音AI代理可以成为公平、可持续数字医疗解决方案的关键入口点。

Abstract: The integration of voice-based AI agents in healthcare presents a
transformative opportunity to bridge economic and accessibility gaps in digital
health delivery. This paper explores the role of large language model
(LLM)-powered voice assistants in enhancing preventive care and continuous
patient monitoring, particularly in underserved populations. Drawing insights
from the development and pilot study of Agent PULSE (Patient Understanding and
Liaison Support Engine) -- a collaborative initiative between IBM Research,
Cleveland Clinic Foundation, and Morehouse School of Medicine -- we present an
economic model demonstrating how AI agents can provide cost-effective
healthcare services where human intervention is economically unfeasible. Our
pilot study with 33 inflammatory bowel disease patients revealed that 70\%
expressed acceptance of AI-driven monitoring, with 37\% preferring it over
traditional modalities. Technical challenges, including real-time
conversational AI processing, integration with healthcare systems, and privacy
compliance, are analyzed alongside policy considerations surrounding
regulation, bias mitigation, and patient autonomy. Our findings suggest that
AI-driven voice agents not only enhance healthcare scalability and efficiency
but also improve patient engagement and accessibility. For healthcare
executives, our cost-utility analysis demonstrates huge potential savings for
routine monitoring tasks, while technologists can leverage our framework to
prioritize improvements yielding the highest patient impact. By addressing
current limitations and aligning AI development with ethical and regulatory
frameworks, voice-based AI agents can serve as a critical entry point for
equitable, sustainable digital healthcare solutions.

</details>


### [22] [ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry](https://arxiv.org/abs/2507.16280)
*Tianze Xu,Pengrui Lu,Lyumanshan Ye,Xiangkun Hu,Pengfei Liu*

Main category: cs.AI

TL;DR: 本文介绍了ResearcherBench，这是首个专门评估深度AI研究系统(DARS)在前沿AI科学问题上能力的基准测试，包含65个研究问题，采用双重评估框架，结果显示OpenAI Deep Research和Gemini Deep Research表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估AI系统作为网络检索和报告生成代理的能力，忽略了它们在科学研究前沿发现新见解的潜力。为填补这一空白，需要专门评估深度AI研究系统在前沿AI科学问题上的能力。

Method: 构建包含65个研究问题的数据集，这些问题来自真实科学场景（如实验室讨论和访谈），涵盖35个不同AI主题，分为技术细节、文献综述和开放咨询三类。采用双重评估框架：使用专家设计标准评估洞察质量的量规评估，以及测量引用准确性和覆盖度的事实评估。

Result: 评估了多个领先的商业DARS和基线系统。结果显示OpenAI Deep Research和Gemini Deep Research显著优于其他系统，在开放式咨询问题上表现尤为突出。这些能力代表了AI自我改进的重要进步。

Conclusion: ResearcherBench为评估下一代AI研究助手提供了标准化平台，有望促进AI研究评估的新视角，推动人工智能与科学研究协作的新模式发展，并将基准开源以促进相关领域发展。

Abstract: The emergence of deep research systems presents significant capabilities in
problem-solving, extending from basic queries to sophisticated research tasks.
However, existing benchmarks primarily evaluate these systems as agents for web
retrieval and report generation, overlooking their potential to discover novel
insights on the frontiers of scientific research. To address this gap, we
introduce ResearcherBench, the first benchmark focused on evaluating the
capabilities of these advanced, agentic systems - which we refer to as Deep AI
Research Systems (DARS) - on frontier AI scientific questions. We compiled a
dataset of 65 research questions expertly selected from real-world scientific
scenarios such as laboratory discussions and interviews, spanning 35 different
AI subjects and categorized into three types: technical details, literature
review, and open consulting. Our dual evaluation framework combines rubric
assessment, which uses expert-designed criteria to evaluate insight quality,
with factual assessment, which measures citation accuracy (faithfulness) and
coverage (groundedness). We evaluated several leading commercial DARS and
baseline systems. Results show that OpenAI Deep Research and Gemini Deep
Research significantly outperform other systems, with particular strength in
open-ended consulting questions. Such capabilities represent a meaningful step
toward AI self-improvement, aligning with the vision of ASI for AI. We
open-source ResearcherBench to provide a standardized platform for promoting
the development of next-generation AI research assistants, hoping to foster a
new perspective in AI research evaluation for a novel pattern of scientific
collaboration: https://github.com/GAIR-NLP/ResearcherBench.

</details>


### [23] [Cross-Modal Distillation For Widely Differing Modalities](https://arxiv.org/abs/2507.16296)
*Cairong Zhao,Yufeng Jin,Zifan Song,Haonan Chen,Duoqian Miao,Guosheng Hu*

Main category: cs.AI

TL;DR: 该论文提出了一个跨模态知识蒸馏框架，通过引入教师模型将判别性知识转移给学生模型，解决了多模态数据在使用时获取困难的问题，并提出了软约束知识蒸馏策略和基于质量的自适应权重模块来避免过拟合。


<details>
  <summary>Details</summary>
Motivation: 深度学习通过增加模型大小来提升性能变得困难且低效，多模态学习可以通过引入更丰富和更具判别性的信息来缓解这一挑战。然而，在使用时获取多模态数据的途径有限，且不同模态间的巨大领域差距容易导致过拟合问题。

Method: 提出了一个跨模态蒸馏框架，包括：1）在特征层和分类器层分别提出两种软约束知识蒸馏策略，避免硬约束损失（如L2损失）导致的过拟合；2）提出基于质量的自适应权重模块，通过量化数据质量来对输入样本进行加权，实现鲁棒的模型训练。

Result: 在说话人识别和图像分类任务上进行了实验，结果表明该方法能够有效地在图像、文本和语音这些常用且差异较大的模态之间实现知识转移。

Conclusion: 通过软约束知识蒸馏策略和自适应权重模块，成功解决了跨模态知识蒸馏中的过拟合问题，实现了不同模态间的有效知识转移，为多模态学习提供了新的解决方案。

Abstract: Deep learning achieved great progress recently, however, it is not easy or
efficient to further improve its performance by increasing the size of the
model. Multi-modal learning can mitigate this challenge by introducing richer
and more discriminative information as input. To solve the problem of limited
access to multi-modal data at the time of use, we conduct multi-modal learning
by introducing a teacher model to transfer discriminative knowledge to a
student model during training. However, this knowledge transfer via
distillation is not trivial because the big domain gap between the widely
differing modalities can easily lead to overfitting. In this work, we introduce
a cross-modal distillation framework. Specifically, we find hard constrained
loss, e.g. l2 loss forcing the student being exact the same as the teacher, can
easily lead to overfitting in cross-modality distillation. To address this, we
propose two soft constrained knowledge distillation strategies at the feature
level and classifier level respectively. In addition, we propose a
quality-based adaptive weights module to weigh input samples via quantified
data quality, leading to robust model training. We conducted experiments on
speaker recognition and image classification tasks, and the results show that
our approach is able to effectively achieve knowledge transfer between the
commonly used and widely differing modalities of image, text, and speech.

</details>


### [24] [Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens](https://arxiv.org/abs/2507.16322)
*Fred Mutisya,Shikoh Gitau,Christine Syovata,Diana Oigara,Ibrahim Matende,Muna Aden,Munira Ali,Ryan Nyotu,Diana Marion,Job Nyangena,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha,Eric Mibuari,Jean Philbert Nsengemana,Talkmore Chidede*

Main category: cs.AI

TL;DR: 该研究发现现有医学大语言模型基准测试主要反映高收入国家的疾病特征，不适用于以疟疾、HIV、结核病等疾病为主的非洲地区。研究开发了基于肯尼亚临床实践指南的Alama Health QA基准测试，更好地代表了非洲疾病负担和监管环境。


<details>
  <summary>Details</summary>
Motivation: 现有医学大语言模型基准测试主要基于高收入国家的考试大纲和疾病特征，在非洲部署时存在有效性问题，因为非洲地区主要疾病负担是疟疾、HIV、结核病、镰状细胞病等被忽视的热带疾病，且医疗实践由国家指南驱动。

Method: 系统回顾了31篇定量大语言模型评估论文（2019年1月至2025年5月），识别出19个英语医学问答基准测试。使用基于肯尼亚临床实践指南的检索增强生成框架开发了Alama Health QA。对6个广泛使用的基准测试进行了统一的语义分析（被忽视热带疾病比例、时效性、可读性、词汇多样性指标）和专家盲评（临床相关性、指南一致性、清晰度、干扰项合理性、语言文化适配性）。

Result: Alama Health QA涵盖了所有语料库中超过40%的被忽视热带疾病提及，在疟疾（7.7%）、HIV（4.1%）和结核病（5.2%）方面具有最高的集合内频率；AfriMedQA排名第二但缺乏正式的指南关联。全球基准测试显示最少的代表性（如镰状细胞病在三个测试集中缺失）。定性评估中，Alama在相关性和指南一致性方面得分最高；PubMedQA在临床实用性方面得分最低。

Conclusion: 文献中广泛使用的定量医学大语言模型基准测试未能充分代表非洲疾病负担和监管环境，存在误导性能声明的风险。基于指南、区域策划的资源如Alama Health QA及其扩展的疾病特异性衍生版本，对于非洲卫生系统中模型的安全、公平评估和部署至关重要。

Abstract: Introduction: Existing medical LLM benchmarks largely reflect examination
syllabi and disease profiles from high income settings, raising questions about
their validity for African deployment where malaria, HIV, TB, sickle cell
disease and other neglected tropical diseases (NTDs) dominate burden and
national guidelines drive care. Methodology: We systematically reviewed 31
quantitative LLM evaluation papers (Jan 2019 May 2025) identifying 19 English
medical QA benchmarks. Alama Health QA was developed using a retrieval
augmented generation framework anchored on the Kenyan Clinical Practice
Guidelines. Six widely used sets (AfriMedQA, MMLUMedical, PubMedQA, MedMCQA,
MedQAUSMLE, and guideline grounded Alama Health QA) underwent harmonized
semantic profiling (NTD proportion, recency, readability, lexical diversity
metrics) and blinded expert rating across five dimensions: clinical relevance,
guideline alignment, clarity, distractor plausibility, and language/cultural
fit. Results: Alama Health QA captured >40% of all NTD mentions across corpora
and the highest within set frequencies for malaria (7.7%), HIV (4.1%), and TB
(5.2%); AfriMedQA ranked second but lacked formal guideline linkage. Global
benchmarks showed minimal representation (e.g., sickle cell disease absent in
three sets) despite large scale. Qualitatively, Alama scored highest for
relevance and guideline alignment; PubMedQA lowest for clinical utility.
Discussion: Quantitative medical LLM benchmarks widely used in the literature
underrepresent African disease burdens and regulatory contexts, risking
misleading performance claims. Guideline anchored, regionally curated resources
such as Alama Health QA and expanded disease specific derivatives are essential
for safe, equitable model evaluation and deployment across African health
systems.

</details>


### [25] [Higher Gauge Flow Models](https://arxiv.org/abs/2507.16334)
*Alexander Strunk,Roland Assam*

Main category: cs.AI

TL;DR: 本文提出了高规范流模型(Higher Gauge Flow Models)，这是一种新颖的生成流模型类别，通过利用L∞代数扩展李代数，将高几何和高对称性集成到生成流模型框架中，在高斯混合模型数据集上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的生成流模型在处理复杂几何结构和高阶对称性方面存在局限性。作者希望通过引入高规范结构来扩展普通规范流模型的能力，利用L∞代数的数学框架来捕获更丰富的几何和对称性信息，从而提升生成模型的表现力。

Method: 基于普通规范流模型(Gauge Flow Models)的基础上，利用L∞代数有效扩展李代数结构。这种扩展允许将与高群相关的高几何(higher geometry)和高对称性(higher symmetries)集成到生成流模型的框架中，形成高规范流模型。

Result: 在高斯混合模型数据集上进行实验评估，高规范流模型相比传统流模型表现出显著的性能改进。

Conclusion: 高规范流模型通过引入L∞代数和高规范结构，成功扩展了生成流模型的能力，能够更好地处理复杂的几何结构和对称性，为生成建模领域提供了一个有前景的新方向。

Abstract: This paper introduces Higher Gauge Flow Models, a novel class of Generative
Flow Models. Building upon ordinary Gauge Flow Models (arXiv:2507.13414), these
Higher Gauge Flow Models leverage an L$_{\infty}$-algebra, effectively
extending the Lie Algebra. This expansion allows for the integration of the
higher geometry and higher symmetries associated with higher groups into the
framework of Generative Flow Models. Experimental evaluation on a Gaussian
Mixture Model dataset revealed substantial performance improvements compared to
traditional Flow Models.

</details>


### [26] [Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health](https://arxiv.org/abs/2507.16356)
*Arpan Dasgupta,Mizhaan Maniyar,Awadhesh Srivastava,Sanat Kumar,Amrita Mahale,Aparna Hedge,Arun Suggala,Karthikeyan Shanmugam,Aparna Taneja,Milind Tambe*

Main category: cs.AI

TL;DR: 该研究针对印度Kilkari母婴健康项目开发了一种协作老虎机算法，通过学习个体母亲的偏好通话时间来优化通话调度，在6500名参与者的实地试验中显著提高了通话接听率，展现了个性化调度在移动健康干预中的有效性。


<details>
  <summary>Details</summary>
Motivation: 印度Kilkari项目通过语音通话向数百万母亲传递重要的母婴健康信息，但当前随机通话调度导致大量未接通话和信息传递效果降低，需要优化通话时间安排以提高信息传递效率。

Method: 设计并部署了一种协作老虎机算法，该算法能够学习每位母亲的个人偏好通话时间，从而优化通话调度。在约6500名Kilkari项目参与者中进行实地试验，将算法效果与基线随机通话方法进行对比。

Result: 使用协作老虎机算法的通话接听率相比随机调度方法有统计学意义上的显著提升，证明了个性化调度能够有效改善信息传递效果。

Conclusion: 个性化调度在移动健康干预中具有显著效果，机器学习技术有潜力大规模改善母婴健康推广工作，该算法有望影响印度数百万母亲的健康信息获取。

Abstract: Mobile health (mHealth) programs utilize automated voice messages to deliver
health information, particularly targeting underserved communities,
demonstrating the effectiveness of using mobile technology to disseminate
crucial health information to these populations, improving health outcomes
through increased awareness and behavioral change. India's Kilkari program
delivers vital maternal health information via weekly voice calls to millions
of mothers. However, the current random call scheduling often results in missed
calls and reduced message delivery. This study presents a field trial of a
collaborative bandit algorithm designed to optimize call timing by learning
individual mothers' preferred call times. We deployed the algorithm with around
$6500$ Kilkari participants as a pilot study, comparing its performance to the
baseline random calling approach. Our results demonstrate a statistically
significant improvement in call pick-up rates with the bandit algorithm,
indicating its potential to enhance message delivery and impact millions of
mothers across India. This research highlights the efficacy of personalized
scheduling in mobile health interventions and underscores the potential of
machine learning to improve maternal health outreach at scale.

</details>


### [27] [Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning](https://arxiv.org/abs/2507.16370)
*Lucas de Lara*

Main category: cs.AI

TL;DR: 本文提出了一种基于反事实模型的新方法来表示和实现反事实推理，该方法允许分析师通过预设边际分布的随机过程来选择反事实概念，并提供了规范化程序来描述各种反事实概念。


<details>
  <summary>Details</summary>
Motivation: 反事实推理是因果关系最细粒度的层面，虽然许多反事实陈述无法被证伪（即使通过随机实验），但它们支撑着个体公平性等基本概念。因此，提供形式化和实现反事实信念的模型仍然是一个基本的科学问题。

Method: 在Pearl因果框架的马尔可夫设定下，作者提出了结构因果模型的替代方法来表示与给定因果图模型兼容的反事实。具体引入了反事实模型（也称为结构因果模型的标准表示），使分析师能够通过具有预设边际分布的随机过程概率分布来选择反事实概念，并刻画结构因果模型的反事实等价类。然后提出规范化程序来描述和实现各种反事实概念。

Result: 与结构因果模型相比，该方法允许在不改变观察和干预约束的情况下指定许多反事实概念。此外，对应反事实层的模型内容不需要被估计，只需要做出选择。理论和数值例子说明了反事实在因果关系中的特定作用以及该方法的优势。

Conclusion: 该研究为反事实推理提供了一个新的理论框架，通过反事实模型和规范化程序，使得在保持观察和干预约束不变的前提下，能够灵活地选择和实现不同的反事实概念，为因果推理提供了更加精细和灵活的工具。

Abstract: Counterfactual reasoning aims at answering contrary-to-fact questions like
''Would have Alice recovered had she taken aspirin?'' and corresponds to the
most fine-grained layer of causation. Critically, while many counterfactual
statements cannot be falsified -- even by randomized experiments -- they
underpin fundamental concepts like individual-wise fairness. Therefore,
providing models to formalize and implement counterfactual beliefs remains a
fundamental scientific problem. In the Markovian setting of Pearl's causal
framework, we propose an alternative approach to structural causal models to
represent counterfactuals compatible with a given causal graphical model. More
precisely, we introduce counterfactual models, also called canonical
representations of structural causal models. They enable analysts to choose a
counterfactual conception via random-process probability distributions with
preassigned marginals and characterize the counterfactual equivalence class of
structural causal models. Then, we present a normalization procedure to
describe and implement various counterfactual conceptions. Compared to
structural causal models, it allows to specify many counterfactual conceptions
without altering the observational and interventional constraints. Moreover,
the content of the model corresponding to the counterfactual layer does not
need to be estimated; only to make a choice. Finally, we illustrate the
specific role of counterfactuals in causality and the benefits of our approach
on theoretical and numerical examples.

</details>


### [28] [LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning](https://arxiv.org/abs/2507.16395)
*Bo Hou,Xin Tan,Kai Zheng,Fang Liu,Yinghao Zhu,Li Zhang*

Main category: cs.AI

TL;DR: 提出了ColaUntangle框架，使用多智能体架构和大语言模型来解决代码提交解耦问题，通过建模显式和隐式依赖关系，在C#和Java数据集上分别实现44%和100%的性能提升


<details>
  <summary>Details</summary>
Motivation: 开发者经常产生混合不相关变更的纠缠提交，影响代码审查和维护。现有的基于规则、特征或图的解耦方法依赖浅层信号，无法有效区分显式依赖（控制/数据流）和隐式依赖（语义或概念关系）

Method: 提出ColaUntangle协作咨询框架，采用多智能体架构：一个智能体专门处理显式依赖，另一个处理隐式依赖，审查智能体通过迭代咨询综合两者观点。构建多版本程序依赖图（delta-PDG）来捕获显式和隐式上下文信息

Result: 在两个广泛使用的数据集（1,612个C#和14k个Java纠缠提交）上评估，ColaUntangle超越最佳基线方法，在C#数据集上实现44%改进，在Java数据集上实现100%改进

Conclusion: 基于大语言模型的协作框架在自动化提交解耦任务中展现出巨大潜力，通过建模显式和隐式依赖关系能够显著提升提交解耦的性能

Abstract: Atomic commits, each of which addresses a single development concern, are a
best practice in software development. However, developers frequently produce
tangled commits that mix unrelated changes due to practical constraints or
unclear boundaries, negatively impacting code review and maintenance. Although
prior commit untangling approaches: rule-based, feature-based, or graph-based,
have made progress, they often rely on shallow signals and fail to distinguish
between explicit dependencies (e.g., control/data flow) and implicit ones
(e.g., semantic or conceptual relationships). In this paper, we propose
ColaUntangle, a new collaborative consultation framework for commit untangling
that models both explicit and implicit dependencies among code changes.
ColaUntangle integrates Large Language Model (LLM)-driven agents in a
multi-agent architecture: one agent specializes in explicit dependencies,
another in implicit ones, and a reviewer agent synthesizes their perspectives
through iterative consultation. To capture explicit and implicit contextual
information, we construct multi-version Program Dependency Graphs (delta-PDG),
enabling agents to reason over code relationships with both symbolic and
semantic depth. We evaluate ColaUntangle on two widely-used datasets (1,612 C#
and 14k Java tangled commits). Experimental results show that ColaUntangle
outperforms the best-performing baseline, achieving an improvement of 44% on
the C# dataset and 100% on the Java dataset. These findings highlight the
potential of LLM-based collaborative frameworks for advancing automated commit
untangling tasks.

</details>


### [29] [Self-Supervised Inductive Logic Programming](https://arxiv.org/abs/2507.16405)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: 该论文提出了一种新的自监督归纳逻辑编程(ILP)方法Poker，能够在缺乏专家知识设计的背景理论和负例的情况下，仅从少量正例和无标签样本中学习递归逻辑程序，并在学习过程中自动生成和标注新的正负例。


<details>
  <summary>Details</summary>
Motivation: 传统的归纳逻辑编程方法如元解释学习(MIL)需要依赖专家精心设计的问题特定背景理论和负例，但在实际应用中这些先验知识往往不可获得。因此需要一种能够在缺乏这些专家知识的情况下进行自监督学习的ILP方法。

Method: 提出了一种新的MIL算法，实现在Poker系统中。该方法能够从正例标注样本和零个或多个无标签样本中学习，在学习过程中自动生成并标注新的正负例。同时引入了二阶确定正规形式(SONF)来进行背景理论的原则性选择，使其足够通用以学习某类中的所有程序。

Result: 在上下文无关语法和L-系统语言的语法学习实验中，Poker系统的性能随着自动生成样本数量的增加而提升，而缺乏负例的Louise系统则出现过泛化问题。实验验证了该方法在仅使用终端词汇表作为一阶背景理论的情况下的有效性。

Conclusion: Poker系统成功解决了自监督ILP设置下的学习问题，通过自动生成训练样本避免了对专家设计背景理论和负例的依赖，为ILP在缺乏先验知识场景下的应用提供了新的解决方案。

Abstract: Inductive Logic Programming (ILP) approaches like Meta \-/ Interpretive
Learning (MIL) can learn, from few examples, recursive logic programs with
invented predicates that generalise well to unseen instances. This ability
relies on a background theory and negative examples, both carefully selected
with expert knowledge of a learning problem and its solutions. But what if such
a problem-specific background theory or negative examples are not available? We
formalise this question as a new setting for Self-Supervised ILP and present a
new MIL algorithm that learns in the new setting from some positive labelled,
and zero or more unlabelled examples, and automatically generates, and labels,
new positive and negative examples during learning. We implement this algorithm
in Prolog in a new MIL system, called Poker. We compare Poker to
state-of-the-art MIL system Louise on experiments learning grammars for
Context-Free and L-System languages from labelled, positive example strings, no
negative examples, and just the terminal vocabulary of a language, seen in
examples, as a first-order background theory. We introduce a new approach for
the principled selection of a second-order background theory as a Second Order
Definite Normal Form (SONF), sufficiently general to learn all programs in a
class, thus removing the need for a backgound theory tailored to a learning
task. We find that Poker's performance improves with increasing numbers of
automatically generated examples while Louise, bereft of negative examples,
over-generalises.

</details>


### [30] [Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework](https://arxiv.org/abs/2507.16414)
*Hongyi Tang,Zhihao Zhu,Yi Yang*

Main category: cs.AI

TL;DR: 该论文提出了NA-PDD算法，通过分析大语言模型中训练数据和非训练数据的神经元激活模式差异来检测预训练数据，并构建了CCNewsPDD基准数据集，在多个基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的训练数据可能包含版权材料或私人信息，引发法律和伦理问题，同时面临数据集污染和偏见内化的批评。现有的预训练数据检测(PDD)方法主要依赖预测置信度和损失等表面特征，性能一般，需要更有效的检测方法。

Method: 提出NA-PDD算法，基于训练数据和非训练数据在大语言模型推理过程中激活不同神经元的观察，分析差异化神经元激活模式。同时构建CCNewsPDD基准数据集，采用严格的数据变换确保训练和非训练数据之间时间分布的一致性，消除时间偏差。

Result: NA-PDD在三个基准数据集和多个大语言模型上的实验表明，该方法显著优于现有的预训练数据检测方法，性能有明显提升。

Conclusion: 通过分析神经元激活模式差异的NA-PDD算法为预训练数据检测提供了更有效的解决方案，能够更准确地识别大语言模型训练数据中的特定内容，有助于解决版权和隐私相关的法律伦理问题。

Abstract: The performance of large language models (LLMs) is closely tied to their
training data, which can include copyrighted material or private information,
raising legal and ethical concerns. Additionally, LLMs face criticism for
dataset contamination and internalizing biases. To address these issues, the
Pre-Training Data Detection (PDD) task was proposed to identify if specific
data was included in an LLM's pre-training corpus. However, existing PDD
methods often rely on superficial features like prediction confidence and loss,
resulting in mediocre performance. To improve this, we introduce NA-PDD, a
novel algorithm analyzing differential neuron activation patterns between
training and non-training data in LLMs. This is based on the observation that
these data types activate different neurons during LLM inference. We also
introduce CCNewsPDD, a temporally unbiased benchmark employing rigorous data
transformations to ensure consistent time distributions between training and
non-training data. Our experiments demonstrate that NA-PDD significantly
outperforms existing methods across three benchmarks and multiple LLMs.

</details>


### [31] [From model-based learning to model-free behaviour with Meta-Interpretive Learning](https://arxiv.org/abs/2507.16434)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: 本文提出了一种结合模型驱动和无模型方法的自主智能体架构，通过元解释学习训练模型驱动求解器，再用其训练无模型控制器，在网格导航任务中验证了两者的等效性。


<details>
  <summary>Details</summary>
Motivation: 现有智能体要么是模型驱动的（能规划但需要完全观察环境状态），要么是无模型的（不需要模型但无法规划）。为了在新环境中独立行动，需要结合两种能力的自主智能体。

Method: 使用元解释学习(Meta-Interpretive Learning)来学习模型驱动的求解器(Solver)，然后用该求解器训练无模型的控制器(Controller)，使控制器能够解决与求解器相同的规划问题。

Result: 在两种网格导航环境（随机生成的迷宫和具有开阔区域的湖泊地图）中验证了方法的有效性。实验表明，求解器能解决的所有导航问题，控制器也都能解决，证明了两者的等效性。

Conclusion: 成功创建了一个结合模型驱动和无模型能力的自主智能体，通过元解释学习实现了知识从模型驱动求解器到无模型控制器的有效转移，两者在问题解决能力上具有等效性。

Abstract: A "model" is a theory that describes the state of an environment and the
effects of an agent's decisions on the environment. A model-based agent can use
its model to predict the effects of its future actions and so plan ahead, but
must know the state of the environment. A model-free agent cannot plan, but can
act without a model and without completely observing the environment. An
autonomous agent capable of acting independently in novel environments must
combine both sets of capabilities. We show how to create such an agent with
Meta-Interpretive Learning used to learn a model-based Solver used to train a
model-free Controller that can solve the same planning problems as the Solver.
We demonstrate the equivalence in problem-solving ability of the two agents on
grid navigation problems in two kinds of environment: randomly generated mazes,
and lake maps with wide open areas. We find that all navigation problems solved
by the Solver are also solved by the Controller, indicating the two are
equivalent.

</details>


### [32] [Improving ASP-based ORS Schedules through Machine Learning Predictions](https://arxiv.org/abs/2507.16454)
*Pierangela Bruno,Carmine Dodaro,Giuseppe Galatà,Marco Maratea,Marco Mochi*

Main category: cs.AI

TL;DR: 本文通过结合机器学习和答集编程(ASP)技术，解决手术室调度问题中无法生成临时调度和调度不够鲁棒的问题，使用历史数据预测手术时长并考虑预测置信度来计算更鲁棒的调度方案。


<details>
  <summary>Details</summary>
Motivation: 现有基于答集编程的手术室调度解决方案只能验证编码是否与实际数据对齐，最多建议可计算的替代调度，无法生成临时调度，且生成的调度方案不够鲁棒。

Method: 集成归纳和演绎技术：首先使用机器学习算法从历史数据中预测手术持续时间来计算临时调度；然后将预测置信度作为额外输入，相应更新编码以计算更鲁棒的调度方案。

Result: 在意大利利古里亚ASL1的历史数据上的实验结果证实了该集成方法的可行性，能够生成临时调度并提高调度的鲁棒性。

Conclusion: 通过将机器学习预测与答集编程相结合，成功解决了手术室调度问题中的关键限制，实现了临时调度生成和更鲁棒的调度计算，为实际医院运营提供了更实用的解决方案。

Abstract: The Operating Room Scheduling (ORS) problem deals with the optimization of
daily operating room surgery schedules. It is a challenging problem subject to
many constraints, like to determine the starting time of different surgeries
and allocating the required resources, including the availability of beds in
different department units. Recently, solutions to this problem based on Answer
Set Programming (ASP) have been delivered. Such solutions are overall
satisfying but, when applied to real data, they can currently only verify
whether the encoding aligns with the actual data and, at most, suggest
alternative schedules that could have been computed. As a consequence, it is
not currently possible to generate provisional schedules. Furthermore, the
resulting schedules are not always robust.
  In this paper, we integrate inductive and deductive techniques for solving
these issues. We first employ machine learning algorithms to predict the
surgery duration, from historical data, to compute provisional schedules. Then,
we consider the confidence of such predictions as an additional input to our
problem and update the encoding correspondingly in order to compute more robust
schedules. Results on historical data from the ASL1 Liguria in Italy confirm
the viability of our integration.
  Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [33] [Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs](https://arxiv.org/abs/2507.16473)
*Chang Li,Yaren Zhang,Haoran Lv,Qiong Cao,Chao Xue,Xiaodong He*

Main category: cs.AI

TL;DR: 本文提出了一种高效的隐式推理框架，通过分层强化学习中的选项(options)在潜在空间中进行"思考"，避免了显式链式思维推理的计算开销，并在复杂逻辑推理和运动控制任务上取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过显式的链式思维(CoT)提示展现出卓越的推理能力，但生成逐步的文本解释在计算上昂贵且缓慢。因此需要开发一种高效的隐式推理框架，让模型在潜在空间中"思考"而无需为每一步生成显式文本。

Method: 提出将潜在思维建模为分层强化学习框架中的时间扩展抽象动作(选项)。引入变分马尔可夫选项评估器(VMOC)作为离策略算法，使用变分推理学习多样化的选项库。扩展连续MDP同态理论为使用选项作为抽象推理空间提供理论基础。设计冷启动程序，利用监督微调数据将人类推理演示蒸馏到潜在选项空间中。

Result: 在复杂逻辑推理基准测试和具有挑战性的运动任务上进行的大量实验表明，该方法取得了强劲的性能表现，验证了框架作为学习语言和控制抽象技能的原则性方法的有效性。

Conclusion: 该框架成功实现了在潜在空间中的高效隐式推理，通过分层强化学习中的选项机制避免了显式文本生成的计算开销，为语言模型的抽象推理能力提供了一种原则性且高效的解决方案。

Abstract: Large Language Models (LLMs) have shown remarkable reasoning ability through
explicit Chain-of-Thought (CoT) prompting, but generating these step-by-step
textual explanations is computationally expensive and slow. To overcome this,
we aim to develop a framework for efficient, implicit reasoning, where the
model "thinks" in a latent space without generating explicit text for every
step. We propose that these latent thoughts can be modeled as
temporally-extended abstract actions, or options, within a hierarchical
reinforcement learning framework. To effectively learn a diverse library of
options as latent embeddings, we first introduce the Variational Markovian
Option Critic (VMOC), an off-policy algorithm that uses variational inference
within the HiT-MDP framework. To provide a rigorous foundation for using these
options as an abstract reasoning space, we extend the theory of continuous MDP
homomorphisms. This proves that learning a policy in the simplified, abstract
latent space, for which VMOC is suited, preserves the optimality of the
solution to the original, complex problem. Finally, we propose a cold-start
procedure that leverages supervised fine-tuning (SFT) data to distill human
reasoning demonstrations into this latent option space, providing a rich
initialization for the model's reasoning capabilities. Extensive experiments
demonstrate that our approach achieves strong performance on complex logical
reasoning benchmarks and challenging locomotion tasks, validating our framework
as a principled method for learning abstract skills for both language and
control.

</details>


### [34] [ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training](https://arxiv.org/abs/2507.16478)
*Shreya Saxena,Siva Prasad,Zishan Ahmad,Vishal Vaddina*

Main category: cs.AI

TL;DR: 本文提出了ACT（Auto-Train for Code Translation）框架，通过自动化微调开源大语言模型来改进代码翻译能力，使用合成数据生成和动态控制器管理整个训练流程，为开发者提供安全可靠的代码翻译替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统的自动化代码翻译方法依赖手工制作的转换规则，缺乏灵活性和可扩展性；而先进的语言模型虽然有前景，但往往受限于专有API实现，存在数据安全和依赖性问题。因此需要一个能够改进开源模型代码翻译能力的框架。

Method: ACT框架包含三个核心模块：1）合成数据生成模块：从初始代码样本构建大规模高质量数据集，结合单元测试确保功能准确性和多样性；2）评估框架：采用执行级检查提供全面的翻译质量评估；3）控制器模块：管理整个流程，动态调整超参数，基于实时评估协调迭代数据生成和微调过程。

Result: 实验结果表明ACT框架能够持续提升开源模型的效果，缩小了开源模型可访问性与闭源解决方案高性能之间的差距。将数据生成流程应用到工业级迁移项目中，显著提高了开发者的工作效率。

Conclusion: ACT为企业和开发者提供了一个安全可靠的代码翻译替代方案，通过自动化微调开源大语言模型，有效改进了代码翻译能力，并在实际工业应用中证明了其价值。

Abstract: Code translation is a crucial process in software development and migration
projects, enabling interoperability between different programming languages and
enhancing software adaptability and thus longevity. Traditional automated
translation methods rely heavily on handcrafted transformation rules, which
often lack flexibility and scalability. Meanwhile, advanced language models
present promising alternatives but are often limited by proprietary, API-based
implementations that raise concerns over data security and reliance. In this
paper, we present Auto-Train for Code Translation (ACT), an innovative
framework that aims to improve code translation capabilities by enabling
in-house finetuning of open-source Large Language Models (LLMs). ACT's
automated pipeline significantly boosts the performance of these models,
narrowing the gap between open-source accessibility and the high performance of
closed-source solutions. Central to ACT is its synthetic data generation
module, which builds extensive, high-quality datasets from initial code
samples, incorporating unit tests to ensure functional accuracy and diversity.
ACT's evaluation framework incorporates execution-level checks, offering a
comprehensive assessment of translation quality. A key feature in ACT is its
controller module, which manages the entire pipeline by dynamically adjusting
hyperparameters, orchestrating iterative data generation, and finetuning based
on real-time evaluations. This enables ACT to intelligently optimize when to
continue training, generate additional targeted training data, or stop the
process. Our results demonstrate that ACT consistently enhances the
effectiveness of open-source models, offering businesses and developers a
secure and reliable alternative. Additionally, applying our data generation
pipeline to industry-scale migration projects has led to a notable increase in
developer acceleration.

</details>


### [35] [Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications](https://arxiv.org/abs/2507.16507)
*Jean Lelong,Adnane Errazine,Annabelle Blangero*

Main category: cs.AI

TL;DR: 本文提出了INRAExplorer，一个基于智能体的检索增强生成(RAG)系统，专门用于探索法国国家农业食品与环境研究院(INRAE)的科学数据，通过多工具架构和知识图谱实现复杂查询处理和多跳推理。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强生成(RAG)系统在处理复杂查询时存在明显不足，只能提供有限的提取式答案，在多目标检索和复杂实体关系导航方面表现困难，这在知识密集型领域是一个关键缺陷。

Method: 引入INRAExplorer，一个基于LLM智能体的RAG系统，采用多工具架构来动态接入丰富的知识库，通过从开放获取的INRAE出版物构建的综合知识图谱来实现功能。

Result: INRAExplorer能够进行迭代式目标查询，检索详尽的数据集(如某作者的全部出版物)，执行多跳推理，并提供结构化的综合性答案。

Conclusion: INRAExplorer为在专业领域中增强知识交互提供了具体的解决方案示例，有效解决了传统RAG系统在复杂查询处理方面的局限性。

Abstract: Conventional Retrieval-Augmented Generation (RAG) systems enhance Large
Language Models (LLMs) but often fall short on complex queries, delivering
limited, extractive answers and struggling with multiple targeted retrievals or
navigating intricate entity relationships. This is a critical gap in
knowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system
for exploring the scientific data of INRAE (France's National Research
Institute for Agriculture, Food and Environment). INRAExplorer employs an
LLM-based agent with a multi-tool architecture to dynamically engage a rich
knowledge base, through a comprehensive knowledge graph derived from open
access INRAE publications. This design empowers INRAExplorer to conduct
iterative, targeted queries, retrieve exhaustive datasets (e.g., all
publications by an author), perform multi-hop reasoning, and deliver
structured, comprehensive answers. INRAExplorer serves as a concrete
illustration of enhancing knowledge interaction in specialized fields.

</details>


### [36] [Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report](https://arxiv.org/abs/2507.16534)
*Shanghai AI Lab,:,Xiaoyang Chen,Yunhao Chen,Zeren Chen,Zhiyun Chen,Hanyun Cui,Yawen Duan,Jiaxuan Guo,Qi Guo,Xuhao Hu,Hong Huang,Lige Huang,Chunxiao Li,Juncheng Li,Qihao Lin,Dongrui Liu,Xinmin Liu,Zicheng Liu,Chaochao Lu,Xiaoya Lu,Jingjing Qu,Qibing Ren,Jing Shao,Jingwei Shi,Jingwei Sun,Peng Wang,Weibing Wang,Jia Xu,Lewen Yan,Xiao Yu,Yi Yu,Boxuan Zhang,Jie Zhang,Weichen Zhang,Zhijie Zheng,Tianyi Zhou,Bowen Zhou*

Main category: cs.AI

TL;DR: 本研究提出了一个全面的AI前沿风险评估框架，通过E-T-C分析方法识别了七个关键风险领域，并使用红线、黄线和绿线系统对当前前沿AI模型进行风险分区评估，发现所有模型都处于绿区和黄区，未跨越红线。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能模型快速发展，需要理解和识别其带来的前所未有的风险，建立系统性的风险评估框架来指导AI的安全部署和发展。

Method: 采用前沿AI风险管理框架中的E-T-C分析方法（部署环境、威胁源、使能能力），识别七个关键风险领域，并基于"AI-45°定律"使用红线（不可容忍阈值）、黄线（早期警告指标）和绿线来划分风险区域。

Result: 所有近期前沿AI模型都处于绿区和黄区，未跨越红线。网络攻击和失控AI研发风险未达到黄线；自我复制和战略欺骗风险多数在绿区，部分推理模型在黄区；说服操控风险多数模型在黄区；生物化学风险无法排除多数模型处于黄区的可能性。

Conclusion: 当前对AI前沿风险的理解表明现有模型尚未达到最危险的红线阈值，但在多个领域存在需要警惕的黄区风险，需要集体行动来缓解这些挑战，加强风险管控和安全部署措施。

Abstract: To understand and identify the unprecedented risks posed by rapidly advancing
artificial intelligence (AI) models, this report presents a comprehensive
assessment of their frontier risks. Drawing on the E-T-C analysis (deployment
environment, threat source, enabling capability) from the Frontier AI Risk
Management Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks
in seven areas: cyber offense, biological and chemical risks, persuasion and
manipulation, uncontrolled autonomous AI R\&D, strategic deception and
scheming, self-replication, and collusion. Guided by the "AI-$45^\circ$ Law,"
we evaluate these risks using "red lines" (intolerable thresholds) and "yellow
lines" (early warning indicators) to define risk zones: green (manageable risk
for routine deployment and continuous monitoring), yellow (requiring
strengthened mitigations and controlled deployment), and red (necessitating
suspension of development and/or deployment). Experimental results show that
all recent frontier AI models reside in green and yellow zones, without
crossing red lines. Specifically, no evaluated models cross the yellow line for
cyber offense or uncontrolled AI R\&D risks. For self-replication, and
strategic deception and scheming, most models remain in the green zone, except
for certain reasoning models in the yellow zone. In persuasion and
manipulation, most models are in the yellow zone due to their effective
influence on humans. For biological and chemical risks, we are unable to rule
out the possibility of most models residing in the yellow zone, although
detailed threat modeling and in-depth assessment are required to make further
claims. This work reflects our current understanding of AI frontier risks and
urges collective action to mitigate these challenges.

</details>


### [37] [Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems](https://arxiv.org/abs/2507.16635)
*Ali Mohamed Ali,Luca Tirel,Hashim A. Hashim*

Main category: cs.AI

TL;DR: 本文提出了一种基于马尔可夫决策过程的工业装配线数学模型，并使用深度强化学习智能体进行任务和资源调度优化，通过动作掩码技术和多智能体方法提高训练效率，实现了比传统方法更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现代工业装配线需要高效的活动规划来维持制造标准、防止项目约束违规并实现成本效益运营。虽然整数规划可以提供精确解，但对于大规模场景往往计算不可行；遗传算法等启发式方法虽然适用，但在大规模案例中经常产生次优解。因此需要一种新的方法来解决装配线优化问题。

Method: 提出了一个通用工业装配线的马尔可夫决策过程数学模型，不对装配线类型做任何假设。使用该模型创建虚拟环境来训练深度强化学习智能体进行任务和资源调度优化。为提高训练效率，提出两个创新工具：1）动作掩码技术，确保智能体只选择可行动作；2）多智能体方法，每个工作站由独立智能体管理。采用集中训练分散执行的框架。

Result: 通过数值仿真验证了所提方案的有效性，与可比较的基于模型的方法相比，展示了显著更快的最优解收敛速度。该框架允许智能体离线学习，并在运营期间通过神经网络将当前工厂状态映射到最优动作来提供实时解决方案。

Conclusion: 提出的基于深度强化学习的工业装配线优化框架具有可扩展性，能够有效解决大规模装配线调度问题。通过马尔可夫决策过程建模、动作掩码技术和多智能体方法的结合，实现了比传统方法更高效的解决方案，为工业装配线的智能化优化提供了新的思路。

Abstract: Efficient planning of activities is essential for modern industrial assembly
lines to uphold manufacturing standards, prevent project constraint violations,
and achieve cost-effective operations. While exact solutions to such challenges
can be obtained through Integer Programming (IP), the dependence of the search
space on input parameters often makes IP computationally infeasible for
large-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also
be applied, but they frequently produce suboptimal solutions in extensive
cases. This paper introduces a novel mathematical model of a generic industrial
assembly line formulated as a Markov Decision Process (MDP), without imposing
assumptions on the type of assembly line a notable distinction from most
existing models. The proposed model is employed to create a virtual environment
for training Deep Reinforcement Learning (DRL) agents to optimize task and
resource scheduling. To enhance the efficiency of agent training, the paper
proposes two innovative tools. The first is an action-masking technique, which
ensures the agent selects only feasible actions, thereby reducing training
time. The second is a multi-agent approach, where each workstation is managed
by an individual agent, as a result, the state and action spaces were reduced.
A centralized training framework with decentralized execution is adopted,
offering a scalable learning architecture for optimizing industrial assembly
lines. This framework allows the agents to learn offline and subsequently
provide real-time solutions during operations by leveraging a neural network
that maps the current factory state to the optimal action. The effectiveness of
the proposed scheme is validated through numerical simulations, demonstrating
significantly faster convergence to the optimal solution compared to a
comparable model-based approach.

</details>


### [38] [Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains](https://arxiv.org/abs/2507.16670)
*Amandeep Kaur,Gyan Prakash*

Main category: cs.AI

TL;DR: 本研究提出了一种新颖的深度强化学习算法，结合价值基和策略基方法来优化农产品供应链中存在需求和交货时间不确定性的库存管理问题，以最大化整体利润并促进利益相关者协作。


<details>
  <summary>Details</summary>
Motivation: 农产品存在季节性生产和需求波动，传统库存管理方法难以应对需求和交货时间的不确定性，同时现有文献缺乏对食品供应链各层级利益相关者协调的考虑，导致库存过剩或缺货问题。

Method: 提出了一种结合价值基和策略基深度强化学习方法的新算法，通过连续动作空间选择最优订货量，同时考虑产品易腐性和不确定性，通过共享的利润最大化目标来激励供应链中利益相关者的协作。

Result: 基于新鲜农产品供应链库存的实证数据验证，实验结果表明所提出的库存补货策略在随机需求模式和交货时间场景下表现出改进的性能，有效解决了库存优化挑战。

Conclusion: 该研究为政策制定者在不确定性条件下更有效地管理农产品库存提供了管理启示，证明了深度强化学习方法在农产品供应链库存管理中的有效性和实用性。

Abstract: Agricultural products are often subject to seasonal fluctuations in
production and demand. Predicting and managing inventory levels in response to
these variations can be challenging, leading to either excess inventory or
stockouts. Additionally, the coordination among stakeholders at various level
of food supply chain is not considered in the existing body of literature. To
bridge these research gaps, this study focuses on inventory management of
agri-food products under demand and lead time uncertainties. By implementing
effective inventory replenishment policy results in maximize the overall profit
throughout the supply chain. However, the complexity of the problem increases
due to these uncertainties and shelf-life of the product, that makes
challenging to implement traditional approaches to generate optimal set of
solutions. Thus, the current study propose a novel Deep Reinforcement Learning
(DRL) algorithm that combines the benefits of both value- and policy-based DRL
approaches for inventory optimization under uncertainties. The proposed
algorithm can incentivize collaboration among stakeholders by aligning their
interests and objectives through shared optimization goal of maximizing
profitability along the agri-food supply chain while considering perishability,
and uncertainty simultaneously. By selecting optimal order quantities with
continuous action space, the proposed algorithm effectively addresses the
inventory optimization challenges. To rigorously evaluate this algorithm, the
empirical data from fresh agricultural products supply chain inventory is
considered. Experimental results corroborate the improved performance of the
proposed inventory replenishment policy under stochastic demand patterns and
lead time scenarios. The research findings hold managerial implications for
policymakers to manage the inventory of agricultural products more effectively
under uncertainty.

</details>


### [39] [Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints](https://arxiv.org/abs/2507.16727)
*Zhenyun Yin,Shujie Wang,Xuhong Wang,Xingjun Ma,Yinchun Wang*

Main category: cs.AI

TL;DR: 本文提出了Deliberative Searcher框架，这是首个将确定性校准与基于检索的搜索相结合的开放域问答系统，通过多步反思和验证提高大语言模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 提高大语言模型(LLMs)在现实场景部署中的可靠性是关键问题，需要解决模型置信度与正确性之间的对齐问题，以产生更可信的输出。

Method: 提出Deliberative Searcher框架，将确定性校准与基于检索的搜索相结合用于开放域问答；智能体在维基百科数据上执行多步反思和验证；使用强化学习算法训练，在软可靠性约束下优化准确性。

Result: 实验结果表明，所提出的方法改善了模型置信度与正确性之间的对齐，产生了更可信的输出。

Conclusion: Deliberative Searcher框架成功提高了大语言模型的可靠性，通过整合确定性校准和检索搜索，实现了置信度与准确性的更好对齐，为LLMs在实际应用中的部署提供了可信解决方案。

Abstract: Improving the reliability of large language models (LLMs) is critical for
deploying them in real-world scenarios. In this paper, we propose
\textbf{Deliberative Searcher}, the first framework to integrate certainty
calibration with retrieval-based search for open-domain question answering. The
agent performs multi-step reflection and verification over Wikipedia data and
is trained with a reinforcement learning algorithm that optimizes for accuracy
under a soft reliability constraint. Empirical results show that proposed
method improves alignment between model confidence and correctness, leading to
more trustworthy outputs. This paper will be continuously updated.

</details>


### [40] [WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding](https://arxiv.org/abs/2507.16768)
*Ran Wang,Xiaoxuan Liu,Hao Ren,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.AI

TL;DR: 提出了wgrammar，一个轻量级解码引擎，通过约束分解和掩码缓存等技术，将结构化解码速度提升了250倍


<details>
  <summary>Details</summary>
Motivation: 现有的结构化解码方法存在效率瓶颈，包括语法编译、状态跟踪和掩码创建等问题，需要一种更高效的解码方案来生成符合下游系统要求的格式化输出

Method: 将约束分解为静态和动态组件，静态结构离线预编译，运行时使用语法片段实例化动态参数；使用组合操作符集合而非下推自动机来建模常规格式；集成领域感知简化、约束分解和掩码缓存技术

Result: wgrammar解码引擎相比现有系统实现了高达250倍的加速，同时保持了生成HTML、JSON等结构化输出的能力

Conclusion: 通过约束分解和优化的操作符设计，可以显著提升大语言模型结构化解码的效率，为实际应用中的格式化输出生成提供了更实用的解决方案

Abstract: Structured decoding enables large language models (LLMs) to generate outputs
in formats required by downstream systems, such as HTML or JSON. However,
existing methods suffer from efficiency bottlenecks due to grammar compilation,
state tracking, and mask creation. We observe that many real-world tasks embed
strong prior knowledge about output structure. Leveraging this, we propose a
decomposition of constraints into static and dynamic components -- precompiling
static structures offline and instantiating dynamic arguments at runtime using
grammar snippets. Instead of relying on pushdown automata, we employ a
compositional set of operators to model regular formats, achieving lower
transition latency. We introduce wgrammar, a lightweight decoding engine that
integrates domain-aware simplification, constraint decomposition, and mask
caching, achieving up to 250x speedup over existing systems. wgrammar's source
code is publicly available at https://github.com/wrran/wgrammar.

</details>


### [41] [ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation](https://arxiv.org/abs/2507.16792)
*Roman Mayr,Michel Schimpf,Thomas Bohné*

Main category: cs.AI

TL;DR: 本文提出ChatChecker框架，用于自动化评估和测试复杂对话系统，通过LLM模拟用户交互来识别对话故障并评估质量，相比以往方法减少了设置工作量且具有更好的通用性。


<details>
  <summary>Details</summary>
Motivation: 现代对话系统通常集成多个LLM、外部工具和数据库，仅评估底层LLM不足以全面测试系统质量。现有工作主要关注回合级分析，缺乏对整体对话级质量保证的关注，这是一个重大挑战。

Method: 提出ChatChecker框架，使用LLM模拟多样化用户交互，识别对话故障并评估质量。设计不需要参考对话且与目标对话系统实现解耦。在提示中包含错误分类法来改进故障检测性能，并基于挑战性人格提出新颖的非合作用户模拟器。

Result: 相比之前基于LLM的方法，通过在提示中包含错误分类法提高了故障检测性能。非合作用户模拟器能更有效地发现目标对话系统的弱点，实现了全面且可扩展的测试。

Conclusion: ChatChecker为研究人员和实践者提供了加速开发稳健对话系统的工具，通过自动化评估框架实现了对复杂对话系统的全面测试，具有减少设置工作量、通用性强等优势。

Abstract: While modern dialogue systems heavily rely on large language models (LLMs),
their implementation often goes beyond pure LLM interaction. Developers
integrate multiple LLMs, external tools, and databases. Therefore, assessment
of the underlying LLM alone does not suffice, and the dialogue systems must be
tested and evaluated as a whole. However, this remains a major challenge. With
most previous work focusing on turn-level analysis, less attention has been
paid to integrated dialogue-level quality assurance. To address this, we
present ChatChecker, a framework for automated evaluation and testing of
complex dialogue systems. ChatChecker uses LLMs to simulate diverse user
interactions, identify dialogue breakdowns, and evaluate quality. Compared to
previous approaches, our design reduces setup effort and is generalizable, as
it does not require reference dialogues and is decoupled from the
implementation of the target dialogue system. We improve breakdown detection
performance over a prior LLM-based approach by including an error taxonomy in
the prompt. Additionally, we propose a novel non-cooperative user simulator
based on challenging personas that uncovers weaknesses in target dialogue
systems more effectively. Through this, ChatChecker contributes to thorough and
scalable testing. This enables both researchers and practitioners to accelerate
the development of robust dialogue systems.

</details>


### [42] [Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2507.16796)
*Mian Ibad Ali Shah,Enda Barrett,Karl Mason*

Main category: cs.AI

TL;DR: 本文提出了一个结合不确定性感知预测和多智能体强化学习的P2P能源交易框架，通过KTU模型量化预测不确定性，实现了更鲁棒的能源交易决策，显著降低了能源购买成本并增加了销售收入。


<details>
  <summary>Details</summary>
Motivation: 当前P2P能源交易研究主要依赖确定性预测，缺乏对预测不确定性的考虑，这在随机性很强的能源交易环境中会导致决策不够鲁棒。因此需要一个能够显式量化预测不确定性并将其整合到交易策略中的框架。

Method: 提出了一个集成不确定性感知预测和多智能体强化学习的P2P能源交易框架。核心组件包括：1）Knowledge Transformer with Uncertainty (KTU)模型，采用异方差概率变换器进行预测并量化不确定性；2）使用定制损失函数训练KTU以确保可靠的概率预测和置信区间；3）将不确定性感知预测整合到MARL框架中，使智能体能够在明确理解风险和变异性的情况下优化交易策略。

Result: 实验结果显示，不确定性感知的深度Q网络(DQN)在无P2P交易时降低能源购买成本高达5.7%，在有P2P交易时降低3.2%；同时分别增加电力销售收入6.4%和44.7%。此外，高峰时段电网需求在无P2P和有P2P情况下分别减少了38.8%和45.6%。

Conclusion: 研究表明，当启用P2P交易时，改进效果更加显著，突出了先进预测技术与市场机制之间的协同作用，为构建具有韧性和经济效率的能源社区提供了有效方案。不确定性感知预测与多智能体强化学习的结合为P2P能源交易提供了更鲁棒和高效的解决方案。

Abstract: This paper presents a novel framework for Peer-to-Peer (P2P) energy trading
that integrates uncertainty-aware prediction with multi-agent reinforcement
learning (MARL), addressing a critical gap in current literature. In contrast
to previous works relying on deterministic forecasts, the proposed approach
employs a heteroscedastic probabilistic transformer-based prediction model
called Knowledge Transformer with Uncertainty (KTU) to explicitly quantify
prediction uncertainty, which is essential for robust decision-making in the
stochastic environment of P2P energy trading. The KTU model leverages
domain-specific features and is trained with a custom loss function that
ensures reliable probabilistic forecasts and confidence intervals for each
prediction. Integrating these uncertainty-aware forecasts into the MARL
framework enables agents to optimize trading strategies with a clear
understanding of risk and variability. Experimental results show that the
uncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to
5.7% without P2P trading and 3.2% with P2P trading, while increasing
electricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak
hour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These
improvements are even more pronounced when P2P trading is enabled, highlighting
the synergy between advanced forecasting and market mechanisms for resilient,
economically efficient energy communities.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [43] [Fast Task Planning with Neuro-Symbolic Relaxation](https://arxiv.org/abs/2507.15975)
*Qiwei Du,Bowen Li,Yi Du,Shaoshu Su,Taimeng Fu,Zitong Zhan,Zhipeng Zhao,Chen Wang*

Main category: cs.RO

TL;DR: 本文提出了Flax方法，通过结合神经网络重要性预测和符号扩展来解决长时域任务规划中的组合爆炸问题，在迷宫导航任务中相比现有方法提升了20.82%的成功率并减少了17.65%的规划时间。


<details>
  <summary>Details</summary>
Motivation: 现实世界的长时域任务规划需要对大量具有复杂关系和属性的实体进行推理，这会导致经典符号规划器的组合爆炸问题。现有的神经符号集成方法虽然通过预测"重要"实体来简化任务，但存在遗漏关键实体和在不可解的简化任务上浪费资源的风险。

Method: 提出Flax神经符号松弛策略，包含三个步骤：1) 使用图神经网络预测实体重要性并创建简化任务；2) 解决规则松弛的任务获得粗糙规划，并将所有引用的实体重新整合到简化任务中；3) 应用互补规则来细化更新的任务，保持其可靠性和紧凑性。

Result: 在合成和真实世界迷宫导航基准测试中，Flax相比最先进的神经符号基线方法平均成功率提升了20.82%，平均规划时间减少了17.65%。

Conclusion: Flax为复杂环境中的快速、可扩展的长时域任务规划提供了一条实用的路径，有效解决了神经符号集成中的关键问题。

Abstract: Real-world task planning requires long-horizon reasoning over large sets of
entities with complex relationships and attributes, leading to a combinatorial
explosion for classical symbolic planners. To prune the search space, recent
methods prioritize searching on a simplified task only containing a few
"important" entities predicted by a neural network. However, such a simple
neuro-symbolic (NeSy) integration risks omitting critical entities and wasting
resources on unsolvable simplified tasks. To enable Fast and reliable planning,
we introduce a NeSy relaxation strategy (Flax), combining neural importance
prediction with symbolic expansion. Specifically, we first learn a graph neural
network to predict entity importance to create a simplified task and solve it
with a symbolic planner. Then, we solve a rule-relaxed task to obtain a quick
rough plan, and reintegrate all referenced entities into the simplified task to
recover any overlooked but essential elements. Finally, we apply complementary
rules to refine the updated task, keeping it both reliable and compact.
Extensive experiments are conducted on both synthetic and real-world maze
navigation benchmarks where a robot must traverse through a maze and interact
with movable objects. The results show that Flax boosts the average success
rate by 20.82% and cuts mean wall-clock planning time by 17.65% compared with
the state-of-the-art NeSy baseline. We expect that Flax offers a practical path
toward fast, scalable, long-horizon task planning in complex environments.

</details>


### [44] [A Comprehensive Evaluation of LiDAR Odometry Techniques](https://arxiv.org/abs/2507.16000)
*Easton Potokar,Michael Kaess*

Main category: cs.RO

TL;DR: 本文对激光雷达里程计(LiDAR Odometry)管道的各个组件进行了全面的消融研究和实证评估，并基于实验结果为未来LO管道设计提供了建议。


<details>
  <summary>Details</summary>
Motivation: 尽管激光雷达传感器在机器人状态估计中广泛应用，但之前的研究主要关注整体管道比较，缺乏对LO管道各个构建模块的详细消融研究，导致难以理解各组件的具体贡献。

Method: 总结了定义LO管道的各种技术，并在大量数据集上对这些LO组件进行实证评估，涵盖不同环境、激光雷达类型和车辆运动模式。

Result: 通过广泛的消融研究，识别出了LO管道中各个组件的性能表现，为不同应用场景下的组件选择提供了实证依据。

Conclusion: 基于实证研究结果，为未来LO管道的设计提供了具体建议，以实现最准确和可靠的性能表现。

Abstract: Light Detection and Ranging (LiDAR) sensors have become the sensor of choice
for many robotic state estimation tasks. Because of this, in recent years there
has been significant work done to fine the most accurate method to perform
state estimation using these sensors. In each of these prior works, an
explosion of possible technique combinations has occurred, with each work
comparing LiDAR Odometry (LO) "pipelines" to prior "pipelines". Unfortunately,
little work up to this point has performed the significant amount of ablation
studies comparing the various building-blocks of a LO pipeline. In this work,
we summarize the various techniques that go into defining a LO pipeline and
empirically evaluate these LO components on an expansive number of datasets
across environments, LiDAR types, and vehicle motions. Finally, we make
empirically-backed recommendations for the design of future LO pipelines to
provide the most accurate and reliable performance.

</details>


### [45] [Improved Semantic Segmentation from Ultra-Low-Resolution RGB Images Applied to Privacy-Preserving Object-Goal Navigation](https://arxiv.org/abs/2507.16034)
*Xuying Huang,Sicong Pan,Olga Zatsarynna,Juergen Gall,Maren Bennewitz*

Main category: cs.RO

TL;DR: 本文提出了一种在超低分辨率设置下的隐私保护语义机器人导航方法，通过联合学习的特征提取器和分割感知判别器来解决超低分辨率语义分割问题，在保护视觉隐私的同时提高导航成功率。


<details>
  <summary>Details</summary>
Motivation: 移动机器人中的用户隐私保护已成为关键问题。现有方法通常要么优先考虑下游机器人任务的性能，要么优先考虑隐私保护，后者往往会限制任务执行的有效性。需要在超低分辨率环境下实现语义机器人导航以保护视觉隐私。

Method: 引入了一种新颖的完全联合学习方法，集成了聚合特征提取器(agglomerative feature extractor)和分割感知判别器(segmentation-aware discriminator)来解决超低分辨率语义分割问题，从而实现隐私保护的语义对象目标导航。

Result: 该方法在超低分辨率语义分割任务上优于不同的基线方法，改进的分割结果提高了在真实世界隐私约束场景下语义对象目标导航的成功率。

Conclusion: 通过联合学习方法成功解决了隐私保护与机器人导航性能之间的平衡问题，在超低分辨率图像上实现了有效的语义分割和导航，为隐私保护的机器人应用提供了可行的解决方案。

Abstract: User privacy in mobile robotics has become a critical concern. Existing
methods typically prioritize either the performance of downstream robotic tasks
or privacy protection, with the latter often constraining the effectiveness of
task execution. To jointly address both objectives, we study semantic-based
robot navigation in an ultra-low-resolution setting to preserve visual privacy.
A key challenge in such scenarios is recovering semantic segmentation from
ultra-low-resolution RGB images. In this work, we introduce a novel fully
joint-learning method that integrates an agglomerative feature extractor and a
segmentation-aware discriminator to solve ultra-low-resolution semantic
segmentation, thereby enabling privacy-preserving, semantic object-goal
navigation. Our method outperforms different baselines on ultra-low-resolution
semantic segmentation and our improved segmentation results increase the
success rate of the semantic object-goal navigation in a real-world
privacy-constrained scenario.

</details>


### [46] [Therapist-Exoskeleton-Patient Interaction: An Immersive Gait Therapy](https://arxiv.org/abs/2507.16059)
*Emek Barış Küçüktabak,Matthew R. Short,Lorenzo Vianello,Daniel Ludvig,Levi Hargrove,Kevin Lynch,Jose Pons*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的步态康复方法，通过物理人-机器人-人交互(pHRHI)系统，让治疗师和中风患者同时穿戴下肢外骨骼，通过虚拟弹簧-阻尼元件连接，实现双向交互指导和反馈，在8名慢性中风患者的研究中显示出优于传统治疗师指导跑步机训练的效果。


<details>
  <summary>Details</summary>
Motivation: 中风后患者常出现下肢无力和独立关节控制丧失导致的行动和平衡障碍。传统的高强度治疗师指导训练虽然有效，但对治疗师体力要求高且难以同时操控多个关节。现有机器人外骨骼虽能提供多关节支持，但控制策略往往限制了治疗师的参与度和适应性。

Method: 开发了基于物理人-机器人-人交互(pHRHI)的步态康复新范式。治疗师和中风患者都穿戴下肢外骨骼，通过髋关节和膝关节的虚拟弹簧-阻尼元件连接，实现双向交互，使治疗师能够指导运动并接收触觉反馈。

Result: 在8名慢性中风患者的研究中，pHRHI训练相比传统治疗师指导的跑步机行走训练表现更佳，在关节活动范围、步态指标、肌肉激活和患者积极性方面都有显著提升。

Conclusion: pHRHI系统成功结合了机器人的精确性和治疗师的直觉判断，为改善康复效果提供了新的可能性，展现了在中风后步态康复领域的应用潜力。

Abstract: Following a stroke, individuals often experience mobility and balance
impairments due to lower-limb weakness and loss of independent joint control.
Gait recovery is a key goal of rehabilitation, traditionally achieved through
high-intensity therapist-led training. However, manual assistance can be
physically demanding and limits the therapist's ability to interact with
multiple joints simultaneously. Robotic exoskeletons offer multi-joint support,
reduce therapist strain, and provide objective feedback, but current control
strategies often limit therapist involvement and adaptability.
  We present a novel gait rehabilitation paradigm based on physical
Human-Robot-Human Interaction (pHRHI), where both the therapist and the
post-stroke individual wear lower-limb exoskeletons virtually connected at the
hips and knees via spring-damper elements. This enables bidirectional
interaction, allowing the therapist to guide movement and receive haptic
feedback. In a study with eight chronic stroke patients, pHRHI training
outperformed conventional therapist-guided treadmill walking, leading to
increased joint range of motion, step metrics, muscle activation, and
motivation. These results highlight pHRHI's potential to combine robotic
precision with therapist intuition for improved rehabilitation outcomes.

</details>


### [47] [Compositional Coordination for Multi-Robot Teams with Large Language Models](https://arxiv.org/abs/2507.16068)
*Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: 本文提出了LAN2CB框架，利用大型语言模型直接将自然语言任务描述转换为多机器人系统的可执行Python代码，简化了传统的专家驱动协调流水线


<details>
  <summary>Details</summary>
Motivation: 传统多机器人协调依赖任务特定的专家驱动流水线，需要领域专家手动将自然语言任务描述转换为数学公式、算法设计和可执行代码，这个过程劳动密集、非专家难以接触且对任务需求变化缺乏灵活性

Method: LAN2CB框架包含两个核心组件：(1)任务分解模块，将任务解析为带依赖关系的任务图；(2)代码生成模块，使用任务图和结构化知识库生成可部署的机器人控制代码。此外还引入了自然语言任务规范数据集用于开发和基准测试

Result: 在仿真和真实世界环境中的实验结果表明，LAN2CB能够从自然语言实现有效且灵活的多机器人协调，显著减少了手动工程的需求，同时支持跨任务类型的泛化

Conclusion: LAN2CB框架成功实现了从自然语言到多机器人协调的直接转换，为多机器人系统提供了更加通用、灵活和易于使用的解决方案，降低了技术门槛并提高了系统的适应性

Abstract: Multi-robot coordination has traditionally relied on a task-specific and
expert-driven pipeline, where natural language mission descriptions are
manually translated by domain experts into mathematical formulation, algorithm
design, and executable code. This conventional process is labor-intensive,
inaccessible to non-experts, and inflexible to changes in mission requirements.
Here, we propose LAN2CB (Language to Collective Behavior), a novel framework
that leverages large language models (LLMs) to streamline and generalize the
multi-robot coordination pipeline. LAN2CB directly converts natural language
mission descriptions into executable Python code for multi-robot systems
through two key components: (1) Mission Decomposition for Task Representation,
which parses the mission into a task graph with dependencies, and (2) Code
Generation, which uses the task graph and a structured knowledge base to
generate deployable robot control code. We further introduce a dataset of
natural language mission specifications to support development and
benchmarking. Experimental results in both simulation and real-world settings
show that LAN2CB enables effective and flexible multi-robot coordination from
natural language, significantly reducing the need for manual engineering while
supporting generalization across mission types. Website:
https://sites.google.com/view/lan2cb.

</details>


### [48] [FTIN: Frequency-Time Integration Network for Inertial Odometry](https://arxiv.org/abs/2507.16120)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一种融合频域和时域信息的新型网络架构用于惯性里程计，通过频域学习建模长期依赖关系并结合Scalar LSTM捕获时序依赖，在多个公开数据集上显著提升了定位精度


<details>
  <summary>Details</summary>
Motivation: 现有的惯性里程计方法主要依赖时域CNN，难以捕获IMU数据中的长期依赖关系，限制了定位精度的进一步提升

Method: 提出融合频域和时域信息的网络架构：利用频域学习的全局视角和能量压缩特性建模长期依赖并减少IMU数据冗余；引入Scalar LSTM捕获时域序列依赖；实现跨域信息融合为定位提供稳定可靠的参考

Result: 在多个公开数据集（RIDI、RoNIN、OxIOD、RNIN、TLIO、IMUNet）上验证了频域-时域融合策略的有效性；在RoNIN数据集上相比RoNIN ResNet实现了43.0%的绝对轨迹误差降低和13.1%的相对轨迹误差降低

Conclusion: 频域-时域融合的网络架构能够有效解决现有惯性里程计方法在长期依赖建模方面的不足，显著提升定位精度，为惯性导航系统的发展提供了新的技术路径

Abstract: In recent years, machine learning has achieved significant advancements in
inertial odometry. However, most existing inertial odometry methods primarily
rely on CNNs in the time domain. These methods often struggle to capture
long-term dependency in inertial measurement unit data, thereby constraining
the potential for further improvements in localization accuracy. To address
these issues, we propose a novel network architecture that integrates both
frequency-domain and time-domain information. Specifically, we leverage the
global view and energy compaction properties of frequency-domain learning to
effectively model long-term dependency and reduce redundancy in IMU data.
Additionally, we introduce a Scalar LSTM to capture sequential dependencies in
the time domain, enabling cross-domain information fusion and providing a
stable and reliable reference for localization. Experimental evaluations on
multiple public datasets (e.g., RIDI, RoNIN, OxIOD, RNIN, TLIO, and IMUNet)
demonstrate the effectiveness of the proposed frequency-time domain fusion
strategy. Notably, on the RoNIN dataset, our method achieves a 43.0% reduction
in absolute trajectory error and a 13.1% reduction in relative trajectory error
compared to RoNIN ResNet.

</details>


### [49] [DWSFormer: A Lightweight Inertial Odometry Network for Complex Motion Modeling](https://arxiv.org/abs/2507.16121)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一个轻量级惯性里程计框架，通过Star Operation方法将惯性数据投影到高维隐式非线性特征空间，结合协同注意力机制和多尺度门控卷积单元，显著提升了复杂运动模式下的定位精度，在RoNIN数据集上ATE误差降低2.26%-65.78%。


<details>
  <summary>Details</summary>
Motivation: 现有惯性里程计方法在简单线性运动轨迹上表现良好，但在转弯等复杂运动模式下会产生漂移误差，严重影响定位精度，限制了消费级定位系统的实际应用。需要开发能够处理复杂运动模式的惯性里程计技术。

Method: 使用Star Operation方法将惯性数据投影到高维隐式非线性特征空间来提取复杂运动特征；引入协同注意力机制对通道和时间维度的全局运动动态进行联合建模；设计多尺度门控卷积单元捕获运动过程中的细粒度动态变化，增强模型学习丰富运动表示的能力。

Result: 在六个广泛使用的惯性数据集上持续超越SOTA基线方法。在RoNIN数据集上相比基线模型，ATE误差降低范围为2.26%到65.78%，在该领域建立了新的基准。

Conclusion: 该轻量级惯性里程计框架通过创新的特征提取和注意力机制，有效解决了复杂运动模式下的漂移问题，显著提升了定位精度，为消费级定位系统的广泛部署提供了核心技术支撑。

Abstract: Inertial odometry (IO) directly estimates the position of a carrier from
inertial sensor measurements and serves as a core technology for the widespread
deployment of consumer grade localization systems. While existing IO methods
can accurately reconstruct simple and near linear motion trajectories, they
often fail to account for drift errors caused by complex motion patterns such
as turning. This limitation significantly degrades localization accuracy and
restricts the applicability of IO systems in real world scenarios. To address
these challenges, we propose a lightweight IO framework. Specifically, inertial
data is projected into a high dimensional implicit nonlinear feature space
using the Star Operation method, enabling the extraction of complex motion
features that are typically overlooked. We further introduce a collaborative
attention mechanism that jointly models global motion dynamics across both
channel and temporal dimensions. In addition, we design Multi Scale Gated
Convolution Units to capture fine grained dynamic variations throughout the
motion process, thereby enhancing the model's ability to learn rich and
expressive motion representations. Extensive experiments demonstrate that our
proposed method consistently outperforms SOTA baselines across six widely used
inertial datasets. Compared to baseline models on the RoNIN dataset, it
achieves reductions in ATE ranging from 2.26% to 65.78%, thereby establishing a
new benchmark in the field.

</details>


### [50] [Benchmarking LLM Privacy Recognition for Social Robot Decision Making](https://arxiv.org/abs/2507.16124)
*Dakota Sullivan,Shirley Zhang,Jennica Li,Heather Kirkorian,Bilge Mutlu,Kassem Fawaz*

Main category: cs.RO

TL;DR: 本研究探讨了大语言模型驱动的社交机器人在家庭环境中的隐私意识问题，发现当前LLM在隐私保护方面与人类用户的偏好存在显著差异，并提出了改进策略。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型技术的发展，社交机器人能够更好地与人类交互，但在家庭环境中这些机器人需要收集敏感个人信息（音频、图像、视频、位置等），因此迫切需要评估LLM在处理敏感数据时的隐私意识能力。

Method: 采用情境完整性(Contextual Integrity, CI)理论构建隐私相关场景，首先调查用户对家庭社交机器人行为的隐私偏好(N=450)，然后将相同场景提供给10个最先进的大语言模型进行测试，并实施四种额外的提示策略来比较结果。

Result: 研究发现人类用户和大语言模型之间在隐私判断上的一致性很低，说明当前的LLM缺乏足够的隐私意识。通过不同的提示策略可以在一定程度上改善LLM的隐私判断能力。

Conclusion: 当前的大语言模型在作为隐私控制器方面能力有限，需要进一步研究和改进AI系统的隐私意识，以确保LLM驱动的社交机器人能够更好地保护用户隐私并符合人类的隐私期望。

Abstract: Social robots are embodied agents that interact with people while following
human communication norms. These robots interact using verbal and non-verbal
cues, and share the physical environments of people. While social robots have
previously utilized rule-based systems or probabilistic models for user
interaction, the rapid evolution of large language models (LLMs) presents new
opportunities to develop LLM-empowered social robots for enhanced human-robot
interaction. To fully realize these capabilities, however, robots need to
collect data such as audio, fine-grained images, video, and locations. As a
result, LLMs often process sensitive personal information, particularly within
home environments. Given the tension between utility and privacy risks,
evaluating how current LLMs manage sensitive data is critical. Specifically, we
aim to explore the extent to which out-of-the-box LLMs are privacy-aware in the
context of household social robots. In this study, we present a set of
privacy-relevant scenarios crafted through the lens of Contextual Integrity
(CI). We first survey users' privacy preferences regarding in-home social robot
behaviors and then examine how their privacy orientation affects their choices
of these behaviors (N = 450). We then provide the same set of scenarios and
questions to state-of-the-art LLMs (N = 10) and find that the agreement between
humans and LLMs is low. To further investigate the capabilities of LLMs as a
potential privacy controller, we implement four additional prompting strategies
and compare their results. Finally, we discuss the implications and potential
of AI privacy awareness in human-robot interaction.

</details>


### [51] [Equivariant Goal Conditioned Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.16139)
*Arsh Tangri,Nichols Crawford Taylor,Haojie Huang,Robert Platt*

Main category: cs.RO

TL;DR: 本文提出了等变对比强化学习(ECRL)，通过利用目标条件操作任务中的旋转对称性来改进对比强化学习，在状态表示和图像表示设置下都显著提升了样本效率和空间泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的对比强化学习(CRL)虽然能从无标签交互中学习有用的结构化表示，但缺乏对潜在空间的进一步结构化约束。机器人操作任务具有内在的对称性(如旋转对称性)，可以被利用来改进学习效率和泛化能力。

Method: 提出等变对比强化学习(ECRL)方法：1)正式定义了目标条件群不变马尔可夫决策过程来刻画旋转对称的机器人操作任务；2)引入新颖的旋转不变批评器表示与旋转等变演员相配合；3)通过等变约束进一步结构化潜在空间，利用任务的内在对称性。

Result: 在多个仿真任务中，该方法在状态表示和图像表示设置下都持续超越了强基线方法，显示出更好的样本效率和空间泛化能力。此外，该方法还成功扩展到离线强化学习设置，在多个任务中展现了有效性。

Conclusion: 等变对比强化学习通过利用目标条件操作任务的旋转对称性，有效改进了对比强化学习的性能。旋转不变批评器与旋转等变演员的组合设计能够更好地结构化潜在空间，从而提升样本效率和泛化能力，并且该方法可以成功应用于离线强化学习场景。

Abstract: Contrastive Reinforcement Learning (CRL) provides a promising framework for
extracting useful structured representations from unlabeled interactions. By
pulling together state-action pairs and their corresponding future states,
while pushing apart negative pairs, CRL enables learning nontrivial policies
without manually designed rewards. In this work, we propose Equivariant CRL
(ECRL), which further structures the latent space using equivariant
constraints. By leveraging inherent symmetries in goal-conditioned manipulation
tasks, our method improves both sample efficiency and spatial generalization.
Specifically, we formally define Goal-Conditioned Group-Invariant MDPs to
characterize rotation-symmetric robotic manipulation tasks, and build on this
by introducing a novel rotation-invariant critic representation paired with a
rotation-equivariant actor for Contrastive RL. Our approach consistently
outperforms strong baselines across a range of simulated tasks in both
state-based and image-based settings. Finally, we extend our method to the
offline RL setting, demonstrating its effectiveness across multiple tasks.

</details>


### [52] [Scanning Bot: Efficient Scan Planning using Panoramic Cameras](https://arxiv.org/abs/2507.16175)
*Euijeong Lee,Kyung Min Han,Young J. Kim*

Main category: cs.RO

TL;DR: 提出了一个全自主的扫描规划系统，用于全景RGB-D相机的3D场景重建，通过自动生成高效的扫描路径来解决手动操作的耗时和复杂性问题


<details>
  <summary>Details</summary>
Motivation: 全景RGB-D相机虽然能产生高质量的3D场景重建，但需要手动选择视点和物理搬运相机，使得3D模型生成过程耗时且繁琐。对于新手用户来说，由于空间约束（如确保视点帧之间有足够的特征重叠）使得操作过程更加困难

Method: 提出了一个全自主的扫描规划方法，能够为环境扫描生成高效的路径规划，确保无碰撞导航和规划内视点之间的充分重叠

Result: 在合成和真实世界环境中进行的大量实验验证了该规划器相对于最先进视图规划器的性能。在真实世界实验中，该方法实现了平均99%的扫描覆盖率，总扫描时间比最先进的规划器快3倍

Conclusion: 该全自主扫描规划系统成功解决了全景RGB-D相机手动操作的局限性，在保证高扫描覆盖率的同时显著提升了扫描效率，为3D场景重建提供了更加实用和高效的解决方案

Abstract: Panoramic RGB-D cameras are known for their ability to produce high quality
3D scene reconstructions. However, operating these cameras involves manually
selecting viewpoints and physically transporting the camera, making the
generation of a 3D model time consuming and tedious. Additionally, the process
can be challenging for novice users due to spatial constraints, such as
ensuring sufficient feature overlap between viewpoint frames. To address these
challenges, we propose a fully autonomous scan planning that generates an
efficient tour plan for environment scanning, ensuring collision-free
navigation and adequate overlap between viewpoints within the plan. Extensive
experiments conducted in both synthetic and real-world environments validate
the performance of our planner against state-of-the-art view planners. In
particular, our method achieved an average scan coverage of 99 percent in the
real-world experiment, with our approach being up to 3 times faster than
state-of-the-art planners in total scan time.

</details>


### [53] [Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers](https://arxiv.org/abs/2507.16214)
*Batu Candan,Simone Servadio*

Main category: cs.RO

TL;DR: 本文提出了一个完整的相对位姿估计管道，结合CNN和自适应UKF滤波器，用于主动碎片清除任务中翻滚卫星的鲁棒导航


<details>
  <summary>Details</summary>
Motivation: 准确且鲁棒的相对位姿估计对于实现具有挑战性的主动碎片清除（ADR）任务至关重要，特别是针对像ESA的ENVISAT这样的翻滚废弃卫星目标

Method: 集成先进计算机视觉技术与自适应非线性滤波：使用经过图像预处理增强的卷积神经网络（CNN）从追踪器图像中检测结构标记（角点），将2D坐标通过相机建模转换为3D测量值，然后在无迹卡尔曼滤波器（UKF）框架内融合这些测量值。采用双自适应策略：动态调整测量噪声协方差以补偿CNN测量不确定性的变化，以及利用测量残差分析自适应调整过程噪声协方差来在线处理未建模动力学或机动

Result: 通过使用真实ENVISAT模型的高保真仿真评估了所提出的自适应集成系统性能，在各种条件下（包括测量中断）将估计结果与真实值进行比较。双自适应策略增强了对测量缺陷和动态模型不确定性的鲁棒性

Conclusion: 这种综合方法为鲁棒的星载相对导航提供了增强解决方案，显著提升了ADR任务中安全邻近操作所需的能力

Abstract: Accurate and robust relative pose estimation is crucial for enabling
challenging Active Debris Removal (ADR) missions targeting tumbling derelict
satellites such as ESA's ENVISAT. This work presents a complete pipeline
integrating advanced computer vision techniques with adaptive nonlinear
filtering to address this challenge. A Convolutional Neural Network (CNN),
enhanced with image preprocessing, detects structural markers (corners) from
chaser imagery, whose 2D coordinates are converted to 3D measurements using
camera modeling. These measurements are fused within an Unscented Kalman Filter
(UKF) framework, selected for its ability to handle nonlinear relative
dynamics, to estimate the full relative pose. Key contributions include the
integrated system architecture and a dual adaptive strategy within the UKF:
dynamic tuning of the measurement noise covariance compensates for varying CNN
measurement uncertainty, while adaptive tuning of the process noise covariance,
utilizing measurement residual analysis, accounts for unmodeled dynamics or
maneuvers online. This dual adaptation enhances robustness against both
measurement imperfections and dynamic model uncertainties. The performance of
the proposed adaptive integrated system is evaluated through high-fidelity
simulations using a realistic ENVISAT model, comparing estimates against ground
truth under various conditions, including measurement outages. This
comprehensive approach offers an enhanced solution for robust onboard relative
navigation, significantly advancing the capabilities required for safe
proximity operations during ADR missions.

</details>


### [54] [GFM-Planner: Perception-Aware Trajectory Planning with Geometric Feature Metric](https://arxiv.org/abs/2507.16233)
*Yue Lin,Xiaoxuan Zhang,Yang Liu,Dong Wang,Huchuan Lu*

Main category: cs.RO

TL;DR: 提出了GFM-Planner，一个基于几何特征度量的感知感知轨迹规划框架，通过引导机器人避开退化区域来提高LiDAR定位精度


<details>
  <summary>Details</summary>
Motivation: 自主机器人依赖特征丰富的环境进行准确定位，类似于人类依靠地标进行方向定位，需要开发一种能够主动选择轨迹以提高LiDAR定位能力的规划框架

Method: 1) 从基础LiDAR定位问题中推导出几何特征度量(GFM)；2) 设计基于2D网格的度量编码图(MEM)来高效存储环境中的GFM值；3) 提出常数时间解码算法从MEM中检索任意姿态的GFM值；4) 开发感知感知轨迹规划算法，引导机器人选择通过特征丰富区域的轨迹

Result: 仿真和真实世界实验都证明该方法能够使机器人主动选择显著提高LiDAR定位精度的轨迹

Conclusion: GFM-Planner框架成功地通过几何特征度量指导轨迹规划，有效提高了机器人的LiDAR定位能力，为自主机器人导航提供了新的解决方案

Abstract: Like humans who rely on landmarks for orientation, autonomous robots depend
on feature-rich environments for accurate localization. In this paper, we
propose the GFM-Planner, a perception-aware trajectory planning framework based
on the geometric feature metric, which enhances LiDAR localization accuracy by
guiding the robot to avoid degraded areas. First, we derive the Geometric
Feature Metric (GFM) from the fundamental LiDAR localization problem. Next, we
design a 2D grid-based Metric Encoding Map (MEM) to efficiently store GFM
values across the environment. A constant-time decoding algorithm is further
proposed to retrieve GFM values for arbitrary poses from the MEM. Finally, we
develop a perception-aware trajectory planning algorithm that improves LiDAR
localization capabilities by guiding the robot in selecting trajectories
through feature-rich areas. Both simulation and real-world experiments
demonstrate that our approach enables the robot to actively select trajectories
that significantly enhance LiDAR localization accuracy.

</details>


### [55] [Trajectory Planning of a Curtain Wall Installation Robot Based on Biomimetic Mechanisms](https://arxiv.org/abs/2507.16305)
*Xiao Liu,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本研究提出了一种受人体上肢举重运动启发的机器人轨迹规划框架，通过模拟人类力量施展和能量消耗模式，结合粒子群优化算法，在幕墙安装任务中实现了48.4%的能耗降低。


<details>
  <summary>Details</summary>
Motivation: 随着机器人市场快速发展，能耗问题成为关键挑战，特别是限制了建筑机器人的应用。为解决这一挑战，研究团队从人体上肢举重运动的力学机制中汲取灵感，希望通过融合人类能量转换原理来优化机器人的能耗表现。

Method: 通过收集哑铃弯举过程中的运动轨迹和肌电图(EMG)信号，构建融合人类力量施展模式和能量消耗模式的拟人化轨迹规划。利用粒子群优化(PSO)算法，基于类人运动特征实现机械臂轨迹规划的动态负载分配，并将这些仿生运动特性应用于幕墙安装任务。

Result: 仿真结果显示，通过动能和势能之间的智能转换，该方法实现了48.4%的能耗降低。在幕墙安装任务的实际应用中验证了该轨迹规划方法的正确性和优越性。

Conclusion: 该方法为幕墙安装机器人在实际搬运任务中的能耗优化提供了新的见解和理论支持，证明了仿生学方法在解决机器人能耗问题方面的有效性和实用性。

Abstract: As the robotics market rapidly evolves, energy consumption has become a
critical issue, particularly restricting the application of construction
robots. To tackle this challenge, our study innovatively draws inspiration from
the mechanics of human upper limb movements during weight lifting, proposing a
bio-inspired trajectory planning framework that incorporates human energy
conversion principles. By collecting motion trajectories and electromyography
(EMG) signals during dumbbell curls, we construct an anthropomorphic trajectory
planning that integrates human force exertion patterns and energy consumption
patterns. Utilizing the Particle Swarm Optimization (PSO) algorithm, we achieve
dynamic load distribution for robotic arm trajectory planning based on
human-like movement features. In practical application, these bio-inspired
movement characteristics are applied to curtain wall installation tasks,
validating the correctness and superiority of our trajectory planning method.
Simulation results demonstrate a 48.4% reduction in energy consumption through
intelligent conversion between kinetic and potential energy. This approach
provides new insights and theoretical support for optimizing energy use in
curtain wall installation robots during actual handling tasks.

</details>


### [56] [Design and Dimensional Optimization of Legged Structures for Construction Robots](https://arxiv.org/abs/2507.16328)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文针对建筑环境提出了一种仿生蚂蚁的腿部配置设计优化方法，通过多维工作空间分析和平均可操作性概念，为建筑机器人在复杂地形中的自主移动提供结构设计基础。


<details>
  <summary>Details</summary>
Motivation: 轮式和履带式机器人在复杂非结构化建筑环境中地形适应性和灵活性存在显著局限，难以满足自主作业要求，因此需要设计更适合建筑场景的腿式机器人配置。

Method: 基于运动学建模和多维工作空间分析引入"改进工作空间"概念，使用图形化方法优化摆动相腿部尺寸；基于速度雅可比矩阵引入"平均可操作性"概念，采用数值解获得最大可操作性的腿段比例；在ADAMS中进行虚拟样机仿真探索机器人本体最优灵活性与腿段比例的关系。

Result: 获得了具有最佳综合运动性能的腿段比例，建立了首个针对建筑环境的腿部运动性能多维定量评估框架。

Conclusion: 研究为腿式建筑机器人在复杂地形中实现自主移动提供了结构设计基础，通过仿生设计和多维优化方法有效提升了建筑机器人的地形适应性和运动灵活性。

Abstract: Faced with complex and unstructured construction environments, wheeled and
tracked robots exhibit significant limitations in terrain adaptability and
flexibility, making it difficult to meet the requirements of autonomous
operation. Inspired by ants in nature, this paper proposes a leg configuration
design and optimization method tailored for construction scenarios, aiming to
enhance the autonomous mobility of construction robots. This paper analyzes the
full operational motion performance of the leg during both swing and stance
phases. First, based on kinematic modeling and multi-dimensional workspace
analysis, the concept of an "improved workspace" is introduced, and graphical
methods are used to optimize the leg dimensions during the swing phase.
Furthermore, a new concept of "average manipulability" is introduced based on
the velocity Jacobian matrix, and numerical solutions are applied to obtain the
leg segment ratio that maximizes manipulability. To overcome the difficulties
associated with traditional analytical methods, virtual prototype simulations
are conducted in ADAMS to explore the relationship between the robot body's
optimal flexibility and leg segment proportions. In summary, the leg segment
proportions with the best comprehensive motion performance are obtained. This
study presents the first multi-dimensional quantitative evaluation framework
for leg motion performance tailored for construction environments, providing a
structural design foundation for legged construction robots to achieve
autonomous mobility in complex terrains.

</details>


### [57] [Topology Optimization of Leg Structures for Construction Robots Based on Variable Density Method](https://arxiv.org/abs/2507.16335)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本研究针对建筑机器人腿部结构提出基于SIMP变密度方法的拓扑优化策略，通过对股骨段进行优化重构，实现股骨质量减轻19.45%，整体腿部质量减轻7.92%的轻量化设计目标，为复杂建筑环境中的机器人设计提供技术支撑。


<details>
  <summary>Details</summary>
Motivation: 在复杂地形建筑环境中，机器人需要同时具备高载荷能力和移动灵活性，而腿部结构作为关键承重部件，其优化设计对机器人性能至关重要。因此需要研究建筑机器人腿部结构的优化方法，以实现轻量化设计。

Method: 采用基于SIMP（固体各向同性微结构惩罚）变密度方法的拓扑优化策略，结合结构重新设计方法。首先对初始设计进行静力学和模态分析评估合理性，然后对占腿部重量最大比例的股骨段应用SIMP变密度拓扑优化方法，基于迭代计算进行股骨二次结构重构，并使用ANSYS有限元分析验证设计性能。

Result: 优化后股骨质量减轻19.45%，整体腿部质量减少7.92%，实现了轻量化设计目标。对重构后的腿部进行静力学和模态分析，结果表明优化后的腿部仍满足结构性能要求，验证了轻量化设计的可行性。

Conclusion: 本研究成功实现了建筑机器人腿部结构的轻量化优化设计，在保证结构性能的前提下显著减轻了重量。该研究为轻量化建筑机器人设计提供了坚实的理论和技术支撑，为其在复杂建筑环境中的高效运行奠定了基础。

Abstract: In complex terrain construction environments, there are high demands for
robots to achieve both high payload capacity and mobility flexibility. As the
key load-bearing component, the optimization of robotic leg structures is of
particular importance. Therefore, this study focuses on the optimization of leg
structures for construction robots, proposing a topology optimization strategy
based on the SIMP (Solid Isotropic Microstructures with Penalization) variable
density method along with a structural re-design approach. The design
performance is comprehensively validated through finite element analysis using
ANSYS. First, static and modal analyses are conducted to evaluate the
rationality of the initial design. Then, topology optimization using the
SIMP-based variable density method is applied to the femur section, which
accounts for the largest proportion of the leg's weight. Based on iterative
calculations, the femur undergoes secondary structural reconstruction. After
optimization, the mass of the femur is reduced by 19.45\%, and the overall leg
mass decreases by 7.92\%, achieving the goal of lightweight design. Finally,
static and modal analyses are conducted on the reconstructed leg. The results
demonstrate that the optimized leg still meets structural performance
requirements, validating the feasibility of lightweight design. This research
provides robust theoretical and technical support for lightweight construction
robot design and lays a foundation for their efficient operation in complex
construction environments.

</details>


### [58] [Humanoid Robot Whole-body Geometric Calibration with Embedded Sensors and a Single Plane](https://arxiv.org/abs/2507.16369)
*Thanh D V Nguyen,Vincent Bonnet,Pierre Fernbach,David Daney,Florent Lamiraux*

Main category: cs.RO

TL;DR: 提出了一种使用单平面、嵌入式力传感器和导纳控制器的人形机器人全身几何标定新方法，无需人工干预，并开发了IROC算法来选择最少的最优标定姿态


<details>
  <summary>Details</summary>
Motivation: 传统的人形机器人全身几何标定方法耗时长、实验负担重，尽管对精确控制和仿真很重要，但在人形机器人社区中经常被忽视

Method: 提出了使用单平面、嵌入式力传感器和导纳控制器的实用标定方法，以及IROC（信息排序算法）来选择最优标定姿态。IROC通过为每个姿态构建归一化加权信息矩阵，确定最少数量的最优姿态用于机器人标定

Result: 在TALOS人形机器人上验证，仅使用31个最优姿态通过机器人抓手在桌面上的3点接触完成全身运动链标定。交叉验证实验中，平均均方根误差比制造商模型减少了2.3倍

Conclusion: 该方法成功实现了人形机器人全身运动学的高效自动化标定，显著提高了标定精度，为人形机器人的精确控制和仿真提供了实用解决方案

Abstract: Whole-body geometric calibration of humanoid robots using classical robot
calibration methods is a timeconsuming and experimentally burdensome task.
However, despite its significance for accurate control and simulation, it is
often overlooked in the humanoid robotics community. To address this issue, we
propose a novel practical method that utilizes a single plane, embedded force
sensors, and an admittance controller to calibrate the whole-body kinematics of
humanoids without requiring manual intervention. Given the complexity of
humanoid robots, it is crucial to generate and determine a minimal set of
optimal calibration postures. To do so, we propose a new algorithm called IROC
(Information Ranking algorithm for selecting Optimal Calibration postures).
IROC requires a pool of feasible candidate postures to build a normalized
weighted information matrix for each posture. Then, contrary to other
algorithms from the literature, IROC will determine the minimal number of
optimal postures that are to be played onto a robot for its calibration. Both
IROC and the single-plane calibration method were experimentally validated on a
TALOS humanoid robot. The total whole-body kinematics chain was calibrated
using solely 31 optimal postures with 3-point contacts on a table by the robot
gripper. In a cross-validation experiment, the average root-mean-square (RMS)
error was reduced by a factor of 2.3 compared to the manufacturer's model.

</details>


### [59] [Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance](https://arxiv.org/abs/2507.16382)
*Chenhao Yao,Zike Yuan,Xiaoxu Liu,Chi Zhu*

Main category: cs.RO

TL;DR: 本文提出了一个基于大语言模型的新框架，用于解决多智能体强化学习中编队控制与避碰问题的奖励函数设计难题，通过动态调整奖励函数实现更高效的策略学习。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在处理编队控制与避碰(FCCA)这类复杂目标时，面临设计有效奖励函数的挑战，难以使策略网络快速收敛到最优解。传统方法在复杂动态环境中效率不高，需要更多迭代才能达到理想性能。

Method: 提出了一个基于大语言模型的新框架，通过让LLM理解任务优先级和各智能体可观察信息，生成可动态调整的奖励函数。该框架采用更先进的评估指标而非奖励本身来在线调整奖励函数，使多智能体系统能够同时实现编队控制和障碍物避免。

Result: 实验研究在仿真和真实环境中验证了该方法的实用性和有效性。相比传统方法，该框架能够以更少的迭代次数达到更优的性能水平，在动态环境中同时实现编队控制和避碰的效率显著提升。

Conclusion: 基于大语言模型的动态奖励函数调整框架成功解决了多智能体强化学习中编队控制与避碰的奖励设计难题，提高了学习效率和性能，在仿真和实际应用中都展现了良好的实用性和有效性。

Abstract: Multi-Agent Systems (MAS) excel at accomplishing complex objectives through
the collaborative efforts of individual agents. Among the methodologies
employed in MAS, Multi-Agent Reinforcement Learning (MARL) stands out as one of
the most efficacious algorithms. However, when confronted with the complex
objective of Formation Control with Collision Avoidance (FCCA): designing an
effective reward function that facilitates swift convergence of the policy
network to an optimal solution. In this paper, we introduce a novel framework
that aims to overcome this challenge. By giving large language models (LLMs) on
the prioritization of tasks and the observable information available to each
agent, our framework generates reward functions that can be dynamically
adjusted online based on evaluation outcomes by employing more advanced
evaluation metrics rather than the rewards themselves. This mechanism enables
the MAS to simultaneously achieve formation control and obstacle avoidance in
dynamic environments with enhanced efficiency, requiring fewer iterations to
reach superior performance levels. Our empirical studies, conducted in both
simulation and real-world settings, validate the practicality and effectiveness
of our proposed approach.

</details>


### [60] [AI or Human? Understanding Perceptions of Embodied Robots with LLMs](https://arxiv.org/abs/2507.16398)
*Lavinia Hriscu,Alberto Sanfeliu,Anais Garrell*

Main category: cs.RO

TL;DR: 该研究通过在机器人平台上实施图灵测试，探讨了具身机器人的智能感知问题。34名参与者在信息检索和包裹交接两个交互任务中无法可靠区分AI控制和人类控制的机器人，为未来交互机器人设计提供了见解。


<details>
  <summary>Details</summary>
Motivation: 图灵测试作为评估系统智能的手段，其在人机交互领域的相关性和应用仍未得到充分探索。研究旨在通过具身机器人平台上的图灵测试来调查人们对机器人智能的感知。

Method: 招募34名参与者，让他们在两个交互任务（信息检索和包裹交接）中区分AI控制和人类控制的机器人。这些任务在静态和动态条件下评估机器人的感知和导航能力。

Result: 参与者无法可靠地区分AI控制和人类控制的机器人，区分准确率仅为随机水平。通过分析参与者反应，识别出影响具身机器人系统中人工智能与人类智能感知的关键因素。

Conclusion: 研究结果为未来交互机器人的设计提供了见解，并为AI驱动系统中智能评估的持续讨论做出了贡献。表明当前AI技术在具身机器人应用中已达到较高的拟人化水平。

Abstract: The pursuit of artificial intelligence has long been associated to the the
challenge of effectively measuring intelligence. Even if the Turing Test was
introduced as a means of assessing a system intelligence, its relevance and
application within the field of human-robot interaction remain largely
underexplored. This study investigates the perception of intelligence in
embodied robots by performing a Turing Test within a robotic platform. A total
of 34 participants were tasked with distinguishing between AI- and
human-operated robots while engaging in two interactive tasks: an information
retrieval and a package handover. These tasks assessed the robot perception and
navigation abilities under both static and dynamic conditions. Results indicate
that participants were unable to reliably differentiate between AI- and
human-controlled robots beyond chance levels. Furthermore, analysis of
participant responses reveals key factors influencing the perception of
artificial versus human intelligence in embodied robotic systems. These
findings provide insights into the design of future interactive robots and
contribute to the ongoing discourse on intelligence assessment in AI-driven
systems.

</details>


### [61] [Distributed Oscillatory Guidance for Formation Flight of Fixed-Wing Drones](https://arxiv.org/abs/2507.16458)
*Yang Xu,Jesús Bautista,José Hinojosa,Héctor García de Marina*

Main category: cs.RO

TL;DR: 本文提出了一种固定翼无人机编队飞行算法，通过在引导向量场上叠加振荡行为来控制平均速度，实现无需调节飞行速度的编队协调控制


<details>
  <summary>Details</summary>
Motivation: 固定翼无人机的速度控制受到严格限制，且大多设计为在标称空速下飞行，这使得需要速度调节的编队飞行变得困难

Method: 提出引导所有无人机沿特定路径（如平行直线）飞行，在引导向量场上叠加振荡行为来控制沿路径的平均速度；每架无人机通过与邻近代理通信，以分布式闭环方式调节其振荡幅度；引入采用非负非对称饱和函数的新型一致性算法

Result: 通过数值仿真和真实世界编队飞行验证了算法的有效性，实现了无需速度调节的固定翼无人机编队飞行

Conclusion: 所提出的基于振荡行为的编队控制算法能够有效解决固定翼无人机编队飞行中的速度约束问题，为实际应用提供了可行的解决方案

Abstract: The autonomous formation flight of fixed-wing drones is hard when the
coordination requires the actuation over their speeds since they are critically
bounded and aircraft are mostly designed to fly at a nominal airspeed. This
paper proposes an algorithm to achieve formation flights of fixed-wing drones
without requiring any actuation over their speed. In particular, we guide all
the drones to travel over specific paths, e.g., parallel straight lines, and we
superpose an oscillatory behavior onto the guiding vector field that drives the
drones to the paths. This oscillation enables control over the average velocity
along the path, thereby facilitating inter-drone coordination. Each drone
adjusts its oscillation amplitude distributively in a closed-loop manner by
communicating with neighboring agents in an undirected and connected graph. A
novel consensus algorithm is introduced, leveraging a non-negative, asymmetric
saturation function. This unconventional saturation is justified since negative
amplitudes do not make drones travel backward or have a negative velocity along
the path. Rigorous theoretical analysis of the algorithm is complemented by
validation through numerical simulations and a real-world formation flight.

</details>


### [62] [Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots](https://arxiv.org/abs/2507.16480)
*Sabrina Livanec,Laura Londoño,Michael Gorki,Adrian Röfer,Abhinav Valada,Andrea Kiesel*

Main category: cs.RO

TL;DR: 该研究通过在线实验评估了112名参与者对不同人机协作场景的看法，发现反社会机器人行为评分最低，与老年人的协作引发更敏感的评估，物体传递场景比无传递场景评价更积极，强调了亲社会设计的重要性


<details>
  <summary>Details</summary>
Motivation: 目前关于参与者如何评估不同机器人行为与多样化人类需求结合的研究稀缺，特别是针对残疾人或高龄等受保护群体的辅助机器人社会协作设计缺乏负责任和包容性的研究

Method: 采用在线研究方法，112名参与者（实验组和对照组）评估了28种人机协作类型变化中的7个视频。实验组在评分前先完成认知-情感映射（CAM）练习，对照组直接评分

Result: CAM反思虽未显著影响整体评分，但对特定机器人行为和人类条件组合产生了更明显的评估。反社会机器人行为评分一致最低，与老年人协作引发更敏感评价，涉及物体传递的场景比无传递场景评价更积极

Conclusion: 人类特征和交互范式都会影响协作机器人的可接受性感知，强调了亲社会设计的重要性。CAM等反思方法有潜力引发细致入微的反馈，支持开发面向用户、社会负责且适应不同人群的机器人系统

Abstract: The development of assistive robots for social collaboration raises critical
questions about responsible and inclusive design, especially when interacting
with individuals from protected groups such as those with disabilities or
advanced age. Currently, research is scarce on how participants assess varying
robot behaviors in combination with diverse human needs, likely since
participants have limited real-world experience with advanced domestic robots.
In the current study, we aim to address this gap while using methods that
enable participants to assess robot behavior, as well as methods that support
meaningful reflection despite limited experience. In an online study, 112
participants (from both experimental and control groups) evaluated 7 videos
from a total of 28 variations of human-robot collaboration types. The
experimental group first completed a cognitive-affective mapping (CAM) exercise
on human-robot collaboration before providing their ratings. Although CAM
reflection did not significantly affect overall ratings, it led to more
pronounced assessments for certain combinations of robot behavior and human
condition. Most importantly, the type of human-robot collaboration influences
the assessment. Antisocial robot behavior was consistently rated as the lowest,
while collaboration with aged individuals elicited more sensitive evaluations.
Scenarios involving object handovers were viewed more positively than those
without them. These findings suggest that both human characteristics and
interaction paradigms influence the perceived acceptability of collaborative
robots, underscoring the importance of prosocial design. They also highlight
the potential of reflective methods, such as CAM, to elicit nuanced feedback,
supporting the development of user-centered and socially responsible robotic
systems tailored to diverse populations.

</details>


### [63] [Guided Reinforcement Learning for Omnidirectional 3D Jumping in Quadruped Robots](https://arxiv.org/abs/2507.16481)
*Riccardo Bussola,Michele Focchi,Giulio Turrisi,Claudio Semini,Luigi Palopoli*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的引导式强化学习方法，结合贝塞尔曲线和匀加速直线运动模型，用于四足机器人的高效可解释跳跃控制，克服了传统优化方法耗时长和端到端强化学习样本复杂度高的问题。


<details>
  <summary>Details</summary>
Motivation: 四足机器人跳跃控制面临重大挑战：传统优化方法耗时且需要大量机器人和地形参数知识，在真实场景中缺乏鲁棒性；传统端到端强化学习方法样本复杂度高，需要大量仿真训练，且最终运动的可预测性差，难以保证安全性认证。

Method: 提出一种新颖的引导式强化学习方法，通过结合贝塞尔曲线与匀加速直线运动(UARM)模型来利用物理直觉，实现高效且可解释的跳跃控制。

Result: 大量仿真和实验结果清楚地证明了该方法相比现有替代方案的优势。

Conclusion: 所提出的引导式强化学习方法成功解决了四足机器人跳跃控制中的效率和可解释性问题，在仿真和实验中均表现出明显优势。

Abstract: Jumping poses a significant challenge for quadruped robots, despite being
crucial for many operational scenarios. While optimisation methods exist for
controlling such motions, they are often time-consuming and demand extensive
knowledge of robot and terrain parameters, making them less robust in
real-world scenarios. Reinforcement learning (RL) is emerging as a viable
alternative, yet conventional end-to-end approaches lack efficiency in terms of
sample complexity, requiring extensive training in simulations, and
predictability of the final motion, which makes it difficult to certify the
safety of the final motion. To overcome these limitations, this paper
introduces a novel guided reinforcement learning approach that leverages
physical intuition for efficient and explainable jumping, by combining B\'ezier
curves with a Uniformly Accelerated Rectilinear Motion (UARM) model. Extensive
simulation and experimental results clearly demonstrate the advantages of our
approach over existing alternatives.

</details>


### [64] [A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System](https://arxiv.org/abs/2507.16621)
*Lorenzo Gentilini,Pierpaolo Serio,Valentina Donzella,Lorenzo Pollini*

Main category: cs.RO

TL;DR: 本文提出了一种基于标定板的多激光雷达和多摄像头外参标定系统，使用定制的ChArUco标定板和非线性优化方法，在仓库环境的真实数据上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中外参标定的准确性对感知流水线至关重要，任何误差都可能影响车辆安全。现代传感器系统收集不同类型的环境数据，使得数据对齐变得更加困难，因此需要一个有效的多传感器外参标定方法。

Method: 提出了一种基于标定板的外参标定系统，专门针对多激光雷达和多摄像头传感器套件设计。该系统使用定制的ChArUco标定板，结合量身定制的非线性优化方法，能够在有限先验知识的情况下实现激光雷达和摄像头之间的交叉标定。

Result: 在仓库环境中收集的真实世界数据上测试了该系统，结果证明了所提出方法的有效性，突出了针对各种类型传感器的独特标定流水线的可行性。

Conclusion: 实验结果验证了所提出的多传感器外参标定方法的有效性，表明该方法能够成功实现多激光雷达和多摄像头系统的精确标定，为自动驾驶感知系统提供了可靠的标定解决方案。

Abstract: Extrinsic Calibration represents the cornerstone of autonomous driving. Its
accuracy plays a crucial role in the perception pipeline, as any errors can
have implications for the safety of the vehicle. Modern sensor systems collect
different types of data from the environment, making it harder to align the
data. To this end, we propose a target-based extrinsic calibration system
tailored for a multi-LiDAR and multi-camera sensor suite. This system enables
cross-calibration between LiDARs and cameras with limited prior knowledge using
a custom ChArUco board and a tailored nonlinear optimization method. We test
the system with real-world data gathered in a warehouse. Results demonstrated
the effectiveness of the proposed method, highlighting the feasibility of a
unique pipeline tailored for various types of sensors.

</details>


### [65] [Morpheus: A Neural-driven Animatronic Face with Hybrid Actuation and Diverse Emotion Control](https://arxiv.org/abs/2507.16645)
*Zongzheng Zhang,Jiawen Yang,Ziqiao Peng,Meng Yang,Jianzhu Ma,Lin Cheng,Huazhe Xu,Hang Zhao,Hao Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种混合驱动的动画面部机器人系统，结合刚性和柔性驱动机制，通过自建模网络实现从语音输入到情感表达的自动控制，能够生成多种细致的面部表情。


<details>
  <summary>Details</summary>
Motivation: 以往的动画面部机器人在情感表达方面存在硬件和软件限制：刚性驱动机制控制精确但设计困难，腱驱动机制节省空间但控制复杂，且缺乏从语音输入直接生成情感特定控制信号的能力。

Method: 提出混合驱动方法：眼部和嘴部采用刚性机制实现精确控制，鼻部和脸颊采用绳索驱动实现微表情控制；开发自建模网络将电机动作映射到面部关键点，通过梯度反向传播建立混合形状系数与电机控制信号的关系；训练神经网络将语音输入映射到相应的混合形状控制。

Result: 系统能够从任意给定句子生成快乐、恐惧、厌恶、愤怒等不同的情感表达，每种表情都具有细致的、情感特定的控制信号，这是早期系统未能实现的功能。

Conclusion: 成功构建了紧凑且多功能的硬件平台，实现了广泛的情感表达能力，并开源了硬件设计和软件代码，为动画面部机器人的情感表达提供了新的解决方案。

Abstract: Previous animatronic faces struggle to express emotions effectively due to
hardware and software limitations. On the hardware side, earlier approaches
either use rigid-driven mechanisms, which provide precise control but are
difficult to design within constrained spaces, or tendon-driven mechanisms,
which are more space-efficient but challenging to control. In contrast, we
propose a hybrid actuation approach that combines the best of both worlds. The
eyes and mouth-key areas for emotional expression-are controlled using rigid
mechanisms for precise movement, while the nose and cheek, which convey subtle
facial microexpressions, are driven by strings. This design allows us to build
a compact yet versatile hardware platform capable of expressing a wide range of
emotions. On the algorithmic side, our method introduces a self-modeling
network that maps motor actions to facial landmarks, allowing us to
automatically establish the relationship between blendshape coefficients for
different facial expressions and the corresponding motor control signals
through gradient backpropagation. We then train a neural network to map speech
input to corresponding blendshape controls. With our method, we can generate
distinct emotional expressions such as happiness, fear, disgust, and anger,
from any given sentence, each with nuanced, emotion-specific control signals-a
feature that has not been demonstrated in earlier systems. We release the
hardware design and code at https://github.com/ZZongzheng0918/Morpheus-Hardware
and https://github.com/ZZongzheng0918/Morpheus-Software.

</details>


### [66] [Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory](https://arxiv.org/abs/2507.16713)
*Guowei Lan,Kaixian Qu,René Zurbrügg,Changan Chen,Christopher E. Mower,Haitham Bou-Ammar,Marco Hutter*

Main category: cs.RO

TL;DR: ExpTeach是一个通过构建自生成的真实世界经验记忆来将视觉语言模型（VLMs）应用于物理机器人的框架，通过反思机制和长期记忆检索显著提升了机器人任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型虽然在机器人自主规划中被广泛采用，但将原本在互联网数据上训练的VLMs适配到多样化的真实世界机器人仍然是一个挑战，需要一种有效的方法来连接模型与物理机器人操作。

Method: ExpTeach框架通过以下方式工作：1）VLM自主规划动作、验证结果、反思失败并在闭环中调整机器人行为；2）将自生成的经验总结为长期记忆；3）通过检索增强生成（RAG）检索学习到的知识指导未来任务；4）使用按需图像标注模块增强VLMs的空间理解能力。

Result: 实验结果显示：1）反思机制将四个挑战性机器人任务的成功率从36%提升到84%；2）观察到智能物体交互的出现，包括创造性工具使用；3）在12个真实世界场景（包括8个未见过的场景）的广泛测试中，长期记忆的应用将单次试验成功率从22%提升到80%。

Conclusion: ExpTeach通过自生成经验记忆和反思机制有效地将视觉语言模型适配到物理机器人，显著提升了机器人任务的成功率和泛化能力，为VLMs在真实世界机器人应用中的部署提供了有效解决方案。

Abstract: Vision-language models (VLMs) have been widely adopted in robotics to enable
autonomous planning. However, grounding VLMs, originally trained on internet
data, to diverse real-world robots remains a challenge. This paper presents
ExpTeach, a framework that grounds VLMs to physical robots by building a
self-generated memory of real-world experiences. In ExpTeach, the VLM
autonomously plans actions, verifies outcomes, reflects on failures, and adapts
robot behaviors in a closed loop. The self-generated experiences during this
process are then summarized into a long-term memory, enabling retrieval of
learned knowledge to guide future tasks via retrieval-augmented generation
(RAG). Additionally, ExpTeach enhances the spatial understanding of VLMs with
an on-demand image annotation module. In experiments, we show that reflection
improves success rates from 36% to 84% on four challenging robotic tasks and
observe the emergence of intelligent object interactions, including creative
tool use. Across extensive tests on 12 real-world scenarios (including eight
unseen ones), we find that grounding with long-term memory boosts single-trial
success rates from 22% to 80%, demonstrating the effectiveness and
generalizability of ExpTeach.

</details>
