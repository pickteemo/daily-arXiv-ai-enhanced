<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 52]
- [cs.RO](#cs.RO) [Total: 35]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Efficient Agents: Building Effective Agents While Reducing Cost](https://arxiv.org/abs/2508.02694)
*Ningning Wang,Xavier Hu,Pai Liu,He Zhu,Yue Hou,Heyuan Huang,Shengyu Zhang,Jian Yang,Jiaheng Liu,Ge Zhang,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: 本文研究了LLM驱动代理系统的效率与性能权衡，提出了Efficient Agents框架，在保持高性能的同时显著降低成本。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理系统复杂性和成本的增加，亟需一种既能保持性能又经济高效的解决方案。

Method: 通过实证分析GAIA基准，评估LLM主干选择、代理框架设计和测试时扩展策略的影响，提出Efficient Agents框架。

Result: Efficient Agents在保持96.7%性能的同时，将运营成本从$0.398降至$0.228，成本效率提升28.4%。

Conclusion: 研究为设计高效、高性能代理系统提供了实用见解，推动了AI驱动的解决方案的可及性和可持续性。

Abstract: The remarkable capabilities of Large Language Model (LLM)-driven agents have
enabled sophisticated systems to tackle complex, multi-step tasks, but their
escalating costs threaten scalability and accessibility. This work presents the
first systematic study of the efficiency-effectiveness trade-off in modern
agent systems, addressing the critical need for cost-effective designs without
sacrificing performance. We investigate three key questions: (1) How much
complexity do agentic tasks inherently require? (2) When do additional modules
yield diminishing returns? (3) How much efficiency can be gained through the
design of efficient agent frameworks? Through an empirical analysis on the GAIA
benchmark, we evaluate the impact of LLM backbone selection, agent framework
designs, and test-time scaling strategies. Using the cost-of-pass metric, we
quantify the efficiency-performance trade-off across these dimensions. Our
findings inform the development of Efficient Agents , a novel agent framework
that has an optimal complexity to task requirements. Efficient Agents retains
96.7% of the performance of OWL, one leading open-source agent framework, while
reducing operational costs from $0.398 to $0.228, resulting in a 28.4%
improvement in cost-of-pass. Our work provides actionable insights for
designing efficient, high-performing agent systems, advancing the accessibility
and sustainability of AI-driven solutions.

</details>


### [2] [Planning with Dynamically Changing Domains](https://arxiv.org/abs/2508.02697)
*Mikhail Soutchanski,Yongmei Liu*

Main category: cs.AI

TL;DR: 论文研究了动态对象变化的规划问题，提出了一种基于一阶逻辑的方法，解决了传统规划中域闭包假设的限制。


<details>
  <summary>Details</summary>
Motivation: 传统规划假设对象集合固定，但实际应用中对象可能动态变化，因此需要一种新方法解决此类问题。

Method: 使用一阶逻辑描述规划问题，限制初始理论为有限的流文字集合，并规定计划长度的有限整数界限，提出基于动作序列的搜索方法。

Result: 证明了方法的完备性和可靠性，适用于无域闭包假设的有限规划问题。

Conclusion: 该方法为动态对象变化的规划问题提供了理论基础，并通过概念验证实现展示了可行性。

Abstract: In classical planning and conformant planning, it is assumed that there are
finitely many named objects given in advance, and only they can participate in
actions and in fluents. This is the Domain Closure Assumption (DCA). However,
there are practical planning problems where the set of objects changes
dynamically as actions are performed; e.g., new objects can be created, old
objects can be destroyed. We formulate the planning problem in first-order
logic, assume an initial theory is a finite consistent set of fluent literals,
discuss when this guarantees that in every situation there are only finitely
many possible actions, impose a finite integer bound on the length of the plan,
and propose to organize search over sequences of actions that are grounded at
planning time. We show the soundness and completeness of our approach. It can
be used to solve the bounded planning problems without DCA that belong to the
intersection of sequential generalized planning (without sensing actions) and
conformant planning, restricted to the case without the disjunction over fluent
literals. We discuss a proof-of-the-concept implementation of our planner.

</details>


### [3] [Recovering Individual-Level Activity Sequences from Location-Based Service Data Using a Novel Transformer-Based Model](https://arxiv.org/abs/2508.02734)
*Weiyu Luo,Chenfeng Xiong*

Main category: cs.AI

TL;DR: 提出VSNIT模型，通过结合插入变换器和变量选择网络，恢复不完整的活动序列，提升LBS数据的实用性。


<details>
  <summary>Details</summary>
Motivation: LBS数据稀疏导致活动序列不完整，难以准确推断人类移动行为，需一种方法恢复缺失部分。

Method: 提出VSNIT模型，结合插入变换器的灵活序列构建和变量选择网络的动态协变量处理能力，恢复缺失活动序列。

Result: VSNIT能插入更多样、真实的活动模式，更接近真实世界变异性，且在所有指标上显著优于基线模型。

Conclusion: VSNIT在活动序列恢复任务中表现出更高的准确性和多样性，为未来基于位置的研究和应用提供框架。

Abstract: Location-Based Service (LBS) data provides critical insights into human
mobility, yet its sparsity often yields incomplete trip and activity sequences,
making accurate inferences about trips and activities difficult. We raise a
research problem: Can we use activity sequences derived from high-quality LBS
data to recover incomplete activity sequences at the individual level? This
study proposes a new solution, the Variable Selection Network-fused Insertion
Transformer (VSNIT), integrating the Insertion Transformer's flexible sequence
construction with the Variable Selection Network's dynamic covariate handling
capability, to recover missing segments in incomplete activity sequences while
preserving existing data. The findings show that VSNIT inserts more diverse,
realistic activity patterns, more closely matching real-world variability, and
restores disrupted activity transitions more effectively aligning with the
target. It also performs significantly better than the baseline model across
all metrics. These results highlight VSNIT's superior accuracy and diversity in
activity sequence recovery tasks, demonstrating its potential to enhance LBS
data utility for mobility analysis. This approach offers a promising framework
for future location-based research and applications.

</details>


### [4] [Large Language Model-based Data Science Agent: A Survey](https://arxiv.org/abs/2508.02744)
*Peiran Wang,Yaoning Yu,Ke Chen,Xianyang Zhan,Haohan Wang*

Main category: cs.AI

TL;DR: 本文综述了基于大语言模型（LLM）的代理在数据科学任务中的应用，从代理和数据科学双视角分析了设计原则与工作流程。


<details>
  <summary>Details</summary>
Motivation: 探索LLM代理在数据科学任务中的潜力，填补现有研究的空白。

Method: 通过综述近期研究，总结代理设计原则（角色、执行、知识、反思）和数据科学工作流程（预处理、模型开发、评估、可视化等）。

Result: 提出了一个双视角框架，连接代理设计原则与数据科学实践。

Conclusion: LLM代理在数据科学中具有广泛应用前景，未来研究可进一步优化其设计和工作流程。

Abstract: The rapid advancement of Large Language Models (LLMs) has driven novel
applications across diverse domains, with LLM-based agents emerging as a
crucial area of exploration. This survey presents a comprehensive analysis of
LLM-based agents designed for data science tasks, summarizing insights from
recent studies. From the agent perspective, we discuss the key design
principles, covering agent roles, execution, knowledge, and reflection methods.
From the data science perspective, we identify key processes for LLM-based
agents, including data preprocessing, model development, evaluation,
visualization, etc. Our work offers two key contributions: (1) a comprehensive
review of recent developments in applying LLMbased agents to data science
tasks; (2) a dual-perspective framework that connects general agent design
principles with the practical workflows in data science.

</details>


### [5] [Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science](https://arxiv.org/abs/2508.02789)
*Newman Cheng,Gordon Broadbent,William Chappell*

Main category: cs.AI

TL;DR: 论文提出了一种名为CLIO的方法，通过动态优化实现AI的深度推理控制，显著提升了GPT-4.1在生物学和医学问题上的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有AI框架在科学发现中缺乏透明性和可操控性，科学家需要一种能够精确控制推理过程的方法。

Method: CLIO通过动态优化和开放设计，使LLM能够自主调整推理策略，并提供可视化推理过程和不确定性评估。

Result: CLIO将GPT-4.1在HLE考试中的准确率提升了13.82%（相对提升161.64%），并揭示了内部不确定性波动对结果的影响。

Conclusion: CLIO为科学决策提供了透明且可控的AI推理工具，其开放设计有助于理解AI的决策机制。

Abstract: The capacity for artificial intelligence (AI) to formulate, evolve, and test
altered thought patterns under dynamic conditions indicates advanced cognition
that is crucial for scientific discovery. The existing AI development landscape
falls into two categories: 1) frameworks over non-reasoning models that
natively incorporate opinions on how humans think, and 2) reasoning models that
abstract precise control of the reasoning intuition away from end users. While
powerful, for scientists to maximize utility of AI in scientific discovery,
they not only require accuracy and transparency in reasoning, but also
steerability. Hence, we introduce an alternative approach that enables deep and
precise control over the reasoning process called: a cognitive loop via in-situ
optimization (CLIO). CLIO enables large language models (LLMs) to
self-formulate ways of approaching a problem, adapt behavior when
self-confidence is low, and ultimately provide scientists with a final belief
or answer. Through CLIO's open design, scientists can observe uncertainty
levels, understand how final belief states are formulated using graph
structures, and interject corrections. Without any further post-training,
OpenAI's GPT-4.1 with CLIO yields an accuracy of 22.37\% in text-based biology
and medicine questions on Humanity's Last Exam (HLE). This yields a 13.82\% net
or 161.64\% relative increase when compared to the base GPT-4.1 model and
surpasses OpenAI's o3 performance in high and low reasoning effort modes. We
further discovered that oscillations within internal uncertainty measures are
key in determining the accuracy of CLIO's results, revealing how its open
design and internal mechanisms can provide insight and control into scientific
decision-making processes.

</details>


### [6] [A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering](https://arxiv.org/abs/2508.02841)
*Ziruo Yi,Jinyu Liu,Ting Xiao,Mark V. Albert*

Main category: cs.AI

TL;DR: 提出了一种多代理系统（MAS）用于放射学视觉问答（RVQA），通过专门代理处理上下文理解、多模态推理和答案验证，解决了现有方法在事实准确性、幻觉和跨模态对齐方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 减轻放射科医生的工作负担，同时解决现有基于多模态大语言模型（MLLMs）和检索增强生成（RAG）方法在RVQA中的不足，如事实准确性、幻觉和跨模态对齐问题。

Method: 设计了一个多代理系统（MAS），包含专门代理分别负责上下文理解、多模态推理和答案验证，并通过模型分歧过滤筛选的挑战性RVQA数据集进行评估。

Result: 实验表明，该系统在多个MLLM基线上表现出优越性和有效性，案例研究展示了其可靠性和可解释性。

Conclusion: 多代理方法在需要复杂推理的可解释和可信赖临床AI应用中具有潜力。

Abstract: Radiology visual question answering (RVQA) provides precise answers to
questions about chest X-ray images, alleviating radiologists' workload. While
recent methods based on multimodal large language models (MLLMs) and
retrieval-augmented generation (RAG) have shown promising progress in RVQA,
they still face challenges in factual accuracy, hallucinations, and cross-modal
misalignment. We introduce a multi-agent system (MAS) designed to support
complex reasoning in RVQA, with specialized agents for context understanding,
multimodal reasoning, and answer validation. We evaluate our system on a
challenging RVQA set curated via model disagreement filtering, comprising
consistently hard cases across multiple MLLMs. Extensive experiments
demonstrate the superiority and effectiveness of our system over strong MLLM
baselines, with a case study illustrating its reliability and interpretability.
This work highlights the potential of multi-agent approaches to support
explainable and trustworthy clinical AI applications that require complex
reasoning.

</details>


### [7] [Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game](https://arxiv.org/abs/2508.02900)
*Michael Katz,Harsha Kokel,Sarath Sreedharan*

Main category: cs.AI

TL;DR: 论文提出了一种基于游戏Countdown的规划能力评估基准，解决了现有基准的不足，并通过理论分析和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有规划能力评估基准存在不足，无法准确衡量基础模型和智能体的长期规划能力。

Method: 提出一种基于Countdown游戏的规划基准生成方法，并进行理论分析和实验评估。

Result: 动态基准对现有LLM辅助规划方法极具挑战性，优于其他类似基准。

Conclusion: Countdown基准为规划能力评估提供了更有效的工具，填补了现有空白。

Abstract: There is a broad consensus that the inability to form long-term plans is one
of the key limitations of current foundational models and agents. However, the
existing planning benchmarks remain woefully inadequate to truly measure their
planning capabilities. Most existing benchmarks either focus on loosely defined
tasks like travel planning or end up leveraging existing domains and problems
from international planning competitions. While the former tasks are hard to
formalize and verify, the latter were specifically designed to test and
challenge the weaknesses of existing automated planners. To address these
shortcomings, we propose a procedure for creating a planning benchmark centered
around the game called Countdown, where a player is expected to form a target
number from a list of input numbers through arithmetic operations. We discuss
how this problem meets many of the desiderata associated with an ideal
benchmark for planning capabilities evaluation. Specifically, the domain allows
for an intuitive, natural language description for each problem instance, it is
computationally challenging (NP-complete), and the instance space is rich
enough that we do not have to worry about memorization. We perform an extensive
theoretical analysis, establishing the computational complexity result and
demonstrate the advantage of our instance generation procedure over public
benchmarks. We evaluate a variety of existing LLM-assisted planning methods on
instances generated using our procedure. Our results show that, unlike other
domains like 24 Game (a special case of Countdown), our proposed dynamic
benchmark remains extremely challenging for existing LLM-based approaches.

</details>


### [8] [Enhancing Japanese Large Language Models with Reasoning Vectors](https://arxiv.org/abs/2508.02913)
*Carolina Minami Oguchi,Leo Wei,Koyo Kobayashi,Hsin-Tai Wu,Dipak Ghosal*

Main category: cs.AI

TL;DR: 通过从推理LLMs中提取推理向量并应用于日语LLMs，提升其性能，解决了资源不足的问题。


<details>
  <summary>Details</summary>
Motivation: 由于资源限制，日语LLMs的性能提升和推理能力增强具有挑战性。

Method: 从推理LLMs中提取推理向量，并将其应用于日语LLMs。

Result: 提出了一种简单有效的方法，显著提升了日语LLMs的性能。

Conclusion: 该方法为其他语言LLMs的性能提升提供了启发。

Abstract: Post-training methods have improved the performance and enhanced the
reasoning capability for mainstream large language models (LLMs), but the same
is challenging for Japanese LLMs to achieve due to the amount of resources
required. Inspired by task vectors that extract the change of weights before
and after training, specifically for a certain task, we obtain reasoning
vectors from reasoning LLMs and apply them to Japanese LLMs to boost their
performance. While the resources available present a challenge to improve
Japanese LLMs, we present a simple and effective way to obtain high improvement
and hope to inspire for other languages.

</details>


### [9] [PentestJudge: Judging Agent Behavior Against Operational Requirements](https://arxiv.org/abs/2508.02921)
*Shane Caldwell,Max Harley,Michael Kouremetis,Vincent Abruzzo,Will Pearce*

Main category: cs.AI

TL;DR: PentestJudge是一个基于大型语言模型（LLM）的系统，用于评估渗透测试代理的操作。它通过分层任务结构和简单标准，模拟人类专家评分，验证AI代理的性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以程序化评估渗透测试代理的操作质量，因此需要一种可扩展且可靠的评估系统。

Method: 开发分层任务结构（树状），将复杂任务分解为简单子任务，利用LLM作为评分者，并与人类专家评分对比。

Result: 最佳模型的F1分数为0.83，工具使用能力强的模型更接近人类专家评分。不同模型在不同类型问题上表现差异显著。

Conclusion: PentestJudge为AI安全代理的评估提供了一种可扩展方法，验证任务可能比生成任务更容易。

Abstract: We introduce PentestJudge, a system for evaluating the operations of
penetration testing agents. PentestJudge is a large language model
(LLM)-as-judge with access to tools that allow it to consume arbitrary
trajectories of agent states and tool call history to determine whether a
security agent's actions meet certain operating criteria that would be
impractical to evaluate programmatically. We develop rubrics that use a tree
structure to hierarchically collapse the penetration testing task for a
particular environment into smaller, simpler, and more manageable sub-tasks and
criteria until each leaf node represents simple yes-or-no criteria for
PentestJudge to evaluate. Task nodes are broken down into different categories
related to operational objectives, operational security, and tradecraft.
LLM-as-judge scores are compared to human domain experts as a ground-truth
reference, allowing us to compare their relative performance with standard
binary classification metrics, such as F1 scores. We evaluate several frontier
and open-source models acting as judge agents, with the best model reaching an
F1 score of 0.83. We find models that are better at tool-use perform more
closely to human experts. By stratifying the F1 scores by requirement type, we
find even models with similar overall scores struggle with different types of
questions, suggesting certain models may be better judges of particular
operating criteria. We find that weaker and cheaper models can judge the
trajectories of pentests performed by stronger and more expensive models,
suggesting verification may be easier than generation for the penetration
testing task. We share this methodology to facilitate future research in
understanding the ability of judges to holistically and scalably evaluate the
process quality of AI-based information security agents so that they may be
confidently used in sensitive production environments.

</details>


### [10] [AQUAH: Automatic Quantification and Unified Agent in Hydrology](https://arxiv.org/abs/2508.02936)
*Songkun Yan,Zhi Li,Siyu Zhu,Yixin Wen,Mofan Zhang,Mengye Chen,Jie Cao,Yang Hong*

Main category: cs.AI

TL;DR: AQUAH是首个专为水文建模设计的端到端语言驱动代理，通过自然语言指令自动完成数据检索、模型配置、模拟运行及报告生成。


<details>
  <summary>Details</summary>
Motivation: 旨在简化复杂的环境建模流程，降低地球观测数据、物理工具与决策者之间的使用门槛。

Method: 基于视觉增强的大型语言模型，自动解析地图和栅格数据，驱动关键决策如出口选择、参数初始化和不确定性分析。

Result: 初步实验表明，AQUAH能完成冷启动模拟并生成分析师就绪的文档，结果被水文专家评价为清晰、透明且物理合理。

Conclusion: 尽管仍需进一步校准和验证，但AQUAH展示了以LLM为核心的智能代理在环境建模中的潜力。

Abstract: We introduce AQUAH, the first end-to-end language-based agent designed
specifically for hydrologic modeling. Starting from a simple natural-language
prompt (e.g., 'simulate floods for the Little Bighorn basin from 2020 to
2022'), AQUAH autonomously retrieves the required terrain, forcing, and gauge
data; configures a hydrologic model; runs the simulation; and generates a
self-contained PDF report. The workflow is driven by vision-enabled large
language models, which interpret maps and rasters on the fly and steer key
decisions such as outlet selection, parameter initialization, and uncertainty
commentary. Initial experiments across a range of U.S. basins show that AQUAH
can complete cold-start simulations and produce analyst-ready documentation
without manual intervention. The results are judged by hydrologists as clear,
transparent, and physically plausible. While further calibration and validation
are still needed for operational deployment, these early outcomes highlight the
promise of LLM-centered, vision-grounded agents to streamline complex
environmental modeling and lower the barrier between Earth observation data,
physics-based tools, and decision makers.

</details>


### [11] [MedBLINK: Probing Basic Perception in Multimodal Language Models for Medicine](https://arxiv.org/abs/2508.02951)
*Mahtab Bigverdi,Wisdom Ikezogwo,Kevin Zhang,Hyewon Jeong,Mingyu Lu,Sungjae Cho,Linda Shapiro,Ranjay Krishna*

Main category: cs.AI

TL;DR: Medblink是一个用于评估多模态语言模型（MLMs）在医学图像感知任务中表现的基准测试，结果显示当前模型在简单感知任务上表现远低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 临床医生对AI工具的采用高度选择性，模型在简单感知任务上的错误会阻碍其临床应用，因此需要评估和改进MLMs的视觉基础能力。

Method: 引入Medblink基准测试，涵盖8个临床相关任务，共1,429道多选题和1,605张图像，评估了19种先进的MLMs。

Result: 人类标注者准确率为96.4%，而最佳模型仅达到65%，表明当前MLMs在常规感知任务上表现不佳。

Conclusion: 当前MLMs的视觉基础能力需加强以支持临床应用，Medblink为改进提供了数据支持。

Abstract: Multimodal language models (MLMs) show promise for clinical decision support
and diagnostic reasoning, raising the prospect of end-to-end automated medical
image interpretation. However, clinicians are highly selective in adopting AI
tools; a model that makes errors on seemingly simple perception tasks such as
determining image orientation or identifying whether a CT scan is
contrast-enhance are unlikely to be adopted for clinical tasks. We introduce
Medblink, a benchmark designed to probe these models for such perceptual
abilities. Medblink spans eight clinically meaningful tasks across multiple
imaging modalities and anatomical regions, totaling 1,429 multiple-choice
questions over 1,605 images. We evaluate 19 state-of-the-art MLMs, including
general purpose (GPT4o, Claude 3.5 Sonnet) and domain specific (Med Flamingo,
LLaVA Med, RadFM) models. While human annotators achieve 96.4% accuracy, the
best-performing model reaches only 65%. These results show that current MLMs
frequently fail at routine perceptual checks, suggesting the need to strengthen
their visual grounding to support clinical adoption. Data is available on our
project page.

</details>


### [12] [Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow](https://arxiv.org/abs/2508.02959)
*Chia-Tung Ho,Jing Gong,Xufeng Yao,Yunsheng Bai,Abhishek B Akkur,Haoxing Ren*

Main category: cs.AI

TL;DR: Polymath是一种自优化代理，通过动态分层工作流解决动态问题，无需标记数据，性能优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有基于标记数据的方法在解决动态问题时效率低且不灵活，需要一种无需标记数据的自动化工作流优化方法。

Method: Polymath结合任务流图的灵活性和代码表示的工作流，采用多网格图优化和自反射进化算法优化工作流。

Result: 在六个基准数据集上，Polymath平均性能提升8.1%。

Conclusion: Polymath为动态问题提供了一种高效且灵活的无监督工作流优化方案。

Abstract: Large language models (LLMs) excel at solving complex tasks by executing
agentic workflows composed of detailed instructions and structured operations.
Yet, building general-purpose agents by manually embedding foundation models
into agentic systems such as Chain-of-Thought, Self-Reflection, and ReACT
through text interfaces limits scalability and efficiency. Recently, many
researchers have sought to automate the generation and optimization of these
workflows through code-based representations. However, existing methods often
rely on labeled datasets to train and optimize workflows, making them
ineffective and inflexible for solving real-world, dynamic problems where
labeled data is unavailable. To address this challenge, we introduce Polymath,
a self-optimizing agent with dynamic hierarchical workflow that leverages the
flexibility of task flow graphs and the expressiveness of code-represented
workflows to solve a wide range of real-world, dynamic problems. The proposed
optimization methodology integrates multi-grid-inspired graph optimization with
a self-reflection-guided evolutionary algorithm to refine workflows without
labeled data. Experimental results on six benchmark datasets across coding,
math, and multi-turn QA tasks show that Polymath achieves 8.1% average
improvement over state-of-the-art baselines.

</details>


### [13] [Defend LLMs Through Self-Consciousness](https://arxiv.org/abs/2508.02961)
*Boshi Huang,Fabio Nonato de Paula*

Main category: cs.AI

TL;DR: 本文提出了一种新型的自意识防御机制，利用LLM的内在推理能力抵御提示注入攻击，通过元认知和仲裁模块实现自主输出评估与调节。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖外部分类器，而本文旨在利用LLM自身能力实现更轻量、高效的防御。

Method: 提出包含元认知和仲裁模块的框架，使LLM能自主评估和调节输出。

Result: 在AdvBench和Prompt-Injection-Mixed-Techniques-2024数据集上测试，防御成功率显著提升，部分模型在增强模式下实现完美防御。

Conclusion: 该方法为提升LLM伦理提供了一种轻量、低成本的解决方案，适用于多平台GenAI应用。

Abstract: This paper introduces a novel self-consciousness defense mechanism for Large
Language Models (LLMs) to combat prompt injection attacks. Unlike traditional
approaches that rely on external classifiers, our method leverages the LLM's
inherent reasoning capabilities to perform self-protection. We propose a
framework that incorporates Meta-Cognitive and Arbitration Modules, enabling
LLMs to evaluate and regulate their own outputs autonomously. Our approach is
evaluated on seven state-of-the-art LLMs using two datasets: AdvBench and
Prompt-Injection-Mixed-Techniques-2024. Experiment results demonstrate
significant improvements in defense success rates across models and datasets,
with some achieving perfect and near-perfect defense in Enhanced Mode. We also
analyze the trade-off between defense success rate improvement and
computational overhead. This self-consciousness method offers a lightweight,
cost-effective solution for enhancing LLM ethics, particularly beneficial for
GenAI use cases across various platforms.

</details>


### [14] [Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling](https://arxiv.org/abs/2508.02979)
*Peng Ding,Rick Stevens*

Main category: cs.AI

TL;DR: 提出了一种统一工具集成方法，通过协议无关设计减少开发负担，实验显示代码减少60-80%，性能提升3.1倍。


<details>
  <summary>Details</summary>
Motivation: 解决工具增强型大语言模型生态碎片化问题，简化多协议、复杂执行流程的开发挑战。

Method: 采用协议无关设计原则，实现自动模式生成、双模式并发执行和多源工具管理。

Result: 代码减少60-80%，性能提升3.1倍，完全兼容现有函数调用标准。

Conclusion: 为工具集成架构提供理论见解，并为实际LLM应用开发提供实用解决方案。

Abstract: The proliferation of tool-augmented Large Language Models (LLMs) has created
a fragmented ecosystem where developers must navigate multiple protocols,
manual schema definitions, and complex execution workflows. We address this
challenge by proposing a unified approach to tool integration that abstracts
protocol differences while optimizing execution performance. Our solution
demonstrates how protocol-agnostic design principles can significantly reduce
development overhead through automated schema generation, dual-mode concurrent
execution, and seamless multi-source tool management. Experimental results show
60-80% code reduction across integration scenarios, performance improvements up
to 3.1x through optimized concurrency, and full compatibility with existing
function calling standards. This work contributes both theoretical insights
into tool integration architecture and practical solutions for real-world LLM
application development.

</details>


### [15] [When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs](https://arxiv.org/abs/2508.02994)
*Fangyi Yu*

Main category: cs.AI

TL;DR: 论文探讨了利用AI代理作为评估者（agent-as-a-judge）的新范式，以解决大语言模型（LLMs）输出评估的瓶颈问题，并分析了其优缺点及实际应用。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs能力和自主性的提升，评估其开放性和复杂任务输出成为关键瓶颈，需要一种可扩展且细致的替代方案。

Method: 定义了agent-as-a-judge概念，追溯了从单模型评估到动态多代理辩论框架的演变，并比较了可靠性、成本和人类对齐等方面。

Result: 展示了该方法在医学、法律、金融和教育等领域的实际应用，并指出其潜力与挑战。

Conclusion: 基于代理的评估可以补充（而非替代）人类监督，是迈向下一代LLMs可信、可扩展评估的一步。

Abstract: As large language models (LLMs) grow in capability and autonomy, evaluating
their outputs-especially in open-ended and complex tasks-has become a critical
bottleneck. A new paradigm is emerging: using AI agents as the evaluators
themselves. This "agent-as-a-judge" approach leverages the reasoning and
perspective-taking abilities of LLMs to assess the quality and safety of other
models, promising calable and nuanced alternatives to human evaluation. In this
review, we define the agent-as-a-judge concept, trace its evolution from
single-model judges to dynamic multi-agent debate frameworks, and critically
examine their strengths and shortcomings. We compare these approaches across
reliability, cost, and human alignment, and survey real-world deployments in
domains such as medicine, law, finance, and education. Finally, we highlight
pressing challenges-including bias, robustness, and meta evaluation-and outline
future research directions. By bringing together these strands, our review
demonstrates how agent-based judging can complement (but not replace) human
oversight, marking a step toward trustworthy, scalable evaluation for
next-generation LLMs.

</details>


### [16] [AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots](https://arxiv.org/abs/2508.02999)
*Xinjie Zhao,Moritz Blum,Fan Gao,Yingjian Chen,Boming Yang,Luis Marquez-Carpintero,Mónica Pina-Navarro,Yanran Fu,So Morikawa,Yusuke Iwasawa,Yutaka Matsuo,Chanjun Park,Irene Li*

Main category: cs.AI

TL;DR: AGENTiGraph是一个用户友好的代理驱动系统，通过自然语言操作知识图谱实现直观交互和领域数据管理，为非技术用户提供可视化解决方案。


<details>
  <summary>Details</summary>
Motivation: 为非技术用户提供无需专业查询语言即可构建和优化知识库的工具，支持多轮对话和动态更新。

Method: 采用意图分类、任务规划和自动知识集成等灵活设计，实现多样化任务间的无缝推理。

Result: 在教育场景的3,500查询基准测试中表现优异（分类准确率95.12%，执行成功率90.45%），展示了在法律和医疗等领域的扩展潜力。

Conclusion: AGENTiGraph为多轮企业知识管理提供了新范式，结合了LLM和结构化图谱的优势。

Abstract: AGENTiGraph is a user-friendly, agent-driven system that enables intuitive
interaction and management of domain-specific data through the manipulation of
knowledge graphs in natural language. It gives non-technical users a complete,
visual solution to incrementally build and refine their knowledge bases,
allowing multi-round dialogues and dynamic updates without specialized query
languages. The flexible design of AGENTiGraph, including intent classification,
task planning, and automatic knowledge integration, ensures seamless reasoning
between diverse tasks. Evaluated on a 3,500-query benchmark within an
educational scenario, the system outperforms strong zero-shot baselines
(achieving 95.12% classification accuracy, 90.45% execution success),
indicating potential scalability to compliance-critical or multi-step queries
in legal and medical domains, e.g., incorporating new statutes or research on
the fly. Our open-source demo offers a powerful new paradigm for multi-turn
enterprise knowledge management that bridges LLMs and structured graphs.

</details>


### [17] [Beyond Policy Optimization: A Data Curation Flywheel for Sparse-Reward Long-Horizon Planning](https://arxiv.org/abs/2508.03018)
*Yutong Wang,Pengliang Ji,Kaixin Li,Baolong Bi,Tao Feng,Guillaume Sartoretti*

Main category: cs.AI

TL;DR: BPO框架通过三阶段（引导、外推和优化）解决大语言模型在多轮代理规划中的信用分配和计算效率问题，显著提升稀疏奖励环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在交互式环境中多轮规划时的信用分配和计算效率问题。

Method: 提出BPO框架，包括引导（规划四元组与长短链思维融合）、外推（复杂度分层课程学习）和优化（奖励门控拒绝采样）。

Result: 在ALFWorld、ScienceWorld和WebShop上实现最优性能，且显著提升token效率。

Conclusion: BPO为代理规划中的推理模型提供了新方法，适用于长时程稀疏奖励环境。

Abstract: Large Language Reasoning Models have demonstrated remarkable success on
static tasks, yet their application to multi-round agentic planning in
interactive environments faces two fundamental challenges. First, the
intractable credit assignment problem renders conventional reinforcement
learning ineffective in sparse-reward settings. Second, the computational
overhead of verbose, step-by-step reasoning histories is prohibitive. To
address these challenges, we propose BPO, a three-stage framework
(bootstrapping, extrapolation, and refinement) that establishes a
self-improving data flywheel to develop robust reasoning models for
long-horizon, sparse-reward environments. Our framework first bootstraps
efficient reasoning using the proposed planning quaternions with long-short
chain-of-thought fusion. It then extrapolates to out-of-distribution tasks
through complexity-stratified curriculum learning. Finally, the model
iteratively refines itself by learning exclusively on experiences selected via
reward-gated rejection sampling. Experiments on ALFWorld, ScienceWorld, and
WebShop demonstrate that our approach achieves state-of-the-art with
significant token efficiency, providing a new recipe for reasoning models in
agentic planning.

</details>


### [18] [Collab-Solver: Collaborative Solving Policy Learning for Mixed-Integer Linear Programming](https://arxiv.org/abs/2508.03030)
*Siyuan Li,Yifan Yu,Yanchen Deng,Zhihao Zhang,Mengjing Chen,Fangzhou Zhu,Tao Zhong,Jianye Hao,Peng Liu,Bo An*

Main category: cs.AI

TL;DR: 论文提出了一种多智能体协作学习框架（Collab-Solver），用于优化混合整数线性规划（MILP）求解器中多个模块的策略，显著提升了求解速度和性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的MILP方法独立处理各模块的策略学习，忽视了模块间的相互依赖，影响了求解效率和质量。

Method: 通过Stackelberg博弈建模模块协作，采用两阶段学习范式：第一阶段预训练数据通信策略，第二阶段协调多模块策略学习。

Result: 在合成和真实MILP数据集上，联合学习的策略显著提升求解性能，并展现出优秀的泛化能力。

Conclusion: Collab-Solver通过协作学习优化多模块策略，有效解决了MILP求解中的模块独立性问题。

Abstract: Mixed-integer linear programming (MILP) has been a fundamental problem in
combinatorial optimization. Previous works have designed a plethora of
hard-coded heuristics to accomplish challenging MILP solving with domain
knowledge. Driven by the high capability of neural networks, recent research is
devoted to replacing manually designed heuristics with learned policies.
Although learning-based MILP methods have shown great promise, existing
worksindependentlytreatthepolicylearningineachmoduleofMILPsolvers without
considering their interdependence, severely hurting the solving speed and
quality. To address this issue, we propose a novel multi-agent-based policy
learning framework for MILP (Collab-Solver), which can collaboratively optimize
the policies for multiple modules. Specifically, we formulate the collaboration
of cut selection and branching in MILP solving as a Stackelberg game. Under
this formulation, we develop a two-phase learning paradigm to stabilize the
collaborative policy learning, where the first phase achieves the
data-communicated policy pretraining and the second phase further orchestrates
the policy learning for various modules. The jointly learned policy
significantly improves the solving performance on both synthetic and
large-scale real-world MILP datasets. Moreover, the policies learned by
Collab-Solver have also demonstrated excellent generalization abilities across
different instance sets.

</details>


### [19] [From Text to Trajectories: GPT-2 as an ODE Solver via In-Context](https://arxiv.org/abs/2508.03031)
*Ziyang Ma,Baojian Zhou,Deqing Yang,Yanghua Xiao*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型（LLM）在上下文学习（ICL）中解决常微分方程（ODE）的能力，发现GPT-2能有效学习元ODE算法，性能优于欧拉方法，并展示出泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索ICL在非线性数值问题中的机制，揭示LLM在ICL下的行为。

Method: 将ODE问题及其解作为序列提示，评估GPT-2在两类ODE任务上的表现。

Result: GPT-2能学习元ODE算法，性能优于欧拉方法，且随示例增加精度呈指数提升，能泛化到分布外问题。

Conclusion: 研究为ICL机制提供了新见解，展示了其在解决非线性数值问题中的潜力。

Abstract: In-Context Learning (ICL) has emerged as a new paradigm in large language
models (LLMs), enabling them to perform novel tasks by conditioning on a few
examples embedded in the prompt. Yet, the highly nonlinear behavior of ICL for
NLP tasks remains poorly understood. To shed light on its underlying
mechanisms, this paper investigates whether LLMs can solve ordinary
differential equations (ODEs) under the ICL setting. We formulate standard ODE
problems and their solutions as sequential prompts and evaluate GPT-2 models on
these tasks. Experiments on two types of ODEs show that GPT-2 can effectively
learn a meta-ODE algorithm, with convergence behavior comparable to, or better
than, the Euler method, and achieve exponential accuracy gains with increasing
numbers of demonstrations. Moreover, the model generalizes to
out-of-distribution (OOD) problems, demonstrating robust extrapolation
capabilities. These empirical findings provide new insights into the mechanisms
of ICL in NLP and its potential for solving nonlinear numerical problems.

</details>


### [20] [Tree-of-Reasoning: Towards Complex Medical Diagnosis via Multi-Agent Reasoning with Evidence Tree](https://arxiv.org/abs/2508.03038)
*Qi Peng,Jialin Cui,Jiayuan Xie,Yi Cai,Qing Li*

Main category: cs.AI

TL;DR: 提出Tree-of-Reasoning (ToR)框架，通过树状结构和跨验证机制提升大语言模型在复杂医疗诊断任务中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在复杂医疗诊断任务中因推理深度不足导致信息丢失或逻辑跳跃，影响诊断准确性。

Method: 引入树状结构记录推理路径和临床证据，并提出跨验证机制确保多智能体决策一致性。

Result: 在真实医疗数据上的实验表明，ToR框架优于现有基线方法。

Conclusion: ToR框架通过结构化推理和验证机制，显著提升了复杂医疗场景下的临床推理能力。

Abstract: Large language models (LLMs) have shown great potential in the medical
domain. However, existing models still fall short when faced with complex
medical diagnosis task in the real world. This is mainly because they lack
sufficient reasoning depth, which leads to information loss or logical jumps
when processing a large amount of specialized medical data, leading to
diagnostic errors. To address these challenges, we propose Tree-of-Reasoning
(ToR), a novel multi-agent framework designed to handle complex scenarios.
Specifically, ToR introduces a tree structure that can clearly record the
reasoning path of LLMs and the corresponding clinical evidence. At the same
time, we propose a cross-validation mechanism to ensure the consistency of
multi-agent decision-making, thereby improving the clinical reasoning ability
of multi-agents in complex medical scenarios. Experimental results on
real-world medical data show that our framework can achieve better performance
than existing baseline methods.

</details>


### [21] [Beyond Surface-Level Detection: Towards Cognitive-Driven Defense Against Jailbreak Attacks via Meta-Operations Reasoning](https://arxiv.org/abs/2508.03054)
*Rui Pu,Chaozhuo Li,Rui Ha,Litian Zhang,Lirong Qiu,Xi Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种名为认知驱动防御（CDD）的框架，通过模拟人类认知推理来防御LLM的越狱攻击，结合监督微调和强化学习提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法依赖浅层模式匹配，难以应对新型攻击策略，因此需要更通用的防御框架。

Method: CDD框架通过全局感知和局部分析揭示隐藏意图，结合监督微调和熵引导的强化学习（EG-GRPO）探索新攻击变体。

Result: 实验表明CDD在防御性能和泛化能力上达到最优水平。

Conclusion: CDD为LLM防御提供了高效且通用的解决方案。

Abstract: Defending large language models (LLMs) against jailbreak attacks is essential
for their safe and reliable deployment. Existing defenses often rely on shallow
pattern matching, which struggles to generalize to novel and unseen attack
strategies. To address this challenge, we propose the Cognitive-Driven Defense
(CDD) framework, which targets the underlying structure of jailbreak prompts by
applying meta-operations, defined as basic manipulations that conceal harmful
intent.CDD emulates human cognitive reasoning through a structured reasoning
chain. It begins with a global perception of the prompt and follows with a
localized analysis to uncover hidden manipulations. By applying supervised
fine-tuning on this structured chain, the model learns to identify and reason
about known manipulation patterns. To enhance generalization to unseen threats,
an entropy-guided reinforcement learning algorithm (EG-GRPO) is introduced to
encourage exploration of new types and variants of meta-operations. Experiments
demonstrate that CDD can achieve state-of-the-art defense performance and
exhibit strong generalization to unseen jailbreak attacks.

</details>


### [22] [ContractEval: Benchmarking LLMs for Clause-Level Legal Risk Identification in Commercial Contracts](https://arxiv.org/abs/2508.03080)
*Shuang Liu,Zelong Li,Ruoyun Ma,Haiyan Zhao,Mengnan Du*

Main category: cs.AI

TL;DR: 本文介绍了ContractEval，首个评估开源与专有LLMs在商业合同法律风险分析中表现的基准，发现专有模型整体更优，但开源模型在特定领域有竞争力。


<details>
  <summary>Details</summary>
Motivation: 探索开源LLMs在法律风险分析中的潜力，满足本地部署需求以保护数据隐私。

Method: 使用CUAD数据集评估4个专有和15个开源LLMs，分析其在条款级法律风险识别中的表现。

Result: 专有模型表现更优；开源模型在规模增大时性能提升有限；推理模式影响输出效果；开源模型更易漏检相关条款；量化加速但降低性能。

Conclusion: 开源LLMs需针对性优化以匹配专有模型，ContractEval为法律领域LLMs发展提供基准。

Abstract: The potential of large language models (LLMs) in specialized domains such as
legal risk analysis remains underexplored. In response to growing interest in
locally deploying open-source LLMs for legal tasks while preserving data
confidentiality, this paper introduces ContractEval, the first benchmark to
thoroughly evaluate whether open-source LLMs could match proprietary LLMs in
identifying clause-level legal risks in commercial contracts. Using the
Contract Understanding Atticus Dataset (CUAD), we assess 4 proprietary and 15
open-source LLMs. Our results highlight five key findings: (1) Proprietary
models outperform open-source models in both correctness and output
effectiveness, though some open-source models are competitive in certain
specific dimensions. (2) Larger open-source models generally perform better,
though the improvement slows down as models get bigger. (3) Reasoning
("thinking") mode improves output effectiveness but reduces correctness, likely
due to over-complicating simpler tasks. (4) Open-source models generate "no
related clause" responses more frequently even when relevant clauses are
present. This suggests "laziness" in thinking or low confidence in extracting
relevant content. (5) Model quantization speeds up inference but at the cost of
performance drop, showing the tradeoff between efficiency and accuracy. These
findings suggest that while most LLMs perform at a level comparable to junior
legal assistants, open-source models require targeted fine-tuning to ensure
correctness and effectiveness in high-stakes legal settings. ContractEval
offers a solid benchmark to guide future development of legal-domain LLMs.

</details>


### [23] [EoH-S: Evolution of Heuristic Set using LLMs for Automated Heuristic Design](https://arxiv.org/abs/2508.03082)
*Fei Liu,Yilu Liu,Qingfu Zhang,Xialiang Tong,Mingxuan Yuan*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型（LLM）的自动化启发式集合设计（AHSD）方法，通过生成互补的启发式集合来解决现有方法泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动化启发式设计（AHD）方法仅生成单一启发式，导致在不同问题实例或分布下泛化能力差。

Method: 提出AHSD框架，目标为生成小型互补启发式集合，并设计EoH-S算法，结合互补种群管理和互补感知的模因搜索。

Result: 在三个AHD任务上的实验表明，EoH-S显著优于现有方法，性能提升高达60%。

Conclusion: AHSD和EoH-S有效提升了启发式设计的泛化能力和性能。

Abstract: Automated Heuristic Design (AHD) using Large Language Models (LLMs) has
achieved notable success in recent years. Despite the effectiveness of existing
approaches, they only design a single heuristic to serve all problem instances,
often inducing poor generalization across different distributions or settings.
To address this issue, we propose Automated Heuristic Set Design (AHSD), a new
formulation for LLM-driven AHD. The aim of AHSD is to automatically generate a
small-sized complementary heuristic set to serve diverse problem instances,
such that each problem instance could be optimized by at least one heuristic in
this set. We show that the objective function of AHSD is monotone and
supermodular. Then, we propose Evolution of Heuristic Set (EoH-S) to apply the
AHSD formulation for LLM-driven AHD. With two novel mechanisms of complementary
population management and complementary-aware memetic search, EoH-S could
effectively generate a set of high-quality and complementary heuristics.
Comprehensive experimental results on three AHD tasks with diverse instances
spanning various sizes and distributions demonstrate that EoH-S consistently
outperforms existing state-of-the-art AHD methods and achieves up to 60\%
performance improvements.

</details>


### [24] [MissDDIM: Deterministic and Efficient Conditional Diffusion for Tabular Data Imputation](https://arxiv.org/abs/2508.03083)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.AI

TL;DR: MissDDIM提出了一种基于DDIM的表格数据填补框架，解决了传统DDPM方法的高延迟和输出不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于DDPM的缺失数据填补方法存在高推理延迟和输出不稳定的问题，限制了其在实际表格数据中的应用。

Method: MissDDIM采用条件扩散框架，基于DDIM进行表格数据填补，避免了随机采样带来的输出不稳定性。

Result: MissDDIM在表格数据填补中表现出更低的推理延迟和更稳定的输出。

Conclusion: MissDDIM通过改进DDIM框架，为表格数据填补提供了更高效和稳定的解决方案。

Abstract: Diffusion models have recently emerged as powerful tools for missing data
imputation by modeling the joint distribution of observed and unobserved
variables. However, existing methods, typically based on stochastic denoising
diffusion probabilistic models (DDPMs), suffer from high inference latency and
variable outputs, limiting their applicability in real-world tabular settings.
To address these deficiencies, we present in this paper MissDDIM, a conditional
diffusion framework that adapts Denoising Diffusion Implicit Models (DDIM) for
tabular imputation. While stochastic sampling enables diverse completions, it
also introduces output variability that complicates downstream processing.

</details>


### [25] [T2UE: Generating Unlearnable Examples from Text Descriptions](https://arxiv.org/abs/2508.03091)
*Xingjun Ma,Hanxun Huang,Tianwei Song,Ye Sun,Yifeng Gao,Yu-Gang Jiang*

Main category: cs.AI

TL;DR: T2UE框架通过文本描述生成不可学习示例（UE），避免直接暴露原始图像数据，解决隐私矛盾，并在实验中显著降低下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成UE的方法需依赖第三方服务，导致隐私泄露风险。T2UE旨在通过文本描述生成UE，实现零接触数据保护。

Method: 结合文本到图像（T2I）模型和误差最小化框架，将文本描述映射为图像噪声，生成有效的UE。

Result: T2UE保护的数据显著降低了跨模态检索等任务的性能，且保护效果泛化至多种架构和监督学习场景。

Conclusion: T2UE证明了仅通过文本描述实现数据保护的可行性，为隐私保护提供了新思路。

Abstract: Large-scale pre-training frameworks like CLIP have revolutionized multimodal
learning, but their reliance on web-scraped datasets, frequently containing
private user data, raises serious concerns about misuse. Unlearnable Examples
(UEs) have emerged as a promising countermeasure against unauthorized model
training, employing carefully crafted unlearnable noise to disrupt the learning
of meaningful representations from protected data. Current approaches typically
generate UEs by jointly optimizing unlearnable noise for both images and their
associated text descriptions (or labels). However, this optimization process is
often computationally prohibitive for on-device execution, forcing reliance on
external third-party services. This creates a fundamental privacy paradox:
users must initially expose their data to these very services to achieve
protection, thereby compromising privacy in the process. Such a contradiction
has severely hindered the development of practical, scalable data protection
solutions. To resolve this paradox, we introduce \textbf{Text-to-Unlearnable
Example (T2UE)}, a novel framework that enables users to generate UEs using
only text descriptions. T2UE circumvents the need for original image data by
employing a text-to-image (T2I) model to map text descriptions into the image
(noise) space, combined with an error-minimization framework to produce
effective unlearnable noise. Extensive experiments show that T2UE-protected
data substantially degrades performance in downstream tasks (e.g., cross-modal
retrieval) for state-of-the-art models. Notably, the protective effect
generalizes across diverse architectures and even to supervised learning
settings. Our work demonstrates the feasibility of "zero-contact data
protection", where personal data can be safeguarded based solely on their
textual descriptions, eliminating the need for direct data exposure.

</details>


### [26] [Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework](https://arxiv.org/abs/2508.03092)
*Zikun Cui,Tianyi Huang,Chia-En Chiang,Cuiqianhe Du*

Main category: cs.AI

TL;DR: 本文提出了一种可验证的虚假信息检测LLM代理，通过动态交互和多工具协作，超越传统二元判断，显著提升了检测准确性和推理透明度。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的普及，虚假信息检测变得愈发重要且复杂，传统方法难以满足需求。

Method: 设计了包含精确网络搜索、来源可信度评估和数值声明验证工具的代理架构，支持多步骤验证和证据记录。

Result: 在标准数据集（如FakeNewsNet）上评估，代理在准确性、推理透明度和抗改写能力上优于基线方法。

Conclusion: 该代理为可信赖的AI辅助事实核查提供了新范式。

Abstract: With the proliferation of Large Language Models (LLMs), the detection of
misinformation has become increasingly important and complex. This research
proposes an innovative verifiable misinformation detection LLM agent that goes
beyond traditional true/false binary judgments. The agent actively verifies
claims through dynamic interaction with diverse web sources, assesses
information source credibility, synthesizes evidence, and provides a complete
verifiable reasoning process. Our designed agent architecture includes three
core tools: precise web search tool, source credibility assessment tool and
numerical claim verification tool. These tools enable the agent to execute
multi-step verification strategies, maintain evidence logs, and form
comprehensive assessment conclusions. We evaluate using standard misinformation
datasets such as FakeNewsNet, comparing with traditional machine learning
models and LLMs. Evaluation metrics include standard classification metrics,
quality assessment of reasoning processes, and robustness testing against
rewritten content. Experimental results show that our agent outperforms
baseline methods in misinformation detection accuracy, reasoning transparency,
and resistance to information rewriting, providing a new paradigm for
trustworthy AI-assisted fact-checking.

</details>


### [27] [AgentSME for Simulating Diverse Communication Modes in Smart Education](https://arxiv.org/abs/2508.03109)
*Wen-Xi Yang,Tian-Fang Zhao*

Main category: cs.AI

TL;DR: 本文提出AgentSME框架，基于LLM为智能教育定制生成代理模型，通过三种通信模式（Solo、Mono、Echo）评估代理性能，发现Echo模式准确率最高，DeepSeek多样性最佳。


<details>
  <summary>Details</summary>
Motivation: 智能教育中生成代理模型发展不足，教育场景复杂且需个性化沟通，需解决此问题。

Method: 提出AgentSME框架，采用三种通信模式（Solo、Mono、Echo），以准确率和多样性指数评估六种LLM。

Result: Echo模式准确率最高，DeepSeek多样性最佳。

Conclusion: 研究为提升代理学习能力和智能教育模型提供有价值信息。

Abstract: Generative agent models specifically tailored for smart education are
critical, yet remain relatively underdeveloped. A key challenge stems from the
inherent complexity of educational contexts: learners are human beings with
various cognitive behaviors, and pedagogy is fundamentally centered on
personalized human-to-human communication. To address this issue, this paper
proposes AgentSME, a unified generative agent framework powered by LLM. Three
directional communication modes are considered in the models, namely Solo,
Mono, and Echo, reflecting different types of agency autonomy and communicative
reciprocity. Accuracy is adopted as the primary evaluation metric, complemented
by three diversity indices designed to assess the diversity of reasoning
contents. Six widely used LLMs are tested to validate the robustness of
communication modes across different model tiers, which are equally divided
into base-capacity and high-capacity configurations. The results show that
generative agents that employ the Echo communication mode achieve the highest
accuracy scores, while DeepSeek exhibits the greatest diversity. This study
provides valuable information to improve agent learning capabilities and
inspire smart education models.

</details>


### [28] [Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation](https://arxiv.org/abs/2508.03117)
*Vinicius Lima,Dzung T. Phan,Jayant Kalagnanam,Dhaval Patel,Nianjun Zhou*

Main category: cs.AI

TL;DR: 提出了一种通过可验证合成数据生成管道训练可信赖大型语言模型（LLM）代理的框架，专注于线性和混合整数线性规划问题。


<details>
  <summary>Details</summary>
Motivation: 构建可靠且可验证的LLM代理，以解决现实世界中的优化问题。

Method: 通过结构化符号表示生成自然语言描述、数学公式和可执行代码，并利用教师模型生成逐步演示。

Result: OptiTrust代理在标准基准测试中表现最佳，在7个数据集中有6个达到最高准确率。

Conclusion: 该方法为构建可靠LLM代理提供了可扩展、可验证且系统化的路径。

Abstract: We present a framework for training trustworthy large language model (LLM)
agents for optimization modeling via a verifiable synthetic data generation
pipeline. Focusing on linear and mixed-integer linear programming, our approach
begins with structured symbolic representations and systematically produces
natural language descriptions, mathematical formulations, and solver-executable
code. By programmatically constructing each instance with known optimal
solutions, the pipeline ensures full verifiability and enables automatic
filtering of low-quality demonstrations generated by teacher models. Each
dataset instance includes a structured representation of the optimization
problem, a corresponding natural language description, the verified optimal
solution, and step-by-step demonstrations - generated by a teacher model - that
show how to model and solve the problem across multiple optimization modeling
languages. This enables supervised fine-tuning of open-source LLMs specifically
tailored to optimization tasks. To operationalize this pipeline, we introduce
OptiTrust, a modular LLM agent that performs multi-stage translation from
natural language to solver-ready code, leveraging stepwise demonstrations,
multi-language inference, and majority-vote cross-validation. Our agent
achieves state-of-the-art performance on standard benchmarks. Out of 7
datasets, it achieves the highest accuracy on six and outperforms the next-best
algorithm by at least 8 percentage on three of them. Our approach provides a
scalable, verifiable, and principled path toward building reliable LLM agents
for real-world optimization applications.

</details>


### [29] [Can Large Language Models Bridge the Gap in Environmental Knowledge?](https://arxiv.org/abs/2508.03149)
*Linda Smail,David Santandreu Calonge,Firuz Kamalov,Nur H. Orak*

Main category: cs.AI

TL;DR: 研究探讨AI模型（如GPT-3.5、GPT-4等）在填补大学生环境教育知识缺口中的潜力，发现其虽能提供丰富知识，但仍需人类专家验证准确性。


<details>
  <summary>Details</summary>
Motivation: 评估AI模型在环境教育中的有效性，以解决大学生环境知识不足的问题。

Method: 使用标准化工具EKT-19及针对性问题，对比AI模型与大学生在环境知识上的表现。

Result: AI模型能提供广泛且有效的知识支持，但需环境科学专家验证信息准确性。

Conclusion: AI可作为环境教育的辅助工具，但人类专家的参与仍不可或缺。

Abstract: This research investigates the potential of Artificial Intelligence (AI)
models to bridge the knowledge gap in environmental education among university
students. By focusing on prominent large language models (LLMs) such as
GPT-3.5, GPT-4, GPT-4o, Gemini, Claude Sonnet, and Llama 2, the study assesses
their effectiveness in conveying environmental concepts and, consequently,
facilitating environmental education. The investigation employs a standardized
tool, the Environmental Knowledge Test (EKT-19), supplemented by targeted
questions, to evaluate the environmental knowledge of university students in
comparison to the responses generated by the AI models. The results of this
study suggest that while AI models possess a vast, readily accessible, and
valid knowledge base with the potential to empower both students and academic
staff, a human discipline specialist in environmental sciences may still be
necessary to validate the accuracy of the information provided.

</details>


### [30] [Causal identification with $Y_0$](https://arxiv.org/abs/2508.03167)
*Charles Tapley Hoyt,Craig Bakker,Richard J. Callahan,Joseph Cottam,August George,Benjamin M. Gyori,Haley M. Hummel,Nathaniel Merrill,Sara Mohammad Taheri,Pruthvi Prakash Navada,Marc-Antoine Parent,Adam Rupe,Olga Vitek,Jeremy Zucker*

Main category: cs.AI

TL;DR: Y_0是一个Python包，用于实现因果识别算法，支持干预、反事实和可迁移性查询，适用于随机对照试验或观察性研究数据。


<details>
  <summary>Details</summary>
Motivation: 帮助研究者在尝试量化因果关系的强度之前，先定性分析因果关系是否可从现有数据中估计。

Method: 提供领域特定语言表示因果查询和估计量，支持因果图模型（如ADMGs）和多种识别算法。

Result: Y_0能够将因果查询转化为符号估计量，并提供工具支持非参数估计。

Conclusion: Y_0为因果推断研究提供了便捷的工具，代码开源且易于安装。

Abstract: We present the $Y_0$ Python package, which implements causal identification
algorithms that apply interventional, counterfactual, and transportability
queries to data from (randomized) controlled trials, observational studies, or
mixtures thereof. $Y_0$ focuses on the qualitative investigation of causation,
helping researchers determine whether a causal relationship can be estimated
from available data before attempting to estimate how strong that relationship
is. Furthermore, $Y_0$ provides guidance on how to transform the causal query
into a symbolic estimand that can be non-parametrically estimated from the
available data. $Y_0$ provides a domain-specific language for representing
causal queries and estimands as symbolic probabilistic expressions, tools for
representing causal graphical models with unobserved confounders, such as
acyclic directed mixed graphs (ADMGs), and implementations of numerous
identification algorithms from the recent causal inference literature. The
$Y_0$ source code can be found under the MIT License at
https://github.com/y0-causal-inference/y0 and it can be installed with pip
install y0.

</details>


### [31] [Geoint-R1: Formalizing Multimodal Geometric Reasoning with Dynamic Auxiliary Constructions](https://arxiv.org/abs/2508.03173)
*Jingxuan Wei,Caijun Jia,Qi Chen,Honghao He,Linzhuang Sun,Conghui He,Lijun Wu,Bihui Yu,Cheng Tan*

Main category: cs.AI

TL;DR: Geoint-R1是一个多模态推理框架，专注于生成可形式化验证的几何解决方案，通过结合辅助元素构建、Lean4形式推理和交互式可视化，显著提升了几何推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在形式化几何推理（尤其是动态构建和验证辅助几何元素）方面表现不佳，Geoint-R1旨在解决这一问题。

Method: Geoint-R1整合了辅助元素构建、Lean4形式化表示和交互式可视化，并通过Geoint基准（1,885个几何问题）进行系统评估。

Result: 实验表明，Geoint-R1在需要显式辅助元素构建的复杂问题上显著优于现有模型。

Conclusion: Geoint-R1为形式化几何推理提供了有效解决方案，并通过基准数据集推动了该领域的发展。

Abstract: Mathematical geometric reasoning is essential for scientific discovery and
educational development, requiring precise logic and rigorous formal
verification. While recent advances in Multimodal Large Language Models (MLLMs)
have improved reasoning tasks, existing models typically struggle with formal
geometric reasoning, particularly when dynamically constructing and verifying
auxiliary geometric elements. To address these challenges, we introduce
Geoint-R1, a multimodal reasoning framework designed to generate formally
verifiable geometric solutions from textual descriptions and visual diagrams.
Geoint-R1 uniquely integrates auxiliary elements construction, formal reasoning
represented via Lean4, and interactive visualization. To systematically
evaluate and advance formal geometric reasoning, we propose the Geoint
benchmark, comprising 1,885 rigorously annotated geometry problems across
diverse topics such as plane, spatial, and solid geometry. Each problem
includes structured textual annotations, precise Lean4 code for auxiliary
constructions, and detailed solution steps verified by experts. Extensive
experiments demonstrate that Geoint-R1 significantly surpasses existing
multimodal and math-specific reasoning models, particularly on challenging
problems requiring explicit auxiliary element constructions.

</details>


### [32] [InqEduAgent: Adaptive AI Learning Partners with Gaussian Process Augmentation](https://arxiv.org/abs/2508.03174)
*Tian-Fang Zhao,Wen-Xi Yang*

Main category: cs.AI

TL;DR: 论文提出了一种基于LLM的智能代理模型InqEduAgent，用于模拟和选择适合探究式学习的学习伙伴，解决了传统方法在知识扩展和灵活性上的不足。


<details>
  <summary>Details</summary>
Motivation: 探究式教育中，学习伙伴的选择通常依赖经验或规则，缺乏科学规划和灵活性，限制了知识扩展和学习效果。

Method: 设计了生成式代理捕捉学习者的认知和评估特征，并采用高斯过程增强的自适应匹配算法识别先验知识模式，为不同练习提供最优学习伙伴匹配。

Result: 实验表明InqEduAgent在多数知识学习场景和不同能力的LLM环境中表现最优。

Conclusion: 该研究推动了基于人类和AI的学习伙伴智能分配，相关代码和数据已公开。

Abstract: Collaborative partnership matters in inquiry-oriented education. However,
most study partners are selected either rely on experience-based assignments
with little scientific planning or build on rule-based machine assistants,
encountering difficulties in knowledge expansion and inadequate flexibility.
This paper proposes an LLM-empowered agent model for simulating and selecting
learning partners tailored to inquiry-oriented learning, named InqEduAgent.
Generative agents are designed to capture cognitive and evaluative features of
learners in real-world scenarios. Then, an adaptive matching algorithm with
Gaussian process augmentation is formulated to identify patterns within prior
knowledge. Optimal learning-partner matches are provided for learners facing
different exercises. The experimental results show the optimal performance of
InqEduAgent in most knowledge-learning scenarios and LLM environment with
different levels of capabilities. This study promotes the intelligent
allocation of human-based learning partners and the formulation of AI-based
learning partners. The code, data, and appendix are publicly available at
https://github.com/InqEduAgent/InqEduAgent.

</details>


### [33] [Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning](https://arxiv.org/abs/2508.03251)
*Osama Mohammed,Jiaxin Pan,Mojtaba Nayyeri,Daniel Hernández,Steffen Staab*

Main category: cs.AI

TL;DR: 论文提出了一种全历史图模型（full-history graph）和边类型解耦网络（ETDNet），用于建模实体间动态交互，显著提升了驾驶意图预测和比特币欺诈检测的性能。


<details>
  <summary>Details</summary>
Motivation: 现实任务中需要建模实体间的动态交互（如交通中的车辆行为或金融交易中的资金流动），现有方法通常使用快照图，无法充分捕捉关系和时间的演化。

Method: 提出全历史图模型，区分时间步内和时间步间边；设计ETDNet，结合图注意力模块和时间注意力模块，分别处理两类边。

Result: 在Waymo和Elliptic++数据集上，ETDNet分别将联合准确率提升至75.6%（原74.1%）和非法类F1提升至88.1%（原60.4%）。

Conclusion: 通过将结构和时间关系表示为图中的不同边，ETDNet显著优于基线方法，验证了其有效性。

Abstract: Modeling evolving interactions among entities is critical in many real-world
tasks. For example, predicting driver maneuvers in traffic requires tracking
how neighboring vehicles accelerate, brake, and change lanes relative to one
another over consecutive frames. Likewise, detecting financial fraud hinges on
following the flow of funds through successive transactions as they propagate
through the network. Unlike classic time-series forecasting, these settings
demand reasoning over who interacts with whom and when, calling for a
temporal-graph representation that makes both the relations and their evolution
explicit. Existing temporal-graph methods typically use snapshot graphs to
encode temporal evolution. We introduce a full-history graph that instantiates
one node for every entity at every time step and separates two edge sets: (i)
intra-time-step edges that capture relations within a single frame and (ii)
inter-time-step edges that connect an entity to itself at consecutive steps. To
learn on this graph we design an Edge-Type Decoupled Network (ETDNet) with
parallel modules: a graph-attention module aggregates information along
intra-time-step edges, a multi-head temporal-attention module attends over an
entity's inter-time-step history, and a fusion module combines the two messages
after every layer. Evaluated on driver-intention prediction (Waymo) and Bitcoin
fraud detection (Elliptic++), ETDNet consistently surpasses strong baselines,
lifting Waymo joint accuracy to 75.6\% (vs. 74.1\%) and raising Elliptic++
illicit-class F1 to 88.1\% (vs. 60.4\%). These gains demonstrate the benefit of
representing structural and temporal relations as distinct edges in a single
graph.

</details>


### [34] [ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools](https://arxiv.org/abs/2508.03284)
*Shaofeng Yin,Ting Lei,Yang Liu*

Main category: cs.AI

TL;DR: ToolVQA是一个大规模多模态数据集，旨在解决现有工具增强视觉问答（VQA）在真实世界多步推理任务中的不足。通过ToolEngine生成，包含23K实例和10种多模态工具，7B LFMs在ToolVQA上表现优异，甚至超越GPT-3.5-turbo。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强VQA在真实世界多步推理任务中表现不足，需要更贴近实际用户交互的数据集和方法。

Method: 提出ToolVQA数据集和ToolEngine生成管道，采用DFS和动态上下文示例匹配机制模拟人类工具使用推理。

Result: 7B LFMs在ToolVQA上表现优异，并在OOD数据集上超越GPT-3.5-turbo，展示强泛化能力。

Conclusion: ToolVQA和ToolEngine为工具增强LFMs提供了更贴近真实场景的数据和方法，显著提升了模型性能。

Abstract: Integrating external tools into Large Foundation Models (LFMs) has emerged as
a promising approach to enhance their problem-solving capabilities. While
existing studies have demonstrated strong performance in tool-augmented Visual
Question Answering (VQA), recent benchmarks reveal significant gaps in
real-world tool-use proficiency, particularly in functionally diverse
multimodal settings requiring multi-step reasoning. In this work, we introduce
ToolVQA, a large-scale multimodal dataset comprising 23K instances, designed to
bridge this gap. Unlike previous datasets that rely on synthetic scenarios and
simplified queries, ToolVQA features real-world visual contexts and challenging
implicit multi-step reasoning tasks, better aligning with real user
interactions. To construct this dataset, we propose ToolEngine, a novel data
generation pipeline that employs Depth-First Search (DFS) with a dynamic
in-context example matching mechanism to simulate human-like tool-use
reasoning. ToolVQA encompasses 10 multimodal tools across 7 diverse task
domains, with an average inference length of 2.78 reasoning steps per instance.
The fine-tuned 7B LFMs on ToolVQA not only achieve impressive performance on
our test set but also surpass the large close-sourced model GPT-3.5-turbo on
various out-of-distribution (OOD) datasets, demonstrating strong
generalizability to real-world tool-use scenarios.

</details>


### [35] [Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science](https://arxiv.org/abs/2508.03341)
*Jiayan Nan,Wenquan Ma,Wenlong Wu,Yize Chen*

Main category: cs.AI

TL;DR: Nemori是一种新型自组织记忆架构，通过两步对齐原则和预测校准原则解决LLMs在长期交互中的记忆问题，显著优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在长期交互中缺乏持久记忆能力，现有记忆系统依赖被动规则，限制了其学习和进化能力。

Method: Nemori采用两步对齐原则（基于事件分割理论）和预测校准原则（基于自由能原理），实现语义连贯的记忆组织和自适应知识进化。

Result: 在LoCoMo和LongMemEval基准测试中，Nemori显著优于现有系统，尤其在长上下文环境中表现突出。

Conclusion: Nemori为解决自主代理在长期动态工作流中的记忆问题提供了可行路径。

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities, yet their
inability to maintain persistent memory in long contexts limits their
effectiveness as autonomous agents in long-term interactions. While existing
memory systems have made progress, their reliance on arbitrary granularity for
defining the basic memory unit and passive, rule-based mechanisms for knowledge
extraction limits their capacity for genuine learning and evolution. To address
these foundational limitations, we present Nemori, a novel self-organizing
memory architecture inspired by human cognitive principles. Nemori's core
innovation is twofold: First, its Two-Step Alignment Principle, inspired by
Event Segmentation Theory, provides a principled, top-down method for
autonomously organizing the raw conversational stream into semantically
coherent episodes, solving the critical issue of memory granularity. Second,
its Predict-Calibrate Principle, inspired by the Free-energy Principle, enables
the agent to proactively learn from prediction gaps, moving beyond pre-defined
heuristics to achieve adaptive knowledge evolution. This offers a viable path
toward handling the long-term, dynamic workflows of autonomous agents.
Extensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that
Nemori significantly outperforms prior state-of-the-art systems, with its
advantage being particularly pronounced in longer contexts.

</details>


### [36] [Adaptive AI Agent Placement and Migration in Edge Intelligence Systems](https://arxiv.org/abs/2508.03345)
*Xingdan Wang,Jiayi He,Zhiqing Tang,Jianxiong Guo,Jiong Lou,Liping Qian,Tian Wang,Weijia Jia*

Main category: cs.AI

TL;DR: 本文提出了一种针对动态边缘环境中基于LLM的AI代理的系统化部署与管理方案，通过自适应框架优化资源利用和QoS。


<details>
  <summary>Details</summary>
Motivation: 随着LLM（如ChatGPT和Claude）的兴起，需要能够实时处理任务的AI代理。传统云数据中心部署导致高延迟，而边缘环境资源有限且异构，需解决代理迁移和资源优化问题。

Method: 提出一种自适应框架，结合蚁群算法和LLM优化，建模资源约束与延迟/成本，实现高效代理部署与轻量级迁移。

Result: 在分布式系统中实现并验证，显著降低部署延迟和迁移成本。

Conclusion: 该方案为动态边缘环境中的AI代理部署提供了高效、低延迟的解决方案。

Abstract: The rise of LLMs such as ChatGPT and Claude fuels the need for AI agents
capable of real-time task handling. However, migrating data-intensive,
multi-modal edge workloads to cloud data centers, traditionally used for agent
deployment, introduces significant latency. Deploying AI agents at the edge
improves efficiency and reduces latency. However, edge environments present
challenges due to limited and heterogeneous resources. Maintaining QoS for
mobile users necessitates agent migration, which is complicated by the
complexity of AI agents coordinating LLMs, task planning, memory, and external
tools. This paper presents the first systematic deployment and management
solution for LLM-based AI agents in dynamic edge environments. We propose a
novel adaptive framework for AI agent placement and migration in edge
intelligence systems. Our approach models resource constraints and
latency/cost, leveraging ant colony algorithms and LLM-based optimization for
efficient decision-making. It autonomously places agents to optimize resource
utilization and QoS and enables lightweight agent migration by transferring
only essential state. Implemented on a distributed system using AgentScope and
validated across globally distributed edge servers, our solution significantly
reduces deployment latency and migration costs.

</details>


### [37] [Compressing Chain-of-Thought in LLMs via Step Entropy](https://arxiv.org/abs/2508.03346)
*Zeju Li,Jianyuan Zhong,Ziyang Zheng,Xiangyu Wen,Zhijian Xu,Yingying Cheng,Fan Zhang,Qiang Xu*

Main category: cs.AI

TL;DR: 提出了一种基于步骤熵的CoT压缩框架，通过识别冗余步骤显著提升LLM推理效率，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs使用CoT提示时生成的冗长推理过程存在大量冗余，增加了推理成本并降低了效率。

Method: 引入步骤熵量化推理步骤的信息贡献，提出两阶段训练策略（SFT和GRPO强化学习），使LLM在推理中生成压缩的CoT。

Result: 实验表明，80%的低熵冗余步骤可被剪枝且对最终答案准确性影响极小。

Conclusion: 该方法显著提升了LLM推理效率，为实际部署和推理结构理解提供了新视角。

Abstract: Large Language Models (LLMs) using Chain-of-Thought (CoT) prompting excel at
complex reasoning but generate verbose thought processes with considerable
redundancy, leading to increased inference costs and reduced efficiency. We
introduce a novel CoT compression framework based on step entropy, a metric
that quantifies the informational contribution of individual reasoning steps to
identify redundancy. Through theoretical analysis and extensive empirical
validation on mathematical reasoning benchmarks, we demonstrate that steps with
low entropy are indeed highly redundant. Our experiments reveal that an
astonishing 80\% of low-entropy intermediate steps can be pruned with minor
degradation in the final answer accuracy across DeepSeek-R1-7B, 14B and
Qwen3-8B. This finding sharply contrasts with random or high-entropy pruning,
which severely impairs reasoning performance. Building on this, we propose a
novel two-stage training strategy combining Supervised Fine-Tuning (SFT) and
Group Relative Policy Optimization (GRPO) reinforcement learning. This approach
enables LLMs to autonomously learn to generate compressed COTs during inference
by strategically incorporating [SKIP] tokens. Our method significantly enhances
LLM inference efficiency while rigorously preserving accuracy, offering
profound implications for practical LLM deployment and a deeper understanding
of reasoning structures.

</details>


### [38] [CogBench: A Large Language Model Benchmark for Multilingual Speech-Based Cognitive Impairment Assessment](https://arxiv.org/abs/2508.03360)
*Feng Rui,Zhiyao Luo,Wei Wang,Yuting Song,Yong Liu,Tingting Zhu,Jianqing Li,Xingyao Wang*

Main category: cs.AI

TL;DR: CogBench是一个评估大语言模型（LLMs）在跨语言和跨临床环境中认知障碍评估泛化能力的基准，结果表明LLMs在链式思维提示下表现更好，LoRA微调显著提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前认知障碍自动评估方法在跨语言和临床环境中的泛化能力不足，限制了实际应用。

Method: 提出CogBench基准，使用统一多模态管道评估LLMs在英语和普通话数据集（ADReSSo、NCMMSC2021-AD、CIR-E）上的表现，对比传统深度学习模型和LLMs的表现，并探索LoRA微调的效果。

Result: 传统深度学习模型在跨领域迁移时性能显著下降，而LLMs在链式思维提示下表现更优，但性能仍受提示设计影响；LoRA微调显著提升泛化能力。

Conclusion: LLMs结合LoRA微调为构建临床实用且语言鲁棒的认知评估工具提供了重要进展。

Abstract: Automatic assessment of cognitive impairment from spontaneous speech offers a
promising, non-invasive avenue for early cognitive screening. However, current
approaches often lack generalizability when deployed across different languages
and clinical settings, limiting their practical utility. In this study, we
propose CogBench, the first benchmark designed to evaluate the cross-lingual
and cross-site generalizability of large language models (LLMs) for
speech-based cognitive impairment assessment. Using a unified multimodal
pipeline, we evaluate model performance on three speech datasets spanning
English and Mandarin: ADReSSo, NCMMSC2021-AD, and a newly collected test set,
CIR-E. Our results show that conventional deep learning models degrade
substantially when transferred across domains. In contrast, LLMs equipped with
chain-of-thought prompting demonstrate better adaptability, though their
performance remains sensitive to prompt design. Furthermore, we explore
lightweight fine-tuning of LLMs via Low-Rank Adaptation (LoRA), which
significantly improves generalization in target domains. These findings offer a
critical step toward building clinically useful and linguistically robust
speech-based cognitive assessment tools.

</details>


### [39] [A Comparative Study of Neurosymbolic AI Approaches to Interpretable Logical Reasoning](https://arxiv.org/abs/2508.03366)
*Michael K. Chen*

Main category: cs.AI

TL;DR: 论文探讨了神经符号AI在通用逻辑推理中的潜力，比较了集成和混合两种方法，发现混合方法更具前景。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在通用逻辑推理上表现不足，神经符号AI成为研究热点，但两种主要方法的优劣尚未明确比较。

Method: 通过分析Logic Neural Network（集成方法）和LLM-Symbolic Solver（混合方法）两种模型，评估其在通用逻辑推理中的表现。

Result: 混合方法在解释性和保留LLM优势方面表现更优，更适合通用逻辑推理。

Conclusion: 提出基于LLM-SS的模块化框架，支持未来混合方法的研究与应用。

Abstract: General logical reasoning, defined as the ability to reason deductively on
domain-agnostic tasks, continues to be a challenge for large language models
(LLMs). Current LLMs fail to reason deterministically and are not
interpretable. As such, there has been a recent surge in interest in
neurosymbolic AI, which attempts to incorporate logic into neural networks. We
first identify two main neurosymbolic approaches to improving logical
reasoning: (i) the integrative approach comprising models where symbolic
reasoning is contained within the neural network, and (ii) the hybrid approach
comprising models where a symbolic solver, separate from the neural network,
performs symbolic reasoning. Both contain AI systems with promising results on
domain-specific logical reasoning benchmarks. However, their performance on
domain-agnostic benchmarks is understudied. To the best of our knowledge, there
has not been a comparison of the contrasting approaches that answers the
following question: Which approach is more promising for developing general
logical reasoning? To analyze their potential, the following best-in-class
domain-agnostic models are introduced: Logic Neural Network (LNN), which uses
the integrative approach, and LLM-Symbolic Solver (LLM-SS), which uses the
hybrid approach. Using both models as case studies and representatives of each
approach, our analysis demonstrates that the hybrid approach is more promising
for developing general logical reasoning because (i) its reasoning chain is
more interpretable, and (ii) it retains the capabilities and advantages of
existing LLMs. To support future works using the hybrid approach, we propose a
generalizable framework based on LLM-SS that is modular by design,
model-agnostic, domain-agnostic, and requires little to no human input.

</details>


### [40] [Board Game Arena: A Framework and Benchmark for Assessing Large Language Models via Strategic Play](https://arxiv.org/abs/2508.03368)
*Lucia Cipolina-Kun,Marianna Nezhurina,Jenia Jitsev*

Main category: cs.AI

TL;DR: Board Game Arena库通过战略棋盘游戏评估大型语言模型（LLM）的决策能力，支持多种游戏场景和代理类型，提供API访问和分布式执行，并分析LLM推理轨迹。


<details>
  <summary>Details</summary>
Motivation: 为LLM的推理能力和博弈行为提供系统化的实证评估框架。

Method: 集成Google OpenSpiel库，支持多种游戏和代理类型，提供API访问、本地部署和分布式执行工具。

Result: 实现了LLM与其他代理（随机、人类、强化学习等）的系统比较，并提供推理轨迹分析。

Conclusion: 该框架为LLM的决策能力和博弈行为研究提供了实用工具和系统评估方法。

Abstract: The Board Game Arena library provides a framework for evaluating the decision
making abilities of large language models (LLMs) through strategic board games
implemented in Google OpenSpiel library. The framework enables systematic
comparisons between LLM based agents and other agents (random, human,
reinforcement learning agents, etc.) in various game scenarios by wrapping
multiple board and matrix games and supporting different agent types. It
integrates API access to models via LiteLLM, local model deployment via vLLM,
and offers distributed execution through Ray. Additionally it provides
extensive analysis tools for the LLM reasoning traces. This paper summarizes
the structure, key characteristics, and motivation of the repository,
highlighting how it contributes to the empirical evaluation of the reasoning of
LLM and game-theoretic behavior

</details>


### [41] [Data Dependency Inference for Industrial Code Generation Based on UML Sequence Diagrams](https://arxiv.org/abs/2508.03379)
*Wenxin Mao,Zhitao Wang Long Wang,Sirong Chen,Cuiyun Gao,Luyang Cao,Ziming Liu,Qiming Zhang,Jun Zhou,Zhi Jin*

Main category: cs.AI

TL;DR: 论文提出UML2Dep框架，通过形式化规范解决自然语言描述代码生成中的模糊性问题，结合增强的UML序列图和数据依赖推理任务，提高代码生成的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 自然语言描述在代码生成中存在模糊性，难以捕捉复杂需求和隐式数据依赖，UML2Dep旨在通过形式化规范解决这一问题。

Method: 1. 引入增强的UML序列图，整合决策表和API规范；2. 提出数据依赖推理（DDI）任务，构建显式数据依赖图；3. 使用数学推理和静态解析优化推理过程。

Result: UML2Dep通过形式化规范和DDI任务，显著减少了模糊性，提高了代码生成的准确性和效率。

Conclusion: UML2Dep框架为复杂需求下的代码生成提供了可靠解决方案，结合形式化规范和LLM的数学优势，具有实际应用潜力。

Abstract: Large language models (LLMs) excel at generating code from natural language
(NL) descriptions. However, the plain textual descriptions are inherently
ambiguous and often fail to capture complex requirements like intricate system
behaviors, conditional logic, and architectural constraints; implicit data
dependencies in service-oriented architectures are difficult to infer and
handle correctly. To bridge this gap, we propose a novel step-by-step code
generation framework named UML2Dep by leveraging unambiguous formal
specifications of complex requirements. First, we introduce an enhanced Unified
Modeling Language (UML) sequence diagram tailored for service-oriented
architectures. This diagram extends traditional visual syntax by integrating
decision tables and API specifications, explicitly formalizing structural
relationships and business logic flows in service interactions to rigorously
eliminate linguistic ambiguity. Second, recognizing the critical role of data
flow, we introduce a dedicated data dependency inference (DDI) task. DDI
systematically constructs an explicit data dependency graph prior to actual
code synthesis. To ensure reliability, we formalize DDI as a constrained
mathematical reasoning task through novel prompting strategies, aligning with
LLMs' excellent mathematical strengths. Additional static parsing and
dependency pruning further reduce context complexity and cognitive load
associated with intricate specifications, thereby enhancing reasoning accuracy
and efficiency.

</details>


### [42] [Hide and Seek with LLMs: An Adversarial Game for Sneaky Error Generation and Self-Improving Diagnosis](https://arxiv.org/abs/2508.03396)
*Rui Zou,Mengqi Wei,Yutao Zhu,Jirong Wen,Xin Zhao,Jing Chen*

Main category: cs.AI

TL;DR: 论文提出了一种动态对抗框架HSG，通过生成和诊断复杂错误来提升大语言模型的诊断能力，实验表明其效果显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推理和生成方面表现出色，但在识别和诊断复杂错误方面仍有不足，主要原因是训练目标过于注重正确答案，缺乏对错误的学习。

Method: 提出Hide and Seek Game (HSG)框架，包含两个对抗角色：Sneaky生成隐蔽的错误，Diagnosis负责检测错误，通过对抗协同进化提升能力。

Result: 在数学问题解决任务中，HSG显著提升了错误诊断能力，准确率比GPT-4o等基线模型高出16.8%--31.4%。

Conclusion: HSG框架有效提升了大语言模型的错误诊断能力，并发布了具有挑战性的数据集，为未来研究提供了基准。

Abstract: Large Language Models (LLMs) excel in reasoning and generation across
domains, but still struggle with identifying and diagnosing complex errors.
This stems mainly from training objectives that prioritize correct answers,
limiting exposure to and learning from errors. While recent studies have begun
to address this by introducing error signals, most rely on shallow, static
errors, restricting improvement in deep diagnostic ability. To overcome this,
we propose Hide and Seek Game (HSG), a dynamic adversarial framework for error
generation and diagnosis, and evaluate it on mathematical problem-solving. HSG
involves two adversarial roles: Sneaky, which "hides" by generating subtle,
deceptive reasoning errors, and Diagnosis, which "seeks" to accurately detect
them. Through adversarial co-evolution, both error stealth and diagnostic
precision are enhanced. Experiments on several math reasoning tasks show that
HSG significantly boosts error diagnosis, achieving 16.8\%--31.4\% higher
accuracy than baselines like GPT-4o. We also release a challenging dataset of
deceptive errors and diagnostic annotations as a benchmark for future research.

</details>


### [43] [Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large Language Models](https://arxiv.org/abs/2508.03406)
*Kai Li,Ruihao Zheng,Xinye Hao,Zhenkun Wang*

Main category: cs.AI

TL;DR: MOID结合LLM代理和多目标优化，为不可行路由问题提供多种可行动建议。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法无法全面处理不可行模型的多重潜在调整需求。

Method: MOID通过多目标优化和LLM代理生成解决方案分析函数，提供多样化诊断建议。

Result: 在50类不可行路由问题中，MOID单次运行即可生成多种实用建议，优于现有方法。

Conclusion: MOID为不可行模型提供了更实用的诊断和决策支持。

Abstract: In real-world routing problems, users often propose conflicting or
unreasonable requirements, which result in infeasible optimization models due
to overly restrictive or contradictory constraints, leading to an empty
feasible solution set. Existing Large Language Model (LLM)-based methods
attempt to diagnose infeasible models, but modifying such models often involves
multiple potential adjustments that these methods do not consider. To fill this
gap, we introduce Multi-Objective Infeasibility Diagnosis (MOID), which
combines LLM agents and multi-objective optimization within an automatic
routing solver, to provide a set of representative actionable suggestions.
Specifically, MOID employs multi-objective optimization to consider both path
cost and constraint violation, generating a set of trade-off solutions, each
encompassing varying degrees of model adjustments. To extract practical
insights from these solutions, MOID utilizes LLM agents to generate a solution
analysis function for the infeasible model. This function analyzes these
distinct solutions to diagnose the original infeasible model, providing users
with diverse diagnostic insights and suggestions. Finally, we compare MOID with
several LLM-based methods on 50 types of infeasible routing problems. The
results indicate that MOID automatically generates multiple diagnostic
suggestions in a single run, providing more practical insights for restoring
model feasibility and decision-making compared to existing methods.

</details>


### [44] [Data Overdose? Time for a Quadruple Shot: Knowledge Graph Construction using Enhanced Triple Extraction](https://arxiv.org/abs/2508.03438)
*Taine J. Elliott,Stephen P. Levitt,Ken Nixon,Martin Bekker*

Main category: cs.AI

TL;DR: 该论文提出了一种基于大语言模型（LLM）的信息提取和知识图谱（KG）生成方法，用于连接生物医学知识，并通过上下文变量增强提取准确性。


<details>
  <summary>Details</summary>
Motivation: 解决医学数据快速增长导致临床和研究领域难以系统化理解和应用最新知识的问题。

Method: 使用LLM代理分解PubMed摘要为语义命题句子，提取KG三元组，并通过上下文变量增强为四元组，结合开放领域和本体论方法。

Result: 提取的三元组增强后生成的自然语言句子与原命题的平均余弦相似度为0.874，上下文变量显著提升了相似度。

Conclusion: 该方法为医学从业者提供了实时更新的集中知识源，并可能在其他领域实现类似效果。

Abstract: The rapid expansion of publicly-available medical data presents a challenge
for clinicians and researchers alike, increasing the gap between the volume of
scientific literature and its applications. The steady growth of studies and
findings overwhelms medical professionals at large, hindering their ability to
systematically review and understand the latest knowledge. This paper presents
an approach to information extraction and automatic knowledge graph (KG)
generation to identify and connect biomedical knowledge. Through a pipeline of
large language model (LLM) agents, the system decomposes 44 PubMed abstracts
into semantically meaningful proposition sentences and extracts KG triples from
these sentences. The triples are enhanced using a combination of open domain
and ontology-based information extraction methodologies to incorporate
ontological categories. On top of this, a context variable is included during
extraction to allow the triple to stand on its own - thereby becoming
`quadruples'. The extraction accuracy of the LLM is validated by comparing
natural language sentences generated from the enhanced triples to the original
propositions, achieving an average cosine similarity of 0.874. The similarity
for generated sentences of enhanced triples were compared with generated
sentences of ordinary triples showing an increase as a result of the context
variable. Furthermore, this research explores the ability for LLMs to infer new
relationships and connect clusters in the knowledge base of the knowledge
graph. This approach leads the way to provide medical practitioners with a
centralised, updated in real-time, and sustainable knowledge source, and may be
the foundation of similar gains in a wide variety of fields.

</details>


### [45] [Toward a Graph-Theoretic Model of Belief: Confidence, Credibility, and Structural Coherence](https://arxiv.org/abs/2508.03465)
*Saleh Nikooroo*

Main category: cs.AI

TL;DR: 本文提出了一种基于有向加权图的信念系统形式化方法，区分了信念的可信度和置信度，避免了传统概率或逻辑模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统信念系统表示方法（如概率分布或逻辑命题）忽略了内部结构，无法处理矛盾或碎片化的认知状态。

Method: 使用有向加权图表示信念系统，节点为信念，边为认知关系（支持或矛盾），并分别定义可信度和置信度函数。

Result: 提供了一种静态框架，支持对信念系统的内部结构、一致性和认知张力的分析，优于传统方法。

Conclusion: 该形式化为信念系统的内部组织提供了更丰富的分类和分析工具，弥补了现有方法的不足。

Abstract: Belief systems are often treated as globally consistent sets of propositions
or as scalar-valued probability distributions. Such representations tend to
obscure the internal structure of belief, conflate external credibility with
internal coherence, and preclude the modeling of fragmented or contradictory
epistemic states. This paper introduces a minimal formalism for belief systems
as directed, weighted graphs. In this framework, nodes represent individual
beliefs, edges encode epistemic relationships (e.g., support or contradiction),
and two distinct functions assign each belief a credibility (reflecting source
trust) and a confidence (derived from internal structural support). Unlike
classical probabilistic models, our approach does not assume prior coherence or
require belief updating. Unlike logical and argumentation-based frameworks, it
supports fine-grained structural representation without committing to binary
justification status or deductive closure. The model is purely static and
deliberately excludes inference or revision procedures. Its aim is to provide a
foundational substrate for analyzing the internal organization of belief
systems, including coherence conditions, epistemic tensions, and
representational limits. By distinguishing belief structure from belief
strength, this formalism enables a richer classification of epistemic states
than existing probabilistic, logical, or argumentation-based approaches.

</details>


### [46] [Semantic-aware Graph-guided Behavior Sequences Generation with Large Language Models for Smart Homes](https://arxiv.org/abs/2508.03484)
*Zhiyao Xu,Dan Zhao,Qingsong Zou,Qing Li,Yong Jiang,Yuhang Wang,Jingyu Xiao*

Main category: cs.AI

TL;DR: SmartGen是一个基于LLM的框架，用于合成上下文感知的用户行为数据，以支持智能家居模型的持续适应。


<details>
  <summary>Details</summary>
Motivation: 智能家居模型通常基于静态数据集训练，难以应对行为漂移（如季节变化、生活方式改变等），而新数据收集又面临速度慢、成本高和隐私问题。

Method: SmartGen包含四个关键组件：时间和语义感知分割、语义感知序列压缩、图引导序列合成和两阶段异常过滤器。

Result: 实验表明，SmartGen显著提升了行为漂移下的异常检测（提升85.43%）和行为预测（提升70.51%）性能。

Conclusion: SmartGen通过合成高质量行为数据，有效解决了智能家居模型的行为漂移问题。

Abstract: As smart homes become increasingly prevalent, intelligent models are widely
used for tasks such as anomaly detection and behavior prediction. These models
are typically trained on static datasets, making them brittle to behavioral
drift caused by seasonal changes, lifestyle shifts, or evolving routines.
However, collecting new behavior data for retraining is often impractical due
to its slow pace, high cost, and privacy concerns. In this paper, we propose
SmartGen, an LLM-based framework that synthesizes context-aware user behavior
data to support continual adaptation of downstream smart home models. SmartGen
consists of four key components. First, we design a Time and Semantic-aware
Split module to divide long behavior sequences into manageable, semantically
coherent subsequences under dual time-span constraints. Second, we propose
Semantic-aware Sequence Compression to reduce input length while preserving
representative semantics by clustering behavior mapping in latent space. Third,
we introduce Graph-guided Sequence Synthesis, which constructs a behavior
relationship graph and encodes frequent transitions into prompts, guiding the
LLM to generate data aligned with contextual changes while retaining core
behavior patterns. Finally, we design a Two-stage Outlier Filter to identify
and remove implausible or semantically inconsistent outputs, aiming to improve
the factual coherence and behavioral validity of the generated sequences.
Experiments on three real-world datasets demonstrate that SmartGen
significantly enhances model performance on anomaly detection and behavior
prediction tasks under behavioral drift, with anomaly detection improving by
85.43% and behavior prediction by 70.51% on average. The code is available at
https://github.com/horizonsinzqs/SmartGen.

</details>


### [47] [VQA support to Arabic Language Learning Educational Tool](https://arxiv.org/abs/2508.03488)
*Khaled Bachir Delassi,Lakhdar Zeggane,Hadda Cherroun,Abdelhamid Haouhat,Kaoutar Bouzouad*

Main category: cs.AI

TL;DR: 论文提出了一种基于AI的阿拉伯语学习工具，通过视觉问答和主动学习提升非母语学习者的语言能力。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语学习工具稀缺的问题，尤其是支持现代教学法（如主动学习）的工具。

Method: 结合视觉语言预训练模型和大型语言模型，生成交互式视觉测验，采用建构主义学习方法。

Result: 通过人工标注的1266个测验评估，工具表现出较高的准确性，验证了其有效性。

Conclusion: 该工具为阿拉伯语学习者提供了个性化、互动的学习体验，填补了教育资源的空白。

Abstract: We address the problem of scarcity of educational Arabic Language Learning
tools that advocate modern pedagogical models such as active learning which
ensures language proficiency. In fact, we investigate the design and evaluation
of an AI-powered educational tool designed to enhance Arabic language learning
for non-native speakers with beginner-to-intermediate proficiency level. The
tool leverages advanced AI models to generate interactive visual quizzes,
deploying Visual Question Answering as the primary activity. Adopting a
constructivist learning approach, the system encourages active learning through
real-life visual quizzes, and image-based questions that focus on improving
vocabulary, grammar, and comprehension. The system integrates Vision-Language
Pretraining models to generate contextually relevant image description from
which Large Language Model generate assignments based on customized Arabic
language Learning quizzes thanks to prompting.
  The effectiveness of the tool is evaluated through a manual annotated
benchmark consisting of 1266 real-life visual quizzes, with human participants
providing feedback. The results show a suitable accuracy rates, validating the
tool's potential to bridge the gap in Arabic language education and
highlighting the tool's promise as a reliable, AI-powered resource for Arabic
learners, offering personalized and interactive learning experiences.

</details>


### [48] [Error Detection and Correction for Interpretable Mathematics in Large Language Models](https://arxiv.org/abs/2508.03500)
*Yijin Yang,Cristina Cornelio,Mario Leiva,Paulo Shakarian*

Main category: cs.AI

TL;DR: EDCIM方法通过检测和纠正LLMs在数学任务中的错误，结合轻量级和强大模型，优化成本与准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs在多步推理中常产生错误，且难以遵守特定输出格式，影响数学表达式或代码生成的准确性。

Method: EDCIM利用LLMs生成方程组，通过符号化错误检测框架识别并提供反馈，结合轻量级和强大模型优化效率。

Result: 实验显示EDCIM显著降低计算和财务成本，同时保持或提升准确性。

Conclusion: EDCIM通过平衡成本与准确性，有效提升LLMs在数学任务中的表现。

Abstract: Recent large language models (LLMs) have demonstrated the ability to perform
explicit multi-step reasoning such as chain-of-thought prompting. However,
their intermediate steps often contain errors that can propagate leading to
inaccurate final predictions. Additionally, LLMs still struggle with
hallucinations and often fail to adhere to prescribed output formats, which is
particularly problematic for tasks like generating mathematical expressions or
source code. This work introduces EDCIM (Error Detection and Correction for
Interpretable Mathematics), a method for detecting and correcting these errors
in interpretable mathematics tasks, where the model must generate the exact
functional form that explicitly solve the problem (expressed in natural
language) rather than a black-box solution. EDCIM uses LLMs to generate a
system of equations for a given problem, followed by a symbolic error-detection
framework that identifies errors and provides targeted feedback for LLM-based
correction. To optimize efficiency, EDCIM integrates lightweight, open-source
LLMs with more powerful proprietary models, balancing cost and accuracy. This
balance is controlled by a single hyperparameter, allowing users to control the
trade-off based on their cost and accuracy requirements. Experimental results
across different datasets show that EDCIM significantly reduces both
computational and financial costs, while maintaining, and even improving,
prediction accuracy when the balance is properly configured.

</details>


### [49] [Hidden Dynamics of Massive Activations in Transformer Training](https://arxiv.org/abs/2508.03616)
*Jorge Gallego-Feliciano,S. Aaron McClendon,Juan Morinelli,Stavros Zervoudakis,Antonios Saravanos*

Main category: cs.AI

TL;DR: 论文分析了Transformer训练过程中大规模激活值的动态发展规律，提出了一种预测模型，并展示了如何通过设计控制这些激活值。


<details>
  <summary>Details</summary>
Motivation: 研究大规模激活值在训练过程中的动态发展规律，填补了现有研究的空白，并为模型设计提供指导。

Method: 使用Pythia模型家族进行系统分析，提出基于指数调制对数函数的数学模型，并开发机器学习框架预测参数。

Result: 发现大规模激活值的发展遵循可预测的数学规律，模型能准确预测稳态行为，但对出现时间和规模的预测精度一般。

Conclusion: 大规模激活值的出现受模型设计影响，可通过设计预测和控制，对模型稳定性、训练周期和优化有重要意义。

Abstract: Massive activations are scalar values in transformer hidden states that
achieve values orders of magnitude larger than typical activations and have
been shown to be critical for model functionality. While prior work has
characterized these phenomena in fully trained models, the temporal dynamics of
their emergence during training remain poorly understood. We present the first
comprehensive analysis of massive activation development throughout transformer
training, using the Pythia model family as our testbed. Through systematic
analysis of various model sizes across multiple training checkpoints, we
demonstrate that massive activation emergence follows predictable mathematical
patterns that can be accurately modeled using an exponentially-modulated
logarithmic function with five key parameters. We develop a machine learning
framework to predict these mathematical parameters from architectural
specifications alone, achieving high accuracy for steady-state behavior and
moderate accuracy for emergence timing and magnitude. These findings enable
architects to predict and potentially control key aspects of massive activation
emergence through design choices, with significant implications for model
stability, training cycle length, interpretability, and optimization. Our
findings demonstrate that the emergence of massive activations is governed by
model design and can be anticipated, and potentially controlled, before
training begins.

</details>


### [50] [Refining Critical Thinking in LLM Code Generation: A Faulty Premise-based Evaluation Framework](https://arxiv.org/abs/2508.03622)
*Jialin Li,Jinzhe Li,Gengxu Li,Yi Chang,Yuan Wu*

Main category: cs.AI

TL;DR: FPBench是首个针对代码生成中错误前提的评估框架，通过构建三类错误前提和多维评估指标，评估了15个代表性LLM，发现模型在错误前提下的表现不佳，揭示了其认知机制的缺陷。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代码生成能力的提升，其对输入前提的依赖增加，但错误前提会导致代码生成幻觉，暴露其自检能力的不足。

Method: 提出FPBench框架，系统构建三类错误前提并整合多维评估指标，对15个LLM进行深入评估。

Result: 发现模型在错误前提下的推理能力差，资源投入存在边际效应，且三类错误前提分别激活不同的缺陷模式。

Conclusion: 研究强调了LLM主动验证前提的紧迫性，FPBench为开发可靠、以人为本的代码生成模型提供了理论和实践基础。

Abstract: With the advancement of code generation capabilities in large language models
(LLMs), their reliance on input premises has intensified. When users provide
inputs containing faulty premises, the probability of code generation
hallucinations rises significantly, exposing deficiencies in their
self-scrutiny capabilities. This paper proposes Faulty Premises Bench
(FPBench), the first code generation evaluation framework targeting faulty
premises. By systematically constructing three categories of faulty premises
and integrating multi-dimensional evaluation metrics, it conducts in-depth
assessments of 15 representative LLMs. The key findings are as follows: (1)
Most models exhibit poor reasoning abilities and suboptimal code generation
performance under faulty premises, heavily relying on explicit prompts for
error detection, with limited self-scrutiny capabilities; (2) Faulty premises
trigger a point of diminishing returns in resource investment, leading to
blindly increasing length fails to enhance quality; (3) The three types of
faulty premises respectively activate distinct defect patterns in models,
revealing a triple dissociation in the cognitive mechanisms of code generation
models. This study not only highlights the urgent need for LLMs to proactively
verify premises in code generation but also, through the proposed FPBench
framework and multi-dimensional evaluation system, provides a theoretical
foundation and practical pathway for developing reliable, human-centric code
generation models.

</details>


### [51] [Automated Algorithmic Discovery for Gravitational-Wave Detection Guided by LLM-Informed Evolutionary Monte Carlo Tree Search](https://arxiv.org/abs/2508.03661)
*He Wang,Liang Zeng*

Main category: cs.AI

TL;DR: 提出了一种名为Evo-MCTS的新框架，结合进化优化和蒙特卡洛树搜索，用于改进引力波信号识别算法，性能提升20.2%。


<details>
  <summary>Details</summary>
Motivation: 现有算法（如匹配滤波和深度神经网络）在引力波信号识别中存在计算量大或决策逻辑不透明的问题。

Method: 结合蒙特卡洛树搜索、进化优化和大语言模型启发式，生成可解释的算法解决方案。

Result: 在MLGWSC-1数据集上性能提升20.2%，并发现新的算法组合。

Conclusion: Evo-MCTS为计算科学领域的自动化算法发现提供了可转移的方法论。

Abstract: Computational scientific discovery increasingly relies on algorithms to
process complex data and identify meaningful patterns - yet faces persistent
challenges in gravitational-wave signal identification. While existing
algorithmic approaches like matched filtering (MF) and deep neural networks
(DNNs) have achieved partial success, their limitations directly stem from
fundamental limitations: MF's excessive computational demands arise from its
reliance on predefined theoretical waveform templates, while DNNs' black-box
architectures obscure decision logic and introduce hidden biases. We propose
Evolutionary Monte Carlo Tree Search (Evo-MCTS), a framework that addresses
these limitations through systematic algorithm space exploration guided by
domain-aware physical constraints. Our approach combines tree-structured search
with evolutionary optimization and large language model heuristics to create
interpretable algorithmic solutions. Our Evo-MCTS framework demonstrates
substantial improvements, achieving a 20.2\% improvement over state-of-the-art
gravitational wave detection algorithms on the MLGWSC-1 benchmark dataset.
High-performing algorithm variants consistently exceed thresholds. The
framework generates human-interpretable algorithmic pathways that reveal
distinct performance patterns. Beyond performance improvements, our framework
discovers novel algorithmic combinations, thereby establishing a transferable
methodology for automated algorithmic discovery across computational science
domains.

</details>


### [52] [Agent Lightning: Train ANY AI Agents with Reinforcement Learning](https://arxiv.org/abs/2508.03680)
*Xufang Luo,Yuge Zhang,Zhiyuan He,Zilong Wang,Siyun Zhao,Dongsheng Li,Luna K. Qiu,Yuqing Yang*

Main category: cs.AI

TL;DR: Agent Lightning是一个灵活可扩展的框架，通过强化学习（RL）训练大型语言模型（LLMs），实现与现有AI代理的无缝集成，无需代码修改。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将RL训练与代理紧密耦合或依赖序列拼接，限制了灵活性和扩展性。Agent Lightning旨在解决这一问题，实现训练与执行的完全解耦。

Method: 通过将代理执行建模为马尔可夫决策过程，定义统一数据接口，并提出分层RL算法LightningRL，包含信用分配模块，支持复杂交互逻辑。

Result: 实验在文本到SQL、检索增强生成和数学工具使用任务中展示了稳定、持续的改进。

Conclusion: Agent Lightning为现实世界代理的训练和部署提供了潜力，支持多样化的代理开发方式。

Abstract: We present Agent Lightning, a flexible and extensible framework that enables
Reinforcement Learning (RL)-based training of Large Language Models (LLMs) for
any AI agent. Unlike existing methods that tightly couple RL training with
agent or rely on sequence concatenation with masking, Agent Lightning achieves
complete decoupling between agent execution and training, allowing seamless
integration with existing agents developed via diverse ways (e.g., using
frameworks like LangChain, OpenAI Agents SDK, AutoGen, and building from
scratch) with almost ZERO code modifications. By formulating agent execution as
Markov decision process, we define an unified data interface and propose a
hierarchical RL algorithm, LightningRL, which contains a credit assignment
module, allowing us to decompose trajectories generated by ANY agents into
training transition. This enables RL to handle complex interaction logic, such
as multi-agent scenarios and dynamic workflows. For the system design, we
introduce a Training-Agent Disaggregation architecture, and brings agent
observability frameworks into agent runtime, providing a standardized agent
finetuning interface. Experiments across text-to-SQL, retrieval-augmented
generation, and math tool-use tasks demonstrate stable, continuous
improvements, showcasing the framework's potential for real-world agent
training and deployment.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [53] [Learning User Interaction Forces using Vision for a Soft Finger Exosuit](https://arxiv.org/abs/2508.02870)
*Mohamed Irfan Refai,Abdulaziz Y. Alkayas,Anup Teejo Mathew,Federico Renda,Thomas George Thuruthel*

Main category: cs.RO

TL;DR: 提出了一种基于图像和学习的框架，用于估计手指外骨骼系统的分布式接触力，解决了软性可穿戴设备的建模和传感难题。


<details>
  <summary>Details</summary>
Motivation: 软性可穿戴辅助设备的非线性与顺应性特性使其物理建模和嵌入式传感具有挑战性，需要一种新方法来捕捉动态辅助的传递。

Method: 使用SoRoSim工具箱生成多样化的外骨骼几何和驱动场景数据集，开发基于图像和学习的框架，从低分辨率灰度图像估计接触力。

Result: 方法能准确估计多接触点的交互力，泛化能力强，对视觉噪声和对比度变化具有鲁棒性，并成功集成到反馈控制器中。

Conclusion: 该框架可作为实时力估计的非侵入式替代方案，为外骨骼的闭环控制提供支持。

Abstract: Wearable assistive devices are increasingly becoming softer. Modelling their
interface with human tissue is necessary to capture transmission of dynamic
assistance. However, their nonlinear and compliant nature makes both physical
modeling and embedded sensing challenging. In this paper, we develop a
image-based, learning-based framework to estimate distributed contact forces
for a finger-exosuit system. We used the SoRoSim toolbox to generate a diverse
dataset of exosuit geometries and actuation scenarios for training. The method
accurately estimated interaction forces across multiple contact locations from
low-resolution grayscale images, was able to generalize to unseen shapes and
actuation levels, and remained robust under visual noise and contrast
variations. We integrated the model into a feedback controller, and found that
the vision-based estimator functions as a surrogate force sensor for
closed-loop control. This approach could be used as a non-intrusive alternative
for real-time force estimation for exosuits.

</details>


### [54] [Tunable Leg Stiffness in a Monopedal Hopper for Energy-Efficient Vertical Hopping Across Varying Ground Profiles](https://arxiv.org/abs/2508.02873)
*Rongqian Chen,Jun Kwon,Kefan Wu,Wei-Hsi Chen*

Main category: cs.RO

TL;DR: HASTA是一种可调刚度的垂直跳跃机器人，通过实时调整腿部刚度优化不同地面条件下的能量效率，实验支持其假设。


<details>
  <summary>Details</summary>
Motivation: 研究目标是优化垂直跳跃机器人在不同地面条件下的能量效率，通过调整腿部刚度实现最大跳跃高度。

Method: 设计并实现HASTA机器人，通过实验和模拟测试不同地面条件下的最佳腿部刚度。

Result: 实验支持假设：软腿在软地面表现更好，硬腿在硬地面更优，可调刚度显著提升能量效率。

Conclusion: 可调刚度能有效提升机器人在不同地面条件下的能量效率，为未来控制器设计提供参考。

Abstract: We present the design and implementation of HASTA (Hopper with Adjustable
Stiffness for Terrain Adaptation), a vertical hopping robot with real-time
tunable leg stiffness, aimed at optimizing energy efficiency across various
ground profiles (a pair of ground stiffness and damping conditions). By
adjusting leg stiffness, we aim to maximize apex hopping height, a key metric
for energy-efficient vertical hopping. We hypothesize that softer legs perform
better on soft, damped ground by minimizing penetration and energy loss, while
stiffer legs excel on hard, less damped ground by reducing limb deformation and
energy dissipation. Through experimental tests and simulations, we find the
best leg stiffness within our selection for each combination of ground
stiffness and damping, enabling the robot to achieve maximum steady-state
hopping height with a constant energy input. These results support our
hypothesis that tunable stiffness improves energy-efficient locomotion in
controlled experimental conditions. In addition, the simulation provides
insights that could aid in the future development of controllers for selecting
leg stiffness.

</details>


### [55] [Co-designing Zoomorphic Robot Concepts for Animal Welfare Education](https://arxiv.org/abs/2508.02898)
*Isobel Voysey,Lynne Baillie,Joanne Williams,Michael Herrmann*

Main category: cs.RO

TL;DR: 研究通过参与式设计工作坊，探讨了动物福利教育中拟人化机器人的需求，包括外观、行为和叙事设计，并提出了针对儿童的新设计方法。


<details>
  <summary>Details</summary>
Motivation: 通过定制化机器人促进儿童对动物行为的理解，改善儿童与动物的互动。

Method: 与动物福利教育者和儿童进行参与式设计工作坊，分析需求并设计机器人。

Result: 发现机器人外观、行为特征及叙事设计的关键需求，并提出了新的设计活动方法。

Conclusion: 研究为动物福利教育中的拟人化机器人设计提供了实践指导，并强调了共识达成的重要性。

Abstract: Animal welfare education could greatly benefit from customized robots to help
children learn about animals and their behavior, and thereby promote positive,
safe child-animal interactions. To this end, we ran Participatory Design
workshops with animal welfare educators and children to identify key
requirements for zoomorphic robots from their perspectives. Our findings
encompass a zoomorphic robot's appearance, behavior, and features, as well as
concepts for a narrative surrounding the robot. Through comparing and
contrasting the two groups, we find the importance of: negative reactions to
undesirable behavior from children; using the facial features and tail to
provide cues signaling an animal's internal state; and a natural, furry
appearance and texture. We also contribute some novel activities for
Participatory Design with children, including branching storyboards inspired by
thematic apperception tests and interactive narratives, and reflect on some of
the key design challenges of achieving consensus between the groups, despite
much overlap in their design concepts.

</details>


### [56] [Context-aware Risk Assessment and Its Application in Autonomous Driving](https://arxiv.org/abs/2508.02919)
*Boyang Tian,Weisong Shi*

Main category: cs.RO

TL;DR: 提出了一种轻量级模块化框架CRI，用于实时风险评估和行为调整，显著提升了自动驾驶的安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有风险评估方法要么缺乏可解释性，要么未具体集成到自动驾驶系统中，或仅针对特定场景。

Method: CRI基于对象运动学和空间关系量化方向性风险，采用动态安全包络、混合概率-最大融合策略和自适应控制策略。

Result: 在Bench2Drive基准测试中，CRI显著减少了碰撞率（19%车辆碰撞/失败路线，20%碰撞/公里），提升了驾驶评分（17%）。

Conclusion: CRI在复杂高风险环境中显著提升了安全性，同时保持了模块化和低运行时开销。

Abstract: Ensuring safety in autonomous driving requires precise, real-time risk
assessment and adaptive behavior. Prior work on risk estimation either outputs
coarse, global scene-level metrics lacking interpretability, proposes
indicators without concrete integration into autonomous systems, or focuses
narrowly on specific driving scenarios. We introduce the Context-aware Risk
Index (CRI), a light-weight modular framework that quantifies directional risks
based on object kinematics and spatial relationships, dynamically adjusting
control commands in real time. CRI employs direction-aware spatial partitioning
within a dynamic safety envelope using Responsibility-Sensitive Safety (RSS)
principles, a hybrid probabilistic-max fusion strategy for risk aggregation,
and an adaptive control policy for real-time behavior modulation. We evaluate
CRI on the Bench2Drive benchmark comprising 220 safety-critical scenarios using
a state-of-the-art end-to-end model Transfuser++ on challenging routes. Our
collision-rate metrics show a 19\% reduction (p = 0.003) in vehicle collisions
per failed route, a 20\% reduction (p = 0.004) in collisions per kilometer, a
17\% increase (p = 0.016) in composed driving score, and a statistically
significant reduction in penalty scores (p = 0.013) with very low overhead (3.6
ms per decision cycle). These results demonstrate that CRI substantially
improves safety and robustness in complex, risk-intensive environments while
maintaining modularity and low runtime overhead.

</details>


### [57] [Model-agnostic Meta-learning for Adaptive Gait Phase and Terrain Geometry Estimation with Wearable Soft Sensors](https://arxiv.org/abs/2508.02930)
*Zenan Zhu,Wenxi Chen,Pei-Chun Kao,Janelle Clark,Lily Behnke,Rebecca Kramer-Bottiglio,Holly Yanco,Yan Gu*

Main category: cs.RO

TL;DR: 提出一种基于MAML的框架，利用少量织物传感器同时准确估计步态和地形，适应性强且泛化能力高。


<details>
  <summary>Details</summary>
Motivation: 解决织物传感器因非线性特性和数据有限导致的步态和地形估计难题。

Method: 结合MAML与深度学习，学习通用模型初始化，快速适应新用户和地形。

Result: 在九名参与者的实验中，框架在步态、运动模式和坡度估计上优于基线方法。

Conclusion: 该框架高效适应新用户，同时保持高泛化能力，适用于实际部署。

Abstract: This letter presents a model-agnostic meta-learning (MAML) based framework
for simultaneous and accurate estimation of human gait phase and terrain
geometry using a small set of fabric-based wearable soft sensors, with
efficient adaptation to unseen subjects and strong generalization across
different subjects and terrains. Compared to rigid alternatives such as
inertial measurement units, fabric-based soft sensors improve comfort but
introduce nonlinearities due to hysteresis, placement error, and fabric
deformation. Moreover, inter-subject and inter-terrain variability, coupled
with limited calibration data in real-world deployments, further complicate
accurate estimation. To address these challenges, the proposed framework
integrates MAML into a deep learning architecture to learn a generalizable
model initialization that captures subject- and terrain-invariant structure.
This initialization enables efficient adaptation (i.e., adaptation with only a
small amount of calibration data and a few fine-tuning steps) to new users,
while maintaining strong generalization (i.e., high estimation accuracy across
subjects and terrains). Experiments on nine participants walking at various
speeds over five terrain conditions demonstrate that the proposed framework
outperforms baseline approaches in estimating gait phase, locomotion mode, and
incline angle, with superior accuracy, adaptation efficiency, and
generalization.

</details>


### [58] [AeroSafe: Mobile Indoor Air Purification using Aerosol Residence Time Analysis and Robotic Cough Emulator Testbed](https://arxiv.org/abs/2508.02947)
*M Tanjid Hasan Tonmoy,Rahath Malladi,Kaustubh Singh,Forsad Al Hossain,Rajesh Gupta,Andrés E. Tejada-Martínez,Tauhidur Rahman*

Main category: cs.RO

TL;DR: AeroSafe是一种通过机器人咳嗽模拟器和数字孪生技术提升室内空气净化系统效率的新方法，专注于解决便携式空气过滤器忽视的咳嗽气溶胶浓度问题。


<details>
  <summary>Details</summary>
Motivation: 室内空气质量对健康至关重要，尤其在空气传播疾病背景下，当前便携式空气过滤器未能有效处理咳嗽生成的气溶胶浓度。

Method: 采用机器人双代理物理模拟器（模拟咳嗽的可操纵人体模型和自主响应气溶胶的便携式空气净化器），结合物理分区模型和机器学习（LSTM网络与图卷积层）的数字孪生模型。

Result: 模型预测气溶胶浓度动态的平均停留时间误差在35秒内，实时干预策略优于静态空气过滤器放置。

Conclusion: AeroSafe系统在降低空气传播病原体风险方面具有潜力，展示了数字孪生技术在室内空气质量管理中的应用前景。

Abstract: Indoor air quality plays an essential role in the safety and well-being of
occupants, especially in the context of airborne diseases. This paper
introduces AeroSafe, a novel approach aimed at enhancing the efficacy of indoor
air purification systems through a robotic cough emulator testbed and a
digital-twins-based aerosol residence time analysis. Current portable air
filters often overlook the concentrations of respiratory aerosols generated by
coughs, posing a risk, particularly in high-exposure environments like
healthcare facilities and public spaces. To address this gap, we present a
robotic dual-agent physical emulator comprising a maneuverable mannequin
simulating cough events and a portable air purifier autonomously responding to
aerosols. The generated data from this emulator trains a digital twins model,
combining a physics-based compartment model with a machine learning approach,
using Long Short-Term Memory (LSTM) networks and graph convolution layers.
Experimental results demonstrate the model's ability to predict aerosol
concentration dynamics with a mean residence time prediction error within 35
seconds. The proposed system's real-time intervention strategies outperform
static air filter placement, showcasing its potential in mitigating airborne
pathogen risks.

</details>


### [59] [A novel autonomous microplastics surveying robot for beach environments](https://arxiv.org/abs/2508.02952)
*Hassan Iqbal,Kobiny Rex,Joseph Shirley,Carlos Baiz,Christian Claudel*

Main category: cs.RO

TL;DR: 本文介绍了一种新型机器人平台，用于自动检测和分析海滩上的微塑料，结合视觉和近红外光谱技术，实现了高精度的分类和定位。


<details>
  <summary>Details</summary>
Motivation: 微塑料已成为普遍的环境污染物，但其检测和浓度映射仍是主要挑战。

Method: 采用移动机械臂系统，结合摄像头和近红外光谱传感器，实时检测和分析微塑料。

Result: 实验表明，系统在操控精度和微塑料分类准确率上表现优异。

Conclusion: 该机器人平台为解决微塑料污染问题提供了高效的技术支持。

Abstract: Microplastics, defined as plastic particles smaller than 5 millimeters, have
become a pervasive environmental contaminant that accumulates on beaches due to
wind patterns and tidal forcing. Detecting microplastics and mapping their
concentration in the wild remains one of the primary challenges in addressing
this environmental issue. This paper introduces a novel robotic platform that
automatically detects and chemically analyzes microplastics on beach surfaces.
This mobile manipulator system scans areas for microplastics using a camera
mounted on the robotic arm's end effector. The system effectively segments
candidate microplastic particles on sand surfaces even in the presence of
organic matter such as leaves and clams. Once a candidate microplastic particle
is detected, the system steers a near-infrared (NIR) spectroscopic sensor onto
the particle using both NIR and visual feedback to chemically analyze it in
real-time. Through experiments in lab and beach environments, the system is
shown to achieve an excellent positional precision in manipulation control and
high microplastic classification accuracy.

</details>


### [60] [Optimal Trajectory Planning in a Vertically Undulating Snake Locomotion using Contact-implicit Optimization](https://arxiv.org/abs/2508.02953)
*Adarsh Salagame,Eric Sihite,Alireza Ramezani*

Main category: cs.RO

TL;DR: 本文提出了一种基于简化动力学模型的蛇形机器人运动控制方法，填补了现有研究的空白，并通过仿真和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究要么忽略蛇形机器人运动的复杂性，要么过于关注复杂交互（如挖掘运动），而缺乏基于简单刚性动力学的中间模型。本文旨在填补这一空白。

Method: 采用Moreau的微分包含数学方法建立简化动力学模型，并通过仿真和实验验证模型准确性。

Result: 模型能够有效解决蛇形机器人运动中的接触和控制分配问题，仿真和实验结果验证了其准确性。

Conclusion: 本文提出的简化动力学模型为蛇形机器人运动控制提供了新思路，实验验证了其可行性。

Abstract: Contact-rich problems, such as snake robot locomotion, offer unexplored yet
rich opportunities for optimization-based trajectory and acyclic contact
planning. So far, a substantial body of control research has focused on
emulating snake locomotion and replicating its distinctive movement patterns
using shape functions that either ignore the complexity of interactions or
focus on complex interactions with matter (e.g., burrowing movements). However,
models and control frameworks that lie in between these two paradigms and are
based on simple, fundamental rigid body dynamics, which alleviate the
challenging contact and control allocation problems in snake locomotion, remain
absent. This work makes meaningful contributions, substantiated by simulations
and experiments, in the following directions: 1) introducing a reduced-order
model based on Moreau's stepping-forward approach from differential inclusion
mathematics, 2) verifying model accuracy, 3) experimental validation.

</details>


### [61] [Robot builds a robot's brain: AI generated drone command and control station hosted in the sky](https://arxiv.org/abs/2508.02962)
*Peter Burke*

Main category: cs.RO

TL;DR: AI生成无人机控制系统，无需人工编码，实现实时飞行控制和任务规划，性能优于人工开发，但存在模型限制。


<details>
  <summary>Details</summary>
Motivation: 探索AI在机器人控制系统开发中的潜力，减少人工编码需求，提高开发效率。

Method: 利用大型语言模型和混合推理模型生成无人机控制代码，部署于真实和模拟无人机，进行性能测试。

Result: AI生成的代码开发速度显著快于人工，功能完整，但受限于模型上下文窗口和推理深度。

Conclusion: AI驱动的机器人控制系统开发具有潜力，未来可能改变机器人工程范式。

Abstract: Advances in artificial intelligence (AI) including large language models
(LLMs) and hybrid reasoning models present an opportunity to reimagine how
autonomous robots such as drones are designed, developed, and validated. Here,
we demonstrate a fully AI-generated drone control system: with minimal human
input, an artificial intelligence (AI) model authored all the code for a
real-time, self-hosted drone command and control platform, which was deployed
and demonstrated on a real drone in flight as well as a simulated virtual drone
in the cloud. The system enables real-time mapping, flight telemetry,
autonomous mission planning and execution, and safety protocolsall orchestrated
through a web interface hosted directly on the drone itself. Not a single line
of code was written by a human. We quantitatively benchmark system performance,
code complexity, and development speed against prior, human-coded
architectures, finding that AI-generated code can deliver functionally complete
command-and-control stacks at orders-of-magnitude faster development cycles,
though with identifiable current limitations related to specific model context
window and reasoning depth. Our analysis uncovers the practical boundaries of
AI-driven robot control code generation at current model scales, as well as
emergent strengths and failure modes in AI-generated robotics code. This work
sets a precedent for the autonomous creation of robot control systems and, more
broadly, suggests a new paradigm for robotics engineeringone in which future
robots may be largely co-designed, developed, and verified by artificial
intelligence. In this initial work, a robot built a robot's brain.

</details>


### [62] [Physics-informed Neural Time Fields for Prehensile Object Manipulation](https://arxiv.org/abs/2508.02976)
*Hanwen Ren,Ruiqi Ni,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出了一种多模态物理信息神经网络（PINN），用于高效解决物体操纵任务，无需专家数据，且在复杂环境中快速规划轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有物体操纵方法效率低、依赖专家演示或试错学习，不适用于实际场景。

Method: 使用多模态物理信息神经网络（PINN），通过学习Eikonal方程并动态调整抓取策略。

Result: 在仿真和实际场景中验证，方法在训练效率、规划时间、轨迹长度和成功率上优于基线。

Conclusion: 该方法高效、通用性强，适用于复杂环境中的物体操纵任务。

Abstract: Object manipulation skills are necessary for robots operating in various
daily-life scenarios, ranging from warehouses to hospitals. They allow the
robots to manipulate the given object to their desired arrangement in the
cluttered environment. The existing approaches to solving object manipulations
are either inefficient sampling based techniques, require expert
demonstrations, or learn by trial and error, making them less ideal for
practical scenarios. In this paper, we propose a novel, multimodal
physics-informed neural network (PINN) for solving object manipulation tasks.
Our approach efficiently learns to solve the Eikonal equation without expert
data and finds object manipulation trajectories fast in complex, cluttered
environments. Our method is multimodal as it also reactively replans the
robot's grasps during manipulation to achieve the desired object poses. We
demonstrate our approach in both simulation and real-world scenarios and
compare it against state-of-the-art baseline methods. The results indicate that
our approach is effective across various objects, has efficient training
compared to previous learning-based methods, and demonstrates high performance
in planning time, trajectory length, and success rates. Our demonstration
videos can be found at https://youtu.be/FaQLkTV9knI.

</details>


### [63] [Multimodal Human-Intent Modeling for Contextual Robot-to-Human Handovers of Arbitrary Objects](https://arxiv.org/abs/2508.02982)
*Lucas Chen,Guna Avula,Hanwen Ren,Zixing Wang,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 论文提出了一种统一方法，通过结合人类语言和非语言指令选择目标物体，并基于人类显性和隐性偏好生成机器人抓取和柔顺的交接动作序列，以优化人机物体交接的自然性和流畅性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预选目标物体，未考虑人类显性和隐性偏好，限制了人机交互的自然性和流畅性。

Method: 提出一种统一框架，结合人类语言和非语言指令选择目标物体，并根据人类偏好生成机器人抓取和柔顺的交接动作序列。

Result: 通过真实实验和用户研究验证了方法的有效性，能够理解人类偏好并完成物体交接任务。

Conclusion: 该方法显著提升了人机物体交接的自然性和流畅性，适用于日常生活中的多种场景。

Abstract: Human-robot object handover is a crucial element for assistive robots that
aim to help people in their daily lives, including elderly care, hospitals, and
factory floors. The existing approaches to solving these tasks rely on
pre-selected target objects and do not contextualize human implicit and
explicit preferences for handover, limiting natural and smooth interaction
between humans and robots. These preferences can be related to the target
object selection from the cluttered environment and to the way the robot should
grasp the selected object to facilitate desirable human grasping during
handovers. Therefore, this paper presents a unified approach that selects
target distant objects using human verbal and non-verbal commands and performs
the handover operation by contextualizing human implicit and explicit
preferences to generate robot grasps and compliant handover motion sequences.
We evaluate our integrated framework and its components through real-world
experiments and user studies with arbitrary daily-life objects. The results of
these evaluations demonstrate the effectiveness of our proposed pipeline in
handling object handover tasks by understanding human preferences. Our
demonstration videos can be found at https://youtu.be/6z27B2INl-s.

</details>


### [64] [Estimation of Aerodynamics Forces in Dynamic Morphing Wing Flight](https://arxiv.org/abs/2508.02984)
*Bibek Gupta,Mintae Kim,Albert Park,Eric Sihite,Koushil Sreenath,Alireza Ramezani*

Main category: cs.RO

TL;DR: 论文研究了两种方法（基于物理的观测器和神经网络回归模型）用于估计仿生扑翼机器人Aerobat的气动力，目标是为闭环飞行控制提供支持。两种方法在实验中表现一致。


<details>
  <summary>Details</summary>
Motivation: 精确估计气动力对扑翼机器人的控制、建模和设计至关重要，尤其是具有动态变形能力的仿生机器人。

Method: 1. 基于哈密顿力学的物理观测器，利用共轭动量推断气动力；2. 神经网络回归模型（MLP），从运动学和环境参数映射到气动力。

Result: 两种方法在三个力分量（Fx, Fy, Fz）上表现一致，验证了其有效性。

Conclusion: 两种方法均适用于气动力估计，为扑翼机器人的闭环控制提供了可靠工具。

Abstract: Accurate estimation of aerodynamic forces is essential for advancing the
control, modeling, and design of flapping-wing aerial robots with dynamic
morphing capabilities. In this paper, we investigate two distinct methodologies
for force estimation on Aerobat, a bio-inspired flapping-wing platform designed
to emulate the inertial and aerodynamic behaviors observed in bat flight. Our
goal is to quantify aerodynamic force contributions during tethered flight, a
crucial step toward closed-loop flight control. The first method is a
physics-based observer derived from Hamiltonian mechanics that leverages the
concept of conjugate momentum to infer external aerodynamic forces acting on
the robot. This observer builds on the system's reduced-order dynamic model and
utilizes real-time sensor data to estimate forces without requiring training
data. The second method employs a neural network-based regression model,
specifically a multi-layer perceptron (MLP), to learn a mapping from joint
kinematics, flapping frequency, and environmental parameters to aerodynamic
force outputs. We evaluate both estimators using a 6-axis load cell in a
high-frequency data acquisition setup that enables fine-grained force
measurements during periodic wingbeats. The conjugate momentum observer and the
regression model demonstrate strong agreement across three force components
(Fx, Fy, Fz).

</details>


### [65] [GACL: Grounded Adaptive Curriculum Learning with Active Task and Performance Monitoring](https://arxiv.org/abs/2508.02988)
*Linji Wang,Zifan Xu,Peter Stone,Xuesu Xiao*

Main category: cs.RO

TL;DR: 提出了一种名为Grounded Adaptive Curriculum Learning（GACL）的框架，用于机器人课程学习，通过任务表示、自适应课程生成和目标领域相关性保持，显著提升了导航和运动任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前机器人课程学习依赖人工设计，效率低且可能不理想；自动化课程学习在简单领域有效，但机器人任务复杂且目标领域信息有限，需要新方法。

Method: GACL框架包含三个创新点：1）复杂任务表示；2）自适应课程生成机制；3）通过交替采样保持目标领域相关性。

Result: 在受限环境中的轮式导航和3D狭窄空间中的四足运动任务中，GACL分别比现有方法提高了6.8%和6.1%的成功率。

Conclusion: GACL为机器人课程学习提供了一种高效且自适应的解决方案，显著提升了复杂任务的性能。

Abstract: Curriculum learning has emerged as a promising approach for training complex
robotics tasks, yet current applications predominantly rely on manually
designed curricula, which demand significant engineering effort and can suffer
from subjective and suboptimal human design choices. While automated curriculum
learning has shown success in simple domains like grid worlds and games where
task distributions can be easily specified, robotics tasks present unique
challenges: they require handling complex task spaces while maintaining
relevance to target domain distributions that are only partially known through
limited samples. To this end, we propose Grounded Adaptive Curriculum Learning,
a framework specifically designed for robotics curriculum learning with three
key innovations: (1) a task representation that consistently handles complex
robot task design, (2) an active performance tracking mechanism that allows
adaptive curriculum generation appropriate for the robot's current
capabilities, and (3) a grounding approach that maintains target domain
relevance through alternating sampling between reference and synthetic tasks.
We validate GACL on wheeled navigation in constrained environments and
quadruped locomotion in challenging 3D confined spaces, achieving 6.8% and 6.1%
higher success rates, respectively, than state-of-the-art methods in each
domain.

</details>


### [66] [Thruster-Enhanced Locomotion: A Decoupled Model Predictive Control with Learned Contact Residuals](https://arxiv.org/abs/2508.03003)
*Chenghao Wang,Alireza Ramezani*

Main category: cs.RO

TL;DR: 论文提出了一种解耦控制架构，结合Raibert型控制器和MPC，通过CRD学习腿部-地面碰撞动力学，解决了轻量级执行器扭矩控制带宽不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统统一MPC框架因执行器扭矩控制带宽不足难以实现姿态操纵与推力矢量化的统一控制，需寻找替代方案。

Method: 采用解耦控制架构：Raibert型控制器负责腿部运动，MPC调节推力器，并通过CRD学习腿部-地面碰撞动力学。

Result: 仿真和硬件实验表明，结合CRD的解耦控制器在推恢复和猫式步态中表现更稳定。

Conclusion: 解耦控制架构结合CRD能有效解决轻量级执行器的控制问题，提升机器人稳定性。

Abstract: Husky Carbon, a robot developed by Northeastern University, serves as a
research platform to explore unification of posture manipulation and thrust
vectoring. Unlike conventional quadrupeds, its joint actuators and thrusters
enable enhanced control authority, facilitating thruster-assisted narrow-path
walking. While a unified Model Predictive Control (MPC) framework optimizing
both ground reaction forces and thruster forces could theoretically address
this control problem, its feasibility is limited by the low torque-control
bandwidth of the system's lightweight actuators. To overcome this challenge, we
propose a decoupled control architecture: a Raibert-type controller governs
legged locomotion using position-based control, while an MPC regulates the
thrusters augmented by learned Contact Residual Dynamics (CRD) to account for
leg-ground impacts. This separation bypasses the torque-control rate bottleneck
while retaining the thruster MPC to explicitly account for leg-ground impact
dynamics through learned residuals. We validate this approach through both
simulation and hardware experiments, showing that the decoupled control
architecture with CRD performs more stable behavior in terms of push recovery
and cat-like walking gait compared to the decoupled controller without CRD.

</details>


### [67] [LiGen: GAN-Augmented Spectral Fingerprinting for Indoor Positioning](https://arxiv.org/abs/2508.03024)
*Jie Lin,Hsun-Yu Lee,Ho-Ming Li,Fang-Jing Wu*

Main category: cs.RO

TL;DR: LiGen是一种新型室内定位系统，利用环境光的光谱强度模式作为指纹，提供比Wi-Fi更稳定且无需基础设施的替代方案。通过GAN数据增强和MLP模型，实现了亚米级精度。


<details>
  <summary>Details</summary>
Motivation: 现有Wi-Fi定位系统易受环境影响，需要更稳定且不依赖基础设施的解决方案。

Method: 利用环境光的光谱强度模式作为指纹，设计基于GAN的数据增强框架（PointGAN和FreeGAN），并使用MLP模型进行定位。

Result: LiGen在亚米级精度上优于Wi-Fi基线50%以上，且在复杂环境中表现稳健。

Conclusion: LiGen是首个结合光谱指纹和GAN数据增强的室内定位系统，具有高精度和强鲁棒性。

Abstract: Accurate and robust indoor localization is critical for smart building
applications, yet existing Wi-Fi-based systems are often vulnerable to
environmental conditions. This work presents a novel indoor localization
system, called LiGen, that leverages the spectral intensity patterns of ambient
light as fingerprints, offering a more stable and infrastructure-free
alternative to radio signals. To address the limited spectral data, we design a
data augmentation framework based on generative adversarial networks (GANs),
featuring two variants: PointGAN, which generates fingerprints conditioned on
coordinates, and FreeGAN, which uses a weak localization model to label
unconditioned samples. Our positioning model, leveraging a Multi-Layer
Perceptron (MLP) architecture to train on synthesized data, achieves
submeter-level accuracy, outperforming Wi-Fi-based baselines by over 50\%.
LiGen also demonstrates strong robustness in cluttered environments. To the
best of our knowledge, this is the first system to combine spectral
fingerprints with GAN-based data augmentation for indoor localization.

</details>


### [68] [CogniPlan: Uncertainty-Guided Path Planning with Conditional Generative Layout Prediction](https://arxiv.org/abs/2508.03027)
*Yizhuo Wang,Haodong He,Jingsong Liang,Yuhong Cao,Ritabrata Chakraborty,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: CogniPlan是一种新型路径规划框架，利用生成模型预测多种可能的布局，结合图注意力路径规划，显著提升探索和导航性能。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中，移动机器人的路径规划面临挑战，需动态感知环境并估计信息增益以指导规划。

Method: 提出CogniPlan框架，利用条件生成模型预测布局，结合图注意力路径规划，实现高效推理。

Result: 在多个数据集和实际场景中，CogniPlan表现优于现有先进规划器，并展示了实际应用潜力。

Conclusion: CogniPlan通过生成模型与图表示的结合，显著提升了路径规划的性能和适应性。

Abstract: Path planning in unknown environments is a crucial yet inherently challenging
capability for mobile robots, which primarily encompasses two coupled tasks:
autonomous exploration and point-goal navigation. In both cases, the robot must
perceive the environment, update its belief, and accurately estimate potential
information gain on-the-fly to guide planning. In this work, we propose
CogniPlan, a novel path planning framework that leverages multiple plausible
layouts predicted by a COnditional GeNerative Inpainting model, mirroring how
humans rely on cognitive maps during navigation. These predictions, based on
the partially observed map and a set of layout conditioning vectors, enable our
planner to reason effectively under uncertainty. We demonstrate strong synergy
between generative image-based layout prediction and graph-attention-based path
planning, allowing CogniPlan to combine the scalability of graph
representations with the fidelity and predictiveness of occupancy maps,
yielding notable performance gains in both exploration and navigation. We
extensively evaluate CogniPlan on two datasets (hundreds of maps and realistic
floor plans), consistently outperforming state-of-the-art planners. We further
deploy it in a high-fidelity simulator and on hardware, showcasing its
high-quality path planning and real-world applicability.

</details>


### [69] [Aerobatic maneuvers in insect-scale flapping-wing aerial robots via deep-learned robust tube model predictive control](https://arxiv.org/abs/2508.03043)
*Yi-Hsuan Hsiao,Andrea Tagliabue,Owen Matteson,Suhan Kim,Tong Zhao,Jonathan P. How,YuFeng Chen*

Main category: cs.RO

TL;DR: 论文提出了一种深度学习的鲁棒管模型预测控制器，使750毫克扑翼机器人实现了类似昆虫的高敏捷飞行。


<details>
  <summary>Details</summary>
Motivation: 昆虫飞行的高敏捷性与现有扑翼机器人的性能差距，激发了研究如何通过控制器设计提升机器人飞行能力。

Method: 设计了深度学习的鲁棒管模型预测控制器，并采用模仿学习方法训练神经网络，以实现高反馈率。

Result: 机器人实现了197厘米/秒的侧向速度和11.7米/秒²的加速度，并在强风和力映射误差下完成高难度动作。

Conclusion: 该研究标志着昆虫级飞行敏捷性的里程碑，为未来传感和计算自主性研究提供了启发。

Abstract: Aerial insects exhibit highly agile maneuvers such as sharp braking,
saccades, and body flips under disturbance. In contrast, insect-scale aerial
robots are limited to tracking non-aggressive trajectories with small body
acceleration. This performance gap is contributed by a combination of low robot
inertia, fast dynamics, uncertainty in flapping-wing aerodynamics, and high
susceptibility to environmental disturbance. Executing highly dynamic maneuvers
requires the generation of aggressive flight trajectories that push against the
hardware limit and a high-rate feedback controller that accounts for model and
environmental uncertainty. Here, through designing a deep-learned robust tube
model predictive controller, we showcase insect-like flight agility and
robustness in a 750-millgram flapping-wing robot. Our model predictive
controller can track aggressive flight trajectories under disturbance. To
achieve a high feedback rate in a compute-constrained real-time system, we
design imitation learning methods to train a two-layer, fully connected neural
network, which resembles insect flight control architecture consisting of
central nervous system and motor neurons. Our robot demonstrates insect-like
saccade movements with lateral speed and acceleration of 197 centimeters per
second and 11.7 meters per second square, representing 447$\%$ and 255$\%$
improvement over prior results. The robot can also perform saccade maneuvers
under 160 centimeters per second wind disturbance and large command-to-force
mapping errors. Furthermore, it performs 10 consecutive body flips in 11
seconds - the most challenging maneuver among sub-gram flyers. These results
represent a milestone in achieving insect-scale flight agility and inspire
future investigations on sensing and compute autonomy.

</details>


### [70] [SkeNa: Learning to Navigate Unseen Environments Based on Abstract Hand-Drawn Maps](https://arxiv.org/abs/2508.03053)
*Haojun Xu,Jiaqi Xiang,Wu Wei,Jinyu Chen,Linqing Zhong,Linjiang Huang,Hongyu Yang,Si Liu*

Main category: cs.RO

TL;DR: 论文提出了一种基于手绘草图导航的任务SkeNa，并构建了大规模数据集SoR，开发了自动化草图生成流程和导航框架SkeNavigator，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 受人类通过环境布局绘制路线图的启发，研究如何在未见环境中仅凭手绘草图导航。

Method: 提出了SkeNavigator框架，通过Ray-based Map Descriptor和Dual-Map Aligned Goal Predictor对齐视觉观测与草图，预测目标位置。

Result: SkeNavigator在高度抽象的验证集上相对提升了105%的SPL，显著优于现有方法。

Conclusion: SkeNa任务和SoR数据集为未来研究提供了基础，SkeNavigator展示了高效草图导航的潜力。

Abstract: A typical human strategy for giving navigation guidance is to sketch route
maps based on the environmental layout. Inspired by this, we introduce Sketch
map-based visual Navigation (SkeNa), an embodied navigation task in which an
agent must reach a goal in an unseen environment using only a hand-drawn sketch
map as guidance. To support research for SkeNa, we present a large-scale
dataset named SoR, comprising 54k trajectory and sketch map pairs across 71
indoor scenes. In SoR, we introduce two navigation validation sets with varying
levels of abstraction in hand-drawn sketches, categorized based on their
preservation of spatial scales in the environment, to facilitate future
research. To construct SoR, we develop an automated sketch-generation pipeline
that efficiently converts floor plans into hand-drawn representations. To solve
SkeNa, we propose SkeNavigator, a navigation framework that aligns visual
observations with hand-drawn maps to estimate navigation targets. It employs a
Ray-based Map Descriptor (RMD) to enhance sketch map valid feature
representation using equidistant sampling points and boundary distances. To
improve alignment with visual observations, a Dual-Map Aligned Goal Predictor
(DAGP) leverages the correspondence between sketch map features and on-site
constructed exploration map features to predict goal position and guide
navigation. SkeNavigator outperforms prior floor plan navigation methods by a
large margin, improving SPL on the high-abstract validation set by 105%
relatively. Our code and dataset will be released.

</details>


### [71] [Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching](https://arxiv.org/abs/2508.03068)
*Sirui Chen,Yufei Ye,Zi-Ang Cao,Jennifer Lew,Pei Xu,C. Karen Liu*

Main category: cs.RO

TL;DR: HEAD框架通过模块化方法，从人类运动和视觉感知数据中学习人形机器人的导航、运动和抓取技能。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在复杂环境中导航和操作的挑战，通过模块化设计提高学习效率和可扩展性。

Method: 采用分层策略：高层规划器指挥手和眼的目标位置，低层策略控制全身动作，分别从运动捕捉数据和Aria眼镜数据中学习。

Result: 在仿真和现实世界中验证了人形机器人在复杂环境中的导航和抓取能力。

Conclusion: 模块化方法有效解耦视觉感知与物理动作，提升了学习效率和场景适应性。

Abstract: We propose Hand-Eye Autonomous Delivery (HEAD), a framework that learns
navigation, locomotion, and reaching skills for humanoids, directly from human
motion and vision perception data. We take a modular approach where the
high-level planner commands the target position and orientation of the hands
and eyes of the humanoid, delivered by the low-level policy that controls the
whole-body movements. Specifically, the low-level whole-body controller learns
to track the three points (eyes, left hand, and right hand) from existing
large-scale human motion capture data while high-level policy learns from human
data collected by Aria glasses. Our modular approach decouples the ego-centric
vision perception from physical actions, promoting efficient learning and
scalability to novel scenes. We evaluate our method both in simulation and in
the real-world, demonstrating humanoid's capabilities to navigate and reach in
complex environments designed for humans.

</details>


### [72] [Optimizing Bipedal Locomotion for The 100m Dash With Comparison to Human Running](https://arxiv.org/abs/2508.03070)
*Devin Crowley,Jeremy Dao,Helei Duan,Kevin Green,Jonathan Hurst,Alan Fern*

Main category: cs.RO

TL;DR: 本文研究了双足机器人Cassie的跑步步态优化，比较了其与人类跑步力学的相似性，并展示了在硬件上实现的高速跑步控制器。


<details>
  <summary>Details</summary>
Motivation: 探索双足机器人Cassie的跑步步态优化，以实现高速跑步，并与人类跑步力学进行对比。

Method: 提出优化步态效率的方法，并与人类生物力学研究进行对比，最后将优化步态集成到控制器中。

Result: 发现Cassie与人类跑步步态在关键特性上高度相似，并在硬件上实现了100米短跑的世界纪录。

Conclusion: 优化后的跑步步态在双足机器人上表现出高效性，且与人类跑步力学相似，成功应用于实际任务。

Abstract: In this paper, we explore the space of running gaits for the bipedal robot
Cassie. Our first contribution is to present an approach for optimizing gait
efficiency across a spectrum of speeds with the aim of enabling extremely
high-speed running on hardware. This raises the question of how the resulting
gaits compare to human running mechanics, which are known to be highly
efficient in comparison to quadrupeds. Our second contribution is to conduct
this comparison based on established human biomechanical studies. We find that
despite morphological differences between Cassie and humans, key properties of
the gaits are highly similar across a wide range of speeds. Finally, our third
contribution is to integrate the optimized running gaits into a full controller
that satisfies the rules of the real-world task of the 100m dash, including
starting and stopping from a standing position. We demonstrate this controller
on hardware to establish the Guinness World Record for Fastest 100m by a
Bipedal Robot.

</details>


### [73] [Point2Act: Efficient 3D Distillation of Multimodal LLMs for Zero-Shot Context-Aware Grasping](https://arxiv.org/abs/2508.03099)
*Sang Min Kim,Hyeongjun Heo,Junho Kim,Yonghyeon Lee,Young Min Kim*

Main category: cs.RO

TL;DR: Point2Act利用多模态大语言模型（MLLMs）直接检索与任务相关的3D动作点，通过3D相关性场高效定位任务特定的动作位置。


<details>
  <summary>Details</summary>
Motivation: 现有方法在2D图像中提取语义信息时难以精确定位3D动作点，Point2Act旨在解决这一问题，实现零样本任务的自然语言描述执行。

Method: 提出3D相关性场，绕过高维特征，直接利用轻量级2D点级指导，并通过多视角聚合补偿几何模糊性和语义不确定性。

Result: 方法能在20秒内生成空间接地的响应，支持实际操纵任务。

Conclusion: Point2Act通过高效定位3D动作点，为通用机器人执行自然语言描述任务提供了实用解决方案。

Abstract: We propose Point2Act, which directly retrieves the 3D action point relevant
for a contextually described task, leveraging Multimodal Large Language Models
(MLLMs). Foundation models opened the possibility for generalist robots that
can perform a zero-shot task following natural language descriptions within an
unseen environment. While the semantics obtained from large-scale image and
language datasets provide contextual understanding in 2D images, the rich yet
nuanced features deduce blurry 2D regions and struggle to find precise 3D
locations for actions. Our proposed 3D relevancy fields bypass the
high-dimensional features and instead efficiently imbue lightweight 2D
point-level guidance tailored to the task-specific action. The multi-view
aggregation effectively compensates for misalignments due to geometric
ambiguities, such as occlusion, or semantic uncertainties inherent in the
language descriptions. The output region is highly localized, reasoning
fine-grained 3D spatial context that can directly transfer to an explicit
position for physical action at the on-the-fly reconstruction of the scene. Our
full-stack pipeline, which includes capturing, MLLM querying, 3D
reconstruction, and grasp pose extraction, generates spatially grounded
responses in under 20 seconds, facilitating practical manipulation tasks.
Project page: https://sangminkim-99.github.io/point2act/

</details>


### [74] [Safety-Aware Imitation Learning via MPC-Guided Disturbance Injection](https://arxiv.org/abs/2508.03129)
*Le Qiu,Yusuf Umut Ciftci,Somil Bansal*

Main category: cs.RO

TL;DR: MPC-SafeGIL通过在设计阶段注入对抗性扰动增强模仿学习的安全性，利用MPC近似最坏情况扰动，适用于高维和黑盒系统。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在安全关键应用中可能因策略错误导致安全问题，需提升其安全性。

Method: 在专家演示中注入对抗性扰动，利用采样MPC近似最坏情况扰动，直接整合安全考量到数据收集。

Result: 在四足机器人运动和视觉导航仿真及四旋翼无人机实验中验证了安全性和任务性能的提升。

Conclusion: MPC-SafeGIL通过扰动增强数据多样性，有效提升了模仿学习的安全性和鲁棒性。

Abstract: Imitation Learning has provided a promising approach to learning complex
robot behaviors from expert demonstrations. However, learned policies can make
errors that lead to safety violations, which limits their deployment in
safety-critical applications. We propose MPC-SafeGIL, a design-time approach
that enhances the safety of imitation learning by injecting adversarial
disturbances during expert demonstrations. This exposes the expert to a broader
range of safety-critical scenarios and allows the imitation policy to learn
robust recovery behaviors. Our method uses sampling-based Model Predictive
Control (MPC) to approximate worst-case disturbances, making it scalable to
high-dimensional and black-box dynamical systems. In contrast to prior work
that relies on analytical models or interactive experts, MPC-SafeGIL integrates
safety considerations directly into data collection. We validate our approach
through extensive simulations including quadruped locomotion and visuomotor
navigation and real-world experiments on a quadrotor, demonstrating
improvements in both safety and task performance. See our website here:
https://leqiu2003.github.io/MPCSafeGIL/

</details>


### [75] [Language as Cost: Proactive Hazard Mapping using VLM for Robot Navigation](https://arxiv.org/abs/2508.03138)
*Mintaek Oh,Chan Kim,Seung-Woo Seo,Seong-Woo Kim*

Main category: cs.RO

TL;DR: 提出了一种基于视觉语言模型（VLM）的零样本语言成本映射框架，用于机器人主动预测和规避动态风险。


<details>
  <summary>Details</summary>
Motivation: 传统导航系统依赖静态地图，难以应对动态风险（如突然出现的行人），导致反应式而非主动式避障。

Method: 利用VLM解析视觉场景，评估动态风险，并预分配风险感知导航成本，结合几何障碍地图实现主动规划。

Result: 实验表明，该方法在模拟和动态环境中显著提高了导航成功率并减少了危险遭遇。

Conclusion: 语言成本映射框架为机器人主动避障提供了新思路，优于传统反应式规划器。

Abstract: Robots operating in human-centric or hazardous environments must proactively
anticipate and mitigate dangers beyond basic obstacle detection. Traditional
navigation systems often depend on static maps, which struggle to account for
dynamic risks, such as a person emerging from a suddenly opening door. As a
result, these systems tend to be reactive rather than anticipatory when
handling dynamic hazards. Recent advancements in pre-trained large language
models and vision-language models (VLMs) create new opportunities for proactive
hazard avoidance. In this work, we propose a zero-shot language-as-cost mapping
framework that leverages VLMs to interpret visual scenes, assess potential
dynamic risks, and assign risk-aware navigation costs preemptively, enabling
robots to anticipate hazards before they materialize. By integrating this
language-based cost map with a geometric obstacle map, the robot not only
identifies existing obstacles but also anticipates and proactively plans around
potential hazards arising from environmental dynamics. Experiments in simulated
and diverse dynamic environments demonstrate that the proposed method
significantly improves navigation success rates and reduces hazard encounters,
compared to reactive baseline planners. Code and supplementary materials are
available at https://github.com/Taekmino/LaC.

</details>


### [76] [CookBench: A Long-Horizon Embodied Planning Benchmark for Complex Cooking Scenarios](https://arxiv.org/abs/2508.03232)
*Muzhen Cai,Xiubo Chen,Yining An,Jiaxin Zhang,Xuesong Wang,Wang Xu,Weinan Zhang,Ting Liu*

Main category: cs.RO

TL;DR: CookBench是一个专注于复杂烹饪场景中长期规划任务的基准测试，通过高保真模拟环境和精细动作设计，挑战AI在意图识别和物理交互中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有体现规划基准多关注短期任务和粗粒度动作，无法满足复杂物理世界中长期任务的需求。

Method: 利用Unity引擎构建高保真模拟环境，设计两阶段任务（意图识别和体现交互），并提供统一API工具集。

Result: 揭示了当前大型语言模型和视觉语言模型在复杂长期任务中的主要缺陷。

Conclusion: CookBench将为未来研究提供开放基准，促进长期规划任务的发展。

Abstract: Embodied Planning is dedicated to the goal of creating agents capable of
executing long-horizon tasks in complex physical worlds. However, existing
embodied planning benchmarks frequently feature short-horizon tasks and
coarse-grained action primitives. To address this challenge, we introduce
CookBench, a benchmark for long-horizon planning in complex cooking scenarios.
By leveraging a high-fidelity simulation environment built upon the powerful
Unity game engine, we define frontier AI challenges in a complex, realistic
environment. The core task in CookBench is designed as a two-stage process.
First, in Intention Recognition, an agent needs to accurately parse a user's
complex intent. Second, in Embodied Interaction, the agent should execute the
identified cooking goal through a long-horizon, fine-grained sequence of
physical actions. Unlike existing embodied planning benchmarks, we refine the
action granularity to a spatial level that considers crucial operational
information while abstracting away low-level robotic control. Besides, We
provide a comprehensive toolset that encapsulates the simulator. Its unified
API supports both macro-level operations, such as placing orders and purchasing
ingredients, and a rich set of fine-grained embodied actions for physical
interaction, enabling researchers to focus on high-level planning and
decision-making. Furthermore, we present an in-depth analysis of
state-of-the-art, closed-source Large Language Model and Vision-Language Model,
revealing their major shortcomings and challenges posed by complex,
long-horizon tasks. The full benchmark will be open-sourced to facilitate
future research.

</details>


### [77] [Force-Compliance MPC and Robot-User CBFs for Interactive Navigation and User-Robot Safety in Hexapod Guide Robots](https://arxiv.org/abs/2508.03246)
*Zehua Fan,Feng Gao,Zhijun Chen,Yunpeng Yin,Limin Yang,Qingxing Xi,En Yang,Xuefeng Luo*

Main category: cs.RO

TL;DR: 提出了一种用于六足导盲机器人的力-顺应模型预测控制（FC-MPC）和机器人-用户控制屏障函数（CBFs），实现实时双向交互和安全导航。


<details>
  <summary>Details</summary>
Motivation: 为视觉障碍者在复杂环境中提供实时双向交互和安全保障的导盲机器人需求。

Method: 采用FC-MPC估计用户施加的力和力矩，通过RLS方法调整机器人运动；使用Robot-User CBFs处理静态和动态障碍；采用Eight-Way Connected DBSCAN聚类障碍物，MBE建模和卡尔曼滤波预测轨迹。

Result: 系统在HexGuide机器人上实现力顺应、自主导航和避障的无缝集成，实验证明其能适应用户力指令并保障安全。

Conclusion: FC-MPC和Robot-User CBFs有效解决了复杂环境中的导盲机器人交互和安全问题。

Abstract: Guiding the visually impaired in complex environments requires real-time
two-way interaction and safety assurance. We propose a Force-Compliance Model
Predictive Control (FC-MPC) and Robot-User Control Barrier Functions (CBFs) for
force-compliant navigation and obstacle avoidance in Hexapod guide robots.
FC-MPC enables two-way interaction by estimating user-applied forces and
moments using the robot's dynamic model and the recursive least squares (RLS)
method, and then adjusting the robot's movements accordingly, while Robot-User
CBFs ensure the safety of both the user and the robot by handling static and
dynamic obstacles, and employ weighted slack variables to overcome feasibility
issues in complex dynamic environments. We also adopt an Eight-Way Connected
DBSCAN method for obstacle clustering, reducing computational complexity from
O(n2) to approximately O(n), enabling real-time local perception on
resource-limited on-board robot computers. Obstacles are modeled using Minimum
Bounding Ellipses (MBEs), and their trajectories are predicted through Kalman
filtering. Implemented on the HexGuide robot, the system seamlessly integrates
force compliance, autonomous navigation, and obstacle avoidance. Experimental
results demonstrate the system's ability to adapt to user force commands while
guaranteeing user and robot safety simultaneously during navigation in complex
environments.

</details>


### [78] [UniFucGrasp: Human-Hand-Inspired Unified Functional Grasp Annotation Strategy and Dataset for Diverse Dexterous Hands](https://arxiv.org/abs/2508.03339)
*Haoran Lin,Wenrui Chen,Xianchi Chen,Fan Yang,Qiang Diao,Wenxin Xie,Sijie Wu,Kailun Yang,Maojun Li,Yaonan Wang*

Main category: cs.RO

TL;DR: 论文提出UniFucGrasp，一种通用的功能性抓取标注策略和数据集，解决了现有抓取数据集忽略功能性需求的问题。


<details>
  <summary>Details</summary>
Motivation: 现有抓取数据集过于关注稳定性，而忽略了功能性抓取（如开瓶盖或握杯柄），且依赖昂贵的高自由度Shadow Hands。

Method: 基于仿生学，将人类自然动作映射到多种手型结构，并利用几何力闭合确保功能性和稳定性。

Result: 实验表明，该方法提高了功能性操作的准确性和抓取稳定性，并能高效泛化到多种机器人手。

Conclusion: UniFucGrasp解决了功能性抓取的标注成本和泛化挑战，为多手功能性抓取提供了首个数据集和合成模型。

Abstract: Dexterous grasp datasets are vital for embodied intelligence, but mostly
emphasize grasp stability, ignoring functional grasps needed for tasks like
opening bottle caps or holding cup handles. Most rely on bulky, costly, and
hard-to-control high-DOF Shadow Hands. Inspired by the human hand's
underactuated mechanism, we establish UniFucGrasp, a universal functional grasp
annotation strategy and dataset for multiple dexterous hand types. Based on
biomimicry, it maps natural human motions to diverse hand structures and uses
geometry-based force closure to ensure functional, stable, human-like grasps.
This method supports low-cost, efficient collection of diverse, high-quality
functional grasps. Finally, we establish the first multi-hand functional grasp
dataset and provide a synthesis model to validate its effectiveness.
Experiments on the UFG dataset, IsaacSim, and complex robotic tasks show that
our method improves functional manipulation accuracy and grasp stability,
enables efficient generalization across diverse robotic hands, and overcomes
annotation cost and generalization challenges in dexterous grasping. The
project page is at https://haochen611.github.io/UFG.

</details>


### [79] [Opti-Acoustic Scene Reconstruction in Highly Turbid Underwater Environments](https://arxiv.org/abs/2508.03408)
*Ivana Collado-Gonzalez,John McConnell,Paul Szenher,Brendan Englot*

Main category: cs.RO

TL;DR: 提出了一种实时光学-声学场景重建方法，适用于浑浊水域，结合相机和声纳数据，避免了传统视觉方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 浑浊水域中单目视觉方法不可靠且缺乏深度信息，声纳虽适应浑浊环境但分辨率低且存在高程模糊。

Method: 通过识别图像中的感兴趣区域并与声纳数据匹配，利用声纳的距离信息和相机的高程数据进行重建。

Result: 实验验证了该方法在不同浑浊度下的有效性，并在码头环境中进行了实地测试。

Conclusion: 该方法在浑浊水域中表现优异，代码已开源以促进复现和社区参与。

Abstract: Scene reconstruction is an essential capability for underwater robots
navigating in close proximity to structures. Monocular vision-based
reconstruction methods are unreliable in turbid waters and lack depth scale
information. Sonars are robust to turbid water and non-uniform lighting
conditions, however, they have low resolution and elevation ambiguity. This
work proposes a real-time opti-acoustic scene reconstruction method that is
specially optimized to work in turbid water. Our strategy avoids having to
identify point features in visual data and instead identifies regions of
interest in the data. We then match relevant regions in the image to
corresponding sonar data. A reconstruction is obtained by leveraging range data
from the sonar and elevation data from the camera image. Experimental
comparisons against other vision-based and sonar-based approaches at varying
turbidity levels, and field tests conducted in marina environments, validate
the effectiveness of the proposed approach. We have made our code open-source
to facilitate reproducibility and encourage community engagement.

</details>


### [80] [Residual Neural Terminal Constraint for MPC-based Collision Avoidance in Dynamic Environments](https://arxiv.org/abs/2508.03428)
*Bojan Derajić,Mohamed-Khalil Bouzidi,Sebastian Bernhard,Wolfgang Hönig*

Main category: cs.RO

TL;DR: 提出了一种混合MPC局部规划器，通过学习近似时变安全集作为MPC终端约束，结合HJ可达性分析和神经网络残差，实现实时安全规划。


<details>
  <summary>Details</summary>
Motivation: 解决HJ可达性分析在实时规划中的计算不可行问题，同时保证安全性。

Method: 利用HJ值函数与符号距离函数的差异，通过神经网络建模残差，结合超网络提升实时性和泛化能力。

Result: 在仿真和硬件实验中，相比三种先进方法，成功率提高30%，计算成本相近且路径质量高。

Conclusion: 该方法在实时性和安全性上表现优异，适用于复杂环境下的路径规划。

Abstract: In this paper, we propose a hybrid MPC local planner that uses a
learning-based approximation of a time-varying safe set, derived from local
observations and applied as the MPC terminal constraint. This set can be
represented as a zero-superlevel set of the value function computed via
Hamilton-Jacobi (HJ) reachability analysis, which is infeasible in real-time.
We exploit the property that the HJ value function can be expressed as a
difference of the corresponding signed distance function (SDF) and a
non-negative residual function. The residual component is modeled as a neural
network with non-negative output and subtracted from the computed SDF,
resulting in a real-time value function estimate that is at least as safe as
the SDF by design. Additionally, we parametrize the neural residual by a
hypernetwork to improve real-time performance and generalization properties.
The proposed method is compared with three state-of-the-art methods in
simulations and hardware experiments, achieving up to 30\% higher success rates
compared to the best baseline while requiring a similar computational effort
and producing high-quality (low travel-time) solutions.

</details>


### [81] [Theatre in the Loop: A Rehearsal-Based, Collaborative Workflow for Expressive Robotic Behaviours](https://arxiv.org/abs/2508.03514)
*Pavlos Panagiotidis,Victor Zhi Heung Ngo,Sean Myatt,Roma Patel,Rachel Ramchurn,Alan Chamberlain,Ayse Kucukyilmaz*

Main category: cs.RO

TL;DR: 提出了一种名为“theatre-in-the-loop”的框架，通过导演指导的木偶工作流开发适合艺术表演的机器人行为。


<details>
  <summary>Details</summary>
Motivation: 利用戏剧方法，通过叙事目标指导木偶师生成表达特定情感的机器人手势，以解决机器人行为表达性问题。

Method: 采用导演指导的木偶工作流，捕捉并整理即兴手势，构建可重用的动作模板数据集。

Result: 初步试验验证了该方法的可行性，展示了如何精确塑造机器人手势以形成连贯的情感弧线，但也揭示了机器人机械限制带来的挑战。

Conclusion: 该框架为跨学科团队创建具有社会表达性的机器人行为提供了模型，同时为人类与机器的共同创作方法提供了新思路。

Abstract: In this paper, we propose theatre-in-the-loop, a framework for developing
expressive robot behaviours tailored to artistic performance through a
director-guided puppeteering workflow. Leveraging theatrical methods, we use
narrative objectives to direct a puppeteer in generating improvised robotic
gestures that convey specific emotions. These improvisations are captured and
curated to build a dataset of reusable movement templates for standalone
playback in future autonomous performances. Initial trials demonstrate the
feasibility of this approach, illustrating how the workflow enables precise
sculpting of robotic gestures into coherent emotional arcs while revealing
challenges posed by the robot's mechanical constraints. We argue that this
practice-led framework provides a model for interdisciplinary teams creating
socially expressive robot behaviours, contributing to (1) theatre as an
interactive training ground for human-robot interaction and (2) co-creation
methodologies between humans and machines.

</details>


### [82] [CollaBot: Vision-Language Guided Simultaneous Collaborative Manipulation](https://arxiv.org/abs/2508.03526)
*Kun Song,Shentao Ma,Gaoming Chen,Ninglong Jin,Guangbao Zhao,Mingyu Ding,Zhenhua Xiong,Jia Pan*

Main category: cs.RO

TL;DR: 提出CollaBot框架，用于多机器人协作搬运大型物体，通过场景分割、协作抓取和两阶段规划实现，实验成功率为52%。


<details>
  <summary>Details</summary>
Motivation: 传统机器人操纵任务集中于小型物体，缺乏适用于大型物体和多机器人协作的通用框架。

Method: 使用SEEM进行场景分割和点云提取，提出协作抓取框架（局部抓取位姿生成和全局协作），设计两阶段规划模块生成无碰撞轨迹。

Result: 实验在不同机器人数量、物体和任务中取得52%的成功率。

Conclusion: CollaBot框架在多机器人协作搬运任务中表现出有效性，具有通用性和扩展性。

Abstract: A central research topic in robotics is how to use this system to interact
with the physical world. Traditional manipulation tasks primarily focus on
small objects. However, in factory or home environments, there is often a need
for the movement of large objects, such as moving tables. These tasks typically
require multi-robot systems to work collaboratively. Previous research lacks a
framework that can scale to arbitrary sizes of robots and generalize to various
kinds of tasks. In this work, we propose CollaBot, a generalist framework for
simultaneous collaborative manipulation. First, we use SEEM for scene
segmentation and point cloud extraction of the target object. Then, we propose
a collaborative grasping framework, which decomposes the task into local grasp
pose generation and global collaboration. Finally, we design a 2-stage planning
module that can generate collision-free trajectories to achieve this task.
Experiments show a success rate of 52% across different numbers of robots,
objects, and tasks, indicating the effectiveness of the proposed framework.

</details>


### [83] [Vision-based Perception System for Automated Delivery Robot-Pedestrians Interactions](https://arxiv.org/abs/2508.03541)
*Ergi Tushe,Bilal Farooq*

Main category: cs.RO

TL;DR: 论文提出了一种基于单视觉传感器的多行人检测与跟踪方法，结合姿态估计和深度感知，提升了行人轨迹预测和身份保持能力。


<details>
  <summary>Details</summary>
Motivation: 解决自动送货机器人在行人密集城市空间中安全、高效且社会可接受的导航问题。

Method: 开发了完整的视觉传感器处理流程，包括多行人检测与跟踪、姿态估计和单目深度感知，并利用MOT17数据集进行验证。

Result: 身份保持（IDF1）提升10%，多目标跟踪精度（MOTA）提高7%，检测精度在复杂场景下仍超过85%。

Conclusion: 系统能识别弱势行人群体，支持更具社会意识和包容性的机器人行为。

Abstract: The integration of Automated Delivery Robots (ADRs) into pedestrian-heavy
urban spaces introduces unique challenges in terms of safe, efficient, and
socially acceptable navigation. We develop the complete pipeline for a single
vision sensor based multi-pedestrian detection and tracking, pose estimation,
and monocular depth perception. Leveraging the real-world MOT17 dataset
sequences, this study demonstrates how integrating human-pose estimation and
depth cues enhances pedestrian trajectory prediction and identity maintenance,
even under occlusions and dense crowds. Results show measurable improvements,
including up to a 10% increase in identity preservation (IDF1), a 7%
improvement in multiobject tracking accuracy (MOTA), and consistently high
detection precision exceeding 85%, even in challenging scenarios. Notably, the
system identifies vulnerable pedestrian groups supporting more socially aware
and inclusive robot behaviour.

</details>


### [84] [Online Learning for Vibration Suppression in Physical Robot Interaction using Power Tools](https://arxiv.org/abs/2508.03559)
*Gokhan Solak,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出了一种改进的BMFLC算法（damped BMFLC），通过自适应步长和阻尼机制提升振动抑制效果和收敛速度，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 协作机器人在复杂环境（如建筑工地）中需要抑制外部振动（如电动工具引起的振动），传统方法在收敛时间和抗噪性上存在不足。

Method: 采用BMFLC算法在线学习振动并通过前馈力控制抵消振动，提出damped BMFLC方法，引入自适应步长和基于逻辑函数的阻尼机制。

Result: 仿真和实物实验表明，该方法在抑制率和效率上优于原始BMFLC及其扩展方法（如递归最小二乘和卡尔曼滤波）。

Conclusion: damped BMFLC方法在振动抑制中表现优异，适用于实际应用场景。

Abstract: Vibration suppression is an important capability for collaborative robots
deployed in challenging environments such as construction sites. We study the
active suppression of vibration caused by external sources such as power tools.
We adopt the band-limited multiple Fourier linear combiner (BMFLC) algorithm to
learn the vibration online and counter it by feedforward force control. We
propose the damped BMFLC method, extending BMFLC with a novel adaptive
step-size approach that improves the convergence time and noise resistance. Our
logistic function-based damping mechanism reduces the effect of noise and
enables larger learning rates. We evaluate our method on extensive simulation
experiments with realistic time-varying multi-frequency vibration and
real-world physical interaction experiments. The simulation experiments show
that our method improves the suppression rate in comparison to the original
BMFLC and its recursive least squares and Kalman filter-based extensions.
Furthermore, our method is far more efficient than the latter two. We further
validate the effectiveness of our method in real-world polishing experiments. A
supplementary video is available at https://youtu.be/ms6m-6JyVAI.

</details>


### [85] [Why Evolve When You Can Adapt? Post-Evolution Adaptation of Genetic Memory for On-the-Fly Control](https://arxiv.org/abs/2508.03600)
*Hamze Hammami,Eva Denisa Barbulescu,Talal Shaikh,Mouayad Aldada,Muhammad Saad Munawar*

Main category: cs.RO

TL;DR: 提出了一种结合遗传算法和海伯学习的零样本自适应机器人控制器，能够在运行时动态调整突触权重以应对环境变化。


<details>
  <summary>Details</summary>
Motivation: 受生物系统启发，旨在解决机器人在实时任务中遇到意外挑战时的自适应问题。

Method: 将遗传算法控制器与在线海伯可塑性结合，利用适应度函数动态调整突触权重，任务结束后恢复原始权重。

Result: 在T型迷宫导航任务中验证了该方法的有效性，能够适应光线变化和障碍物。

Conclusion: 该方法为机器人提供了一种无需额外训练的动态自适应能力，同时保留了核心知识。

Abstract: Imagine a robot controller with the ability to adapt like human synapses,
dynamically rewiring itself to overcome unforeseen challenges in real time.
This paper proposes a novel zero-shot adaptation mechanism for evolutionary
robotics, merging a standard Genetic Algorithm (GA) controller with online
Hebbian plasticity. Inspired by biological systems, the method separates
learning and memory, with the genotype acting as memory and Hebbian updates
handling learning. In our approach, the fitness function is leveraged as a live
scaling factor for Hebbian learning, enabling the robot's neural controller to
adjust synaptic weights on-the-fly without additional training. This adds a
dynamic adaptive layer that activates only during runtime to handle unexpected
environmental changes. After the task, the robot 'forgets' the temporary
adjustments and reverts to the original weights, preserving core knowledge. We
validate this hybrid GA-Hebbian controller on an e-puck robot in a T-maze
navigation task with changing light conditions and obstacles.

</details>


### [86] [DiWA: Diffusion Policy Adaptation with World Models](https://arxiv.org/abs/2508.03645)
*Akshay L Chandra,Iman Nematollahi,Chenguang Huang,Tim Welschehold,Wolfram Burgard,Abhinav Valada*

Main category: cs.RO

TL;DR: DiWA框架通过离线世界模型优化扩散策略，显著提升样本效率，减少实际交互需求。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在强化学习中的微调面临奖励传播困难和大量实际交互需求的问题。

Method: 提出DiWA框架，利用离线训练的世界模型微调扩散策略，避免依赖环境交互。

Result: 在CALVIN基准测试中，DiWA仅通过离线适应提升了八项任务的性能，且样本效率显著优于基线方法。

Conclusion: DiWA首次实现了基于离线世界模型的扩散策略微调，为实际机器人学习提供了更高效、安全的解决方案。

Abstract: Fine-tuning diffusion policies with reinforcement learning (RL) presents
significant challenges. The long denoising sequence for each action prediction
impedes effective reward propagation. Moreover, standard RL methods require
millions of real-world interactions, posing a major bottleneck for practical
fine-tuning. Although prior work frames the denoising process in diffusion
policies as a Markov Decision Process to enable RL-based updates, its strong
dependence on environment interaction remains highly inefficient. To bridge
this gap, we introduce DiWA, a novel framework that leverages a world model for
fine-tuning diffusion-based robotic skills entirely offline with reinforcement
learning. Unlike model-free approaches that require millions of environment
interactions to fine-tune a repertoire of robot skills, DiWA achieves effective
adaptation using a world model trained once on a few hundred thousand offline
play interactions. This results in dramatically improved sample efficiency,
making the approach significantly more practical and safer for real-world robot
learning. On the challenging CALVIN benchmark, DiWA improves performance across
eight tasks using only offline adaptation, while requiring orders of magnitude
fewer physical interactions than model-free baselines. To our knowledge, this
is the first demonstration of fine-tuning diffusion policies for real-world
robotic skills using an offline world model. We make the code publicly
available at https://diwa.cs.uni-freiburg.de.

</details>


### [87] [Inland-LOAM: Voxel-Based Structural Semantic Mapping for Inland Waterways](https://arxiv.org/abs/2508.03672)
*Zhongbi Luo,Yunjia Wang,Jan Swevers,Peter Slaets,Herman Bruyninckx*

Main category: cs.RO

TL;DR: Inland-LOAM是一种用于内河水道的LiDAR SLAM框架，通过改进的特征提取和水面平面约束减少垂直漂移，并生成语义地图以支持自主导航。


<details>
  <summary>Details</summary>
Motivation: 现有水道图表（IENC）缺乏实时细节，传统LiDAR SLAM在水道环境中表现不佳，导致垂直漂移和非语义地图，阻碍自主导航。

Method: Inland-LOAM采用改进的特征提取和水面平面约束，通过体素几何分析将3D点云转化为结构化2D语义地图，并实时计算导航参数。

Result: 在真实数据集上，Inland-LOAM表现出优于现有方法的定位精度，生成的语义地图和岸线与实际情况一致。

Conclusion: Inland-LOAM为内河水道自主导航提供了可靠的数据支持，代码和数据集将公开。

Abstract: Accurate geospatial information is crucial for safe, autonomous Inland
Waterway Transport (IWT), as existing charts (IENC) lack real-time detail and
conventional LiDAR SLAM fails in waterway environments. These challenges lead
to vertical drift and non-semantic maps, hindering autonomous navigation.
  This paper introduces Inland-LOAM, a LiDAR SLAM framework for waterways. It
uses an improved feature extraction and a water surface planar constraint to
mitigate vertical drift. A novel pipeline transforms 3D point clouds into
structured 2D semantic maps using voxel-based geometric analysis, enabling
real-time computation of navigational parameters like bridge clearances. An
automated module extracts shorelines and exports them into a lightweight,
IENC-compatible format.
  Evaluations on a real-world dataset show Inland-LOAM achieves superior
localization accuracy over state-of-the-art methods. The generated semantic
maps and shorelines align with real-world conditions, providing reliable data
for enhanced situational awareness. The code and dataset will be publicly
available

</details>
