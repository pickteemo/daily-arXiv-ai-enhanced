{"id": "2507.22188", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.22188", "abs": "https://arxiv.org/abs/2507.22188", "authors": ["Ethan DeVries", "Jack Ferlazzo", "Mustafa Ugur", "Laura H. Blumenschein"], "title": "Deployment of Objects with a Soft Everting Robot", "comment": "9 pages, 10 figures, This work has been submitted to the IEEE for\n  possible publication", "summary": "Soft everting robots present significant advantages over traditional rigid\nrobots, including enhanced dexterity, improved environmental interaction, and\nsafe navigation in unpredictable environments. While soft everting robots have\nbeen widely demonstrated for exploration type tasks, their potential to move\nand deploy payloads in such tasks has been less investigated, with previous\nwork focusing on sensors and tools for the robot. Leveraging the navigation\ncapabilities, and deployed body, of the soft everting robot to deliver payloads\nin hazardous areas, e.g. carrying a water bottle to a person stuck under\ndebris, would represent a significant capability in many applications. In this\nwork, we present an analysis of how soft everting robots can be used to deploy\nlarger, heavier payloads through the inside of the robot. We analyze both what\nobjects can be deployed and what terrain features they can be carried through.\nBuilding on existing models, we present methods to quantify the effects of\npayloads on robot growth and self-support, and develop a model to predict\npayload slip. We then experimentally quantify payload transport using soft\neverting robot with a variety of payload shapes, sizes, and weights and though\na series of tasks: steering, vertical transport, movement through holes, and\nmovement across gaps. Overall, the results show that we can transport payloads\nin a variety of shapes and up to 1.5kg in weight and that we can move through\ncircular apertures with as little as 0.01cm clearance around payloads, carry\nout discrete turns up to 135 degrees, and move across unsupported gaps of 1.15m\nin length.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8f6f\u7ffb\u8f6c\u673a\u5668\u4eba\u5728\u5371\u9669\u73af\u5883\u4e2d\u8fd0\u8f93\u548c\u90e8\u7f72\u6709\u6548\u8f7d\u8377\u7684\u80fd\u529b\uff0c\u5206\u6790\u4e86\u5176\u8fd0\u8f93\u80fd\u529b\u53ca\u5730\u5f62\u9002\u5e94\u6027\u3002", "motivation": "\u8f6f\u7ffb\u8f6c\u673a\u5668\u4eba\u5728\u63a2\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u8fd0\u8f93\u548c\u90e8\u7f72\u6709\u6548\u8f7d\u8377\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u5c24\u5176\u662f\u5728\u5371\u9669\u73af\u5883\u4e2d\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5efa\u6a21\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u5f62\u72b6\u3001\u5927\u5c0f\u548c\u91cd\u91cf\u7684\u8f7d\u8377\u5bf9\u673a\u5668\u4eba\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u673a\u5668\u4eba\u53ef\u8fd0\u8f93\u91cd\u8fbe1.5kg\u7684\u8f7d\u8377\uff0c\u5e76\u80fd\u901a\u8fc7\u72ed\u7a84\u7a7a\u95f4\u3001\u5b8c\u6210135\u5ea6\u8f6c\u5f2f\u548c\u8de8\u8d8a1.15m\u7684\u95f4\u9699\u3002", "conclusion": "\u8f6f\u7ffb\u8f6c\u673a\u5668\u4eba\u5177\u5907\u5728\u590d\u6742\u73af\u5883\u4e2d\u8fd0\u8f93\u548c\u90e8\u7f72\u6709\u6548\u8f7d\u8377\u7684\u6f5c\u529b\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u3002"}}
{"id": "2507.22345", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.22345", "abs": "https://arxiv.org/abs/2507.22345", "authors": ["Zhicheng Song", "Jinglan Xu", "Chunxin Zheng", "Yulin Li", "Zhihai Bi", "Jun Ma"], "title": "FLORES: A Reconfigured Wheel-Legged Robot for Enhanced Steering and Adaptability", "comment": null, "summary": "Wheel-legged robots integrate the agility of legs for navigating rough\nterrains while harnessing the efficiency of wheels for smooth surfaces.\nHowever, most existing designs do not fully capitalize on the benefits of both\nlegged and wheeled structures, which limits overall system flexibility and\nefficiency. We present FLORES (reconfigured wheel-legged robot for enhanced\nsteering and adaptability), a novel wheel-legged robot design featuring a\ndistinctive front-leg configuration that sets it beyond standard design\napproaches. Specifically, FLORES replaces the conventional hip-roll degree of\nfreedom (DoF) of the front leg with hip-yaw DoFs, and this allows for efficient\nmovement on flat surfaces while ensuring adaptability when navigating complex\nterrains. This innovative design facilitates seamless transitions between\ndifferent locomotion modes (i.e., legged locomotion and wheeled locomotion) and\noptimizes the performance across varied environments. To fully exploit FLORES's\nmechanical capabilities, we develop a tailored reinforcement learning (RL)\ncontroller that adapts the Hybrid Internal Model (HIM) with a customized reward\nstructure optimized for our unique mechanical configuration. This framework\nenables the generation of adaptive, multi-modal locomotion strategies that\nfacilitate smooth transitions between wheeled and legged movements.\nFurthermore, our distinctive joint design enables the robot to exhibit novel\nand highly efficient locomotion gaits that capitalize on the synergistic\nadvantages of both locomotion modes. Through comprehensive experiments, we\ndemonstrate FLORES's enhanced steering capabilities, improved navigation\nefficiency, and versatile locomotion across various terrains. The open-source\nproject can be found at\nhttps://github.com/ZhichengSong6/FLORES-A-Reconfigured-Wheel-Legged-Robot-for-Enhanced-Steering-and-Adaptability.git.", "AI": {"tldr": "FLORES\u662f\u4e00\u79cd\u65b0\u578b\u8f6e\u817f\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u72ec\u7279\u7684\u524d\u817f\u8bbe\u8ba1\uff08\u7528\u9acb\u504f\u822a\u81ea\u7531\u5ea6\u66ff\u4ee3\u4f20\u7edf\u7684\u9acb\u6eda\u52a8\u81ea\u7531\u5ea6\uff09\u548c\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\uff0c\u5b9e\u73b0\u4e86\u5728\u5e73\u5766\u548c\u590d\u6742\u5730\u5f62\u4e0a\u7684\u9ad8\u6548\u591a\u6a21\u6001\u8fd0\u52a8\u3002", "motivation": "\u73b0\u6709\u8f6e\u817f\u673a\u5668\u4eba\u672a\u80fd\u5145\u5206\u5229\u7528\u817f\u548c\u8f6e\u7684\u4f18\u52bf\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002FLORES\u65e8\u5728\u901a\u8fc7\u521b\u65b0\u8bbe\u8ba1\u548c\u63a7\u5236\u7b56\u7565\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u9acb\u504f\u822a\u81ea\u7531\u5ea6\u7684\u524d\u817f\u8bbe\u8ba1\uff0c\u7ed3\u5408\u5b9a\u5236\u7684\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\uff08\u57fa\u4e8e\u6df7\u5408\u5185\u90e8\u6a21\u578b\u548c\u5956\u52b1\u7ed3\u6784\uff09\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u8fd0\u52a8\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFLORES\u5177\u6709\u589e\u5f3a\u7684\u8f6c\u5411\u80fd\u529b\u3001\u5bfc\u822a\u6548\u7387\u548c\u8de8\u5730\u5f62\u9002\u5e94\u6027\u3002", "conclusion": "FLORES\u901a\u8fc7\u521b\u65b0\u673a\u68b0\u8bbe\u8ba1\u548c\u63a7\u5236\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f6e\u817f\u673a\u5668\u4eba\u7684\u6027\u80fd\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2507.22356", "categories": ["cs.RO", "J.2"], "pdf": "https://arxiv.org/pdf/2507.22356", "abs": "https://arxiv.org/abs/2507.22356", "authors": ["W. Jacob Wagner", "Ahmet Soylemezoglu", "Katherine Driggs-Campbell"], "title": "In-Situ Soil-Property Estimation and Bayesian Mapping with a Simulated Compact Track Loader", "comment": "29 pages, 12 figures, 5 algorithms, ISTVS 2025", "summary": "Existing earthmoving autonomy is largely confined to highly controlled and\nwell-characterized environments due to the complexity of vehicle-terrain\ninteraction dynamics and the partial observability of the terrain resulting\nfrom unknown and spatially varying soil conditions. In this chapter, a a\nsoil-property mapping system is proposed to extend the environmental state, in\norder to overcome these restrictions and facilitate development of more robust\nautonomous earthmoving. A GPU accelerated elevation mapping system is extended\nto incorporate a blind mapping component which traces the movement of the blade\nthrough the terrain to displace and erode intersected soil, enabling separately\ntracking undisturbed and disturbed soil. Each interaction is approximated as a\nflat blade moving through a locally homogeneous soil, enabling modeling of\ncutting forces using the fundamental equation of earthmoving (FEE). Building\nupon our prior work on in situ soil-property estimation, a method is devised to\nextract approximate geometric parameters of the model given the uneven terrain,\nand an improved physics infused neural network (PINN) model is developed to\npredict soil properties and uncertainties of these estimates. A simulation of a\ncompact track loader (CTL) with a blade attachment is used to collect data to\ntrain the PINN model. Post-training, the model is leveraged online by the\nmapping system to track soil property estimates spatially as separate layers in\nthe map, with updates being performed in a Bayesian manner. Initial experiments\nshow that the system accurately highlights regions requiring higher relative\ninteraction forces, indicating the promise of this approach in enabling\nsoil-aware planning for autonomous terrain shaping.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u571f\u58e4\u5c5e\u6027\u6620\u5c04\u7cfb\u7edf\uff0c\u901a\u8fc7GPU\u52a0\u901f\u548c\u76f2\u6620\u5c04\u7ec4\u4ef6\uff0c\u7ed3\u5408\u7269\u7406\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\uff08PINN\uff09\u6a21\u578b\uff0c\u5b9e\u73b0\u571f\u58e4\u5c5e\u6027\u7684\u5728\u7ebf\u4f30\u8ba1\u548c\u66f4\u65b0\uff0c\u4ee5\u652f\u6301\u81ea\u4e3b\u571f\u65b9\u5de5\u7a0b\u7684\u571f\u58e4\u611f\u77e5\u89c4\u5212\u3002", "motivation": "\u73b0\u6709\u81ea\u4e3b\u571f\u65b9\u5de5\u7a0b\u53d7\u9650\u4e8e\u590d\u6742\u7684\u5730\u5f62-\u8f66\u8f86\u4ea4\u4e92\u52a8\u6001\u548c\u571f\u58e4\u6761\u4ef6\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u96be\u4ee5\u5728\u975e\u53d7\u63a7\u73af\u5883\u4e2d\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6269\u5c55\u73af\u5883\u72b6\u6001\u4fe1\u606f\uff0c\u63d0\u5347\u81ea\u4e3b\u571f\u65b9\u5de5\u7a0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u6269\u5c55GPU\u52a0\u901f\u9ad8\u7a0b\u6620\u5c04\u7cfb\u7edf\uff0c\u5f15\u5165\u76f2\u6620\u5c04\u7ec4\u4ef6\u8ffd\u8e2a\u94f2\u5200\u8fd0\u52a8\uff0c\u7ed3\u5408FEE\u6a21\u578b\u548cPINN\u9884\u6d4b\u571f\u58e4\u5c5e\u6027\u3002\u901a\u8fc7\u6a21\u62df\u6570\u636e\u8bad\u7ec3PINN\uff0c\u5e76\u5728\u5728\u7ebf\u6620\u5c04\u4e2d\u4ee5\u8d1d\u53f6\u65af\u65b9\u5f0f\u66f4\u65b0\u571f\u58e4\u5c5e\u6027\u4f30\u8ba1\u3002", "result": "\u7cfb\u7edf\u80fd\u51c6\u786e\u8bc6\u522b\u9700\u8981\u66f4\u9ad8\u4ea4\u4e92\u529b\u7684\u533a\u57df\uff0c\u521d\u6b65\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u571f\u58e4\u611f\u77e5\u89c4\u5212\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u81ea\u4e3b\u5730\u5f62\u5851\u9020\u63d0\u4f9b\u4e86\u571f\u58e4\u611f\u77e5\u80fd\u529b\uff0c\u5c55\u73b0\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u5e94\u7528\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2507.22380", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22380", "abs": "https://arxiv.org/abs/2507.22380", "authors": ["Yifei Chen", "Yuzhe Zhang", "Giovanni D'urso", "Nicholas Lawrance", "Brendan Tidd"], "title": "Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations", "comment": "13 pages", "summary": "Recent developments in imitation learning have considerably advanced robotic\nmanipulation. However, current techniques in imitation learning can suffer from\npoor generalization, limiting performance even under relatively minor domain\nshifts. In this work, we aim to enhance the generalization capabilities of\ncomplex imitation learning algorithms to handle unpredictable changes from the\ntraining environments to deployment environments. To avoid confusion caused by\nobservations that are not relevant to the target task, we propose to explicitly\nlearn the causal relationship between observation components and expert\nactions, employing a framework similar to [6], where a causal structural\nfunction is learned by intervention on the imitation learning policy.\nDisentangling the feature representation from image input as in [6] is hard to\nsatisfy in complex imitation learning process in robotic manipulation, we\ntheoretically clarify that this requirement is not necessary in causal\nrelationship learning. Therefore, we propose a simple causal structure learning\nframework that can be easily embedded in recent imitation learning\narchitectures, such as the Action Chunking Transformer [31]. We demonstrate our\napproach using a simulation of the ALOHA [31] bimanual robot arms in Mujoco,\nand show that the method can considerably mitigate the generalization problem\nof existing complex imitation learning algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u56e0\u679c\u7ed3\u6784\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u589e\u5f3a\u6a21\u4eff\u5b66\u4e60\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u6a21\u4eff\u5b66\u4e60\u6280\u672f\u5728\u9762\u5bf9\u8bad\u7ec3\u73af\u5883\u4e0e\u90e8\u7f72\u73af\u5883\u7684\u5fae\u5c0f\u53d8\u5316\u65f6\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u663e\u5f0f\u5b66\u4e60\u89c2\u5bdf\u7ec4\u4ef6\u4e0e\u4e13\u5bb6\u52a8\u4f5c\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u590d\u6742\u7279\u5f81\u89e3\u8026\u7684\u56e0\u679c\u7ed3\u6784\u5b66\u4e60\u6846\u67b6\u3002", "result": "\u5728ALOHA\u53cc\u624b\u673a\u5668\u4eba\u81c2\u7684\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u7f13\u89e3\u4e86\u73b0\u6709\u590d\u6742\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\u7684\u6cdb\u5316\u95ee\u9898\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7b80\u5355\u6613\u5d4c\u5165\u73b0\u6709\u67b6\u6784\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u4eff\u5b66\u4e60\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.22149", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22149", "abs": "https://arxiv.org/abs/2507.22149", "authors": ["Xianxuan Long", "Yao Fu", "Runchao Li", "Mu Sheng", "Haotian Yu", "Xiaotian Han", "Pan Li"], "title": "When Truthful Representations Flip Under Deceptive Instructions?", "comment": null, "summary": "Large language models (LLMs) tend to follow maliciously crafted instructions\nto generate deceptive responses, posing safety challenges. How deceptive\ninstructions alter the internal representations of LLM compared to truthful\nones remains poorly understood beyond output analysis. To bridge this gap, we\ninvestigate when and how these representations ``flip'', such as from truthful\nto deceptive, under deceptive versus truthful/neutral instructions. Analyzing\nthe internal representations of Llama-3.1-8B-Instruct and Gemma-2-9B-Instruct\non a factual verification task, we find the model's instructed True/False\noutput is predictable via linear probes across all conditions based on the\ninternal representation. Further, we use Sparse Autoencoders (SAEs) to show\nthat the Deceptive instructions induce significant representational shifts\ncompared to Truthful/Neutral representations (which are similar), concentrated\nin early-to-mid layers and detectable even on complex datasets. We also\nidentify specific SAE features highly sensitive to deceptive instruction and\nuse targeted visualizations to confirm distinct truthful/deceptive\nrepresentational subspaces. % Our analysis pinpoints layer-wise and\nfeature-level correlates of instructed dishonesty, offering insights for LLM\ndetection and control. Our findings expose feature- and layer-level signatures\nof deception, offering new insights for detecting and mitigating instructed\ndishonesty in LLMs.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6b3a\u9a97\u6027\u6307\u4ee4\u4e0b\u5185\u90e8\u8868\u5f81\u7684\u53d8\u5316\uff0c\u53d1\u73b0\u6b3a\u9a97\u6027\u6307\u4ee4\u4f1a\u5bfc\u81f4\u663e\u8457\u7684\u8868\u793a\u504f\u79fb\uff0c\u5e76\u8bc6\u522b\u4e86\u654f\u611f\u7279\u5f81\u548c\u5c42\u7ea7\u7684\u6b3a\u9a97\u7279\u5f81\u3002", "motivation": "\u7406\u89e3\u6b3a\u9a97\u6027\u6307\u4ee4\u5982\u4f55\u6539\u53d8LLM\u7684\u5185\u90e8\u8868\u5f81\uff0c\u4ee5\u89e3\u51b3\u6a21\u578b\u7684\u5b89\u5168\u6027\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u7ebf\u6027\u63a2\u6d4b\u548c\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u5206\u6790Llama-3.1-8B-Instruct\u548cGemma-2-9B-Instruct\u7684\u5185\u90e8\u8868\u5f81\u3002", "result": "\u6b3a\u9a97\u6027\u6307\u4ee4\u5728\u65e9\u671f\u81f3\u4e2d\u5c42\u5bfc\u81f4\u663e\u8457\u8868\u5f81\u504f\u79fb\uff0c\u5e76\u8bc6\u522b\u51fa\u654f\u611f\u7279\u5f81\u548c\u4e0d\u540c\u7684\u8868\u5f81\u5b50\u7a7a\u95f4\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u6b3a\u9a97\u6027\u6307\u4ee4\u7684\u7279\u5f81\u548c\u5c42\u7ea7\u7279\u5f81\uff0c\u4e3aLLM\u7684\u68c0\u6d4b\u548c\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2507.22389", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.22389", "abs": "https://arxiv.org/abs/2507.22389", "authors": ["Kaustav Chakraborty", "Zeyuan Feng", "Sushant Veer", "Apoorva Sharma", "Wenhao Ding", "Sever Topan", "Boris Ivanovic", "Marco Pavone", "Somil Bansal"], "title": "Safety Evaluation of Motion Plans Using Trajectory Predictors as Forward Reachable Set Estimators", "comment": null, "summary": "The advent of end-to-end autonomy stacks - often lacking interpretable\nintermediate modules - has placed an increased burden on ensuring that the\nfinal output, i.e., the motion plan, is safe in order to validate the safety of\nthe entire stack. This requires a safety monitor that is both complete (able to\ndetect all unsafe plans) and sound (does not flag safe plans). In this work, we\npropose a principled safety monitor that leverages modern multi-modal\ntrajectory predictors to approximate forward reachable sets (FRS) of\nsurrounding agents. By formulating a convex program, we efficiently extract\nthese data-driven FRSs directly from the predicted state distributions,\nconditioned on scene context such as lane topology and agent history. To ensure\ncompleteness, we leverage conformal prediction to calibrate the FRS and\nguarantee coverage of ground-truth trajectories with high probability. To\npreserve soundness in out-of-distribution (OOD) scenarios or under predictor\nfailure, we introduce a Bayesian filter that dynamically adjusts the FRS\nconservativeness based on the predictor's observed performance. We then assess\nthe safety of the ego vehicle's motion plan by checking for intersections with\nthese calibrated FRSs, ensuring the plan remains collision-free under plausible\nfuture behaviors of others. Extensive experiments on the nuScenes dataset show\nour approach significantly improves soundness while maintaining completeness,\noffering a practical and reliable safety monitor for learned autonomy stacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u7684\u5b89\u5168\u76d1\u63a7\u65b9\u6cd5\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u548c\u5171\u5f62\u9884\u6d4b\u786e\u4fdd\u8fd0\u52a8\u8ba1\u5212\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7f3a\u4e4f\u53ef\u89e3\u91ca\u7684\u4e2d\u95f4\u6a21\u5757\uff0c\u9700\u786e\u4fdd\u6700\u7ec8\u8fd0\u52a8\u8ba1\u5212\u7684\u5b89\u5168\u6027\u3002", "method": "\u5229\u7528\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u5668\u8fd1\u4f3c\u5468\u56f4\u667a\u80fd\u4f53\u7684\u524d\u5411\u53ef\u8fbe\u96c6\uff08FRS\uff09\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u63d0\u53d6\u6570\u636e\u9a71\u52a8\u7684FRS\uff0c\u5e76\u4f7f\u7528\u5171\u5f62\u9884\u6d4b\u6821\u51c6FRS\u4ee5\u786e\u4fdd\u5b8c\u6574\u6027\u3002\u5f15\u5165\u8d1d\u53f6\u65af\u6ee4\u6ce2\u5668\u8c03\u6574FRS\u7684\u4fdd\u5b88\u6027\u3002", "result": "\u5728nuScenes\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u9760\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b8c\u6574\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b66\u4e60\u578b\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u9760\u7684\u5b89\u5168\u76d1\u63a7\u65b9\u6848\u3002"}}
{"id": "2507.22197", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.22197", "abs": "https://arxiv.org/abs/2507.22197", "authors": ["Matthieu Queloz"], "title": "Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence", "comment": "39 pages; final, published version", "summary": "This paper argues that explainability is only one facet of a broader ideal\nthat shapes our expectations towards artificial intelligence (AI).\nFundamentally, the issue is to what extent AI exhibits systematicity--not\nmerely in being sensitive to how thoughts are composed of recombinable\nconstituents, but in striving towards an integrated body of thought that is\nconsistent, coherent, comprehensive, and parsimoniously principled. This richer\nconception of systematicity has been obscured by the long shadow of the\n\"systematicity challenge\" to connectionism, according to which network\narchitectures are fundamentally at odds with what Fodor and colleagues termed\n\"the systematicity of thought.\" I offer a conceptual framework for thinking\nabout \"the systematicity of thought\" that distinguishes four senses of the\nphrase. I use these distinctions to defuse the perceived tension between\nsystematicity and connectionism and show that the conception of systematicity\nthat historically shaped our sense of what makes thought rational,\nauthoritative, and scientific is more demanding than the Fodorian notion. To\ndetermine whether we have reason to hold AI models to this ideal of\nsystematicity, I then argue, we must look to the rationales for systematization\nand explore to what extent they transfer to AI models. I identify five such\nrationales and apply them to AI. This brings into view the \"hard systematicity\nchallenge.\" However, the demand for systematization itself needs to be\nregulated by the rationales for systematization. This yields a dynamic\nunderstanding of the need to systematize thought, which tells us how systematic\nwe need AI models to be and when.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u7684\u7cfb\u7edf\u6027\u4e0d\u4ec5\u662f\u53ef\u89e3\u91ca\u6027\u7684\u4e00\u90e8\u5206\uff0c\u800c\u662f\u66f4\u5e7f\u6cdb\u7684\u7406\u60f3\uff0c\u6d89\u53ca\u4e00\u81f4\u6027\u3001\u8fde\u8d2f\u6027\u3001\u5168\u9762\u6027\u548c\u7b80\u6d01\u6027\u539f\u5219\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u7cfb\u7edf\u6027\u601d\u7ef4\u7684\u56db\u79cd\u542b\u4e49\uff0c\u5e76\u63a2\u8ba8\u4e86\u7cfb\u7edf\u6027\u9700\u6c42\u5bf9AI\u6a21\u578b\u7684\u9002\u7528\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u6f84\u6e05\u7cfb\u7edf\u6027\u601d\u7ef4\u7684\u591a\u91cd\u542b\u4e49\uff0c\u5e76\u63a2\u8ba8AI\u6a21\u578b\u662f\u5426\u5e94\u6ee1\u8db3\u66f4\u9ad8\u7684\u7cfb\u7edf\u6027\u6807\u51c6\uff0c\u4ee5\u7b26\u5408\u4eba\u7c7b\u601d\u7ef4\u7684\u7406\u6027\u3001\u6743\u5a01\u6027\u548c\u79d1\u5b66\u6027\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\uff0c\u533a\u5206\u4e86\u7cfb\u7edf\u6027\u601d\u7ef4\u7684\u56db\u79cd\u542b\u4e49\uff0c\u5e76\u5206\u6790\u4e86\u7cfb\u7edf\u6027\u9700\u6c42\u5bf9AI\u6a21\u578b\u7684\u9002\u7528\u6027\uff0c\u5217\u4e3e\u4e86\u4e94\u79cd\u7cfb\u7edf\u6027\u7406\u7531\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cAI\u6a21\u578b\u7684\u7cfb\u7edf\u6027\u9700\u6c42\u5e94\u6839\u636e\u5177\u4f53\u7406\u7531\u52a8\u6001\u8c03\u6574\uff0c\u800c\u975e\u4e00\u5200\u5207\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u7cfb\u7edf\u6027\u9700\u6c42\u9700\u8981\u57fa\u4e8e\u5177\u4f53\u7406\u7531\u52a8\u6001\u8c03\u8282\uff0c\u4ece\u800c\u660e\u786eAI\u6a21\u578b\u5728\u4f55\u65f6\u9700\u8981\u4f55\u79cd\u7a0b\u5ea6\u7684\u7cfb\u7edf\u6027\u3002"}}
{"id": "2507.22429", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22429", "abs": "https://arxiv.org/abs/2507.22429", "authors": ["Erwin de Gelder", "Maren Buermann", "Olaf Op den Camp"], "title": "Comparing Normalizing Flows with Kernel Density Estimation in Estimating Risk of Automated Driving Systems", "comment": "Accepted for publication in proceedings of the 2025 IEEE\n  International Automated Vehicle Validation Conference", "summary": "The development of safety validation methods is essential for the safe\ndeployment and operation of Automated Driving Systems (ADSs). One of the goals\nof safety validation is to prospectively evaluate the risk of an ADS dealing\nwith real-world traffic. Scenario-based assessment is a widely-used approach,\nwhere test cases are derived from real-world driving data. To allow for a\nquantitative analysis of the system performance, the exposure of the scenarios\nmust be accurately estimated. The exposure of scenarios at parameter level is\nexpressed using a Probability Density Function (PDF). However, assumptions\nabout the PDF, such as parameter independence, can introduce errors, while\navoiding assumptions often leads to oversimplified models with limited\nparameters to mitigate the curse of dimensionality.\n  This paper considers the use of Normalizing Flows (NF) for estimating the PDF\nof the parameters. NF are a class of generative models that transform a simple\nbase distribution into a complex one using a sequence of invertible and\ndifferentiable mappings, enabling flexible, high-dimensional density estimation\nwithout restrictive assumptions on the PDF's shape. We demonstrate the\neffectiveness of NF in quantifying risk and risk uncertainty of an ADS,\ncomparing its performance with Kernel Density Estimation (KDE), a traditional\nmethod for non-parametric PDF estimation. While NF require more computational\nresources compared to KDE, NF is less sensitive to the curse of dimensionality.\nAs a result, NF can improve risk uncertainty estimation, offering a more\nprecise assessment of an ADS's safety.\n  This work illustrates the potential of NF in scenario-based safety. Future\nwork involves experimenting more with using NF for scenario generation and\noptimizing the NF architecture, transformation types, and training\nhyperparameters to further enhance their applicability.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u5f52\u4e00\u5316\u6d41\uff08NF\uff09\u4f30\u8ba1\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff08ADS\uff09\u573a\u666f\u53c2\u6570\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff08PDF\uff09\uff0c\u4ee5\u6539\u8fdb\u5b89\u5168\u9a8c\u8bc1\u4e2d\u7684\u98ce\u9669\u91cf\u5316\u3002", "motivation": "\u5b89\u5168\u9a8c\u8bc1\u65b9\u6cd5\u5bf9\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5b89\u5168\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5728\u53c2\u6570\u72ec\u7acb\u6027\u548c\u7ef4\u5ea6\u707e\u96be\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u91c7\u7528\u5f52\u4e00\u5316\u6d41\uff08NF\uff09\u8fdb\u884c\u9ad8\u7ef4\u5bc6\u5ea6\u4f30\u8ba1\uff0c\u907f\u514d\u5bf9PDF\u5f62\u72b6\u7684\u4e25\u683c\u5047\u8bbe\uff0c\u5e76\u4e0e\u6838\u5bc6\u5ea6\u4f30\u8ba1\uff08KDE\uff09\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002", "result": "NF\u5728\u98ce\u9669\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4e0a\u4f18\u4e8eKDE\uff0c\u5c3d\u7ba1\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u66f4\u9ad8\uff0c\u4f46\u5bf9\u7ef4\u5ea6\u707e\u96be\u66f4\u4e0d\u654f\u611f\u3002", "conclusion": "NF\u5728\u573a\u666f\u5316\u5b89\u5168\u9a8c\u8bc1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u672a\u6765\u53ef\u4f18\u5316\u5176\u67b6\u6784\u548c\u8bad\u7ec3\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u9002\u7528\u6027\u3002"}}
{"id": "2507.22281", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.22281", "abs": "https://arxiv.org/abs/2507.22281", "authors": ["Minsoo Kim", "Seung-won Hwang"], "title": "CoEx -- Co-evolving World-model and Exploration", "comment": null, "summary": "Planning in modern LLM agents relies on the utilization of LLM as an internal\nworld model, acquired during pretraining. However, existing agent designs fail\nto effectively assimilate new observations into dynamic updates of the world\nmodel. This reliance on the LLM's static internal world model is progressively\nprone to misalignment with the underlying true state of the world, leading to\nthe generation of divergent and erroneous plans. We introduce a hierarchical\nagent architecture, CoEx, in which hierarchical state abstraction allows LLM\nplanning to co-evolve with a dynamically updated model of the world. CoEx plans\nand interacts with the world by using LLM reasoning to orchestrate dynamic\nplans consisting of subgoals, and its learning mechanism continuously\nincorporates these subgoal experiences into a persistent world model in the\nform of a neurosymbolic belief state, comprising textual inferences and\ncode-based symbolic memory. We evaluate our agent across a diverse set of agent\nscenarios involving rich environments and complex tasks including ALFWorld,\nPDDL, and Jericho. Our experiments show that CoEx outperforms existing agent\nparadigms in planning and exploration.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u4ee3\u7406\u67b6\u6784CoEx\uff0c\u901a\u8fc7\u52a8\u6001\u66f4\u65b0\u4e16\u754c\u6a21\u578b\u89e3\u51b3\u73b0\u6709LLM\u4ee3\u7406\u5728\u89c4\u5212\u4e2d\u56e0\u9759\u6001\u4e16\u754c\u6a21\u578b\u5bfc\u81f4\u7684\u9519\u8bef\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u4f9d\u8d56\u9884\u8bad\u7ec3\u4e2d\u7684\u9759\u6001\u4e16\u754c\u6a21\u578b\uff0c\u65e0\u6cd5\u6709\u6548\u6574\u5408\u65b0\u89c2\u5bdf\uff0c\u5bfc\u81f4\u89c4\u5212\u4e0e\u5b9e\u9645\u72b6\u6001\u8131\u8282\u3002", "method": "CoEx\u91c7\u7528\u5206\u5c42\u72b6\u6001\u62bd\u8c61\uff0c\u7ed3\u5408LLM\u63a8\u7406\u548c\u795e\u7ecf\u7b26\u53f7\u4fe1\u5ff5\u72b6\u6001\uff08\u6587\u672c\u63a8\u65ad\u4e0e\u4ee3\u7801\u7b26\u53f7\u8bb0\u5fc6\uff09\uff0c\u52a8\u6001\u66f4\u65b0\u4e16\u754c\u6a21\u578b\u3002", "result": "\u5728ALFWorld\u3001PDDL\u548cJericho\u7b49\u590d\u6742\u4efb\u52a1\u4e2d\uff0cCoEx\u5728\u89c4\u5212\u548c\u63a2\u7d22\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u4ee3\u7406\u8303\u5f0f\u3002", "conclusion": "CoEx\u901a\u8fc7\u52a8\u6001\u4e16\u754c\u6a21\u578b\u548c\u5206\u5c42\u89c4\u5212\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u4ee3\u7406\u7684\u89c4\u5212\u80fd\u529b\u3002"}}
{"id": "2507.22433", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.22433", "abs": "https://arxiv.org/abs/2507.22433", "authors": ["Olaf Op den Camp", "Erwin de Gelder"], "title": "Operationalization of Scenario-Based Safety Assessment of Automated Driving Systems", "comment": "Accepted for publication in proceedings of the 2025 IEEE\n  International Automated Vehicle Validation Conference", "summary": "Before introducing an Automated Driving System (ADS) on the road at scale,\nthe manufacturer must conduct some sort of safety assurance. To structure and\nharmonize the safety assurance process, the UNECE WP.29 Working Party on\nAutomated/Autonomous and Connected Vehicles (GRVA) is developing the New\nAssessment/Test Method (NATM) that indicates what steps need to be taken for\nsafety assessment of an ADS. In this paper, we will show how to practically\nconduct safety assessment making use of a scenario database, and what\nadditional steps must be taken to fully operationalize the NATM. In addition,\nwe will elaborate on how the use of scenario databases fits with methods\ndeveloped in the Horizon Europe projects that focus on safety assessment\nfollowing the NATM approach.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u573a\u666f\u6570\u636e\u5e93\u5b9e\u9645\u8fdb\u884c\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff08ADS\uff09\u7684\u5b89\u5168\u8bc4\u4f30\uff0c\u5e76\u8865\u5145\u4e86\u5b8c\u5168\u5b9e\u65bdNATM\u6240\u9700\u7684\u989d\u5916\u6b65\u9aa4\u3002", "motivation": "\u4e3a\u4e86\u5728\u9053\u8def\u4e0a\u5927\u89c4\u6a21\u5f15\u5165ADS\uff0c\u5236\u9020\u5546\u9700\u8981\u8fdb\u884c\u5b89\u5168\u4fdd\u8bc1\uff0c\u800cNATM\u4e3a\u8fd9\u4e00\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u7ed3\u6784\u548c\u534f\u8c03\u3002", "method": "\u5229\u7528\u573a\u666f\u6570\u636e\u5e93\u8fdb\u884c\u5b89\u5168\u8bc4\u4f30\uff0c\u5e76\u7ed3\u5408Horizon Europe\u9879\u76ee\u5f00\u53d1\u7684\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u5b9e\u9645\u8bc4\u4f30ADS\u5b89\u5168\u6027\u7684\u65b9\u6cd5\uff0c\u5e76\u8865\u5145\u4e86NATM\u7684\u5b8c\u6574\u5b9e\u65bd\u6b65\u9aa4\u3002", "conclusion": "\u573a\u666f\u6570\u636e\u5e93\u4e0eNATM\u65b9\u6cd5\u7684\u7ed3\u5408\u4e3aADS\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.22326", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22326", "abs": "https://arxiv.org/abs/2507.22326", "authors": ["Qun Ma", "Xiao Xue", "Ming Zhang", "Yifan Shen", "Zihan Zhao"], "title": "An Explainable Emotion Alignment Framework for LLM-Empowered Agent in Metaverse Service Ecosystem", "comment": null, "summary": "Metaverse service is a product of the convergence between Metaverse and\nservice systems, designed to address service-related challenges concerning\ndigital avatars, digital twins, and digital natives within Metaverse. With the\nrise of large language models (LLMs), agents now play a pivotal role in\nMetaverse service ecosystem, serving dual functions: as digital avatars\nrepresenting users in the virtual realm and as service assistants (or NPCs)\nproviding personalized support. However, during the modeling of Metaverse\nservice ecosystems, existing LLM-based agents face significant challenges in\nbridging virtual-world services with real-world services, particularly\nregarding issues such as character data fusion, character knowledge\nassociation, and ethical safety concerns. This paper proposes an explainable\nemotion alignment framework for LLM-based agents in Metaverse Service\nEcosystem. It aims to integrate factual factors into the decision-making loop\nof LLM-based agents, systematically demonstrating how to achieve more\nrelational fact alignment for these agents. Finally, a simulation experiment in\nthe Offline-to-Offline food delivery scenario is conducted to evaluate the\neffectiveness of this framework, obtaining more realistic social emergence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u53ef\u89e3\u91ca\u60c5\u611f\u5bf9\u9f50\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5143\u5b87\u5b99\u670d\u52a1\u751f\u6001\u4e2d\u865a\u62df\u4e0e\u73b0\u5b9e\u670d\u52a1\u878d\u5408\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\uff0c\u4ee3\u7406\u5728\u5143\u5b87\u5b99\u670d\u52a1\u751f\u6001\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\uff0c\u4f46\u73b0\u6709\u4ee3\u7406\u5728\u865a\u62df\u4e0e\u73b0\u5b9e\u670d\u52a1\u878d\u5408\u65b9\u9762\u9762\u4e34\u6570\u636e\u878d\u5408\u3001\u77e5\u8bc6\u5173\u8054\u548c\u4f26\u7406\u5b89\u5168\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u60c5\u611f\u5bf9\u9f50\u6846\u67b6\uff0c\u5c06\u4e8b\u5b9e\u56e0\u7d20\u878d\u5165LLM\u4ee3\u7406\u7684\u51b3\u7b56\u5faa\u73af\uff0c\u5b9e\u73b0\u66f4\u76f8\u5173\u7684\u4e8b\u5b9e\u5bf9\u9f50\u3002", "result": "\u5728O2O\u5916\u5356\u573a\u666f\u7684\u6a21\u62df\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u83b7\u5f97\u4e86\u66f4\u771f\u5b9e\u7684\u793e\u4f1a\u6d8c\u73b0\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aLLM\u4ee3\u7406\u5728\u5143\u5b87\u5b99\u670d\u52a1\u751f\u6001\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.22473", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.22473", "abs": "https://arxiv.org/abs/2507.22473", "authors": ["Yongjie Li", "Zhou Liu", "Wenshuai Yu", "Zhangji Lu", "Chenyang Wang", "Fei Yu", "Qingquan Li"], "title": "A Two-Stage Lightweight Framework for Efficient Land-Air Bimodal Robot Autonomous Navigation", "comment": "IROS2025", "summary": "Land-air bimodal robots (LABR) are gaining attention for autonomous\nnavigation, combining high mobility from aerial vehicles with long endurance\nfrom ground vehicles. However, existing LABR navigation methods are limited by\nsuboptimal trajectories from mapping-based approaches and the excessive\ncomputational demands of learning-based methods. To address this, we propose a\ntwo-stage lightweight framework that integrates global key points prediction\nwith local trajectory refinement to generate efficient and reachable\ntrajectories. In the first stage, the Global Key points Prediction Network\n(GKPN) was used to generate a hybrid land-air keypoint path. The GKPN includes\na Sobel Perception Network (SPN) for improved obstacle detection and a\nLightweight Attention Planning Network (LAPN) to improves predictive ability by\ncapturing contextual information. In the second stage, the global path is\nsegmented based on predicted key points and refined using a mapping-based\nplanner to create smooth, collision-free trajectories. Experiments conducted on\nour LABR platform show that our framework reduces network parameters by 14\\%\nand energy consumption during land-air transitions by 35\\% compared to existing\napproaches. The framework achieves real-time navigation without GPU\nacceleration and enables zero-shot transfer from simulation to reality during", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7ed3\u5408\u5168\u5c40\u5173\u952e\u70b9\u9884\u6d4b\u4e0e\u5c40\u90e8\u8f68\u8ff9\u4f18\u5316\uff0c\u7528\u4e8e\u9646\u5730-\u7a7a\u4e2d\u53cc\u6a21\u6001\u673a\u5668\u4eba\u7684\u9ad8\u6548\u5bfc\u822a\u3002", "motivation": "\u73b0\u6709\u9646\u5730-\u7a7a\u4e2d\u53cc\u6a21\u6001\u673a\u5668\u4eba\u5bfc\u822a\u65b9\u6cd5\u5b58\u5728\u8f68\u8ff9\u4f18\u5316\u4e0d\u8db3\u548c\u8ba1\u7b97\u9700\u6c42\u8fc7\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5168\u5c40\u5173\u952e\u70b9\u9884\u6d4b\u7f51\u7edc\uff08GKPN\uff09\u751f\u6210\u6df7\u5408\u8def\u5f84\uff0c\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u6620\u5c04\u89c4\u5212\u5668\u4f18\u5316\u8f68\u8ff9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6846\u67b6\u51cf\u5c11\u4e8614%\u7684\u7f51\u7edc\u53c2\u6570\u548c35%\u7684\u80fd\u8017\uff0c\u652f\u6301\u5b9e\u65f6\u5bfc\u822a\u548c\u96f6\u6837\u672c\u8fc1\u79fb\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u9646\u5730-\u7a7a\u4e2d\u53cc\u6a21\u6001\u673a\u5668\u4eba\u7684\u5bfc\u822a\u6548\u7387\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.22358", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.22358", "abs": "https://arxiv.org/abs/2507.22358", "authors": ["Hussein Mozannar", "Gagan Bansal", "Cheng Tan", "Adam Fourney", "Victor Dibia", "Jingya Chen", "Jack Gerrits", "Tyler Payne", "Matheus Kunzler Maldaner", "Madeleine Grunde-McLaughlin", "Eric Zhu", "Griffin Bassman", "Jacob Alber", "Peter Chang", "Ricky Loynd", "Friederike Niedtner", "Ece Kamar", "Maya Murad", "Rafah Hosn", "Saleema Amershi"], "title": "Magentic-UI: Towards Human-in-the-loop Agentic Systems", "comment": null, "summary": "AI agents powered by large language models are increasingly capable of\nautonomously completing complex, multi-step tasks using external tools. Yet,\nthey still fall short of human-level performance in most domains including\ncomputer use, software development, and research. Their growing autonomy and\nability to interact with the outside world, also introduces safety and security\nrisks including potentially misaligned actions and adversarial manipulation. We\nargue that human-in-the-loop agentic systems offer a promising path forward,\ncombining human oversight and control with AI efficiency to unlock productivity\nfrom imperfect systems. We introduce Magentic-UI, an open-source web interface\nfor developing and studying human-agent interaction. Built on a flexible\nmulti-agent architecture, Magentic-UI supports web browsing, code execution,\nand file manipulation, and can be extended with diverse tools via Model Context\nProtocol (MCP). Moreover, Magentic-UI presents six interaction mechanisms for\nenabling effective, low-cost human involvement: co-planning, co-tasking,\nmulti-tasking, action guards, and long-term memory. We evaluate Magentic-UI\nacross four dimensions: autonomous task completion on agentic benchmarks,\nsimulated user testing of its interaction capabilities, qualitative studies\nwith real users, and targeted safety assessments. Our findings highlight\nMagentic-UI's potential to advance safe and efficient human-agent\ncollaboration.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMagentic-UI\uff0c\u4e00\u4e2a\u5f00\u6e90\u7684\u4eba\u673a\u4ea4\u4e92\u754c\u9762\uff0c\u65e8\u5728\u901a\u8fc7\u4eba\u7c7b\u76d1\u7763\u63d0\u5347AI\u4ee3\u7406\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4ecd\u4e0d\u53ca\u4eba\u7c7b\uff0c\u4e14\u5b58\u5728\u5b89\u5168\u548c\u98ce\u9669\u95ee\u9898\uff0c\u9700\u8981\u4eba\u7c7b\u53c2\u4e0e\u4ee5\u63d0\u5347\u6027\u80fd\u548c\u5b89\u5168\u6027\u3002", "method": "\u5f00\u53d1Magentic-UI\uff0c\u652f\u6301\u591a\u4ee3\u7406\u67b6\u6784\u548c\u591a\u6837\u5316\u5de5\u5177\u6269\u5c55\uff0c\u63d0\u4f9b\u516d\u79cd\u4ea4\u4e92\u673a\u5236\u4ee5\u5b9e\u73b0\u9ad8\u6548\u4f4e\u6210\u672c\u7684\u4eba\u7c7b\u53c2\u4e0e\u3002", "result": "\u8bc4\u4f30\u663e\u793aMagentic-UI\u5728\u4efb\u52a1\u5b8c\u6210\u3001\u4ea4\u4e92\u80fd\u529b\u3001\u7528\u6237\u6d4b\u8bd5\u548c\u5b89\u5168\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "Magentic-UI\u4e3a\u5b89\u5168\u9ad8\u6548\u7684\u4eba\u673a\u534f\u4f5c\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2507.22546", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.22546", "abs": "https://arxiv.org/abs/2507.22546", "authors": ["Alex George", "Will Shepherd", "Simon Tait", "Lyudmila Mihaylova", "Sean R. Anderson"], "title": "Explainable Deep Anomaly Detection with Sequential Hypothesis Testing for Robotic Sewer Inspection", "comment": null, "summary": "Sewer pipe faults, such as leaks and blockages, can lead to severe\nconsequences including groundwater contamination, property damage, and service\ndisruption. Traditional inspection methods rely heavily on the manual review of\nCCTV footage collected by mobile robots, which is inefficient and susceptible\nto human error. To automate this process, we propose a novel system\nincorporating explainable deep learning anomaly detection combined with\nsequential probability ratio testing (SPRT). The anomaly detector processes\nsingle image frames, providing interpretable spatial localisation of anomalies,\nwhilst the SPRT introduces temporal evidence aggregation, enhancing robustness\nagainst noise over sequences of image frames. Experimental results demonstrate\nimproved anomaly detection performance, highlighting the benefits of the\ncombined spatiotemporal analysis system for reliable and robust sewer\ninspection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53ef\u89e3\u91ca\u6df1\u5ea6\u5b66\u4e60\u5f02\u5e38\u68c0\u6d4b\u4e0e\u5e8f\u8d2f\u6982\u7387\u6bd4\u6d4b\u8bd5\uff08SPRT\uff09\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u4e0b\u6c34\u9053\u7ba1\u9053\u6545\u969c\u68c0\u6d4b\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u4e0b\u6c34\u9053\u7ba1\u9053\u68c0\u67e5\u4f9d\u8d56\u4eba\u5de5\u5ba1\u67e5CCTV\u5f55\u50cf\uff0c\u6548\u7387\u4f4e\u4e14\u6613\u51fa\u9519\uff0c\u9700\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u53ef\u89e3\u91ca\u6df1\u5ea6\u5b66\u4e60\u5f02\u5e38\u68c0\u6d4b\uff08\u7a7a\u95f4\u5b9a\u4f4d\uff09\u4e0eSPRT\uff08\u65f6\u95f4\u8bc1\u636e\u805a\u5408\uff09\uff0c\u63d0\u5347\u6297\u566a\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u7cfb\u7edf\u5728\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u4e0a\u6709\u6240\u63d0\u5347\u3002", "conclusion": "\u7ed3\u5408\u65f6\u7a7a\u5206\u6790\u7684\u7cfb\u7edf\u4e3a\u4e0b\u6c34\u9053\u68c0\u67e5\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.22359", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.22359", "abs": "https://arxiv.org/abs/2507.22359", "authors": ["Qianhong Guo", "Wei Xie", "Xiaofang Cai", "Enze Wang", "Shuoyoucheng Ma", "Kai Chen", "Xiaofeng Wang", "Baosheng Wang"], "title": "LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models", "comment": null, "summary": "Although large language models (LLMs) demonstrate remarkable capabilities\nacross various tasks, evaluating their capabilities remains a challenging task.\nExisting evaluation methods suffer from issues such as data contamination,\nblack-box operation, and subjective preference. These issues make it difficult\nto evaluate the LLMs' true capabilities comprehensively. To tackle these\nchallenges, we propose a novel benchmark-free evaluation paradigm,\nLLM-Crowdsourced. It utilizes LLMs to generate questions, answer independently,\nand evaluate mutually. This method integrates four key evaluation criteria:\ndynamic, transparent, objective, and professional, which existing evaluation\nmethods cannot satisfy simultaneously. Experiments on eight mainstream LLMs\nacross mathematics and programming verify the advantages of our method in\ndistinguishing LLM performance. Furthermore, our study reveals several novel\nfindings that are difficult for traditional methods to detect, including but\nnot limited to: (1) Gemini demonstrates the highest original and professional\nquestion-design capabilities among others; (2) Some LLMs exhibit\n''memorization-based answering'' by misrecognizing questions as familiar ones\nwith a similar structure; (3) LLM evaluation results demonstrate high\nconsistency (robustness).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u57fa\u51c6\u8bc4\u4f30\u8303\u5f0fLLM-Crowdsourced\uff0c\u901a\u8fc7LLM\u751f\u6210\u95ee\u9898\u3001\u72ec\u7acb\u56de\u7b54\u548c\u76f8\u4e92\u8bc4\u4f30\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u6570\u636e\u6c61\u67d3\u3001\u9ed1\u7bb1\u64cd\u4f5c\u548c\u4e3b\u89c2\u504f\u597d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u6570\u636e\u6c61\u67d3\u3001\u9ed1\u7bb1\u64cd\u4f5c\u548c\u4e3b\u89c2\u504f\u597d\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u5168\u9762\u8bc4\u4f30LLM\u7684\u771f\u5b9e\u80fd\u529b\u3002", "method": "\u63d0\u51faLLM-Crowdsourced\u8303\u5f0f\uff0c\u5229\u7528LLM\u751f\u6210\u95ee\u9898\u3001\u72ec\u7acb\u56de\u7b54\u548c\u76f8\u4e92\u8bc4\u4f30\uff0c\u6ee1\u8db3\u52a8\u6001\u3001\u900f\u660e\u3001\u5ba2\u89c2\u548c\u4e13\u4e1a\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "result": "\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u53d1\u73b0\u4e86\u4e00\u4e9b\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u68c0\u6d4b\u7684\u65b0\u73b0\u8c61\uff0c\u5982Gemini\u5728\u95ee\u9898\u8bbe\u8ba1\u80fd\u529b\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "LLM-Crowdsourced\u662f\u4e00\u79cd\u66f4\u5168\u9762\u3001\u53ef\u9760\u7684LLM\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u591f\u63ed\u793a\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u53d1\u73b0\u7684\u6027\u80fd\u5dee\u5f02\u548c\u73b0\u8c61\u3002"}}
{"id": "2507.22653", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.22653", "abs": "https://arxiv.org/abs/2507.22653", "authors": ["Weijie Xi", "Zhanxiang Cao", "Chenlin Ming", "Jianying Zheng", "Guyue Zhou"], "title": "UniLegs: Universal Multi-Legged Robot Control through Morphology-Agnostic Policy Distillation", "comment": "6 pages, 3 figures, IROS 2025", "summary": "Developing controllers that generalize across diverse robot morphologies\nremains a significant challenge in legged locomotion. Traditional approaches\neither create specialized controllers for each morphology or compromise\nperformance for generality. This paper introduces a two-stage teacher-student\nframework that bridges this gap through policy distillation. First, we train\nspecialized teacher policies optimized for individual morphologies, capturing\nthe unique optimal control strategies for each robot design. Then, we distill\nthis specialized expertise into a single Transformer-based student policy\ncapable of controlling robots with varying leg configurations. Our experiments\nacross five distinct legged morphologies demonstrate that our approach\npreserves morphology-specific optimal behaviors, with the Transformer\narchitecture achieving 94.47\\% of teacher performance on training morphologies\nand 72.64\\% on unseen robot designs. Comparative analysis reveals that\nTransformer-based architectures consistently outperform MLP baselines by\nleveraging attention mechanisms to effectively model joint relationships across\ndifferent kinematic structures. We validate our approach through successful\ndeployment on a physical quadruped robot, demonstrating the practical viability\nof our morphology-agnostic control framework. This work presents a scalable\nsolution for developing universal legged robot controllers that maintain\nnear-optimal performance while generalizing across diverse morphologies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u5e08\u751f\u6846\u67b6\uff0c\u901a\u8fc7\u7b56\u7565\u84b8\u998f\u5b9e\u73b0\u8de8\u591a\u6837\u673a\u5668\u4eba\u5f62\u6001\u7684\u901a\u7528\u63a7\u5236\u5668\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u817f\u5f0f\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u65e0\u6cd5\u517c\u987e\u901a\u7528\u6027\u548c\u6027\u80fd\u7684\u95ee\u9898\u3002", "method": "\u5148\u8bad\u7ec3\u9488\u5bf9\u7279\u5b9a\u5f62\u6001\u7684\u6559\u5e08\u7b56\u7565\uff0c\u518d\u901a\u8fc7Transformer\u67b6\u6784\u84b8\u998f\u4e3a\u901a\u7528\u5b66\u751f\u7b56\u7565\u3002", "result": "Transformer\u67b6\u6784\u5728\u8bad\u7ec3\u5f62\u6001\u4e0a\u8fbe\u5230\u6559\u5e08\u6027\u80fd\u768494.47%\uff0c\u5728\u672a\u89c1\u5f62\u6001\u4e0a\u8fbe\u523072.64%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u901a\u7528\u817f\u5f0f\u673a\u5668\u4eba\u63a7\u5236\u5668\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2507.22365", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.22365", "abs": "https://arxiv.org/abs/2507.22365", "authors": ["ZhaoBin Li", "Mark Steyvers"], "title": "Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making", "comment": "26 pages, 5 figures, submitted to Decision Analysis", "summary": "In settings where human decision-making relies on AI input, both the\npredictive accuracy of the AI system and the reliability of its confidence\nestimates influence decision quality. We highlight the role of AI metacognitive\nsensitivity -- its ability to assign confidence scores that accurately\ndistinguish correct from incorrect predictions -- and introduce a theoretical\nframework for assessing the joint impact of AI's predictive accuracy and\nmetacognitive sensitivity in hybrid decision-making settings. Our analysis\nidentifies conditions under which an AI with lower predictive accuracy but\nhigher metacognitive sensitivity can enhance the overall accuracy of human\ndecision making. Finally, a behavioral experiment confirms that greater AI\nmetacognitive sensitivity improves human decision performance. Together, these\nfindings underscore the importance of evaluating AI assistance not only by\naccuracy but also by metacognitive sensitivity, and of optimizing both to\nachieve superior decision outcomes.", "AI": {"tldr": "AI\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u5143\u8ba4\u77e5\u654f\u611f\u6027\u5171\u540c\u5f71\u54cd\u4eba\u7c7b\u51b3\u7b56\u8d28\u91cf\uff0c\u7814\u7a76\u53d1\u73b0\u5143\u8ba4\u77e5\u654f\u611f\u6027\u9ad8\u7684AI\u5373\u4f7f\u51c6\u786e\u6027\u8f83\u4f4e\uff0c\u4e5f\u80fd\u63d0\u5347\u51b3\u7b56\u8868\u73b0\u3002", "motivation": "\u63a2\u8ba8AI\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u5143\u8ba4\u77e5\u654f\u611f\u6027\u5728\u6df7\u5408\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u8054\u5408\u4f5c\u7528\uff0c\u4ee5\u4f18\u5316\u4eba\u7c7b\u51b3\u7b56\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u5206\u6790AI\u51c6\u786e\u6027\u4e0e\u5143\u8ba4\u77e5\u654f\u611f\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u884c\u4e3a\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\uff0c\u66f4\u9ad8\u7684AI\u5143\u8ba4\u77e5\u654f\u611f\u6027\u53ef\u663e\u8457\u63d0\u5347\u4eba\u7c7b\u51b3\u7b56\u8868\u73b0\u3002", "conclusion": "\u8bc4\u4f30AI\u8f85\u52a9\u65f6\u9700\u540c\u65f6\u8003\u8651\u51c6\u786e\u6027\u548c\u5143\u8ba4\u77e5\u654f\u611f\u6027\uff0c\u4f18\u5316\u4e24\u8005\u4ee5\u5b9e\u73b0\u66f4\u4f18\u51b3\u7b56\u7ed3\u679c\u3002"}}
{"id": "2507.22769", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.22769", "abs": "https://arxiv.org/abs/2507.22769", "authors": ["Satyesh Shanker Awasthi", "Mohammed Irshadh Ismaaeel Sathyamangalam Imran", "Stefano Arrigoni", "Francesco Braghin"], "title": "Bayesian Optimization applied for accelerated Virtual Validation of the Autonomous Driving Function", "comment": null, "summary": "Rigorous Verification and Validation (V&V) of Autonomous Driving Functions\n(ADFs) is paramount for ensuring the safety and public acceptance of Autonomous\nVehicles (AVs). Current validation relies heavily on simulation to achieve\nsufficient test coverage within the Operational Design Domain (ODD) of a\nvehicle, but exhaustively exploring the vast parameter space of possible\nscenarios is computationally expensive and time-consuming. This work introduces\na framework based on Bayesian Optimization (BO) to accelerate the discovery of\ncritical scenarios. We demonstrate the effectiveness of the framework on an\nModel Predictive Controller (MPC)-based motion planner, showing that it\nidentifies hazardous situations, such as off-road events, using orders of\nmagnitude fewer simulations than brute-force Design of Experiments (DoE)\nmethods. Furthermore, this study investigates the scalability of the framework\nin higher-dimensional parameter spaces and its ability to identify multiple,\ndistinct critical regions within the ODD of the motion planner used as the case\nstudy .", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\uff08BO\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u52a0\u901f\u81ea\u52a8\u9a7e\u9a76\u529f\u80fd\uff08ADF\uff09\u9a8c\u8bc1\u4e2d\u7684\u5173\u952e\u573a\u666f\u53d1\u73b0\uff0c\u663e\u8457\u51cf\u5c11\u6a21\u62df\u6b21\u6570\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff08AV\uff09\u9a8c\u8bc1\u4f9d\u8d56\u5927\u91cf\u6a21\u62df\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u8017\u65f6\uff0c\u4e9f\u9700\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\u7684\u8fd0\u52a8\u89c4\u5212\u5668\uff0c\u4ee5\u53d1\u73b0\u5371\u9669\u573a\u666f\u3002", "result": "\u6846\u67b6\u5728\u8f83\u5c11\u6a21\u62df\u6b21\u6570\u4e0b\u6210\u529f\u8bc6\u522b\u5371\u9669\u60c5\u51b5\uff08\u5982\u504f\u79bb\u9053\u8def\u4e8b\u4ef6\uff09\uff0c\u5e76\u5728\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u9ad8\u6548\u53d1\u73b0\u5173\u952e\u573a\u666f\uff0c\u9002\u7528\u4e8e\u590d\u6742\u81ea\u52a8\u9a7e\u9a76\u529f\u80fd\u9a8c\u8bc1\u3002"}}
{"id": "2507.22423", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22423", "abs": "https://arxiv.org/abs/2507.22423", "authors": ["Kei-Sing Ng"], "title": "On the Definition of Intelligence", "comment": "Accepted at AGI-25", "summary": "To engineer AGI, we should first capture the essence of intelligence in a\nspecies-agnostic form that can be evaluated, while being sufficiently general\nto encompass diverse paradigms of intelligent behavior, including reinforcement\nlearning, generative models, classification, analogical reasoning, and\ngoal-directed decision-making. We propose a general criterion based on sample\nfidelity: intelligence is the ability, given sample(s) from a category, to\ngenerate sample(s) from the same category. We formalise this intuition as\n{\\epsilon}-category intelligence: it is {\\epsilon}-intelligent with respect to\na category if no chosen admissible distinguisher can separate generated from\noriginal samples beyond tolerance {\\epsilon}. We present the formal framework,\noutline empirical protocols, and discuss implications for evaluation, safety,\nand generalization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6837\u672c\u4fdd\u771f\u5ea6\u7684\u901a\u7528\u667a\u80fd\u6807\u51c6\uff0c\u5373\u667a\u80fd\u662f\u7ed9\u5b9a\u7c7b\u522b\u6837\u672c\u540e\u751f\u6210\u540c\u7c7b\u6837\u672c\u7684\u80fd\u529b\uff0c\u5e76\u5f62\u5f0f\u5316\u4e3a\u03b5-\u7c7b\u522b\u667a\u80fd\u3002", "motivation": "\u4e3a\u4e86\u6784\u5efa\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8bc4\u4f30\u4e14\u6db5\u76d6\u591a\u79cd\u667a\u80fd\u884c\u4e3a\u8303\u5f0f\u7684\u667a\u80fd\u5b9a\u4e49\u3002", "method": "\u63d0\u51fa\u03b5-\u7c7b\u522b\u667a\u80fd\u6846\u67b6\uff0c\u901a\u8fc7\u6837\u672c\u751f\u6210\u80fd\u529b\u5b9a\u4e49\u667a\u80fd\uff0c\u5e76\u8bbe\u8ba1\u5b9e\u9a8c\u534f\u8bae\u9a8c\u8bc1\u3002", "result": "\u5f62\u5f0f\u5316\u6846\u67b6\u548c\u5b9e\u9a8c\u534f\u8bae\u4e3a\u667a\u80fd\u8bc4\u4f30\u3001\u5b89\u5168\u6027\u548c\u6cdb\u5316\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAGI\u7814\u7a76\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u5de5\u5177\u3002"}}
{"id": "2507.22432", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22432", "abs": "https://arxiv.org/abs/2507.22432", "authors": ["Zhe Yu", "Yiwei Lu", "Burkhard Schafer", "Zhe Lin"], "title": "Cross-Border Legal Adaptation of Autonomous Vehicle Design based on Logic and Non-monotonic Reasoning", "comment": "Accepted to appear in Proceedings of the 20th International\n  Conference on Artificial Intelligence and Law (ICAIL 2025)", "summary": "This paper focuses on the legal compliance challenges of autonomous vehicles\nin a transnational context. We choose the perspective of designers and try to\nprovide supporting legal reasoning in the design process. Based on\nargumentation theory, we introduce a logic to represent the basic properties of\nargument-based practical (normative) reasoning, combined with partial order\nsets of natural numbers to express priority. Finally, through case analysis of\nlegal texts, we show how the reasoning system we provide can help designers to\nadapt their design solutions more flexibly in the cross-border application of\nautonomous vehicles and to more easily understand the legal implications of\ntheir decisions.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u5728\u8de8\u56fd\u80cc\u666f\u4e0b\u7684\u6cd5\u5f8b\u5408\u89c4\u6311\u6218\uff0c\u4ece\u8bbe\u8ba1\u8005\u89d2\u5ea6\u51fa\u53d1\uff0c\u63d0\u4f9b\u652f\u6301\u6cd5\u5f8b\u63a8\u7406\u7684\u8bbe\u8ba1\u65b9\u6cd5\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u5728\u8de8\u56fd\u5e94\u7528\u4e2d\u9762\u4e34\u590d\u6742\u7684\u6cd5\u5f8b\u5408\u89c4\u95ee\u9898\uff0c\u8bbe\u8ba1\u8005\u9700\u8981\u5de5\u5177\u6765\u8f85\u52a9\u51b3\u7b56\u3002", "method": "\u57fa\u4e8e\u8bba\u8bc1\u7406\u8bba\uff0c\u5f15\u5165\u4e00\u79cd\u903b\u8f91\u8868\u793a\u89c4\u8303\u6027\u63a8\u7406\u7684\u57fa\u672c\u5c5e\u6027\uff0c\u5e76\u7ed3\u5408\u81ea\u7136\u6570\u7684\u504f\u5e8f\u96c6\u8868\u8fbe\u4f18\u5148\u7ea7\u3002", "result": "\u901a\u8fc7\u6cd5\u5f8b\u6587\u672c\u7684\u6848\u4f8b\u5206\u6790\uff0c\u5c55\u793a\u6240\u63d0\u63a8\u7406\u7cfb\u7edf\u5982\u4f55\u5e2e\u52a9\u8bbe\u8ba1\u8005\u7075\u6d3b\u8c03\u6574\u8bbe\u8ba1\u65b9\u6848\u5e76\u7406\u89e3\u6cd5\u5f8b\u5f71\u54cd\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u4e3a\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u8de8\u56fd\u5e94\u7528\u4e2d\u7684\u6cd5\u5f8b\u5408\u89c4\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u652f\u6301\u3002"}}
{"id": "2507.22440", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.22440", "abs": "https://arxiv.org/abs/2507.22440", "authors": ["Yiya Diao", "Changhe Li", "Sanyou Zeng", "Xinye Cai", "Wenjian Luo", "Shengxiang Yang", "Carlos A. Coello Coello"], "title": "Nearest-Better Network for Visualizing and Analyzing Combinatorial Optimization Problems: A Unified Tool", "comment": null, "summary": "The Nearest-Better Network (NBN) is a powerful method to visualize sampled\ndata for continuous optimization problems while preserving multiple landscape\nfeatures. However, the calculation of NBN is very time-consuming, and the\nextension of the method to combinatorial optimization problems is challenging\nbut very important for analyzing the algorithm's behavior. This paper provides\na straightforward theoretical derivation showing that the NBN network\nessentially functions as the maximum probability transition network for\nalgorithms. This paper also presents an efficient NBN computation method with\nlogarithmic linear time complexity to address the time-consuming issue. By\napplying this efficient NBN algorithm to the OneMax problem and the Traveling\nSalesman Problem (TSP), we have made several remarkable discoveries for the\nfirst time: The fitness landscape of OneMax exhibits neutrality, ruggedness,\nand modality features. The primary challenges of TSP problems are ruggedness,\nmodality, and deception. Two state-of-the-art TSP algorithms (i.e., EAX and\nLKH) have limitations when addressing challenges related to modality and\ndeception, respectively. LKH, based on local search operators, fails when there\nare deceptive solutions near global optima. EAX, which is based on a single\npopulation, can efficiently maintain diversity. However, when multiple\nattraction basins exist, EAX retains individuals within multiple basins\nsimultaneously, reducing inter-basin interaction efficiency and leading to\nalgorithm's stagnation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684NBN\u8ba1\u7b97\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u5176\u8ba1\u7b97\u8017\u65f6\u95ee\u9898\uff0c\u5e76\u9996\u6b21\u63ed\u793a\u4e86OneMax\u548cTSP\u95ee\u9898\u7684\u666f\u89c2\u7279\u5f81\u53ca\u7b97\u6cd5\u5c40\u9650\u6027\u3002", "motivation": "NBN\u65b9\u6cd5\u5728\u8fde\u7eed\u4f18\u5316\u95ee\u9898\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u8ba1\u7b97\u8017\u65f6\u4e14\u96be\u4ee5\u6269\u5c55\u81f3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u8bc1\u660eNBN\u4f5c\u4e3a\u6700\u5927\u6982\u7387\u8f6c\u79fb\u7f51\u7edc\u7684\u529f\u80fd\uff0c\u5e76\u63d0\u51fa\u5bf9\u6570\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u7684NBN\u8ba1\u7b97\u65b9\u6cd5\u3002", "result": "\u5e94\u7528\u4e8eOneMax\u548cTSP\u95ee\u9898\uff0c\u9996\u6b21\u53d1\u73b0OneMax\u7684\u4e2d\u7acb\u6027\u3001\u5d0e\u5c96\u6027\u548c\u6a21\u6001\u7279\u5f81\uff0c\u4ee5\u53caTSP\u7684\u5d0e\u5c96\u6027\u3001\u6a21\u6001\u6027\u548c\u6b3a\u9a97\u6027\u3002\u540c\u65f6\u63ed\u793a\u4e86EAX\u548cLKH\u7b97\u6cd5\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u9ad8\u6548\u7684NBN\u8ba1\u7b97\u65b9\u6cd5\u4e3a\u7b97\u6cd5\u884c\u4e3a\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u73b0\u6709\u7b97\u6cd5\u5728\u6a21\u6001\u548c\u6b3a\u9a97\u6027\u6311\u6218\u4e2d\u7684\u4e0d\u8db3\u3002"}}
{"id": "2507.22504", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22504", "abs": "https://arxiv.org/abs/2507.22504", "authors": ["Hongyan Cheng", "Chengzhang Yu", "Yanshu Shi", "Chiyue Wang", "Cong Liu", "Zhanpeng Jin"], "title": "Collaborative Medical Triage under Uncertainty: A Multi-Agent Dynamic Matching Approach", "comment": "10 pages, 8 figures, 2 table", "summary": "The post-pandemic surge in healthcare demand, coupled with critical nursing\nshortages, has placed unprecedented pressure on emergency department triage\nsystems, necessitating innovative AI-driven solutions. We present a multi-agent\ninteractive intelligent system for medical triage that addresses three\nfundamental challenges in current AI-based triage systems: insufficient medical\nspecialization leading to hallucination-induced misclassifications,\nheterogeneous department structures across healthcare institutions, and\ninefficient detail-oriented questioning that impedes rapid triage decisions.\nOur system employs three specialized agents - RecipientAgent, InquirerAgent,\nand DepartmentAgent - that collaborate through structured inquiry mechanisms\nand department-specific guidance rules to transform unstructured patient\nsymptoms into accurate department recommendations. To ensure robust evaluation,\nwe constructed a comprehensive Chinese medical triage dataset from a medical\nwebsite, comprising 3,360 real-world cases spanning 9 primary departments and\n62 secondary departments. Through systematic data imputation using large\nlanguage models, we address the prevalent issue of incomplete medical records\nin real-world data. Experimental results demonstrate that our multi-agent\nsystem achieves 89.2% accuracy in primary department classification and 73.9%\naccuracy in secondary department classification after four rounds of patient\ninteraction. The system's pattern-matching-based guidance mechanisms enable\nefficient adaptation to diverse hospital configurations while maintaining high\ntriage accuracy. Our work provides a scalable framework for deploying\nAI-assisted triage systems that can accommodate the organizational\nheterogeneity of healthcare institutions while ensuring clinically sound\ndecision-making.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4ee3\u7406\u4ea4\u4e92\u5f0f\u667a\u80fd\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u51b3\u533b\u7597\u5206\u8bca\u4e2dAI\u7cfb\u7edf\u7684\u4e09\u5927\u6311\u6218\uff1a\u533b\u5b66\u4e13\u4e1a\u6027\u4e0d\u8db3\u3001\u673a\u6784\u90e8\u95e8\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u4f4e\u6548\u63d0\u95ee\u3002\u7cfb\u7edf\u901a\u8fc7\u4e09\u4e2a\u4e13\u4e1a\u4ee3\u7406\u534f\u4f5c\uff0c\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u5ea6\u7684\u5206\u8bca\u63a8\u8350\u3002", "motivation": "\u75ab\u60c5\u540e\u533b\u7597\u9700\u6c42\u6fc0\u589e\u4e0e\u62a4\u7406\u4eba\u5458\u77ed\u7f3a\uff0c\u5bfc\u81f4\u6025\u8bca\u5206\u8bca\u7cfb\u7edf\u538b\u529b\u5de8\u5927\uff0c\u4e9f\u9700\u521b\u65b0\u7684AI\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u91c7\u7528RecipientAgent\u3001InquirerAgent\u548cDepartmentAgent\u4e09\u4e2a\u4ee3\u7406\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8be2\u95ee\u673a\u5236\u548c\u90e8\u95e8\u7279\u5b9a\u89c4\u5219\uff0c\u5c06\u60a3\u8005\u75c7\u72b6\u8f6c\u5316\u4e3a\u51c6\u786e\u7684\u5206\u8bca\u5efa\u8bae\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7cfb\u7edf\u5728\u56db\u6b21\u4ea4\u4e92\u540e\uff0c\u4e3b\u79d1\u5ba4\u5206\u7c7b\u51c6\u786e\u7387\u8fbe89.2%\uff0c\u6b21\u79d1\u5ba4\u5206\u7c7b\u51c6\u786e\u7387\u8fbe73.9%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3aAI\u8f85\u52a9\u5206\u8bca\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u9002\u5e94\u533b\u7597\u673a\u6784\u5f02\u8d28\u6027\u5e76\u786e\u4fdd\u4e34\u5e8a\u51b3\u7b56\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2507.22606", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22606", "abs": "https://arxiv.org/abs/2507.22606", "authors": ["Yaolun Zhang", "Xiaogeng Liu", "Chaowei Xiao"], "title": "MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines", "comment": "ICML 2025", "summary": "Large Language Models (LLMs) have demonstrated the ability to solve a wide\nrange of practical tasks within multi-agent systems. However, existing\nhuman-designed multi-agent frameworks are typically limited to a small set of\npre-defined scenarios, while current automated design methods suffer from\nseveral limitations, such as the lack of tool integration, dependence on\nexternal training data, and rigid communication structures. In this paper, we\npropose MetaAgent, a finite state machine based framework that can\nautomatically generate a multi-agent system. Given a task description,\nMetaAgent will design a multi-agent system and polish it through an\noptimization algorithm. When the multi-agent system is deployed, the finite\nstate machine will control the agent's actions and the state transitions. To\nevaluate our framework, we conduct experiments on both text-based tasks and\npractical tasks. The results indicate that the generated multi-agent system\nsurpasses other auto-designed methods and can achieve a comparable performance\nwith the human-designed multi-agent system, which is optimized for those\nspecific tasks.", "AI": {"tldr": "MetaAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u6709\u9650\u72b6\u6001\u673a\u7684\u6846\u67b6\uff0c\u80fd\u81ea\u52a8\u751f\u6210\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u7b97\u6cd5\u6539\u8fdb\uff0c\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u81ea\u52a8\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u63a5\u8fd1\u4eba\u5de5\u8bbe\u8ba1\u7684\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u5de5\u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5c40\u9650\u4e8e\u9884\u5b9a\u4e49\u573a\u666f\uff0c\u81ea\u52a8\u8bbe\u8ba1\u65b9\u6cd5\u5b58\u5728\u5de5\u5177\u96c6\u6210\u4e0d\u8db3\u3001\u4f9d\u8d56\u5916\u90e8\u6570\u636e\u3001\u901a\u4fe1\u7ed3\u6784\u50f5\u5316\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faMetaAgent\u6846\u67b6\uff0c\u57fa\u4e8e\u6709\u9650\u72b6\u6001\u673a\u81ea\u52a8\u751f\u6210\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u7b97\u6cd5\u4f18\u5316\u8bbe\u8ba1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u751f\u6210\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f18\u4e8e\u5176\u4ed6\u81ea\u52a8\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u6027\u80fd\u63a5\u8fd1\u4eba\u5de5\u8bbe\u8ba1\u7684\u7cfb\u7edf\u3002", "conclusion": "MetaAgent\u4e3a\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u81ea\u52a8\u8bbe\u8ba1\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2507.22619", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22619", "abs": "https://arxiv.org/abs/2507.22619", "authors": ["Sebastian Monka", "Irlan Grangel-Gonz\u00e1lez", "Stefan Schmid", "Lavdim Halilaj", "Marc Rickart", "Oliver Rudolph", "Rui Dias"], "title": "Enhancing Manufacturing Knowledge Access with LLMs and Context-aware Prompting", "comment": "European Conference on Artificial Intelligence (ECAI) 2024", "summary": "Knowledge graphs (KGs) have transformed data management within the\nmanufacturing industry, offering effective means for integrating disparate data\nsources through shared and structured conceptual schemas. However, harnessing\nthe power of KGs can be daunting for non-experts, as it often requires\nformulating complex SPARQL queries to retrieve specific information. With the\nadvent of Large Language Models (LLMs), there is a growing potential to\nautomatically translate natural language queries into the SPARQL format, thus\nbridging the gap between user-friendly interfaces and the sophisticated\narchitecture of KGs. The challenge remains in adequately informing LLMs about\nthe relevant context and structure of domain-specific KGs, e.g., in\nmanufacturing, to improve the accuracy of generated queries. In this paper, we\nevaluate multiple strategies that use LLMs as mediators to facilitate\ninformation retrieval from KGs. We focus on the manufacturing domain,\nparticularly on the Bosch Line Information System KG and the I40 Core\nInformation Model. In our evaluation, we compare various approaches for feeding\nrelevant context from the KG to the LLM and analyze their proficiency in\ntransforming real-world questions into SPARQL queries. Our findings show that\nLLMs can significantly improve their performance on generating correct and\ncomplete queries when provided only the adequate context of the KG schema. Such\ncontext-aware prompting techniques help LLMs to focus on the relevant parts of\nthe ontology and reduce the risk of hallucination. We anticipate that the\nproposed techniques help LLMs to democratize access to complex data\nrepositories and empower informed decision-making in manufacturing settings.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u81ea\u52a8\u8f6c\u6362\u4e3aSPARQL\u67e5\u8be2\uff0c\u4ee5\u7b80\u5316\u77e5\u8bc6\u56fe\u8c31\uff08KGs\uff09\u5728\u5236\u9020\u4e1a\u4e2d\u7684\u4f7f\u7528\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u5728\u5236\u9020\u4e1a\u4e2d\u6574\u5408\u6570\u636e\u6548\u679c\u663e\u8457\uff0c\u4f46\u975e\u4e13\u5bb6\u7528\u6237\u96be\u4ee5\u901a\u8fc7\u590d\u6742SPARQL\u67e5\u8be2\u83b7\u53d6\u4fe1\u606f\u3002LLMs\u7684\u6f5c\u529b\u5728\u4e8e\u89e3\u51b3\u8fd9\u4e00\u96be\u9898\u3002", "method": "\u8bc4\u4f30\u591a\u79cd\u7b56\u7565\uff0c\u5229\u7528LLMs\u4f5c\u4e3a\u4e2d\u4ecb\uff0c\u4ece\u5236\u9020\u4e1a\u77e5\u8bc6\u56fe\u8c31\uff08\u5982Bosch Line Information System KG\u548cI40 Core Information Model\uff09\u4e2d\u68c0\u7d22\u4fe1\u606f\u3002\u6bd4\u8f83\u4e0d\u540c\u4e0a\u4e0b\u6587\u8f93\u5165\u65b9\u6cd5\u5bf9LLMs\u751f\u6210SPARQL\u67e5\u8be2\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u63d0\u4f9b\u9002\u5f53\u7684KG\u4e0a\u4e0b\u6587\u53ef\u663e\u8457\u63d0\u5347LLMs\u751f\u6210\u51c6\u786e\u5b8c\u6574\u67e5\u8be2\u7684\u80fd\u529b\uff0c\u51cf\u5c11\u5e7b\u89c9\u98ce\u9669\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\u6280\u672f\u6709\u52a9\u4e8eLLMs\u66f4\u9ad8\u6548\u5730\u8bbf\u95ee\u590d\u6742\u6570\u636e\uff0c\u652f\u6301\u5236\u9020\u4e1a\u7684\u51b3\u7b56\u5236\u5b9a\u3002"}}
{"id": "2507.22774", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22774", "abs": "https://arxiv.org/abs/2507.22774", "authors": ["Thomas Eiter", "Tobias Geibinger", "Tobias Kaminski", "Nysret Musliu", "Johannes Oetsch"], "title": "ASP-FZN: A Translation-based Constraint Answer Set Solver", "comment": "Presented at the 41st International Conference on Logic Programming\n  (ICLP 2025)", "summary": "We present the solver asp-fzn for Constraint Answer Set Programming (CASP),\nwhich extends ASP with linear constraints. Our approach is based on translating\nCASP programs into the solver-independent FlatZinc language that supports\nseveral Constraint Programming and Integer Programming backend solvers. Our\nsolver supports a rich language of linear constraints, including some common\nglobal constraints. As for evaluation, we show that asp-fzn is competitive with\nstate-of-the-art ASP solvers on benchmarks taken from past ASP competitions.\nFurthermore, we evaluate it on several CASP problems from the literature and\ncompare its performance with clingcon, which is a prominent CASP solver that\nsupports most of the asp-fzn language. The performance of asp-fzn is very\npromising as it is already competitive on plain ASP and even outperforms\nclingcon on some CASP benchmarks.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86asp-fzn\u6c42\u89e3\u5668\uff0c\u7528\u4e8e\u7ea6\u675f\u7b54\u6848\u96c6\u7f16\u7a0b\uff08CASP\uff09\uff0c\u901a\u8fc7\u5c06CASP\u7a0b\u5e8f\u8f6c\u6362\u4e3aFlatZinc\u8bed\u8a00\uff0c\u652f\u6301\u591a\u79cd\u540e\u7aef\u6c42\u89e3\u5668\uff0c\u6027\u80fd\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u6269\u5c55ASP\u4ee5\u652f\u6301\u7ebf\u6027\u7ea6\u675f\uff0c\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u7ea6\u675f\u8bed\u8a00\uff0c\u5e76\u63d0\u5347\u6c42\u89e3\u6548\u7387\u3002", "method": "\u5c06CASP\u7a0b\u5e8f\u7ffb\u8bd1\u4e3aFlatZinc\u8bed\u8a00\uff0c\u5229\u7528\u591a\u79cd\u540e\u7aef\u6c42\u89e3\u5668\uff08\u5982\u7ea6\u675f\u89c4\u5212\u548c\u6574\u6570\u89c4\u5212\uff09\u8fdb\u884c\u5904\u7406\u3002", "result": "asp-fzn\u5728ASP\u7ade\u8d5b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u90e8\u5206CASP\u95ee\u9898\u4e0a\u751a\u81f3\u4f18\u4e8eclingcon\u3002", "conclusion": "asp-fzn\u662f\u4e00\u4e2a\u6709\u7ade\u4e89\u529b\u7684CASP\u6c42\u89e3\u5668\uff0c\u5c24\u5176\u5728\u652f\u6301\u7ebf\u6027\u7ea6\u675f\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.22782", "categories": ["cs.AI", "cs.LG", "I.2.0; I.2.8"], "pdf": "https://arxiv.org/pdf/2507.22782", "abs": "https://arxiv.org/abs/2507.22782", "authors": ["Hugo Garrido-Lestache", "Jeremy Kedziora"], "title": "Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies", "comment": "8 pages", "summary": "This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement\nlearning algorithm designed to enhance multi-agent collaboration in cooperative\nenvironments. TAAC employs a Centralized Training/Centralized Execution scheme\nincorporating multi-headed attention mechanisms in both the actor and critic.\nThis design facilitates dynamic, inter-agent communication, allowing agents to\nexplicitly query teammates, thereby efficiently managing the exponential growth\nof joint-action spaces while ensuring a high degree of collaboration. We\nfurther introduce a penalized loss function which promotes diverse yet\ncomplementary roles among agents. We evaluate TAAC in a simulated soccer\nenvironment against benchmark algorithms representing other multi-agent\nparadigms, including Proximal Policy Optimization and Multi-Agent\nActor-Attention-Critic. We find that TAAC exhibits superior performance and\nenhanced collaborative behaviors across a variety of metrics (win rates, goal\ndifferentials, Elo ratings, inter-agent connectivity, balanced spatial\ndistributions, and frequent tactical interactions such as ball possession\nswaps).", "AI": {"tldr": "TAAC\u662f\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u548c\u96c6\u4e2d\u8bad\u7ec3/\u6267\u884c\u65b9\u6848\u63d0\u5347\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u8054\u5408\u52a8\u4f5c\u7a7a\u95f4\u7206\u70b8\u548c\u52a8\u6001\u901a\u4fe1\u95ee\u9898\u3002", "method": "\u91c7\u7528\u96c6\u4e2d\u8bad\u7ec3/\u6267\u884c\u65b9\u6848\u548c\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5f15\u5165\u60e9\u7f5a\u635f\u5931\u51fd\u6570\u4fc3\u8fdb\u89d2\u8272\u591a\u6837\u6027\u3002", "result": "\u5728\u6a21\u62df\u8db3\u7403\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u7b97\u6cd5\uff0c\u534f\u4f5c\u884c\u4e3a\u663e\u8457\u63d0\u5347\u3002", "conclusion": "TAAC\u5728\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.22847", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.22847", "abs": "https://arxiv.org/abs/2507.22847", "authors": ["Han Jiang", "Pengda Wang", "Xiaoyuan Yi", "Xing Xie", "Ziang Xiao"], "title": "The Incomplete Bridge: How AI Research (Mis)Engages with Psychology", "comment": null, "summary": "Social sciences have accumulated a rich body of theories and methodologies\nfor investigating the human mind and behaviors, while offering valuable\ninsights into the design and understanding of Artificial Intelligence (AI)\nsystems. Focusing on psychology as a prominent case, this study explores the\ninterdisciplinary synergy between AI and the field by analyzing 1,006\nLLM-related papers published in premier AI venues between 2023 and 2025, along\nwith the 2,544 psychology publications they cite. Through our analysis, we\nidentify key patterns of interdisciplinary integration, locate the psychology\ndomains most frequently referenced, and highlight areas that remain\nunderexplored. We further examine how psychology theories/frameworks are\noperationalized and interpreted, identify common types of misapplication, and\noffer guidance for more effective incorporation. Our work provides a\ncomprehensive map of interdisciplinary engagement between AI and psychology,\nthereby facilitating deeper collaboration and advancing AI systems.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86AI\u4e0e\u5fc3\u7406\u5b66\u7684\u8de8\u5b66\u79d1\u6574\u5408\uff0c\u901a\u8fc7\u7814\u7a761006\u7bc7AI\u8bba\u6587\u548c2544\u7bc7\u5fc3\u7406\u5b66\u6587\u732e\uff0c\u63ed\u793a\u4e86\u5173\u952e\u6a21\u5f0f\u3001\u9ad8\u9891\u5f15\u7528\u9886\u57df\u53ca\u672a\u5145\u5206\u63a2\u7d22\u7684\u65b9\u5411\u3002", "motivation": "\u63a2\u7d22AI\u4e0e\u5fc3\u7406\u5b66\u7684\u8de8\u5b66\u79d1\u534f\u540c\uff0c\u4ee5\u5fc3\u7406\u5b66\u4e3a\u4f8b\uff0c\u63ed\u793a\u5982\u4f55\u66f4\u597d\u5730\u5c06\u5fc3\u7406\u5b66\u7406\u8bba\u5e94\u7528\u4e8eAI\u7cfb\u7edf\u8bbe\u8ba1\u3002", "method": "\u5206\u6790\u4e862023\u81f32025\u5e74\u95f4\u53d1\u8868\u76841006\u7bc7AI\u8bba\u6587\u53ca\u5176\u5f15\u7528\u76842544\u7bc7\u5fc3\u7406\u5b66\u6587\u732e\uff0c\u8bc6\u522b\u6574\u5408\u6a21\u5f0f\u3001\u9ad8\u9891\u9886\u57df\u53ca\u64cd\u4f5c\u5316\u65b9\u5f0f\u3002", "result": "\u63ed\u793a\u4e86\u5fc3\u7406\u5b66\u5728AI\u4e2d\u7684\u5e94\u7528\u6a21\u5f0f\uff0c\u6307\u51fa\u4e86\u5e38\u89c1\u8bef\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u66f4\u6709\u6548\u7684\u6574\u5408\u5efa\u8bae\u3002", "conclusion": "\u7814\u7a76\u4e3aAI\u4e0e\u5fc3\u7406\u5b66\u7684\u8de8\u5b66\u79d1\u5408\u4f5c\u63d0\u4f9b\u4e86\u5168\u9762\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8AI\u7cfb\u7edf\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2507.22876", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.22876", "abs": "https://arxiv.org/abs/2507.22876", "authors": ["Yiwen Sun", "Furong Ye", "Zhihan Chen", "Ke Wei", "Shaowei Cai"], "title": "Automatically discovering heuristics in a complex SAT solver with large language models", "comment": null, "summary": "Satisfiability problem (SAT) is a cornerstone of computational complexity\nwith broad industrial applications, and it remains challenging to optimize\nmodern SAT solvers in real-world settings due to their intricate architectures.\nWhile automatic configuration frameworks have been developed, they rely on\nmanually constrained search spaces and yield limited performance gains. This\nwork introduces a novel paradigm which effectively optimizes complex SAT\nsolvers via Large Language Models (LLMs), and a tool called AutoModSAT is\ndeveloped. Three fundamental challenges are addressed in order to achieve\nsuperior performance: (1) LLM-friendly solver: Systematic guidelines are\nproposed for developing a modularized solver to meet LLMs' compatibility,\nemphasizing code simplification, information share and bug reduction; (2)\nAutomatic prompt optimization: An unsupervised automatic prompt optimization\nmethod is introduced to advance the diversity of LLMs' output; (3) Efficient\nsearch strategy: We design a presearch strategy and an EA evolutionary\nalgorithm for the final efficient and effective discovery of heuristics.\nExtensive experiments across a wide range of datasets demonstrate that\nAutoModSAT achieves 50% performance improvement over the baseline solver and\nachieves 30% superiority against the state-of-the-art (SOTA) solvers. Moreover,\nAutoModSAT attains a 20% speedup on average compared to parameter-tuned\nalternatives of the SOTA solvers, showcasing the enhanced capability in\nhandling complex problem instances. This work bridges the gap between AI-driven\nheuristics discovery and mission-critical system optimization, and provides\nboth methodological advancements and empirically validated results for\nnext-generation complex solver development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f18\u5316\u590d\u6742SAT\u6c42\u89e3\u5668\u7684\u65b0\u8303\u5f0f\uff0c\u5f00\u53d1\u4e86\u5de5\u5177AutoModSAT\uff0c\u89e3\u51b3\u4e86\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u4ee3SAT\u6c42\u89e3\u5668\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u590d\u6742\u67b6\u6784\u5bfc\u81f4\u4f18\u5316\u56f0\u96be\u3002\u73b0\u6709\u81ea\u52a8\u914d\u7f6e\u6846\u67b6\u4f9d\u8d56\u624b\u52a8\u7ea6\u675f\u641c\u7d22\u7a7a\u95f4\uff0c\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002", "method": "1. \u8bbe\u8ba1LLM\u53cb\u597d\u7684\u6c42\u89e3\u5668\uff08\u4ee3\u7801\u7b80\u5316\u3001\u4fe1\u606f\u5171\u4eab\u3001\u51cf\u5c11\u9519\u8bef\uff09\uff1b2. \u81ea\u52a8\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff1b3. \u9ad8\u6548\u7684\u641c\u7d22\u7b56\u7565\uff08\u9884\u641c\u7d22\u548c\u8fdb\u5316\u7b97\u6cd5\uff09\u3002", "result": "AutoModSAT\u5728\u5b9e\u9a8c\u4e2d\u6bd4\u57fa\u7ebf\u6c42\u89e3\u5668\u6027\u80fd\u63d0\u534750%\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u6c42\u89e3\u566830%\uff0c\u901f\u5ea6\u5e73\u5747\u63d0\u534720%\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86AI\u9a71\u52a8\u542f\u53d1\u5f0f\u53d1\u73b0\u4e0e\u5173\u952e\u7cfb\u7edf\u4f18\u5316\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u590d\u6742\u6c42\u89e3\u5668\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u548c\u5b9e\u8bc1\u7ed3\u679c\u3002"}}
{"id": "2507.19647", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.19647", "abs": "https://arxiv.org/abs/2507.19647", "authors": ["Amin Banayeeanzade", "Fatemeh Bahrani", "Yutai Zhou", "Erdem B\u0131y\u0131k"], "title": "GABRIL: Gaze-Based Regularization for Mitigating Causal Confusion in Imitation Learning", "comment": "IROS 2025 camera-ready version. First two authors contributed equally", "summary": "Imitation Learning (IL) is a widely adopted approach which enables agents to\nlearn from human expert demonstrations by framing the task as a supervised\nlearning problem. However, IL often suffers from causal confusion, where agents\nmisinterpret spurious correlations as causal relationships, leading to poor\nperformance in testing environments with distribution shift. To address this\nissue, we introduce GAze-Based Regularization in Imitation Learning (GABRIL), a\nnovel method that leverages the human gaze data gathered during the data\ncollection phase to guide the representation learning in IL. GABRIL utilizes a\nregularization loss which encourages the model to focus on causally relevant\nfeatures identified through expert gaze and consequently mitigates the effects\nof confounding variables. We validate our approach in Atari environments and\nthe Bench2Drive benchmark in CARLA by collecting human gaze datasets and\napplying our method in both domains. Experimental results show that the\nimprovement of GABRIL over behavior cloning is around 179% more than the same\nnumber for other baselines in the Atari and 76% in the CARLA setup. Finally, we\nshow that our method provides extra explainability when compared to regular IL\nagents.", "AI": {"tldr": "GABRIL\u5229\u7528\u4eba\u7c7b\u6ce8\u89c6\u6570\u636e\u6539\u8fdb\u6a21\u4eff\u5b66\u4e60\uff0c\u901a\u8fc7\u6b63\u5219\u5316\u635f\u5931\u51cf\u5c11\u56e0\u679c\u6df7\u6dc6\uff0c\u63d0\u5347\u6d4b\u8bd5\u73af\u5883\u6027\u80fd\u3002", "motivation": "\u6a21\u4eff\u5b66\u4e60\u6613\u53d7\u56e0\u679c\u6df7\u6dc6\u5f71\u54cd\uff0c\u5bfc\u81f4\u5728\u5206\u5e03\u504f\u79fb\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6ce8\u89c6\u6570\u636e\u7684\u6b63\u5219\u5316\u635f\u5931\uff08GABRIL\uff09\uff0c\u6307\u5bfc\u6a21\u578b\u5173\u6ce8\u56e0\u679c\u76f8\u5173\u7279\u5f81\u3002", "result": "\u5728Atari\u548cCARLA\u5b9e\u9a8c\u4e2d\uff0cGABRIL\u5206\u522b\u6bd4\u57fa\u7ebf\u63d0\u5347179%\u548c76%\u3002", "conclusion": "GABRIL\u4e0d\u4ec5\u63d0\u5347\u6027\u80fd\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
