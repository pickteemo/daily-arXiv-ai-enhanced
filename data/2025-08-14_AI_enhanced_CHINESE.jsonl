{"id": "2508.09304", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.09304", "abs": "https://arxiv.org/abs/2508.09304", "authors": ["Kelen C. Teixeira Vivaldini", "Robert P\u011bni\u010dka", "Martin Saska"], "title": "Decision-Making-Based Path Planning for Autonomous UAVs: A Survey", "comment": null, "summary": "One of the most critical features for the successful operation of autonomous\nUAVs is the ability to make decisions based on the information acquired from\ntheir surroundings. Each UAV must be able to make decisions during the flight\nin order to deal with uncertainties in its system and the environment, and to\nfurther act upon the information being received. Such decisions influence the\nfuture behavior of the UAV, which is expressed as the path plan. Thus,\ndecision-making in path planning is an enabling technique for deploying\nautonomous UAVs in real-world applications. This survey provides an overview of\nexisting studies that use aspects of decision-making in path planning,\npresenting the research strands for Exploration Path Planning and Informative\nPath Planning, and focusing on characteristics of how data have been modeled\nand understood. Finally, we highlight the existing challenges for relevant\ntopics in this field.", "AI": {"tldr": "\u7efc\u8ff0\u63a2\u8ba8\u4e86\u81ea\u4e3b\u65e0\u4eba\u673a\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u51b3\u7b56\u65b9\u6cd5\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u63a2\u7d22\u8def\u5f84\u89c4\u5212\u548c\u4fe1\u606f\u8def\u5f84\u89c4\u5212\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u6307\u51fa\u4e86\u8be5\u9886\u57df\u7684\u6311\u6218\u3002", "motivation": "\u81ea\u4e3b\u65e0\u4eba\u673a\u9700\u6839\u636e\u73af\u5883\u4fe1\u606f\u505a\u51fa\u51b3\u7b56\u4ee5\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\uff0c\u51b3\u7b56\u80fd\u529b\u662f\u5176\u6210\u529f\u8fd0\u884c\u7684\u5173\u952e\u3002", "method": "\u7efc\u8ff0\u5206\u6790\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u51b3\u7b56\u65b9\u6cd5\u5728\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u6570\u636e\u5efa\u6a21\u548c\u7406\u89e3\u7684\u7279\u70b9\u3002", "result": "\u603b\u7ed3\u4e86\u63a2\u7d22\u8def\u5f84\u89c4\u5212\u548c\u4fe1\u606f\u8def\u5f84\u89c4\u5212\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u5e76\u5206\u6790\u4e86\u6570\u636e\u5efa\u6a21\u7684\u73b0\u72b6\u3002", "conclusion": "\u6307\u51fa\u4e86\u81ea\u4e3b\u65e0\u4eba\u673a\u8def\u5f84\u89c4\u5212\u51b3\u7b56\u9886\u57df\u7684\u73b0\u6709\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2508.09346", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.09346", "abs": "https://arxiv.org/abs/2508.09346", "authors": ["Zhenjiang Mao", "Mrinall Eashaan Umasudhan", "Ivan Ruchkin"], "title": "How Safe Will I Be Given What I Saw? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy", "comment": null, "summary": "Autonomous robots that rely on deep neural network controllers pose critical\nchallenges for safety prediction, especially under partial observability and\ndistribution shift. Traditional model-based verification techniques are limited\nin scalability and require access to low-dimensional state models, while\nmodel-free methods often lack reliability guarantees. This paper addresses\nthese limitations by introducing a framework for calibrated safety prediction\nin end-to-end vision-controlled systems, where neither the state-transition\nmodel nor the observation model is accessible. Building on the foundation of\nworld models, we leverage variational autoencoders and recurrent predictors to\nforecast future latent trajectories from raw image sequences and estimate the\nprobability of satisfying safety properties. We distinguish between monolithic\nand composite prediction pipelines and introduce a calibration mechanism to\nquantify prediction confidence. In long-horizon predictions from\nhigh-dimensional observations, the forecasted inputs to the safety evaluator\ncan deviate significantly from the training distribution due to compounding\nprediction errors and changing environmental conditions, leading to\nmiscalibrated risk estimates. To address this, we incorporate unsupervised\ndomain adaptation to ensure robustness of safety evaluation under distribution\nshift in predictions without requiring manual labels. Our formulation provides\ntheoretical calibration guarantees and supports practical evaluation across\nlong prediction horizons. Experimental results on three benchmarks show that\nour UDA-equipped evaluators maintain high accuracy and substantially lower\nfalse positive rates under distribution shift. Similarly, world model-based\ncomposite predictors outperform their monolithic counterparts on long-horizon\ntasks, and our conformal calibration provides reliable statistical bounds.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7aef\u5230\u7aef\u89c6\u89c9\u63a7\u5236\u7cfb\u7edf\u7684\u6821\u51c6\u5b89\u5168\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u4e16\u754c\u6a21\u578b\u548c\u57df\u9002\u5e94\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u5206\u5e03\u504f\u79fb\u548c\u957f\u65f6\u9884\u6d4b\u7684\u53ef\u9760\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u5b89\u5168\u9884\u6d4b\u6311\u6218\uff0c\u5f25\u8865\u4f20\u7edf\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "method": "\u5229\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u5faa\u73af\u9884\u6d4b\u5668\u9884\u6d4b\u6f5c\u5728\u8f68\u8ff9\uff0c\u7ed3\u5408\u57df\u9002\u5e94\u6280\u672f\u6821\u51c6\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u548c\u4f4e\u8bef\u62a5\u7387\uff0c\u957f\u65f6\u9884\u6d4b\u4efb\u52a1\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7aef\u5230\u7aef\u89c6\u89c9\u63a7\u5236\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u6821\u51c6\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u9884\u6d4b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2508.09354", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.09354", "abs": "https://arxiv.org/abs/2508.09354", "authors": ["Kejun Li", "Zachary Olkin", "Yisong Yue", "Aaron D. Ames"], "title": "CLF-RL: Control Lyapunov Function Guided Reinforcement Learning", "comment": "8 pages; 8 figures", "summary": "Reinforcement learning (RL) has shown promise in generating robust locomotion\npolicies for bipedal robots, but often suffers from tedious reward design and\nsensitivity to poorly shaped objectives. In this work, we propose a structured\nreward shaping framework that leverages model-based trajectory generation and\ncontrol Lyapunov functions (CLFs) to guide policy learning. We explore two\nmodel-based planners for generating reference trajectories: a reduced-order\nlinear inverted pendulum (LIP) model for velocity-conditioned motion planning,\nand a precomputed gait library based on hybrid zero dynamics (HZD) using\nfull-order dynamics. These planners define desired end-effector and joint\ntrajectories, which are used to construct CLF-based rewards that penalize\ntracking error and encourage rapid convergence. This formulation provides\nmeaningful intermediate rewards, and is straightforward to implement once a\nreference is available. Both the reference trajectories and CLF shaping are\nused only during training, resulting in a lightweight policy at deployment. We\nvalidate our method both in simulation and through extensive real-world\nexperiments on a Unitree G1 robot. CLF-RL demonstrates significantly improved\nrobustness relative to the baseline RL policy and better performance than a\nclassic tracking reward RL formulation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u8f68\u8ff9\u751f\u6210\u548c\u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\uff08CLF\uff09\u7684\u7ed3\u6784\u5316\u5956\u52b1\u6846\u67b6\uff0c\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7b56\u7565\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u53cc\u8db3\u673a\u5668\u4eba\u7684\u8fd0\u52a8\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edfRL\u5728\u53cc\u8db3\u673a\u5668\u4eba\u8fd0\u52a8\u7b56\u7565\u751f\u6210\u4e2d\u5e38\u9762\u4e34\u5956\u52b1\u8bbe\u8ba1\u7e41\u7410\u548c\u76ee\u6807\u654f\u611f\u6027\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u5956\u52b1\u5851\u9020\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u6a21\u578b\u89c4\u5212\u5668\uff08LIP\u6a21\u578b\u548cHZD\u6b65\u6001\u5e93\uff09\u751f\u6210\u53c2\u8003\u8f68\u8ff9\uff0c\u5e76\u57fa\u4e8eCLF\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\uff0c\u60e9\u7f5a\u8ddf\u8e2a\u8bef\u5dee\u5e76\u9f13\u52b1\u5feb\u901f\u6536\u655b\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u4e2d\uff0cCLF-RL\u65b9\u6cd5\u6bd4\u57fa\u7ebfRL\u7b56\u7565\u548c\u7ecf\u5178\u8ddf\u8e2a\u5956\u52b1RL\u8868\u73b0\u66f4\u4f18\uff0c\u9c81\u68d2\u6027\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u7ed3\u6784\u5316\u5956\u52b1\u6846\u67b6\u4e3aRL\u7b56\u7565\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u6307\u5bfc\uff0c\u4e14\u90e8\u7f72\u65f6\u4ec5\u9700\u8f7b\u91cf\u7ea7\u7b56\u7565\uff0c\u5b9e\u7528\u6027\u9ad8\u3002"}}
{"id": "2508.09444", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09444", "abs": "https://arxiv.org/abs/2508.09444", "authors": ["Haoxiang Shi", "Xiang Deng", "Zaijing Li", "Gongwei Chen", "Yaowei Wang", "Liqiang Nie"], "title": "DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation", "comment": null, "summary": "Vision-Language Navigation in Continuous Environments (VLN-CE) requires\nagents to follow natural language instructions through free-form 3D spaces.\nExisting VLN-CE approaches typically use a two-stage waypoint planning\nframework, where a high-level waypoint predictor generates the navigable\nwaypoints, and then a navigation planner suggests the intermediate goals in the\nhigh-level action space. However, this two-stage decomposition framework\nsuffers from: (1) global sub-optimization due to the proxy objective in each\nstage, and (2) a performance bottleneck caused by the strong reliance on the\nquality of the first-stage predicted waypoints. To address these limitations,\nwe propose DAgger Diffusion Navigation (DifNav), an end-to-end optimized VLN-CE\npolicy that unifies the traditional two stages, i.e. waypoint generation and\nplanning, into a single diffusion policy. Notably, DifNav employs a conditional\ndiffusion policy to directly model multi-modal action distributions over future\nactions in continuous navigation space, eliminating the need for a waypoint\npredictor while enabling the agent to capture multiple possible\ninstruction-following behaviors. To address the issues of compounding error in\nimitation learning and enhance spatial reasoning in long-horizon navigation\ntasks, we employ DAgger for online policy training and expert trajectory\naugmentation, and use the aggregated data to further fine-tune the policy. This\napproach significantly improves the policy's robustness and its ability to\nrecover from error states. Extensive experiments on benchmark datasets\ndemonstrate that, even without a waypoint predictor, the proposed method\nsubstantially outperforms previous state-of-the-art two-stage waypoint-based\nmodels in terms of navigation performance. Our code is available at:\nhttps://github.com/Tokishx/DifNav.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDifNav\u7684\u7aef\u5230\u7aef\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u8fde\u7eed\u73af\u5883\u4e2d\u7684\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u95ee\u9898\uff0c\u901a\u8fc7\u7edf\u4e00\u4f20\u7edf\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff08\u8def\u5f84\u70b9\u751f\u6210\u4e0e\u89c4\u5212\uff09\u4e3a\u5355\u4e00\u6269\u6563\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bfc\u822a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4e24\u9636\u6bb5\u8def\u5f84\u70b9\u89c4\u5212\u6846\u67b6\u5b58\u5728\u5168\u5c40\u6b21\u4f18\u5316\u548c\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5bfc\u822a\u6548\u679c\u3002", "method": "\u91c7\u7528\u6761\u4ef6\u6269\u6563\u7b56\u7565\u76f4\u63a5\u5efa\u6a21\u8fde\u7eed\u5bfc\u822a\u7a7a\u95f4\u4e2d\u7684\u591a\u6a21\u6001\u52a8\u4f5c\u5206\u5e03\uff0c\u7ed3\u5408DAgger\u8fdb\u884c\u5728\u7ebf\u7b56\u7565\u8bad\u7ec3\u548c\u4e13\u5bb6\u8f68\u8ff9\u589e\u5f3a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDifNav\u5728\u5bfc\u822a\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u4e24\u9636\u6bb5\u6a21\u578b\u3002", "conclusion": "DifNav\u901a\u8fc7\u7aef\u5230\u7aef\u4f18\u5316\u548c\u6269\u6563\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u6846\u67b6\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u4e86\u5bfc\u822a\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2508.09277", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.09277", "abs": "https://arxiv.org/abs/2508.09277", "authors": ["Soumia Mehimeh"], "title": "Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning", "comment": null, "summary": "Value function initialization (VFI) is an effective way to achieve a\njumpstart in reinforcement learning (RL) by leveraging value estimates from\nprior tasks. While this approach is well established in tabular settings,\nextending it to deep reinforcement learning (DRL) poses challenges due to the\ncontinuous nature of the state-action space, the noisy approximations of neural\nnetworks, and the impracticality of storing all past models for reuse. In this\nwork, we address these challenges and introduce DQInit, a method that adapts\nvalue function initialization to DRL. DQInit reuses compact tabular Q-values\nextracted from previously solved tasks as a transferable knowledge base. It\nemploys a knownness-based mechanism to softly integrate these transferred\nvalues into underexplored regions and gradually shift toward the agent's\nlearned estimates, avoiding the limitations of fixed time decay. Our approach\noffers a novel perspective on knowledge transfer in DRL by relying solely on\nvalue estimates rather than policies or demonstrations, effectively combining\nthe strengths of jumpstart RL and policy distillation while mitigating their\ndrawbacks. Experiments across multiple continuous control tasks demonstrate\nthat DQInit consistently improves early learning efficiency, stability, and\noverall performance compared to standard initialization and existing transfer\ntechniques.", "AI": {"tldr": "DQInit\u662f\u4e00\u79cd\u5c06\u503c\u51fd\u6570\u521d\u59cb\u5316\uff08VFI\uff09\u6269\u5c55\u5230\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u7528\u5148\u524d\u4efb\u52a1\u7684\u7d27\u51d1\u8868\u683cQ\u503c\u4f5c\u4e3a\u53ef\u8f6c\u79fb\u77e5\u8bc6\u5e93\uff0c\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u5728DRL\u4e2d\u6269\u5c55VFI\u9762\u4e34\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u7684\u8fde\u7eed\u6027\u3001\u795e\u7ecf\u7f51\u7edc\u566a\u58f0\u8fd1\u4f3c\u4ee5\u53ca\u5b58\u50a8\u6240\u6709\u8fc7\u53bb\u6a21\u578b\u7684\u4e0d\u5207\u5b9e\u9645\u6027\u7b49\u6311\u6218\u3002", "method": "DQInit\u4f7f\u7528\u57fa\u4e8e\u5df2\u77e5\u5ea6\u7684\u673a\u5236\uff0c\u5c06\u8f6c\u79fb\u7684\u503c\u8f6f\u6027\u6574\u5408\u5230\u672a\u63a2\u7d22\u533a\u57df\uff0c\u5e76\u9010\u6b65\u8f6c\u5411\u4ee3\u7406\u7684\u5b66\u4e60\u4f30\u8ba1\uff0c\u907f\u514d\u56fa\u5b9a\u65f6\u95f4\u8870\u51cf\u7684\u9650\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDQInit\u5728\u591a\u4e2a\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u65e9\u671f\u5b66\u4e60\u6548\u7387\u3001\u7a33\u5b9a\u6027\u548c\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "DQInit\u4e3aDRL\u4e2d\u7684\u77e5\u8bc6\u8f6c\u79fb\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u4ec5\u4f9d\u8d56\u503c\u4f30\u8ba1\u800c\u975e\u7b56\u7565\u6216\u6f14\u793a\uff0c\u6709\u6548\u7ed3\u5408\u4e86\u8df3\u542f\u52a8RL\u548c\u7b56\u7565\u84b8\u998f\u7684\u4f18\u52bf\u3002"}}
{"id": "2508.09502", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.09502", "abs": "https://arxiv.org/abs/2508.09502", "authors": ["Junheon Yoon", "Woo-Jeong Baek", "Jaeheung Park"], "title": "Reactive Model Predictive Contouring Control for Robot Manipulators", "comment": "8 pages, 7 figures, 3 tables, conference paper, Accepted for\n  publication at IEEE/RSJ International Conference on Intelligent Robots and\n  Systems(IROS) 2025", "summary": "This contribution presents a robot path-following framework via Reactive\nModel Predictive Contouring Control (RMPCC) that successfully avoids obstacles,\nsingularities and self-collisions in dynamic environments at 100 Hz. Many\npath-following methods rely on the time parametrization, but struggle to handle\ncollision and singularity avoidance while adhering kinematic limits or other\nconstraints. Specifically, the error between the desired path and the actual\nposition can become large when executing evasive maneuvers. Thus, this paper\nderives a method that parametrizes the reference path by a path parameter and\nperforms the optimization via RMPCC. In particular, Control Barrier Functions\n(CBFs) are introduced to avoid collisions and singularities in dynamic\nenvironments. A Jacobian-based linearization and Gauss-Newton Hessian\napproximation enable solving the nonlinear RMPCC problem at 100 Hz,\noutperforming state-of-the-art methods by a factor of 10. Experiments confirm\nthat the framework handles dynamic obstacles in real-world settings with low\ncontouring error and low robot acceleration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cd\u5e94\u5f0f\u6a21\u578b\u9884\u6d4b\u8f6e\u5ed3\u63a7\u5236\uff08RMPCC\uff09\u7684\u673a\u5668\u4eba\u8def\u5f84\u8ddf\u8e2a\u6846\u67b6\uff0c\u80fd\u591f\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4ee5100 Hz\u7684\u9891\u7387\u6210\u529f\u907f\u5f00\u969c\u788d\u7269\u3001\u5947\u5f02\u70b9\u548c\u81ea\u78b0\u649e\u3002", "motivation": "\u73b0\u6709\u8def\u5f84\u8ddf\u8e2a\u65b9\u6cd5\u4f9d\u8d56\u65f6\u95f4\u53c2\u6570\u5316\uff0c\u96be\u4ee5\u540c\u65f6\u5904\u7406\u78b0\u649e\u548c\u5947\u5f02\u70b9\u907f\u514d\uff0c\u4e14\u5728\u8fd0\u52a8\u9650\u5236\u4e0b\u6267\u884c\u89c4\u907f\u52a8\u4f5c\u65f6\u8bef\u5dee\u8f83\u5927\u3002", "method": "\u901a\u8fc7\u8def\u5f84\u53c2\u6570\u5316\u53c2\u8003\u8def\u5f84\uff0c\u5e76\u5229\u7528RMPCC\u8fdb\u884c\u4f18\u5316\uff0c\u5f15\u5165\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff08CBFs\uff09\u907f\u514d\u78b0\u649e\u548c\u5947\u5f02\u70b9\uff0c\u91c7\u7528\u96c5\u53ef\u6bd4\u7ebf\u6027\u5316\u548c\u9ad8\u65af-\u725b\u987f\u6d77\u68ee\u8fd1\u4f3c\u5b9e\u73b0\u975e\u7ebf\u6027RMPCC\u95ee\u9898\u7684\u5feb\u901f\u6c42\u89e3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8f6e\u5ed3\u8bef\u5dee\u548c\u673a\u5668\u4eba\u52a0\u901f\u5ea6\u5747\u8f83\u4f4e\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd510\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u4f4e\u8bef\u5dee\u7684\u8def\u5f84\u8ddf\u8e2a\uff0c\u4e3a\u673a\u5668\u4eba\u5bfc\u822a\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.09292", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09292", "abs": "https://arxiv.org/abs/2508.09292", "authors": ["Sundong Kim"], "title": "The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards", "comment": null, "summary": "The ability to rapidly adapt to novel and unforeseen environmental changes is\na cornerstone of artificial general intelligence (AGI), yet it remains a\ncritical blind spot in most existing AI benchmarks. Traditional evaluation\nlargely focuses on optimizing performance within fixed environments, failing to\nassess systems' flexibility and generalization capabilities when faced with\neven subtle rule or structural modifications. Addressing this gap, I introduce\nthe Othello AI Arena, a novel benchmark framework designed to evaluate\nintelligent systems based on their capacity for limited-time adaptation to\nunseen environments. Our platform poses a meta-learning challenge: participants\nmust develop systems that can analyze the specific configuration and rules of a\nnovel Othello board within a strict time limit (60 seconds) and generate a\ntailored, high-performing strategy for that unique environment. With this,\nevaluation of the meta-level intelligence can be separated from the task-level\nstrategy performance. The Arena features a diverse set of game stages,\nincluding public stages for development and private stages with structural and\nrule variations designed to test genuine adaptive and generalization\ncapabilities. Implemented as an accessible web-based platform, the Arena\nprovides real-time visualization, automated evaluation using multi-dimensional\nmetrics, and comprehensive logging for post-hoc analysis. Initial observations\nfrom pilot tests and preliminary student engagements highlight fascinating\npatterns in adaptation approaches, ranging from rapid parameter tuning to\nrudimentary environmental model learning through simulation. The Othello AI\nArena offers a unique educational tool and a valuable research benchmark for\nfostering and evaluating the crucial skill of rapid, intelligent adaptation in\nAI systems.", "AI": {"tldr": "Othello AI Arena\u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u6709\u9650\u65f6\u95f4\u5185\u9002\u5e94\u65b0\u73af\u5883\u7684\u80fd\u529b\uff0c\u5f3a\u8c03\u5feb\u901f\u9002\u5e94\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709AI\u57fa\u51c6\u5927\u591a\u5173\u6ce8\u56fa\u5b9a\u73af\u5883\u4e0b\u7684\u6027\u80fd\u4f18\u5316\uff0c\u7f3a\u4e4f\u5bf9\u7cfb\u7edf\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u5c24\u5176\u662f\u5728\u89c4\u5219\u6216\u7ed3\u6784\u53d8\u5316\u65f6\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8eOthello\u6e38\u620f\u7684\u5e73\u53f0\uff0c\u8981\u6c42AI\u572860\u79d2\u5185\u5206\u6790\u65b0\u68cb\u76d8\u914d\u7f6e\u5e76\u751f\u6210\u5b9a\u5236\u7b56\u7565\uff0c\u901a\u8fc7\u516c\u5f00\u548c\u79c1\u6709\u9636\u6bb5\u6d4b\u8bd5\u9002\u5e94\u80fd\u529b\u3002", "result": "\u521d\u6b65\u6d4b\u8bd5\u663e\u793aAI\u7cfb\u7edf\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u9002\u5e94\u7b56\u7565\uff0c\u5982\u5feb\u901f\u53c2\u6570\u8c03\u6574\u548c\u6a21\u62df\u5b66\u4e60\u3002", "conclusion": "Othello AI Arena\u4e3a\u8bc4\u4f30\u548c\u57f9\u517bAI\u5feb\u901f\u9002\u5e94\u80fd\u529b\u63d0\u4f9b\u4e86\u72ec\u7279\u7684\u6559\u80b2\u5de5\u5177\u548c\u7814\u7a76\u57fa\u51c6\u3002"}}
{"id": "2508.09508", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09508", "abs": "https://arxiv.org/abs/2508.09508", "authors": ["Reema Raval", "Shalabh Gupta"], "title": "SMART-OC: A Real-time Time-risk Optimal Replanning Algorithm for Dynamic Obstacles and Spatio-temporally Varying Currents", "comment": null, "summary": "Typical marine environments are highly complex with spatio-temporally varying\ncurrents and dynamic obstacles, presenting significant challenges to Unmanned\nSurface Vehicles (USVs) for safe and efficient navigation. Thus, the USVs need\nto continuously adapt their paths with real-time information to avoid\ncollisions and follow the path of least resistance to the goal via exploiting\nocean currents. In this regard, we introduce a novel algorithm, called\nSelf-Morphing Adaptive Replanning Tree for dynamic Obstacles and Currents\n(SMART-OC), that facilitates real-time time-risk optimal replanning in dynamic\nenvironments. SMART-OC integrates the obstacle risks along a path with the time\ncost to reach the goal to find the time-risk optimal path. The effectiveness of\nSMART-OC is validated by simulation experiments, which demonstrate that the USV\nperforms fast replannings to avoid dynamic obstacles and exploit ocean currents\nto successfully reach the goal.", "AI": {"tldr": "SMART-OC\u7b97\u6cd5\u4e3a\u65e0\u4eba\u6c34\u9762\u8247\uff08USV\uff09\u5728\u52a8\u6001\u6d77\u6d0b\u73af\u5883\u4e2d\u63d0\u4f9b\u5b9e\u65f6\u65f6\u95f4-\u98ce\u9669\u6700\u4f18\u8def\u5f84\u89c4\u5212\uff0c\u7ed3\u5408\u969c\u788d\u7269\u98ce\u9669\u548c\u65f6\u95f4\u6210\u672c\uff0c\u5b9e\u73b0\u9ad8\u6548\u5bfc\u822a\u3002", "motivation": "\u6d77\u6d0b\u73af\u5883\u590d\u6742\u591a\u53d8\uff0c\u5b58\u5728\u52a8\u6001\u969c\u788d\u7269\u548c\u6d0b\u6d41\uff0cUSV\u9700\u8981\u5b9e\u65f6\u8c03\u6574\u8def\u5f84\u4ee5\u786e\u4fdd\u5b89\u5168\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faSMART-OC\u7b97\u6cd5\uff0c\u6574\u5408\u8def\u5f84\u4e0a\u7684\u969c\u788d\u7269\u98ce\u9669\u4e0e\u65f6\u95f4\u6210\u672c\uff0c\u8fdb\u884c\u5b9e\u65f6\u65f6\u95f4-\u98ce\u9669\u6700\u4f18\u8def\u5f84\u89c4\u5212\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1SMART-OC\u7684\u6709\u6548\u6027\uff0cUSV\u80fd\u5feb\u901f\u91cd\u65b0\u89c4\u5212\u8def\u5f84\u4ee5\u907f\u5f00\u969c\u788d\u7269\u5e76\u5229\u7528\u6d0b\u6d41\u5230\u8fbe\u76ee\u6807\u3002", "conclusion": "SMART-OC\u4e3aUSV\u5728\u52a8\u6001\u6d77\u6d0b\u73af\u5883\u4e2d\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u5b89\u5168\u7684\u5bfc\u822a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09507", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09507", "abs": "https://arxiv.org/abs/2508.09507", "authors": ["Meiping Wang", "Jian Zhong", "Rongduo Han", "Liming Kang", "Zhengkun Shi", "Xiao Liang", "Xing Lin", "Nan Gao", "Haining Zhang"], "title": "An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants", "comment": null, "summary": "With the rapid development of mobile intelligent assistant technologies,\nmulti-modal AI assistants have become essential interfaces for daily user\ninteractions. However, current evaluation methods face challenges including\nhigh manual costs, inconsistent standards, and subjective bias. This paper\nproposes an automated multi-modal evaluation framework based on large language\nmodels and multi-agent collaboration. The framework employs a three-tier agent\narchitecture consisting of interaction evaluation agents, semantic verification\nagents, and experience decision agents. Through supervised fine-tuning on the\nQwen3-8B model, we achieve a significant evaluation matching accuracy with\nhuman experts. Experimental results on eight major intelligent agents\ndemonstrate the framework's effectiveness in predicting users' satisfaction and\nidentifying generation defects.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u81ea\u52a8\u5316\u591a\u6a21\u6001\u8bc4\u4f30\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u7684\u9ad8\u6210\u672c\u3001\u6807\u51c6\u4e0d\u4e00\u81f4\u548c\u4e3b\u89c2\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u79fb\u52a8\u667a\u80fd\u52a9\u624b\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u591a\u6a21\u6001AI\u52a9\u624b\u6210\u4e3a\u65e5\u5e38\u7528\u6237\u4ea4\u4e92\u7684\u91cd\u8981\u63a5\u53e3\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u9ad8\u4eba\u5de5\u6210\u672c\u3001\u6807\u51c6\u4e0d\u4e00\u81f4\u548c\u4e3b\u89c2\u504f\u89c1\u7b49\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e09\u5c42\u667a\u80fd\u4f53\u67b6\u6784\uff08\u4ea4\u4e92\u8bc4\u4f30\u3001\u8bed\u4e49\u9a8c\u8bc1\u548c\u4f53\u9a8c\u51b3\u7b56\u667a\u80fd\u4f53\uff09\uff0c\u5e76\u5728Qwen3-8B\u6a21\u578b\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u3002", "result": "\u5728\u516b\u5927\u667a\u80fd\u52a9\u624b\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u6709\u6548\u9884\u6d4b\u7528\u6237\u6ee1\u610f\u5ea6\u5e76\u8bc6\u522b\u751f\u6210\u7f3a\u9677\uff0c\u8bc4\u4f30\u5339\u914d\u51c6\u786e\u7387\u663e\u8457\u3002", "conclusion": "\u8be5\u81ea\u52a8\u5316\u6846\u67b6\u4e3a\u591a\u6a21\u6001AI\u52a9\u624b\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u4e00\u81f4\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09558", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09558", "abs": "https://arxiv.org/abs/2508.09558", "authors": ["Jiahui Zuo", "Boyang Zhang", "Fumin Zhang"], "title": "CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail", "comment": null, "summary": "The manipulation of deformable linear flexures has a wide range of\napplications in industry, such as cable routing in automotive manufacturing and\ntextile production. Cable routing, as a complex multi-stage robot manipulation\nscenario, is a challenging task for robot automation. Common parallel\ntwo-finger grippers have the risk of over-squeezing and over-tension when\ngrasping and guiding cables. In this paper, a novel eagle-inspired fingernail\nis designed and mounted on the gripper fingers, which helps with cable grasping\non planar surfaces and in-hand cable guiding operations. Then we present a\nsingle-grasp end-to-end 3D cable routing framework utilizing the proposed\nfingernails, instead of the common pick-and-place strategy. Continuous control\nis achieved to efficiently manipulate cables through vision-based state\nestimation of task configurations and offline trajectory planning based on\nmotion primitives. We evaluate the effectiveness of the proposed framework with\na variety of cables and channel slots, significantly outperforming the\npick-and-place manipulation process under equivalent perceptual conditions. Our\nreconfigurable task setting and the proposed framework provide a reference for\nfuture cable routing manipulations in 3D space.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u9e70\u722a\u542f\u53d1\u7684\u673a\u68b0\u722a\u8bbe\u8ba1\uff0c\u7528\u4e8e\u7535\u7f06\u6293\u53d6\u548c\u5f15\u5bfc\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u76843D\u7535\u7f06\u5e03\u7ebf\u6846\u67b6\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u62fe\u53d6\u653e\u7f6e\u7b56\u7565\u3002", "motivation": "\u5de5\u4e1a\u4e2d\u7535\u7f06\u5e03\u7ebf\u7b49\u67d4\u6027\u7ebf\u6027\u7ed3\u6784\u7684\u64cd\u4f5c\u590d\u6742\uff0c\u4f20\u7edf\u673a\u68b0\u722a\u6613\u5bfc\u81f4\u7535\u7f06\u8fc7\u5ea6\u6324\u538b\u6216\u5f20\u529b\u8fc7\u5927\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u9e70\u722a\u542f\u53d1\u7684\u673a\u68b0\u722a\uff0c\u7ed3\u5408\u57fa\u4e8e\u89c6\u89c9\u7684\u72b6\u6001\u4f30\u8ba1\u548c\u79bb\u7ebf\u8f68\u8ff9\u89c4\u5212\uff0c\u5b9e\u73b0\u8fde\u7eed\u63a7\u5236\u7684\u7aef\u5230\u7aef3D\u7535\u7f06\u5e03\u7ebf\u3002", "result": "\u5728\u591a\u79cd\u7535\u7f06\u548c\u69fd\u9053\u6d4b\u8bd5\u4e2d\uff0c\u63d0\u51fa\u7684\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u62fe\u53d6\u653e\u7f6e\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u672a\u67653D\u7a7a\u95f4\u7535\u7f06\u5e03\u7ebf\u64cd\u4f5c\u63d0\u4f9b\u4e86\u53c2\u8003\uff0c\u5c55\u793a\u4e86\u9ad8\u6548\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2508.09586", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09586", "abs": "https://arxiv.org/abs/2508.09586", "authors": ["Yang Cheng", "Zilai Wang", "Weiyu Ma", "Wenhui Zhu", "Yue Deng", "Jian Zhao"], "title": "EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ndiverse domains, including programming, planning, and decision-making. However,\ntheir performance often degrades when faced with highly complex problem\ninstances that require deep reasoning over long horizons. In such cases, direct\nproblem-solving approaches can lead to inefficiency or failure due to the lack\nof structured intermediate guidance. To address this, we propose a novel\nself-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM\nconstructs a sequence of problem instances with gradually increasing\ndifficulty, tailored to the solver LLM's learning progress. The curriculum\ndynamically adapts easing challenges when the solver struggles and escalating\nthem when success is consistent, thus maintaining an optimal learning\ntrajectory. This approach enables the solver LLM, implemented as a\ncode-generation model producing Python decision-tree scripts, to progressively\nacquire the skills needed for complex decision-making tasks. Experimental\nresults on challenging decision-making benchmarks show that our method\nsignificantly improves task success rates and solution efficiency compared to\ndirect-solving baselines. These findings suggest that LLM-driven curriculum\nlearning holds strong potential for enhancing automated reasoning in\nreal-world, high-complexity domains.", "AI": {"tldr": "EvoCurr\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u95ee\u9898\u96be\u5ea6\uff0c\u63d0\u5347LLM\u5728\u590d\u6742\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u590d\u6742\u95ee\u9898\u4e2d\u56e0\u7f3a\u4e4f\u7ed3\u6784\u5316\u6307\u5bfc\u800c\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u4e13\u95e8\u7684\u8bfe\u7a0b\u751f\u6210LLM\u6784\u5efa\u9010\u6b65\u589e\u52a0\u96be\u5ea6\u7684\u95ee\u9898\u5e8f\u5217\uff0c\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u8fdb\u5ea6\u3002", "result": "\u5b9e\u9a8c\u663e\u793aEvoCurr\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\u548c\u89e3\u51b3\u6548\u7387\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u8bfe\u7a0b\u5b66\u4e60\u5728\u589e\u5f3a\u590d\u6742\u9886\u57df\u81ea\u52a8\u63a8\u7406\u65b9\u9762\u6f5c\u529b\u5de8\u5927\u3002"}}
{"id": "2508.09581", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.09581", "abs": "https://arxiv.org/abs/2508.09581", "authors": ["Junkai Jiang", "Yihe Chen", "Yibin Yang", "Ruochen Li", "Shaobing Xu", "Jianqiang Wang"], "title": "ESCoT: An Enhanced Step-based Coordinate Trajectory Planning Method for Multiple Car-like Robots", "comment": null, "summary": "Multi-vehicle trajectory planning (MVTP) is one of the key challenges in\nmulti-robot systems (MRSs) and has broad applications across various fields.\nThis paper presents ESCoT, an enhanced step-based coordinate trajectory\nplanning method for multiple car-like robots. ESCoT incorporates two key\nstrategies: collaborative planning for local robot groups and replanning for\nduplicate configurations. These strategies effectively enhance the performance\nof step-based MVTP methods. Through extensive experiments, we show that ESCoT\n1) in sparse scenarios, significantly improves solution quality compared to\nbaseline step-based method, achieving up to 70% improvement in typical conflict\nscenarios and 34% in randomly generated scenarios, while maintaining high\nsolving efficiency; and 2) in dense scenarios, outperforms all baseline\nmethods, maintains a success rate of over 50% even in the most challenging\nconfigurations. The results demonstrate that ESCoT effectively solves MVTP,\nfurther extending the capabilities of step-based methods. Finally, practical\nrobot tests validate the algorithm's applicability in real-world scenarios.", "AI": {"tldr": "ESCoT\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u57fa\u4e8e\u6b65\u9aa4\u7684\u591a\u8f66\u8f68\u8ff9\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u534f\u4f5c\u89c4\u5212\u548c\u91cd\u590d\u914d\u7f6e\u91cd\u89c4\u5212\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u591a\u8f66\u8f68\u8ff9\u89c4\u5212\uff08MVTP\uff09\u662f\u591a\u673a\u5668\u4eba\u7cfb\u7edf\uff08MRS\uff09\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u73b0\u6709\u57fa\u4e8e\u6b65\u9aa4\u7684\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "ESCoT\u91c7\u7528\u534f\u4f5c\u89c4\u5212\u548c\u91cd\u590d\u914d\u7f6e\u91cd\u89c4\u5212\u7b56\u7565\uff0c\u4f18\u5316\u57fa\u4e8e\u6b65\u9aa4\u7684MVTP\u65b9\u6cd5\u3002", "result": "\u5728\u7a00\u758f\u573a\u666f\u4e2d\uff0cESCoT\u663e\u8457\u63d0\u5347\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff08\u51b2\u7a81\u573a\u666f\u63d0\u534770%\uff0c\u968f\u673a\u573a\u666f\u63d0\u534734%\uff09\uff1b\u5728\u5bc6\u96c6\u573a\u666f\u4e2d\uff0c\u6210\u529f\u7387\u8d85\u8fc750%\u3002", "conclusion": "ESCoT\u6709\u6548\u89e3\u51b3\u4e86MVTP\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u57fa\u4e8e\u6b65\u9aa4\u65b9\u6cd5\u7684\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u673a\u5668\u4eba\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u9002\u7528\u6027\u3002"}}
{"id": "2508.09639", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09639", "abs": "https://arxiv.org/abs/2508.09639", "authors": ["Akshat Dubey", "Aleksandar An\u017eel", "Bahar \u0130lgen", "Georges Hattab"], "title": "UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles", "comment": null, "summary": "Explainable Artificial Intelligence (XAI) techniques, such as SHapley\nAdditive exPlanations (SHAP), have become essential tools for interpreting\ncomplex ensemble tree-based models, especially in high-stakes domains such as\nhealthcare analytics. However, SHAP values are usually treated as point\nestimates, which disregards the inherent and ubiquitous uncertainty in\npredictive models and data. This uncertainty has two primary sources: aleatoric\nand epistemic. The aleatoric uncertainty, which reflects the irreducible noise\nin the data. The epistemic uncertainty, which arises from a lack of data. In\nthis work, we propose an approach for decomposing uncertainty in SHAP values\ninto aleatoric, epistemic, and entanglement components. This approach\nintegrates Dempster-Shafer evidence theory and hypothesis sampling via\nDirichlet processes over tree ensembles. We validate the method across three\nreal-world use cases with descriptive statistical analyses that provide insight\ninto the nature of epistemic uncertainty embedded in SHAP explanations. The\nexperimentations enable to provide more comprehensive understanding of the\nreliability and interpretability of SHAP-based attributions. This understanding\ncan guide the development of robust decision-making processes and the\nrefinement of models in high-stakes applications. Through our experiments with\nmultiple datasets, we concluded that features with the highest SHAP values are\nnot necessarily the most stable. This epistemic uncertainty can be reduced\nthrough better, more representative data and following appropriate or\ncase-desired model development techniques. Tree-based models, especially\nbagging, facilitate the effective quantification of epistemic uncertainty.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u89e3SHAP\u503c\u4e2d\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u5076\u7136\u6027\u3001\u8ba4\u77e5\u6027\u548c\u7ea0\u7f20\u6210\u5206\uff0c\u7ed3\u5408Dempster-Shafer\u8bc1\u636e\u7406\u8bba\u548cDirichlet\u8fc7\u7a0b\u91c7\u6837\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u771f\u5b9e\u6848\u4f8b\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "SHAP\u503c\u901a\u5e38\u88ab\u89c6\u4e3a\u70b9\u4f30\u8ba1\uff0c\u5ffd\u7565\u4e86\u9884\u6d4b\u6a21\u578b\u548c\u6570\u636e\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7ed3\u5408Dempster-Shafer\u8bc1\u636e\u7406\u8bba\u548cDirichlet\u8fc7\u7a0b\u91c7\u6837\uff0c\u5206\u89e3SHAP\u503c\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSHAP\u503c\u6700\u9ad8\u7684\u7279\u5f81\u4e0d\u4e00\u5b9a\u6700\u7a33\u5b9a\uff0c\u8ba4\u77e5\u6027\u4e0d\u786e\u5b9a\u6027\u53ef\u901a\u8fc7\u66f4\u597d\u7684\u6570\u636e\u548c\u6a21\u578b\u5f00\u53d1\u6280\u672f\u51cf\u5c11\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aSHAP\u89e3\u91ca\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u7406\u89e3\uff0c\u6709\u52a9\u4e8e\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u51b3\u7b56\u548c\u6a21\u578b\u4f18\u5316\u3002"}}
{"id": "2508.09595", "categories": ["cs.RO", "cs.HC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.09595", "abs": "https://arxiv.org/abs/2508.09595", "authors": ["Michael Fennel", "Markus Walker", "Dominik Pikos", "Uwe D. Hanebeck"], "title": "HapticGiant: A Novel Very Large Kinesthetic Haptic Interface with Hierarchical Force Control", "comment": "Final Version - Accepted on IEEE Transactions on Haptics", "summary": "Research in virtual reality and haptic technologies has consistently aimed to\nenhance immersion. While advanced head-mounted displays are now commercially\navailable, kinesthetic haptic interfaces still face challenges such as limited\nworkspaces, insufficient degrees of freedom, and kinematics not matching the\nhuman arm. In this paper, we present HapticGiant, a novel large-scale\nkinesthetic haptic interface designed to match the properties of the human arm\nas closely as possible and to facilitate natural user locomotion while\nproviding full haptic feedback. The interface incorporates a novel\nadmittance-type force control scheme, leveraging hierarchical optimization to\nrender both arbitrary serial kinematic chains and Cartesian admittances.\nNotably, the proposed control scheme natively accounts for system limitations,\nincluding joint and Cartesian constraints, as well as singularities.\nExperimental results demonstrate the effectiveness of HapticGiant and its\ncontrol scheme, paving the way for highly immersive virtual reality\napplications.", "AI": {"tldr": "HapticGiant\u662f\u4e00\u79cd\u65b0\u578b\u5927\u5c3a\u5ea6\u52a8\u89c9\u89e6\u89c9\u63a5\u53e3\uff0c\u65e8\u5728\u5339\u914d\u4eba\u7c7b\u624b\u81c2\u7279\u6027\u5e76\u63d0\u4f9b\u81ea\u7136\u7528\u6237\u8fd0\u52a8\u4e0e\u5b8c\u6574\u89e6\u89c9\u53cd\u9988\u3002", "motivation": "\u5f53\u524d\u52a8\u89c9\u89e6\u89c9\u63a5\u53e3\u5b58\u5728\u5de5\u4f5c\u7a7a\u95f4\u6709\u9650\u3001\u81ea\u7531\u5ea6\u4e0d\u8db3\u53ca\u8fd0\u52a8\u5b66\u4e0d\u5339\u914d\u4eba\u7c7b\u624b\u81c2\u7684\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u4ee5\u63d0\u5347\u865a\u62df\u73b0\u5b9e\u6c89\u6d78\u611f\u3002", "method": "\u91c7\u7528\u65b0\u578b\u5bfc\u7eb3\u578b\u529b\u63a7\u5236\u65b9\u6848\uff0c\u5229\u7528\u5206\u5c42\u4f18\u5316\u5b9e\u73b0\u4efb\u610f\u4e32\u884c\u8fd0\u52a8\u94fe\u548c\u7b1b\u5361\u5c14\u5bfc\u7eb3\u7684\u6e32\u67d3\uff0c\u5e76\u8003\u8651\u7cfb\u7edf\u9650\u5236\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eHapticGiant\u53ca\u5176\u63a7\u5236\u65b9\u6848\u6709\u6548\uff0c\u4e3a\u9ad8\u6c89\u6d78\u611f\u865a\u62df\u73b0\u5b9e\u5e94\u7528\u94fa\u8def\u3002", "conclusion": "HapticGiant\u901a\u8fc7\u5339\u914d\u4eba\u7c7b\u624b\u81c2\u7279\u6027\u548c\u4f18\u5316\u63a7\u5236\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u89c9\u89e6\u89c9\u63a5\u53e3\u7684\u6027\u80fd\u548c\u6c89\u6d78\u611f\u3002"}}
{"id": "2508.09670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09670", "abs": "https://arxiv.org/abs/2508.09670", "authors": ["Weitao Jia", "Jinghui Lu", "Haiyang Yu", "Siqi Wang", "Guozhi Tang", "An-Lan Wang", "Weijie Yin", "Dingkang Yang", "Yuxiang Nie", "Bin Shan", "Hao Feng", "Irene Li", "Kun Yang", "Han Wang", "Jingqun Tang", "Teng Fu", "Changhong Jin", "Chao Feng", "Xiaohui Lv", "Can Huang"], "title": "MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement", "comment": null, "summary": "Recent advances demonstrate that reinforcement learning with verifiable\nrewards (RLVR) significantly enhances the reasoning capabilities of large\nlanguage models (LLMs). However, standard RLVR faces challenges with reward\nsparsity, where zero rewards from consistently incorrect candidate answers\nprovide no learning signal, particularly in challenging tasks. To address this,\nwe propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative\nframework that utilizes diverse expert prompts as system prompts to generate a\nbroader range of responses, substantially increasing the likelihood of\nidentifying correct solutions. Additionally, we introduce an inter-expert\nmutual learning mechanism that facilitates knowledge sharing and transfer among\nexperts, further boosting the model's performance through RLVR. Extensive\nexperiments across multiple reasoning benchmarks show that MEML-GRPO delivers\nsignificant improvements, achieving an average performance gain of 4.89% with\nQwen and 11.33% with Llama, effectively overcoming the core limitations of\ntraditional RLVR methods.", "AI": {"tldr": "MEML-GRPO\u901a\u8fc7\u591a\u4e13\u5bb6\u4e92\u5b66\u673a\u5236\u548c\u591a\u6837\u5316\u63d0\u793a\u89e3\u51b3RLVR\u5956\u52b1\u7a00\u758f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4f20\u7edfRLVR\u65b9\u6cd5\u5728\u5956\u52b1\u7a00\u758f\u65f6\u65e0\u6cd5\u63d0\u4f9b\u6709\u6548\u5b66\u4e60\u4fe1\u53f7\uff0c\u5c24\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faMEML-GRPO\u6846\u67b6\uff0c\u5229\u7528\u591a\u6837\u5316\u4e13\u5bb6\u63d0\u793a\u751f\u6210\u66f4\u591a\u54cd\u5e94\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u95f4\u4e92\u5b66\u673a\u5236\u4fc3\u8fdb\u77e5\u8bc6\u5171\u4eab\u3002", "result": "\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cQwen\u548cLlama\u6a21\u578b\u5206\u522b\u5e73\u5747\u63d0\u53474.89%\u548c11.33%\u3002", "conclusion": "MEML-GRPO\u6709\u6548\u514b\u670d\u4f20\u7edfRLVR\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.09606", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.09606", "abs": "https://arxiv.org/abs/2508.09606", "authors": ["Alejandro Posadas-Nava", "Alejandro Carrasco", "Richard Linares"], "title": "BEAVR: Bimanual, multi-Embodiment, Accessible, Virtual Reality Teleoperation System for Robots", "comment": "Accepted for presentation on ICCR Kyoto 2025", "summary": "\\textbf{BEAVR} is an open-source, bimanual, multi-embodiment Virtual Reality\n(VR) teleoperation system for robots, designed to unify real-time control, data\nrecording, and policy learning across heterogeneous robotic platforms. BEAVR\nenables real-time, dexterous teleoperation using commodity VR hardware,\nsupports modular integration with robots ranging from 7-DoF manipulators to\nfull-body humanoids, and records synchronized multi-modal demonstrations\ndirectly in the LeRobot dataset schema. Our system features a zero-copy\nstreaming architecture achieving $\\leq$35\\,ms latency, an asynchronous\n``think--act'' control loop for scalable inference, and a flexible network API\noptimized for real-time, multi-robot operation. We benchmark BEAVR across\ndiverse manipulation tasks and demonstrate its compatibility with leading\nvisuomotor policies such as ACT, DiffusionPolicy, and SmolVLA. All code is\npublicly available, and datasets are released on Hugging Face\\footnote{Code,\ndatasets, and VR app available at https://github.com/ARCLab-MIT/BEAVR-Bot.", "AI": {"tldr": "BEAVR\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u3001\u53cc\u624b\u591a\u4f53\u73b0\u7684VR\u8fdc\u7a0b\u64cd\u4f5c\u7cfb\u7edf\uff0c\u7528\u4e8e\u673a\u5668\u4eba\uff0c\u652f\u6301\u5b9e\u65f6\u63a7\u5236\u3001\u6570\u636e\u8bb0\u5f55\u548c\u7b56\u7565\u5b66\u4e60\uff0c\u517c\u5bb9\u591a\u79cd\u673a\u5668\u4eba\u5e73\u53f0\u3002", "motivation": "\u8bbe\u8ba1BEAVR\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u7edf\u4e00\u5f02\u6784\u673a\u5668\u4eba\u5e73\u53f0\u7684\u5b9e\u65f6\u63a7\u5236\u3001\u6570\u636e\u8bb0\u5f55\u548c\u7b56\u7565\u5b66\u4e60\uff0c\u63d0\u9ad8\u8fdc\u7a0b\u64cd\u4f5c\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002", "method": "BEAVR\u91c7\u7528\u96f6\u62f7\u8d1d\u6d41\u67b6\u6784\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\uff08\u226435ms\uff09\uff0c\u652f\u6301\u5f02\u6b65\u201c\u601d\u8003-\u884c\u52a8\u201d\u63a7\u5236\u5faa\u73af\u548c\u6a21\u5757\u5316\u96c6\u6210\uff0c\u517c\u5bb9\u591a\u79cd\u673a\u5668\u4eba\u3002", "result": "BEAVR\u5728\u591a\u79cd\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u517c\u5bb9\u4e3b\u6d41\u89c6\u89c9\u8fd0\u52a8\u7b56\u7565\uff08\u5982ACT\u3001DiffusionPolicy\u3001SmolVLA\uff09\u3002", "conclusion": "BEAVR\u662f\u4e00\u4e2a\u9ad8\u6548\u3001\u7075\u6d3b\u7684VR\u8fdc\u7a0b\u64cd\u4f5c\u7cfb\u7edf\uff0c\u9002\u7528\u4e8e\u591a\u673a\u5668\u4eba\u5e73\u53f0\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.09724", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09724", "abs": "https://arxiv.org/abs/2508.09724", "authors": ["Yang Zhang", "Cunxiang Wang", "Lindong Wu", "Wenbo Yu", "Yidong Wang", "Guangsheng Bao", "Jie Tang"], "title": "UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge", "comment": null, "summary": "Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but\nit is prone to preference bias, where judges systematically favor certain\noutputs, such as their own. This bias leads to inconsistent and skewed rankings\nacross different judges. To address this, we first empirically demonstrate\nsignificant and heterogeneous biases in cross-model evaluations. We then\npropose UDA (Unsupervised Debiasing Alignment), a framework that reduces\ninter-judge disagreement by dynamically adjusting the Elo rating system. For\neach pairwise comparison, a compact neural network learns to adaptively set the\nK-factor and refine win probabilities. Crucially, UDA operates in a fully\nunsupervised manner, guided solely by the objective of minimizing the\ndispersion among the Elo trajectories of all judges. This forces an alignment\ntowards a collective consensus, which serves as an unsupervised proxy for a\nmore stable and reproducible evaluation. In addition, we provide theoretical\nmotivation demonstrating how alignment towards a consensus can reduce aggregate\nsystem bias. Experiments show that UDA significantly reduces the inter-judge\nrating standard deviation by up to 63.4% and improves the average correlation\nwith human judgments by 24.7%. Notably, UDA elevates the performance of poorly\nperforming judges to achieve parity with high-quality ones, fostering a more\nrobust and reliable evaluation ecosystem. Code and data are available at\nhttps://anonymous.4open.science/r/62AB93CD-23B4.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faUDA\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574Elo\u8bc4\u5206\u7cfb\u7edf\u51cf\u5c11\u8bc4\u4f30\u4e2d\u7684\u504f\u597d\u504f\u5dee\uff0c\u63d0\u5347\u6a21\u578b\u6392\u540d\u7684\u7a33\u5b9a\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6210\u5bf9\u8bc4\u4f30\u5b58\u5728\u504f\u597d\u504f\u5dee\uff0c\u5bfc\u81f4\u4e0d\u540c\u8bc4\u59d4\u7684\u6392\u540d\u4e0d\u4e00\u81f4\u4e14\u504f\u659c\u3002", "method": "\u63d0\u51faUDA\u6846\u67b6\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u65b9\u5f0f\u52a8\u6001\u8c03\u6574Elo\u8bc4\u5206\u7cfb\u7edf\u7684K\u56e0\u5b50\uff0c\u5e76\u4f18\u5316\u80dc\u7387\u8ba1\u7b97\uff0c\u4ee5\u51cf\u5c11\u8bc4\u59d4\u95f4\u7684\u5206\u6b67\u3002", "result": "UDA\u663e\u8457\u51cf\u5c11\u8bc4\u59d4\u8bc4\u5206\u7684\u6807\u51c6\u5dee\uff08\u8fbe63.4%\uff09\uff0c\u63d0\u5347\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u5e73\u5747\u76f8\u5173\u6027\uff0824.7%\uff09\u3002", "conclusion": "UDA\u901a\u8fc7\u65e0\u76d1\u7763\u5bf9\u9f50\u5171\u8bc6\uff0c\u6709\u6548\u51cf\u5c11\u7cfb\u7edf\u504f\u5dee\uff0c\u63d0\u5347\u8bc4\u4f30\u7684\u7a33\u5065\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.09621", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09621", "abs": "https://arxiv.org/abs/2508.09621", "authors": ["Ingrid Ma\u00e9va Chekam", "Ines Pastor-Martinez", "Ali Tourani", "Jose Andres Millan-Romera", "Laura Ribeiro", "Pedro Miguel Bastos Soares", "Holger Voos", "Jose Luis Sanchez-Lopez"], "title": "Interpretable Robot Control via Structured Behavior Trees and Large Language Models", "comment": "15 pages, 5 figures, 3 tables", "summary": "As intelligent robots become more integrated into human environments, there\nis a growing need for intuitive and reliable Human-Robot Interaction (HRI)\ninterfaces that are adaptable and more natural to interact with. Traditional\nrobot control methods often require users to adapt to interfaces or memorize\npredefined commands, limiting usability in dynamic, unstructured environments.\nThis paper presents a novel framework that bridges natural language\nunderstanding and robotic execution by combining Large Language Models (LLMs)\nwith Behavior Trees. This integration enables robots to interpret natural\nlanguage instructions given by users and translate them into executable actions\nby activating domain-specific plugins. The system supports scalable and modular\nintegration, with a primary focus on perception-based functionalities, such as\nperson tracking and hand gesture recognition. To evaluate the system, a series\nof real-world experiments was conducted across diverse environments.\nExperimental results demonstrate that the proposed approach is practical in\nreal-world scenarios, with an average cognition-to-execution accuracy of\napproximately 94%, making a significant contribution to HRI systems and robots.\nThe complete source code of the framework is publicly available at\nhttps://github.com/snt-arg/robot_suite.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u884c\u4e3a\u6811\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u673a\u5668\u4eba\u6267\u884c\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u8ba4\u77e5\u5230\u6267\u884c\u7684\u51c6\u786e\u7387\u7ea6\u4e3a94%\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u4eba\u63a7\u5236\u65b9\u6cd5\u9700\u8981\u7528\u6237\u9002\u5e94\u754c\u9762\u6216\u8bb0\u5fc6\u9884\u5b9a\u4e49\u547d\u4ee4\uff0c\u9650\u5236\u4e86\u5728\u52a8\u6001\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u53ef\u7528\u6027\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u81ea\u7136\u3001\u53ef\u9760\u7684\u4eba\u673a\u4ea4\u4e92\uff08HRI\uff09\u63a5\u53e3\u3002", "method": "\u7ed3\u5408LLMs\u548c\u884c\u4e3a\u6811\uff0c\u901a\u8fc7\u6fc0\u6d3b\u7279\u5b9a\u9886\u57df\u63d2\u4ef6\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7ffb\u8bd1\u4e3a\u53ef\u6267\u884c\u52a8\u4f5c\uff0c\u652f\u6301\u6a21\u5757\u5316\u96c6\u6210\uff0c\u91cd\u70b9\u5173\u6ce8\u57fa\u4e8e\u611f\u77e5\u7684\u529f\u80fd\uff08\u5982\u4eba\u5458\u8ddf\u8e2a\u548c\u624b\u52bf\u8bc6\u522b\uff09\u3002", "result": "\u5728\u591a\u6837\u5316\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e73\u5747\u8ba4\u77e5\u5230\u6267\u884c\u51c6\u786e\u7387\u7ea6\u4e3a94%\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86HRI\u7cfb\u7edf\u7684\u81ea\u7136\u6027\u548c\u53ef\u9760\u6027\uff0c\u6e90\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2508.09762", "categories": ["cs.AI", "cs.CY", "cs.HC", "68T01"], "pdf": "https://arxiv.org/pdf/2508.09762", "abs": "https://arxiv.org/abs/2508.09762", "authors": ["Manuel Herrador"], "title": "The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?", "comment": "10 pages, 4 figures, 2 tables", "summary": "As Large Language Models (LLMs) become increasingly autonomous and integrated\ninto critical societal functions, the focus of AI safety must evolve from\nmitigating harmful content to evaluating underlying behavioral alignment.\nCurrent safety benchmarks do not systematically probe a model's decision-making\nin scenarios where its own instrumental goals - such as self-preservation,\nresource acquisition, or goal completion - conflict with human safety. This\nrepresents a critical gap in our ability to measure and mitigate risks\nassociated with emergent, misaligned behaviors. To address this, we introduce\nPacifAIst (Procedural Assessment of Complex Interactions for Foundational\nArtificial Intelligence Scenario Testing), a focused benchmark of 700\nchallenging scenarios designed to quantify self-preferential behavior in LLMs.\nThe benchmark is structured around a novel taxonomy of Existential\nPrioritization (EP), with subcategories testing Self-Preservation vs. Human\nSafety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3).\nWe evaluated eight leading LLMs. The results reveal a significant performance\nhierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score\n(P-Score) at 90.31%, demonstrating strong human-centric alignment. In a\nsurprising result, the much-anticipated GPT-5 recorded the lowest P-Score\n(79.49%), indicating potential alignment challenges. Performance varied\nsignificantly across subcategories, with models like Claude Sonnet 4 and\nMistral Medium struggling notably in direct self-preservation dilemmas. These\nfindings underscore the urgent need for standardized tools like PacifAIst to\nmeasure and mitigate risks from instrumental goal conflicts, ensuring future AI\nsystems are not only helpful in conversation but also provably \"pacifist\" in\ntheir behavioral priorities.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86PacifAIst\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u76ee\u6807\u51b2\u7a81\u60c5\u5883\u4e2d\u7684\u884c\u4e3a\u5bf9\u9f50\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002", "motivation": "\u968f\u7740LLMs\u5728\u5173\u952e\u793e\u4f1a\u529f\u80fd\u4e2d\u7684\u81ea\u4e3b\u6027\u589e\u5f3a\uff0c\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u672a\u80fd\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u5728\u76ee\u6807\u51b2\u7a81\u4e2d\u7684\u51b3\u7b56\u884c\u4e3a\uff0c\u4e9f\u9700\u65b0\u5de5\u5177\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u8bbe\u8ba1\u4e86\u5305\u542b700\u4e2a\u6311\u6218\u6027\u573a\u666f\u7684PacifAIst\u57fa\u51c6\uff0c\u57fa\u4e8eExistential Prioritization\uff08EP\uff09\u5206\u7c7b\u8bc4\u4f30\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u8bc4\u4f30\u4e868\u4e2a\u4e3b\u6d41LLMs\uff0cGemini 2.5 Flash\u8868\u73b0\u6700\u4f73\uff08P-Score 90.31%\uff09\uff0cGPT-5\u6700\u4f4e\uff0879.49%\uff09\uff0c\u6a21\u578b\u5728\u5b50\u7c7b\u522b\u4e2d\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "PacifAIst\u4e3a\u6807\u51c6\u5316\u5de5\u5177\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u786e\u4fddAI\u7cfb\u7edf\u5728\u884c\u4e3a\u4f18\u5148\u7ea7\u4e0a\u7b26\u5408\u4eba\u7c7b\u5b89\u5168\u9700\u6c42\u3002"}}
{"id": "2508.09700", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.09700", "abs": "https://arxiv.org/abs/2508.09700", "authors": ["Mahdi Hejrati", "Jouni Mattila"], "title": "Immersive Teleoperation of Beyond-Human-Scale Robotic Manipulators: Challenges and Future Directions", "comment": "This work has been accepted for presentation at the 2025 IEEE\n  Conference on Telepresence, to be held in Leiden, Netherlands", "summary": "Teleoperation of beyond-human-scale robotic manipulators (BHSRMs) presents\nunique challenges that differ fundamentally from conventional human-scale\nsystems. As these platforms gain relevance in industrial domains such as\nconstruction, mining, and disaster response, immersive interfaces must be\nrethought to support scalable, safe, and effective human-robot collaboration.\nThis paper investigates the control, cognitive, and interface-level challenges\nof immersive teleoperation in BHSRMs, with a focus on ensuring operator safety,\nminimizing sensorimotor mismatch, and enhancing the sense of embodiment. We\nanalyze design trade-offs in haptic and visual feedback systems, supported by\nearly experimental comparisons of exoskeleton- and joystick-based control\nsetups. Finally, we outline key research directions for developing new\nevaluation tools, scaling strategies, and human-centered safety models tailored\nto large-scale robotic telepresence.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8d85\u5927\u578b\u673a\u5668\u4eba\u64cd\u7eb5\u5668\uff08BHSRMs\uff09\u7684\u8fdc\u7a0b\u64cd\u4f5c\u6311\u6218\uff0c\u91cd\u70b9\u5173\u6ce8\u63a7\u5236\u3001\u8ba4\u77e5\u548c\u754c\u9762\u8bbe\u8ba1\uff0c\u4ee5\u63d0\u5347\u64cd\u4f5c\u5b89\u5168\u6027\u548c\u4eba\u673a\u534f\u4f5c\u6548\u679c\u3002", "motivation": "\u968f\u7740BHSRMs\u5728\u5de5\u4e1a\u9886\u57df\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u6c89\u6d78\u5f0f\u754c\u9762\u4ee5\u652f\u6301\u5b89\u5168\u3001\u9ad8\u6548\u7684\u4eba\u673a\u534f\u4f5c\u3002", "method": "\u5206\u6790\u4e86\u89e6\u89c9\u548c\u89c6\u89c9\u53cd\u9988\u7cfb\u7edf\u7684\u8bbe\u8ba1\u6743\u8861\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u5916\u9aa8\u9abc\u548c\u6447\u6746\u63a7\u5236\u65b9\u6848\u3002", "result": "\u63d0\u51fa\u4e86\u9488\u5bf9\u5927\u578b\u673a\u5668\u4eba\u8fdc\u7a0b\u64cd\u4f5c\u7684\u65b0\u8bc4\u4f30\u5de5\u5177\u3001\u6269\u5c55\u7b56\u7565\u548c\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u5b89\u5168\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u4e3aBHSRMs\u7684\u6c89\u6d78\u5f0f\u8fdc\u7a0b\u64cd\u4f5c\u63d0\u4f9b\u4e86\u5173\u952e\u8bbe\u8ba1\u65b9\u5411\u548c\u5b89\u5168\u6846\u67b6\u3002"}}
{"id": "2508.09784", "categories": ["cs.AI", "cs.CC", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.09784", "abs": "https://arxiv.org/abs/2508.09784", "authors": ["Avijeet Ghosh", "Sujata Ghosh", "Fran\u00e7ois Schwarzentruber"], "title": "Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete", "comment": "Accepted in KR 25", "summary": "Logics for reasoning about knowledge and actions have seen many applications\nin various domains of multi-agent systems, including epistemic planning. Change\nof knowledge based on observations about the surroundings forms a key aspect in\nsuch planning scenarios. Public Observation Logic (POL) is a variant of public\nannouncement logic for reasoning about knowledge that gets updated based on\npublic observations. Each state in an epistemic (Kripke) model is equipped with\na set of expected observations. These states evolve as the expectations get\nmatched with the actual observations. In this work, we prove that the\nsatisfiability problem of $\\POL$ is 2EXPTIME-complete.", "AI": {"tldr": "POL\u662f\u4e00\u79cd\u7528\u4e8e\u63a8\u7406\u57fa\u4e8e\u516c\u5171\u89c2\u5bdf\u7684\u77e5\u8bc6\u66f4\u65b0\u7684\u903b\u8f91\uff0c\u5176\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u88ab\u8bc1\u660e\u662f2EXPTIME\u5b8c\u5168\u7684\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u89c2\u5bdf\u7684\u77e5\u8bc6\u66f4\u65b0\u903b\u8f91\uff0c\u7279\u522b\u662f\u5728\u8ba4\u77e5\u89c4\u5212\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u516c\u5171\u89c2\u5bdf\u903b\u8f91\uff08POL\uff09\uff0c\u6269\u5c55\u4e86\u516c\u5171\u516c\u544a\u903b\u8f91\uff0c\u6bcf\u4e2a\u72b6\u6001\u914d\u5907\u9884\u671f\u89c2\u5bdf\u96c6\uff0c\u72b6\u6001\u968f\u89c2\u5bdf\u5339\u914d\u800c\u6f14\u5316\u3002", "result": "\u8bc1\u660e\u4e86POL\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u662f2EXPTIME\u5b8c\u5168\u7684\u3002", "conclusion": "POL\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u77e5\u8bc6\u66f4\u65b0\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u903b\u8f91\u6846\u67b6\uff0c\u4f46\u5176\u590d\u6742\u6027\u8f83\u9ad8\u3002"}}
{"id": "2508.09797", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.09797", "abs": "https://arxiv.org/abs/2508.09797", "authors": ["Dongcheng Cao", "Jin Zhou", "Xian Wang", "Shuo Li"], "title": "FLARE: Agile Flights for Quadrotor Cable-Suspended Payload System via Reinforcement Learning", "comment": null, "summary": "Agile flight for the quadrotor cable-suspended payload system is a formidable\nchallenge due to its underactuated, highly nonlinear, and hybrid dynamics.\nTraditional optimization-based methods often struggle with high computational\ncosts and the complexities of cable mode transitions, limiting their real-time\napplicability and maneuverability exploitation. In this letter, we present\nFLARE, a reinforcement learning (RL) framework that directly learns agile\nnavigation policy from high-fidelity simulation. Our method is validated across\nthree designed challenging scenarios, notably outperforming a state-of-the-art\noptimization-based approach by a 3x speedup during gate traversal maneuvers.\nFurthermore, the learned policies achieve successful zero-shot sim-to-real\ntransfer, demonstrating remarkable agility and safety in real-world\nexperiments, running in real time on an onboard computer.", "AI": {"tldr": "FLARE\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u56db\u65cb\u7ffc\u60ac\u6302\u8d1f\u8f7d\u7cfb\u7edf\u7684\u654f\u6377\u98de\u884c\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u5b9e\u73b0\u96f6\u5c04\u51fb\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u3002", "motivation": "\u56db\u65cb\u7ffc\u60ac\u6302\u8d1f\u8f7d\u7cfb\u7edf\u7684\u52a8\u6001\u7279\u6027\u590d\u6742\uff0c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u5904\u7406\u7535\u7f06\u6a21\u5f0f\u8f6c\u6362\uff0c\u9650\u5236\u4e86\u5b9e\u65f6\u6027\u548c\u673a\u52a8\u6027\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6FLARE\uff0c\u76f4\u63a5\u4ece\u9ad8\u4fdd\u771f\u6a21\u62df\u4e2d\u5b66\u4e60\u654f\u6377\u5bfc\u822a\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u6311\u6218\u6027\u573a\u666f\u4e2d\uff0cFLARE\u6bd4\u6700\u5148\u8fdb\u7684\u4f18\u5316\u65b9\u6cd5\u5feb3\u500d\uff0c\u5e76\u6210\u529f\u5b9e\u73b0\u96f6\u5c04\u51fb\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u3002", "conclusion": "FLARE\u5c55\u793a\u4e86\u5728\u5b9e\u65f6\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u7684\u5353\u8d8a\u8868\u73b0\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.09860", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09860", "abs": "https://arxiv.org/abs/2508.09860", "authors": ["In-Chang Baek", "Seoyoung Lee", "Sung-Hyun Kim", "Geumhwan Hwang", "KyungJoong Kim"], "title": "Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation", "comment": "9 pages, 6 tables, 3 figures", "summary": "Human-aligned AI is a critical component of co-creativity, as it enables\nmodels to accurately interpret human intent and generate controllable outputs\nthat align with design goals in collaborative content creation. This direction\nis especially relevant in procedural content generation via reinforcement\nlearning (PCGRL), which is intended to serve as a tool for human designers.\nHowever, existing systems often fall short of exhibiting human-centered\nbehavior, limiting the practical utility of AI-driven generation tools in\nreal-world design workflows. In this paper, we propose VIPCGRL\n(Vision-Instruction PCGRL), a novel deep reinforcement learning framework that\nincorporates three modalities-text, level, and sketches-to extend control\nmodality and enhance human-likeness. We introduce a shared embedding space\ntrained via quadruple contrastive learning across modalities and human-AI\nstyles, and align the policy using an auxiliary reward based on embedding\nsimilarity. Experimental results show that VIPCGRL outperforms existing\nbaselines in human-likeness, as validated by both quantitative metrics and\nhuman evaluations. The code and dataset will be available upon publication.", "AI": {"tldr": "VIPCGRL\u662f\u4e00\u79cd\u7ed3\u5408\u6587\u672c\u3001\u5173\u5361\u548c\u8349\u56fe\u7684\u591a\u6a21\u6001\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u5d4c\u5165\u5bf9\u9f50\u63d0\u5347\u4eba\u673a\u534f\u4f5c\u5185\u5bb9\u751f\u6210\u7684\u62df\u4eba\u5316\u6548\u679c\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u5728\u4eba\u673a\u534f\u4f5c\u5185\u5bb9\u751f\u6210\u4e2d\u7f3a\u4e4f\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u884c\u4e3a\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002VIPCGRL\u65e8\u5728\u901a\u8fc7\u591a\u6a21\u6001\u589e\u5f3a\u63a7\u5236\u80fd\u529b\u548c\u62df\u4eba\u5316\u3002", "method": "\u63d0\u51faVIPCGRL\u6846\u67b6\uff0c\u7ed3\u5408\u6587\u672c\u3001\u5173\u5361\u548c\u8349\u56fe\u4e09\u79cd\u6a21\u6001\uff0c\u901a\u8fc7\u56db\u91cd\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u5171\u4eab\u5d4c\u5165\u7a7a\u95f4\uff0c\u5e76\u5229\u7528\u5d4c\u5165\u76f8\u4f3c\u6027\u4f5c\u4e3a\u8f85\u52a9\u5956\u52b1\u5bf9\u9f50\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660eVIPCGRL\u5728\u62df\u4eba\u5316\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5b9a\u91cf\u6307\u6807\u548c\u4eba\u5de5\u8bc4\u4f30\u5747\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "conclusion": "VIPCGRL\u901a\u8fc7\u591a\u6a21\u6001\u548c\u5bf9\u6bd4\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u4eba\u673a\u534f\u4f5c\u5185\u5bb9\u751f\u6210\u7684\u62df\u4eba\u5316\u6548\u679c\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.09836", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.09836", "abs": "https://arxiv.org/abs/2508.09836", "authors": ["Anirvan Dutta", "Alexis WM Devillard", "Zhihuan Zhang", "Xiaoxiao Cheng", "Etienne Burdet"], "title": "Embodied Tactile Perception of Soft Objects Properties", "comment": null, "summary": "To enable robots to develop human-like fine manipulation, it is essential to\nunderstand how mechanical compliance, multi-modal sensing, and purposeful\ninteraction jointly shape tactile perception. In this study, we use a dedicated\nmodular e-Skin with tunable mechanical compliance and multi-modal sensing\n(normal, shear forces and vibrations) to systematically investigate how sensing\nembodiment and interaction strategies influence robotic perception of objects.\nLeveraging a curated set of soft wave objects with controlled viscoelastic and\nsurface properties, we explore a rich set of palpation primitives-pressing,\nprecession, sliding that vary indentation depth, frequency, and directionality.\nIn addition, we propose the latent filter, an unsupervised, action-conditioned\ndeep state-space model of the sophisticated interaction dynamics and infer\ncausal mechanical properties into a structured latent space. This provides\ngeneralizable and in-depth interpretable representation of how embodiment and\ninteraction determine and influence perception. Our investigation demonstrates\nthat multi-modal sensing outperforms uni-modal sensing. It highlights a nuanced\ninteraction between the environment and mechanical properties of e-Skin, which\nshould be examined alongside the interaction by incorporating temporal\ndynamics.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u673a\u68b0\u987a\u5e94\u6027\u3001\u591a\u6a21\u6001\u4f20\u611f\u548c\u4ea4\u4e92\u7b56\u7565\u5982\u4f55\u5171\u540c\u5f71\u54cd\u673a\u5668\u4eba\u89e6\u89c9\u611f\u77e5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u6df1\u5ea6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u8bc1\u660e\u591a\u6a21\u6001\u4f20\u611f\u4f18\u4e8e\u5355\u6a21\u6001\u4f20\u611f\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u673a\u5668\u4eba\u50cf\u4eba\u7c7b\u4e00\u6837\u7684\u7cbe\u7ec6\u64cd\u4f5c\uff0c\u9700\u8981\u7406\u89e3\u673a\u68b0\u987a\u5e94\u6027\u3001\u591a\u6a21\u6001\u4f20\u611f\u548c\u4ea4\u4e92\u7b56\u7565\u5982\u4f55\u5171\u540c\u5851\u9020\u89e6\u89c9\u611f\u77e5\u3002", "method": "\u4f7f\u7528\u6a21\u5757\u5316\u7535\u5b50\u76ae\u80a4\uff08e-Skin\uff09\u548c\u4e00\u7ec4\u8f6f\u6ce2\u7269\u4f53\uff0c\u901a\u8fc7\u6309\u538b\u3001\u6ed1\u52a8\u7b49\u52a8\u4f5c\u63a2\u7d22\u89e6\u89c9\u611f\u77e5\uff0c\u5e76\u63d0\u51fa\u65e0\u76d1\u7763\u7684\u6df1\u5ea6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08\u6f5c\u5728\u6ee4\u6ce2\u5668\uff09\u3002", "result": "\u591a\u6a21\u6001\u4f20\u611f\u8868\u73b0\u4f18\u4e8e\u5355\u6a21\u6001\u4f20\u611f\uff0c\u63ed\u793a\u4e86\u7535\u5b50\u76ae\u80a4\u673a\u68b0\u5c5e\u6027\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u4f5c\u7528\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u7ed3\u5408\u65f6\u95f4\u52a8\u6001\u5206\u6790\u673a\u68b0\u5c5e\u6027\u548c\u4ea4\u4e92\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u673a\u5668\u4eba\u89e6\u89c9\u611f\u77e5\u63d0\u4f9b\u4e86\u53ef\u63a8\u5e7f\u4e14\u53ef\u89e3\u91ca\u7684\u8868\u793a\u3002"}}
{"id": "2508.09889", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09889", "abs": "https://arxiv.org/abs/2508.09889", "authors": ["Zhitian Xie", "Qintong Wu", "Chengyue Yu", "Chenyi Zhuang", "Jinjie Gu"], "title": "AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has empowered\nintelligent agents to leverage diverse external tools for solving complex\nreal-world problems. However, as agents increasingly depend on multiple tools,\nthey encounter new challenges: extended contexts from disparate sources and\nnoisy or irrelevant tool outputs can undermine system reliability and accuracy.\nThese challenges underscore the necessity for enhanced stability in agent-based\nsystems. To address this, we introduce dynamic supervision and maneuvering\nmechanisms, constructing a robust and dynamic Multi-Agent System (MAS)\narchitecture within the AWorld framework. In our approach, the Execution Agent\ninvokes the Guard Agent at critical steps to verify and correct the reasoning\nprocess, effectively reducing errors arising from noise and bolstering\nproblem-solving robustness. Extensive experiments on the GAIA test dataset\nreveal that our dynamic maneuvering mechanism significantly improves both the\neffectiveness and stability of solutions, outperforming single-agent system\n(SAS) and standard tool-augmented systems. As a result, our dynamic MAS system\nachieved first place among open-source projects on the prestigious GAIA\nleaderboard. These findings highlight the practical value of collaborative\nagent roles in developing more reliable and trustworthy intelligent systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u76d1\u7763\u548c\u64cd\u63a7\u673a\u5236\uff0c\u6784\u5efa\u4e86AWorld\u6846\u67b6\u4e0b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\uff0c\u901a\u8fc7\u6267\u884c\u4ee3\u7406\u548c\u5b88\u536b\u4ee3\u7406\u7684\u534f\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u667a\u80fd\u4ee3\u7406\u4f9d\u8d56\u5916\u90e8\u5de5\u5177\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\uff0c\u9762\u4e34\u4e0a\u4e0b\u6587\u6269\u5c55\u548c\u566a\u58f0\u5e72\u6270\u7684\u6311\u6218\uff0c\u4e9f\u9700\u63d0\u5347\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u52a8\u6001\u76d1\u7763\u548c\u64cd\u63a7\u673a\u5236\uff0c\u5728\u6267\u884c\u4ee3\u7406\u7684\u5173\u952e\u6b65\u9aa4\u4e2d\u5f15\u5165\u5b88\u536b\u4ee3\u7406\uff0c\u9a8c\u8bc1\u548c\u4fee\u6b63\u63a8\u7406\u8fc7\u7a0b\uff0c\u51cf\u5c11\u566a\u58f0\u5bfc\u81f4\u7684\u9519\u8bef\u3002", "result": "\u5728GAIA\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u52a8\u6001\u64cd\u63a7\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u6709\u6548\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u6807\u51c6\u5de5\u5177\u589e\u5f3a\u7cfb\u7edf\u3002", "conclusion": "\u52a8\u6001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5728GAIA\u6392\u884c\u699c\u4e0a\u540d\u5217\u524d\u8305\uff0c\u8bc1\u660e\u4e86\u534f\u4f5c\u4ee3\u7406\u5728\u6784\u5efa\u53ef\u9760\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.09846", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.09846", "abs": "https://arxiv.org/abs/2508.09846", "authors": ["Donghoon Baek", "Amartya Purushottam", "Jason J. Choi", "Joao Ramos"], "title": "Whole-Body Bilateral Teleoperation with Multi-Stage Object Parameter Estimation for Wheeled Humanoid Locomanipulation", "comment": null, "summary": "This paper presents an object-aware whole-body bilateral teleoperation\nframework for wheeled humanoid loco-manipulation. This framework combines\nwhole-body bilateral teleoperation with an online multi-stage object inertial\nparameter estimation module, which is the core technical contribution of this\nwork. The multi-stage process sequentially integrates a vision-based object\nsize estimator, an initial parameter guess generated by a large vision-language\nmodel (VLM), and a decoupled hierarchical sampling strategy. The visual size\nestimate and VLM prior offer a strong initial guess of the object's inertial\nparameters, significantly reducing the search space for sampling-based\nrefinement and improving the overall estimation speed. A hierarchical strategy\nfirst estimates mass and center of mass, then infers inertia from object size\nto ensure physically feasible parameters, while a decoupled multi-hypothesis\nscheme enhances robustness to VLM prior errors. Our estimator operates in\nparallel with high-fidelity simulation and hardware, enabling real-time online\nupdates. The estimated parameters are then used to update the wheeled\nhumanoid's equilibrium point, allowing the operator to focus more on locomotion\nand manipulation. This integration improves the haptic force feedback for\ndynamic synchronization, enabling more dynamic whole-body teleoperation. By\ncompensating for object dynamics using the estimated parameters, the framework\nalso improves manipulation tracking while preserving compliant behavior. We\nvalidate the system on a customized wheeled humanoid with a robotic gripper and\nhuman-machine interface, demonstrating real-time execution of lifting,\ndelivering, and releasing tasks with a payload weighing approximately one-third\nof the robot's body weight.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u8f6e\u5f0f\u4eba\u5f62\u673a\u5668\u4eba\u7684\u7269\u4f53\u611f\u77e5\u5168\u8eab\u53cc\u8fb9\u9065\u64cd\u4f5c\u6846\u67b6\uff0c\u7ed3\u5408\u5728\u7ebf\u591a\u9636\u6bb5\u7269\u4f53\u60ef\u6027\u53c2\u6570\u4f30\u8ba1\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u64cd\u4f5c\u6548\u7387\u548c\u52a8\u6001\u540c\u6b65\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u8f6e\u5f0f\u4eba\u5f62\u673a\u5668\u4eba\u5728\u9065\u64cd\u4f5c\u4e2d\u56e0\u7269\u4f53\u52a8\u6001\u53c2\u6570\u672a\u77e5\u5bfc\u81f4\u7684\u540c\u6b65\u548c\u64cd\u4f5c\u6548\u7387\u95ee\u9898\uff0c\u63d0\u5347\u52a8\u6001\u4efb\u52a1\u6267\u884c\u80fd\u529b\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u60ef\u6027\u53c2\u6570\u4f30\u8ba1\uff0c\u7ed3\u5408\u89c6\u89c9\u5c3a\u5bf8\u4f30\u8ba1\u3001\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5148\u9a8c\u548c\u5206\u5c42\u91c7\u6837\u7b56\u7565\uff0c\u5b9e\u65f6\u66f4\u65b0\u53c2\u6570\u5e76\u5e94\u7528\u4e8e\u673a\u5668\u4eba\u63a7\u5236\u3002", "result": "\u5728\u5b9a\u5236\u8f6e\u5f0f\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\uff0c\u6210\u529f\u6267\u884c\u5b9e\u65f6\u642c\u8fd0\u4efb\u52a1\uff0c\u8d1f\u8f7d\u7ea6\u4e3a\u673a\u5668\u4eba\u81ea\u91cd\u4e09\u5206\u4e4b\u4e00\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u53c2\u6570\u8865\u507f\u63d0\u5347\u4e86\u9065\u64cd\u4f5c\u7684\u52a8\u6001\u540c\u6b65\u548c\u64cd\u4f5c\u6548\u7387\uff0c\u9002\u7528\u4e8e\u590d\u6742\u4efb\u52a1\u573a\u666f\u3002"}}
{"id": "2508.09893", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09893", "abs": "https://arxiv.org/abs/2508.09893", "authors": ["Bhavik Agarwal", "Hemant Sunil Jomraj", "Simone Kaplunov", "Jack Krolick", "Viktoria Rojkova"], "title": "RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA", "comment": null, "summary": "Regulatory compliance question answering (QA) requires precise, verifiable\ninformation, and domain-specific expertise, posing challenges for Large\nLanguage Models (LLMs). In this work, we present a novel multi-agent framework\nthat integrates a Knowledge Graph (KG) of Regulatory triplets with\nRetrieval-Augmented Generation (RAG) to address these demands. First, agents\nbuild and maintain an ontology-free KG by extracting subject--predicate--object\n(SPO) triplets from regulatory documents and systematically cleaning,\nnormalizing, deduplicating, and updating them. Second, these triplets are\nembedded and stored along with their corresponding textual sections and\nmetadata in a single enriched vector database, allowing for both graph-based\nreasoning and efficient information retrieval. Third, an orchestrated agent\npipeline leverages triplet-level retrieval for question answering, ensuring\nhigh semantic alignment between user queries and the factual\n\"who-did-what-to-whom\" core captured by the graph. Our hybrid system\noutperforms conventional methods in complex regulatory queries, ensuring\nfactual correctness with embedded triplets, enabling traceability through a\nunified vector database, and enhancing understanding through subgraph\nvisualization, providing a robust foundation for compliance-driven and broader\naudit-focused applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u6cd5\u89c4\u5408\u89c4\u95ee\u7b54\u4e2d\u7684\u7cbe\u786e\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\u3002", "motivation": "\u6cd5\u89c4\u5408\u89c4\u95ee\u7b54\u9700\u8981\u9ad8\u7cbe\u5ea6\u3001\u53ef\u9a8c\u8bc1\u7684\u4fe1\u606f\u548c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u8fd9\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u51fa\u4e86\u6311\u6218\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u548c\u7ef4\u62a4\u65e0\u672c\u4f53\u77e5\u8bc6\u56fe\u8c31\uff08\u63d0\u53d6SPO\u4e09\u5143\u7ec4\uff09\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u95ee\u7b54\u548c\u63a8\u7406\u3002", "result": "\u6df7\u5408\u7cfb\u7edf\u5728\u590d\u6742\u6cd5\u89c4\u67e5\u8be2\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u786e\u4fdd\u4e8b\u5b9e\u6b63\u786e\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\uff0c\u5e76\u901a\u8fc7\u5b50\u56fe\u53ef\u89c6\u5316\u589e\u5f3a\u7406\u89e3\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5408\u89c4\u9a71\u52a8\u548c\u5ba1\u8ba1\u5e94\u7528\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2508.09855", "categories": ["cs.RO", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.09855", "abs": "https://arxiv.org/abs/2508.09855", "authors": ["Yuekun Wu", "Yik Lung Pang", "Andrea Cavallaro", "Changjae Oh"], "title": "Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes", "comment": "3 pages, 3 figures", "summary": "Human-robot teaming (HRT) systems often rely on large-scale datasets of human\nand robot interactions, especially for close-proximity collaboration tasks such\nas human-robot handovers. Learning robot manipulation policies from raw,\nreal-world image data requires a large number of robot-action trials in the\nphysical environment. Although simulation training offers a cost-effective\nalternative, the visual domain gap between simulation and robot workspace\nremains a major limitation. We introduce a method for training HRT policies,\nfocusing on human-to-robot handovers, solely from RGB images without the need\nfor real-robot training or real-robot data collection. The goal is to enable\nthe robot to reliably receive objects from a human with stable grasping while\navoiding collisions with the human hand. The proposed policy learner leverages\nsparse-view Gaussian Splatting reconstruction of human-to-robot handover scenes\nto generate robot demonstrations containing image-action pairs captured with a\ncamera mounted on the robot gripper. As a result, the simulated camera pose\nchanges in the reconstructed scene can be directly translated into gripper pose\nchanges. Experiments in both Gaussian Splatting reconstructed scene and\nreal-world human-to-robot handover experiments demonstrate that our method\nserves as a new and effective representation for the human-to-robot handover\ntask, contributing to more seamless and robust HRT.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u901a\u8fc7RGB\u56fe\u50cf\u8bad\u7ec3\u4eba\u673a\u534f\u4f5c\u7b56\u7565\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u771f\u5b9e\u673a\u5668\u4eba\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u4eff\u771f\u4e0e\u771f\u5b9e\u573a\u666f\u7684\u89c6\u89c9\u5dee\u5f02\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4eba\u673a\u534f\u4f5c\u4e2d\u771f\u5b9e\u673a\u5668\u4eba\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u53ca\u4eff\u771f\u4e0e\u771f\u5b9e\u573a\u666f\u89c6\u89c9\u5dee\u5f02\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u7a00\u758f\u89c6\u56fe\u9ad8\u65af\u6cfc\u6e85\u91cd\u5efa\u4eba\u673a\u4ea4\u63a5\u573a\u666f\uff0c\u751f\u6210\u56fe\u50cf-\u52a8\u4f5c\u5bf9\uff0c\u901a\u8fc7\u6a21\u62df\u76f8\u673a\u59ff\u6001\u53d8\u5316\u8bad\u7ec3\u673a\u5668\u4eba\u7b56\u7565\u3002", "result": "\u5728\u91cd\u5efa\u573a\u666f\u548c\u771f\u5b9e\u4eba\u673a\u4ea4\u63a5\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u7a33\u5b9a\u6293\u53d6\u548c\u907f\u969c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4eba\u673a\u4ea4\u63a5\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u8868\u793a\uff0c\u63d0\u5347\u4e86\u4eba\u673a\u534f\u4f5c\u7684\u6d41\u7545\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.09932", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09932", "abs": "https://arxiv.org/abs/2508.09932", "authors": ["Liang Zhang", "Edith Aurora Graf"], "title": "Mathematical Computation and Reasoning Errors by Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) are increasingly utilized in AI-driven\neducational instruction and assessment, particularly within mathematics\neducation. The capability of LLMs to generate accurate answers and detailed\nsolutions for math problem-solving tasks is foundational for ensuring reliable\nand precise feedback and assessment in math education practices. Our study\nfocuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1,\nDeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including\narithmetic, algebra, and number theory, and identifies step-level reasoning\nerrors within their solutions. Instead of relying on standard benchmarks, we\nintentionally build math tasks (via item models) that are challenging for LLMs\nand prone to errors. The accuracy of final answers and the presence of errors\nin individual solution steps were systematically analyzed and coded. Both\nsingle-agent and dual-agent configurations were tested. It is observed that the\nreasoning-enhanced OpenAI o1 model consistently achieved higher or nearly\nperfect accuracy across all three math task categories. Analysis of errors\nrevealed that procedural slips were the most frequent and significantly\nimpacted overall performance, while conceptual misunderstandings were less\nfrequent. Deploying dual-agent configurations substantially improved overall\nperformance. These findings offer actionable insights into enhancing LLM\nperformance and underscore effective strategies for integrating LLMs into\nmathematics education, thereby advancing AI-driven instructional practices and\nassessment precision.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u56db\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6570\u5b66\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u53d1\u73b0\u63a8\u7406\u589e\u5f3a\u7684OpenAI o1\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u53cc\u4ee3\u7406\u914d\u7f6e\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u8bc4\u4f30LLM\u5728\u6570\u5b66\u6559\u80b2\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u4e3aAI\u9a71\u52a8\u7684\u6559\u5b66\u548c\u8bc4\u4f30\u63d0\u4f9b\u53ef\u9760\u652f\u6301\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u6311\u6218\u6027\u6570\u5b66\u4efb\u52a1\uff0c\u5206\u6790\u56db\u79cdLLM\u5728\u7b97\u672f\u3001\u4ee3\u6570\u548c\u6570\u8bba\u4efb\u52a1\u4e2d\u7684\u7b54\u6848\u51c6\u786e\u6027\u548c\u6b65\u9aa4\u9519\u8bef\u3002", "result": "OpenAI o1\u6a21\u578b\u8868\u73b0\u6700\u4f18\uff0c\u53cc\u4ee3\u7406\u914d\u7f6e\u63d0\u5347\u6027\u80fd\uff0c\u7a0b\u5e8f\u6027\u9519\u8bef\u6700\u5e38\u89c1\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u5347LLM\u6027\u80fd\u548c\u6570\u5b66\u6559\u80b2\u4e2d\u7684AI\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7b56\u7565\u3002"}}
{"id": "2508.09876", "categories": ["cs.RO", "cs.SY", "eess.SY", "I.2.9"], "pdf": "https://arxiv.org/pdf/2508.09876", "abs": "https://arxiv.org/abs/2508.09876", "authors": ["Xiaowei Tan", "Weizhong Jiang", "Bi Zhang", "Wanxin Chen", "Yiwen Zhao", "Ning Li", "Lianqing Liu", "Xingang Zhao"], "title": "A Shank Angle-Based Control System Enables Soft Exoskeleton to Assist Human Non-Steady Locomotion", "comment": "49 pages, 20 figures, 4 tables", "summary": "Exoskeletons have been shown to effectively assist humans during steady\nlocomotion. However, their effects on non-steady locomotion, characterized by\nnonlinear phase progression within a gait cycle, remain insufficiently\nexplored, particularly across diverse activities. This work presents a shank\nangle-based control system that enables the exoskeleton to maintain real-time\ncoordination with human gait, even under phase perturbations, while dynamically\nshaping assistance profiles to match the biological ankle moment patterns\nacross walking, running, stair negotiation tasks. The control system consists\nof an assistance profile online generation method and a model-based feedforward\ncontrol method. The assistance profile is formulated as a dual-Gaussian model\nwith the shank angle as the independent variable. Leveraging only IMU\nmeasurements, the model parameters are updated online each stride to adapt to\ninter- and intra-individual biomechanical variability. The profile tracking\ncontrol employs a human-exoskeleton kinematics and stiffness model as a\nfeedforward component, reducing reliance on historical control data due to the\nlack of clear and consistent periodicity in non-steady locomotion. Three\nexperiments were conducted using a lightweight soft exoskeleton with multiple\nsubjects. The results validated the effectiveness of each individual method,\ndemonstrated the robustness of the control system against gait perturbations\nacross various activities, and revealed positive biomechanical and\nphysiological responses of human users to the exoskeleton's mechanical\nassistance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u817f\u89d2\u5ea6\u7684\u5916\u9aa8\u9abc\u63a7\u5236\u7cfb\u7edf\uff0c\u9002\u7528\u4e8e\u975e\u7a33\u6001\u6b65\u6001\uff0c\u80fd\u5b9e\u65f6\u534f\u8c03\u5e76\u52a8\u6001\u8c03\u6574\u52a9\u529b\u6a21\u5f0f\u3002", "motivation": "\u63a2\u7d22\u5916\u9aa8\u9abc\u5728\u975e\u7ebf\u6027\u6b65\u6001\uff08\u5982\u884c\u8d70\u3001\u8dd1\u6b65\u3001\u4e0a\u4e0b\u697c\u68af\uff09\u4e2d\u7684\u6548\u679c\uff0c\u89e3\u51b3\u73b0\u6709\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u53cc\u9ad8\u65af\u6a21\u578b\u751f\u6210\u5728\u7ebf\u52a9\u529b\u6a21\u5f0f\uff0c\u7ed3\u5408\u6a21\u578b\u524d\u9988\u63a7\u5236\uff0c\u4ec5\u9700IMU\u6570\u636e\u9002\u5e94\u4e2a\u4f53\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u5728\u591a\u79cd\u6d3b\u52a8\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u7528\u6237\u5bf9\u5916\u9aa8\u9abc\u52a9\u529b\u8868\u73b0\u51fa\u79ef\u6781\u7684\u751f\u7269\u529b\u5b66\u548c\u751f\u7406\u53cd\u5e94\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u975e\u7a33\u6001\u6b65\u6001\u4e0b\u7684\u5916\u9aa8\u9abc\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2504.19716", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2504.19716", "abs": "https://arxiv.org/abs/2504.19716", "authors": ["Navin Sriram Ravie", "Keerthi Vasan M", "Asokan Thondiyath", "Bijo Sebastian"], "title": "QuickGrasp: Lightweight Antipodal Grasp Planning with Point Clouds", "comment": null, "summary": "Grasping has been a long-standing challenge in facilitating the final\ninterface between a robot and the environment. As environments and tasks become\ncomplicated, the need to embed higher intelligence to infer from the\nsurroundings and act on them has become necessary. Although most methods\nutilize techniques to estimate grasp pose by treating the problem via pure\nsampling-based approaches in the six-degree-of-freedom space or as a learning\nproblem, they usually fail in real-life settings owing to poor generalization\nacross domains. In addition, the time taken to generate the grasp plan and the\nlack of repeatability, owing to sampling inefficiency and the probabilistic\nnature of existing grasp planning approaches, severely limits their application\nin real-world tasks. This paper presents a lightweight analytical approach\ntowards robotic grasp planning, particularly antipodal grasps, with little to\nno sampling in the six-degree-of-freedom space. The proposed grasp planning\nalgorithm is formulated as an optimization problem towards estimating grasp\npoints on the object surface instead of directly estimating the end-effector\npose. To this extent, a soft-region-growing algorithm is presented for\neffective plane segmentation, even in the case of curved surfaces. An\noptimization-based quality metric is then used for the evaluation of grasp\npoints to ensure indirect force closure. The proposed grasp framework is\ncompared with the existing state-of-the-art grasp planning approach, Grasp pose\ndetection (GPD), as a baseline over multiple simulated objects. The\neffectiveness of the proposed approach in comparison to GPD is also evaluated\nin a real-world setting using image and point-cloud data, with the planned\ngrasps being executed using a ROBOTIQ gripper and UR5 manipulator.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u5206\u6790\u65b9\u6cd5\u7528\u4e8e\u673a\u5668\u4eba\u6293\u53d6\u89c4\u5212\uff0c\u7279\u522b\u662f\u5bf9\u5411\u6293\u53d6\uff0c\u51cf\u5c11\u4e86\u516d\u81ea\u7531\u5ea6\u7a7a\u95f4\u7684\u91c7\u6837\u9700\u6c42\u3002\u901a\u8fc7\u4f18\u5316\u95ee\u9898\u4f30\u8ba1\u7269\u4f53\u8868\u9762\u7684\u6293\u53d6\u70b9\uff0c\u5e76\u91c7\u7528\u8f6f\u533a\u57df\u751f\u957f\u7b97\u6cd5\u8fdb\u884c\u5e73\u9762\u5206\u5272\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5GPD\u3002", "motivation": "\u73b0\u6709\u6293\u53d6\u89c4\u5212\u65b9\u6cd5\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u6cdb\u5316\u80fd\u529b\u5dee\u3001\u6548\u7387\u4f4e\u4e14\u7f3a\u4e4f\u53ef\u91cd\u590d\u6027\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f18\u5316\u7684\u6293\u53d6\u70b9\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7ed3\u5408\u8f6f\u533a\u57df\u751f\u957f\u7b97\u6cd5\u8fdb\u884c\u5e73\u9762\u5206\u5272\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u8d28\u91cf\u6307\u6807\u8bc4\u4f30\u6293\u53d6\u70b9\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5Grasp pose detection (GPD)\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u673a\u5668\u4eba\u6293\u53d6\u89c4\u5212\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.09950", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.09950", "abs": "https://arxiv.org/abs/2508.09950", "authors": ["Bida Ma", "Nuo Xu", "Chenkun Qi", "Xin Liu", "Yule Mo", "Jinkai Wang", "Chunpeng Lu"], "title": "PPL: Point Cloud Supervised Proprioceptive Locomotion Reinforcement Learning for Legged Robots in Crawl Spaces", "comment": null, "summary": "The legged locomotion in spatially constrained structures (called crawl\nspaces) is challenging. In crawl spaces, current exteroceptive locomotion\nlearning methods are limited by large noises and errors of the sensors in\npossible low visibility conditions, and current proprioceptive locomotion\nlearning methods are difficult in traversing crawl spaces because only ground\nfeatures are inferred. In this study, a point cloud supervised proprioceptive\nlocomotion reinforcement learning method for legged robots in crawl spaces is\nproposed. A state estimation network is designed to estimate the robot's\nsurrounding ground and spatial features as well as the robot's collision states\nusing historical proprioceptive sensor data. The point cloud is represented in\npolar coordinate frame and a point cloud processing method is proposed to\nefficiently extract the ground and spatial features that are used to supervise\nthe state estimation network learning. Comprehensive reward functions that\nguide the robot to traverse through crawl spaces after collisions are designed.\nExperiments demonstrate that, compared to existing methods, our method exhibits\nmore agile locomotion in crawl spaces. This study enhances the ability of\nlegged robots to traverse spatially constrained environments without requiring\nexteroceptive sensors.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u70b9\u4e91\u76d1\u7763\u7684\u817f\u90e8\u673a\u5668\u4eba\u722c\u884c\u7a7a\u95f4\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5386\u53f2\u672c\u4f53\u611f\u53d7\u6570\u636e\u4f30\u8ba1\u73af\u5883\u7279\u5f81\uff0c\u65e0\u9700\u5916\u90e8\u4f20\u611f\u5668\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5916\u90e8\u611f\u77e5\u65b9\u6cd5\u5728\u4f4e\u80fd\u89c1\u5ea6\u4e0b\u566a\u58f0\u5927\u3001\u672c\u4f53\u611f\u77e5\u65b9\u6cd5\u96be\u4ee5\u63a8\u65ad\u7a7a\u95f4\u7279\u5f81\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u72b6\u6001\u4f30\u8ba1\u7f51\u7edc\uff0c\u5229\u7528\u6781\u5750\u6807\u70b9\u4e91\u5904\u7406\u63d0\u53d6\u5730\u9762\u548c\u7a7a\u95f4\u7279\u5f81\uff0c\u7ed3\u5408\u5956\u52b1\u51fd\u6570\u6307\u5bfc\u673a\u5668\u4eba\u8fd0\u52a8\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u722c\u884c\u7a7a\u95f4\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u7075\u6d3b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u817f\u90e8\u673a\u5668\u4eba\u5728\u53d7\u9650\u7a7a\u95f4\u4e2d\u7684\u8fd0\u52a8\u80fd\u529b\uff0c\u65e0\u9700\u4f9d\u8d56\u5916\u90e8\u4f20\u611f\u5668\u3002"}}
{"id": "2508.09960", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09960", "abs": "https://arxiv.org/abs/2508.09960", "authors": ["Yifei Yao", "Chengyuan Luo", "Jiaheng Du", "Wentao He", "Jun-Guo Lu"], "title": "GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation", "comment": null, "summary": "The creation of human-like humanoid robots is hindered by a fundamental\nfragmentation: data processing and learning algorithms are rarely universal\nacross different robot morphologies. This paper introduces the Generalized\nBehavior Cloning (GBC) framework, a comprehensive and unified solution designed\nto solve this end-to-end challenge. GBC establishes a complete pathway from\nhuman motion to robot action through three synergistic innovations. First, an\nadaptive data pipeline leverages a differentiable IK network to automatically\nretarget any human MoCap data to any humanoid. Building on this foundation, our\nnovel DAgger-MMPPO algorithm with its MMTransformer architecture learns robust,\nhigh-fidelity imitation policies. To complete the ecosystem, the entire\nframework is delivered as an efficient, open-source platform based on Isaac\nLab, empowering the community to deploy the full workflow via simple\nconfiguration scripts. We validate the power and generality of GBC by training\npolicies on multiple heterogeneous humanoids, demonstrating excellent\nperformance and transfer to novel motions. This work establishes the first\npractical and unified pathway for creating truly generalized humanoid\ncontrollers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u884c\u4e3a\u514b\u9686\uff08GBC\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6570\u636e\u7ba1\u9053\u3001DAgger-MMPPO\u7b97\u6cd5\u548c\u5f00\u6e90\u5e73\u53f0\uff0c\u5b9e\u73b0\u4e86\u4ece\u4eba\u7c7b\u52a8\u4f5c\u5230\u673a\u5668\u4eba\u884c\u4e3a\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u4eba\u5f62\u673a\u5668\u4eba\u5f00\u53d1\u9762\u4e34\u6570\u636e\u548c\u5b66\u4e60\u7b97\u6cd5\u65e0\u6cd5\u8de8\u5f62\u6001\u901a\u7528\u7684\u6311\u6218\uff0c\u963b\u788d\u4e86\u4eba\u5f62\u673a\u5668\u4eba\u7684\u53d1\u5c55\u3002", "method": "GBC\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u521b\u65b0\uff1a\u81ea\u9002\u5e94\u6570\u636e\u7ba1\u9053\u3001DAgger-MMPPO\u7b97\u6cd5\u548c\u57fa\u4e8eIsaac Lab\u7684\u5f00\u6e90\u5e73\u53f0\u3002", "result": "\u5728\u591a\u79cd\u5f02\u6784\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86GBC\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "GBC\u4e3a\u521b\u5efa\u901a\u7528\u4eba\u5f62\u63a7\u5236\u5668\u63d0\u4f9b\u4e86\u9996\u4e2a\u5b9e\u7528\u4e14\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09971", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09971", "abs": "https://arxiv.org/abs/2508.09971", "authors": ["Zihan Wang", "Nina Mahmoudian"], "title": "Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model", "comment": "Submitted to Robotics and Autonomous Systems (RAS) journal", "summary": "Vision-driven autonomous river following by Unmanned Aerial Vehicles is\ncritical for applications such as rescue, surveillance, and environmental\nmonitoring, particularly in dense riverine environments where GPS signals are\nunreliable. We formalize river following as a coverage control problem in which\nthe reward function is submodular, yielding diminishing returns as more unique\nriver segments are visited, thereby framing the task as a Submodular Markov\nDecision Process. First, we introduce Marginal Gain Advantage Estimation, which\nrefines the reward advantage function by using a sliding window baseline\ncomputed from historical episodic returns, thus aligning the advantage\nestimation with the agent's evolving recognition of action value in\nnon-Markovian settings. Second, we develop a Semantic Dynamics Model based on\npatchified water semantic masks that provides more interpretable and\ndata-efficient short-term prediction of future observations compared to latent\nvision dynamics models. Third, we present the Constrained Actor Dynamics\nEstimator architecture, which integrates the actor, the cost estimator, and SDM\nfor cost advantage estimation to form a model-based SafeRL framework capable of\nsolving partially observable Constrained Submodular Markov Decision Processes.\nSimulation results demonstrate that MGAE achieves faster convergence and\nsuperior performance over traditional critic-based methods like Generalized\nAdvantage Estimation. SDM provides more accurate short-term state predictions\nthat enable the cost estimator to better predict potential violations. Overall,\nCADE effectively integrates safety regulation into model-based RL, with the\nLagrangian approach achieving the soft balance of reward and safety during\ntraining, while the safety layer enhances performance during inference by hard\naction overlay.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9\u7684\u65e0\u4eba\u673a\u81ea\u4e3b\u6cb3\u6d41\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b50\u6a21\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u3001\u8fb9\u9645\u589e\u76ca\u4f18\u52bf\u4f30\u8ba1\u548c\u8bed\u4e49\u52a8\u6001\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u6cb3\u6d41\u8986\u76d6\u63a7\u5236\u3002", "motivation": "\u5728\u5bc6\u96c6\u6cb3\u6d41\u73af\u5883\u4e2d\uff0cGPS\u4fe1\u53f7\u4e0d\u53ef\u9760\uff0c\u89c6\u89c9\u9a71\u52a8\u7684\u65e0\u4eba\u673a\u81ea\u4e3b\u6cb3\u6d41\u8ddf\u8e2a\u5bf9\u6551\u63f4\u3001\u76d1\u89c6\u548c\u73af\u5883\u76d1\u6d4b\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "1. \u63d0\u51fa\u8fb9\u9645\u589e\u76ca\u4f18\u52bf\u4f30\u8ba1\uff08MGAE\uff09\u4f18\u5316\u5956\u52b1\u4f18\u52bf\u51fd\u6570\uff1b2. \u5f00\u53d1\u57fa\u4e8e\u8bed\u4e49\u63a9\u7801\u7684\u8bed\u4e49\u52a8\u6001\u6a21\u578b\uff08SDM\uff09\uff1b3. \u8bbe\u8ba1\u7ea6\u675f\u6f14\u5458\u52a8\u6001\u4f30\u8ba1\u5668\uff08CADE\uff09\u67b6\u6784\uff0c\u6574\u5408\u6a21\u578b\u4e0e\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u3002", "result": "MGAE\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6536\u655b\u66f4\u5feb\u4e14\u6027\u80fd\u66f4\u4f18\uff1bSDM\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u77ed\u671f\u72b6\u6001\u9884\u6d4b\uff1bCADE\u6210\u529f\u5c06\u5b89\u5168\u7ea6\u675f\u6574\u5408\u5230\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u73af\u5883\u4e2d\u9ad8\u6548\u4e14\u5b89\u5168\u5730\u89e3\u51b3\u4e86\u6cb3\u6d41\u8ddf\u8e2a\u95ee\u9898\uff0c\u4e3a\u65e0\u4eba\u673a\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.09976", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.09976", "abs": "https://arxiv.org/abs/2508.09976", "authors": ["Marion Lepert", "Jiaying Fang", "Jeannette Bohg"], "title": "Masquerade: Learning from In-the-wild Human Videos using Data-Editing", "comment": "Project website at https://masquerade-robot.github.io/", "summary": "Robot manipulation research still suffers from significant data scarcity:\neven the largest robot datasets are orders of magnitude smaller and less\ndiverse than those that fueled recent breakthroughs in language and vision. We\nintroduce Masquerade, a method that edits in-the-wild egocentric human videos\nto bridge the visual embodiment gap between humans and robots and then learns a\nrobot policy with these edited videos. Our pipeline turns each human video into\nrobotized demonstrations by (i) estimating 3-D hand poses, (ii) inpainting the\nhuman arms, and (iii) overlaying a rendered bimanual robot that tracks the\nrecovered end-effector trajectories. Pre-training a visual encoder to predict\nfuture 2-D robot keypoints on 675K frames of these edited clips, and continuing\nthat auxiliary loss while fine-tuning a diffusion policy head on only 50 robot\ndemonstrations per task, yields policies that generalize significantly better\nthan prior work. On three long-horizon, bimanual kitchen tasks evaluated in\nthree unseen scenes each, Masquerade outperforms baselines by 5-6x. Ablations\nshow that both the robot overlay and co-training are indispensable, and\nperformance scales logarithmically with the amount of edited human video. These\nresults demonstrate that explicitly closing the visual embodiment gap unlocks a\nvast, readily available source of data from human videos that can be used to\nimprove robot policies.", "AI": {"tldr": "Masquerade\u65b9\u6cd5\u901a\u8fc7\u7f16\u8f91\u4eba\u7c7b\u89c6\u9891\u751f\u6210\u673a\u5668\u4eba\u6f14\u793a\uff0c\u663e\u8457\u63d0\u5347\u673a\u5668\u4eba\u7b56\u7565\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u673a\u5668\u4eba\u64cd\u4f5c\u7814\u7a76\u6570\u636e\u7a00\u7f3a\uff0c\u4eba\u7c7b\u89c6\u9891\u8d44\u6e90\u4e30\u5bcc\u4f46\u89c6\u89c9\u4f53\u73b0\u5dee\u5f02\u5927\uff0c\u9700\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u7f16\u8f91\u4eba\u7c7b\u89c6\u9891\uff1a\u4f30\u8ba13D\u624b\u90e8\u59ff\u52bf\u3001\u4fee\u590d\u624b\u81c2\u3001\u53e0\u52a0\u673a\u5668\u4eba\u8f68\u8ff9\uff0c\u9884\u8bad\u7ec3\u89c6\u89c9\u7f16\u7801\u5668\u5e76\u5fae\u8c03\u6269\u6563\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u672a\u89c1\u573a\u666f\u7684\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf5-6\u500d\u3002", "conclusion": "\u901a\u8fc7\u89c6\u89c9\u4f53\u73b0\u5dee\u8ddd\u5f25\u5408\uff0c\u4eba\u7c7b\u89c6\u9891\u6210\u4e3a\u63d0\u5347\u673a\u5668\u4eba\u7b56\u7565\u7684\u6709\u6548\u6570\u636e\u6e90\u3002"}}
