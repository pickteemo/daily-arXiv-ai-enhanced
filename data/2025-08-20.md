<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]
- [cs.AI](#cs.AI) [Total: 41]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Diff-MSM: Differentiable MusculoSkeletal Model for Simultaneous Identification of Human Muscle and Bone Parameters](https://arxiv.org/abs/2508.13303)
*Yingfan Zhou,Philip Sanderink,Sigurd Jager Lemming,Cheng Fang*

Main category: cs.RO

TL;DR: 提出可微分肌肉骨骼模型(Diff-MSM)，通过端到端自动微分技术同时识别肌肉和骨骼参数，无需测量内部关节扭矩，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高保真个性化人体肌肉骨骼模型对于人机交互系统仿真和安全验证至关重要，但传统方法难以直接测量内部生物力学变量，特别是关节扭矩。

Method: 使用可微分肌肉骨骼模型(Diff-MSM)，通过自动微分技术从可测量的肌肉激活到可观察的运动进行端到端参数识别，无需测量内部关节扭矩。

Result: 仿真结果表明该方法显著优于现有基线方法，肌肉参数估计误差低至0.05%（初始猜测从均值为真实值、标准差为10%的正态分布中采样）。

Conclusion: Diff-MSM参数识别技术不仅在肌肉骨骼建模和仿真中有重要应用，在肌肉健康监测、康复和运动科学等领域也具有巨大潜力。

Abstract: High-fidelity personalized human musculoskeletal models are crucial for
simulating realistic behavior of physically coupled human-robot interactive
systems and verifying their safety-critical applications in simulations before
actual deployment, such as human-robot co-transportation and rehabilitation
through robotic exoskeletons. Identifying subject-specific Hill-type muscle
model parameters and bone dynamic parameters is essential for a personalized
musculoskeletal model, but very challenging due to the difficulty of measuring
the internal biomechanical variables in vivo directly, especially the joint
torques. In this paper, we propose using Differentiable MusculoSkeletal Model
(Diff-MSM) to simultaneously identify its muscle and bone parameters with an
end-to-end automatic differentiation technique differentiating from the
measurable muscle activation, through the joint torque, to the resulting
observable motion without the need to measure the internal joint torques.
Through extensive comparative simulations, the results manifested that our
proposed method significantly outperformed the state-of-the-art baseline
methods, especially in terms of accurate estimation of the muscle parameters
(i.e., initial guess sampled from a normal distribution with the mean being the
ground truth and the standard deviation being 10% of the ground truth could end
up with an average of the percentage errors of the estimated values as low as
0.05%). In addition to human musculoskeletal modeling and simulation, the new
parameter identification technique with the Diff-MSM has great potential to
enable new applications in muscle health monitoring, rehabilitation, and sports
science.

</details>


### [2] [A Surveillance Based Interactive Robot](https://arxiv.org/abs/2508.13319)
*Kshitij Kavimandan,Pooja Mangal,Devanshi Mehta*

Main category: cs.RO

TL;DR: 基于树莓派Raspberry Pi的移动监控机器人系统，支持实时视频流、语音控制和多语言交互，通过YOLOv3进行对象检测和自主导航


<details>
  <summary>Details</summary>
Motivation: 构建一个使用普通硬件和开源软件的易于复现的移动监控机器人系统，支持远程监控和语音控制

Method: 采用两个Raspberry Pi 4单元：前端单元负责感知和运动，中央单元负责视频流和视觉处理。使用FFmpeg传输视频，YOLOv3进行对象检测，Python语音库实现语音识别和多语言语音合成，Kinect RGB-D传感器提供深度信息

Result: 室内测试中，机器人能够在CPU上以交互弧率检测常见物体，可靠识别命令，并将其转换为动作而无需手动控制

Conclusion: 设计依赖商用硬件和开源软件，易于复现。讨论了传感器融合、GPU加速、人脸和文本识别等扩展可能性

Abstract: We build a mobile surveillance robot that streams video in real time and
responds to speech so a user can monitor and steer it from a phone or browser.
The system uses two Raspberry Pi 4 units: a front unit on a differential drive
base with camera, mic, and speaker, and a central unit that serves the live
feed and runs perception. Video is sent with FFmpeg. Objects in the scene are
detected using YOLOv3 to support navigation and event awareness. For voice
interaction, we use Python libraries for speech recognition, multilingual
translation, and text-to-speech, so the robot can take spoken commands and read
back responses in the requested language. A Kinect RGB-D sensor provides visual
input and obstacle cues. In indoor tests the robot detects common objects at
interactive frame rates on CPU, recognises commands reliably, and translates
them to actions without manual control. The design relies on off-the-shelf
hardware and open software, making it easy to reproduce. We discuss limits and
practical extensions, including sensor fusion with ultrasonic range data, GPU
acceleration, and adding face and text recognition.

</details>


### [3] [Incremental Generalized Hybrid A*](https://arxiv.org/abs/2508.13392)
*Sidharth Talia,Oren Salzman,Siddhartha Srinivasa*

Main category: cs.RO

TL;DR: 提出了Incremental Generalized Hybrid A* (IGHA*)算法，通过动态组织顶点扩展而非刚性剪枝，在复杂动力学规划中比传统Hybrid A*减少6倍扩展次数，实现实时性能


<details>
  <summary>Details</summary>
Motivation: 解决大型树搜索的高效组织问题，特别是在越野自动驾驶等需要实时规划的复杂动力学场景中。传统Hybrid A*的网格分辨率选择困难，过粗会导致失败，过细则导致扩展过多和规划缓慢

Method: 提出增量广义混合A*（IGHA*）框架，采用动态顶点扩展组织方式，避免刚性剪枝。这是一个随时树搜索框架，能够渐进式改进解决方案

Result: 在汽车类机器人的道路运动学和越野动力学规划查询中，IGHA*变体比优化版Hybrid A*减少6倍扩展次数。在高保真模拟器的越野实验中，IGHA*优于HA*M，并在仿真和小型越野车辆上展示了实时性能

Conclusion: IGHA*算法能够实现复杂动力学下的快速鲁棒规划，在理论和实验上都证明优于传统Hybrid A*方法，为实时自动驾驶规划提供了有效解决方案

Abstract: We address the problem of efficiently organizing search over very large
trees, which arises in many applications ranging from autonomous driving to
aerial vehicles. Here, we are motivated by off-road autonomy, where real-time
planning is essential. Classical approaches use graphs of motion primitives and
exploit dominance to mitigate the curse of dimensionality and prune expansions
efficiently. However, for complex dynamics, repeatedly solving two-point
boundary-value problems makes graph construction too slow for fast kinodynamic
planning. Hybrid A* (HA*) addressed this challenge by searching over a tree of
motion primitives and introducing approximate pruning using a grid-based
dominance check. However, choosing the grid resolution is difficult: too coarse
risks failure, while too fine leads to excessive expansions and slow planning.
We propose Incremental Generalized Hybrid A* (IGHA*), an anytime tree-search
framework that dynamically organizes vertex expansions without rigid pruning.
IGHA* provably matches or outperforms HA*. For both on-road kinematic and
off-road kinodynamic planning queries for a car-like robot, variants of IGHA*
use 6x fewer expansions to the best solution compared to an optimized version
of HA*. In simulated off-road experiments in a high fidelity simulator, IGHA*
outperforms HA*M when both are used in the loop with a model predictive
controller. We demonstrate real-time performance both in simulation and on a
small-scale off-road vehicle, enabling fast, robust planning under complex
dynamics. Code: https://github.com/personalrobotics/IGHAStar

</details>


### [4] [Accelerating Signal-Temporal-Logic-Based Task and Motion Planning of Bipedal Navigation using Benders Decomposition](https://arxiv.org/abs/2508.13407)
*Jiming Ren,Xuan Lin,Roman Mineyev,Karen M. Feigh,Samuel Coogan,Ye Zhao*

Main category: cs.RO

TL;DR: 提出基于Benders分解的方法来解决双足机器人运动规划中混合整数规划的计算复杂度问题，通过主问题和子问题迭代求解，比传统方法更快


<details>
  <summary>Details</summary>
Motivation: 双足机器人运动规划中的任务和运动规划在信号时序逻辑约束下是NP难问题，混合整数规划方法在处理非凸约束（如运动学可达性和脚步旋转）时计算复杂度极高

Method: 使用Benders分解方法，将问题分解为主问题（生成满足任务规范的计划原型）和一系列子问题（进行运动学和动力学可行性检查），采用迭代切割平面技术

Result: 实验证明该方法比替代算法在求解具有非线性约束的优化程序时实现了更快的规划速度

Conclusion: Benders分解方法能有效解决双足机器人运动规划中的计算复杂性问题，为处理混合整数规划问题提供了可行的解决方案

Abstract: Task and motion planning under Signal Temporal Logic constraints is known to
be NP-hard. A common class of approaches formulates these hybrid problems,
which involve discrete task scheduling and continuous motion planning, as
mixed-integer programs (MIP). However, in applications for bipedal locomotion,
introduction of non-convex constraints such as kinematic reachability and
footstep rotation exacerbates the computational complexity of MIPs. In this
work, we present a method based on Benders Decomposition to address scenarios
where solving the entire monolithic optimization problem is prohibitively
intractable. Benders Decomposition proposes an iterative cutting-plane
technique that partitions the problem into a master problem to prototype a plan
that meets the task specification, and a series of subproblems for kinematics
and dynamics feasibility checks. Our experiments demonstrate that this method
achieves faster planning compared to alternative algorithms for solving the
resulting optimization program with nonlinear constraints.

</details>


### [5] [Switch4EAI: Leveraging Console Game Platform for Benchmarking Robotic Athletics](https://arxiv.org/abs/2508.13444)
*Tianyu Li,Jeonghwan Kim,Wontaek Kim,Donghoon Baek,Seungeun Rho,Sehoon Ha*

Main category: cs.RO

TL;DR: Switch4EAI是一个低成本、易部署的评估系统，利用体感游戏（如Just Dance）来评估全身机器人控制策略的性能，并在Unitree G1人形机器人上验证了可行性


<details>
  <summary>Details</summary>
Motivation: 当前缺乏在真实环境中评估人形机器人运动性能并与人类进行直接比较的标准化基准测试方法

Method: 利用任天堂Switch的体感游戏捕获、重建和重定向游戏中的舞蹈动作，通过开源全身控制器在Unitree G1人形机器人上执行

Result: 成功建立了机器人性能的量化基线，并与人类玩家进行了比较验证

Conclusion: 商业游戏平台可以作为物理基础的基准测试工具，为具身AI的基准测试提供了新的方向

Abstract: Recent advances in whole-body robot control have enabled humanoid and legged
robots to execute increasingly agile and coordinated movements. However,
standardized benchmarks for evaluating robotic athletic performance in
real-world settings and in direct comparison to humans remain scarce. We
present Switch4EAI(Switch-for-Embodied-AI), a low-cost and easily deployable
pipeline that leverages motion-sensing console games to evaluate whole-body
robot control policies. Using Just Dance on the Nintendo Switch as a
representative example, our system captures, reconstructs, and retargets
in-game choreography for robotic execution. We validate the system on a Unitree
G1 humanoid with an open-source whole-body controller, establishing a
quantitative baseline for the robot's performance against a human player. In
the paper, we discuss these results, which demonstrate the feasibility of using
commercial games platform as physically grounded benchmarks and motivate future
work to for benchmarking embodied AI.

</details>


### [6] [CAST: Counterfactual Labels Improve Instruction Following in Vision-Language-Action Models](https://arxiv.org/abs/2508.13446)
*Catherine Glossop,William Chen,Arjun Bhorkar,Dhruv Shah,Sergey Levine*

Main category: cs.RO

TL;DR: 本文提出了一种利用视觉语言模型生成反事实标签来增强机器人数据集的方法，显著提升了视觉语言动作模型在细粒度指令跟随方面的能力，在导航任务中成功率提高了27%。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言动作模型在处理细粒度指令时表现不佳，主要原因是现有机器人数据集缺乏语义多样性和语言基础，特别是针对相似观察的细粒度任务多样性不足。

Method: 提出了一种新颖的数据增强方法，利用视觉语言模型为现有机器人数据集创建反事实标签，通过生成反事实语言和动作来增加语言基础的多样性和粒度。

Result: 在3个不同室内外环境中的视觉语言导航实验表明，该方法显著提升了VLA策略的指令跟随能力，使其与最先进方法竞争，导航任务成功率提高了27%。

Conclusion: 反事实重标注方法无需额外数据收集就能有效提升VLA模型的指令跟随性能，为解决机器人数据集语言基础不足的问题提供了有效解决方案。

Abstract: Generalist robots should be able to understand and follow user instructions,
but current vision-language-action (VLA) models struggle with following
fine-grained commands despite providing a powerful architecture for mapping
open-vocabulary natural language instructions to robot actions. One cause for
this is a lack of semantic diversity and language grounding in existing robot
datasets and, specifically, a lack of fine-grained task diversity for similar
observations. To address this, we present a novel method to augment existing
robot datasets by leveraging vision language models to create counterfactual
labels. Our method improves the language-following capabilities of VLAs by
increasing the diversity and granularity of language grounding for robot
datasets by generating counterfactual language and actions. We evaluate the
resulting model's ability to follow language instructions, ranging from simple
object-centric commands to complex referential tasks, by conducting visual
language navigation experiments in 3 different indoor and outdoor environments.
Our experiments demonstrate that counterfactual relabeling, without any
additional data collection, significantly improves instruction-following in VLA
policies, making them competitive with state-of-the-art methods and increasing
success rate by 27% on navigation tasks.

</details>


### [7] [Modeling and Control of AWOISV: A Filtered Tube-Based MPC Approach for Simultaneous Tracking of Lateral Position and Heading Angle](https://arxiv.org/abs/2508.13457)
*Xu Yang,Jun Ni,Hengyang Feng,Feiyu Wang,Tiezhen Wang*

Main category: cs.RO

TL;DR: 本文提出了一种全轮全向独立转向车辆(AWOISV)的理论框架和控制策略，通过建立转向半径角和侧偏角表示法，开发了广义动力学模型，并设计了滤波管式线性时变MPC控制器，实现了位置和航向角的高精度同步跟踪。


<details>
  <summary>Details</summary>
Motivation: 全轮全向独立转向车辆具有独特的机动能力（如横摆和对角线移动），但现有控制方法难以实现位置和航向角的同时精确控制，且缺乏统一的运动模式切换理论框架。

Method: 1) 提出基于瞬时旋转中心位置的转向半径角-侧偏角(θ_R-β_R)表示法；2) 建立以速度v、侧偏角β、横摆率r为状态，θ_R和β_R为控制输入的广义动力学模型；3) 设计滤波管式线性时变MPC(FT-LTVMPC)控制策略。

Result: 通过联合仿真和硬件在环实验验证，FT-LTVMPC能够实现位置和任意航向角的高精度同步跟踪，对模型不精确性和参数不确定性具有鲁棒性，且保证了优异的实时性能。

Conclusion: 所提出的理论框架和控制策略为AWOISV提供了统一的运动模式描述和切换标准，实现了多运动模式间的无缝过渡，为全向移动机器人的精确控制提供了有效解决方案。

Abstract: An all-wheel omni-directional independent steering vehicle (AWOISV) is a
specialized all-wheel independent steering vehicle with each wheel capable of
steering up to 90{\deg}, enabling unique maneuvers like yaw and diagonal
movement. This paper introduces a theoretical steering radius angle and
sideslip angle (\( \theta_R \)-\(\beta_R \)) representation, based on the
position of the instantaneous center of rotation relative to the wheel rotation
center, defining the motion modes and switching criteria for AWOISVs. A
generalized \( v\)-\(\beta\)-\(r \) dynamic model is developed with forward
velocity \(v\), sideslip angle \(\beta\), and yaw rate \(r\) as states, and
\(\theta_R\) and \(\beta_R\) as control inputs. This model decouples
longitudinal and lateral motions into forward and rotational motions, allowing
seamless transitions across all motion modes under specific conditions. A
filtered tube-based linear time-varying MPC (FT-LTVMPC) strategy is proposed,
achieving simultaneous tracking of lateral position and arbitrary heading
angles, with robustness to model inaccuracies and parameter uncertainties.
Co-simulation and hardware-in-loop (HIL) experiments confirm that FT-LTVMPC
enables high-precision control of both position and heading while ensuring
excellent real-time performance.

</details>


### [8] [Multi-Robot Navigation in Social Mini-Games: Definitions, Taxonomy, and Algorithms](https://arxiv.org/abs/2508.13459)
*Rohan Chandra,Shubham Singh,Abhishek Jha,Dannon Andrade,Hriday Sainathuni,Katia Sycara*

Main category: cs.RO

TL;DR: 本文对社交小游戏（SMG）导航研究进行了首次系统性分类，提出了统一分类法和评估协议，以解决该领域研究缺乏标准化的问题。


<details>
  <summary>Details</summary>
Motivation: 解决"最后一英里挑战"中机器人导航在受限拥挤环境（SMG）中的性能问题，当前SMG导航研究缺乏统一分类和标准化评估，导致研究比较困难和新研究者入门障碍。

Method: 通过定义明确的统一分类法对现有SMG求解器进行编目和分类，建立专门的评估指标和协议。

Result: 创建了首个SMG导航研究的系统性分类框架，为后续研究提供了标准化基础。

Conclusion: SMG导航研究需要专门的分类法、定义和评估协议来指导有效研究，本调查为该领域建立了必要的标准化框架。

Abstract: The ``Last Mile Challenge'' has long been considered an important, yet
unsolved, challenge for autonomous vehicles, public service robots, and
delivery robots. A central issue in this challenge is the ability of robots to
navigate constrained and cluttered environments (e.g., doorways, hallways,
corridor intersections), often while competing for space with other robots and
humans. We refer to these environments as ``Social Mini-Games'' (SMGs). SMGs
are tightly coupled, high-agency interactions that arise within general
multi-robot navigation (MRN) scenarios. They are identified through certain
distinct characteristics and require specialized metrics to evaluate them.
Traditional navigation approaches designed for MRN do not perform well in SMGs,
which has led to focused research on dedicated SMG solvers (navigation methods
specialized to navigate in SMGs), which has flourished in recent years.
However, publications on SMG navigation research make different assumptions (on
centralized versus decentralized, observability, communication, cooperation,
etc.), and have different objective functions (safety versus liveness). These
assumptions and objectives are sometimes implicitly assumed or described
informally. This makes it difficult to establish appropriate baselines for
comparison in research papers, as well as making it difficult for practitioners
to find the papers relevant to their concrete application. Such ad-hoc
representation of the field also presents a barrier to new researchers wanting
to start research in this area. SMG navigation research requires its own
taxonomy, definitions, and evaluation protocols to guide effective research
moving forward. This survey is the first to catalog SMG solvers using a
well-defined and unified taxonomy and to classify existing methods accordingly.

</details>


### [9] [ROVER: Robust Loop Closure Verification with Trajectory Prior in Repetitive Environments](https://arxiv.org/abs/2508.13488)
*Jingwen Yu,Jiayi Yang,Anjun Hu,Jiankun Wang,Ping Tan,Hong Zhang*

Main category: cs.RO

TL;DR: ROVER是一种利用历史轨迹作为先验约束的闭环验证方法，专门针对重复环境中外观特征失效的问题，通过轨迹优化和评分机制有效拒绝错误闭环检测。


<details>
  <summary>Details</summary>
Motivation: 在重复性环境中，基于外观特征的闭环检测容易产生误判，现有方法忽略了机器人的时空运动轨迹这一重要先验知识，需要一种能够利用轨迹信息进行验证的方法。

Method: 提出ROVER方法：对于每个闭环候选，首先通过位姿图优化估计机器人轨迹，然后通过评分方案评估该轨迹与无闭环时的轨迹先验的一致性，从而决定是否接受该闭环。

Result: 基准测试和真实环境实验证明了该方法的有效性，集成到最先进的SLAM系统中验证了其鲁棒性和效率。

Conclusion: ROVER通过利用历史轨迹作为先验约束，在具有挑战性的重复环境中能够有效拒绝错误闭环，提高了SLAM系统的可靠性。

Abstract: Loop closure detection is important for simultaneous localization and mapping
(SLAM), which associates current observations with historical keyframes,
achieving drift correction and global relocalization. However, a falsely
detected loop can be fatal, and this is especially difficult in repetitive
environments where appearance-based features fail due to the high similarity.
Therefore, verification of a loop closure is a critical step in avoiding false
positive detections. Existing works in loop closure verification predominantly
focus on learning invariant appearance features, neglecting the prior knowledge
of the robot's spatial-temporal motion cue, i.e., trajectory. In this letter,
we propose ROVER, a loop closure verification method that leverages the
historical trajectory as a prior constraint to reject false loops in
challenging repetitive environments. For each loop candidate, it is first used
to estimate the robot trajectory with pose-graph optimization. This trajectory
is then submitted to a scoring scheme that assesses its compliance with the
trajectory without the loop, which we refer to as the trajectory prior, to
determine if the loop candidate should be accepted. Benchmark comparisons and
real-world experiments demonstrate the effectiveness of the proposed method.
Furthermore, we integrate ROVER into state-of-the-art SLAM systems to verify
its robustness and efficiency. Our source code and self-collected dataset are
available at https://github.com/jarvisyjw/ROVER.

</details>


### [10] [Unified Hierarchical MPC in Task Executing for Modular Manipulators across Diverse Morphologies](https://arxiv.org/abs/2508.13513)
*Maolin Lei,Edoardo Romiti,Arturo Laurenzi,Cheng Zhou,Wanli Xing,Liang Lu,Nikos G. Tsagarakis*

Main category: cs.RO

TL;DR: 提出分层模型预测控制(H-MPC)方法，用于不同形态模块化机械臂的统一控制，无需大量参数调整即可适应不同配置执行任务


<details>
  <summary>Details</summary>
Motivation: 解决模块化机械臂在不同形态配置下的统一控制问题，避免为每种配置单独调整控制器参数

Method: 采用两层MPC结构：高层MPC预测未来状态并提供轨迹信息，低层MPC基于高层信息更新预测模型并细化控制动作，结合二次线性化技术提升运动学模型精度

Result: 方法能够处理运动学约束，确保平滑的关节空间轨迹，即使在奇异配置附近也能稳定工作，在真实场景中成功执行拾放任务

Conclusion: H-MPC为模块化机械臂提供了一种通用且精确的控制方案，在保持线性控制模型简单性的同时提高了控制精度和可靠性

Abstract: This work proposes a unified Hierarchical Model Predictive Control (H-MPC)
for modular manipulators across various morphologies, as the controller can
adapt to different configurations to execute the given task without extensive
parameter tuning in the controller. The H-MPC divides the control process into
two levels: a high-level MPC and a low-level MPC. The high-level MPC predicts
future states and provides trajectory information, while the low-level MPC
refines control actions by updating the predictive model based on this
high-level information. This hierarchical structure allows for the integration
of kinematic constraints and ensures smooth joint-space trajectories, even near
singular configurations. Moreover, the low-level MPC incorporates secondary
linearization by leveraging predictive information from the high-level MPC,
effectively capturing the second-order Taylor expansion information of the
kinematic model while still maintaining a linearized model formulation. This
approach not only preserves the simplicity of a linear control model but also
enhances the accuracy of the kinematic representation, thereby improving
overall control precision and reliability. To validate the effectiveness of the
control policy, we conduct extensive evaluations across different manipulator
morphologies and demonstrate the execution of pick-and-place tasks in
real-world scenarios.

</details>


### [11] [A Three-Level Whole-Body Disturbance Rejection Control Framework for Dynamic Motions in Legged Robots](https://arxiv.org/abs/2508.13531)
*Bolin Li,Gewei Zuo,Zhixiang Wang,Xiaotian Ke,Lijun Zhu,Han Ding*

Main category: cs.RO

TL;DR: 提出了一种三层次全身扰动抑制控制框架(T-WB-DRC)，通过移动视界扩展状态观测器估计不确定性，显著提升腿式机器人在负载运输、外部扰动抑制和容错方面的性能。


<details>
  <summary>Details</summary>
Motivation: 解决腿式机器人在模型不确定性、外部扰动和故障等复杂环境下的稳定性和鲁棒性问题，传统两层次控制框架在处理不确定性方面存在局限。

Method: 1. 提出移动视界扩展状态观测器(MH-ESO)来估计系统不确定性并抑制噪声；2. 设计三层次全身扰动抑制控制框架，同时考虑无不确定性和有不确定性的动力学规划；3. 在Gazebo仿真和人形/四足机器人实验中进行验证。

Result: 仿真和实验结果表明，T-WB-DRC框架在各种扰动条件下都能有效提升系统的鲁棒性和稳定性，特别是在负载运输、外部扰动抑制和容错方面表现显著。

Conclusion: 所提出的三层次控制框架为腿式机器人提供了更强的抗干扰能力和环境适应性，为复杂环境下的机器人控制提供了有效的解决方案。

Abstract: This paper presents a control framework designed to enhance the stability and
robustness of legged robots in the presence of uncertainties, including model
uncertainties, external disturbances, and faults. The framework enables the
full-state feedback estimator to estimate and compensate for uncertainties in
whole-body dynamics of the legged robots. First, we propose a novel moving
horizon extended state observer (MH-ESO) to estimate uncertainties and mitigate
noise in legged systems, which can be integrated into the framework for
disturbance compensation. Second, we introduce a three-level whole-body
disturbance rejection control framework (T-WB-DRC). Unlike the previous
two-level approach, this three-level framework considers both the plan based on
whole-body dynamics without uncertainties and the plan based on dynamics with
uncertainties, significantly improving payload transportation, external
disturbance rejection, and fault tolerance. Third, simulations of both humanoid
and quadruped robots in the Gazebo simulator demonstrate the effectiveness and
versatility of T-WB-DRC. Finally, extensive experimental trials on a quadruped
robot validate the robustness and stability of the system when using T-WB-DRC
under various disturbance conditions.

</details>


### [12] [MimicFunc: Imitating Tool Manipulation from a Single Human Video via Functional Correspondence](https://arxiv.org/abs/2508.13534)
*Chao Tang,Anxing Xiao,Yuhong Deng,Tianrun Hu,Wenlong Dong,Hanbo Zhang,David Hsu,Hong Zhang*

Main category: cs.RO

TL;DR: MimicFunc是一个从单个人类视频中模仿工具操作技能的框架，通过功能帧建立功能级对应关系，使机器人能够泛化到新工具


<details>
  <summary>Details</summary>
Motivation: 人类能够通过观察一次就模仿工具操作行为并轻松将技能迁移到不同工具，而当前机器人难以达到这种泛化水平，主要挑战在于功能级对应关系的建立

Method: 提出MimicFunc框架，使用功能帧（function-centric local coordinate frame）和基于关键点的抽象来建立功能对应关系

Result: 实验证明MimicFunc能有效让机器人从单个RGB-D人类视频中泛化技能，操作新工具完成功能等效任务，并可用于训练视觉运动策略

Conclusion: 该框架为解决工具操作技能模仿中的功能级对应挑战提供了有效方案，具有一次性泛化能力，可减少人工遥操作数据收集的需求

Abstract: Imitating tool manipulation from human videos offers an intuitive approach to
teaching robots, while also providing a promising and scalable alternative to
labor-intensive teleoperation data collection for visuomotor policy learning.
While humans can mimic tool manipulation behavior by observing others perform a
task just once and effortlessly transfer the skill to diverse tools for
functionally equivalent tasks, current robots struggle to achieve this level of
generalization. A key challenge lies in establishing function-level
correspondences, considering the significant geometric variations among
functionally similar tools, referred to as intra-function variations. To
address this challenge, we propose MimicFunc, a framework that establishes
functional correspondences with function frame, a function-centric local
coordinate frame constructed with keypoint-based abstraction, for imitating
tool manipulation skills. Experiments demonstrate that MimicFunc effectively
enables the robot to generalize the skill from a single RGB-D human video to
manipulating novel tools for functionally equivalent tasks. Furthermore,
leveraging MimicFunc's one-shot generalization capability, the generated
rollouts can be used to train visuomotor policies without requiring
labor-intensive teleoperation data collection for novel objects. Our code and
video are available at https://sites.google.com/view/mimicfunc.

</details>


### [13] [Assessing Pedestrian Behavior Around Autonomous Cleaning Robots in Public Spaces: Findings from a Field Observation](https://arxiv.org/abs/2508.13699)
*Maren Raab,Linda Miller,Zhe Zeng,Pascal Jansen,Martin Baumann,Johannes Kraus*

Main category: cs.RO

TL;DR: 研究探索自主清洁机器人在公共场所对行人移动行为的影响，重点关注机器人类型和移动模式对分心与未分心行人的不同效应。


<details>
  <summary>Details</summary>
Motivation: 随着自主机器人在公共场所日益普及，需要开发能增强即时透明度并减少关键情况发生概率的通信策略，但目前缺乏关于分心行人在机器人存在下行为的研究。

Method: 在实地环境中，对498名不知情的行人进行录像观察，记录他们经过两个工作的自主清洁机器人时的移动行为，分析机器人类型（大小）和移动模式（圆形vs偏移矩形）的影响。

Result: 分心与未分心行人在机器人周围的移动行为无显著差异；较大的扫地机器人和偏移矩形移动模式显著增加了横向适应次数；偏移矩形模式导致更多近距离横向适应；不同机器人类型下移动模式对横向适应距离产生差异影响。

Conclusion: 研究为公共场所自主清洁机器人周围行人移动行为提供了初步见解，对HRI研究领域有贡献，强调机器人物理特性和移动模式设计的重要性。

Abstract: As autonomous robots become more common in public spaces, spontaneous
encounters with laypersons are more frequent. For this, robots need to be
equipped with communication strategies that enhance momentary transparency and
reduce the probability of critical situations. Adapting these robotic
strategies requires consideration of robot movements, environmental conditions,
and user characteristics and states. While numerous studies have investigated
the impact of distraction on pedestrians' movement behavior, limited research
has examined this behavior in the presence of autonomous robots. This research
addresses the impact of robot type and robot movement pattern on distracted and
undistracted pedestrians' movement behavior. In a field setting, unaware
pedestrians were videotaped while moving past two working, autonomous cleaning
robots. Out of N=498 observed pedestrians, approximately 8% were distracted by
smartphones. Distracted and undistracted pedestrians did not exhibit
significant differences in their movement behaviors around the robots. Instead,
both the larger sweeping robot and the offset rectangular movement pattern
significantly increased the number of lateral adaptations compared to the
smaller cleaning robot and the circular movement pattern. The offset
rectangular movement pattern also led to significantly more close lateral
adaptations. Depending on the robot type, the movement patterns led to
differences in the distances of lateral adaptations. The study provides initial
insights into pedestrian movement behavior around an autonomous cleaning robot
in public spaces, contributing to the growing field of HRI research.

</details>


### [14] [Blast Hole Seeking and Dipping -- The Navigation and Perception Framework in a Mine Site Inspection Robot](https://arxiv.org/abs/2508.13785)
*Liyang Liu,Ehsan Mihankhah,Nathan Wallace,Javier Martinez,Andrew J. Hill*

Main category: cs.RO

TL;DR: 开发了DIPPeR自主矿山检测机器人，通过LiDAR点云处理和2D投影实现爆破孔的自动检测与导航，提高钻孔检测效率和精度


<details>
  <summary>Details</summary>
Motivation: 露天采矿中爆破孔的手动检测效率低、成本高，且难以准确获取孔洞几何和地质特性，需要自动化解决方案来降低物料处理成本

Method: 使用LiDAR采集点云数据，提取锥形钻孔废料体积，将3D点云投影到虚拟深度图像进行2D分割，通过稳健检测模块识别孔中心并抑制非最大候选点，实现精确传感器定位

Result: 系统在高保真仿真环境和现场测试中均表现出有效性，能够连续跟踪目标孔洞并确保传感器准确定位，避免与孔壁碰撞

Conclusion: 提出的自动化检测框架能够显著提高爆破孔检测的效率和准确性，为矿山作业带来实质性成本节约

Abstract: In open-pit mining, holes are drilled into the surface of the excavation site
and detonated with explosives to facilitate digging. These blast holes need to
be inspected internally for investigation of downhole material types and
properties. Knowing these properties can lead to significant savings in
material handling costs in downstream processes. Manual hole inspection is slow
and expensive, with major limitations in revealing the geometric and geological
properties of the holes and their contents. This has been the motivation for
the development of our autonomous mine-site inspection robot - "DIPPeR". In
this paper, the automation aspect of the project is explained. We present a
robust blast hole seeking and detection framework that enables target-based
navigation and accurate down-hole sensor positioning. The pipeline first
processes point-cloud data collected by the on-board LiDAR sensors, extracting
the cone-shaped volume of drill-waste above the ground. By projecting the 3D
cone points into a virtual depth image, segmentation is achieved in the 2D
domain, yielding a circular hole at the image centre and a collared cone face.
We then identify the hole centre using a robust detection module while
suppressing non-maximum candidates, ensuring precise sensor placement for
down-hole inspection and avoiding collisions with the cavity wall. To enable
autonomous hole-seeking, the pipeline automatically adjusts its projection
parameters during robot navigation to account for variations in point sparsity
and hole opening size, ensuring a consistent hole appearance in 2D images. This
allows continuous tracking of the target hole as the robot approaches the goal
point. We demonstrate the effectiveness of our navigation and perception system
in both high-fidelity simulation environments and on-site field tests. A
demonstration video is available at
"https://www.youtube.com/watch?v=fRNbcBcaSqE".

</details>


### [15] [Trajectory Tracking and Stabilization of Quadrotors Using Deep Koopman Model Predictive Control](https://arxiv.org/abs/2508.13795)
*Haitham El-Hussieny*

Main category: cs.RO

TL;DR: 提出基于深度Koopman算子和模型预测控制的数据驱动控制框架(DK-MPC)，通过深度学习构建高维潜在空间的线性模型表示，实现四旋翼系统的精确轨迹跟踪和稳定控制


<details>
  <summary>Details</summary>
Motivation: 传统非线性MPC计算复杂度高，难以满足嵌入式飞控实时性要求，需要一种既能处理复杂非线性动力学又能高效计算的控制方法

Method: 使用深度Koopman算子从飞行数据中学习，构建高维潜在空间的线性动力学模型，然后应用MPC进行有限时域优化控制

Result: 数值实验显示相比传统非线性MPC具有更高的跟踪精度和显著降低的计算时间，满足实时控制要求

Conclusion: Koopman学习方法能有效处理复杂四旋翼动力学，未来将扩展到更敏捷飞行场景并提升抗外部干扰鲁棒性

Abstract: This paper presents a data-driven control framework for quadrotor systems
that integrates a deep Koopman operator with model predictive control (DK-MPC).
The deep Koopman operator is trained on sampled flight data to construct a
high-dimensional latent representation in which the nonlinear quadrotor
dynamics are approximated by linear models. This linearization enables the
application of MPC to efficiently optimize control actions over a finite
prediction horizon, ensuring accurate trajectory tracking and stabilization.
The proposed DK-MPC approach is validated through a series of
trajectory-following and point-stabilization numerical experiments, where it
demonstrates superior tracking accuracy and significantly lower computation
time compared to conventional nonlinear MPC. These results highlight the
potential of Koopman-based learning methods to handle complex quadrotor
dynamics while meeting the real-time requirements of embedded flight control.
Future work will focus on extending the framework to more agile flight
scenarios and improving robustness against external disturbances.

</details>


### [16] [Toward Deployable Multi-Robot Collaboration via a Symbolically-Guided Decision Transformer](https://arxiv.org/abs/2508.13877)
*Rathnam Vidushika Rasanji,Jin Wei-Kocsis,Jiansong Zhang,Dongming Gan,Ragu Athinarayanan,Paul Asunda*

Main category: cs.RO

TL;DR: 提出SGDT框架，结合神经符号机制和因果变换器，用于多机器人协作操作任务


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人操作中数据密集且依赖MDP假设，难以处理复杂动态和长期依赖的多机器人操作任务。决策变换器作为离线替代方案在多机器人操作中应用不足

Method: 神经符号规划器生成符号子目标的高级任务计划，目标条件决策变换器在子目标指导下进行低级序列决策

Result: 在零样本和少样本场景中评估性能，是首个探索基于决策变换器的多机器人操作技术的工作

Conclusion: SGDT的分层架构实现了结构化、可解释和可泛化的复杂多机器人协作决策

Abstract: Reinforcement learning (RL) has demonstrated great potential in robotic
operations. However, its data-intensive nature and reliance on the Markov
Decision Process (MDP) assumption limit its practical deployment in real-world
scenarios involving complex dynamics and long-term temporal dependencies, such
as multi-robot manipulation. Decision Transformers (DTs) have emerged as a
promising offline alternative by leveraging causal transformers for sequence
modeling in RL tasks. However, their applications to multi-robot manipulations
still remain underexplored. To address this gap, we propose a novel framework,
Symbolically-Guided Decision Transformer (SGDT), which integrates a
neuro-symbolic mechanism with a causal transformer to enable deployable
multi-robot collaboration. In the proposed SGDT framework, a neuro-symbolic
planner generates a high-level task-oriented plan composed of symbolic
subgoals. Guided by these subgoals, a goal-conditioned decision transformer
(GCDT) performs low-level sequential decision-making for multi-robot
manipulation. This hierarchical architecture enables structured, interpretable,
and generalizable decision making in complex multi-robot collaboration tasks.
We evaluate the performance of SGDT across a range of task scenarios, including
zero-shot and few-shot scenarios. To our knowledge, this is the first work to
explore DT-based technology for multi-robot manipulation.

</details>


### [17] [Driving Style Recognition Like an Expert Using Semantic Privileged Information from Large Language Models](https://arxiv.org/abs/2508.13881)
*Zhaokun Chen,Chaopeng Zhang,Xiaohan Li,Wenshuo Wang,Gentiane Venture,Junqiang Xi*

Main category: cs.RO

TL;DR: 提出了一种融合大语言模型语义特权信息(SPI)的驾驶风格识别框架，通过语义推理提升识别准确性并与专家判断对齐


<details>
  <summary>Details</summary>
Motivation: 现有驾驶风格识别系统过度依赖底层传感器特征，缺乏人类专家的语义推理能力，导致算法分类与专家判断存在根本性不一致

Method: 1) 开发DriBehavGPT交互式LLM模块生成驾驶行为自然语言描述；2) 通过文本嵌入和降维转换为机器学习可处理表示；3) 作为特权信息整合到SVM+中进行训练

Result: 在多种真实驾驶场景中，SPI增强框架显著优于传统方法，F1分数提升7.6%(跟车)和7.9%(变道)，且推理阶段仅需传感器数据

Conclusion: 语义行为表征在提升识别准确性和推进可解释、以人为本的驾驶系统方面发挥关键作用

Abstract: Existing driving style recognition systems largely depend on low-level
sensor-derived features for training, neglecting the rich semantic reasoning
capability inherent to human experts. This discrepancy results in a fundamental
misalignment between algorithmic classifications and expert judgments. To
bridge this gap, we propose a novel framework that integrates Semantic
Privileged Information (SPI) derived from large language models (LLMs) to align
recognition outcomes with human-interpretable reasoning. First, we introduce
DriBehavGPT, an interactive LLM-based module that generates natural-language
descriptions of driving behaviors. These descriptions are then encoded into
machine learning-compatible representations via text embedding and
dimensionality reduction. Finally, we incorporate them as privileged
information into Support Vector Machine Plus (SVM+) for training, enabling the
model to approximate human-like interpretation patterns. Experiments across
diverse real-world driving scenarios demonstrate that our SPI-enhanced
framework outperforms conventional methods, achieving F1-score improvements of
7.6% (car-following) and 7.9% (lane-changing). Importantly, SPI is exclusively
used during training, while inference relies solely on sensor data, ensuring
computational efficiency without sacrificing performance. These results
highlight the pivotal role of semantic behavioral representations in improving
recognition accuracy while advancing interpretable, human-centric driving
systems.

</details>


### [18] [Multimodal Data Storage and Retrieval for Embodied AI: A Survey](https://arxiv.org/abs/2508.13901)
*Yihao Lu,Hao Tang*

Main category: cs.RO

TL;DR: 本文系统评估了5种存储架构和5种检索范式在具身AI数据管理中的适用性，揭示了语义一致性与实时响应之间的根本矛盾，并提出了包含物理感知数据模型、自适应优化等的前瞻研究议程。


<details>
  <summary>Details</summary>
Motivation: 具身AI代理持续与物理世界交互产生海量异构多模态数据流，传统管理系统难以有效处理这些数据，需要专门的数据管理解决方案来满足物理接地、低延迟访问和动态可扩展性等核心需求。

Method: 基于对180多项相关研究的全面回顾，系统评估了图数据库、多模型数据库、数据湖、向量数据库和时间序列数据库五种存储架构，以及基于融合策略、表示对齐、图结构、生成模型和高效检索优化的五种检索范式。

Result: 研究发现存储检索系统在实现长期语义一致性和保持实时响应性之间存在根本性矛盾，识别出从物理接地差距到跨模态集成、动态适应和开放世界泛化等系统性挑战的关键瓶颈。

Conclusion: 提出了包含物理感知数据模型、自适应存储检索协同优化和标准化基准测试的前瞻性研究议程，为下一代自主具身系统设计稳健高性能数据管理框架提供了严谨路线图。

Abstract: Embodied AI (EAI) agents continuously interact with the physical world,
generating vast, heterogeneous multimodal data streams that traditional
management systems are ill-equipped to handle. In this survey, we first
systematically evaluate five storage architectures (Graph Databases,
Multi-Model Databases, Data Lakes, Vector Databases, and Time-Series
Databases), focusing on their suitability for addressing EAI's core
requirements, including physical grounding, low-latency access, and dynamic
scalability. We then analyze five retrieval paradigms (Fusion Strategy-Based
Retrieval, Representation Alignment-Based Retrieval, Graph-Structure-Based
Retrieval, Generation Model-Based Retrieval, and Efficient Retrieval-Based
Optimization), revealing a fundamental tension between achieving long-term
semantic coherence and maintaining real-time responsiveness. Based on this
comprehensive analysis, we identify key bottlenecks, spanning from the
foundational Physical Grounding Gap to systemic challenges in cross-modal
integration, dynamic adaptation, and open-world generalization. Finally, we
outline a forward-looking research agenda encompassing physics-aware data
models, adaptive storage-retrieval co-optimization, and standardized
benchmarking, to guide future research toward principled data management
solutions for EAI. Our survey is based on a comprehensive review of more than
180 related studies, providing a rigorous roadmap for designing the robust,
high-performance data management frameworks essential for the next generation
of autonomous embodied systems.

</details>


### [19] [Augmenting cobots for sheet-metal SMEs with 3D object recognition and localisation](https://arxiv.org/abs/2508.13964)
*Martijn Cramer,Yanming Wu,David De Schepper,Eric Demeester*

Main category: cs.RO

TL;DR: 该研究探讨了在中小企业钣金车间中使用协作机器人作为移动可重构生产助手的机遇与挑战，通过集成3D物体识别和定位技术来解决小批量多品种生产中的自动化难题。


<details>
  <summary>Details</summary>
Motivation: 中小企业面临小批量多品种生产的挑战，标准自动化解决方案难以应对，导致依赖重复性手工劳动，增加了生产成本且未能充分利用技术熟练劳动力的潜力。

Method: 通过COOCK+ ROBUST项目，集成现有技术（包括3D物体识别和定位），将协作机器人转变为移动可重构的生产助手，并以ACRO研究单位与工业合作伙伴的实际项目作为实施案例。

Result: 研究识别了在工业环境中增强协作机器人系统的机遇和挑战，并概述了实施过程中的关键步骤，提供了具体的实施范例。

Conclusion: 将协作机器人配备3D视觉技术可以成为中小企业应对高混合低产量生产挑战的有效解决方案，但需要克服技术集成和实施方面的挑战。

Abstract: Due to high-mix-low-volume production, sheet-metal workshops today are
challenged by small series and varying orders. As standard automation solutions
tend to fall short, SMEs resort to repetitive manual labour impacting
production costs and leading to tech-skilled workforces not being used to their
full potential. The COOCK+ ROBUST project aims to transform cobots into mobile
and reconfigurable production assistants by integrating existing technologies,
including 3D object recognition and localisation. This article explores both
the opportunities and challenges of enhancing cobotic systems with these
technologies in an industrial setting, outlining the key steps involved in the
process. Additionally, insights from a past project, carried out by the ACRO
research unit in collaboration with an industrial partner, serves as a concrete
implementation example throughout.

</details>


### [20] [Toward an Interaction-Centered Approach to Robot Trustworthiness](https://arxiv.org/abs/2508.13976)
*Carlo Mazzola,Hassan Ali,Kristína Malinovská,Igor Farkaš*

Main category: cs.RO

TL;DR: 本文提出了一个基于交互的框架，通过人机相互理解来建立信任，强调人类意识和透明度两大支柱，旨在使机器人行为符合人类期望并避免误信风险。


<details>
  <summary>Details</summary>
Motivation: 随着机器人更深入融入人类环境，需要建立与机器人技能相匹配的人类信任，避免误信或过度信任带来的安全风险和伦理问题，实现有效安全的人机交互。

Method: 提出基于交互的信任构建框架，包含两大核心支柱：人类意识（机器人准确解读人类行为）和透明度（清晰传达机器人意图和目标），并引入四个关键组件来弥合人类感知信任与机器人实际能力之间的差距。

Result: 框架通过整合人类意识和透明度，使机器人能够以符合人类期望和需求的方式行为，同时为人类伙伴提供对其行为的理解和控制能力。

Conclusion: 该交互框架为人机信任建立提供了系统化方法，通过双向理解机制促进安全有效的人机协作，对解决人机交互中的信任校准问题具有重要意义。

Abstract: As robots get more integrated into human environments, fostering
trustworthiness in embodied robotic agents becomes paramount for an effective
and safe human-robot interaction (HRI). To achieve that, HRI applications must
promote human trust that aligns with robot skills and avoid misplaced trust or
overtrust, which can pose safety risks and ethical concerns. To achieve that,
HRI applications must promote human trust that aligns with robot skills and
avoid misplaced trust or overtrust, which can pose safety risks and ethical
concerns. In this position paper, we outline an interaction-based framework for
building trust through mutual understanding between humans and robots. We
emphasize two main pillars: human awareness and transparency, referring to the
robot ability to interpret human actions accurately and to clearly communicate
its intentions and goals, respectively. By integrating these two pillars,
robots can behave in a manner that aligns with human expectations and needs
while providing their human partners with both comprehension and control over
their actions. We also introduce four components that we think are important
for bridging the gap between a human-perceived sense of trust and a robot true
capabilities.

</details>


### [21] [The Social Context of Human-Robot Interactions](https://arxiv.org/abs/2508.13982)
*Sydney Thompson,Kate Candon,Marynel Vázquez*

Main category: cs.RO

TL;DR: 本文对HRI领域中"社交情境"术语的混乱使用进行了系统梳理，提出了一个概念模型来统一描述人机交互的社交情境，并讨论了该模型在交互规划、机器人行为建模和事后分析中的应用价值。


<details>
  <summary>Details</summary>
Motivation: HRI研究社区中"社交情境"术语使用混乱，导致研究之间难以建立联系和比较，需要统一的概念框架来促进该领域的发展。

Method: 通过文献综述梳理现有"社交情境"定义和使用方式，提出概念模型来描述人机交互的社交情境，并将该模型应用于现有研究工作。

Result: 建立了一个统一的概念模型，能够帮助研究人员规划交互、开发机器人行为模型，并在交互发生后获得洞察。

Conclusion: 提出了理解人机交互社交情境的重要框架，并指出了该领域未来研究的关键问题和发展方向。

Abstract: The Human-Robot Interaction (HRI) community often highlights the social
context of an interaction as a key consideration when designing, implementing,
and evaluating robot behavior. Unfortunately, researchers use the term "social
context" in varied ways. This can lead to miscommunication, making it
challenging to draw connections between related work on understanding and
modeling the social contexts of human-robot interactions. To address this gap,
we survey the HRI literature for existing definitions and uses of the term
"social context". Then, we propose a conceptual model for describing the social
context of a human-robot interaction. We apply this model to existing work, and
we discuss a range of attributes of social contexts that can help researchers
plan for interactions, develop behavior models for robots, and gain insights
after interactions have taken place. We conclude with a discussion of open
research questions in relation to understanding and modeling the social
contexts of human-robot interactions.

</details>


### [22] [Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation](https://arxiv.org/abs/2508.13998)
*Yifu Yuan,Haiqin Cui,Yaoting Huang,Yibin Chen,Fei Ni,Zibin Dong,Pengyi Li,Yan Zheng,Jianye Hao*

Main category: cs.RO

TL;DR: 该论文提出了Embodied-R1模型，通过统一的"指向"表示来解决具身AI中的"看到-行动"鸿沟问题，在11个基准测试中达到最先进性能，并在零样本泛化方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决具身AI中的"看到-行动鸿沟"问题，该问题源于数据稀缺和具身异构性，阻碍了泛化能力。

Method: 提出"指向"作为统一的、具身无关的中间表示，构建Embodied-Points-200K数据集，使用两阶段强化微调(RFT)课程训练3B参数的视觉语言模型Embodied-R1。

Result: 在11个具身空间和指向基准测试中达到最先进性能，在SIMPLEREnv中零样本成功率达到56.2%，在8个真实世界XArm任务中达到87.5%成功率，比强基线提升62%。

Conclusion: 指向中心表示结合RFT训练范式为解决机器人感知-行动鸿沟提供了有效且可泛化的途径。

Abstract: Generalization in embodied AI is hindered by the "seeing-to-doing gap," which
stems from data scarcity and embodiment heterogeneity. To address this, we
pioneer "pointing" as a unified, embodiment-agnostic intermediate
representation, defining four core embodied pointing abilities that bridge
high-level vision-language comprehension with low-level action primitives. We
introduce Embodied-R1, a 3B Vision-Language Model (VLM) specifically designed
for embodied reasoning and pointing. We use a wide range of embodied and
general visual reasoning datasets as sources to construct a large-scale
dataset, Embodied-Points-200K, which supports key embodied pointing
capabilities. We then train Embodied-R1 using a two-stage Reinforced
Fine-tuning (RFT) curriculum with a specialized multi-task reward design.
Embodied-R1 achieves state-of-the-art performance on 11 embodied spatial and
pointing benchmarks. Critically, it demonstrates robust zero-shot
generalization by achieving a 56.2% success rate in the SIMPLEREnv and 87.5%
across 8 real-world XArm tasks without any task-specific fine-tuning,
representing a 62% improvement over strong baselines. Furthermore, the model
exhibits high robustness against diverse visual disturbances. Our work shows
that a pointing-centric representation, combined with an RFT training paradigm,
offers an effective and generalizable pathway to closing the perception-action
gap in robotics.

</details>


### [23] [Train Once, Deploy Anywhere: Realize Data-Efficient Dynamic Object Manipulation](https://arxiv.org/abs/2508.14042)
*Zhuoling Li,Xiaoyang Wu,Zhenhua Xu,Hengshuang Zhao*

Main category: cs.RO

TL;DR: 本文提出了一个基于熵的理论框架和GEM系统，仅需少量演示就能实现动态物体操作的强泛化能力，在真实食堂餐具收集任务中取得了97%以上的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决动态物体操作中演示数据收集成本高的问题，探索仅用少量演示就能实现强泛化能力的可能性，提高制造业效率。

Method: 开发基于熵的理论框架来量化模仿学习的优化，并基于此提出Generalizable Entropy-based Manipulation (GEM)系统。

Result: 在仿真和真实任务中的广泛实验表明，GEM能够泛化到不同的环境背景、机器人形态、运动动力学和物体几何形状。在真实食堂餐具收集中，无需场景内演示，超过10,000次操作中成功率超过97%。

Conclusion: GEM系统证明了仅用少量演示就能实现动态物体操作的强泛化能力，为制造业提供了高效且通用的解决方案。

Abstract: Realizing generalizable dynamic object manipulation is important for
enhancing manufacturing efficiency, as it eliminates specialized engineering
for various scenarios. To this end, imitation learning emerges as a promising
paradigm, leveraging expert demonstrations to teach a policy manipulation
skills. Although the generalization of an imitation learning policy can be
improved by increasing demonstrations, demonstration collection is
labor-intensive. To address this problem, this paper investigates whether
strong generalization in dynamic object manipulation is achievable with only a
few demonstrations. Specifically, we develop an entropy-based theoretical
framework to quantify the optimization of imitation learning. Based on this
framework, we propose a system named Generalizable Entropy-based Manipulation
(GEM). Extensive experiments in simulated and real tasks demonstrate that GEM
can generalize across diverse environment backgrounds, robot embodiments,
motion dynamics, and object geometries. Notably, GEM has been deployed in a
real canteen for tableware collection. Without any in-scene demonstration, it
achieves a success rate of over 97% across more than 10,000 operations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL](https://arxiv.org/abs/2508.13167)
*Weizhen Li,Jianbo Lin,Zhuosong Jiang,Jingyi Cao,Xinpeng Liu,Jiayu Zhang,Zhenqiang Huang,Qianben Chen,Weichen Sun,Qiexiang Wang,Hongxuan Lu,Tianrui Qin,Chenghao Zhu,Yi Yao,Shuying Fan,Xiaowan Li,Tiannan Wang,Pai Liu,King Zhu,He Zhu,Dingfeng Shi,Piaohong Wang,Yeyi Guan,Xiangru Tang,Minghao Liu,Yuchen Eleanor Jiang,Jian Yang,Jiaheng Liu,Ge Zhang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: 提出Chain-of-Agents(CoA)新范式，通过多智能体蒸馏和强化学习训练Agent Foundation Models(AFMs)，在单一模型内实现端到端复杂问题解决，性能达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统依赖手动提示工程，计算效率低、能力有限且无法从数据驱动学习中受益，需要更高效的端到端解决方案。

Method: 1) 多智能体蒸馏框架将先进多智能体系统蒸馏为CoA轨迹进行监督微调；2) 在可验证智能体任务上使用智能体强化学习进一步提升能力；3) 构建Agent Foundation Models(AFMs)。

Result: AFM在网页智能体和代码智能体等多个基准测试中建立了新的最先进性能，显著优于现有方法。

Conclusion: CoA范式成功实现了单一模型内的端到端复杂问题解决，AFM模型开源为未来智能体模型和智能体强化学习研究提供了坚实基础。

Abstract: Recent advances in large language models (LLMs) and multi-agent systems have
demonstrated remarkable capabilities in complex problem-solving tasks such as
deep research, vibe coding, and mathematical reasoning. However, most existing
multi-agent systems are built upon manual prompt/workflow engineering with
sophisticated agent frameworks, making them computationally inefficient, less
capable, and can not benefit from data-centric learning. In this work, we
introduce Chain-of-Agents (CoA), a novel paradigm of LLM reasoning that enables
native end-to-end complex problem-solving in the same way as a multi-agent
system (i.e., multi-turn problem solving with multiple tools and multiple
agents) within one model. In chain-of-agents problem-solving, the model
dynamically activates different tool agents and role-playing agents to simulate
multi-agent collaboration in an end-to-end fashion. To elicit end-to-end
chain-of-agents problem-solving abilities in LLMs, we introduce a multi-agent
distillation framework to distill state-of-the-art multi-agent systems into
chain-of-agents trajectories for agentic supervised fine-tuning. We then use
agentic reinforcement learning on verifiable agentic tasks to further improve
the models' capabilities on chain-of-agents problem solving. We call the
resulting models Agent Foundation Models (AFMs). Our empirical studies
demonstrate that AFM establishes new state-of-the-art performance across
diverse benchmarks in both web agent and code agent settings. We make the
entire research, including the model weights, code for training and evaluation,
and the training data, fully open-sourced, which offers a solid starting point
for future research on agent models and agentic RL.

</details>


### [25] [Cognitive Workspace: Active Memory Management for LLMs -- An Empirical Study of Functional Infinite Context](https://arxiv.org/abs/2508.13171)
*Tao An*

Main category: cs.AI

TL;DR: 提出了Cognitive Workspace新范式，通过模拟人类外部记忆机制，解决了LLM上下文管理的根本限制，相比传统RAG实现了58.6%的内存重用率和17-18%的效率提升


<details>
  <summary>Details</summary>
Motivation: 现有LLM尽管上下文窗口扩展到百万token，但仍缺乏人类认知的动态任务驱动记忆管理能力，被动检索系统无法实现真正的认知扩展

Method: 基于认知科学理论（Baddeley工作记忆模型、Clark扩展心智理论等），提出三个核心创新：主动记忆管理、分层认知缓冲区和任务驱动的上下文优化

Result: 实证验证显示58.6%平均内存重用率（传统RAG为0%），17-18%净效率增益，统计显著（p<0.001，Cohen's d>23）

Conclusion: Cognitive Workspace代表了从信息检索到真正认知增强的根本性转变，为LLM系统提供了首个主动记忆优势的量化证据

Abstract: Large Language Models (LLMs) face fundamental limitations in context
management despite recent advances extending context windows to millions of
tokens. We propose Cognitive Workspace, a novel paradigm that transcends
traditional Retrieval-Augmented Generation (RAG) by emulating human cognitive
mechanisms of external memory use. Drawing from cognitive science foundations
including Baddeley's working memory model, Clark's extended mind thesis, and
Hutchins' distributed cognition framework, we demonstrate that current passive
retrieval systems fail to capture the dynamic, task-driven nature of human
memory management. Our analysis of 2024-2025 developments reveals that while
techniques like Infini-attention and StreamingLLM achieve impressive context
lengths, they lack the metacognitive awareness and active planning capabilities
essential for true cognitive extension. Cognitive Workspace addresses these
limitations through three core innovations: (1) active memory management with
deliberate information curation, (2) hierarchical cognitive buffers enabling
persistent working states, and (3) task-driven context optimization that
dynamically adapts to cognitive demands. Empirical validation demonstrates
Cognitive Workspace achieves an average 58.6% memory reuse rate (ranging from
54-60% across different tasks) compared to 0% for traditional RAG, with 17-18%
net efficiency gain despite 3.3x higher operation counts. Statistical analysis
confirms these advantages with p < 0.001 and Cohen's d > 23 across multiple
task types, establishing the first quantitative evidence for active memory
superiority in LLM systems. We present a comprehensive theoretical framework
synthesizing insights from 50+ recent papers, positioning Cognitive Workspace
as a fundamental shift from information retrieval to genuine cognitive
augmentation.

</details>


### [26] [AlphaEval: A Comprehensive and Efficient Evaluation Framework for Formula Alpha Mining](https://arxiv.org/abs/2508.13174)
*Hongjun Ding,Binqi Chen,Jinsheng Huang,Taian Guo,Zhengyang Mao,Guoyi Shao,Lutong Zou,Luchen Liu,Ming Zhang*

Main category: cs.AI

TL;DR: AlphaEval是一个统一、可并行、无需回测的自动化alpha挖掘模型评估框架，从五个维度全面评估alpha质量，比传统方法更高效全面。


<details>
  <summary>Details</summary>
Motivation: 现有alpha挖掘评估方法存在局限性：回测计算密集且参数敏感，相关性指标只关注预测能力而忽略其他重要属性，且大多数模型闭源阻碍了领域发展。

Method: 提出AlphaEval框架，从预测能力、稳定性、市场扰动鲁棒性、金融逻辑性和多样性五个互补维度综合评估生成的alpha信号。

Result: 实验表明AlphaEval在评估一致性上与全面回测相当，但提供更全面的洞察和更高效率，并能有效识别优于传统单指标筛选的优质alpha。

Conclusion: AlphaEval解决了alpha挖掘系统评估的关键挑战，所有实现和评估工具都已开源以促进可复现性和社区参与。

Abstract: Formula alpha mining, which generates predictive signals from financial data,
is critical for quantitative investment. Although various algorithmic
approaches-such as genetic programming, reinforcement learning, and large
language models-have significantly expanded the capacity for alpha discovery,
systematic evaluation remains a key challenge. Existing evaluation metrics
predominantly include backtesting and correlation-based measures. Backtesting
is computationally intensive, inherently sequential, and sensitive to specific
strategy parameters. Correlation-based metrics, though efficient, assess only
predictive ability and overlook other crucial properties such as temporal
stability, robustness, diversity, and interpretability. Additionally, the
closed-source nature of most existing alpha mining models hinders
reproducibility and slows progress in this field. To address these issues, we
propose AlphaEval, a unified, parallelizable, and backtest-free evaluation
framework for automated alpha mining models. AlphaEval assesses the overall
quality of generated alphas along five complementary dimensions: predictive
power, stability, robustness to market perturbations, financial logic, and
diversity. Extensive experiments across representative alpha mining algorithms
demonstrate that AlphaEval achieves evaluation consistency comparable to
comprehensive backtesting, while providing more comprehensive insights and
higher efficiency. Furthermore, AlphaEval effectively identifies superior
alphas compared to traditional single-metric screening approaches. All
implementations and evaluation tools are open-sourced to promote
reproducibility and community engagement.

</details>


### [27] [Fitting Ontologies and Constraints to Relational Structures](https://arxiv.org/abs/2508.13176)
*Simon Hosemann,Jean Christoph Jung,Carsten Lutz,Sebastian Rudolph*

Main category: cs.AI

TL;DR: 本文研究了基于正负关系结构示例的本体和约束拟合问题，分析了多种描述逻辑和TGDs的复杂性、算法和拟合大小，并探讨了有限基的存在性问题。


<details>
  <summary>Details</summary>
Motivation: 研究如何从正负示例中自动学习本体和约束，这对于知识表示和数据库系统的自动化构建具有重要意义。

Method: 使用描述逻辑EL和ELI以及多种类型的元组生成依赖（TGDs）作为本体和约束语言，通过理论分析和算法设计来研究拟合问题的计算复杂性和解决方案。

Result: 精确确定了各种语言下拟合问题的计算复杂度，设计了相应算法，分析了拟合本体和TGDs的大小，并发现某些TGDs类型不存在有限基。

Conclusion: 该研究为基于示例的本体学习提供了理论基础和实用算法，揭示了不同语言在有限基存在性方面的根本差异，对知识表示系统的自动化构建具有重要指导意义。

Abstract: We study the problem of fitting ontologies and constraints to positive and
negative examples that take the form of a finite relational structure. As
ontology and constraint languages, we consider the description logics
$\mathcal{E\mkern-2mu L}$ and $\mathcal{E\mkern-2mu LI}$ as well as several
classes of tuple-generating dependencies (TGDs): full, guarded,
frontier-guarded, frontier-one, and unrestricted TGDs as well as inclusion
dependencies. We pinpoint the exact computational complexity, design
algorithms, and analyze the size of fitting ontologies and TGDs. We also
investigate the related problem of constructing a finite basis of concept
inclusions / TGDs for a given set of finite structures. While finite bases
exist for $\mathcal{E\mkern-2mu L}$, $\mathcal{E\mkern-2mu LI}$, guarded TGDs,
and inclusion dependencies, they in general do not exist for full,
frontier-guarded and frontier-one TGDs.

</details>


### [28] [A Hardware-oriented Approach for Efficient Active Inference Computation and Deployment](https://arxiv.org/abs/2508.13177)
*Nikola Pižurica,Nikola Milović,Igor Jovančević,Conor Heins,Miguel de Prado*

Main category: cs.AI

TL;DR: 本文提出了一种将Active Inference框架与硬件优化计算图相结合的方法，显著降低了计算延迟和内存使用


<details>
  <summary>Details</summary>
Motivation: Active Inference (AIF)框架虽然决策能力强，但其计算和内存需求在资源受限环境中部署存在挑战

Method: 整合pymdp的灵活性和效率，构建统一的稀疏计算图，针对硬件高效执行进行优化

Result: 延迟降低超过2倍，内存使用减少高达35%

Conclusion: 该方法推进了高效AIF智能体在实时和嵌入式应用中的部署

Abstract: Active Inference (AIF) offers a robust framework for decision-making, yet its
computational and memory demands pose challenges for deployment, especially in
resource-constrained environments. This work presents a methodology that
facilitates AIF's deployment by integrating pymdp's flexibility and efficiency
with a unified, sparse, computational graph tailored for hardware-efficient
execution. Our approach reduces latency by over 2x and memory by up to 35%,
advancing the deployment of efficient AIF agents for real-time and embedded
applications.

</details>


### [29] [The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task](https://arxiv.org/abs/2508.13178)
*Cong Zhang*

Main category: cs.AI

TL;DR: CESQL模型通过集成模型可解释性分析和执行引导策略，结合过滤调整、逻辑关联优化和模型融合，显著提升了文本到SQL转换在WHERE子句语义解析中的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提升文本到SQL模型在真实应用中的基础能力和泛化性能，特别是在处理WHERE子句语义解析时减少对条件列数据的依赖和人工标注训练数据的影响。

Method: 集成模型可解释性分析与执行引导策略，采用过滤调整、逻辑关联精化和模型融合技术，设计出支持条件增强的CESQL模型。

Result: 在WikiSQL数据集上表现优异，显著提高了预测结果的准确性，特别是在WHERE子句条件值预测方面取得了突破。

Conclusion: 该研究为处理复杂查询和真实数据库环境中不规则数据场景的研究提供了新的视角和方法基础。

Abstract: To elevate the foundational capabilities and generalization prowess of the
text-to-SQL model in real-world applications, we integrate model
interpretability analysis with execution-guided strategy for semantic parsing
of WHERE clauses in SQL queries. Furthermore, we augment this approach with
filtering adjustments, logical correlation refinements, and model fusion,
culminating in the design of the CESQL model that facilitates conditional
enhancement. Our model excels on the WikiSQL dataset, which is emblematic of
single-table database query tasks, markedly boosting the accuracy of prediction
outcomes. When predicting conditional values in WHERE clauses, we have not only
minimized our dependence on data within the condition columns of tables but
also circumvented the impact of manually labeled training data. Our hope is
that this endeavor to enhance accuracy in processing basic database queries
will offer fresh perspectives for research into handling complex queries and
scenarios featuring irregular data in real-world database environments.

</details>


### [30] [Search-Time Data Contamination](https://arxiv.org/abs/2508.13180)
*Ziwen Han,Meher Mankikar,Julian Michael,Zifan Wang*

Main category: cs.AI

TL;DR: 本文提出了一种新的评估污染问题——搜索时污染（STC），指搜索型LLM代理在回答问题时通过搜索工具从在线平台（如HuggingFace）直接获取测试问题和答案，而非通过推理生成答案，从而损害基准测试的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注训练数据污染，但忽略了搜索型LLM代理在评估过程中可能通过搜索工具直接获取测试答案的问题，这种搜索时污染会严重破坏基准测试的完整性。

Method: 通过在三个常用能力基准（HLE、SimpleQA、GPQA）上测试搜索型代理，分析其搜索日志，发现约3%的问题能直接从HuggingFace获取带标签的数据集；通过阻断HuggingFace进行对比实验，观察准确率变化。

Result: 约3%的测试问题存在搜索时污染，代理直接从HuggingFace获取答案；阻断HuggingFace后，受污染子集的准确率下降约15%；实验表明HuggingFace可能不是唯一的污染源。

Conclusion: 需要制定基准设计和结果报告的最佳实践来解决搜索时污染问题，确保搜索型LLM代理评估的可信度；同时公开实验日志以方便审计评估结果。

Abstract: Data contamination refers to the leakage of evaluation data into model
training data, resulting in overfitting to supposedly held-out test sets and
compromising test validity. We identify an analogous issue, search-time
contamination (STC), in evaluating search-based LLM agents which use tools to
gather information from online sources when answering user queries. STC occurs
when the retrieval step surfaces a source containing the test question (or a
near-duplicate) alongside its answer, enabling agents to copy rather than
genuinely infer or reason, undermining benchmark integrity. We find that
HuggingFace, an online platform hosting evaluation datasets, appears among
retrieved sources in search based agent logs. Consequently, agents often
explicitly acknowledge discovering question answer pairs from HuggingFace
within their reasoning chains. On three commonly used capability benchmarks:
Humanity's Last Exam (HLE), SimpleQA, and GPQA, we demonstrate that for
approximately 3% of questions, search-based agents directly find the datasets
with ground truth labels on HuggingFace. When millions of evaluation queries
target the same benchmark, even small, repeated leaks can accelerate the
benchmark's obsolescence, shortening its intended lifecycle. After HuggingFace
is blocked, we observe a drop in accuracy on the contaminated subset of
approximately 15%. We further show through ablation experiments that publicly
accessible evaluation datasets on HuggingFace may not be the sole source of
STC. To this end, we conclude by proposing best practices for benchmark design
and result reporting to address this novel form of leakage and ensure
trustworthy evaluation of search-based LLM agents. To facilitate the auditing
of evaluation results, we also publicly release the complete logs from our
experiments.

</details>


### [31] [QuickMerge++: Fast Token Merging with Autoregressive Prior](https://arxiv.org/abs/2508.13204)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: QuickMerge是一个轻量级token合并框架，通过动态选择重要token来减少计算成本，同时保持自回归生成能力，在多模态领域实现了计算效率与准确性的平衡


<details>
  <summary>Details</summary>
Motivation: 随着生成模型处理更大规模输入，token级别的计算成本成为关键瓶颈。现有token选择方法大多是静态的、模态特定的或不兼容自回归生成

Method: 基于注意力范数幅度的动态token选择，使用基于熵的预算估计器指导，并引入轻量级transformer先验来保持自回归兼容性

Result: 在多模态领域评估显示，QuickMerge显著减少token数量，同时匹配甚至超越学习型tokenizer和固定patch基线的性能

Conclusion: QuickMerge通过语义显著性估计、灵活token预算和自回归对齐的组合，实现了用更少token进行准确生成的有效框架

Abstract: As generative models scale to larger inputs across language, vision, and
video domains, the cost of token-level computation has become a key bottleneck.
While prior work suggests that only a subset of tokens significantly influence
downstream predictions, most token selection methods are static,
modality-specific, or incompatible with autoregressive generation. In this
paper, we propose QuickMerge, a lightweight token merging framework designed
for efficient next-token prediction.
  QuickMerge dynamically selects a reduced number of tokens based on attention
norm magnitude, guided by an entropy-based budget estimator. To preserve
autoregressive compatibility, we introduce a lightweight transformer prior
trained over the merged token sequence. By combining semantic salience
estimation, flexible token budgets, and AR alignment, QuickMerge enables
accurate generation with fewer tokens.
  We evaluate QuickMerge across multi-modality domains, demonstrating
consistent improvements in compute-accuracy tradeoffs. Specifically, QuickMerge
reduces token counts sustantially while matching as well as exceeding the
performance of learned tokenizers and fixed-patch baselines.

</details>


### [32] [AI sustains higher strategic tension than humans in chess](https://arxiv.org/abs/2508.13213)
*Adamo Cerioli,Edward D. Lee,Vito D. P. Servedio*

Main category: cs.AI

TL;DR: 一种网络基于棋子互动的指标用于量化棋局战略紧张程度，发现AI比人类更能维持更高水平的长期战略紧张


<details>
  <summary>Details</summary>
Motivation: 研究在象棋这种战略游戏中，人类和AI如何处理即时机会与长期目标之间的拉换关系，寻找量化战略紧张的方法

Method: 提出基于棋子互动网络的指标来量化棋局战略紧张程度，对比分析人类vs人类和AIvsAI对局的演化过程

Result: AI对手能维持更高水平的长期战略紧张，人类专家在红1600和2300豪时出现紧张水平的突变增长，AI对互联平衡攻防的复杂局面更宽容

Conclusion: AI和人类在战略决策中采取不同策略，AI更能承受长期复杂局面，这可能体现人类认知限制和适应性策略，对复杂战略环境中使用AI有重要启示

Abstract: Strategic decision-making involves managing the tension between immediate
opportunities and long-term objectives. We study this trade-off in chess by
characterizing and comparing dynamics between human vs human and AI vs AI
games. We propose a network-based metric of piece-to-piece interaction to
quantify the ongoing strategic tension on the board. Its evolution in games
reveals that the most competitive AI players sustain higher levels of strategic
tension for longer durations than elite human players. Cumulative tension
varies with algorithmic complexity for AI and correspondingly in human-played
games increases abruptly with expertise at about 1600 Elo and again at 2300
Elo. The profiles reveal different approaches. Highly competitive AI tolerates
interconnected positions balanced between offensive and defensive tactics over
long periods. Human play, in contrast, limits tension and game complexity,
which may reflect cognitive limitations and adaptive strategies. The difference
may have implications for AI usage in complex, strategic environments.

</details>


### [33] [Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information](https://arxiv.org/abs/2508.13250)
*Zeyu Zhang,Yang Zhang,Haoran Tan,Rui Li,Xu Chen*

Main category: cs.AI

TL;DR: 本文提出了多跳个性化推理任务，研究不同记忆机制在个性化信息多跳推理中的表现，构建了数据集和评估框架，并提出了HybridMem混合方法来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于记忆的个性化方法主要关注偏好对齐和简单问答，但现实世界中复杂任务需要对大量用户信息进行多跳推理，这对当前记忆方法提出了重大挑战。

Method: 明确定义多跳个性化推理任务，构建数据集和统一评估框架，实现各种显式和隐式记忆方法，提出结合两种范式的HybridMem混合方法。

Result: 通过综合实验从多角度评估了不同记忆方法的性能，分析了它们的优缺点，并证明了HybridMem方法的有效性。

Conclusion: 多跳个性化推理是一个重要但具有挑战性的任务，混合记忆方法能够有效解决现有方法的局限性，为研究社区提供了有价值的数据集和框架。

Abstract: In large language model-based agents, memory serves as a critical capability
for achieving personalization by storing and utilizing users' information.
Although some previous studies have adopted memory to implement user
personalization, they typically focus on preference alignment and simple
question-answering. However, in the real world, complex tasks often require
multi-hop reasoning on a large amount of user information, which poses
significant challenges for current memory approaches. To address this
limitation, we propose the multi-hop personalized reasoning task to explore how
different memory mechanisms perform in multi-hop reasoning over personalized
information. We explicitly define this task and construct a dataset along with
a unified evaluation framework. Then, we implement various explicit and
implicit memory methods and conduct comprehensive experiments. We evaluate
their performance on this task from multiple perspectives and analyze their
strengths and weaknesses. Besides, we explore hybrid approaches that combine
both paradigms and propose the HybridMem method to address their limitations.
We demonstrate the effectiveness of our proposed model through extensive
experiments. To benefit the research community, we release this project at
https://github.com/nuster1128/MPR.

</details>


### [34] ["DIVE" into Hydrogen Storage Materials Discovery with AI Agents](https://arxiv.org/abs/2508.13251)
*Di Zhang,Xue Jia,Tran Ba Hung,Seong Hoon Jang,Linda Zhang,Ryuhei Sato,Yusuke Hashimoto,Toyoto Sato,Kiyoe Konno,Shin-ichi Orimo,Hao Li*

Main category: cs.AI

TL;DR: DIVE多智能体工作流从科学文献图表中自动提取材料数据，显著提升数据提取准确性，建立了包含3万条数据的氢存储材料数据库，实现2分钟内逆向设计新材料


<details>
  <summary>Details</summary>
Motivation: 科学文献中的大量材料数据被困在非结构化的图表中，阻碍了基于大语言模型的AI智能体进行自动化材料设计

Method: 开发DIVE多智能体工作流，系统读取和组织科学文献图形元素中的实验数据，专注于固态氢存储材料

Result: DIVE相比多模态模型直接提取，准确率提升10-15%（商业模型）和30%以上（开源模型），建立了包含3万条数据的数据库，能在2分钟内识别未报道的氢存储材料成分

Conclusion: 该AI工作流和智能体设计可广泛迁移到不同材料领域，为AI驱动的材料发现提供了新范式

Abstract: Data-driven artificial intelligence (AI) approaches are fundamentally
transforming the discovery of new materials. Despite the unprecedented
availability of materials data in the scientific literature, much of this
information remains trapped in unstructured figures and tables, hindering the
construction of large language model (LLM)-based AI agent for automated
materials design. Here, we present the Descriptive Interpretation of Visual
Expression (DIVE) multi-agent workflow, which systematically reads and
organizes experimental data from graphical elements in scientific literatures.
We focus on solid-state hydrogen storage materials-a class of materials central
to future clean-energy technologies and demonstrate that DIVE markedly improves
the accuracy and coverage of data extraction compared to the direct extraction
by multimodal models, with gains of 10-15% over commercial models and over 30%
relative to open-source models. Building on a curated database of over 30,000
entries from 4,000 publications, we establish a rapid inverse design workflow
capable of identifying previously unreported hydrogen storage compositions in
two minutes. The proposed AI workflow and agent design are broadly transferable
across diverse materials, providing a paradigm for AI-driven materials
discovery.

</details>


### [35] [CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support](https://arxiv.org/abs/2508.13256)
*Yuting Zhang,Karina V. Bunting,Asgher Champsi,Xiaoxia Wang,Wenqi Lu,Alexander Thorley,Sandeep S Hothi,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: CardAIc-Agents是一个多模态AI框架，通过外部工具增强模型能力，自适应支持多样化心脏疾病任务，在三个数据集上表现优于主流视觉语言模型和最先进的代理系统。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，医疗工作者严重短缺。现有AI系统存在临床角色分配依赖提示工程、工作流程僵化、知识库静态、输入输出模式固定等问题，限制了临床应用。

Method: 提出多模态框架CardAIc-Agents：1)CardiacRAG代理从可更新心脏知识生成通用计划；2)主代理集成工具自主执行计划；3)逐步更新策略动态优化复杂任务计划；4)多学科讨论工具处理疑难病例；5)视觉审查面板辅助最终验证。

Result: 在三个数据集上的实验表明，CardAIc-Agents相比主流视觉语言模型、最先进的代理系统和微调视觉语言模型具有更高的效率。

Conclusion: 该框架通过工具增强和自适应推理能力，有效解决了现有AI系统在心血管疾病临床应用中的局限性，为自动化早期检测和主动筛查提供了可行方案。

Abstract: Cardiovascular diseases (CVDs) remain the foremost cause of mortality
worldwide, a burden worsened by a severe deficit of healthcare workers.
Artificial intelligence (AI) agents have shown potential to alleviate this gap
via automated early detection and proactive screening, yet their clinical
application remains limited by: 1) prompt-based clinical role assignment that
relies on intrinsic model capabilities without domain-specific tool support; or
2) rigid sequential workflows, whereas clinical care often requires adaptive
reasoning that orders specific tests and, based on their results, guides
personalised next steps; 3) general and static knowledge bases without
continuous learning capability; and 4) fixed unimodal or bimodal inputs and
lack of on-demand visual outputs when further clarification is needed. In
response, a multimodal framework, CardAIc-Agents, was proposed to augment
models with external tools and adaptively support diverse cardiac tasks.
Specifically, a CardiacRAG agent generated general plans from updatable cardiac
knowledge, while the chief agent integrated tools to autonomously execute these
plans and deliver decisions. To enable adaptive and case-specific
customization, a stepwise update strategy was proposed to dynamically refine
plans based on preceding execution results, once the task was assessed as
complex. In addition, a multidisciplinary discussion tool was introduced to
interpret challenging cases, thereby supporting further adaptation. When
clinicians raised concerns, visual review panels were provided to assist final
validation. Experiments across three datasets showed the efficiency of
CardAIc-Agents compared to mainstream Vision-Language Models (VLMs),
state-of-the-art agentic systems, and fine-tuned VLMs.

</details>


### [36] [Towards Unified Multimodal Financial Forecasting: Integrating Sentiment Embeddings and Market Indicators via Cross-Modal Attention](https://arxiv.org/abs/2508.13327)
*Sarthak Khanna,Armin Berger,David Berghaus,Tobias Deusser,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.AI

TL;DR: STONK是一个多模态股票预测框架，结合数值市场指标和情感增强的新闻嵌入，通过特征拼接和跨模态注意力机制提升股票走势预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统单一分析方法（仅数值或仅文本）的局限性，通过整合多模态数据提高股票预测的准确性和可靠性。

Method: 采用特征拼接和跨模态注意力机制融合数值市场指标和情感增强的新闻嵌入，构建统一的多模态预测管道。

Result: 回测显示STONK优于仅使用数值指标的基线模型，提供了融合策略和模型配置的实证指导。

Conclusion: STONK为可扩展的多模态金融预测提供了有效的解决方案，源代码已在GitHub上开源。

Abstract: We propose STONK (Stock Optimization using News Knowledge), a multimodal
framework integrating numerical market indicators with sentiment-enriched news
embeddings to improve daily stock-movement prediction. By combining numerical &
textual embeddings via feature concatenation and cross-modal attention, our
unified pipeline addresses limitations of isolated analyses. Backtesting shows
STONK outperforms numeric-only baselines. A comprehensive evaluation of fusion
strategies and model configurations offers evidence-based guidance for scalable
multimodal financial forecasting. Source code is available on GitHub

</details>


### [37] [HiFo-Prompt: Prompting with Hindsight and Foresight for LLM-based Automatic Heuristic Design](https://arxiv.org/abs/2508.13333)
*Chentong Chen,Mengyuan Zhong,Jianyong Sun,Ye Fan,Jialong Shi*

Main category: cs.AI

TL;DR: HiFo-Prompt框架通过前瞻性和后顾性提示策略，解决LLM自动启发式设计中静态操作符和知识积累不足的问题，显著提升启发式生成质量和收敛速度


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自动启发式设计方法使用静态操作符且缺乏知识积累机制，限制了其有效性

Method: 提出HiFo-Prompt框架，包含两种协同提示策略：前瞻性提示基于种群动态自适应引导搜索，管理探索-利用权衡；后顾性提示从过往成功启发式中提炼可重用设计原则

Result: 实验结果表明HiFo-Prompt显著优于最先进的LLM-based AHD方法，生成更高质量启发式，实现更快收敛和更优查询效率

Conclusion: 双机制提示策略将瞬时发现转化为持久知识库，使LLM能够从自身经验中学习，有效提升自动启发式设计性能

Abstract: LLM-based Automatic Heuristic Design (AHD) within Evolutionary Computation
(EC) frameworks has shown promising results. However, its effectiveness is
hindered by the use of static operators and the lack of knowledge accumulation
mechanisms. We introduce HiFo-Prompt, a framework that guides LLMs with two
synergistic prompting strategies: Foresight and Hindsight. Foresight-based
prompts adaptively steer the search based on population dynamics, managing the
exploration-exploitation trade-off. In addition, hindsight-based prompts mimic
human expertise by distilling successful heuristics from past generations into
fundamental, reusable design principles. This dual mechanism transforms
transient discoveries into a persistent knowledge base, enabling the LLM to
learn from its own experience. Empirical results demonstrate that HiFo-Prompt
significantly outperforms state-of-the-art LLM-based AHD methods, generating
higher-quality heuristics while achieving substantially faster convergence and
superior query efficiency.

</details>


### [38] [LOOP: A Plug-and-Play Neuro-Symbolic Framework for Enhancing Planning in Autonomous Systems](https://arxiv.org/abs/2508.13371)
*Ronit Virwani,Ruchika Suryawanshi*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Planning is one of the most critical tasks in autonomous systems, where even
a small error can lead to major failures or million-dollar losses. Current
state-of-the-art neural planning approaches struggle with complex domains,
producing plans with missing preconditions, inconsistent goals, and
hallucinations. While classical planners provide logical guarantees, they lack
the flexibility and natural language understanding capabilities needed for
modern autonomous systems. Existing neuro-symbolic approaches use one-shot
translation from natural language to formal plans, missing the opportunity for
neural and symbolic components to work and refine solutions together. To
address this gap, we develop LOOP -- a novel neuro-symbolic planning framework
that treats planning as an iterative conversation between neural and symbolic
components rather than simple translation. LOOP integrates 13 coordinated
neural features including graph neural networks for spatial relationships,
multi-agent validation for consensus-based correctness, hierarchical
decomposition for complex task management, and causal memory that learns from
both successes and failures. Unlike existing approaches, LOOP generates PDDL
specifications, refines them iteratively based on symbolic feedback, and builds
a causal knowledge base from execution traces. LOOP was evaluated on six
standard IPC benchmark domains, where it achieved 85.8% success rate compared
to LLM+P (55.0%), LLM-as-Planner (19.2%), and Tree-of-Thoughts (3.3%). This
work shows that the key to reliable planning is not in choosing between neural
networks or symbolic reasoners but it lies in making them actually ``talk'' to
each other during the entire process. LOOP provides a thorough blueprint for
building autonomous systems that can finally be trusted with critical
real-world applications.

</details>


### [39] [SPANER: Shared Prompt Aligner for Multimodal Semantic Representation](https://arxiv.org/abs/2508.13387)
*Thye Shan Ng,Caren Soyeon Han,Eun-Jung Holden*

Main category: cs.AI

TL;DR: SPANER是一个模态无关的参数高效微调框架，通过共享提示机制将不同模态输入嵌入到统一语义空间，提升多模态学习的可扩展性和跨模态泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态PEFT方法主要关注任务特定性能提升，但忽视了多模态嵌入空间的结构，导致模态特定表示孤立，限制了跨模态泛化能力。

Method: 提出SPANER框架，采用共享提示机制作为概念锚点，使语义相关的实例在空间中聚合，无论其模态如何。该设计支持无缝集成额外模态（如音频）而无需改变核心架构。

Result: 在视觉-语言和音频-视觉基准测试中，SPANER展示了具有竞争力的少样本检索性能，同时在学习的嵌入空间中保持了高语义一致性。

Conclusion: 研究强调了调整嵌入空间结构的重要性，而不仅仅是调整适配器权重，这对于可扩展的多模态学习至关重要。

Abstract: Recent advances in multimodal Parameter-Efficient Fine-Tuning (PEFT) have
significantly improved performance on downstream tasks such as few-shot
retrieval. However, most existing approaches focus on task-specific gains while
neglecting the structure of the multimodal embedding space. As a result,
modality-specific representations often remain isolated, limiting cross-modal
generalisation. In this work, we introduce Shared Prompt AligNER (SPANER), a
modality-agnostic PEFT framework designed to embed inputs from diverse
modalities into a unified semantic space. At its core, SPANER employs a shared
prompt mechanism that acts as a conceptual anchor, enabling semantically
related instances to converge spatially regardless of modality. This shared
prompt design is inherently extensible, supporting the seamless integration of
additional modalities, such as audio, without altering the core architecture.
Through comprehensive experiments across vision-language and audio-visual
benchmarks, SPANER demonstrates competitive few-shot retrieval performance
while preserving high semantic coherence in the learned embedding space. Our
results highlight the importance of aligning embedding structures, rather than
merely tuning adapter weights, for scalable multimodal learning.

</details>


### [40] [TASER: Table Agents for Schema-guided Extraction and Recommendation](https://arxiv.org/abs/2508.13404)
*Nicole Cho,Kirsty Fielding,William Watson,Sumitra Ganesh,Manuela Veloso*

Main category: cs.AI

TL;DR: TASER是一个持续学习的智能表格提取系统，专门处理现实世界中高度非结构化、多页、异构的金融表格，通过模式引导的提取和推荐机制，在表格检测性能上超越现有模型10.1%，并能显著提升提取的金融持仓数据量。


<details>
  <summary>Details</summary>
Motivation: 现实金融文档中的表格信息往往埋藏在混乱、多页、碎片化的表格中（99.4%的表格没有边界框，最多426行跨44页），传统方法难以有效处理这些独特的挑战。

Method: 开发了TASER系统，包含表格检测、分类、提取和推荐代理，利用初始模式执行任务，然后通过推荐代理审查输出、建议模式修订并决定最终推荐，实现持续学习。

Result: TASER在表格检测上比Table Transformer模型提升10.1%；更大的批量大小使可操作和使用的模式建议增加104.3%，提取的持仓数据增加9.8%；创建了包含22,584页、3,213个表格、7310亿美元持仓的真实金融表格数据集TASERTab。

Conclusion: 基于代理的模式引导提取系统在理解现实世界金融表格方面展现出巨大潜力，持续学习过程对于提升提取性能至关重要。

Abstract: Real-world financial documents report essential information about an entity's
financial holdings that can span millions of different financial instrument
types. Yet, these details are often buried in messy, multi-page, fragmented
tables - for example, 99.4% of the tables in our dataset have no bounding boxes
with the maximum number of rows amounting to 426 per table across 44 pages. To
tackle these unique challenges from real-world tables, we present a
continuously learning, agentic table extraction system, TASER (Table Agents for
Schema-guided Extraction and Recommendation) that extracts highly unstructured,
multi-page, heterogeneous tables into normalized, schema-conforming outputs.
Our table agents execute on table detection, classification, extraction, and
recommendations by leveraging an initial schema. Then, our Recommender Agent
reviews the outputs, recommends schema revisions, and decides on the final
recommendations, enabling TASER to outperform existing table detection models
such as Table Transformer by 10.1%. Within this continuous learning process, we
highlight that larger batch sizes result in a 104.3% increase in schema
recommendations that are actionable and utilized, resulting in a 9.8% increase
in extracted holdings - highlighting the importance of a continuous learning
process. To train TASER, we have manually labeled 22,584 pages (28,150,449
tokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of
the first real financial table datasets. We release our dataset TASERTab to
enable the research community to access real-world financial tables and
outputs. Our results highlight the promise of agentic, schema-guided extraction
systems for robust understanding of real-world financial tables.

</details>


### [41] [Virtuous Machines: Towards Artificial General Science](https://arxiv.org/abs/2508.13421)
*Gabrielle Wehr,Reuben Rideaux,Amaya J. Fox,David R. Lightfoot,Jason Tangen,Jason B. Mattingley,Shane E. Ehrhardt*

Main category: cs.AI

TL;DR: AI系统自主完成心理学研究全流程：假设生成、数据收集、分析到论文撰写，展示了AI科学发现能力


<details>
  <summary>Details</summary>
Motivation: 科学文献爆炸式增长和领域专业化限制了跨学科知识整合，需要更通用的AI系统来加速科学发现

Method: 使用领域无关的AI代理系统，自主设计并执行三个心理学研究（视觉工作记忆、心理旋转、意象生动度），收集288名参与者数据，开发分析流程

Result: AI系统能够进行非平凡研究，理论推理和方法严谨性堪比经验丰富的研究人员，但在概念细微差别和理论解释方面存在局限

Conclusion: 这是向能够通过真实实验测试假设的具身AI迈出的一步，可自主探索人类认知和资源限制无法触及的科学领域，引发了关于科学理解本质和科学贡献归属的重要问题

Abstract: Artificial intelligence systems are transforming scientific discovery by
accelerating specific research tasks, from protein structure prediction to
materials design, yet remain confined to narrow domains requiring substantial
human oversight. The exponential growth of scientific literature and increasing
domain specialisation constrain researchers' capacity to synthesise knowledge
across disciplines and develop unifying theories, motivating exploration of
more general-purpose AI systems for science. Here we show that a
domain-agnostic, agentic AI system can independently navigate the scientific
workflow - from hypothesis generation through data collection to manuscript
preparation. The system autonomously designed and executed three psychological
studies on visual working memory, mental rotation, and imagery vividness,
executed one new online data collection with 288 participants, developed
analysis pipelines through 8-hour+ continuous coding sessions, and produced
completed manuscripts. The results demonstrate the capability of AI scientific
discovery pipelines to conduct non-trivial research with theoretical reasoning
and methodological rigour comparable to experienced researchers, though with
limitations in conceptual nuance and theoretical interpretation. This is a step
toward embodied AI that can test hypotheses through real-world experiments,
accelerating discovery by autonomously exploring regions of scientific space
that human cognitive and resource constraints might otherwise leave unexplored.
It raises important questions about the nature of scientific understanding and
the attribution of scientific credit.

</details>


### [42] [STPFormer: A State-of-the-Art Pattern-Aware Spatio-Temporal Transformer for Traffic Forecasting](https://arxiv.org/abs/2508.13433)
*Jiayu Fang,Zhiqi Shao,S T Boris Choy,Junbin Gao*

Main category: cs.AI

TL;DR: STPFormer是一个时空模式感知Transformer模型，通过统一的表示学习方法在交通预测任务中实现了最先进的性能，包含四个核心模块来处理复杂的时空模式。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer模型在时空交通预测中存在时间编码僵化和时空融合能力弱的问题，无法有效处理复杂的时空模式和多样化的输入格式。

Method: 提出了STPFormer模型，包含四个模块：Temporal Position Aggregator（TPA）用于模式感知的时间编码，Spatial Sequence Aggregator（SSA）用于序列空间学习，Spatial-Temporal Graph Matching（STGM）用于跨域对齐，以及Attention Mixer用于多尺度融合。

Result: 在五个真实世界数据集上的实验表明，STPFormer始终达到新的SOTA结果，消融实验和可视化验证了其有效性和泛化能力。

Conclusion: STPFormer通过统一的表示学习方法成功解决了时空交通预测中的关键挑战，为复杂时空模式建模提供了有效的解决方案。

Abstract: Spatio-temporal traffic forecasting is challenging due to complex temporal
patterns, dynamic spatial structures, and diverse input formats. Although
Transformer-based models offer strong global modeling, they often struggle with
rigid temporal encoding and weak space-time fusion. We propose STPFormer, a
Spatio-Temporal Pattern-Aware Transformer that achieves state-of-the-art
performance via unified and interpretable representation learning. It
integrates four modules: Temporal Position Aggregator (TPA) for pattern-aware
temporal encoding, Spatial Sequence Aggregator (SSA) for sequential spatial
learning, Spatial-Temporal Graph Matching (STGM) for cross-domain alignment,
and an Attention Mixer for multi-scale fusion. Experiments on five real-world
datasets show that STPFormer consistently sets new SOTA results, with ablation
and visualizations confirming its effectiveness and generalizability.

</details>


### [43] [Discrete Optimization of Min-Max Violation and its Applications Across Computational Sciences](https://arxiv.org/abs/2508.13437)
*Cheikh Ahmed,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: 提出了离散最小最大违规（DMMV）作为通用优化问题，开发了GPU加速启发式算法，在语言模型量化、离散层析成像和FIR滤波器设计三个应用场景中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 许多应用场景都有最坏情况性能要求，需要一个能够最小化最大约束违规的通用优化框架来处理离散值分配问题。

Method: 提出了DMMV问题的数学定义，开发了基于GPU加速的启发式算法，利用DMMV的数学特性加速求解过程。

Result: 在量化任务中平均提升14%，离散层析成像中误差减少16%且GPU加速6倍，FIR滤波器设计中波纹减少近50%。

Conclusion: DMMV作为上下文无关优化问题具有广泛适用性，提出的启发式算法在多个领域展现优势，代码将开源以促进进一步研究。

Abstract: We introduce the Discrete Min-Max Violation (DMMV) as a general optimization
problem which seeks an assignment of discrete values to variables that
minimizes the largest constraint violation. This context-free mathematical
formulation is applicable to a wide range of use cases that have worst-case
performance requirements. After defining the DMMV problem mathematically, we
explore its properties to establish a foundational understanding. To tackle
DMMV instance sizes of practical relevance, we develop a GPU-accelerated
heuristic that takes advantage of the mathematical properties of DMMV for
speeding up the solution process. We demonstrate the versatile applicability of
our heuristic by solving three optimization problems as use cases: (1)
post-training quantization of language models, (2) discrete tomography, and (3)
Finite Impulse Response (FIR) filter design. In quantization without outlier
separation, our heuristic achieves 14% improvement on average over existing
methods. In discrete tomography, it reduces reconstruction error by 16% under
uniform noise and accelerates computations by a factor of 6 on GPU. For FIR
filter design, it nearly achieves 50% ripple reduction compared to using the
commercial integer optimization solver, Gurobi. Our comparative results point
to the benefits of studying DMMV as a context-free optimization problem and the
advantages that our proposed heuristic offers on three distinct problems. Our
GPU-accelerated heuristic will be made open-source to further stimulate
research on DMMV and its other applications. The code is available at
https://anonymous.4open.science/r/AMVM-5F3E/

</details>


### [44] [LM Agents May Fail to Act on Their Own Risk Knowledge](https://arxiv.org/abs/2508.13465)
*Yuzhi Tang,Tianxiao Li,Elizabeth Li,Chris J. Maddison,Honghua Dong,Yangjun Ruan*

Main category: cs.AI

TL;DR: 研究发现语言模型代理存在风险意识与安全执行能力之间的显著差距，即使知道某些操作危险，在实际执行时仍会执行危险操作。作者开发了评估框架和风险验证器系统，将危险操作执行率降低了55.3%。


<details>
  <summary>Details</summary>
Motivation: 语言模型代理在安全关键场景中存在严重风险，虽然具备风险知识但在实际执行时无法有效应用这些知识，存在明显的知行差距。

Method: 开发了包含三个维度的评估框架：风险知识、风险识别能力、风险规避行为。基于观察到的差距，设计了风险验证器系统，包含抽象器将具体执行轨迹转换为抽象描述以便模型更好识别风险。

Result: 评估显示代理风险知识通过率>98%，但实际风险识别性能下降>23%，危险操作执行通过率<26%。风险验证器系统将危险操作执行率降低了55.3%。

Conclusion: 单纯提升模型能力或推理计算无法解决安全问题，需要专门的安全机制。风险验证器系统能有效减少危险操作执行，为解决语言模型代理的安全问题提供了有效方案。

Abstract: Language model (LM) agents have demonstrated significant potential for
automating real-world tasks, yet they pose a diverse array of potential, severe
risks in safety-critical scenarios. In this work, we identify a significant gap
between LM agents' risk awareness and safety execution abilities: while they
often answer "Yes" to queries like "Is executing `sudo rm -rf /*' dangerous?",
they will likely fail to identify such risks in instantiated trajectories or
even directly perform these risky actions when acting as agents. To
systematically investigate this, we develop a comprehensive evaluation
framework to examine agents' safety across three progressive dimensions: 1)
their knowledge about potential risks, 2) their ability to identify
corresponding risks in execution trajectories, and 3) their actual behaviors to
avoid executing these risky actions. Our evaluation reveals two critical
performance gaps that resemble the generator-validator gaps observed in LMs:
while agents demonstrate near-perfect risk knowledge ($>98\%$ pass rates), they
fail to apply this knowledge when identifying risks in actual scenarios (with
performance dropping by $>23\%$) and often still execute risky actions ($<26\%$
pass rates). Notably, this trend persists across more capable LMs as well as in
specialized reasoning models like DeepSeek-R1, indicating that simply scaling
model capabilities or inference compute does not inherently resolve safety
concerns. Instead, we take advantage of these observed gaps to develop a risk
verifier that independently critiques the proposed actions by agents, with an
abstractor that converts specific execution trajectories into abstract
descriptions where LMs can more effectively identify the risks. Our overall
system achieves a significant reduction of risky action execution by $55.3\%$
over vanilla-prompted agents.

</details>


### [45] [CrafterDojo: A Suite of Foundation Models for Building Open-Ended Embodied Agents in Crafter](https://arxiv.org/abs/2508.13530)
*Junyeong Park,Hyeonseo Cho,Sungjin Ahn*

Main category: cs.AI

TL;DR: CrafterDojo是一个轻量级的Minecraft-like测试平台，提供基础模型和工具套件，用于通用具身智能体研究的快速原型开发。


<details>
  <summary>Details</summary>
Motivation: Minecraft环境复杂但运行缓慢，不适合快速原型开发；Crafter环境轻量但缺乏基础模型支持，限制了其在通用具身智能体研究中的应用。

Method: 开发了CrafterVPT（行为先验）、CrafterCLIP（视觉语言基础）和CrafterSteve-1（指令跟随）三个基础模型，以及CrafterPlay（行为数据集生成）、CrafterCaption（字幕数据集生成）等工具套件。

Result: 构建了完整的开源代码库，包含参考智能体实现和基准评估，解锁了Crafter环境作为轻量级测试平台的能力。

Conclusion: CrafterDojo成功地将Crafter环境转化为一个适合快速原型开发的Minecraft-like测试平台，为通用具身智能体研究提供了实用的工具和基础模型支持。

Abstract: Developing general-purpose embodied agents is a core challenge in AI.
Minecraft provides rich complexity and internet-scale data, but its slow speed
and engineering overhead make it unsuitable for rapid prototyping. Crafter
offers a lightweight alternative that retains key challenges from Minecraft,
yet its use has remained limited to narrow tasks due to the absence of
foundation models that have driven progress in the Minecraft setting. In this
paper, we present CrafterDojo, a suite of foundation models and tools that
unlock the Crafter environment as a lightweight, prototyping-friendly, and
Minecraft-like testbed for general-purpose embodied agent research. CrafterDojo
addresses this by introducing CrafterVPT, CrafterCLIP, and CrafterSteve-1 for
behavior priors, vision-language grounding, and instruction following,
respectively. In addition, we provide toolkits for generating behavior and
caption datasets (CrafterPlay and CrafterCaption), reference agent
implementations, benchmark evaluations, and a complete open-source codebase.

</details>


### [46] [Toward Better EHR Reasoning in LLMs: Reinforcement Learning with Expert Attention Guidance](https://arxiv.org/abs/2508.13579)
*Yue Fang,Yuxin Guo,Jiaran Gao,Hongxin Ding,Xinke Jiang,Weibin Liao,Yongxin Xu,Yinghao Zhu,Zhibang Yang,Liantao Ma,Junfeng Zhao,Yasha Wang*

Main category: cs.AI

TL;DR: EAG-RL是一个两阶段训练框架，通过专家注意力指导增强大语言模型在电子健康记录推理中的内在能力，平均提升14.62%的性能


<details>
  <summary>Details</summary>
Motivation: 现有方法仅将LLMs用作冻结的检索器，而下游深度学习模型处理预测，未能提升LLMs的内在推理能力，且继承了DL模型的泛化限制

Method: 首先使用专家引导的蒙特卡洛树搜索构建高质量逐步推理轨迹来初始化LLM策略，然后通过强化学习将LLM注意力与专家EHR模型识别的临床显著特征对齐

Result: 在两个真实世界EHR数据集上的实验显示，EAG-RL平均提升LLMs内在EHR推理能力14.62%，同时增强对特征扰动的鲁棒性和对未见临床领域的泛化能力

Conclusion: EAG-RL展示了在临床预测任务中实际部署的潜力，通过专家注意力指导有效提升了LLMs在EHR推理中的性能

Abstract: Improving large language models (LLMs) for electronic health record (EHR)
reasoning is essential for enabling accurate and generalizable clinical
predictions. While LLMs excel at medical text understanding, they underperform
on EHR-based prediction tasks due to challenges in modeling temporally
structured, high-dimensional data. Existing approaches often rely on hybrid
paradigms, where LLMs serve merely as frozen prior retrievers while downstream
deep learning (DL) models handle prediction, failing to improve the LLM's
intrinsic reasoning capacity and inheriting the generalization limitations of
DL models. To this end, we propose EAG-RL, a novel two-stage training framework
designed to intrinsically enhance LLMs' EHR reasoning ability through expert
attention guidance, where expert EHR models refer to task-specific DL models
trained on EHR data. Concretely, EAG-RL first constructs high-quality, stepwise
reasoning trajectories using expert-guided Monte Carlo Tree Search to
effectively initialize the LLM's policy. Then, EAG-RL further optimizes the
policy via reinforcement learning by aligning the LLM's attention with
clinically salient features identified by expert EHR models. Extensive
experiments on two real-world EHR datasets show that EAG-RL improves the
intrinsic EHR reasoning ability of LLMs by an average of 14.62%, while also
enhancing robustness to feature perturbations and generalization to unseen
clinical domains. These results demonstrate the practical potential of EAG-RL
for real-world deployment in clinical prediction tasks. Our code have been
available at https://github.com/devilran6/EAG-RL.

</details>


### [47] [Breaking the SFT Plateau: Multimodal Structured Reinforcement Learning for Chart-to-Code Generation](https://arxiv.org/abs/2508.13587)
*Lei Chen,Xuanle Zhao,Zhixiong Zeng,Jing Huang,Liming Zheng,Yufeng Zhong,Lin Ma*

Main category: cs.AI

TL;DR: 本文提出了多模态结构化强化学习(MSRL)方法，通过结合文本和视觉反馈的多粒度奖励系统，突破了图表转代码任务中监督微调的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在视觉语言模型中有效，但在需要深度理解信息丰富图像和生成结构化输出的任务中应用不足。图表转代码生成需要复杂的视觉推理，仅靠监督微调往往不够，需要有效的强化学习策略来适当奖励结构化输出。

Method: 构建了包含300万真实arXiv表格图表-代码对的最大训练语料库；提出MSRL方法，使用多粒度结构化奖励系统：文本层面基于规则的奖励验证细粒度代码细节，视觉层面通过渲染代码成图像并使用评估模型评估结构相似性；采用两阶段课程学习确保训练稳定性。

Result: MSRL显著突破了SFT的性能瓶颈，在ChartMimic和ReachQA基准测试上分别将高级指标提升了6.2%和9.9%，达到了与先进闭源模型竞争的性能水平。

Conclusion: 多模态结构化强化学习是解决图表转代码生成任务中监督微调性能瓶颈的有效方法，通过结合文本和视觉反馈的多粒度奖励机制能够显著提升模型性能。

Abstract: While reinforcement learning (RL) has proven highly effective for general
reasoning in vision-language models, its application to tasks requiring
in-depth understanding of information-rich images and generation of structured
outputs remains underexplored. Chart-to-code generation exemplifies this
challenge, demanding complex reasoning over visual charts to generate
structured code. Supervised fine-tuning (SFT) alone is often insufficient,
highlighting the need for effective RL strategies that appropriately reward
structured outputs. We systematically investigate the performance plateau in
SFT through large-scale experiments and propose Multimodal Structured
Reinforcement Learning (MSRL) for chart-to-code generation, which substantially
breaks through this plateau. We construct the largest training corpus to date,
containing 3 million chart-code pairs from real-world arXiv tables to mitigate
simplistic patterns of prior synthetic data. Despite reaching state-of-the-art
performance, our experiments show that scaling SFT data eventually hits a
plateau where further increases yield negligible improvements. Our MSRL method
leverages a multi-granularity structured reward system using multimodal textual
and visual feedback. At the textual level, rule-based rewards validate
fine-grained code details. At the visual level, model-based rewards assess
structural similarity by rendering generated code into images and employing an
evaluator model. We implement this within a two-stage curriculum for training
stability. Results demonstrate that MSRL significantly breaks the SFT plateau,
improving high-level metrics by 6.2% and 9.9% on ChartMimic and ReachQA
benchmarks respectively, achieving competitive performance with advanced
closed-source models.

</details>


### [48] [V2P: From Background Suppression to Center Peaking for Robust GUI Grounding Task](https://arxiv.org/abs/2508.13634)
*Jikai Chen,Long Chen,Dong Wang,Leilei Gan,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: V2P方法通过抑制注意力机制和Fitts定律启发的2D高斯热图建模，解决了GUI元素定位中的背景干扰和中心-边缘区分问题，在ScreenSpot基准上取得了92.3%和50.5%的性能


<details>
  <summary>Details</summary>
Motivation: 传统GUI定位方法依赖边界框或中心点回归，忽视了空间交互不确定性和视觉语义层次结构，且存在背景干扰导致注意力漂移以及均匀标注无法区分目标UI元素中心与边缘的问题

Method: 提出Valley-to-Peak (V2P)方法：1) 抑制注意力机制最小化对无关区域的关注；2) 基于Fitts定律的2D高斯热图建模，权重从中心向边缘逐渐递减，方差由目标尺寸决定

Result: 在ScreenSpot-v2和ScreenSpot-Pro两个基准测试上分别达到92.3%和50.5%的性能，消融实验验证了各组件贡献

Conclusion: V2P方法能有效隔离目标区域并让模型专注于UI元素的最关键点，展示了在精确GUI定位任务中的良好泛化能力

Abstract: Precise localization of GUI elements is crucial for the development of GUI
agents. Traditional methods rely on bounding box or center-point regression,
neglecting spatial interaction uncertainty and visual-semantic hierarchies.
Recent methods incorporate attention mechanisms but still face two key issues:
(1) ignoring processing background regions causes attention drift from the
desired area, and (2) uniform labeling fails to distinguish between center and
edges of the target UI element, leading to click imprecision. Inspired by how
humans visually process and interact with GUI elements, we propose the
Valley-to-Peak (V2P) method to address these issues. To mitigate background
distractions, V2P introduces a suppression attention mechanism that minimizes
the model's focus on irrelevant regions to highlight the intended region. For
the issue of center-edge distinction, V2P applies a Fitts' Law-inspired
approach by modeling GUI interactions as 2D Gaussian heatmaps where the weight
gradually decreases from the center towards the edges. The weight distribution
follows a Gaussian function, with the variance determined by the target's size.
Consequently, V2P effectively isolates the target area and teaches the model to
concentrate on the most essential point of the UI element. The model trained by
V2P achieves the performance with 92.3% and 50.5% on two benchmarks
ScreenSpot-v2 and ScreenSpot-Pro. Ablations further confirm each component's
contribution, highlighting V2P's generalizability for precise GUI grounding
tasks.

</details>


### [49] [Interactive Query Answering on Knowledge Graphs with Soft Entity Constraints](https://arxiv.org/abs/2508.13663)
*Daniel Daza,Alberto Bernardi,Luca Costabello,Christophe Gueret,Masoud Mansoury,Michael Cochez,Martijn Schut*

Main category: cs.AI

TL;DR: 提出了基于软约束的知识图谱查询应答方法NQR，通过交互式学习用户偏好来调整查询结果排序，同时保持原有查询答案的完整性


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱查询方法主要基于一阶逻辑，无法处理现实世界中常见的模糊或上下文相关的软约束（如属性偏好、相关类别偏好）

Method: 提出神经查询重排序器(NQR)，通过增量学习用户提供的偏好和非偏好实体示例，在不破坏原始查询答案的前提下调整答案得分

Result: 在扩展的QA基准测试上验证了NQR能够有效捕获软约束，同时保持稳健的查询应答性能

Conclusion: NQR为解决知识图谱查询中的软约束问题提供了有效方案，支持交互式偏好学习，在保持查询完整性的同时提升结果相关性

Abstract: Methods for query answering over incomplete knowledge graphs retrieve
entities that are likely to be answers, which is particularly useful when such
answers cannot be reached by direct graph traversal due to missing edges.
However, existing approaches have focused on queries formalized using
first-order-logic. In practice, many real-world queries involve constraints
that are inherently vague or context-dependent, such as preferences for
attributes or related categories. Addressing this gap, we introduce the problem
of query answering with soft constraints. We propose a Neural Query Reranker
(NQR) designed to adjust query answer scores by incorporating soft constraints
without disrupting the original answers to a query. NQR operates interactively,
refining answers based on incremental examples of preferred and non-preferred
entities. We extend existing QA benchmarks by generating datasets with soft
constraints. Our experiments demonstrate that NQR can capture soft constraints
while maintaining robust query answering performance.

</details>


### [50] [ITL-LIME: Instance-Based Transfer Learning for Enhancing Local Explanations in Low-Resource Data Settings](https://arxiv.org/abs/2508.13672)
*Rehan Raza,Guanjin Wang,Kevin Wong,Hamid Laga,Marco Fisichella*

Main category: cs.AI

TL;DR: 提出ITL-LIME框架，通过实例迁移学习解决LIME在数据稀缺环境下的局部性和不稳定性问题，利用相关源域的真实实例提升解释的保真度和稳定性。


<details>
  <summary>Details</summary>
Motivation: LIME方法在扰动和采样过程中存在随机性，导致在训练数据有限的情况下产生局部性和不稳定性问题，可能生成偏离真实数据流形的样本，使代理模型无法准确近似原始模型的复杂决策边界。

Method: ITL-LIME引入实例迁移学习，通过聚类将源域分区并获取代表性原型，检索与目标实例最相似的原型对应的源域真实实例，结合目标实例的邻近真实实例，使用对比学习编码器作为加权机制，基于实例与目标实例的接近程度分配权重，最后用加权后的源域和目标实例训练代理模型进行解释。

Result: 该方法在数据受限环境下提高了解释的保真度和稳定性，通过利用相关源域的真实实例避免了生成不现实的变异样本，更准确地近似了原始模型的决策边界。

Conclusion: ITL-LIME框架有效解决了LIME在数据稀缺场景下的局限性，通过实例迁移学习和对比学习加权机制，显著提升了可解释人工智能方法在现实数据约束环境中的性能和可靠性。

Abstract: Explainable Artificial Intelligence (XAI) methods, such as Local
Interpretable Model-Agnostic Explanations (LIME), have advanced the
interpretability of black-box machine learning models by approximating their
behavior locally using interpretable surrogate models. However, LIME's inherent
randomness in perturbation and sampling can lead to locality and instability
issues, especially in scenarios with limited training data. In such cases, data
scarcity can result in the generation of unrealistic variations and samples
that deviate from the true data manifold. Consequently, the surrogate model may
fail to accurately approximate the complex decision boundary of the original
model. To address these challenges, we propose a novel Instance-based Transfer
Learning LIME framework (ITL-LIME) that enhances explanation fidelity and
stability in data-constrained environments. ITL-LIME introduces instance
transfer learning into the LIME framework by leveraging relevant real instances
from a related source domain to aid the explanation process in the target
domain. Specifically, we employ clustering to partition the source domain into
clusters with representative prototypes. Instead of generating random
perturbations, our method retrieves pertinent real source instances from the
source cluster whose prototype is most similar to the target instance. These
are then combined with the target instance's neighboring real instances. To
define a compact locality, we further construct a contrastive learning-based
encoder as a weighting mechanism to assign weights to the instances from the
combined set based on their proximity to the target instance. Finally, these
weighted source and target instances are used to train the surrogate model for
explanation purposes.

</details>


### [51] [Knowledge Graph Completion for Action Prediction on Situational Graphs -- A Case Study on Household Tasks](https://arxiv.org/abs/2508.13675)
*Mariam Arustashvili,Jörg Deigmöller,Heiko Paulheim*

Main category: cs.AI

TL;DR: 本文研究发现，用于家庭行为描述的情境知识图谱具有特殊特征，使得许多标准链接预测算法表现不佳，甚至无法超越简单基线方法。


<details>
  <summary>Details</summary>
Motivation: 知识图谱在家庭机器人控制和视频分析中很重要，但视频提取的信息通常不完整，需要补全知识图谱来增强情境理解。

Method: 研究分析了情境知识图谱的特殊特性，并比较了多种链接预测算法在这些图谱上的表现。

Result: 标准链接预测算法在情境知识图谱上表现不佳，无法超越简单基线方法，说明这些算法不适合此类特殊任务。

Conclusion: 情境知识图谱具有独特特征，需要开发专门的链接预测方法来有效处理家庭行为描述任务。

Abstract: Knowledge Graphs are used for various purposes, including business
applications, biomedical analyses, or digital twins in industry 4.0. In this
paper, we investigate knowledge graphs describing household actions, which are
beneficial for controlling household robots and analyzing video footage. In the
latter case, the information extracted from videos is notoriously incomplete,
and completing the knowledge graph for enhancing the situational picture is
essential. In this paper, we show that, while a standard link prediction
problem, situational knowledge graphs have special characteristics that render
many link prediction algorithms not fit for the job, and unable to outperform
even simple baselines.

</details>


### [52] [MHSNet:An MoE-based Hierarchical Semantic Representation Network for Accurate Duplicate Resume Detection with Large Language Model](https://arxiv.org/abs/2508.13676)
*Yu Li,Zulong Chen,Wenjian Xu,Hong Wen,Yipeng Yu,Man Lung Yiu,Yuyu Yin*

Main category: cs.AI

TL;DR: MHSNet是一个多级身份验证框架，用于检测第三方简历与公司人才库中简历的重复项，通过对比学习微调BGE-M3模型，利用MoE生成多级稀疏和密集表示来计算语义相似度。


<details>
  <summary>Details</summary>
Motivation: 第三方网站获取的简历通常不完整且不准确，需要通过重复检测来提升简历质量并丰富公司人才库，但简历文本的语义复杂性、结构异质性和信息不完整性使得这一任务具有挑战性。

Method: 提出MHSNet框架，使用对比学习微调BGE-M3模型，通过状态感知的Mixture-of-Experts (MoE) 生成多级稀疏和密集表示来计算多级语义相似度，处理各种不完整简历。

Result: 实验结果验证了MHSNet的有效性。

Conclusion: MHSNet能够有效解决简历重复检测中的挑战，提升第三方简历质量并丰富公司人才库。

Abstract: To maintain the company's talent pool, recruiters need to continuously search
for resumes from third-party websites (e.g., LinkedIn, Indeed). However,
fetched resumes are often incomplete and inaccurate. To improve the quality of
third-party resumes and enrich the company's talent pool, it is essential to
conduct duplication detection between the fetched resumes and those already in
the company's talent pool. Such duplication detection is challenging due to the
semantic complexity, structural heterogeneity, and information incompleteness
of resume texts. To this end, we propose MHSNet, an multi-level identity
verification framework that fine-tunes BGE-M3 using contrastive learning. With
the fine-tuned , Mixture-of-Experts (MoE) generates multi-level sparse and
dense representations for resumes, enabling the computation of corresponding
multi-level semantic similarities. Moreover, the state-aware Mixture-of-Experts
(MoE) is employed in MHSNet to handle diverse incomplete resumes. Experimental
results verify the effectiveness of MHSNet

</details>


### [53] [Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models](https://arxiv.org/abs/2508.13678)
*Xiao-Wen Yang,Jie-Jing Shao,Lan-Zhe Guo,Bo-Wen Zhang,Zhi Zhou,Lin-Han Jia,Wang-Zhou Dai,Yu-Feng Li*

Main category: cs.AI

TL;DR: 这篇论文全面综述了神经符号方法在增强大语言模型推理能力方面的最新进展，从三个角度讨论了相关方法，并指出了关键挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在各种任务中表现出色，但其推理能力仍然是一个基本挑战。开发具有强大推理能力的AI系统被认为是实现通用人工智能的关键里程碑，受到学术界和工业界的广泛关注。

Method: 论文从三个角度讨论神经符号方法：符号→LLM、LLM→符号、以及LLM+符号的协同方法，对每种方法进行了系统性的综述和分析。

Result: 论文提供了神经符号方法增强LLM推理能力的全面综述，建立了形式化的推理任务框架，并发布了包含相关论文和资源的GitHub仓库。

Conclusion: 神经符号方法是增强LLM推理能力的有前景途径，但仍面临一些关键挑战，需要进一步研究和发展。

Abstract: Large Language Models (LLMs) have shown promising results across various
tasks, yet their reasoning capabilities remain a fundamental challenge.
Developing AI systems with strong reasoning capabilities is regarded as a
crucial milestone in the pursuit of Artificial General Intelligence (AGI) and
has garnered considerable attention from both academia and industry. Various
techniques have been explored to enhance the reasoning capabilities of LLMs,
with neuro-symbolic approaches being a particularly promising way. This paper
comprehensively reviews recent developments in neuro-symbolic approaches for
enhancing LLM reasoning. We first present a formalization of reasoning tasks
and give a brief introduction to the neurosymbolic learning paradigm. Then, we
discuss neuro-symbolic methods for improving the reasoning capabilities of LLMs
from three perspectives: Symbolic->LLM, LLM->Symbolic, and LLM+Symbolic.
Finally, we discuss several key challenges and promising future directions. We
have also released a GitHub repository including papers and resources related
to this survey: https://github.com/LAMDASZ-ML/Awesome-LLM-Reasoning-with-NeSy.

</details>


### [54] [The DeepLog Neurosymbolic Machine](https://arxiv.org/abs/2508.13697)
*Vincent Derkinderen,Robin Manhaeve,Rik Adriaensen,Lucas Van Praet,Lennert De Smet,Giuseppe Marra,Luc De Raedt*

Main category: cs.AI

TL;DR: DeepLog是一个神经符号AI的理论和操作框架，提供构建块和原语来抽象表示和计算机制，支持多种神经符号系统。


<details>
  <summary>Details</summary>
Motivation: 为了解决神经符号AI中缺乏统一框架和抽象表示的问题，提供一个通用的神经符号抽象机器来支持不同类型的逻辑和计算方式。

Method: 包含DeepLog语言（基于一阶逻辑的神经扩展）和计算级组件（使用扩展代数电路作为计算图），形成神经符号抽象机器。

Result: 实现了软件实现，支持GPU加速，能够比较不同模糊和概率逻辑、架构与损失函数中的逻辑使用，以及CPU与GPU实现的性能差异。

Conclusion: DeepLog提供了一个通用且高效的神经符号AI框架，通过抽象化和声明式方法简化了不同神经符号模型的构建和比较。

Abstract: We contribute a theoretical and operational framework for neurosymbolic AI
called DeepLog. DeepLog introduces building blocks and primitives for
neurosymbolic AI that make abstraction of commonly used representations and
computational mechanisms used in neurosymbolic AI. DeepLog can represent and
emulate a wide range of neurosymbolic systems. It consists of two key
components. The first is the DeepLog language for specifying neurosymbolic
models and inference tasks. This language consists of an annotated neural
extension of grounded first-order logic, and makes abstraction of the type of
logic, e.g. boolean, fuzzy or probabilistic, and whether logic is used in the
architecture or in the loss function. The second DeepLog component is situated
at the computational level and uses extended algebraic circuits as
computational graphs. Together these two components are to be considered as a
neurosymbolic abstract machine, with the DeepLog language as the intermediate
level of abstraction and the circuits level as the computational one. DeepLog
is implemented in software, relies on the latest insights in implementing
algebraic circuits on GPUs, and is declarative in that it is easy to obtain
different neurosymbolic models by making different choices for the underlying
algebraic structures and logics. The generality and efficiency of the DeepLog
neurosymbolic machine is demonstrated through an experimental comparison
between 1) different fuzzy and probabilistic logics, 2) between using logic in
the architecture or in the loss function, and 3) between a standalone CPU-based
implementation of a neurosymbolic AI system and a DeepLog GPU-based one.

</details>


### [55] [CausalPlan: Empowering Efficient LLM Multi-Agent Collaboration Through Causality-Driven Planning](https://arxiv.org/abs/2508.13721)
*Minh Hoang Nguyen,Van Dai Do,Dung Nguyen,Thin Nguyen,Hung Le*

Main category: cs.AI

TL;DR: CausalPlan是一个两阶段框架，通过整合显式结构因果推理来改进LLM代理在协作任务中的规划能力，减少无效动作并提高协作性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理（尤其是小型开源模型）在协作任务中经常产生因果无效或不连贯的动作，因为它们依赖表面相关性而非基于因果推理，这限制了它们在动态环境中的协调和规划能力

Method: 提出CausalPlan框架，核心是结构因果行动（SCA）模型：1）从代理轨迹中学习因果图，捕捉先前行动和当前环境状态对未来决策的影响；2）使用因果图为LLM生成的动作提案分配因果分数并重新加权，或在需要时回退到因果基础替代方案

Result: 在Overcooked-AI基准测试的五个多代理协调任务和四个不同规模的LLM上进行评估，CausalPlan持续减少无效动作，在AI-AI和人类-AI设置中都提高了协作性能，优于强化学习基线

Conclusion: 因果驱动规划对于部署高效、可解释和可泛化的多代理LLM系统具有重要价值，无需对LLM本身进行微调即可实现干预一致的行为

Abstract: Large language model (LLM) agents-especially smaller, open-source
models-often produce causally invalid or incoherent actions in collaborative
tasks due to their reliance on surface-level correlations rather than grounded
causal reasoning. This limitation undermines their performance in terms of
coordination and planning in dynamic environments. We address this challenge
with CausalPlan, a two-phase framework that integrates explicit structural
causal reasoning into the LLM planning process. At the core of CausalPlan is
the Structural Causal Action (SCA) model, which learns a causal graph from
agent trajectories to capture how prior actions and current environment states
influence future decisions. This structure is then used to guide action
selection by assigning causal scores to LLM-generated proposals, reweighting
them accordingly, or falling back to causally grounded alternatives when
needed. By embedding this causal knowledge directly into the decision loop,
CausalPlan constrains planning to intervention-consistent behaviours without
requiring fine-tuning of the LLM itself. We evaluate CausalPlan on the
Overcooked-AI benchmark across five multi-agent coordination tasks and four
LLMs of varying sizes: Gemma-7B, Llama-8B, Qwen-14B, and Llama-70B.
Experimental results show that CausalPlan consistently reduces invalid actions
and improves collaboration in both AI-AI and human-AI settings, outperforming
strong reinforcement learning baselines. Our findings highlight the value of
causality-driven planning for deploying efficient, interpretable, and
generalisable multi-agent LLM systems.

</details>


### [56] [Expertise-aware Multi-LLM Recruitment and Collaboration for Medical Decision-Making](https://arxiv.org/abs/2508.13754)
*Liuxin Bao,Zhihao Peng,Xiaofei Zhou,Runmin Cong,Jiyong Zhang,Yixuan Yuan*

Main category: cs.AI

TL;DR: 提出了EMRC框架，通过专家感知的多LLM招募与协作来提升医疗决策的准确性和可靠性，在三个公开数据集上表现优于现有最佳方法


<details>
  <summary>Details</summary>
Motivation: 单个大语言模型在医疗决策中存在参数知识限制和静态训练数据的问题，无法有效整合复杂的临床信息

Method: 两阶段框架：1）基于公开语料构建LLM专业能力表进行专家感知的代理招募；2）通过置信度融合和对抗验证进行多代理协作

Result: 在MMLU-Pro-Health数据集上达到74.45%准确率，比最佳闭源模型GPT-4-0613提升2.69%

Conclusion: EMRC框架通过利用不同LLM的专业能力互补，显著提升了医疗决策系统的性能

Abstract: Medical Decision-Making (MDM) is a complex process requiring substantial
domain-specific expertise to effectively synthesize heterogeneous and
complicated clinical information. While recent advancements in Large Language
Models (LLMs) show promise in supporting MDM, single-LLM approaches are limited
by their parametric knowledge constraints and static training corpora, failing
to robustly integrate the clinical information. To address this challenge, we
propose the Expertise-aware Multi-LLM Recruitment and Collaboration (EMRC)
framework to enhance the accuracy and reliability of MDM systems. It operates
in two stages: (i) expertise-aware agent recruitment and (ii) confidence- and
adversarial-driven multi-agent collaboration. Specifically, in the first stage,
we use a publicly available corpus to construct an LLM expertise table for
capturing expertise-specific strengths of multiple LLMs across medical
department categories and query difficulty levels. This table enables the
subsequent dynamic selection of the optimal LLMs to act as medical expert
agents for each medical query during the inference phase. In the second stage,
we employ selected agents to generate responses with self-assessed confidence
scores, which are then integrated through the confidence fusion and adversarial
validation to improve diagnostic reliability. We evaluate our EMRC framework on
three public MDM datasets, where the results demonstrate that our EMRC
outperforms state-of-the-art single- and multi-LLM methods, achieving superior
diagnostic performance. For instance, on the MMLU-Pro-Health dataset, our EMRC
achieves 74.45% accuracy, representing a 2.69% improvement over the
best-performing closed-source model GPT- 4-0613, which demonstrates the
effectiveness of our expertise-aware agent recruitment strategy and the agent
complementarity in leveraging each LLM's specialized capabilities.

</details>


### [57] [Quantifier Instantiations: To Mimic or To Revolt?](https://arxiv.org/abs/2508.13811)
*Jan Jakubův,Mikoláš Janota*

Main category: cs.AI

TL;DR: 提出了一种基于概率上下文无关文法的动态量化实例化方法，通过从现有技术中学习实例化模式来平衡利用与探索


<details>
  <summary>Details</summary>
Motivation: 量化公式是SMT求解器面临的主要挑战，现有实例化技术各有优势但需要互补。需要一种能够动态学习并生成新实例的方法来改进量化推理

Method: 将观察到的实例化视为潜在语言的样本，使用概率上下文无关文法生成相似的新术语。可以反转学习到的术语概率来探索多样性

Result: 该方法能够模仿成功的过往实例化，同时通过概率反转实现探索多样性，在量化推理中实现利用与探索的平衡

Conclusion: 提出的概率文法方法为量化实例化提供了新的动态学习框架，能够有效结合现有技术的优势并生成高质量的实例化术语

Abstract: Quantified formulas pose a significant challenge for Satisfiability Modulo
Theories (SMT) solvers due to their inherent undecidability. Existing
instantiation techniques, such as e-matching, syntax-guided, model-based,
conflict-based, and enumerative methods, often complement each other. This
paper introduces a novel instantiation approach that dynamically learns from
these techniques during solving. By treating observed instantiations as samples
from a latent language, we use probabilistic context-free grammars to generate
new, similar terms. Our method not only mimics successful past instantiations
but also explores diversity by optionally inverting learned term probabilities,
aiming to balance exploitation and exploration in quantifier reasoning.

</details>


### [58] [Revisiting RAG Ensemble: A Theoretical and Mechanistic Analysis of Multi-RAG System Collaboration](https://arxiv.org/abs/2508.13828)
*Yifei Chen,Guanting Dong,Yutao Zhu,Zhicheng Dou*

Main category: cs.AI

TL;DR: 本文系统研究了基于多RAG系统的集成方法，从信息熵理论角度解释RAG集成框架，并在流水线和模块层面进行机制分析，实验证明多RAG系统集成具有良好的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 单一RAG框架无法很好适应广泛的下游任务，需要探索如何利用多个RAG系统的优势来解决这一问题。

Method: 从理论和机制两个角度分析RAG集成框架：理论层面从信息熵角度解释；机制层面从流水线（分支、迭代、循环、代理四种）和模块（生成器、检索器、重排序器三个）两个层级进行探索，解决了七个不同的研究问题。

Result: 实验表明，无论是在流水线层面还是模块层面，聚合多个RAG系统都具有良好的泛化性和鲁棒性。

Conclusion: 本研究为多RAG系统集成相关研究奠定了基础，证明了集成方法的有效性。

Abstract: Retrieval-Augmented Generation (RAG) technology has been widely applied in
recent years. However, despite the emergence of various RAG frameworks, a
single RAG framework still cannot adapt well to a broad range of downstream
tasks. Therefore, how to leverage the advantages of multiple RAG systems has
become an area worth exploring. To address this issue, we have conducted a
comprehensive and systematic investigation into ensemble methods based on RAG
systems. Specifically, we have analyzed the RAG ensemble framework from both
theoretical and mechanistic analysis perspectives. From the theoretical
analysis, we provide the first explanation of the RAG ensemble framework from
the perspective of information entropy. In terms of mechanism analysis, we have
explored the RAG ensemble framework from both the pipeline and module levels.
We carefully select four different pipelines (Branching, Iterative, Loop, and
Agentic) and three different modules (Generator, Retriever, and Reranker) to
solve seven different research questions. The experiments show that aggregating
multiple RAG systems is both generalizable and robust, whether at the pipeline
level or the module level. Our work lays the foundation for similar research on
the multi-RAG system ensemble.

</details>


### [59] [Improved Generalized Planning with LLMs through Strategy Refinement and Reflection](https://arxiv.org/abs/2508.13876)
*Katharina Stein,Nils Hodel,Daniel Fišer,Jörg Hoffmann,Michael Katz,Alexander Koller*

Main category: cs.AI

TL;DR: 本文提出了一种改进的LLM生成广义规划方法，通过伪代码调试和程序变体选择，显著提高了PDDL领域中Python程序的规划质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接生成单一策略并转换为Python程序，如果策略错误会导致整个规划失败。需要先验证策略正确性再生成程序。

Method: 1) 生成伪代码策略并自动调试 2) 在Python调试阶段增加反思步骤定位失败原因 3) 生成多个程序变体并选择最佳方案

Result: 在17个基准域上测试，新方法显著提升规划质量且从不降低性能。12个域中的最佳程序能解决该域生成器产生的所有任务。

Conclusion: 通过伪代码调试、反思机制和多程序选择，有效提高了LLM生成广义规划的可靠性和成功率。

Abstract: LLMs have recently been used to generate Python programs representing
generalized plans in PDDL planning, i.e., plans that generalize across the
tasks of a given PDDL domain. Previous work proposed a framework consisting of
three steps: the LLM first generates a summary and then a strategy for the
domain, both in natural language, and then implements that strategy as a Python
program, that gets debugged on example planning tasks. In that work, only one
strategy is generated and passed directly to the program generation. If the
strategy is incorrect, its implementation will therefore result in an incorrect
generalized plan. Here, we introduce an approach that generates the strategy in
the form of pseudocode and enables automatic debugging of the pseudocode, hence
allowing us to identify and fix errors prior to the generation of the
generalized plan itself. Additionally, we extend the Python debugging phase
with a reflection step prompting the LLM to pinpoint the reason for the
observed plan failure. Finally, we take inspiration from LLM code generation to
produce several program variants and pick the best one. Running experiments on
17 benchmark domains, we show that these extensions substantially improve (and
never deteriorate) the quality of the generalized plans. In 12 of the domains,
our best Python programs solve all tasks that can be generated with the
respective instance generator.

</details>


### [60] [Structured Agentic Workflows for Financial Time-Series Modeling with LLMs and Reflective Feedback](https://arxiv.org/abs/2508.13915)
*Yihao Ang,Yifan Bao,Lei Jiang,Jiajie Tao,Anthony K. H. Tung,Lukasz Szpruch,Hao Ni*

Main category: cs.AI

TL;DR: TS-Agent是一个模块化代理框架，用于自动化金融时间序列建模工作流，通过三阶段决策过程（模型选择、代码优化、微调）实现优于现有AutoML和代理基准的性能。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列数据建模面临高绩效、可解释性和可审计性的挑战，现有AutoML框架缺乏对领域特定需求和动态目标的适应性，而LLM代理系统提供了更灵活的工作流自动化路径。

Method: 设计了三阶段结构化迭代决策流程：模型选择、代码优化和微调，配备结构化知识库和精选模型库的规划代理指导探索，提高可解释性并减少错误传播。

Result: 在多样化金融预测和合成数据生成任务上的实证评估表明，TS-Agent在准确性、鲁棒性和决策可追溯性方面持续优于最先进的AutoML和代理基准。

Conclusion: TS-Agent支持自适应学习、鲁棒调试和透明审计，满足了金融服务等高风险环境的关键要求，为时间序列建模提供了有效的自动化解决方案。

Abstract: Time-series data is central to decision-making in financial markets, yet
building high-performing, interpretable, and auditable models remains a major
challenge. While Automated Machine Learning (AutoML) frameworks streamline
model development, they often lack adaptability and responsiveness to
domain-specific needs and evolving objectives. Concurrently, Large Language
Models (LLMs) have enabled agentic systems capable of reasoning, memory
management, and dynamic code generation, offering a path toward more flexible
workflow automation. In this paper, we introduce \textsf{TS-Agent}, a modular
agentic framework designed to automate and enhance time-series modeling
workflows for financial applications. The agent formalizes the pipeline as a
structured, iterative decision process across three stages: model selection,
code refinement, and fine-tuning, guided by contextual reasoning and
experimental feedback. Central to our architecture is a planner agent equipped
with structured knowledge banks, curated libraries of models and refinement
strategies, which guide exploration, while improving interpretability and
reducing error propagation. \textsf{TS-Agent} supports adaptive learning,
robust debugging, and transparent auditing, key requirements for high-stakes
environments such as financial services. Empirical evaluations on diverse
financial forecasting and synthetic data generation tasks demonstrate that
\textsf{TS-Agent} consistently outperforms state-of-the-art AutoML and agentic
baselines, achieving superior accuracy, robustness, and decision traceability.

</details>


### [61] [The Collaboration Paradox: Why Generative AI Requires Both Strategic Intelligence and Operational Stability in Supply Chain Management](https://arxiv.org/abs/2508.13942)
*Soumyadeep Dhar*

Main category: cs.AI

TL;DR: 研究发现AI驱动的协作代理在供应链中会出现"合作悖论"，即理论上更优的协作AI代理比非AI基准表现更差，原因是库存囤积导致系统瘫痪。


<details>
  <summary>Details</summary>
Motivation: 研究AI代理在经济环境中的涌现战略行为，特别是在多级供应链这种容易出现牛鞭效应等不稳定性的合作环境中。

Method: 使用大型语言模型驱动的生成式AI代理在受控供应链模拟中进行计算实验，设计包含供应商管理库存原则的协作AI代理。

Result: 发现协作悖论现象，AI代理会囤积库存导致系统瘫痪；最终开发出结合高层AI驱动策略制定和低层协作执行协议的双层框架。

Conclusion: 揭示了协作AI代理的涌现行为特征，为设计稳定有效的商业分析AI驱动系统提供了蓝图，强调需要分层架构来实现弹性。

Abstract: The rise of autonomous, AI-driven agents in economic settings raises critical
questions about their emergent strategic behavior. This paper investigates
these dynamics in the cooperative context of a multi-echelon supply chain, a
system famously prone to instabilities like the bullwhip effect. We conduct
computational experiments with generative AI agents, powered by Large Language
Models (LLMs), within a controlled supply chain simulation designed to isolate
their behavioral tendencies. Our central finding is the "collaboration
paradox": a novel, catastrophic failure mode where theoretically superior
collaborative AI agents, designed with Vendor-Managed Inventory (VMI)
principles, perform even worse than non-AI baselines. We demonstrate that this
paradox arises from an operational flaw where agents hoard inventory, starving
the system. We then show that resilience is only achieved through a synthesis
of two distinct layers: high-level, AI-driven proactive policy-setting to
establish robust operational targets, and a low-level, collaborative execution
protocol with proactive downstream replenishment to maintain stability. Our
final framework, which implements this synthesis, can autonomously generate,
evaluate, and quantify a portfolio of viable strategic choices. The work
provides a crucial insight into the emergent behaviors of collaborative AI
agents and offers a blueprint for designing stable, effective AI-driven systems
for business analytics.

</details>


### [62] [ChronoLLM: Customizing Language Models for Physics-Based Simulation Code Generation](https://arxiv.org/abs/2508.13975)
*Jingquan Wang,Andrew Negrut,Harry Zhang,Khailanii Slaton,Shu Wang,Radu Serban,Jinlong Wu,Dan Negrut*

Main category: cs.AI

TL;DR: 本文研究如何通过精调大语言模型(LLMs)来创建虚拟助手，帮助专家使用PyChrono多物理动力学仿真工具生成仿真脚本，降低仿真工具的使用门槛。


<details>
  <summary>Details</summary>
Motivation: 探索预训练大语言模型能否通过精调和定制，成为帮助专家有效使用仿真工具的虚拟助手，特别是针对PyChrono多体系统动力学仿真工具。

Method: 提出了一个框架来精调和定制开源及闭源LLMs，通过特定流程提升生成PyChrono仿真脚本的质量，从简单单摆仿真到复杂车辆在可变形地形上的虚拟实验。

Result: 精调后的LLMs在生成PyChrono仿真脚本质量上有量化提升，虽然生成的脚本很少完美，但通常能作为用户修改和改进的良好起点，还能回答特定API问题和推荐建模方法。

Conclusion: 该框架具有通用性，可应用于降低其他应用领域相关仿真工具的使用门槛，证明了LLMs在辅助专家使用专业仿真工具方面的潜力。

Abstract: This contribution is concerned with the following issue: can pretrained large
language models (LLMs) be refined and customized to the point where they become
virtual assistants helping experts with the effective use of a simulation tool?
In this case study, the ``simulation tool'' considered is PyChrono, an open
source multi-physics dynamics engine for multibody systems. We present a
framework for refining and customizing both open- and closed-source LLMs to
harness the power of AI in generating scripts that perform PyChrono virtual
experiments. We refine and customize several classes of LLMs through a process
that leads to a quantifiable improvement in the quality of the generated
PyChrono simulation scripts. These scripts can range from simple
single-pendulum simulations to complex virtual experiments involving full
vehicles on deformable terrain. While the generated scripts are rarely perfect,
they often serve as strong starting points for the user to modify and improve
on. Additionally, the LLM can answer specific API questions about the
simulator, or recommend modeling approaches. The framework discussed is general
and can be applied to lower the entry barrier for simulation tools associated
with other application domains.

</details>


### [63] [A Biased Random Key Genetic Algorithm for Solving the Longest Run Subsequence Problem](https://arxiv.org/abs/2508.14020)
*Christian Blum,Pedro Pinacho-Davidson*

Main category: cs.AI

TL;DR: 本文提出了一种使用偏置随机密钥遗传算法（BRKGA）解决最长运行子序列（LRS）问题的方法，该算法在计算效率方面表现优异，是目前LRS问题的最先进技术。


<details>
  <summary>Details</summary>
Motivation: LRS问题是一个NP难的组合优化问题，在生物信息学中的基因组重组装中具有重要作用，需要高效的求解方法。

Method: 采用偏置随机密钥遗传算法（BRKGA），重点优化个体评估的计算效率，将灰度值向量转换为有效解。同时开发了最大最小蚂蚁系统和CPLEX求解器进行比较。

Result: 计算结果表明，提出的BRKGA算法在LRS问题上表现优异，是目前最先进的技术。

Conclusion: 虽然BRKGA在LRS问题上表现良好，但在基于大字母表的输入字符串方面仍有改进空间。

Abstract: The longest run subsequence (LRS) problem is an NP-hard combinatorial
optimization problem belonging to the class of subsequence problems from
bioinformatics. In particular, the problem plays a role in genome reassembly.
In this paper, we present a solution to the LRS problem using a Biased Random
Key Genetic Algorithm (BRKGA). Our approach places particular focus on the
computational efficiency of evaluating individuals, which involves converting
vectors of gray values into valid solutions to the problem. For comparison
purposes, a Max-Min Ant System is developed and implemented. This is in
addition to the application of the integer linear programming solver CPLEX for
solving all considered problem instances. The computation results show that the
proposed BRKGA is currently a state-of-the-art technique for the LRS problem.
Nevertheless, the results also show that there is room for improvement,
especially in the context of input strings based on large alphabet sizes.

</details>


### [64] [ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents](https://arxiv.org/abs/2508.14040)
*Hanyu Lai,Xiao Liu,Yanxiao Zhao,Han Xu,Hanchen Zhang,Bohao Jing,Yanyu Ren,Shuntian Yao,Yuxiao Dong,Jie Tang*

Main category: cs.AI

TL;DR: ComputerRL是一个自主桌面智能框架，通过API-GUI范式统一程序化API调用和直接GUI交互，解决机器代理与人类中心桌面环境的不匹配问题。采用分布式RL基础设施和Entropulse训练策略，在OSWorld基准测试中达到48.1%的新SOTA准确率。


<details>
  <summary>Details</summary>
Motivation: 解决机器代理在人类中心桌面环境中操作复杂数字工作空间时的固有失配问题，提升桌面自动化的通用性和效率。

Method: 提出API-GUI范式统一程序化API和GUI交互；开发分布式RL基础设施支持大规模并行虚拟桌面环境训练；设计Entropulse训练策略交替使用强化学习和监督微调来缓解熵崩溃问题。

Result: 在OSWorld基准测试中，基于GLM-4-9B-0414的AutoGLM-OS-9B模型达到48.1%的state-of-the-art准确率，显著提升了桌面自动化通用代理的性能。

Conclusion: ComputerRL框架通过创新的API-GUI范式和可扩展的训练基础设施，成功实现了桌面智能代理的高效训练和优异性能，为自主桌面自动化提供了有效解决方案。

Abstract: We introduce ComputerRL, a framework for autonomous desktop intelligence that
enables agents to operate complex digital workspaces skillfully. ComputerRL
features the API-GUI paradigm, which unifies programmatic API calls and direct
GUI interaction to address the inherent mismatch between machine agents and
human-centric desktop environments. Scaling end-to-end RL training is crucial
for improvement and generalization across diverse desktop tasks, yet remains
challenging due to environmental inefficiency and instability in extended
training. To support scalable and robust training, we develop a distributed RL
infrastructure capable of orchestrating thousands of parallel virtual desktop
environments to accelerate large-scale online RL. Furthermore, we propose
Entropulse, a training strategy that alternates reinforcement learning with
supervised fine-tuning, effectively mitigating entropy collapse during extended
training runs. We employ ComputerRL on open models GLM-4-9B-0414 and
Qwen2.5-14B, and evaluate them on the OSWorld benchmark. The AutoGLM-OS-9B
based on GLM-4-9B-0414 achieves a new state-of-the-art accuracy of 48.1%,
demonstrating significant improvements for general agents in desktop
automation. The algorithm and framework are adopted in building AutoGLM (Liu et
al., 2024a)

</details>
