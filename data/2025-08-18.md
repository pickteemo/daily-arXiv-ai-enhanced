<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 30]
- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Developing and Validating a High-Throughput Robotic System for the Accelerated Development of Porous Membranes](https://arxiv.org/abs/2508.10973)
*Hongchen Wang,Sima Zeinali Danalou,Jiahao Zhu,Kenneth Sulimro,Chaewon Lim,Smita Basak,Aimee Tai,Usan Siriwardana,Jason Hattrick-Simpers,Jay Werber*

Main category: cs.RO

TL;DR: 提出了一种全自动平台，用于通过非溶剂诱导相分离（NIPS）制备和表征多孔聚合物膜，提高了实验效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 传统多孔聚合物膜的开发过程耗时且依赖试错，需要更高效、可控的方法。

Method: 集成自动化溶液制备、刮刀涂布、控制浸没和压缩测试，精确控制参数如聚合物浓度和环境湿度。

Result: 系统成功复现了聚合物浓度和湿度对膜性能的影响，支持高通量实验。

Conclusion: 该自动化平台为数据驱动的多孔膜优化提供了可扩展且可重复的基础。

Abstract: The development of porous polymeric membranes remains a labor-intensive
process, often requiring extensive trial and error to identify optimal
fabrication parameters. In this study, we present a fully automated platform
for membrane fabrication and characterization via nonsolvent-induced phase
separation (NIPS). The system integrates automated solution preparation, blade
casting, controlled immersion, and compression testing, allowing precise
control over fabrication parameters such as polymer concentration and ambient
humidity. The modular design allows parallel processing and reproducible
handling of samples, reducing experimental time and increasing consistency.
Compression testing is introduced as a sensitive mechanical characterization
method for estimating membrane stiffness and as a proxy to infer porosity and
intra-sample uniformity through automated analysis of stress-strain curves. As
a proof of concept to demonstrate the effectiveness of the system, NIPS was
carried out with polysulfone, the green solvent PolarClean, and water as the
polymer, solvent, and nonsolvent, respectively. Experiments conducted with the
automated system reproduced expected effects of polymer concentration and
ambient humidity on membrane properties, namely increased stiffness and
uniformity with increasing polymer concentration and humidity variations in
pore morphology and mechanical response. The developed automated platform
supports high-throughput experimentation and is well-suited for integration
into self-driving laboratory workflows, offering a scalable and reproducible
foundation for data-driven optimization of porous polymeric membranes through
NIPS.

</details>


### [2] [Robust Online Calibration for UWB-Aided Visual-Inertial Navigation with Bias Correction](https://arxiv.org/abs/2508.10999)
*Yizhi Zhou,Jie Xu,Jiawei Xia,Zechen Hu,Weizi Li,Xuan Wang*

Main category: cs.RO

TL;DR: 提出了一种新颖的鲁棒在线校准框架，用于UWB辅助视觉惯性导航系统中的UWB锚点校准，解决了现有方法对机器人定位误差和初始猜测敏感的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有UWB锚点校准方法依赖准确的机器人定位和初始猜测，实际应用中鲁棒性不足。

Method: 通过显式考虑机器人定位不确定性，提出基于Schmidt Kalman Filter的紧耦合在线优化方法。

Result: 仿真和实际实验验证了该方法在精度和鲁棒性上的提升。

Conclusion: 该方法显著提高了UWB锚点校准的鲁棒性和实用性。

Abstract: This paper presents a novel robust online calibration framework for
Ultra-Wideband (UWB) anchors in UWB-aided Visual-Inertial Navigation Systems
(VINS). Accurate anchor positioning, a process known as calibration, is crucial
for integrating UWB ranging measurements into state estimation. While several
prior works have demonstrated satisfactory results by using robot-aided systems
to autonomously calibrate UWB systems, there are still some limitations: 1)
these approaches assume accurate robot localization during the initialization
step, ignoring localization errors that can compromise calibration robustness,
and 2) the calibration results are highly sensitive to the initial guess of the
UWB anchors' positions, reducing the practical applicability of these methods
in real-world scenarios. Our approach addresses these challenges by explicitly
incorporating the impact of robot localization uncertainties into the
calibration process, ensuring robust initialization. To further enhance the
robustness of the calibration results against initialization errors, we propose
a tightly-coupled Schmidt Kalman Filter (SKF)-based online refinement method,
making the system suitable for practical applications. Simulations and
real-world experiments validate the improved accuracy and robustness of our
approach.

</details>


### [3] [3D FlowMatch Actor: Unified 3D Policy for Single- and Dual-Arm Manipulation](https://arxiv.org/abs/2508.11002)
*Nikolaos Gkanatsios,Jiahe Xu,Matthew Bronars,Arsalan Mousavian,Tsung-Wei Ke,Katerina Fragkiadaki*

Main category: cs.RO

TL;DR: 3DFA是一种结合流匹配和3D预训练视觉场景表示的机器人操作策略架构，显著提升了训练和推理速度，并在多个基准测试中达到最新性能。


<details>
  <summary>Details</summary>
Motivation: 通过结合流匹配和3D视觉表示，提升机器人操作策略的学习效率和性能，解决现有方法训练慢和性能不足的问题。

Method: 利用3D相对注意力机制和流匹配技术，优化动作去噪过程，并通过系统级和架构优化加速训练和推理。

Result: 在PerAct2基准测试中性能提升41.4%，训练和推理速度提升30倍，并在真实世界和RLBench任务中表现优异。

Conclusion: 3DFA通过创新的设计和优化，显著提升了机器人操作策略的效率和性能，为未来研究提供了重要参考。

Abstract: We present 3D FlowMatch Actor (3DFA), a 3D policy architecture for robot
manipulation that combines flow matching for trajectory prediction with 3D
pretrained visual scene representations for learning from demonstration. 3DFA
leverages 3D relative attention between action and visual tokens during action
denoising, building on prior work in 3D diffusion-based single-arm policy
learning. Through a combination of flow matching and targeted system-level and
architectural optimizations, 3DFA achieves over 30x faster training and
inference than previous 3D diffusion-based policies, without sacrificing
performance. On the bimanual PerAct2 benchmark, it establishes a new state of
the art, outperforming the next-best method by an absolute margin of 41.4%. In
extensive real-world evaluations, it surpasses strong baselines with up to
1000x more parameters and significantly more pretraining. In unimanual
settings, it sets a new state of the art on 74 RLBench tasks by directly
predicting dense end-effector trajectories, eliminating the need for motion
planning. Comprehensive ablation studies underscore the importance of our
design choices for both policy effectiveness and efficiency.

</details>


### [4] [GenFlowRL: Shaping Rewards with Generative Object-Centric Flow in Visual Reinforcement Learning](https://arxiv.org/abs/2508.11049)
*Kelin Yu,Sheng Zhang,Harshit Soora,Furong Huang,Heng Huang,Pratap Tokekar,Ruohan Gao*

Main category: cs.RO

TL;DR: GenFlowRL通过从多样化的跨体现数据集中提取生成的流来塑造奖励，从而学习通用且鲁棒的策略。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型依赖生成数据质量且缺乏环境反馈，难以处理精细操作，同时视频生成的不确定性和大规模机器人数据集收集的挑战限制了视频强化学习的性能。

Method: 提出GenFlowRL，利用从跨体现数据集中训练的生成流提取形状奖励，通过低维、以对象为中心的特征学习策略。

Result: 在10个操作任务的仿真和现实跨体现评估中，GenFlowRL表现出色，能有效利用生成的对象中心流特征。

Conclusion: GenFlowRL通过生成的对象中心流特征，在多样化和挑战性场景中实现了优越性能。

Abstract: Recent advances have shown that video generation models can enhance robot
learning by deriving effective robot actions through inverse dynamics. However,
these methods heavily depend on the quality of generated data and struggle with
fine-grained manipulation due to the lack of environment feedback. While
video-based reinforcement learning improves policy robustness, it remains
constrained by the uncertainty of video generation and the challenges of
collecting large-scale robot datasets for training diffusion models. To address
these limitations, we propose GenFlowRL, which derives shaped rewards from
generated flow trained from diverse cross-embodiment datasets. This enables
learning generalizable and robust policies from diverse demonstrations using
low-dimensional, object-centric features. Experiments on 10 manipulation tasks,
both in simulation and real-world cross-embodiment evaluations, demonstrate
that GenFlowRL effectively leverages manipulation features extracted from
generated object-centric flow, consistently achieving superior performance
across diverse and challenging scenarios. Our Project Page:
https://colinyu1.github.io/genflowrl

</details>


### [5] [Utilizing Vision-Language Models as Action Models for Intent Recognition and Assistance](https://arxiv.org/abs/2508.11093)
*Cesar Alan Contreras,Manolis Chiou,Alireza Rastegarpanah,Michal Szulik,Rustam Stolkin*

Main category: cs.RO

TL;DR: 论文提出了一种结合视觉语言模型（VLM）和纯文本语言模型（LLM）的GUIDER框架改进方法，用于增强人机协作中意图推断和目标选择的能力。


<details>
  <summary>Details</summary>
Motivation: 提升机器人在人机协作中快速推断用户意图、提供透明推理并协助用户实现目标的能力。

Method: 通过VLM和LLM构建语义先验，结合YOLO和Segment Anything Model的视觉管道，筛选与任务提示相关的对象和位置。

Result: 改进后的GUIDER框架能够根据上下文选择相关目标，并在达到阈值后实现自主导航和物体抓取。

Conclusion: 未来工作将在Isaac Sim中评估系统，重点关注实时辅助能力。

Abstract: Human-robot collaboration requires robots to quickly infer user intent,
provide transparent reasoning, and assist users in achieving their goals. Our
recent work introduced GUIDER, our framework for inferring navigation and
manipulation intents. We propose augmenting GUIDER with a vision-language model
(VLM) and a text-only language model (LLM) to form a semantic prior that
filters objects and locations based on the mission prompt. A vision pipeline
(YOLO for object detection and the Segment Anything Model for instance
segmentation) feeds candidate object crops into the VLM, which scores their
relevance given an operator prompt; in addition, the list of detected object
labels is ranked by a text-only LLM. These scores weight the existing
navigation and manipulation layers of GUIDER, selecting context-relevant
targets while suppressing unrelated objects. Once the combined belief exceeds a
threshold, autonomy changes occur, enabling the robot to navigate to the
desired area and retrieve the desired object, while adapting to any changes in
the operator's intent. Future work will evaluate the system on Isaac Sim using
a Franka Emika arm on a Ridgeback base, with a focus on real-time assistance.

</details>


### [6] [Robot Policy Evaluation for Sim-to-Real Transfer: A Benchmarking Perspective](https://arxiv.org/abs/2508.11117)
*Xuning Yang,Clemens Eppner,Jonathan Tremblay,Dieter Fox,Stan Birchfield,Fabio Ramos*

Main category: cs.RO

TL;DR: 论文讨论了设计通用机器人操作策略基准的挑战与需求，提出了高视觉保真仿真、任务复杂性评估和性能对齐量化的方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉的机器人仿真基准在真实世界应用中评估通用策略的进展滞后，需改进仿真到现实的策略迁移。

Method: 1) 使用高视觉保真仿真；2) 通过增加任务复杂性和扰动评估策略鲁棒性；3) 量化仿真与现实的性能对齐。

Result: 提出的方法旨在提升仿真到现实的策略迁移效果，并评估策略的鲁棒性和性能一致性。

Conclusion: 设计通用机器人操作策略基准需关注仿真保真度、任务复杂性和性能对齐，以促进真实世界应用。

Abstract: Current vision-based robotics simulation benchmarks have significantly
advanced robotic manipulation research. However, robotics is fundamentally a
real-world problem, and evaluation for real-world applications has lagged
behind in evaluating generalist policies. In this paper, we discuss challenges
and desiderata in designing benchmarks for generalist robotic manipulation
policies for the goal of sim-to-real policy transfer. We propose 1) utilizing
high visual-fidelity simulation for improved sim-to-real transfer, 2)
evaluating policies by systematically increasing task complexity and scenario
perturbation to assess robustness, and 3) quantifying performance alignment
between real-world performance and its simulation counterparts.

</details>


### [7] [Geometry-Aware Predictive Safety Filters on Humanoids: From Poisson Safety Functions to CBF Constrained MPC](https://arxiv.org/abs/2508.11129)
*Ryan M. Bena,Gilbert Bahati,Blake Werner,Ryan K. Cosner,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 提出了一种基于控制屏障函数（CBFs）的非线性模型预测控制（MPC）算法，用于动态环境中腿式机器人的安全轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 解决腿式机器人在非结构化和动态变化环境中的自主导航问题，尤其是几何不对称性带来的安全挑战。

Method: 利用泊松安全函数从感知数据中合成CBF约束，扩展理论框架以处理动态边界问题，并采用Minkowski集合操作考虑机器人几何形状。

Result: 在类人机器人和四足机器人上实现了实时预测安全过滤器，验证了泊松安全函数的通用性和CBF约束MPC控制器的优势。

Conclusion: 该方法为动态环境中的机器人安全导航提供了有效的解决方案，展示了泊松安全函数和CBF约束MPC的潜力。

Abstract: Autonomous navigation through unstructured and dynamically-changing
environments is a complex task that continues to present many challenges for
modern roboticists. In particular, legged robots typically possess manipulable
asymmetric geometries which must be considered during safety-critical
trajectory planning. This work proposes a predictive safety filter: a nonlinear
model predictive control (MPC) algorithm for online trajectory generation with
geometry-aware safety constraints based on control barrier functions (CBFs).
Critically, our method leverages Poisson safety functions to numerically
synthesize CBF constraints directly from perception data. We extend the
theoretical framework for Poisson safety functions to incorporate temporal
changes in the domain by reformulating the static Dirichlet problem for
Poisson's equation as a parameterized moving boundary value problem.
Furthermore, we employ Minkowski set operations to lift the domain into a
configuration space that accounts for robot geometry. Finally, we implement our
real-time predictive safety filter on humanoid and quadruped robots in various
safety-critical scenarios. The results highlight the versatility of Poisson
safety functions, as well as the benefit of CBF constrained model predictive
safety-critical controllers.

</details>


### [8] [Actor-Critic for Continuous Action Chunks: A Reinforcement Learning Framework for Long-Horizon Robotic Manipulation with Sparse Reward](https://arxiv.org/abs/2508.11143)
*Jiarui Yang,Bin Zhu,Jingjing Chen,Yu-Gang Jiang*

Main category: cs.RO

TL;DR: AC3（Actor-Critic for Continuous Chunks）是一种新型强化学习框架，通过稳定化机制高效学习连续动作序列，解决了稀疏奖励任务中的长时程机器人操作问题。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在稀疏奖励的长时程机器人操作任务中表现不佳，直接学习连续动作块存在稳定性和数据效率的挑战。

Method: AC3结合了非对称更新规则（仅从成功轨迹学习）和稳定化批评家更新（使用n步回报和自监督模块提供内在奖励）。

Result: 在BiGym和RLBench的25个任务中，AC3仅需少量演示和简单模型架构即取得更高成功率。

Conclusion: AC3通过设计有效的稳定化机制，显著提升了稀疏奖励任务中的性能。

Abstract: Existing reinforcement learning (RL) methods struggle with long-horizon
robotic manipulation tasks, particularly those involving sparse rewards. While
action chunking is a promising paradigm for robotic manipulation, using RL to
directly learn continuous action chunks in a stable and data-efficient manner
remains a critical challenge. This paper introduces AC3 (Actor-Critic for
Continuous Chunks), a novel RL framework that learns to generate
high-dimensional, continuous action sequences. To make this learning process
stable and data-efficient, AC3 incorporates targeted stabilization mechanisms
for both the actor and the critic. First, to ensure reliable policy
improvement, the actor is trained with an asymmetric update rule, learning
exclusively from successful trajectories. Second, to enable effective value
learning despite sparse rewards, the critic's update is stabilized using
intra-chunk $n$-step returns and further enriched by a self-supervised module
providing intrinsic rewards at anchor points aligned with each action chunk. We
conducted extensive experiments on 25 tasks from the BiGym and RLBench
benchmarks. Results show that by using only a few demonstrations and a simple
model architecture, AC3 achieves superior success rates on most tasks,
validating its effective design.

</details>


### [9] [Visuomotor Grasping with World Models for Surgical Robots](https://arxiv.org/abs/2508.11200)
*Hongbin Lin,Bin Li,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: GASv2是一个用于手术抓取的视觉运动学习框架，通过世界模型架构和混合控制系统实现高泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自动化手术抓取可减轻外科医生负担，提高效率、安全性和一致性，但现有方法在泛化性、鲁棒性和处理变形对象方面存在局限。

Method: GASv2结合世界模型架构和手术感知管道，通过域随机化在仿真中训练策略，并在真实机器人上部署。

Result: 实验显示策略在幻影和离体手术场景中成功率65%，泛化至未见对象和夹具，适应多样干扰。

Conclusion: GASv2展示了高性能、泛化性和鲁棒性，为手术抓取自动化提供了可行解决方案。

Abstract: Grasping is a fundamental task in robot-assisted surgery (RAS), and
automating it can reduce surgeon workload while enhancing efficiency, safety,
and consistency beyond teleoperated systems. Most prior approaches rely on
explicit object pose tracking or handcrafted visual features, limiting their
generalization to novel objects, robustness to visual disturbances, and the
ability to handle deformable objects. Visuomotor learning offers a promising
alternative, but deploying it in RAS presents unique challenges, such as low
signal-to-noise ratio in visual observations, demands for high safety and
millimeter-level precision, as well as the complex surgical environment. This
paper addresses three key challenges: (i) sim-to-real transfer of visuomotor
policies to ex vivo surgical scenes, (ii) visuomotor learning using only a
single stereo camera pair -- the standard RAS setup, and (iii) object-agnostic
grasping with a single policy that generalizes to diverse, unseen surgical
objects without retraining or task-specific models. We introduce Grasp Anything
for Surgery V2 (GASv2), a visuomotor learning framework for surgical grasping.
GASv2 leverages a world-model-based architecture and a surgical perception
pipeline for visual observations, combined with a hybrid control system for
safe execution. We train the policy in simulation using domain randomization
for sim-to-real transfer and deploy it on a real robot in both phantom-based
and ex vivo surgical settings, using only a single pair of endoscopic cameras.
Extensive experiments show our policy achieves a 65% success rate in both
settings, generalizes to unseen objects and grippers, and adapts to diverse
disturbances, demonstrating strong performance, generality, and robustness.

</details>


### [10] [Multi-Group Equivariant Augmentation for Reinforcement Learning in Robot Manipulation](https://arxiv.org/abs/2508.11204)
*Hongbin Lin,Juan Rojas,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 论文提出了一种非等距对称性方法（MEA），结合离线强化学习和体素视觉表示，提升机器人操作的采样效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究多局限于等距对称性，限制了采样效率的提升空间。

Method: 引入非等距对称性POMDP模型，提出MEA数据增强方法，结合离线强化学习和体素视觉表示。

Result: 在仿真和真实机器人实验中验证了方法的有效性。

Conclusion: 非等距对称性方法显著提升了采样效率，适用于复杂机器人操作任务。

Abstract: Sampling efficiency is critical for deploying visuomotor learning in
real-world robotic manipulation. While task symmetry has emerged as a promising
inductive bias to improve efficiency, most prior work is limited to isometric
symmetries -- applying the same group transformation to all task objects across
all timesteps. In this work, we explore non-isometric symmetries, applying
multiple independent group transformations across spatial and temporal
dimensions to relax these constraints. We introduce a novel formulation of the
partially observable Markov decision process (POMDP) that incorporates the
non-isometric symmetry structures, and propose a simple yet effective data
augmentation method, Multi-Group Equivariance Augmentation (MEA). We integrate
MEA with offline reinforcement learning to enhance sampling efficiency, and
introduce a voxel-based visual representation that preserves translational
equivariance. Extensive simulation and real-robot experiments across two
manipulation domains demonstrate the effectiveness of our approach.

</details>


### [11] [Embodied Edge Intelligence Meets Near Field Communication: Concept, Design, and Verification](https://arxiv.org/abs/2508.11232)
*Guoliang Li,Xibin Jin,Yujie Wan,Chenxuan Liu,Tong Zhang,Shuai Wang,Chengzhong Xu*

Main category: cs.RO

TL;DR: 本文提出了一种结合边缘智能（EEI）和近场通信（NFC）的新范式NEEI，以解决大型模型在实时推理中的计算需求，并通过联合优化解决新挑战。


<details>
  <summary>Details</summary>
Motivation: 实现具身人工智能面临大型模型的高计算需求挑战，EEI和NFC的结合为解决这一问题提供了新思路。

Method: 提出NEEI范式，包括EEI辅助NFC的无线电友好规划和NFC辅助EEI的视导波束聚焦，并通过协作导航实现资源高效。

Result: 实验结果表明，所提技术优于多种基准方法。

Conclusion: NEEI范式为具身智能提供了高效解决方案，未来可进一步优化其联合设计。

Abstract: Realizing embodied artificial intelligence is challenging due to the huge
computation demands of large models (LMs). To support LMs while ensuring
real-time inference, embodied edge intelligence (EEI) is a promising paradigm,
which leverages an LM edge to provide computing powers in close proximity to
embodied robots. Due to embodied data exchange, EEI requires higher spectral
efficiency, enhanced communication security, and reduced inter-user
interference. To meet these requirements, near-field communication (NFC), which
leverages extremely large antenna arrays as its hardware foundation, is an
ideal solution. Therefore, this paper advocates the integration of EEI and NFC,
resulting in a near-field EEI (NEEI) paradigm. However, NEEI also introduces
new challenges that cannot be adequately addressed by isolated EEI or NFC
designs, creating research opportunities for joint optimization of both
functionalities. To this end, we propose radio-friendly embodied planning for
EEI-assisted NFC scenarios and view-guided beam-focusing for NFC-assisted EEI
scenarios. We also elaborate how to realize resource-efficient NEEI through
opportunistic collaborative navigation. Experimental results are provided to
confirm the superiority of the proposed techniques compared with various
benchmarks.

</details>


### [12] [Tactile Robotics: An Outlook](https://arxiv.org/abs/2508.11261)
*Shan Luo,Nathan F. Lepora,Wenzhen Yuan,Kaspar Althoefer,Gordon Cheng,Ravinder Dahiya*

Main category: cs.RO

TL;DR: 本文探讨了机器人触觉感知技术的发展现状、挑战及未来方向，强调了其在人机交互中的重要性。


<details>
  <summary>Details</summary>
Motivation: 为机器人提供类似生物系统的触觉感知能力，以支持其在人类共存和紧密互动中的应用需求。

Method: 综述了多种触觉传感技术（如压阻、压电、电容、磁性和光学传感器）及其集成方法，并讨论了仿真工具和多模态融合的作用。

Result: 触觉感知技术的进步为机器人提供了更有效的物理交互能力，但仍需解决当前挑战以推动跨领域创新。

Conclusion: 需采用整体方法推动触觉机器人技术的变革，解决现有挑战并探索在制造、医疗、回收和农业等领域的潜在应用。

Abstract: Robotics research has long sought to give robots the ability to perceive the
physical world through touch in an analogous manner to many biological systems.
Developing such tactile capabilities is important for numerous emerging
applications that require robots to co-exist and interact closely with humans.
Consequently, there has been growing interest in tactile sensing, leading to
the development of various technologies, including piezoresistive and
piezoelectric sensors, capacitive sensors, magnetic sensors, and optical
tactile sensors. These diverse approaches utilise different transduction
methods and materials to equip robots with distributed sensing capabilities,
enabling more effective physical interactions. These advances have been
supported in recent years by simulation tools that generate large-scale tactile
datasets to support sensor designs and algorithms to interpret and improve the
utility of tactile data. The integration of tactile sensing with other
modalities, such as vision, as well as with action strategies for active
tactile perception highlights the growing scope of this field. To further the
transformative progress in tactile robotics, a holistic approach is essential.
In this outlook article, we examine several challenges associated with the
current state of the art in tactile robotics and explore potential solutions to
inspire innovations across multiple domains, including manufacturing,
healthcare, recycling and agriculture.

</details>


### [13] [Learning Differentiable Reachability Maps for Optimization-based Humanoid Motion Generation](https://arxiv.org/abs/2508.11275)
*Masaki Murooka,Iori Kumagai,Mitsuharu Morisawa,Fumio Kanehiro*

Main category: cs.RO

TL;DR: 提出了一种可微分可达性地图的新方法，用于降低人形机器人运动生成的算力成本。


<details>
  <summary>Details</summary>
Motivation: 减少人形机器人运动生成的算力成本，通过连续且可微分的可达性地图优化运动规划。

Method: 使用神经网络或支持向量机从机器人末端执行器姿态中学习可微分可达性地图，并将其作为约束用于连续优化问题。

Result: 该方法能高效解决多种运动规划问题，如步态规划、多接触运动规划和操作-移动规划。

Conclusion: 可微分可达性地图为连续优化提供了有效约束，显著提升了人形机器人运动生成的效率。

Abstract: To reduce the computational cost of humanoid motion generation, we introduce
a new approach to representing robot kinematic reachability: the differentiable
reachability map. This map is a scalar-valued function defined in the task
space that takes positive values only in regions reachable by the robot's
end-effector. A key feature of this representation is that it is continuous and
differentiable with respect to task-space coordinates, enabling its direct use
as constraints in continuous optimization for humanoid motion planning. We
describe a method to learn such differentiable reachability maps from a set of
end-effector poses generated using a robot's kinematic model, using either a
neural network or a support vector machine as the learning model. By
incorporating the learned reachability map as a constraint, we formulate
humanoid motion generation as a continuous optimization problem. We demonstrate
that the proposed approach efficiently solves various motion planning problems,
including footstep planning, multi-contact motion planning, and
loco-manipulation planning for humanoid robots.

</details>


### [14] [Scene Graph-Guided Proactive Replanning for Failure-Resilient Embodied Agent](https://arxiv.org/abs/2508.11286)
*Che Rin Yu,Daewon Chae,Dabin Seo,Sangwon Lee,Hyeongwoo Im,Jinkyu Kim*

Main category: cs.RO

TL;DR: 论文提出了一种主动重规划框架，通过对比当前场景图与参考场景图，在子任务边界检测并修正潜在失败，提升机器人任务成功率。


<details>
  <summary>Details</summary>
Motivation: 人类能根据环境状态调整行为，而机器人常因缺乏适应性导致失败。现有方法多在失败后响应，而主动重规划可提前预防失败，但依赖人工规则和监督。

Method: 构建当前RGB-D观测的场景图与成功演示的参考图对比，在子任务边界检测不匹配时，启动轻量推理模块调整计划。

Result: 在AI2-THOR模拟器中，该方法能提前检测语义和空间不匹配，显著提升任务成功率和鲁棒性。

Conclusion: 主动重规划框架通过场景图对比和轻量推理，有效预防执行失败，增强了机器人的自适应能力。

Abstract: When humans perform everyday tasks, we naturally adjust our actions based on
the current state of the environment. For instance, if we intend to put
something into a drawer but notice it is closed, we open it first. However,
many autonomous robots lack this adaptive awareness. They often follow
pre-planned actions that may overlook subtle yet critical changes in the scene,
which can result in actions being executed under outdated assumptions and
eventual failure. While replanning is critical for robust autonomy, most
existing methods respond only after failures occur, when recovery may be
inefficient or infeasible. While proactive replanning holds promise for
preventing failures in advance, current solutions often rely on manually
designed rules and extensive supervision. In this work, we present a proactive
replanning framework that detects and corrects failures at subtask boundaries
by comparing scene graphs constructed from current RGB-D observations against
reference graphs extracted from successful demonstrations. When the current
scene fails to align with reference trajectories, a lightweight reasoning
module is activated to diagnose the mismatch and adjust the plan. Experiments
in the AI2-THOR simulator demonstrate that our approach detects semantic and
spatial mismatches before execution failures occur, significantly improving
task success and robustness.

</details>


### [15] [A Recursive Total Least Squares Solution for Bearing-Only Target Motion Analysis and Circumnavigation](https://arxiv.org/abs/2508.11289)
*Lin Li,Xueming Liu,Zhoujingzi Qiu,Tianjiang Hu,Qingrui Zhang*

Main category: cs.RO

TL;DR: 提出了一种递归总最小二乘法（RTLS）用于移动观测器的在线目标定位与跟踪，解决了仅方位目标运动分析（TMA）的非线性和观测性问题，并通过环绕控制器提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 仅方位TMA因测量模型非线性和缺乏距离信息导致观测性和估计器收敛性差，需要改进。

Method: 采用RTLS方法减少位置估计偏差，并结合环绕控制器提升观测性。

Result: 仿真和实验验证了方法的有效性和鲁棒性，性能优于现有方法。

Conclusion: RTLS结合环绕控制器显著提升了仅方位TMA的精度和稳定性。

Abstract: Bearing-only Target Motion Analysis (TMA) is a promising technique for
passive tracking in various applications as a bearing angle is easy to measure.
Despite its advantages, bearing-only TMA is challenging due to the nonlinearity
of the bearing measurement model and the lack of range information, which
impairs observability and estimator convergence. This paper addresses these
issues by proposing a Recursive Total Least Squares (RTLS) method for online
target localization and tracking using mobile observers. The RTLS approach,
inspired by previous results on Total Least Squares (TLS), mitigates biases in
position estimation and improves computational efficiency compared to
pseudo-linear Kalman filter (PLKF) methods. Additionally, we propose a
circumnavigation controller to enhance system observability and estimator
convergence by guiding the mobile observer in orbit around the target.
Extensive simulations and experiments are performed to demonstrate the
effectiveness and robustness of the proposed method. The proposed algorithm is
also compared with the state-of-the-art approaches, which confirms its superior
performance in terms of both accuracy and stability.

</details>


### [16] [Pedestrian Dead Reckoning using Invariant Extended Kalman Filter](https://arxiv.org/abs/2508.11396)
*Jingran Zhang,Zhengzhang Yan,Yiming Chen,Zeqiang He,Jiahao Chen*

Main category: cs.RO

TL;DR: 本文提出了一种在GPS缺失环境下为双足机器人设计的低成本惯性行人航位推算方法，通过伪测量校正IMU预测，并展示了InEKF优于标准EKF的实验结果。


<details>
  <summary>Details</summary>
Motivation: 在GPS缺失环境中，双足机器人需要可靠的定位方法。传统EKF调参复杂，而InEKF在理论和实际应用中表现更优。

Method: 利用IMU在支撑脚时的伪测量校正预测，采用基于矩阵李群的InEKF理论，并通过三种实验验证方法可行性。

Result: 实验表明InEKF在运动捕捉、大规模多楼层行走和双足机器人实验中均优于EKF，且调参更简单。

Conclusion: InEKF是一种高效且易于调参的双足机器人定位方法，适用于GPS缺失环境。

Abstract: This paper presents a cost-effective inertial pedestrian dead reckoning
method for the bipedal robot in the GPS-denied environment. Each time when the
inertial measurement unit (IMU) is on the stance foot, a stationary
pseudo-measurement can be executed to provide innovation to the IMU measurement
based prediction. The matrix Lie group based theoretical development of the
adopted invariant extended Kalman filter (InEKF) is set forth for tutorial
purpose. Three experiments are conducted to compare between InEKF and standard
EKF, including motion capture benchmark experiment, large-scale multi-floor
walking experiment, and bipedal robot experiment, as an effort to show our
method's feasibility in real-world robot system. In addition, a sensitivity
analysis is included to show that InEKF is much easier to tune than EKF.

</details>


### [17] [An Exploratory Study on Crack Detection in Concrete through Human-Robot Collaboration](https://arxiv.org/abs/2508.11404)
*Junyeon Kim,Tianshu Ruan,Cesar Alan Contreras,Manolis Chiou*

Main category: cs.RO

TL;DR: AI与机器人技术结合，通过人机协作提升核设施结构检测的准确性和效率，减少人工负担。


<details>
  <summary>Details</summary>
Motivation: 传统人工检测方法存在安全风险、认知负担高和人为误差问题，亟需更安全高效的替代方案。

Method: 研究采用AI辅助视觉裂纹检测技术，集成到移动Jackal机器人平台中，实现人机协作检测。

Result: 实验表明，人机协作显著提高检测准确性并降低操作员工作负担。

Conclusion: AI辅助机器人检测在核设施结构检查中表现优于传统人工方法。

Abstract: Structural inspection in nuclear facilities is vital for maintaining
operational safety and integrity. Traditional methods of manual inspection pose
significant challenges, including safety risks, high cognitive demands, and
potential inaccuracies due to human limitations. Recent advancements in
Artificial Intelligence (AI) and robotic technologies have opened new
possibilities for safer, more efficient, and accurate inspection methodologies.
Specifically, Human-Robot Collaboration (HRC), leveraging robotic platforms
equipped with advanced detection algorithms, promises significant improvements
in inspection outcomes and reductions in human workload. This study explores
the effectiveness of AI-assisted visual crack detection integrated into a
mobile Jackal robot platform. The experiment results indicate that HRC enhances
inspection accuracy and reduces operator workload, resulting in potential
superior performance outcomes compared to traditional manual methods.

</details>


### [18] [Open, Reproducible and Trustworthy Robot-Based Experiments with Virtual Labs and Digital-Twin-Based Execution Tracing](https://arxiv.org/abs/2508.11406)
*Benjamin Alt,Mareike Picklum,Sorin Arion,Franklin Kenghagho Kenfack,Michael Beetz*

Main category: cs.RO

TL;DR: 论文提出了一种语义执行追踪框架和AICOR VRB平台，旨在实现透明、可复现的机器人自主科学实验。


<details>
  <summary>Details</summary>
Motivation: 为实现机器人科学实验的透明性、可重复性和开放性，推动自主系统参与科学发现。

Method: 开发语义执行追踪框架记录传感器数据和机器人信念状态，并构建AICOR VRB云平台以共享和验证任务执行。

Result: 工具整合了确定性执行、语义记忆和开放知识表示，支持可复现的机器人驱动科学研究。

Conclusion: 这些工具为自主系统参与科学发现奠定了基础，提升了实验的透明性和可复现性。

Abstract: We envision a future in which autonomous robots conduct scientific
experiments in ways that are not only precise and repeatable, but also open,
trustworthy, and transparent. To realize this vision, we present two key
contributions: a semantic execution tracing framework that logs sensor data
together with semantically annotated robot belief states, ensuring that
automated experimentation is transparent and replicable; and the AICOR Virtual
Research Building (VRB), a cloud-based platform for sharing, replicating, and
validating robot task executions at scale. Together, these tools enable
reproducible, robot-driven science by integrating deterministic execution,
semantic memory, and open knowledge representation, laying the foundation for
autonomous systems to participate in scientific discovery.

</details>


### [19] [EvoPSF: Online Evolution of Autonomous Driving Models via Planning-State Feedback](https://arxiv.org/abs/2508.11453)
*Jiayue Jin,Lang Qian,Jingyu Zhang,Chuanyu Ju,Liang Song*

Main category: cs.RO

TL;DR: EvoPSF提出了一种基于规划状态反馈的在线演化框架，通过利用规划器的不确定性作为触发信号，针对性地更新模型，提升自动驾驶系统在未知环境中的适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统多为离线训练，缺乏在线适应新环境的机制，导致在真实场景中泛化能力不足。

Method: 利用规划器的不确定性作为触发信号，通过自监督损失对关键对象进行针对性模型更新。

Result: 实验表明，EvoPSF在nuScenes数据集的不同区域和损坏变体上均提升了规划性能。

Conclusion: EvoPSF通过在线演化机制，显著提升了自动驾驶系统在复杂环境中的鲁棒性和规划准确性。

Abstract: Recent years have witnessed remarkable progress in autonomous driving, with
systems evolving from modular pipelines to end-to-end architectures. However,
most existing methods are trained offline and lack mechanisms to adapt to new
environments during deployment. As a result, their generalization ability
diminishes when faced with unseen variations in real-world driving scenarios.
In this paper, we break away from the conventional "train once, deploy forever"
paradigm and propose EvoPSF, a novel online Evolution framework for autonomous
driving based on Planning-State Feedback. We argue that planning failures are
primarily caused by inaccurate object-level motion predictions, and such
failures are often reflected in the form of increased planner uncertainty. To
address this, we treat planner uncertainty as a trigger for online evolution,
using it as a diagnostic signal to initiate targeted model updates. Rather than
performing blind updates, we leverage the planner's agent-agent attention to
identify the specific objects that the ego vehicle attends to most, which are
primarily responsible for the planning failures. For these critical objects, we
compute a targeted self-supervised loss by comparing their predicted waypoints
from the prediction module with their actual future positions, selected from
the perception module's outputs with high confidence scores. This loss is then
backpropagated to adapt the model online. As a result, our method improves the
model's robustness to environmental changes, leads to more precise motion
predictions, and therefore enables more accurate and stable planning behaviors.
Experiments on both cross-region and corrupted variants of the nuScenes dataset
demonstrate that EvoPSF consistently improves planning performance under
challenging conditions.

</details>


### [20] [OVSegDT: Segmenting Transformer for Open-Vocabulary Object Goal Navigation](https://arxiv.org/abs/2508.11479)
*Tatiana Zemskova,Aleksei Staroverov,Dmitry Yudin,Aleksandr Panov*

Main category: cs.RO

TL;DR: OVSegDT是一种轻量级Transformer策略，通过语义分支和熵自适应损失调制，显著提升了开放词汇目标导航的性能和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决现有端到端策略在小规模模拟数据集上的过拟合问题，以及泛化能力差和不安全行为（频繁碰撞）的挑战。

Method: 1. 语义分支：包含目标二进制掩码编码器和辅助分割损失函数，用于文本目标的空间定位。2. 熵自适应损失调制：动态平衡模仿和强化信号，避免手动切换。

Result: 训练样本复杂度降低33%，碰撞次数减少一半，推理成本低（130M参数，仅RGB输入）。在HM3D-OVON上，未见类别性能与已见类别相当，达到SOTA（40.1% SR，20.9% SPL）。

Conclusion: OVSegDT通过创新设计显著提升了开放词汇目标导航的性能和泛化能力，同时保持低计算成本。

Abstract: Open-vocabulary Object Goal Navigation requires an embodied agent to reach
objects described by free-form language, including categories never seen during
training. Existing end-to-end policies overfit small simulator datasets,
achieving high success on training scenes but failing to generalize and
exhibiting unsafe behaviour (frequent collisions). We introduce OVSegDT, a
lightweight transformer policy that tackles these issues with two synergistic
components. The first component is the semantic branch, which includes an
encoder for the target binary mask and an auxiliary segmentation loss function,
grounding the textual goal and providing precise spatial cues. The second
component consists of a proposed Entropy-Adaptive Loss Modulation, a per-sample
scheduler that continuously balances imitation and reinforcement signals
according to the policy entropy, eliminating brittle manual phase switches.
These additions cut the sample complexity of training by 33%, and reduce
collision count in two times while keeping inference cost low (130M parameters,
RGB-only input). On HM3D-OVON, our model matches the performance on unseen
categories to that on seen ones and establishes state-of-the-art results (40.1%
SR, 20.9% SPL on val unseen) without depth, odometry, or large vision-language
models. Code is available at https://github.com/CognitiveAISystems/OVSegDT.

</details>


### [21] [i2Nav-Robot: A Large-Scale Indoor-Outdoor Robot Dataset for Multi-Sensor Fusion Navigation and Mapping](https://arxiv.org/abs/2508.11485)
*Hailiang Tang,Tisheng Zhang,Liqiang Wang,Xin Ding,Man Yuan,Zhiyu Xiang,Jujin Chen,Yuhan Bian,Shuangyan Liu,Yuqing Wang,Guan Wang,Xiaoji Niu*

Main category: cs.RO

TL;DR: i2Nav-Robot是一个大规模多传感器融合数据集，旨在解决UGV导航和地图构建中的传感器配置、时间同步和场景多样性不足问题。


<details>
  <summary>Details</summary>
Motivation: 当前UGV数据集在传感器配置、时间同步、地面真实性和场景多样性方面存在不足，限制了导航和地图构建技术的发展。

Method: 通过集成多模态传感器（如LiDAR、雷达、相机等），并采用硬件同步和离线校准确保时间同步，构建了覆盖室内外场景的10个大规模序列。

Result: 数据集总长度约17060米，地面真实位置精度达厘米级，经多个开源系统验证具有高质量。

Conclusion: i2Nav-Robot数据集为UGV导航和地图构建提供了高质量、多样化的数据支持。

Abstract: Accurate and reliable navigation is crucial for autonomous unmanned ground
vehicle (UGV). However, current UGV datasets fall short in meeting the demands
for advancing navigation and mapping techniques due to limitations in sensor
configuration, time synchronization, ground truth, and scenario diversity. To
address these challenges, we present i2Nav-Robot, a large-scale dataset
designed for multi-sensor fusion navigation and mapping in indoor-outdoor
environments. We integrate multi-modal sensors, including the newest front-view
and 360-degree solid-state LiDARs, 4-dimensional (4D) radar, stereo cameras,
odometer, global navigation satellite system (GNSS) receiver, and inertial
measurement units (IMU) on an omnidirectional wheeled robot. Accurate
timestamps are obtained through both online hardware synchronization and
offline calibration for all sensors. The dataset comprises ten larger-scale
sequences covering diverse UGV operating scenarios, such as outdoor streets,
and indoor parking lots, with a total length of about 17060 meters.
High-frequency ground truth, with centimeter-level accuracy for position, is
derived from post-processing integrated navigation methods using a
navigation-grade IMU. The proposed i2Nav-Robot dataset is evaluated by more
than ten open-sourced multi-sensor fusion systems, and it has proven to have
superior data quality.

</details>


### [22] [Relative Position Matters: Trajectory Prediction and Planning with Polar Representation](https://arxiv.org/abs/2508.11492)
*Bozhou Zhang,Nan Song,Bingzhao Gao,Li Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种基于极坐标的轨迹预测与规划方法Polaris，通过距离和方向建模，显著提升了自动驾驶中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在笛卡尔坐标系中建模车辆与周围元素的相对关系不够直观，无法有效捕捉距离和方向的影响。

Method: 采用极坐标系统（半径和角度表示），设计专用编码和优化模块，显式建模距离和方向变化。

Result: 在Argoverse 2和nuPlan基准测试中，Polaris达到了最先进的性能。

Conclusion: 极坐标表示能更直观地建模空间关系，为自动驾驶的轨迹预测与规划提供了更优的解决方案。

Abstract: Trajectory prediction and planning in autonomous driving are highly
challenging due to the complexity of predicting surrounding agents' movements
and planning the ego agent's actions in dynamic environments. Existing methods
encode map and agent positions and decode future trajectories in Cartesian
coordinates. However, modeling the relationships between the ego vehicle and
surrounding traffic elements in Cartesian space can be suboptimal, as it does
not naturally capture the varying influence of different elements based on
their relative distances and directions. To address this limitation, we adopt
the Polar coordinate system, where positions are represented by radius and
angle. This representation provides a more intuitive and effective way to model
spatial changes and relative relationships, especially in terms of distance and
directional influence. Based on this insight, we propose Polaris, a novel
method that operates entirely in Polar coordinates, distinguishing itself from
conventional Cartesian-based approaches. By leveraging the Polar
representation, this method explicitly models distance and direction variations
and captures relative relationships through dedicated encoding and refinement
modules, enabling more structured and spatially aware trajectory prediction and
planning. Extensive experiments on the challenging prediction (Argoverse 2) and
planning benchmarks (nuPlan) demonstrate that Polaris achieves state-of-the-art
performance.

</details>


### [23] [Sim2Dust: Mastering Dynamic Waypoint Tracking on Granular Media](https://arxiv.org/abs/2508.11503)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 提出了一种完整的模拟到现实框架，用于在行星表面复杂地形中开发可靠的自主导航控制策略。


<details>
  <summary>Details</summary>
Motivation: 解决学习型控制器在行星表面非结构化地形中的模拟到现实差距问题，特别是轮与颗粒介质交互的复杂动力学。

Method: 利用大规模并行模拟训练强化学习代理，通过随机化物理生成多样化环境，零样本迁移到物理月球模拟设施中的轮式漫游车。

Result: 实验表明，具有程序多样性的代理在零样本性能上优于静态场景训练的代理，高保真粒子物理微调在低速精度上略有提升但计算成本高。

Conclusion: 建立了一个可靠的基于学习的导航系统开发流程，为未来空间探索中的自主机器人部署迈出关键一步。

Abstract: Reliable autonomous navigation across the unstructured terrains of distant
planetary surfaces is a critical enabler for future space exploration. However,
the deployment of learning-based controllers is hindered by the inherent
sim-to-real gap, particularly for the complex dynamics of wheel interactions
with granular media. This work presents a complete sim-to-real framework for
developing and validating robust control policies for dynamic waypoint tracking
on such challenging surfaces. We leverage massively parallel simulation to
train reinforcement learning agents across a vast distribution of procedurally
generated environments with randomized physics. These policies are then
transferred zero-shot to a physical wheeled rover operating in a lunar-analogue
facility. Our experiments systematically compare multiple reinforcement
learning algorithms and action smoothing filters to identify the most effective
combinations for real-world deployment. Crucially, we provide strong empirical
evidence that agents trained with procedural diversity achieve superior
zero-shot performance compared to those trained on static scenarios. We also
analyze the trade-offs of fine-tuning with high-fidelity particle physics,
which offers minor gains in low-speed precision at a significant computational
cost. Together, these contributions establish a validated workflow for creating
reliable learning-based navigation systems, marking a critical step towards
deploying autonomous robots in the final frontier.

</details>


### [24] [Swarm-in-Blocks: Simplifying Drone Swarm Programming with Block-Based Language](https://arxiv.org/abs/2508.11498)
*Agnes Bressan de Almeida,Joao Aires Correa Fernandes Marsicano*

Main category: cs.RO

TL;DR: Swarm in Blocks 2.0是一个基于块编程的高阶接口，简化了无人机群编程，适用于教育和实际应用。


<details>
  <summary>Details</summary>
Motivation: 随着无人机群在配送、农业和监控等领域的应用增加，管理复杂性也随之上升，特别是对初学者。Atena团队开发此工具以降低ROS和编程知识门槛。

Method: 基于Clover平台，使用块编程语言创建功能（如循环和条件结构），并通过组装代码块实现群控。

Result: Swarm in Blocks 2.0进一步优化了平台，使其更用户友好，同时扩展了编程教育的机会。

Conclusion: 该工具通过块编程简化了无人机群管理，为非专业用户提供了便捷的解决方案，并促进了编程教育。

Abstract: Swarm in Blocks, originally developed for CopterHack 2022, is a high-level
interface that simplifies drone swarm programming using a block-based language.
Building on the Clover platform, this tool enables users to create
functionalities like loops and conditional structures by assembling code
blocks. In 2023, we introduced Swarm in Blocks 2.0, further refining the
platform to address the complexities of swarm management in a user-friendly
way. As drone swarm applications grow in areas like delivery, agriculture, and
surveillance, the challenge of managing them, especially for beginners, has
also increased. The Atena team developed this interface to make swarm handling
accessible without requiring extensive knowledge of ROS or programming. The
block-based approach not only simplifies swarm control but also expands
educational opportunities in programming.

</details>


### [25] [Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks](https://arxiv.org/abs/2508.11584)
*Jakub Łucki,Jonathan Becktor,Georgios Georgakis,Robert Royce,Shehryar Khattak*

Main category: cs.RO

TL;DR: VPEngine是一个模块化框架，通过共享基础模型和多任务并行处理，提升资源受限机器人平台上的视觉多任务效率，实现3倍加速。


<details>
  <summary>Details</summary>
Motivation: 解决多模型部署在资源受限机器人平台上导致的冗余计算、内存占用大和集成复杂的问题。

Method: 利用共享基础模型提取图像表征，并行运行多个任务专用模型头，避免GPU-CPU内存传输，支持动态任务优先级调整。

Result: 使用DINOv2作为基础模型，在深度、目标检测和语义分割任务上实现3倍加速，并在NVIDIA Jetson Orin AGX上达到≥50 Hz的实时性能。

Conclusion: VPEngine通过高效GPU利用和动态任务管理，为机器人视觉多任务提供了可扩展且易用的解决方案。

Abstract: Deploying multiple machine learning models on resource-constrained robotic
platforms for different perception tasks often results in redundant
computations, large memory footprints, and complex integration challenges. In
response, this work presents Visual Perception Engine (VPEngine), a modular
framework designed to enable efficient GPU usage for visual multitasking while
maintaining extensibility and developer accessibility. Our framework
architecture leverages a shared foundation model backbone that extracts image
representations, which are efficiently shared, without any unnecessary GPU-CPU
memory transfers, across multiple specialized task-specific model heads running
in parallel. This design eliminates the computational redundancy inherent in
feature extraction component when deploying traditional sequential models while
enabling dynamic task prioritization based on application demands. We
demonstrate our framework's capabilities through an example implementation
using DINOv2 as the foundation model with multiple task (depth, object
detection and semantic segmentation) heads, achieving up to 3x speedup compared
to sequential execution. Building on CUDA Multi-Process Service (MPS), VPEngine
offers efficient GPU utilization and maintains a constant memory footprint
while allowing per-task inference frequencies to be adjusted dynamically during
runtime. The framework is written in Python and is open source with ROS2 C++
(Humble) bindings for ease of use by the robotics community across diverse
robotic platforms. Our example implementation demonstrates end-to-end real-time
performance at $\geq$50 Hz on NVIDIA Jetson Orin AGX for TensorRT optimized
models.

</details>


### [26] [A Comparative Study of Floating-Base Space Parameterizations for Agile Whole-Body Motion Planning](https://arxiv.org/abs/2508.11520)
*Evangelos Tsiatsianas,Chairi Kiourt,Konstantinos Chatzilygeroudis*

Main category: cs.RO

TL;DR: 本文比较了不同浮基空间参数化方法在腿式系统敏捷运动轨迹优化中的性能，并提出了一种基于SE(3)切空间的新方法。


<details>
  <summary>Details</summary>
Motivation: 解决腿式和人形机器人生成敏捷全身运动的挑战，尤其是浮基空间参数化选择对性能的影响。

Method: 通过直接转录轨迹优化，系统比较多种常见参数化方法，并提出基于SE(3)切空间的新参数化方法。

Result: 新方法无需专用流形优化技术，可直接使用成熟数值求解器，为敏捷运动生成提供了有效选择。

Conclusion: 研究为选择浮基表示提供了实用指导，新方法在性能和易用性上具有优势。

Abstract: Automatically generating agile whole-body motions for legged and humanoid
robots remains a fundamental challenge in robotics. While numerous trajectory
optimization approaches have been proposed, there is no clear guideline on how
the choice of floating-base space parameterization affects performance,
especially for agile behaviors involving complex contact dynamics. In this
paper, we present a comparative study of different parameterizations for direct
transcription-based trajectory optimization of agile motions in legged systems.
We systematically evaluate several common choices under identical optimization
settings to ensure a fair comparison. Furthermore, we introduce a novel
formulation based on the tangent space of SE(3) for representing the robot's
floating-base pose, which, to our knowledge, has not received attention from
the literature. This approach enables the use of mature off-the-shelf numerical
solvers without requiring specialized manifold optimization techniques. We hope
that our experiments and analysis will provide meaningful insights for
selecting the appropriate floating-based representation for agile whole-body
motion generation.

</details>


### [27] [MultiPark: Multimodal Parking Transformer with Next-Segment Prediction](https://arxiv.org/abs/2508.11537)
*Han Zheng,Zikang Zhou,Guli Zhang,Zhepei Wang,Kaixuan Wang,Peiliang Li,Shaojie Shen,Ming Yang,Tong Qin*

Main category: cs.RO

TL;DR: 论文提出MultiPark，一种基于自回归变换器的多模态停车方法，解决了现有模仿学习在停车任务中的多模态行为和因果混淆问题。


<details>
  <summary>Details</summary>
Motivation: 停车在高度受限空间中的准确性和安全性是重要挑战，现有模仿学习方法忽略了停车行为的多模态特性，且难以泛化到多样化场景。

Method: 采用数据高效的下一段预测范式处理急转弯路径，设计可学习的停车查询分解为档位、纵向和横向组件，并行解码多种停车行为，并使用目标中心位姿和自中心碰撞作为损失。

Result: 在真实数据集上评估显示MultiPark达到最先进性能，并在实际车辆部署中验证了其鲁棒性。

Conclusion: MultiPark通过多模态建模和因果混淆缓解，显著提升了停车任务的性能和泛化能力。

Abstract: Parking accurately and safely in highly constrained spaces remains a critical
challenge. Unlike structured driving environments, parking requires executing
complex maneuvers such as frequent gear shifts and steering saturation. Recent
attempts to employ imitation learning (IL) for parking have achieved promising
results. However, existing works ignore the multimodal nature of parking
behavior in lane-free open space, failing to derive multiple plausible
solutions under the same situation. Notably, IL-based methods encompass
inherent causal confusion, so enabling a neural network to generalize across
diverse parking scenarios is particularly difficult. To address these
challenges, we propose MultiPark, an autoregressive transformer for multimodal
parking. To handle paths filled with abrupt turning points, we introduce a
data-efficient next-segment prediction paradigm, enabling spatial
generalization and temporal extrapolation. Furthermore, we design learnable
parking queries factorized into gear, longitudinal, and lateral components,
parallelly decoding diverse parking behaviors. To mitigate causal confusion in
IL, our method employs target-centric pose and ego-centric collision as
outcome-oriented loss across all modalities beyond pure imitation loss.
Evaluations on real-world datasets demonstrate that MultiPark achieves
state-of-the-art performance across various scenarios. We deploy MultiPark on a
production vehicle, further confirming our approach's robustness in real-world
parking environments.

</details>


### [28] [Towards Fully Onboard State Estimation and Trajectory Tracking for UAVs with Suspended Payloads](https://arxiv.org/abs/2508.11547)
*Martin Jiroušek,Tomáš Báča,Martin Saska*

Main category: cs.RO

TL;DR: 提出一种仅使用无人机标准传感器（RTK-GNSS和IMU）的框架，用于估计和控制悬挂载荷的位置，无需额外硬件。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖复杂硬件（如运动捕捉系统或额外摄像头）的问题，实现低成本、易部署的载荷跟踪方案。

Method: 结合线性卡尔曼滤波、模型预测轮廓控制规划和增量模型预测控制器，建模无人机与载荷的耦合动力学。

Result: 仿真显示性能接近基于真实测量的控制（仅下降<6%），且对载荷参数变化鲁棒性强；户外实验验证了实用性。

Conclusion: 该框架在仅使用现成硬件的情况下，实现了高效、可靠的载荷位置控制，适用于实际部署。

Abstract: This paper addresses the problem of tracking the position of a
cable-suspended payload carried by an unmanned aerial vehicle, with a focus on
real-world deployment and minimal hardware requirements. In contrast to many
existing approaches that rely on motion-capture systems, additional onboard
cameras, or instrumented payloads, we propose a framework that uses only
standard onboard sensors--specifically, real-time kinematic global navigation
satellite system measurements and data from the onboard inertial measurement
unit--to estimate and control the payload's position. The system models the
full coupled dynamics of the aerial vehicle and payload, and integrates a
linear Kalman filter for state estimation, a model predictive contouring
control planner, and an incremental model predictive controller. The control
architecture is designed to remain effective despite sensing limitations and
estimation uncertainty. Extensive simulations demonstrate that the proposed
system achieves performance comparable to control based on ground-truth
measurements, with only minor degradation (< 6%). The system also shows strong
robustness to variations in payload parameters. Field experiments further
validate the framework, confirming its practical applicability and reliable
performance in outdoor environments using only off-the-shelf aerial vehicle
hardware.

</details>


### [29] [Nominal Evaluation Of Automatic Multi-Sections Control Potential In Comparison To A Simpler One- Or Two-Sections Alternative With Predictive Spray Switching](https://arxiv.org/abs/2508.11573)
*Mogens Plessen*

Main category: cs.RO

TL;DR: 论文比较了自动多段控制与更简单的一或两段预测喷雾切换方法，提出了一种低成本、无传感器的优选方案。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索在复杂农业喷雾场景中是否存在比传统自动分段控制更简单的替代方法。

Method: 比较了三种分段设置（48段、2段和单段控制）以及两种路径规划和喷雾切换逻辑，并在10个实际农田案例中评估。

Result: 优选方法在路径长度、重叠控制和成本效益上表现更佳，且无需传感器。

Conclusion: 提出了一种低成本、无传感器的喷雾控制方法，适用于手动驾驶，并在复杂农田条件下表现良好。

Abstract: Automatic Section Control (ASC) is a long-standing trend for spraying in
agriculture. It promises to minimise spray overlap areas. The core idea is to
(i) switch off spray nozzles on areas that have already been sprayed, and (ii)
to dynamically adjust nozzle flow rates along the boom bar that holds the spray
nozzles when velocities of boom sections vary during turn maneuvers. ASC is not
possible without sensors, in particular for accurate positioning data. Spraying
and the movement of modern wide boom bars are highly dynamic processes. In
addition, many uncertainty factors have an effect such as cross wind drift,
boom height, nozzle clogging in open-field conditions, and so forth. In view of
this complexity, the natural question arises if a simpler alternative exist.
Therefore, an Automatic Multi-Sections Control method is compared to a proposed
simpler one- or two-sections alternative that uses predictive spray switching.
The comparison is provided under nominal conditions. Agricultural spraying is
intrinsically linked to area coverage path planning and spray switching logic.
Combinations of two area coverage path planning and switching logics as well as
three sections-setups are compared. The three sections-setups differ by
controlling 48 sections, 2 sections or controlling all nozzles uniformly with
the same control signal as one single section. Methods are evaluated on 10
diverse real-world field examples, including non-convex field contours,
freeform mainfield lanes and multiple obstacle areas. A preferred method is
suggested that (i) minimises area coverage pathlength, (ii) offers intermediate
overlap, (iii) is suitable for manual driving by following a pre-planned
predictive spray switching logic for an area coverage path plan, and (iv) and
in contrast to ASC can be implemented sensor-free and therefore at low cost.

</details>


### [30] [Investigating Sensors and Methods in Grasp State Classification in Agricultural Manipulation](https://arxiv.org/abs/2508.11588)
*Benjamin Walt,Jordan Westphal,Girish Krishnan*

Main category: cs.RO

TL;DR: 该研究探讨了农业抓取状态的准确识别，通过集成多种传感器和分类模型，实现了高效的水果采摘。


<details>
  <summary>Details</summary>
Motivation: 农业环境的复杂性和遮挡问题使得抓取状态识别具有挑战性，需要可靠的传感器和建模技术。

Method: 研究结合了IMU、红外反射、张力、触觉传感器和RGB相机，并使用随机森林和LSTM模型进行分类。

Result: 随机森林模型在实验室和实际樱桃番茄植株测试中实现了100%的准确率，优于基线性能。

Conclusion: IMU和张力传感器的组合能够有效分类抓取状态，提升采摘效率和可靠性。

Abstract: Effective and efficient agricultural manipulation and harvesting depend on
accurately understanding the current state of the grasp. The agricultural
environment presents unique challenges due to its complexity, clutter, and
occlusion. Additionally, fruit is physically attached to the plant, requiring
precise separation during harvesting. Selecting appropriate sensors and
modeling techniques is critical for obtaining reliable feedback and correctly
identifying grasp states. This work investigates a set of key sensors, namely
inertial measurement units (IMUs), infrared (IR) reflectance, tension, tactile
sensors, and RGB cameras, integrated into a compliant gripper to classify grasp
states. We evaluate the individual contribution of each sensor and compare the
performance of two widely used classification models: Random Forest and Long
Short-Term Memory (LSTM) networks. Our results demonstrate that a Random Forest
classifier, trained in a controlled lab environment and tested on real cherry
tomato plants, achieved 100% accuracy in identifying slip, grasp failure, and
successful picks, marking a substantial improvement over baseline performance.
Furthermore, we identify a minimal viable sensor combination, namely IMU and
tension sensors that effectively classifies grasp states. This classifier
enables the planning of corrective actions based on real-time feedback, thereby
enhancing the efficiency and reliability of fruit harvesting operations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [31] [Grounding Rule-Based Argumentation Using Datalog](https://arxiv.org/abs/2508.10976)
*Martin Diller,Sarah Alice Gaggl,Philipp Hanisch,Giuseppina Monterosso,Fritz Rauschenbach*

Main category: cs.AI

TL;DR: ASPIC+框架缺乏针对一阶规则的高效推理方法，本文提出了一种智能基础化方法，通过Datalog转换和简化技术，解决了基础化规模爆炸问题，并验证了其可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有ASPIC+框架主要支持命题规则，一阶规则推理需要基础化步骤，但基础化可能导致理论规模指数增长，缺乏高效解决方案。

Method: 将一阶ASPIC+实例转换为Datalog程序，利用Datalog引擎获取基础化替换，并提出ASPIC+特有的简化技术避免无效规则基础化。

Result: 通过原型实现的实证评估，验证了该方法在保持推理正确性的同时，能够有效管理基础化规模。

Conclusion: 提出的智能基础化方法解决了ASPIC+框架中一阶规则推理的规模问题，具有实际应用潜力。

Abstract: ASPIC+ is one of the main general frameworks for rule-based argumentation for
AI. Although first-order rules are commonly used in ASPIC+ examples, most
existing approaches to reason over rule-based argumentation only support
propositional rules. To enable reasoning over first-order instances, a
preliminary grounding step is required. As groundings can lead to an
exponential increase in the size of the input theories, intelligent procedures
are needed. However, there is a lack of dedicated solutions for ASPIC+.
Therefore, we propose an intelligent grounding procedure that keeps the size of
the grounding manageable while preserving the correctness of the reasoning
process. To this end, we translate the first-order ASPIC+ instance into a
Datalog program and query a Datalog engine to obtain ground substitutions to
perform the grounding of rules and contraries. Additionally, we propose
simplifications specific to the ASPIC+ formalism to avoid grounding of rules
that have no influence on the reasoning process. Finally, we performed an
empirical evaluation of a prototypical implementation to show scalability.

</details>


### [32] [From Individual to Multi-Agent Algorithmic Recourse: Minimizing the Welfare Gap via Capacitated Bipartite Matching](https://arxiv.org/abs/2508.11070)
*Zahra Khotanlou,Kate Larson,Amir-Hossein Karimi*

Main category: cs.AI

TL;DR: 论文提出了一种多主体算法追索框架，解决现有研究中单主体和单模型场景的局限性，通过加权二分图匹配优化社会福祉。


<details>
  <summary>Details</summary>
Motivation: 现实世界中，多个追索寻求者和提供者之间的互动未被现有研究充分解决，需要一种系统级设计来优化社会福祉。

Method: 采用三层优化框架：基础容量匹配、最优容量再分配和成本感知优化，通过加权二分图建模多主体互动。

Result: 实验验证表明，该框架能在系统设置最小修改下实现接近最优的社会福祉。

Conclusion: 该研究将算法追索从个体推荐扩展到系统级设计，为社会福祉和个体可操作性提供了可行路径。

Abstract: Decision makers are increasingly relying on machine learning in sensitive
situations. In such settings, algorithmic recourse aims to provide individuals
with actionable and minimally costly steps to reverse unfavorable AI-driven
decisions. While existing research predominantly focuses on single-individual
(i.e., seeker) and single-model (i.e., provider) scenarios, real-world
applications often involve multiple interacting stakeholders. Optimizing
outcomes for seekers under an individual welfare approach overlooks the
inherently multi-agent nature of real-world systems, where individuals interact
and compete for limited resources. To address this, we introduce a novel
framework for multi-agent algorithmic recourse that accounts for multiple
recourse seekers and recourse providers. We model this many-to-many interaction
as a capacitated weighted bipartite matching problem, where matches are guided
by both recourse cost and provider capacity. Edge weights, reflecting recourse
costs, are optimized for social welfare while quantifying the welfare gap
between individual welfare and this collectively feasible outcome. We propose a
three-layer optimization framework: (1) basic capacitated matching, (2) optimal
capacity redistribution to minimize the welfare gap, and (3) cost-aware
optimization balancing welfare maximization with capacity adjustment costs.
Experimental validation on synthetic and real-world datasets demonstrates that
our framework enables the many-to-many algorithmic recourse to achieve
near-optimal welfare with minimum modification in system settings. This work
extends algorithmic recourse from individual recommendations to system-level
design, providing a tractable path toward higher social welfare while
maintaining individual actionability.

</details>


### [33] [Learn to optimize for automatic proton PBS treatment planning for H&N cancers](https://arxiv.org/abs/2508.11085)
*Qingqing Wang,Liqiang Xiao,Chang Chang*

Main category: cs.AI

TL;DR: 提出了一种基于数据驱动的逆优化器和PPO框架的自动治疗计划方法，显著提升了头颈癌质子PBS治疗计划的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 头颈癌质子PBS治疗计划中，多目标冲突和计算密集型逆优化问题导致计划制定耗时且依赖经验。

Method: 结合L2O逆优化器和PPO框架，利用Transformer处理长上下文，自动调整目标参数并生成高质量计划。

Result: 相比L-BFGSB，L2O逆优化器效率提升36.41%，有效性提升22.97%，计划时间平均2.55小时。

Conclusion: 该方法在临床可接受时间内生成优于或等同于人工计划的治疗计划，适用于多种复杂情况。

Abstract: Proton PBS treatment planning for H&N cancers involves numerous conflicting
objectives, requiring significant effort from human planners to balance and
satisfy multiple clinical goals during planning. To achieve this,
experience-demanding objective parameter adjustment and computationally
expensive inverse optimization are performed iteratively. Extensive efforts
have been made to automatically adjust objective parameters, but the most
time-consuming component, i.e., inverse optimization, still relies heavily on
theory-driven approaches. We propose a data-driven inverse optimizer and
integrate it into a PPO-based automatic treatment planning framework to
automatically generate high-quality plans within a clinical acceptable planning
time. The inverse optimizer is a L2O method that predicts update steps by
learning from the task-specific data distribution. For the first time, we
integrate techniques designed for long-context processing, originally developed
for LLMs, into a Transformer-based L2O framework to address the scalability
issue of existing L2O methods. The PPO framework functions as an outer-loop
virtual planner, autonomously adjusting objective parameters through a policy
network, and the dose predictor is used to initialize objective parameters. The
inner-loop L2O inverse optimizer computes machine-deliverable MU values based
on objectives refined by the PPO policy network. 97 patients are collected in
this study, and compared with L-BFGSB, our L2O-based inverse optimizer improves
the effectiveness and efficiency by 22.97% and 36.41%, respectively. In
conjunction with the PPO-based learned virtual planner, plans generated by our
framework within an average of 2.55 hours show improved or comparable OAR
sparing with superior target coverage for patients with different prescription
dose levels, number of target volumes, beam angles, etc., compared with
human-generated plans.

</details>


### [34] [On Strong and Weak Admissibility in Non-Flat Assumption-Based Argumentation](https://arxiv.org/abs/2508.11182)
*Matti Berthold,Lydia Blümel,Anna Rapberger*

Main category: cs.AI

TL;DR: 本文扩展了基于假设的论证（ABA）中可接受性概念的研究，探讨了强可接受性和弱可接受性两种替代标准，并引入了相应的优先、完备和基础语义。通过抽象双极集合论证框架（BSAFs）作为形式工具，研究了非平坦ABA框架的性质。


<details>
  <summary>Details</summary>
Motivation: 研究ABA中标准可接受性之外的替代概念（强和弱可接受性），以填补强可接受性在ABA中未被研究的空白，并扩展弱可接受性在非平坦ABA中的应用。

Method: 使用BSAFs作为形式工具，分析强和弱可接受性在非平坦ABA中的性质，并验证其模块化特性。

Result: 证明了强和弱可接受性在非平坦ABA中保持了模块化特性，但也揭示了其与标准可接受性类似的局限性。

Conclusion: 强和弱可接受性在非平坦ABA中具有研究价值，但仍需进一步解决其局限性。

Abstract: In this work, we broaden the investigation of admissibility notions in the
context of assumption-based argumentation (ABA). More specifically, we study
two prominent alternatives to the standard notion of admissibility from
abstract argumentation, namely strong and weak admissibility, and introduce the
respective preferred, complete and grounded semantics for general (sometimes
called non-flat) ABA. To do so, we use abstract bipolar set-based argumentation
frameworks (BSAFs) as formal playground since they concisely capture the
relations between assumptions and are expressive enough to represent general
non-flat ABA frameworks, as recently shown. While weak admissibility has been
recently investigated for a restricted fragment of ABA in which assumptions
cannot be derived (flat ABA), strong admissibility has not been investigated
for ABA so far. We introduce strong admissibility for ABA and investigate
desirable properties. We furthermore extend the recent investigations of weak
admissibility in the flat ABA fragment to the non-flat case. We show that the
central modularization property is maintained under classical, strong, and weak
admissibility. We also show that strong and weakly admissible semantics in
non-flat ABA share some of the shortcomings of standard admissible semantics
and discuss ways to address these.

</details>


### [35] [Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information](https://arxiv.org/abs/2508.11252)
*Youcheng Huang,Bowen Qin,Chen Huang,Duanyu Feng,Xi Yang,Wenqiang Lei*

Main category: cs.AI

TL;DR: 论文提出新数据集评估大型推理模型（LRMs）在不完整问题中的表现，发现其无法主动请求信息，并揭示其过度思考和幻觉行为。


<details>
  <summary>Details</summary>
Motivation: 现有评估仅关注定义明确的问题，而真正的智能代理应能主动请求补充信息。

Method: 构建包含不完整问题的新数据集，系统评估LRMs表现。

Result: LRMs无法主动请求信息，存在过度思考和幻觉问题。

Conclusion: 监督微调有潜力但具挑战，需开发真正智能的LRMs。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable problem-solving
abilities in mathematics, as evaluated by existing benchmarks exclusively on
well-defined problems. However, such evaluation setup constitutes a critical
gap, since a genuine intelligent agent should not only solve problems (as a
math quiz solver), but also be able~to ask for information when the problems
lack sufficient information, enabling proactivity in responding users'
requests. To bridge such gap, we proposes a new dataset consisting of two types
of incomplete problems with diverse contexts. Based on the dataset, our
systematical evaluation of LRMs reveals their inability in proactively asking
for information. In addition, we uncover the behaviors related to overthinking
and hallucination of LRMs, and highlight the potential and challenges of
supervised fine-tuning in learning such ability. We hope to provide new
insights in developing LRMs with genuine intelligence, rather than just solving
problems.

</details>


### [36] [SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding](https://arxiv.org/abs/2508.11347)
*Yifei Li,Lingling Zhang,Hang Yan,Tianzhe Zhao,Zihan Ma,Muye Huang,Jun Liu*

Main category: cs.AI

TL;DR: SAGE提出了一种动态知识图谱嵌入框架，通过自适应维度扩展和动态蒸馏机制，显著提升了动态知识图谱的嵌入性能。


<details>
  <summary>Details</summary>
Motivation: 现实中的知识图谱是动态演化的，现有方法未能充分考虑更新规模差异和系统评估需求。

Method: SAGE根据更新规模确定嵌入维度并扩展空间，采用动态蒸馏机制平衡新旧知识。

Result: 在七个基准测试中，SAGE在MRR、H@1和H@10上分别提升1.38%、1.25%和1.6%。

Conclusion: SAGE证明了自适应嵌入维度在动态知识图谱嵌入中的重要性，性能优于固定维度方法。

Abstract: Traditional knowledge graph (KG) embedding methods aim to represent entities
and relations in a low-dimensional space, primarily focusing on static graphs.
However, real-world KGs are dynamically evolving with the constant addition of
entities, relations and facts. To address such dynamic nature of KGs, several
continual knowledge graph embedding (CKGE) methods have been developed to
efficiently update KG embeddings to accommodate new facts while maintaining
learned knowledge. As KGs grow at different rates and scales in real-world
scenarios, existing CKGE methods often fail to consider the varying scales of
updates and lack systematic evaluation throughout the entire update process. In
this paper, we propose SAGE, a scale-aware gradual evolution framework for
CKGE. Specifically, SAGE firstly determine the embedding dimensions based on
the update scales and expand the embedding space accordingly. The Dynamic
Distillation mechanism is further employed to balance the preservation of
learned knowledge and the incorporation of new facts. We conduct extensive
experiments on seven benchmarks, and the results show that SAGE consistently
outperforms existing baselines, with a notable improvement of 1.38% in MRR,
1.25% in H@1 and 1.6% in H@10. Furthermore, experiments comparing SAGE with
methods using fixed embedding dimensions show that SAGE achieves optimal
performance on every snapshot, demonstrating the importance of adaptive
embedding dimensions in CKGE. The codes of SAGE are publicly available at:
https://github.com/lyfxjtu/Dynamic-Embedding.

</details>


### [37] [CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks](https://arxiv.org/abs/2508.11360)
*Songqin Nong,Jingxuan Xu,Sheng Zhou,Jianfeng Chen,Xiaoxuan Tang,Tao Jiang,Wenhao Xu*

Main category: cs.AI

TL;DR: 提出CRAFT-GUI框架，通过课程学习和细粒度奖励设计，解决GUI任务中RL方法的局限性，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在GUI任务中忽视任务难度差异和奖励信号单一化，导致学习效率低下。

Method: 基于GRPO的课程学习框架，结合规则和模型评估的细粒度奖励函数。

Result: 在Android Control和内部基准上分别提升5.6%和10.3%。

Conclusion: 课程学习与RL结合在GUI任务中有效，显著优于现有方法。

Abstract: As autonomous agents become adept at understanding and interacting with
graphical user interface (GUI) environments, a new era of automated task
execution is emerging. Recent studies have demonstrated that Reinforcement
Learning (RL) can effectively enhance agents' performance in dynamic
interactive GUI environments. However, these methods face two key limitations:
(1) they overlook the significant variation in difficulty across different GUI
tasks by treating the entire training data as a uniform set, which hampers the
agent's ability to adapt its learning process; and (2) most approaches collapse
task-specific nuances into a single, coarse reward, leaving the agent with a
uniform signal that yields inefficient policy updates. To address these
limitations, we propose CRAFT-GUI, a curriculum learning framework based on
Group Relative Policy Optimization (GRPO) that explicitly accounts for the
varying difficulty across trajectories. To enable more fine-grained policy
optimization, we design a reward function that combines simple rule-based
signals with model-judged evaluation, providing richer and more nuanced
feedback during training. Experimental results demonstrate that our method
achieves significant improvements over previous state-of-the-art approaches,
outperforming them by 5.6% on public benchmarks Android Control and 10.3% on
our internal online benchmarks, respectively. These findings empirically
validate the effectiveness of integrating reinforcement learning with
curriculum learning in GUI interaction tasks.

</details>


### [38] [AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager](https://arxiv.org/abs/2508.11416)
*Xuhua Zhao,Yuxuan Xie,Caihua Chen,Yuxiang Sun*

Main category: cs.AI

TL;DR: 论文提出AIM-Bench基准，评估LLM代理在不确定供应链管理中的决策行为，发现其存在类似人类的决策偏差，并探讨缓解策略。


<details>
  <summary>Details</summary>
Motivation: 研究LLM代理在库存决策中的能力和潜在偏差，填补其在不确定环境下决策行为的研究空白。

Method: 通过AIM-Bench基准，设计多样化的库存补充实验，评估LLM代理的决策行为，并尝试缓解偏差的策略。

Result: 不同LLM表现出类似人类的决策偏差，提出认知反思和信息共享作为缓解策略。

Conclusion: 需谨慎考虑LLM在库存决策中的潜在偏差，研究为减少人类决策偏差和开发人本决策支持系统提供方向。

Abstract: Recent advances in mathematical reasoning and the long-term planning
capabilities of large language models (LLMs) have precipitated the development
of agents, which are being increasingly leveraged in business operations
processes. Decision models to optimize inventory levels are one of the core
elements of operations management. However, the capabilities of the LLM agent
in making inventory decisions in uncertain contexts, as well as the
decision-making biases (e.g. framing effect, etc.) of the agent, remain largely
unexplored. This prompts concerns regarding the capacity of LLM agents to
effectively address real-world problems, as well as the potential implications
of biases that may be present. To address this gap, we introduce AIM-Bench, a
novel benchmark designed to assess the decision-making behaviour of LLM agents
in uncertain supply chain management scenarios through a diverse series of
inventory replenishment experiments. Our results reveal that different LLMs
typically exhibit varying degrees of decision bias that are similar to those
observed in human beings. In addition, we explored strategies to mitigate the
pull-to-centre effect and the bullwhip effect, namely cognitive reflection and
implementation of information sharing. These findings underscore the need for
careful consideration of the potential biases in deploying LLMs in Inventory
decision-making scenarios. We hope that these insights will pave the way for
mitigating human decision bias and developing human-centred decision support
systems for supply chains.

</details>


### [39] [Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps](https://arxiv.org/abs/2508.11452)
*Kangyu Wang,Hongliang He,Lin Liu,Ruiqi Liang,Zhenzhong Lan,Jianguo Li*

Main category: cs.AI

TL;DR: Inclusion Arena是一个实时排行榜，通过用户反馈评估LLMs和MLLMs在实际应用中的表现，采用Bradley-Terry模型和两项创新技术（Placement Matches和Proximity Sampling）提升排名稳定性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试和排行榜依赖静态数据集或通用领域提示，无法反映模型在实际应用中的表现，因此需要一种更贴近实际使用场景的评估方法。

Method: 平台通过自然用户交互收集反馈，采用Bradley-Terry模型，并结合Placement Matches（冷启动机制）和Proximity Sampling（智能对比策略）优化排名。

Result: Inclusion Arena提供稳定可靠的排名，数据传递性优于众包数据集，并能有效减少恶意操纵风险。

Conclusion: Inclusion Arena通过连接基础模型和实际应用，加速开发更贴近用户需求的LLMs和MLLMs。

Abstract: Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)
have ushered in a new era of AI capabilities, demonstrating near-human-level
performance across diverse scenarios. While numerous benchmarks (e.g., MMLU)
and leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the
development of LLMs and MLLMs, most rely on static datasets or crowdsourced
general-domain prompts, often falling short of reflecting performance in
real-world applications. To bridge this critical gap, we present Inclusion
Arena, a live leaderboard that ranks models based on human feedback collected
directly from AI-powered applications. Our platform integrates pairwise model
comparisons into natural user interactions, ensuring evaluations reflect
practical usage scenarios. For robust model ranking, we employ the
Bradley-Terry model augmented with two key innovations: (1) Placement Matches,
a cold-start mechanism to quickly estimate initial ratings for newly integrated
models, and (2) Proximity Sampling, an intelligent comparison strategy that
prioritizes battles between models of similar capabilities to maximize
information gain and enhance rating stability. Extensive empirical analyses and
simulations demonstrate that Inclusion Arena yields reliable and stable
rankings, exhibits higher data transitivity compared to general crowdsourced
datasets, and significantly mitigates the risk of malicious manipulation. By
fostering an open alliance between foundation models and real-world
applications, Inclusion Arena aims to accelerate the development of LLMs and
MLLMs truly optimized for practical, user-centric deployments. The platform is
publicly accessible at https://doraemon.alipay.com/model-ranking.

</details>


### [40] [Landmark-Assisted Monte Carlo Planning](https://arxiv.org/abs/2508.11493)
*David H. Chan,Mark Roberts,Dana S. Nau*

Main category: cs.AI

TL;DR: 论文提出了一种概率地标的概念，并将其应用于UCT算法以分解MDP问题，通过平衡地标达成与最终目标达成，显著提升了在线概率规划的性能。


<details>
  <summary>Details</summary>
Motivation: 地标在经典规划中已有显著贡献，但在随机领域应用较少。论文旨在探索地标在概率规划中的潜力。

Method: 形式化概率地标，并改进UCT算法，将其作为子目标分解MDP，核心在于平衡地标达成与最终目标达成。

Result: 在基准测试中，合适的地标选择显著提升了UCT算法的性能，但最佳平衡点因问题而异。

Conclusion: 地标可为解决MDP的即时算法提供有效指导。

Abstract: Landmarks$\unicode{x2013}$conditions that must be satisfied at some point in
every solution plan$\unicode{x2013}$have contributed to major advancements in
classical planning, but they have seldom been used in stochastic domains. We
formalize probabilistic landmarks and adapt the UCT algorithm to leverage them
as subgoals to decompose MDPs; core to the adaptation is balancing between
greedy landmark achievement and final goal achievement. Our results in
benchmark domains show that well-chosen landmarks can significantly improve the
performance of UCT in online probabilistic planning, while the best balance of
greedy versus long-term goal achievement is problem-dependent. The results
suggest that landmarks can provide helpful guidance for anytime algorithms
solving MDPs.

</details>


### [41] [Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models](https://arxiv.org/abs/2508.11524)
*Wenkai Yu,Jianhang Tang,Yang Zhang,Shanjiang Tang,Kebing Jin,Hankz Hankui Zhuo*

Main category: cs.AI

TL;DR: 本文提出了一种结合LLM与问题分解的新型规划器，通过LLM4Inspire和LLM4Predict两种范式辅助分解大规模规划问题，实验证明LLM4Predict在搜索空间剪枝中表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决大规模规划问题中的状态空间爆炸问题，并探索如何有效结合LLM与领域知识以生成有效计划。

Method: 提出LLM辅助规划器，通过问题分解将大问题拆分为子任务，并利用LLM4Inspire（通用知识启发）和LLM4Predict（领域知识推断）辅助分解。

Result: 实验验证了规划器的有效性，LLM4Predict在搜索空间剪枝中表现优于LLM4Inspire。

Conclusion: 结合领域知识的LLM（LLM4Predict）在大规模规划问题中更具潜力。

Abstract: Addressing large-scale planning problems has become one of the central
challenges in the planning community, deriving from the state-space explosion
caused by growing objects and actions. Recently, researchers have explored the
effectiveness of leveraging Large Language Models (LLMs) to generate helpful
actions and states to prune the search space. However, prior works have largely
overlooked integrating LLMs with domain-specific knowledge to ensure valid
plans. In this paper, we propose a novel LLM-assisted planner integrated with
problem decomposition, which first decomposes large planning problems into
multiple simpler sub-tasks. Then we explore two novel paradigms to utilize
LLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, where
LLM4Inspire provides heuristic guidance according to general knowledge and
LLM4Predict employs domain-specific knowledge to infer intermediate conditions.
We empirically validate the effectiveness of our planner across multiple
domains, demonstrating the ability of search space partition when solving
large-scale planning problems. The experimental results show that LLMs
effectively locate feasible solutions when pruning the search space, where
infusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holds
particular promise compared with LLM4Inspire, which offers general knowledge
within LLMs.

</details>
