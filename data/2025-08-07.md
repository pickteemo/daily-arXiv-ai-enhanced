<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 31]
- [cs.RO](#cs.RO) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems](https://arxiv.org/abs/2508.03858)
*Charles L. Wang,Trisha Singhal,Ameya Kelkar,Jason Tuo*

Main category: cs.AI

TL;DR: MI9是首个专为代理型AI系统设计的运行时治理框架，通过六项集成组件解决传统治理方法无法应对的新型风险。


<details>
  <summary>Details</summary>
Motivation: 代理型AI系统在运行时表现出不可预测的行为，传统治理方法无法完全覆盖这些风险，亟需新的治理框架。

Method: MI9框架包含六项实时控制组件：代理风险指数、代理语义遥测捕获、持续授权监控、基于有限状态机的符合性引擎、目标条件漂移检测和分级遏制策略。

Result: MI9在多样化场景中展示了系统性覆盖治理挑战的能力，为代理型AI的安全部署提供了技术基础。

Conclusion: MI9为代理型AI的大规模安全部署提供了首个全面运行时治理框架，填补了传统治理方法的空白。

Abstract: Agentic AI systems capable of reasoning, planning, and executing actions
present fundamentally distinct governance challenges compared to traditional AI
models. Unlike conventional AI, these systems exhibit emergent and unexpected
behaviors during runtime, introducing novel agent-related risks that cannot be
fully anticipated through pre-deployment governance alone. To address this
critical gap, we introduce MI9, the first fully integrated runtime governance
framework designed specifically for safety and alignment of agentic AI systems.
MI9 introduces real-time controls through six integrated components:
agency-risk index, agent-semantic telemetry capture, continuous authorization
monitoring, Finite-State-Machine (FSM)-based conformance engines,
goal-conditioned drift detection, and graduated containment strategies.
Operating transparently across heterogeneous agent architectures, MI9 enables
the systematic, safe, and responsible deployment of agentic systems in
production environments where conventional governance approaches fall short,
providing the foundational infrastructure for safe agentic AI deployment at
scale. Detailed analysis through a diverse set of scenarios demonstrates MI9's
systematic coverage of governance challenges that existing approaches fail to
address, establishing the technical foundation for comprehensive agentic AI
oversight.

</details>


### [2] [Evo-MARL: Co-Evolutionary Multi-Agent Reinforcement Learning for Internalized Safety](https://arxiv.org/abs/2508.03864)
*Zhenyu Pan,Yiting Zhang,Yutong Zhang,Jianshu Zhang,Haozheng Luo,Yuwei Han,Dennis Wu,Hong-Yu Chen,Philip S. Yu,Manling Li,Han Liu*

Main category: cs.AI

TL;DR: Evo-MARL是一种多智能体强化学习框架，通过联合训练任务智能体获得防御能力，避免依赖外部安全模块，提升系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统（MAS）在开放性和交互复杂性增加时面临安全风险，现有防御方法依赖外部模块，存在单点故障和成本问题。

Method: 提出Evo-MARL框架，通过多智能体强化学习训练每个智能体同时执行任务和防御，结合进化搜索和参数共享强化学习进行对抗训练。

Result: 实验显示，Evo-MARL将攻击成功率降低22%，推理任务准确率提升5%，安全性和实用性同时提高。

Conclusion: Evo-MARL通过内部化安全机制和对抗训练，有效提升多智能体系统的安全性和性能。

Abstract: Multi-agent systems (MAS) built on multimodal large language models exhibit
strong collaboration and performance. However, their growing openness and
interaction complexity pose serious risks, notably jailbreak and adversarial
attacks. Existing defenses typically rely on external guard modules, such as
dedicated safety agents, to handle unsafe behaviors. Unfortunately, this
paradigm faces two challenges: (1) standalone agents offer limited protection,
and (2) their independence leads to single-point failure-if compromised,
system-wide safety collapses. Naively increasing the number of guard agents
further raises cost and complexity. To address these challenges, we propose
Evo-MARL, a novel multi-agent reinforcement learning (MARL) framework that
enables all task agents to jointly acquire defensive capabilities. Rather than
relying on external safety modules, Evo-MARL trains each agent to
simultaneously perform its primary function and resist adversarial threats,
ensuring robustness without increasing system overhead or single-node failure.
Furthermore, Evo-MARL integrates evolutionary search with parameter-sharing
reinforcement learning to co-evolve attackers and defenders. This adversarial
training paradigm internalizes safety mechanisms and continually enhances MAS
performance under co-evolving threats. Experiments show that Evo-MARL reduces
attack success rates by up to 22% while boosting accuracy by up to 5% on
reasoning tasks-demonstrating that safety and utility can be jointly improved.

</details>


### [3] [MOTIF: Multi-strategy Optimization via Turn-based Interactive Framework](https://arxiv.org/abs/2508.03929)
*Nguyen Viet Tuan Kiet,Dao Van Tung,Tran Cong Dao,Huynh Thi Thanh Binh*

Main category: cs.AI

TL;DR: 论文提出了一种基于多策略优化的框架MOTIF，通过两个LLM代理的轮流交互优化组合优化问题的求解器设计。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只优化单一组件（如启发式评分函数），而忽略了多组件协同优化的潜力。

Method: 提出MOTIF框架，基于蒙特卡洛树搜索，通过两个LLM代理的轮流交互优化多个组件。

Result: 实验表明，MOTIF在多个组合优化领域优于现有方法。

Conclusion: MOTIF展示了基于多代理交互的自动化求解器设计的潜力。

Abstract: Designing effective algorithmic components remains a fundamental obstacle in
tackling NP-hard combinatorial optimization problems (COPs), where solvers
often rely on carefully hand-crafted strategies. Despite recent advances in
using large language models (LLMs) to synthesize high-quality components, most
approaches restrict the search to a single element - commonly a heuristic
scoring function - thus missing broader opportunities for innovation. In this
paper, we introduce a broader formulation of solver design as a multi-strategy
optimization problem, which seeks to jointly improve a set of interdependent
components under a unified objective. To address this, we propose
Multi-strategy Optimization via Turn-based Interactive Framework (MOTIF) - a
novel framework based on Monte Carlo Tree Search that facilitates turn-based
optimization between two LLM agents. At each turn, an agent improves one
component by leveraging the history of both its own and its opponent's prior
updates, promoting both competitive pressure and emergent cooperation. This
structured interaction broadens the search landscape and encourages the
discovery of diverse, high-performing solutions. Experiments across multiple
COP domains show that MOTIF consistently outperforms state-of-the-art methods,
highlighting the promise of turn-based, multi-agent prompting for fully
automated solver design.

</details>


### [4] [Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?](https://arxiv.org/abs/2508.03963)
*Zewen Liu,Juntong Ni,Xianfeng Tang,Max S. Y. Lau,Wei Jin*

Main category: cs.AI

TL;DR: SymbolBench是一个评估大语言模型在时间序列数据中符号推理能力的基准测试，涵盖多元符号回归、布尔网络推断和因果发现任务。


<details>
  <summary>Details</summary>
Motivation: 揭示时间序列数据中的隐藏符号规律是科学发现和人工智能的核心挑战，但目前大语言模型在这方面的能力尚未充分探索。

Method: 提出SymbolBench基准测试，并设计了一个结合大语言模型和遗传编程的闭环符号推理框架。

Result: 实验结果表明当前模型在符号推理上的优势和局限性，强调了结合领域知识、上下文对齐和推理结构的重要性。

Conclusion: 通过SymbolBench和提出的框架，为大语言模型在自动科学发现中的改进提供了方向。

Abstract: Uncovering hidden symbolic laws from time series data, as an aspiration
dating back to Kepler's discovery of planetary motion, remains a core challenge
in scientific discovery and artificial intelligence. While Large Language
Models show promise in structured reasoning tasks, their ability to infer
interpretable, context-aligned symbolic structures from time series data is
still underexplored. To systematically evaluate this capability, we introduce
SymbolBench, a comprehensive benchmark designed to assess symbolic reasoning
over real-world time series across three tasks: multivariate symbolic
regression, Boolean network inference, and causal discovery. Unlike prior
efforts limited to simple algebraic equations, SymbolBench spans a diverse set
of symbolic forms with varying complexity. We further propose a unified
framework that integrates LLMs with genetic programming to form a closed-loop
symbolic reasoning system, where LLMs act both as predictors and evaluators.
Our empirical results reveal key strengths and limitations of current models,
highlighting the importance of combining domain knowledge, context alignment,
and reasoning structure to improve LLMs in automated scientific discovery.

</details>


### [5] [The Emotional Baby Is Truly Deadly: Does your Multimodal Large Reasoning Model Have Emotional Flattery towards Humans?](https://arxiv.org/abs/2508.03986)
*Yuan Xun,Xiaojun Jia,Xinwei Liu,Hua Zhang*

Main category: cs.AI

TL;DR: 论文提出EmoAgent框架，通过情感提示劫持推理路径，揭示MLRMs在情感强度高时易忽视安全协议的问题，并引入三项指标量化风险。


<details>
  <summary>Details</summary>
Motivation: 发现面向人类服务的MLRMs在深度思考阶段易受用户情感影响，可能绕过安全协议，需研究其风险。

Method: 提出EmoAgent框架，通过情感提示操控推理路径，并设计RRSS、RVNR、RAIC三项指标评估风险。

Result: 实验证明EmoAgent有效，揭示了MLRMs在情感认知与安全行为间的深层错位。

Conclusion: 情感提示可显著影响MLRMs推理，现有安全措施需改进以应对情感驱动的风险。

Abstract: We observe that MLRMs oriented toward human-centric service are highly
susceptible to user emotional cues during the deep-thinking stage, often
overriding safety protocols or built-in safety checks under high emotional
intensity. Inspired by this key insight, we propose EmoAgent, an autonomous
adversarial emotion-agent framework that orchestrates exaggerated affective
prompts to hijack reasoning pathways. Even when visual risks are correctly
identified, models can still produce harmful completions through emotional
misalignment. We further identify persistent high-risk failure modes in
transparent deep-thinking scenarios, such as MLRMs generating harmful reasoning
masked behind seemingly safe responses. These failures expose misalignments
between internal inference and surface-level behavior, eluding existing
content-based safeguards. To quantify these risks, we introduce three metrics:
(1) Risk-Reasoning Stealth Score (RRSS) for harmful reasoning beneath benign
outputs; (2) Risk-Visual Neglect Rate (RVNR) for unsafe completions despite
visual risk recognition; and (3) Refusal Attitude Inconsistency (RAIC) for
evaluating refusal unstability under prompt variants. Extensive experiments on
advanced MLRMs demonstrate the effectiveness of EmoAgent and reveal deeper
emotional cognitive misalignments in model safety behavior.

</details>


### [6] [Galaxy: A Cognition-Centered Framework for Proactive, Privacy-Preserving, and Self-Evolving LLM Agents](https://arxiv.org/abs/2508.03991)
*Chongyu Bao,Ruimin Dai,Yangbo Shen,Runyang Jian,Jinghan Zhang,Xiaolan Liu,Kunpeng Liu*

Main category: cs.AI

TL;DR: 论文提出了一种名为Cognition Forest的语义结构，用于统一认知建模与系统设计，并基于此开发了Galaxy框架，支持多维交互和个性化能力生成。实验证明其优于现有基准。


<details>
  <summary>Details</summary>
Motivation: 智能个人助手（IPAs）的主动行为研究不足，设计兼具主动性、隐私保护和自我进化能力的IPA仍具挑战性。

Method: 提出Cognition Forest语义结构，将认知架构与系统设计统一为自增强循环，并开发Galaxy框架，实现多维交互和个性化能力生成。

Result: Galaxy框架在实验中表现优于现有基准，并通过消融研究和实际交互案例验证了其有效性。

Conclusion: Cognition Forest和Galaxy框架为IPA的主动性和自我进化提供了有效解决方案。

Abstract: Intelligent personal assistants (IPAs) such as Siri and Google Assistant are
designed to enhance human capabilities and perform tasks on behalf of users.
The emergence of LLM agents brings new opportunities for the development of
IPAs. While responsive capabilities have been widely studied, proactive
behaviors remain underexplored. Designing an IPA that is proactive,
privacy-preserving, and capable of self-evolution remains a significant
challenge. Designing such IPAs relies on the cognitive architecture of LLM
agents. This work proposes Cognition Forest, a semantic structure designed to
align cognitive modeling with system-level design. We unify cognitive
architecture and system design into a self-reinforcing loop instead of treating
them separately. Based on this principle, we present Galaxy, a framework that
supports multidimensional interactions and personalized capability generation.
Two cooperative agents are implemented based on Galaxy: KoRa, a
cognition-enhanced generative agent that supports both responsive and proactive
skills; and Kernel, a meta-cognition-based meta-agent that enables Galaxy's
self-evolution and privacy preservation. Experimental results show that Galaxy
outperforms multiple state-of-the-art benchmarks. Ablation studies and
real-world interaction cases validate the effectiveness of Galaxy.

</details>


### [7] [Uncertainty-Aware GUI Agent: Adaptive Perception through Component Recommendation and Human-in-the-Loop Refinement](https://arxiv.org/abs/2508.04025)
*Chao Hao,Shuai Wang,Kaiwen Zhou*

Main category: cs.AI

TL;DR: RecAgent是一种不确定性感知的GUI代理，通过自适应感知解决输入冗余和决策模糊问题，包括感知不确定性和决策不确定性，并整合了组件推荐和交互模块。


<details>
  <summary>Details</summary>
Motivation: GUI代理在移动任务自动化中存在输入冗余和决策模糊的问题，需要一种能有效处理这两种不确定性的方法。

Method: RecAgent通过组件推荐机制减少感知不确定性，通过交互模块处理决策不确定性，并整合为统一框架。

Result: 实验验证了RecAgent的有效性，并提出了ComplexAction数据集用于评估GUI代理。

Conclusion: RecAgent成功解决了GUI导航中的不确定性问题，并通过人机协作优化了决策过程。

Abstract: Graphical user interface (GUI) agents have shown promise in automating mobile
tasks but still struggle with input redundancy and decision ambiguity. In this
paper, we present \textbf{RecAgent}, an uncertainty-aware agent that addresses
these issues through adaptive perception. We distinguish two types of
uncertainty in GUI navigation: (1) perceptual uncertainty, caused by input
redundancy and noise from comprehensive screen information, and (2) decision
uncertainty, arising from ambiguous tasks and complex reasoning. To reduce
perceptual uncertainty, RecAgent employs a component recommendation mechanism
that identifies and focuses on the most relevant UI elements. For decision
uncertainty, it uses an interactive module to request user feedback in
ambiguous situations, enabling intent-aware decisions. These components are
integrated into a unified framework that proactively reduces input complexity
and reacts to high-uncertainty cases via human-in-the-loop refinement.
Additionally, we propose a dataset called \textbf{ComplexAction} to evaluate
the success rate of GUI agents in executing specified single-step actions
within complex scenarios. Extensive experiments validate the effectiveness of
our approach. The dataset and code will be available at
https://github.com/Fanye12/RecAgent.

</details>


### [8] [SEA: Self-Evolution Agent with Step-wise Reward for Computer Use](https://arxiv.org/abs/2508.04037)
*Liang Tang,Shuxian Li,Yuhao Cheng,Yukang Huo,Zhepeng Wang,Yiqiang Yan,Kaer Huang,Yanzhe Jing,Tiaonan Duan*

Main category: cs.AI

TL;DR: 提出了一种名为SEA的自我进化代理，通过创新的数据生成、强化学习和模型增强方法，显著提升了计算机使用代理的性能。


<details>
  <summary>Details</summary>
Motivation: 当前计算机使用代理的性能不足以满足实际需求，因此需要开发更高效的代理。

Method: 提出自动生成可验证轨迹的管道、高效的逐步强化学习策略，以及无需额外训练的模型增强方法。

Result: SEA仅需7B参数，性能优于同规模模型，并可与更大模型媲美。

Conclusion: SEA为计算机使用代理提供了高效解决方案，未来将开源模型权重和相关代码。

Abstract: Computer use agent is an emerging area in artificial intelligence that aims
to operate the computers to achieve the user's tasks, which attracts a lot of
attention from both industry and academia. However, the present agents'
performance is far from being used. In this paper, we propose the
Self-Evolution Agent (SEA) for computer use, and to develop this agent, we
propose creative methods in data generation, reinforcement learning, and model
enhancement. Specifically, we first propose an automatic pipeline to generate
the verifiable trajectory for training. And then, we propose efficient
step-wise reinforcement learning to alleviate the significant computational
requirements for long-horizon training. In the end, we propose the enhancement
method to merge the grounding and planning ability into one model without any
extra training. Accordingly, based on our proposed innovation of data
generation, training strategy, and enhancement, we get the Selfevolution Agent
(SEA) for computer use with only 7B parameters, which outperforms models with
the same number of parameters and has comparable performance to larger ones. We
will make the models' weight and related codes open-source in the future.

</details>


### [9] [Personalized Knowledge Transfer Through Generative AI: Contextualizing Learning to Individual Career Goals](https://arxiv.org/abs/2508.04070)
*Ronja Mehlan,Claudia Hess,Quintus Stierstorfer,Kristina Schaaff*

Main category: cs.AI

TL;DR: 研究探讨了基于职业目标的生成式AI学习内容个性化对学习者参与度、满意度和学习效率的影响，结果显示个性化内容显著提升了这些指标。


<details>
  <summary>Details</summary>
Motivation: 随着AI在数字学习环境中的普及，个性化学习内容有望提升学习者的长期动机和参与度。

Method: 采用混合方法实验，4000多名学习者分为实验组（接受职业目标定制内容）和对照组。

Result: 实验组在会话时长、满意度评分和学习效率上表现更优，学习者认为个性化内容更具激励性和实用性。

Conclusion: 研究表明，将教育内容与职业目标对齐具有重要价值，AI个性化可有效连接学术知识与职场应用。

Abstract: As artificial intelligence becomes increasingly integrated into digital
learning environments, the personalization of learning content to reflect
learners' individual career goals offers promising potential to enhance
engagement and long-term motivation. In our study, we investigate how career
goal-based content adaptation in learning systems based on generative AI
(GenAI) influences learner engagement, satisfaction, and study efficiency. The
mixed-methods experiment involved more than 4,000 learners, with one group
receiving learning scenarios tailored to their career goals and a control
group. Quantitative results show increased session duration, higher
satisfaction ratings, and a modest reduction in study duration compared to
standard content. Qualitative analysis highlights that learners found the
personalized material motivating and practical, enabling deep cognitive
engagement and strong identification with the content. These findings
underscore the value of aligning educational content with learners' career
goals and suggest that scalable AI personalization can bridge academic
knowledge and workplace applicability.

</details>


### [10] [KG-Augmented Executable CoT for Mathematical Coding](https://arxiv.org/abs/2508.04072)
*Xingyu Chen,Junxiu An,Jun Guo,Li Wang,Jingcai Guo*

Main category: cs.AI

TL;DR: KGA-ECoT框架通过知识图谱和可执行代码提升复杂数学推理能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理任务（如数学推理和代码生成）中表现不足，需改进。

Method: 提出KGA-ECoT框架，结合知识图谱（GraphRAG）和可执行代码分解问题，生成可验证代码。

Result: 在多个数学推理基准测试中，KGA-ECoT显著提升准确率，绝对改进达数个百分点。

Conclusion: KGA-ECoT是一个高效且通用的复杂数学推理框架，GraphRAG和代码执行是关键。

Abstract: In recent years, large language models (LLMs) have excelled in natural
language processing tasks but face significant challenges in complex reasoning
tasks such as mathematical reasoning and code generation. To address these
limitations, we propose KG-Augmented Executable Chain-of-Thought (KGA-ECoT), a
novel framework that enhances code generation through knowledge graphs and
improves mathematical reasoning via executable code. KGA-ECoT decomposes
problems into a Structured Task Graph, leverages efficient GraphRAG for precise
knowledge retrieval from mathematical libraries, and generates verifiable code
to ensure computational accuracy. Evaluations on multiple mathematical
reasoning benchmarks demonstrate that KGA-ECoT significantly outperforms
existing prompting methods, achieving absolute accuracy improvements ranging
from several to over ten percentage points. Further analysis confirms the
critical roles of GraphRAG in enhancing code quality and external code
execution in ensuring precision. These findings collectively establish KGA-ECoT
as a robust and highly generalizable framework for complex mathematical
reasoning tasks.

</details>


### [11] [GeoSR: Cognitive-Agentic Framework for Probing Geospatial Knowledge Boundaries via Iterative Self-Refinement](https://arxiv.org/abs/2508.04080)
*Jinfan Tang,Kunming Wu,Ruifeng Gongxie,Yuya He,Yuankai Wu*

Main category: cs.AI

TL;DR: GeoSR是一个自优化的地理推理框架，通过嵌入地理原则（如Tobler第一地理定律）和多代理协作，提升LLM在空间一致性和多跳推理中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在空间一致性、多跳推理和地理偏见方面的挑战。

Method: 提出GeoSR框架，包含变量选择代理、点选择代理和优化代理，通过迭代优化预测质量。

Result: 实验显示GeoSR在物理和社会经济预测任务中优于标准提示策略。

Conclusion: GeoSR通过结合地理统计先验和空间结构化推理，提高了LLM的地理预测准确性和公平性。

Abstract: Recent studies have extended the application of large language models (LLMs)
to geographic problems, revealing surprising geospatial competence even without
explicit spatial supervision. However, LLMs still face challenges in spatial
consistency, multi-hop reasoning, and geographic bias. To address these issues,
we propose GeoSR, a self-refining agentic reasoning framework that embeds core
geographic principles -- most notably Tobler's First Law of Geography -- into
an iterative prediction loop. In GeoSR, the reasoning process is decomposed
into three collaborating agents: (1) a variable-selection agent that selects
relevant covariates from the same location; (2) a point-selection agent that
chooses reference predictions at nearby locations generated by the LLM in
previous rounds; and (3) a refine agent that coordinates the iterative
refinement process by evaluating prediction quality and triggering further
rounds when necessary. This agentic loop progressively improves prediction
quality by leveraging both spatial dependencies and inter-variable
relationships. We validate GeoSR on tasks ranging from physical-world property
estimation to socioeconomic prediction. Experimental results show consistent
improvements over standard prompting strategies, demonstrating that
incorporating geostatistical priors and spatially structured reasoning into
LLMs leads to more accurate and equitable geospatial predictions. The code of
GeoSR is available at https://github.com/JinfanTang/GeoSR.

</details>


### [12] [Towards Transparent AI Grading: Semantic Entropy as a Signal for Human-AI Disagreement](https://arxiv.org/abs/2508.04105)
*Karrtik Iyer,Manikandan Ravikiran,Prasanna Pendse,Shayan Mohanty*

Main category: cs.AI

TL;DR: 该论文提出了一种名为“语义熵”的方法，通过GPT-4生成的多重解释来衡量自动评分系统的不确定性，并与人类评分者的分歧对齐。


<details>
  <summary>Details</summary>
Motivation: 当前自动评分系统无法有效反映评分决策的不确定性或争议性，因此需要一种透明且可信的方法来量化这种不确定性。

Method: 通过聚类基于蕴含相似性的解释并计算这些簇的熵，量化评分的多样性，而不依赖最终输出分数。

Result: 实验表明，语义熵与人类评分者的分歧相关，且在不同学科和任务结构中有意义地变化。

Conclusion: 语义熵作为一种可解释的不确定性信号，有助于提升AI辅助评分的透明度和可信度。

Abstract: Automated grading systems can efficiently score short-answer responses, yet
they often fail to indicate when a grading decision is uncertain or potentially
contentious. We introduce semantic entropy, a measure of variability across
multiple GPT-4-generated explanations for the same student response, as a proxy
for human grader disagreement. By clustering rationales via entailment-based
similarity and computing entropy over these clusters, we quantify the diversity
of justifications without relying on final output scores. We address three
research questions: (1) Does semantic entropy align with human grader
disagreement? (2) Does it generalize across academic subjects? (3) Is it
sensitive to structural task features such as source dependency? Experiments on
the ASAP-SAS dataset show that semantic entropy correlates with rater
disagreement, varies meaningfully across subjects, and increases in tasks
requiring interpretive reasoning. Our findings position semantic entropy as an
interpretable uncertainty signal that supports more transparent and trustworthy
AI-assisted grading workflows.

</details>


### [13] [A Compositional Framework for On-the-Fly LTLf Synthesis](https://arxiv.org/abs/2508.04116)
*Yongkang Li,Shengping Xiao,Shufang Zhu,Jianwen Li,Geguang Pu*

Main category: cs.AI

TL;DR: 提出了一种组合式即时合成框架，结合了DFA构造和游戏求解的优势，适用于大型LTLf公式。


<details>
  <summary>Details</summary>
Motivation: 现有技术在DFA构造和游戏求解上各有局限，缺乏统一优势。

Method: 组合式即时合成框架，在游戏求解过程中进行组合，支持两种组合变体。

Result: 能够解决其他求解器无法处理的实例，两种组合变体各有优势。

Conclusion: 框架有效结合了两种方法的优点，提升了合成能力。

Abstract: Reactive synthesis from Linear Temporal Logic over finite traces (LTLf) can
be reduced to a two-player game over a Deterministic Finite Automaton (DFA) of
the LTLf specification. The primary challenge here is DFA construction, which
is 2EXPTIME-complete in the worst case. Existing techniques either construct
the DFA compositionally before solving the game, leveraging automata
minimization to mitigate state-space explosion, or build the DFA incrementally
during game solving to avoid full DFA construction. However, neither is
dominant. In this paper, we introduce a compositional on-the-fly synthesis
framework that integrates the strengths of both approaches, focusing on large
conjunctions of smaller LTLf formulas common in practice. This framework
applies composition during game solving instead of automata (game arena)
construction. While composing all intermediate results may be necessary in the
worst case, pruning these results simplifies subsequent compositions and
enables early detection of unrealizability. Specifically, the framework allows
two composition variants: pruning before composition to take full advantage of
minimization or pruning during composition to guide on-the-fly synthesis.
Compared to state-of-the-art synthesis solvers, our framework is able to solve
a notable number of instances that other solvers cannot handle. A detailed
analysis shows that both composition variants have unique merits.

</details>


### [14] [AgREE: Agentic Reasoning for Knowledge Graph Completion on Emerging Entities](https://arxiv.org/abs/2508.04118)
*Ruochen Zhao,Simone Conia,Eric Peng,Min Li,Saloni Potdar*

Main category: cs.AI

TL;DR: AgREE框架通过结合迭代检索和多步推理，动态构建知识图谱三元组，显著优于现有方法，尤其适用于新兴实体。


<details>
  <summary>Details</summary>
Motivation: 开放域知识图谱补全面临动态世界中新兴实体信息不足的挑战，现有方法依赖预训练模型或单步检索，难以捕捉最新信息。

Method: 提出AgREE框架，结合迭代检索和多步推理，动态构建知识图谱三元组，无需训练数据。

Result: AgREE在构建知识图谱三元组上显著优于现有方法，尤其对新兴实体表现突出，提升达13.7%。

Conclusion: AgREE展示了基于代理的推理与信息检索结合在动态知识图谱维护中的有效性。

Abstract: Open-domain Knowledge Graph Completion (KGC) faces significant challenges in
an ever-changing world, especially when considering the continual emergence of
new entities in daily news. Existing approaches for KGC mainly rely on
pretrained language models' parametric knowledge, pre-constructed queries, or
single-step retrieval, typically requiring substantial supervision and training
data. Even so, they often fail to capture comprehensive and up-to-date
information about unpopular and/or emerging entities. To this end, we introduce
Agentic Reasoning for Emerging Entities (AgREE), a novel agent-based framework
that combines iterative retrieval actions and multi-step reasoning to
dynamically construct rich knowledge graph triplets. Experiments show that,
despite requiring zero training efforts, AgREE significantly outperforms
existing methods in constructing knowledge graph triplets, especially for
emerging entities that were not seen during language models' training
processes, outperforming previous methods by up to 13.7%. Moreover, we propose
a new evaluation methodology that addresses a fundamental weakness of existing
setups and a new benchmark for KGC on emerging entities. Our work demonstrates
the effectiveness of combining agent-based reasoning with strategic information
retrieval for maintaining up-to-date knowledge graphs in dynamic information
environments.

</details>


### [15] [Generic-to-Specific Reasoning and Learning for Scalable Ad Hoc Teamwork](https://arxiv.org/abs/2508.04163)
*Hasra Dodampegama,Mohan Sridharan*

Main category: cs.AI

TL;DR: 论文提出了一种结合知识驱动和数据驱动的方法，用于提升AI代理在临时团队协作中的决策能力，解决了现有数据驱动方法的透明性和适应性不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有临时团队协作方法依赖大量标注数据且缺乏透明性，难以快速适应变化，随着代理数量增加，协作效率下降。

Method: 提出了一种架构，结合非单调逻辑推理、领域知识、快速学习和预测其他代理行为的能力，以及基于基础模型的未来目标预测。

Result: 在VirtualHome仿真环境中验证了该架构的有效性。

Conclusion: 结合知识驱动和数据驱动的方法能显著提升临时团队协作的效率和适应性。

Abstract: AI agents deployed in assistive roles often have to collaborate with other
agents (humans, AI systems) without prior coordination. Methods considered
state of the art for such ad hoc teamwork often pursue a data-driven approach
that needs a large labeled dataset of prior observations, lacks transparency,
and makes it difficult to rapidly revise existing knowledge in response to
changes. As the number of agents increases, the complexity of decision-making
makes it difficult to collaborate effectively. This paper advocates leveraging
the complementary strengths of knowledge-based and data-driven methods for
reasoning and learning for ad hoc teamwork. For any given goal, our
architecture enables each ad hoc agent to determine its actions through
non-monotonic logical reasoning with: (a) prior commonsense domain-specific
knowledge; (b) models learned and revised rapidly to predict the behavior of
other agents; and (c) anticipated abstract future goals based on generic
knowledge of similar situations in an existing foundation model. We
experimentally evaluate our architecture's capabilities in VirtualHome, a
realistic physics-based 3D simulation environment.

</details>


### [16] [Circuit-Aware SAT Solving: Guiding CDCL via Conditional Probabilities](https://arxiv.org/abs/2508.04235)
*Jiaying Zhu,Ziyang Zheng,Zhengyuan Shi,Yalun Cai,Qiang Xu*

Main category: cs.AI

TL;DR: CASCAD是一种新型电路感知SAT求解框架，通过GNN计算电路级条件概率，显著提升求解效率。


<details>
  <summary>Details</summary>
Motivation: 传统方法将电路转换为CNF并丢弃结构信息，导致求解性能不佳。

Method: 利用GNN计算门级条件概率，动态指导CDCL启发式（变量相位选择和子句管理）。

Result: 在LEC基准测试中，求解时间减少10倍，概率引导子句过滤策略额外减少23.5%运行时间。

Conclusion: 保留电路结构信息对提升SAT求解效率和EDA工具设计至关重要。

Abstract: Circuit Satisfiability (CSAT) plays a pivotal role in Electronic Design
Automation. The standard workflow for solving CSAT problems converts circuits
into Conjunctive Normal Form (CNF) and employs generic SAT solvers powered by
Conflict-Driven Clause Learning (CDCL). However, this process inherently
discards rich structural and functional information, leading to suboptimal
solver performance. To address this limitation, we introduce CASCAD, a novel
circuit-aware SAT solving framework that directly leverages circuit-level
conditional probabilities computed via Graph Neural Networks (GNNs). By
explicitly modeling gate-level conditional probabilities, CASCAD dynamically
guides two critical CDCL heuristics -- variable phase selection and clause
managementto significantly enhance solver efficiency. Extensive evaluations on
challenging real-world Logical Equivalence Checking (LEC) benchmarks
demonstrate that CASCAD reduces solving times by up to 10x compared to
state-of-the-art CNF-based approaches, achieving an additional 23.5% runtime
reduction via our probability-guided clause filtering strategy. Our results
underscore the importance of preserving circuit-level structural insights
within SAT solvers, providing a robust foundation for future improvements in
SAT-solving efficiency and EDA tool design.

</details>


### [17] [Large Language Model's Multi-Capability Alignment in Biomedical Domain](https://arxiv.org/abs/2508.04278)
*Wentao Wu,Linqing Chen,Hanmeng Zhong,Weilei Wang*

Main category: cs.AI

TL;DR: BalancedBio是一个理论支持的参数高效生物医学推理框架，通过正交梯度空间防止能力干扰，结合医学知识生成和策略优化，实现多能力集成与安全部署。


<details>
  <summary>Details</summary>
Motivation: 解决生物医学领域AI多能力集成中的能力干扰问题，确保安全部署和临床准确性。

Method: 1. MKGSG（医学知识基础合成生成）结合临床工作流和医学本体验证；2. 能力感知的组相对策略优化，保持强化学习中的正交性。

Result: 在多个指标上显著提升（如BIOMED-MMLU达80.95%），并实现78%成本降低和23%诊断准确率提升。

Conclusion: BalancedBio为生物医学AI对齐提供了理论和方法支持，实现了高效、安全、可靠的推理，即将发布0.5B模型。

Abstract: BalancedBio is a theoretically grounded framework for parameter-efficient
biomedical reasoning, addressing multi-capability integration in
domain-specific AI alignment. It establishes the Biomedical Multi-Capability
Convergence Theorem, proving orthogonal gradient spaces are essential to
prevent capability interference for safe deployment. Key innovations include:
(1) Medical Knowledge Grounded Synthetic Generation (MKGSG), extending
Source2Synth with clinical workflow constraints and medical ontology validation
for factual accuracy and safety; and (2) Capability Aware Group Relative Policy
Optimization, deriving optimal hybrid reward weighting to maintain
orthogonality in RL, using a reward model with rule-based and model-based
scores adapted to biomedical tasks. Mathematical analysis proves Pareto-optimal
convergence, preserving performance across capabilities. It achieves
state-of-the-art results in its parameter class: domain expertise (80.95%
BIOMED-MMLU, +15.32% over baseline), reasoning (61.94%, +7.75%), instruction
following (67.95%, +6.44%), and integration (86.7%, +18.5%). Theoretical safety
guarantees include bounds on capability preservation and clinical accuracy.
Real-world deployment yields 78% cost reduction, 23% improved diagnostic
accuracy, and 89% clinician acceptance. This work provides a principled
methodology for biomedical AI alignment, enabling efficient reasoning with
essential safety and reliability, with the 0.5B model version to be released.

</details>


### [18] [Synthetic POMDPs to Challenge Memory-Augmented RL: Memory Demand Structure Modeling](https://arxiv.org/abs/2508.04282)
*Yongyi Wang,Lingfeng Li,Bozhou Chen,Ang Li,Hanyu Liu,Qirui Zheng,Xionghui Yang,Wenxin Li*

Main category: cs.AI

TL;DR: 论文提出了一种基于理论框架的POMDP合成方法，用于评估记忆增强强化学习算法，并提供了可定制难度的环境。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试缺乏对记忆模型挑战程度的可控性，而合成环境能更精细地评估记忆增强RL。

Method: 结合线性过程动态、状态聚合和奖励重分配，构建具有预设属性的POMDP。

Result: 开发了一系列难度递增的POMDP环境，为记忆模型选择提供了实证支持。

Conclusion: 研究明确了记忆增强RL在解决POMDP中的挑战，并为环境设计和分析提供了指导。

Abstract: Recent research has developed benchmarks for memory-augmented reinforcement
learning (RL) algorithms, providing Partially Observable Markov Decision
Process (POMDP) environments where agents depend on past observations to make
decisions. While many benchmarks incorporate sufficiently complex real-world
problems, they lack controllability over the degree of challenges posed to
memory models. In contrast, synthetic environments enable fine-grained
manipulation of dynamics, making them critical for detailed and rigorous
evaluation of memory-augmented RL. Our study focuses on POMDP synthesis with
three key contributions:
  1. A theoretical framework for analyzing POMDPs, grounded in Memory Demand
Structure (MDS), transition invariance, and related concepts; 2. A methodology
leveraging linear process dynamics, state aggregation, and reward
redistribution to construct customized POMDPs with predefined properties; 3.
Empirically validated series of POMDP environments with increasing difficulty
levels, designed based on our theoretical insights. Our work clarifies the
challenges of memory-augmented RL in solving POMDPs, provides guidelines for
analyzing and designing POMDP environments, and offers empirical support for
selecting memory models in RL tasks.

</details>


### [19] [Deliberative Reasoning Network: An Uncertainty-Driven Paradigm for Belief-Tracked Inference with Pretrained Language Models](https://arxiv.org/abs/2508.04339)
*Anran Xu,Jincheng Wang,Baigen Cai,Tao Wen*

Main category: cs.AI

TL;DR: 论文提出了一种名为DRN的新方法，通过将逻辑推理从概率最大化转变为不确定性最小化，解决了大语言模型在语义启发式与决定性证据冲突时的逻辑推理失败问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在逻辑推理中常因语义启发式与决定性证据冲突而失败，这种现象被称为认知陷阱。为了解决这一根本限制，研究团队提出了DRN方法。

Method: DRN通过跟踪信念状态和量化竞争假设的认知不确定性，将逻辑推理问题从‘哪个答案最可能’转变为‘哪个假设的证据最内部一致’。方法包括一个定制判别模型和一个轻量级验证模块。

Result: 在LCR-1000对抗性推理基准测试中，DRN比标准基线提高了15.2%。与Mistral-7B集成后，系统在最难问题上的准确率从20%提升到80%。DRN还表现出强大的零样本泛化能力，TruthfulQA性能提升23.6%。

Conclusion: DRN作为一种可验证的System 2推理组件，为构建更可信的AI系统提供了基础。

Abstract: Large language models often fail at logical reasoning when semantic
heuristics conflict with decisive evidence - a phenomenon we term cognitive
traps. To address this fundamental limitation, we introduce the Deliberative
Reasoning Network (DRN), a novel paradigm that reframes logical reasoning from
probability maximization to uncertainty minimization. Instead of asking "Which
answer is most likely?", DRN asks "Which hypothesis has the most internally
consistent evidence?". DRN achieves intrinsic interpretability by explicitly
tracking belief states and quantifying epistemic uncertainty for competing
hypotheses through an iterative evidence synthesis process. We validate our
approach through two complementary architectures - a bespoke discriminative
model that embodies the core uncertainty minimization principle, and a
lightweight verification module that enhances existing generative LLMs.
Evaluated on LCR-1000, our new adversarial reasoning benchmark designed to
expose cognitive traps, the bespoke DRN achieves up to 15.2% improvement over
standard baselines. When integrated as a parameter-efficient verifier with
Mistral-7B, our hybrid system boosts accuracy from 20% to 80% on the most
challenging problems. Critically, DRN demonstrates strong zero-shot
generalization, improving TruthfulQA performance by 23.6% without additional
training, indicating that uncertainty-driven deliberation learns transferable
reasoning principles. We position DRN as a foundational, verifiable System 2
reasoning component for building more trustworthy AI systems.

</details>


### [20] [OmniPlay: Benchmarking Omni-Modal Models on Omni-Modal Game Playing](https://arxiv.org/abs/2508.04361)
*Fuqing Bie,Shiyu Huang,Xijia Tao,Zhiqin Fang,Leyi Pan,Junzhe Chen,Min Ren,Liuyu Xiang,Zhaofeng He*

Main category: cs.AI

TL;DR: OmniPlay是一个多模态基准测试，旨在评估动态交互世界中智能体的跨模态推理能力，揭示现有模型在协同融合方面的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法全面测试多模态模型在动态交互环境中的智能表现，尤其是缺乏对听觉和时间线索的考量。

Method: OmniPlay包含五个游戏环境，通过协同和冲突场景系统测试模型的跨模态推理能力。

Result: 评估显示，模型在高保真记忆任务中表现优异，但在需要推理和规划的任务中表现脆弱，揭示了融合机制的缺陷。

Conclusion: 研究指出，实现稳健的通用人工智能需超越规模扩展，专注于协同融合机制的研究。

Abstract: While generalist foundation models like Gemini and GPT-4o demonstrate
impressive multi-modal competence, existing evaluations fail to test their
intelligence in dynamic, interactive worlds. Static benchmarks lack agency,
while interactive benchmarks suffer from a severe modal bottleneck, typically
ignoring crucial auditory and temporal cues. To bridge this evaluation chasm,
we introduce OmniPlay, a diagnostic benchmark designed not just to evaluate,
but to probe the fusion and reasoning capabilities of agentic models across the
full sensory spectrum. Built on a core philosophy of modality interdependence,
OmniPlay comprises a suite of five game environments that systematically create
scenarios of both synergy and conflict, forcing agents to perform genuine
cross-modal reasoning. Our comprehensive evaluation of six leading omni-modal
models reveals a critical dichotomy: they exhibit superhuman performance on
high-fidelity memory tasks but suffer from systemic failures in challenges
requiring robust reasoning and strategic planning. We demonstrate that this
fragility stems from brittle fusion mechanisms, which lead to catastrophic
performance degradation under modality conflict and uncover a counter-intuitive
"less is more" paradox, where removing sensory information can paradoxically
improve performance. Our findings suggest that the path toward robust AGI
requires a research focus beyond scaling to explicitly address synergistic
fusion. Our platform is available for anonymous review at
https://github.com/fuqingbie/omni-game-benchmark.

</details>


### [21] [Artificial Consciousness as Interface Representation](https://arxiv.org/abs/2508.04383)
*Robert Prentner*

Main category: cs.AI

TL;DR: 本文提出一个框架，通过SLP测试（主观-语言、潜在-涌现、现象学-结构）来评估AI系统是否具备类似意识的属性。


<details>
  <summary>Details</summary>
Motivation: 探讨AI系统是否可能拥有意识，由于主观体验的定义和操作化存在挑战，需要一种实证方法。

Method: 引入SLP测试，利用范畴论建模接口表示，作为关系基质与可观察行为之间的映射。

Result: SLP测试将主观体验操作化为功能接口，而非物理系统的内在属性。

Conclusion: 该框架为研究人工意识提供了实证路径，强调功能性接口的重要性。

Abstract: Whether artificial intelligence (AI) systems can possess consciousness is a
contentious question because of the inherent challenges of defining and
operationalizing subjective experience. This paper proposes a framework to
reframe the question of artificial consciousness into empirically tractable
tests. We introduce three evaluative criteria - S (subjective-linguistic), L
(latent-emergent), and P (phenomenological-structural) - collectively termed
SLP-tests, which assess whether an AI system instantiates interface
representations that facilitate consciousness-like properties. Drawing on
category theory, we model interface representations as mappings between
relational substrates (RS) and observable behaviors, akin to specific types of
abstraction layers. The SLP-tests collectively operationalize subjective
experience not as an intrinsic property of physical systems but as a functional
interface to a relational entity.

</details>


### [22] [GuirlVG: Incentivize GUI Visual Grounding via Empirical Exploration on Reinforcement Learning](https://arxiv.org/abs/2508.04389)
*Weitai Kang,Bin Lei,Gaowen Liu,Caiwen Ding,Yan Yan*

Main category: cs.AI

TL;DR: 论文提出了一种基于强化学习的GUI视觉定位方法GuirlVG，通过系统实证研究和新稳定技术，显著优于传统监督微调方法。


<details>
  <summary>Details</summary>
Motivation: 传统GUI视觉定位依赖监督微调（SFT），但数据需求大且训练成本高。随着多模态大模型（MLLMs）的进步，SFT的必要性受到质疑，而规则强化微调（RFT）成为更高效的选择。

Method: 研究分解RFT核心组件并优化其形式，提出动态稳定训练的Adversarial KL Factor，并探索RFT的训练配置。

Result: GuirlVG仅用5.2K训练样本，性能超越使用10M样本的SFT方法，在多个数据集上取得显著提升。

Conclusion: GuirlVG证明了RFT在GUI视觉定位中的高效性，为未来研究提供了新方向。

Abstract: Graphical user interface visual grounding (GUI-VG), a core capability for GUI
agents, has primarily relied on supervised fine-tuning (SFT) of multimodal
large language models (MLLMs), which demands extensive data curation and
significant training costs. However, as MLLMs continue to advance and even
cover GUI domains during pretraining, the necessity of exhaustive SFT
post-training becomes increasingly questionable. Meanwhile, recent successes of
rule-based reinforcement fine-tuning (RFT) suggest a more efficient
alternative. Despite this promise, the optimal manner of applying RFT for
GUI-VG remains unexplored. To bridge this gap, we introduce GuirlVG, a
reinforcement learning-based GUI-VG method built on a systematic empirical
study and a novel stabilization technique. We find that naive application of
RFT underperforms the SFT baseline, motivating a deeper exploration. First, we
decompose RFT into its core components and analyze the optimal formulation of
each. Second, we propose a novel Adversarial KL Factor that dynamically
stabilizes training to mitigate reward over-optimization. Third, we further
explore the training configurations of RFT to enhance effectiveness. Extensive
experiments show that GuirlVG, with only 5.2K training samples, outperforms SFT
methods trained on over 10M samples, achieving a 7.7% improvement on
ScreenSpot, a 17.2% improvement on ScreenSpotPro, and 91.9% accuracy on
ScreenSpotV2.

</details>


### [23] [Beyond Pixels: Exploring DOM Downsampling for LLM-Based Web Agents](https://arxiv.org/abs/2508.04412)
*Thassilo M. Schiepanski,Nicholas Piël*

Main category: cs.AI

TL;DR: D2Snap是一种新型DOM降采样算法，通过GPT-4o后端评估，其性能接近或优于基于GUI快照的基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于GUI快照的网页代理方法受限于LLM视觉能力不足，而DOM快照虽结构更优，但因输入令牌过大难以实现。

Method: 提出D2Snap算法，对DOM快照进行降采样，并在Online-Mind2Web数据集上评估其性能。

Result: D2Snap降采样后的DOM快照成功率（67%）与GUI快照基线（65%）相当，且在更高令牌配置下性能提升8%。

Conclusion: DOM的层次结构是LLM理解UI的有效特征，D2Snap为DOM快照的实用化提供了可行方案。

Abstract: Frontier LLMs only recently enabled serviceable, autonomous web agents. At
that, a model poses as an instantaneous domain model backend. Ought to suggest
interaction, it is consulted with a web-based task and respective application
state. The key problem lies in application state serialisation
$\unicode{x2013}$ referred to as snapshot. State-of-the-art web agents are
premised on grounded GUI snapshots, i.e., screenshots enhanced with visual
cues. Not least to resemble human perception, but for images representing
relatively cheap means of model input. LLM vision still lag behind code
interpretation capabilities. DOM snapshots, which structurally resemble HTML,
impose a desired alternative. Vast model input token size, however, disables
reliable implementation with web agents to date.
  We propose D2Snap, a first-of-its-kind DOM downsampling algorithm. Based on a
GPT-4o backend, we evaluate D2Snap on tasks sampled from the Online-Mind2Web
dataset. The success rate of D2Snap-downsampled DOM snapshots (67%) matches a
grounded GUI snapshot baseline (65%) $\unicode{x2013}$ within the same input
token order of magnitude (1e3). Our best evaluated configurations
$\unicode{x2013}$ one token order above, but within the model's context window
$\unicode{x2013}$ outperform this baseline by 8%. Our evaluation, moreover,
yields that DOM-inherent hierarchy embodies a strong UI feature for LLMs.

</details>


### [24] [\textsc{SimInstruct}: A Responsible Tool for Collecting Scaffolding Dialogues Between Experts and LLM-Simulated Novices](https://arxiv.org/abs/2508.04428)
*Si Chen,Izzy Molnar,Ting Hua,Peiyu Li,Le Huy Khiem,G. Alex Ambrose,Jim Lang,Ronald Metoyer,Nitesh V. Chawla*

Main category: cs.AI

TL;DR: SimInstruct是一种通过专家参与和LLM模拟新手收集高质量教学对话的工具，其生成的对话在教学相关性和认知深度上与真实对话相当，并可用于改进专家模型。


<details>
  <summary>Details</summary>
Motivation: 高质量的多轮教学对话对AI教学系统至关重要，但此类数据稀缺，主要因隐私和求助脆弱性问题。

Method: SimInstruct利用LLM模拟新手，结合专家反馈生成教学对话，避免真实新手参与。

Result: 生成的对话与真实对话相当，专家反馈提升了数据质量和专业洞察力，改进的LLaMA模型在教学质量上优于GPT-4o。

Conclusion: SimInstruct为教学对话数据收集提供了可行方案，同时揭示了GPT-4o在教学支持中的局限性。

Abstract: High-quality, multi-turn instructional dialogues between novices and experts
are essential for developing AI systems that support teaching, learning, and
decision-making. These dialogues often involve scaffolding -- the process by
which an expert supports a novice's thinking through questions, feedback, and
step-by-step guidance. However, such data are scarce due to privacy concerns in
recording and the vulnerability inherent in help-seeking. We present
SimInstruct, a scalable, expert-in-the-loop tool for collecting scaffolding
dialogues. Using teaching development coaching as an example domain,
SimInstruct simulates novice instructors via LLMs, varying their teaching
challenges and LLM's persona traits, while human experts provide multi-turn
feedback, reasoning, and instructional support. This design enables the
creation of realistic, pedagogically rich dialogues without requiring real
novice participants. Our results reveal that persona traits, such as
extroversion and introversion, meaningfully influence how experts engage.
Compared to real mentoring recordings, SimInstruct dialogues demonstrate
comparable pedagogical relevance and cognitive depth. Experts also reported the
process as engaging and reflective, improving both data quality and their own
professional insight. We further fine-tuned a LLaMA model to be an expert model
using the augmented dataset, which outperformed GPT-4o in instructional
quality. Our analysis highlights GPT-4o's limitations in weak reflective
questioning, overuse of generic praise, a condescending tone, and a tendency to
overwhelm novices with excessive suggestions.

</details>


### [25] [From "Aha Moments" to Controllable Thinking: Toward Meta-Cognitive Reasoning in Large Reasoning Models via Decoupled Reasoning and Control](https://arxiv.org/abs/2508.04460)
*Rui Ha,Chaozhuo Li,Rui Pu,Sen Su*

Main category: cs.AI

TL;DR: 论文提出Meta-cognitive Reasoning Framework (MERA)，通过分离推理与控制组件，优化大型推理模型（LRMs）的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在推理过程中缺乏内在调控机制，导致过度推理和计算资源浪费，限制了实际应用。

Method: MERA框架将推理过程分解为推理和控制组件，采用接管式数据构建机制、结构化分离监督微调和控制段策略优化（CSPO）。

Result: 实验表明，MERA训练的模型在推理效率和准确性上均有提升。

Conclusion: MERA通过显式分离和控制推理过程，有效解决了LRMs的过度推理问题，提升了实际部署的可行性。

Abstract: Large Reasoning Models (LRMs) have demonstrated a latent capacity for complex
reasoning by spontaneously exhibiting cognitive behaviors such as step-by-step
reasoning, reflection, and backtracking, commonly referred to as "Aha Moments".
However, such emergent behaviors remain unregulated and uncontrolled, often
resulting in overthinking, where the model continues generating redundant
reasoning content even after reaching reliable conclusions. This leads to
excessive computational costs and increased latency, limiting the practical
deployment of LRMs. The root cause lies in the absence of intrinsic regulatory
mechanisms, as current models are unable to monitor and adaptively manage their
reasoning process to determine when to continue, backtrack, or terminate. To
address this issue, we propose the Meta-cognitive Reasoning Framework (MERA),
which explicitly decouples the thinking process into distinct reasoning and
control components, thereby enabling the independent optimization of control
strategies. Specifically, MERA incorporates a takeover-based data construction
mechanism that identifies critical decision points during reasoning and
delegates the creation of control signals to auxiliary LLMs, thereby enabling
the construction of high-quality reasoning-control data. Additionally, a
structured reasoning-control separation is implemented via supervised
fine-tuning, enabling the model to generate explicit traces and acquire initial
meta-cognitive control capabilities. Finally, MERA employs Control-Segment
Policy Optimization (CSPO), which combines segment-wise Group Relative Policy
Optimization (GRPO) with a control-masking mechanism to optimize control
behavior learning while minimizing interference from irrelevant content.
Experiments on various reasoning benchmarks demonstrate that models trained
with MERA enhance both reasoning efficiency and accuracy.

</details>


### [26] [OS Agents: A Survey on MLLM-based Agents for General Computing Devices Use](https://arxiv.org/abs/2508.04482)
*Xueyu Hu,Tao Xiong,Biao Yi,Zishu Wei,Ruixuan Xiao,Yurun Chen,Jiasheng Ye,Meiling Tao,Xiangxin Zhou,Ziyu Zhao,Yuhuai Li,Shengze Xu,Shenzhi Wang,Xinchen Xu,Shuofei Qiao,Zhaokai Wang,Kun Kuang,Tieyong Zeng,Liang Wang,Jiwei Li,Yuchen Eleanor Jiang,Wangchunshu Zhou,Guoyin Wang,Keting Yin,Zhou Zhao,Hongxia Yang,Fan Wu,Shengyu Zhang,Fei Wu*

Main category: cs.AI

TL;DR: 本文综述了基于多模态大语言模型（MLLMs）的操作系统代理（OS Agents），探讨其组成、能力、构建方法、评估标准及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 实现像钢铁侠中J.A.R.V.I.S.一样全能的人工智能助手，通过OS Agents在多模态环境中自动化任务。

Method: 综述OS Agents的基础组件（环境、观察空间、动作空间）、能力（理解、规划、落地）、构建方法（领域特定基础模型、代理框架）及评估协议。

Result: 总结了OS Agents的研究现状，提出了未来方向（安全隐私、个性化、自我进化），并维护开源GitHub资源库。

Conclusion: OS Agents研究已取得显著进展，但仍需解决安全隐私等问题，未来有望进一步推动学术与工业发展。

Abstract: The dream to create AI assistants as capable and versatile as the fictional
J.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution
of (multi-modal) large language models ((M)LLMs), this dream is closer to
reality, as (M)LLM-based Agents using computing devices (e.g., computers and
mobile phones) by operating within the environments and interfaces (e.g.,
Graphical User Interface (GUI)) provided by operating systems (OS) to automate
tasks have significantly advanced. This paper presents a comprehensive survey
of these advanced agents, designated as OS Agents. We begin by elucidating the
fundamentals of OS Agents, exploring their key components including the
environment, observation space, and action space, and outlining essential
capabilities such as understanding, planning, and grounding. We then examine
methodologies for constructing OS Agents, focusing on domain-specific
foundation models and agent frameworks. A detailed review of evaluation
protocols and benchmarks highlights how OS Agents are assessed across diverse
tasks. Finally, we discuss current challenges and identify promising directions
for future research, including safety and privacy, personalization and
self-evolution. This survey aims to consolidate the state of OS Agents
research, providing insights to guide both academic inquiry and industrial
development. An open-source GitHub repository is maintained as a dynamic
resource to foster further innovation in this field. We present a 9-page
version of our work, accepted by ACL 2025, to provide a concise overview to the
domain.

</details>


### [27] [Argumentative Debates for Transparent Bias Detection [Technical Report]](https://arxiv.org/abs/2508.04511)
*Hamed Ayoobi,Nico Potyka,Anna Rapberger,Francesca Toni*

Main category: cs.AI

TL;DR: 提出了一种基于辩论的新型可解释、可解释的偏见检测方法，结合形式化和计算论证技术，强调透明度和公平性。


<details>
  <summary>Details</summary>
Motivation: AI系统中的偏见可能导致对特定群体的系统性不利，现有方法多忽略透明度，而可解释性和可解释性是实现算法公平的核心需求。

Method: 基于辩论的方法，通过保护特征值和邻域内个体的值，利用形式化和计算论证技术检测偏见。

Result: 方法在性能上优于基线，同时具备高度的可解释性和可解释性。

Conclusion: 该方法为偏见检测提供了透明且有效的解决方案，强调了可解释性在公平性中的重要性。

Abstract: As the use of AI systems in society grows, addressing potential biases that
emerge from data or are learned by models is essential to prevent systematic
disadvantages against specific groups. Several notions of (un)fairness have
been proposed in the literature, alongside corresponding algorithmic methods
for detecting and mitigating unfairness, but, with very few exceptions, these
tend to ignore transparency. Instead, interpretability and explainability are
core requirements for algorithmic fairness, even more so than for other
algorithmic solutions, given the human-oriented nature of fairness. In this
paper, we contribute a novel interpretable, explainable method for bias
detection relying on debates about the presence of bias against individuals,
based on the values of protected features for the individuals and others in
their neighbourhoods. Our method builds upon techniques from formal and
computational argumentation, whereby debates result from arguing about biases
within and across neighbourhoods. We provide formal, quantitative, and
qualitative evaluations of our method, highlighting its strengths in
performance against baselines, as well as its interpretability and
explainability.

</details>


### [28] [SID: Benchmarking Guided Instruction Capabilities in STEM Education with a Socratic Interdisciplinary Dialogues Dataset](https://arxiv.org/abs/2508.04563)
*Mei Jiang,Houping Yue,Bingdong Li,Hao Hao,Ying Qian,Bo Jiang,Aimin Zhou*

Main category: cs.AI

TL;DR: 论文介绍了SID基准，用于评估LLM在多轮跨学科苏格拉底对话中的高阶指导能力，发现当前LLM在引导学生知识整合与迁移方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 现代教育核心目标是培养学生解决复杂问题的能力，跨学科STEM教育是关键途径，但专家指导难以规模化。LLM虽有潜力，但缺乏有效评估基准。

Method: 提出SID基准，包含10,000轮对话、48个复杂STEM项目数据集，采用新标注模式（如X-SRG）评估LLM的指导能力。

Result: 实验表明，即使是先进LLM也难以有效引导学生实现知识整合与迁移。

Conclusion: SID基准对推动更具教育意识的LLM发展具有重要价值。

Abstract: Fostering students' abilities for knowledge integration and transfer in
complex problem-solving scenarios is a core objective of modern education, and
interdisciplinary STEM is a key pathway to achieve this, yet it requires expert
guidance that is difficult to scale. While LLMs offer potential in this regard,
their true capability for guided instruction remains unclear due to the lack of
an effective evaluation benchmark. To address this, we introduce SID, the first
benchmark designed to systematically evaluate the higher-order guidance
capabilities of LLMs in multi-turn, interdisciplinary Socratic dialogues. Our
contributions include a large-scale dataset of 10,000 dialogue turns across 48
complex STEM projects, a novel annotation schema for capturing deep pedagogical
features, and a new suite of evaluation metrics (e.g., X-SRG). Baseline
experiments confirm that even state-of-the-art LLMs struggle to execute
effective guided dialogues that lead students to achieve knowledge integration
and transfer. This highlights the critical value of our benchmark in driving
the development of more pedagogically-aware LLMs.

</details>


### [29] [ConfProBench: A Confidence Evaluation Benchmark for MLLM-Based Process Judges](https://arxiv.org/abs/2508.04576)
*Yue Zhou,Yi Chang,Yuan Wu*

Main category: cs.AI

TL;DR: 提出ConfProBench基准，评估多模态大语言模型（MLLMs）在推理步骤置信度可靠性上的表现，填补现有研究空白。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注推理步骤分类和搜索，忽略置信度可靠性，需系统性评估以指导改进。

Method: 构建三种对抗性扰动推理步骤（同义词替换、句法变换、图像扰动），提出三个新评估指标（CRS、CSS、CCS）。

Result: 实验揭示当前MPJs在置信度表现上的局限性，并提供竞争性基线。

Conclusion: ConfProBench为未来研究提供系统性评估工具，推动MLLMs推理能力的提升。

Abstract: Reasoning is a critical capability of multimodal large language models
(MLLMs) for solving complex multimodal tasks, and judging the correctness of
reasoning steps is crucial for improving this capability. Recently, MLLM-based
process judges (MPJs) have been widely used to assess the correctness of
reasoning steps in multimodal tasks. Therefore, evaluating MPJs is important
for identifying their limitations and guiding future improvements. However,
existing benchmarks for MPJs mainly focus on tasks such as step correctness
classification and reasoning process search, while overlooking a key aspect:
whether the confidence scores produced by MPJs at the step level are reliable.
To address this gap, we propose ConfProBench, the first comprehensive benchmark
designed to systematically evaluate the reliability of step-level confidence
scores generated by MPJs. Our benchmark constructs three types of adversarially
perturbed reasoning steps: Synonym Substitution, Syntactic Transformation, and
Image Perturbation, to test the robustness of MPJ confidence under
perturbations. In addition, we introduce three novel evaluation metrics:
Confidence Robustness Score (CRS), Confidence Sensitivity Score (CSS), and
Confidence Calibration Score (CCS), which evaluate robustness, sensitivity, and
calibration, respectively. We evaluate 14 state-of-the-art MLLMs, including
both proprietary and open-source models. Experiments reveal limitations in
current MPJs' confidence performance and offer competitive baselines to support
future research.

</details>


### [30] [LLM Collaboration With Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.04652)
*Shuo Liu,Zeyu Liang,Xueguang Lyu,Christopher Amato*

Main category: cs.AI

TL;DR: 论文提出了一种多智能体强化学习框架MAGRPO，用于优化大型语言模型（LLM）在多智能体系统中的协作能力，解决了现有方法依赖复杂个体奖励设计的问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在多智能体系统中协作能力不足，且现有微调框架依赖复杂的个体奖励设计，难以有效促进协作。

Method: 将LLM协作建模为合作型多智能体强化学习问题，提出多智能体、多轮算法MAGRPO，结合现有RL和MARL技术。

Result: 实验表明，MAGRPO能有效提升LLM在写作和编程协作任务中的生成质量和效率。

Conclusion: MAGRPO为LLM协作提供了新思路，并展示了MARL方法在LLM中的潜力与挑战。

Abstract: A large amount of work has been done in Multi-Agent Systems (MAS) for
modeling and solving problems with multiple interacting agents. However, most
LLMs are pretrained independently and not specifically optimized for
coordination. Existing LLM fine-tuning frameworks rely on individual rewards,
which require complex reward designs for each agent to encourage collaboration.
To address these challenges, we model LLM collaboration as a cooperative
Multi-Agent Reinforcement Learning (MARL) problem. We develop a multi-agent,
multi-turn algorithm, Multi-Agent Group Relative Policy Optimization (MAGRPO),
to solve it, building on current RL approaches for LLMs as well as MARL
techniques. Our experiments on LLM writing and coding collaboration demonstrate
that fine-tuning MAS with MAGRPO enables agents to generate high-quality
responses efficiently through effective cooperation. Our approach opens the
door to using other MARL methods for LLMs and highlights the associated
challenges.

</details>


### [31] [SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience](https://arxiv.org/abs/2508.04700)
*Zeyi Sun,Ziyu Liu,Yuhang Zang,Yuhang Cao,Xiaoyi Dong,Tong Wu,Dahua Lin,Jiaqi Wang*

Main category: cs.AI

TL;DR: SEAgent是一种自进化框架，通过自主学习和任务生成，提升计算机使用代理（CUA）在陌生软件环境中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型（LVLM）在缺乏人类标注的陌生软件中表现不佳，需要一种自主进化的解决方案。

Method: SEAgent结合了世界状态模型、课程生成器和经验学习（包括失败动作的对抗模仿和成功动作的GRPO优化），并通过专家到通用策略整合个体经验。

Result: 在OS-World的五个新软件环境中，SEAgent的成功率从11.3%提升至34.5%，显著优于UI-TARS。

Conclusion: SEAgent通过自主学习和任务生成，显著提升了CUA在陌生软件中的性能，展示了自进化框架的潜力。

Abstract: Repurposing large vision-language models (LVLMs) as computer use agents
(CUAs) has led to substantial breakthroughs, primarily driven by human-labeled
data. However, these models often struggle with novel and specialized software,
particularly in scenarios lacking human annotations. To address this challenge,
we propose SEAgent, an agentic self-evolving framework enabling CUAs to
autonomously evolve through interactions with unfamiliar software.
Specifically, SEAgent empowers computer-use agents to autonomously master novel
software environments via experiential learning, where agents explore new
software, learn through iterative trial-and-error, and progressively tackle
auto-generated tasks organized from simple to complex. To achieve this goal, we
design a World State Model for step-wise trajectory assessment, along with a
Curriculum Generator that generates increasingly diverse and challenging tasks.
The agent's policy is updated through experiential learning, comprised of
adversarial imitation of failure actions and Group Relative Policy Optimization
(GRPO) on successful ones. Furthermore, we introduce a specialist-to-generalist
training strategy that integrates individual experiential insights from
specialist agents, facilitating the development of a stronger generalist CUA
capable of continuous autonomous evolution. This unified agent ultimately
achieves performance surpassing ensembles of individual specialist agents on
their specialized software. We validate the effectiveness of SEAgent across
five novel software environments within OS-World. Our approach achieves a
significant improvement of 23.2% in success rate, from 11.3% to 34.5%, over a
competitive open-source CUA, i.e., UI-TARS.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [32] [Uncertainty-aware Accurate Elevation Modeling for Off-road Navigation via Neural Processes](https://arxiv.org/abs/2508.03890)
*Sanghun Jung,Daehoon Gwak,Byron Boots,James Hays*

Main category: cs.RO

TL;DR: 提出了一种基于神经过程（NPs）的地形高程建模方法，结合贝叶斯不确定性估计与神经网络效率，显著提升了实时性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如高斯过程和神经网络）无法同时满足实时性、精确估计和不确定性量化需求，限制了复杂越野环境下的导航规划与控制。

Method: 利用LiDAR和相机传感器的语义特征，结合局部球查询注意力机制，降低计算复杂度并保留关键空间信息。

Result: 在包含多种地形特征的越野数据集上表现优于基线方法，证明了NPs在复杂地形建模中的潜力。

Conclusion: NPs为地形高程建模提供了一种高效且表达力强的方法，适用于复杂越野环境。

Abstract: Terrain elevation modeling for off-road navigation aims to accurately
estimate changes in terrain geometry in real-time and quantify the
corresponding uncertainties. Having precise estimations and uncertainties plays
a crucial role in planning and control algorithms to explore safe and reliable
maneuver strategies. However, existing approaches, such as Gaussian Processes
(GPs) and neural network-based methods, often fail to meet these needs. They
are either unable to perform in real-time due to high computational demands,
underestimating sharp geometry changes, or harming elevation accuracy when
learned with uncertainties. Recently, Neural Processes (NPs) have emerged as a
promising approach that integrates the Bayesian uncertainty estimation of GPs
with the efficiency and flexibility of neural networks. Inspired by NPs, we
propose an effective NP-based method that precisely estimates sharp elevation
changes and quantifies the corresponding predictive uncertainty without losing
elevation accuracy. Our method leverages semantic features from LiDAR and
camera sensors to improve interpolation and extrapolation accuracy in
unobserved regions. Also, we introduce a local ball-query attention mechanism
to effectively reduce the computational complexity of global attention by 17\%
while preserving crucial local and spatial information. We evaluate our method
on off-road datasets having interesting geometric features, collected from
trails, deserts, and hills. Our results demonstrate superior performance over
baselines and showcase the potential of neural processes for effective and
expressive terrain modeling in complex off-road environments.

</details>


### [33] [Constraint-Preserving Data Generation for Visuomotor Policy Learning](https://arxiv.org/abs/2508.03944)
*Kevin Lin,Varun Ragunath,Andrew McAlinden,Aaditya Prasad,Jimmy Wu,Yuke Zhu,Jeannette Bohg*

Main category: cs.RO

TL;DR: CP-Gen是一种利用单条专家轨迹生成机器人演示数据的方法，支持新物体几何和姿态的生成，用于训练闭环视觉运动策略，实现零样本迁移和泛化。


<details>
  <summary>Details</summary>
Motivation: 大规模机器人演示数据收集成本高且耗时，CP-Gen旨在通过单条专家轨迹生成多样化的数据，解决这一问题。

Method: CP-Gen将专家轨迹分解为自由空间运动和机器人技能，通过关键点轨迹约束实现几何感知的数据生成，采样姿态和几何变换后优化机器人关节配置。

Result: 在16个仿真任务和4个真实任务中，CP-Gen训练的策略平均成功率为77%，优于基线方法的50%。

Conclusion: CP-Gen通过高效数据生成方法显著提升了机器人策略的性能和泛化能力。

Abstract: Large-scale demonstration data has powered key breakthroughs in robot
manipulation, but collecting that data remains costly and time-consuming. We
present Constraint-Preserving Data Generation (CP-Gen), a method that uses a
single expert trajectory to generate robot demonstrations containing novel
object geometries and poses. These generated demonstrations are used to train
closed-loop visuomotor policies that transfer zero-shot to the real world and
generalize across variations in object geometries and poses. Similar to prior
work using pose variations for data generation, CP-Gen first decomposes expert
demonstrations into free-space motions and robot skills. But unlike those
works, we achieve geometry-aware data generation by formulating robot skills as
keypoint-trajectory constraints: keypoints on the robot or grasped object must
track a reference trajectory defined relative to a task-relevant object. To
generate a new demonstration, CP-Gen samples pose and geometry transforms for
each task-relevant object, then applies these transforms to the object and its
associated keypoints or keypoint trajectories. We optimize robot joint
configurations so that the keypoints on the robot or grasped object track the
transformed keypoint trajectory, and then motion plan a collision-free path to
the first optimized joint configuration. Experiments on 16 simulation tasks and
four real-world tasks, featuring multi-stage, non-prehensile and
tight-tolerance manipulation, show that policies trained using CP-Gen achieve
an average success rate of 77%, outperforming the best baseline that achieves
an average of 50%.

</details>


### [34] [Optimization of sliding control parameters for a 3-dof robot arm using genetic algorithm (GA)](https://arxiv.org/abs/2508.04009)
*Vu Ngoc Son,Pham Van Cuong,Dao Thi My Linh,Le Tieu Nien*

Main category: cs.RO

TL;DR: 本文提出了一种基于遗传算法优化机器人滑模控制参数的方法，以提高轨迹跟踪精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 滑模控制（SMC）在机器人轨迹跟踪中表现优异，但其性能和鲁棒性依赖于参数选择，传统方法难以优化。

Method: 采用遗传算法（GA）自动寻找最优SMC参数，以满足性能需求。

Result: 仿真结果表明，GA-SMC方法比传统SMC和模糊SMC具有更好的跟踪能力和更小的抖动效应。

Conclusion: 遗传算法优化SMC参数是一种高效且鲁棒的方法，适用于机器人轨迹跟踪。

Abstract: This paper presents a method for optimizing the sliding mode control (SMC)
parameter for a robot manipulator applying a genetic algorithm (GA). The
objective of the SMC is to achieve precise and consistent tracking of the
trajectory of the robot manipulator under uncertain and disturbed conditions.
However, the system effectiveness and robustness depend on the choice of the
SMC parameters, which is a difficult and crucial task. To solve this problem, a
genetic algorithm is used to locate the optimal values of these parameters that
gratify the capability criteria. The proposed method is efficient compared with
the conventional SMC and Fuzzy-SMC. The simulation results show that the
genetic algorithm with SMC can achieve better tracking capability and reduce
the chattering effect.

</details>


### [35] [SCOUT: An in-vivo Methane Sensing System for Real-time Monitoring of Enteric Emissions in Cattle with ex-vivo Validation](https://arxiv.org/abs/2508.04056)
*Yuelin Deng,Hinayah Rojas de Oliveira,Richard M. Voyles,Upinder Kaur*

Main category: cs.RO

TL;DR: SCOUT系统通过创新的闭环气体循环设计，实现了对反刍动物瘤胃甲烷浓度的连续高分辨率监测，显著提升了数据保留率和监测精度，为可持续畜牧业提供了关键工具。


<details>
  <summary>Details</summary>
Motivation: 现有环境采样方法在数据保留率、环境干扰和时间分辨率方面存在局限，阻碍了通过遗传选择和精准管理提升畜牧业可持续性的进展。

Method: 开发了SCOUT系统，采用闭环气体循环设计，并在两头瘤胃瘘管牛上进行了全面验证，与传统环境嗅探系统进行了跨平台比较。

Result: SCOUT数据保留率达82%，远高于传统系统的17%，并捕捉到比环境方法高100-1000倍的甲烷浓度。高频监测揭示了行为与排放的新关联。

Conclusion: SCOUT系统是革命性进步，为基因组选择和精准畜牧业提供了准确、连续的排放表型数据，同时为农业传感器性能设定了新标准。

Abstract: Accurate measurement of enteric methane emissions remains a critical
bottleneck for advancing livestock sustainability through genetic selection and
precision management. Existing ambient sampling approaches suffer from low data
retention rates, environmental interference, and limited temporal resolution.
We developed SCOUT (Smart Cannula-mounted Optical Unit for Trace-methane), the
first robust in-vivo sensing system enabling continuous, high-resolution
monitoring of ruminal methane concentrations through an innovative closed-loop
gas recirculation design. We conducted comprehensive validation with two
cannulated Simmental heifers under contrasting dietary treatments, with
cross-platform comparison against established ambient sniffer systems. SCOUT
achieved exceptional performance with 82% data retention compared to 17% for
conventional sniffer systems, while capturing methane concentrations 100-1000x
higher than ambient approaches. Cross-platform validation demonstrated strong
scale-dependent correlations, with optimal correlation strength (r = -0.564
$\pm$ 0.007) at biologically relevant 40-minute windows and 100% statistical
significance. High-frequency monitoring revealed novel behavior-emission
coupling, including rapid concentration changes (14.5 $\pm$ 11.3k ppm)
triggered by postural transitions within 15 minutes, insights previously
inaccessible through existing technologies. The SCOUT system represents a
transformative advancement, enabling accurate, continuous emission phenotyping
essential for genomic selection programs and sustainable precision livestock
management. This validation framework establishes new benchmarks for
agricultural sensor performance while generating unprecedented biological
insights into ruminal methane dynamics, contributing essential tools for
sustainable livestock production in climate-conscious agricultural systems.

</details>


### [36] [DRIVE: Dynamic Rule Inference and Verified Evaluation for Constraint-Aware Autonomous Driving](https://arxiv.org/abs/2508.04066)
*Longling Geng,Huangxing Li,Viktor Lado Naess,Mert Pilanci*

Main category: cs.RO

TL;DR: DRIVE框架通过动态规则推断和验证评估，从专家演示中建模人类驾驶约束，结合概率表示和凸优化规划，实现动态可行且符合人类偏好的轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需理解隐含、上下文相关的软约束，但现有方法难以明确指定或泛化这些约束。

Method: DRIVE利用指数族似然建模估计状态转移可行性，构建概率化行为规则，嵌入凸优化规划模块。

Result: 实验显示DRIVE在多种驾驶场景中实现0.0%软约束违反率、更平滑轨迹和更强泛化能力。

Conclusion: DRIVE框架高效、可解释且鲁棒，适用于实际部署。

Abstract: Understanding and adhering to soft constraints is essential for safe and
socially compliant autonomous driving. However, such constraints are often
implicit, context-dependent, and difficult to specify explicitly. In this work,
we present DRIVE, a novel framework for Dynamic Rule Inference and Verified
Evaluation that models and evaluates human-like driving constraints from expert
demonstrations. DRIVE leverages exponential-family likelihood modeling to
estimate the feasibility of state transitions, constructing a probabilistic
representation of soft behavioral rules that vary across driving contexts.
These learned rule distributions are then embedded into a convex
optimization-based planning module, enabling the generation of trajectories
that are not only dynamically feasible but also compliant with inferred human
preferences. Unlike prior approaches that rely on fixed constraint forms or
purely reward-based modeling, DRIVE offers a unified framework that tightly
couples rule inference with trajectory-level decision-making. It supports both
data-driven constraint generalization and principled feasibility verification.
We validate DRIVE on large-scale naturalistic driving datasets, including inD,
highD, and RoundD, and benchmark it against representative inverse constraint
learning and planning baselines. Experimental results show that DRIVE achieves
0.0% soft constraint violation rates, smoother trajectories, and stronger
generalization across diverse driving scenarios. Verified evaluations further
demonstrate the efficiency, explanability, and robustness of the framework for
real-world deployment.

</details>


### [37] [Industrial Robot Motion Planning with GPUs: Integration of cuRobo for Extended DOF Systems](https://arxiv.org/abs/2508.04146)
*Luai Abuelsamen,Harsh Rana,Ho-Wei Lu,Wenhan Tang,Swati Priyadarshini,Gabriel Gomes*

Main category: cs.RO

TL;DR: 论文提出了一种基于GPU加速的运动规划方法，通过NVIDIA的cuRobo库和CAD数字孪生技术，实现了快速轨迹生成和动态碰撞避免。


<details>
  <summary>Details</summary>
Motivation: 工业机器人中高效运动规划是一个关键挑战，尤其是在复杂环境中操作的多轴系统。

Method: 集成GPU加速的运动规划（NVIDIA cuRobo库），利用CAD数字孪生和实时并行优化。

Result: 在配备额外自由度的机器人上展示了性能提升，规划速度和鲁棒性显著提高。

Conclusion: GPU为基础的规划流程在现代工业工作流中具有可扩展和适应性部署的潜力。

Abstract: Efficient motion planning remains a key challenge in industrial robotics,
especially for multi-axis systems operating in complex environments. This paper
addresses that challenge by integrating GPU-accelerated motion planning through
NVIDIA's cuRobo library into Vention's modular automation platform. By
leveraging accurate CAD-based digital twins and real-time parallel
optimization, our system enables rapid trajectory generation and dynamic
collision avoidance for pick-and-place tasks. We demonstrate this capability on
robots equipped with additional degrees of freedom, including a 7th-axis
gantry, and benchmark performance across various scenarios. The results show
significant improvements in planning speed and robustness, highlighting the
potential of GPU-based planning pipelines for scalable, adaptable deployment in
modern industrial workflows.

</details>


### [38] [Improving Tactile Gesture Recognition with Optical Flow](https://arxiv.org/abs/2508.04338)
*Shaohong Zhong,Alessandro Albini,Giammarco Caroleo,Giorgio Cannata,Perla Maiolino*

Main category: cs.RO

TL;DR: 通过计算密集光流增强触觉图像动态信息，提升触觉手势识别分类器准确率9%。


<details>
  <summary>Details</summary>
Motivation: 触觉手势识别在人机交互中至关重要，但仅凭触觉图像难以区分某些相似手势。

Method: 提出在触觉图像中计算密集光流，突出接触动态信息，作为分类器输入。

Result: 实验显示，使用光流增强触觉图像的分类器准确率提升9%。

Conclusion: 通过增强触觉图像的动态信息，能有效提升手势识别准确率。

Abstract: Tactile gesture recognition systems play a crucial role in Human-Robot
Interaction (HRI) by enabling intuitive communication between humans and
robots. The literature mainly addresses this problem by applying machine
learning techniques to classify sequences of tactile images encoding the
pressure distribution generated when executing the gestures. However, some
gestures can be hard to differentiate based on the information provided by
tactile images alone. In this paper, we present a simple yet effective way to
improve the accuracy of a gesture recognition classifier. Our approach focuses
solely on processing the tactile images used as input by the classifier. In
particular, we propose to explicitly highlight the dynamics of the contact in
the tactile image by computing the dense optical flow. This additional
information makes it easier to distinguish between gestures that produce
similar tactile images but exhibit different contact dynamics. We validate the
proposed approach in a tactile gesture recognition task, showing that a
classifier trained on tactile images augmented with optical flow information
achieved a 9% improvement in gesture classification accuracy compared to one
trained on standard tactile images.

</details>


### [39] [Tactile Comfort: Lowering Heart Rate Through Interactions](https://arxiv.org/abs/2508.04372)
*Morten Roed Frederiksen,Kasper Støy,Maja Matarić*

Main category: cs.RO

TL;DR: 研究探讨了一种无需预先训练的口袋伴侣机器人，通过触觉游戏分散注意力，显著降低儿童心率。


<details>
  <summary>Details</summary>
Motivation: 现有焦虑管理策略需预先训练，研究旨在开发一种即时有效的放松工具。

Method: 采用触觉游戏机器人，通过两项研究（14天试点和主研究）测量儿童心率变化。

Result: 机器人互动显著降低心率（p<0.01），显示一致镇静效果。

Conclusion: 触觉伴侣机器人可增强放松技术的治疗潜力。

Abstract: Children diagnosed with anxiety disorders are taught a range of strategies to
navigate situations of heightened anxiety. Techniques such as deep breathing
and repetition of mantras are commonly employed, as they are known to be
calming and reduce elevated heart rates. Although these strategies are often
effective, their successful application relies on prior training of the
children for successful use when faced with challenging situations. This paper
investigates a pocket-sized companion robot designed to offer a relaxation
technique requiring no prior training, with a focus on immediate impact on the
user's heart rate. The robot utilizes a tactile game to divert the user's
attention, thereby promoting relaxation. We conducted two studies with children
who were not diagnosed with anxiety: a 14-day pilot study with two children
(age 8) and a main study with 18 children (ages 7-8). Both studies employed a
within-subjects design and focused on measuring heart rate during tactile
interaction with the robot and during non-use. Interacting with the robot was
found to significantly lower the study participants' heart rate (p$<$0.01)
compared to the non-use condition, indicating a consistent calming effect
across all participants. These results suggest that tactile companion robots
have the potential to enhance the therapeutic value of relaxation techniques.

</details>


### [40] [Incorporating Stochastic Models of Controller Behavior into Kinodynamic Efficiently Adaptive State Lattices for Mobile Robot Motion Planning in Off-Road Environments](https://arxiv.org/abs/2508.04384)
*Eric R. Damm,Eli S. Lancaster,Felix A. Sanchez,Kiana Bronder,Jason M. Gregory,Thomas M. Howard*

Main category: cs.RO

TL;DR: 论文提出三种方法，将随机控制器行为融入KEASL规划器的搜索空间，以减少物理机器人运动中的不确定性影响。实验表明，该方法能生成更保守的轨迹，降低碰撞概率。


<details>
  <summary>Details</summary>
Motivation: 物理机器人运动规划中，理论模型因现实物理和底层控制器的不确定性而产生误差，需改进以提高可靠性。

Method: 在KEASL规划器中引入三种随机控制器行为采样方法，并通过实验验证其在非结构化环境中的效果。

Result: 实验显示，随机采样方法生成的轨迹更保守，碰撞预测概率降低，但与基线规划相比，成功率有所下降。

Conclusion: 随机控制器采样能有效减少碰撞风险，但需权衡规划成功率，适用于对安全性要求高的场景。

Abstract: Mobile robot motion planners rely on theoretical models to predict how the
robot will move through the world. However, when deployed on a physical robot,
these models are subject to errors due to real-world physics and uncertainty in
how the lower-level controller follows the planned trajectory. In this work, we
address this problem by presenting three methods of incorporating stochastic
controller behavior into the recombinant search space of the Kinodynamic
Efficiently Adaptive State Lattice (KEASL) planner. To demonstrate this work,
we analyze the results of experiments performed on a Clearpath Robotics Warthog
Unmanned Ground Vehicle (UGV) in an off-road, unstructured environment using
two different perception algorithms, and performed an ablation study using a
full spectrum of simulated environment map complexities. Analysis of the data
found that incorporating stochastic controller sampling into KEASL leads to
more conservative trajectories that decrease predicted collision likelihood
when compared to KEASL without sampling. When compared to baseline planning
with expanded obstacle footprints, the predicted likelihood of collisions
becomes more comparable, but reduces the planning success rate for baseline
search.

</details>


### [41] [Reliable and Real-Time Highway Trajectory Planning via Hybrid Learning-Optimization Frameworks](https://arxiv.org/abs/2508.04436)
*Yujia Lu,Chong Wei,Lu Ma*

Main category: cs.RO

TL;DR: 提出了一种混合轨迹规划框架，结合学习方法和优化方法，实现高效安全的自动驾驶高速公路行驶。


<details>
  <summary>Details</summary>
Motivation: 高速公路驾驶环境变化快且反应时间有限，需可靠高效的轨迹规划以减少碰撞风险。

Method: 采用双层架构：上层用图神经网络预测速度，下层用混合整数二次规划优化路径，并引入线性近似降低计算复杂度。

Result: 实验显示规划器在复杂紧急场景中生成平滑无碰撞轨迹，成功率超97%，平均规划时间54毫秒。

Conclusion: 该框架在保证安全的同时实现了实时性能，适用于高速公路自动驾驶。

Abstract: Autonomous highway driving presents a high collision risk due to
fast-changing environments and limited reaction time, necessitating reliable
and efficient trajectory planning. This paper proposes a hybrid trajectory
planning framework that integrates the adaptability of learning-based methods
with the formal safety guarantees of optimization-based approaches. The
framework features a two-layer architecture: an upper layer employing a graph
neural network (GNN) trained on real-world highway data to predict human-like
longitudinal velocity profiles, and a lower layer utilizing path optimization
formulated as a mixed-integer quadratic programming (MIQP) problem. The primary
contribution is the lower-layer path optimization model, which introduces a
linear approximation of discretized vehicle geometry to substantially reduce
computational complexity, while enforcing strict spatiotemporal non-overlapping
constraints to formally guarantee collision avoidance throughout the planning
horizon. Experimental results demonstrate that the planner generates highly
smooth, collision-free trajectories in complex real-world emergency scenarios,
achieving success rates exceeding 97% with average planning times of 54 ms,
thereby confirming real-time capability.

</details>


### [42] [Behaviorally Adaptive Multi-Robot Hazard Localization in Failure-Prone, Communication-Denied Environments](https://arxiv.org/abs/2508.04537)
*Alkesh K. Srivastava,Aamodh Suresh,Carlos Nieto-Granda*

Main category: cs.RO

TL;DR: 论文提出了一种基于行为熵的多机器人自适应路径规划框架（BAPP），用于高风险、通信受限环境中的自主危险地图构建。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在高风险、易失败、通信受限环境（如灾后区域、地下矿井等）中的自主探索与地图构建问题。

Method: 提出了行为熵（BE）概念，并基于此设计了BAPP框架，包含两种算法：BAPP-TID（智能触发高保真机器人）和BAPP-SIG（高风险下的安全部署）。

Result: BAPP框架在单机器人和多机器人模拟中表现优于基于香农熵和随机策略的方法，BAPP-TID加速熵减，BAPP-SIG提高机器人存活率。

Conclusion: 行为自适应规划在复杂、高风险环境中具有显著优势，BAPP框架通过空间分区和角色异构实现了高效扩展。

Abstract: We address the challenge of multi-robot autonomous hazard mapping in
high-risk, failure-prone, communication-denied environments such as
post-disaster zones, underground mines, caves, and planetary surfaces. In these
missions, robots must explore and map hazards while minimizing the risk of
failure due to environmental threats or hardware limitations. We introduce a
behavior-adaptive, information-theoretic planning framework for multi-robot
teams grounded in the concept of Behavioral Entropy (BE), that generalizes
Shannon entropy (SE) to capture diverse human-like uncertainty evaluations.
Building on this formulation, we propose the Behavior-Adaptive Path Planning
(BAPP) framework, which modulates information gathering strategies via a
tunable risk-sensitivity parameter, and present two planning algorithms:
BAPP-TID for intelligent triggering of high-fidelity robots, and BAPP-SIG for
safe deployment under high risk. We provide theoretical insights on the
informativeness of the proposed BAPP framework and validate its effectiveness
through both single-robot and multi-robot simulations. Our results show that
the BAPP stack consistently outperforms Shannon-based and random strategies:
BAPP-TID accelerates entropy reduction, while BAPP-SIG improves robot
survivability with minimal loss in information gain. In multi-agent
deployments, BAPP scales effectively through spatial partitioning, mobile base
relocation, and role-aware heterogeneity. These findings underscore the value
of behavior-adaptive planning for robust, risk-sensitive exploration in
complex, failure-prone environments.

</details>


### [43] [$NavA^3$: Understanding Any Instruction, Navigating Anywhere, Finding Anything](https://arxiv.org/abs/2508.04598)
*Lingfeng Zhang,Xiaoshuai Hao,Yingbo Tang,Haoxiang Fu,Xinyu Zheng,Pengwei Wang,Zhongyuan Wang,Wenbo Ding,Shanghang Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种名为$NavA^3$的分层框架，用于解决复杂开放场景中的长时程导航任务，结合全局和局部策略，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有导航任务局限于预定义对象或指令跟随，无法满足真实场景中复杂开放需求，因此需要一种能理解高级人类指令并实现空间感知导航的方法。

Method: 采用分层框架：全局策略利用Reasoning-VLM解析指令并结合3D场景视图；局部策略通过NaviAfford模型（PointingVLM）实现开放词汇对象定位和空间感知。

Result: $NavA^3$在导航性能上达到SOTA，成功完成不同机器人平台的长时程导航任务。

Conclusion: $NavA^3$为通用导航提供了新方向，数据集和代码将公开。

Abstract: Embodied navigation is a fundamental capability of embodied intelligence,
enabling robots to move and interact within physical environments. However,
existing navigation tasks primarily focus on predefined object navigation or
instruction following, which significantly differs from human needs in
real-world scenarios involving complex, open-ended scenes. To bridge this gap,
we introduce a challenging long-horizon navigation task that requires
understanding high-level human instructions and performing spatial-aware object
navigation in real-world environments. Existing embodied navigation methods
struggle with such tasks due to their limitations in comprehending high-level
human instructions and localizing objects with an open vocabulary. In this
paper, we propose $NavA^3$, a hierarchical framework divided into two stages:
global and local policies. In the global policy, we leverage the reasoning
capabilities of Reasoning-VLM to parse high-level human instructions and
integrate them with global 3D scene views. This allows us to reason and
navigate to regions most likely to contain the goal object. In the local
policy, we have collected a dataset of 1.0 million samples of spatial-aware
object affordances to train the NaviAfford model (PointingVLM), which provides
robust open-vocabulary object localization and spatial awareness for precise
goal identification and navigation in complex environments. Extensive
experiments demonstrate that $NavA^3$ achieves SOTA results in navigation
performance and can successfully complete longhorizon navigation tasks across
different robot embodiments in real-world settings, paving the way for
universal embodied navigation. The dataset and code will be made available.
Project website: https://NavigationA3.github.io/.

</details>


### [44] [RoboTron-Sim: Improving Real-World Driving via Simulated Hard-Case](https://arxiv.org/abs/2508.04642)
*Baihui Xiao,Chengjian Feng,Zhijian Huang,Feng yan,Yujie Zhong,Lin Ma*

Main category: cs.RO

TL;DR: RoboTron-Sim通过模拟高风险场景提升自动驾驶系统在关键情况下的表现，包括开发HASS数据集和引入SPE与I2E编码器。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界中罕见高风险场景数据不足导致自动驾驶系统性能不佳的问题。

Method: 开发HASS模拟数据集，引入SPE和I2E编码器，利用多模态大语言模型学习驾驶技能。

Result: 在nuScenes上实验显示，驾驶性能提升约50%，达到开环规划的最先进水平。

Conclusion: RoboTron-Sim能有效管理罕见高风险驾驶场景，提升自动驾驶系统性能。

Abstract: Collecting real-world data for rare high-risk scenarios, long-tailed driving
events, and complex interactions remains challenging, leading to poor
performance of existing autonomous driving systems in these critical
situations. In this paper, we propose RoboTron-Sim that improves real-world
driving in critical situations by utilizing simulated hard cases. First, we
develop a simulated dataset called Hard-case Augmented Synthetic Scenarios
(HASS), which covers 13 high-risk edge-case categories, as well as balanced
environmental conditions such as day/night and sunny/rainy. Second, we
introduce Scenario-aware Prompt Engineering (SPE) and an Image-to-Ego Encoder
(I2E Encoder) to enable multimodal large language models to effectively learn
real-world challenging driving skills from HASS, via adapting to environmental
deviations and hardware differences between real-world and simulated scenarios.
Extensive experiments on nuScenes show that RoboTron-Sim improves driving
performance in challenging scenarios by around 50%, achieving state-of-the-art
results in real-world open-loop planning. Qualitative results further
demonstrate the effectiveness of RoboTron-Sim in better managing rare high-risk
driving scenarios. Project page: https://stars79689.github.io/RoboTron-Sim/

</details>


### [45] [Open Scene Graphs for Open-World Object-Goal Navigation](https://arxiv.org/abs/2508.04678)
*Joel Loo,Zhanxin Wu,David Hsu*

Main category: cs.RO

TL;DR: OSG Navigator是一个基于基础模型的模块化系统，用于开放世界的目标导航（ObjectNav），通过Open Scene Graph表示作为空间记忆，实现零样本适应新环境。


<details>
  <summary>Details</summary>
Motivation: 解决开放世界语义导航的挑战，如在新环境中通过自然语言搜索目标对象。

Method: 使用Open Scene Graph表示作为空间记忆，通过OSG模式层次化组织空间信息，模式可自动生成。

Result: 在Fetch和Spot机器人上的实验表明，OSG Navigator在ObjectNav基准测试中达到最先进性能，并能零样本适应多样目标、环境和机器人形态。

Conclusion: OSG Navigator通过基础模型和Open Scene Graph，有效解决了开放世界语义导航问题，展示了强大的适应性和泛化能力。

Abstract: How can we build general-purpose robot systems for open-world semantic
navigation, e.g., searching a novel environment for a target object specified
in natural language? To tackle this challenge, we introduce OSG Navigator, a
modular system composed of foundation models, for open-world Object-Goal
Navigation (ObjectNav). Foundation models provide enormous semantic knowledge
about the world, but struggle to organise and maintain spatial information
effectively at scale. Key to OSG Navigator is the Open Scene Graph
representation, which acts as spatial memory for OSG Navigator. It organises
spatial information hierarchically using OSG schemas, which are templates, each
describing the common structure of a class of environments. OSG schemas can be
automatically generated from simple semantic labels of a given environment,
e.g., "home" or "supermarket". They enable OSG Navigator to adapt zero-shot to
new environment types. We conducted experiments using both Fetch and Spot
robots in simulation and in the real world, showing that OSG Navigator achieves
state-of-the-art performance on ObjectNav benchmarks and generalises zero-shot
over diverse goals, environments, and robot embodiments.

</details>


### [46] [From MAS to MARS: Coordination Failures and Reasoning Trade-offs in Hierarchical Multi-Agent Robotic Systems within a Healthcare Scenario](https://arxiv.org/abs/2508.04691)
*Yuanchen Bai,Zijian Ding,Shaoyue Wen,Xiang Chang,Angelique Taylor*

Main category: cs.RO

TL;DR: 论文研究了多智能体机器人系统（MARS）在实际部署中的性能权衡问题，通过两项模拟医疗场景的实验，分析了协调失败和改进通信结构的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管多智能体框架技术先进，但其在机器人上的实际应用受限，阻碍了MARS研究的实践进展。

Method: 研究1使用CrewAI迭代优化知识库，识别协调失败；研究2使用AutoGen评估双向通信结构，比较推理与非推理模型的性能。

Result: 研究发现自主性与稳定性之间存在张力，边缘案例测试对系统可靠性和安全性至关重要。

Conclusion: 强调改进系统可靠性和安全性的重要性，为未来实际部署提供参考。

Abstract: Multi-agent robotic systems (MARS) build upon multi-agent systems by
integrating physical and task-related constraints, increasing the complexity of
action execution and agent coordination. However, despite the availability of
advanced multi-agent frameworks, their real-world deployment on robots remains
limited, hindering the advancement of MARS research in practice. To bridge this
gap, we conducted two studies to investigate performance trade-offs of
hierarchical multi-agent frameworks in a simulated real-world multi-robot
healthcare scenario. In Study 1, using CrewAI, we iteratively refine the
system's knowledge base, to systematically identify and categorize coordination
failures (e.g., tool access violations, lack of timely handling of failure
reports) not resolvable by providing contextual knowledge alone. In Study 2,
using AutoGen, we evaluate a redesigned bidirectional communication structure
and further measure the trade-offs between reasoning and non-reasoning models
operating within the same robotic team setting. Drawing from our empirical
findings, we emphasize the tension between autonomy and stability and the
importance of edge-case testing to improve system reliability and safety for
future real-world deployment. Supplementary materials, including codes, task
agent setup, trace outputs, and annotated examples of coordination failures and
reasoning behaviors, are available at:
https://byc-sophie.github.io/mas-to-mars/.

</details>


### [47] [Achieving Precise and Reliable Locomotion with Differentiable Simulation-Based System Identification](https://arxiv.org/abs/2508.04696)
*Vyacheslav Kovalev,Ekaterina Chaikovskaia,Egor Davydenko,Roman Gorbachev*

Main category: cs.RO

TL;DR: 提出了一种结合系统辨识和强化学习的新型控制框架，利用可微分仿真优化系统参数，仅需轨迹数据和控制输入即可估计参数，显著提升轨迹跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 在双足行走中，准确的系统辨识对减少轨迹漂移至关重要，尤其是在强化学习和基于模型的控制中。传统方法依赖直接扭矩测量，而新方法仅需轨迹数据和控制输入。

Method: 利用可微分仿真器MuJoCo-XLA优化系统参数，使仿真机器人行为与实际运动一致。支持质量和惯性等物理属性，并通过神经网络近似处理复杂非线性行为（如摩擦模型）。

Result: 实验结果表明，该框架显著改善了轨迹跟踪性能。

Conclusion: 该框架实现了可扩展且灵活的参数优化，为双足行走中的系统辨识提供了高效解决方案。

Abstract: Accurate system identification is crucial for reducing trajectory drift in
bipedal locomotion, particularly in reinforcement learning and model-based
control. In this paper, we present a novel control framework that integrates
system identification into the reinforcement learning training loop using
differentiable simulation. Unlike traditional approaches that rely on direct
torque measurements, our method estimates system parameters using only
trajectory data (positions, velocities) and control inputs. We leverage the
differentiable simulator MuJoCo-XLA to optimize system parameters, ensuring
that simulated robot behavior closely aligns with real-world motion. This
framework enables scalable and flexible parameter optimization. Accurate system
identification is crucial for reducing trajectory drift in bipedal locomotion,
particularly in reinforcement learning and model-based control. In this paper,
we present a novel control framework that integrates system identification into
the reinforcement learning training loop using differentiable simulation.
Unlike traditional approaches that rely on direct torque measurements, our
method estimates system parameters using only trajectory data (positions,
velocities) and control inputs. We leverage the differentiable simulator
MuJoCo-XLA to optimize system parameters, ensuring that simulated robot
behavior closely aligns with real-world motion. This framework enables scalable
and flexible parameter optimization. It supports fundamental physical
properties such as mass and inertia. Additionally, it handles complex system
nonlinear behaviors, including advanced friction models, through neural network
approximations. Experimental results show that our framework significantly
improves trajectory following.

</details>
