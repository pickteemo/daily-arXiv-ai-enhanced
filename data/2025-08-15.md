<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 23]
- [cs.AI](#cs.AI) [Total: 31]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [WiFi-based Global Localization in Large-Scale Environments Leveraging Structural Priors from osmAG](https://arxiv.org/abs/2508.10144)
*Xu Ma,Jiajie Zhang,Fujing Xie,Sören Schwertfeger*

Main category: cs.RO

TL;DR: 提出了一种基于WiFi和OpenStreetMap Area Graph（osmAG）的室内定位框架，结合信号传播建模与几何拓扑先验，显著提高了定位精度和空间效率。


<details>
  <summary>Details</summary>
Motivation: 解决GPS信号缺失的室内环境中机器人全局定位问题，利用现有WiFi基础设施和osmAG提供低成本、可扩展的解决方案。

Method: 离线阶段通过迭代优化算法定位WiFi接入点（AP），在线阶段利用增强osmAG地图进行实时定位，结合信号传播模型和指纹数据。

Result: 离线阶段AP定位误差3.79米（比三边测量提升35.3%），在线阶段指纹区域误差3.12米（比KNN指纹提升8.77%），非指纹区域误差3.83米（提升81.05%）。

Conclusion: 该框架在复杂多楼层环境中验证有效，解决了绑架机器人问题，提供了高精度、空间高效的室内定位方案。

Abstract: Global localization is essential for autonomous robotics, especially in
indoor environments where the GPS signal is denied. We propose a novel
WiFi-based localization framework that leverages ubiquitous wireless
infrastructure and the OpenStreetMap Area Graph (osmAG) for large-scale indoor
environments. Our approach integrates signal propagation modeling with osmAG's
geometric and topological priors. In the offline phase, an iterative
optimization algorithm localizes WiFi Access Points (APs) by modeling wall
attenuation, achieving a mean localization error of 3.79 m (35.3\% improvement
over trilateration). In the online phase, real-time robot localization uses the
augmented osmAG map, yielding a mean error of 3.12 m in fingerprinted areas
(8.77\% improvement over KNN fingerprinting) and 3.83 m in non-fingerprinted
areas (81.05\% improvement). Comparison with a fingerprint-based method shows
that our approach is much more space efficient and achieves superior
localization accuracy, especially for positions where no fingerprint data are
available. Validated across a complex 11,025 &m^2& multi-floor environment,
this framework offers a scalable, cost-effective solution for indoor robotic
localization, solving the kidnapped robot problem. The code and dataset are
available at https://github.com/XuMa369/osmag-wifi-localization.

</details>


### [2] [Systematic Constraint Formulation and Collision-Free Trajectory Planning Using Space-Time Graphs of Convex Sets](https://arxiv.org/abs/2508.10203)
*Matthew D. Osburn,Cameron K. Peterson,John L. Salmon*

Main category: cs.RO

TL;DR: 论文提出了一种通过动态杂乱环境生成最优无碰撞时间依赖轨迹的方法，利用ST-GCS框架无需初始猜测即可求解。


<details>
  <summary>Details</summary>
Motivation: 解决在动态环境中因空间和时间约束导致难以找到数值求解器初始猜测的问题。

Method: 采用ST-GCS框架生成最优无碰撞轨迹，并探索通用GCS兼容约束的推导与适配策略。

Result: ST-GCS在静态环境中与标准GCS等效，在动态环境中能生成最小距离无碰撞轨迹。

Conclusion: ST-GCS框架有效解决了动态环境中的轨迹规划问题，无需初始猜测即可生成最优解。

Abstract: In this paper, we create optimal, collision-free, time-dependent trajectories
through cluttered dynamic environments. The many spatial and temporal
constraints make finding an initial guess for a numerical solver difficult.
Graphs of Convex Sets (GCS) and the recently developed Space-Time Graphs of
Convex Sets formulation (ST-GCS) enable us to generate optimal minimum distance
collision-free trajectories without providing an initial guess to the solver.
We also explore the derivation of general GCS-compatible constraints and
document an intuitive strategy for adapting general constraints to the
framework. We show that ST-GCS produces equivalent trajectories to the standard
GCS formulation when the environment is static. We then show ST-GCS operating
in dynamic environments to find minimum distance collision-free trajectories.

</details>


### [3] [Hybrid Data-Driven Predictive Control for Robust and Reactive Exoskeleton Locomotion Synthesis](https://arxiv.org/abs/2508.10269)
*Kejun Li,Jeeseop Kim,Maxime Brunet,Marine Pétriaux,Yisong Yue,Aaron D. Ames*

Main category: cs.RO

TL;DR: 提出了一种混合数据驱动的预测控制框架（HDDPC），用于外骨骼机器人的动态步态规划，结合接触调度和轨迹规划，提升环境适应性。


<details>
  <summary>Details</summary>
Motivation: 解决外骨骼机器人在动态环境中实时反应的需求，提升步态的鲁棒性和适应性。

Method: 采用Hankel矩阵建模系统动力学，结合步间（S2S）转换，实现接触调度与轨迹规划的统一。

Result: 在Atalante外骨骼上验证，展示了更强的鲁棒性和适应性。

Conclusion: HDDPC框架为动态环境中的外骨骼步态规划提供了高效、统一的解决方案。

Abstract: Robust bipedal locomotion in exoskeletons requires the ability to dynamically
react to changes in the environment in real time. This paper introduces the
hybrid data-driven predictive control (HDDPC) framework, an extension of the
data-enabled predictive control, that addresses these challenges by
simultaneously planning foot contact schedules and continuous domain
trajectories. The proposed framework utilizes a Hankel matrix-based
representation to model system dynamics, incorporating step-to-step (S2S)
transitions to enhance adaptability in dynamic environments. By integrating
contact scheduling with trajectory planning, the framework offers an efficient,
unified solution for locomotion motion synthesis that enables robust and
reactive walking through online replanning. We validate the approach on the
Atalante exoskeleton, demonstrating improved robustness and adaptability.

</details>


### [4] [ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver](https://arxiv.org/abs/2508.10333)
*Wenxuan Song,Ziyang Zhou,Han Zhao,Jiayi Chen,Pengxiang Ding,Haodong Yan,Yuxin Huang,Feilong Tang,Donglin Wang,Haoang Li*

Main category: cs.RO

TL;DR: ReconVLA提出了一种隐式接地范式，通过重构目标区域的视觉注意力，提升VLA模型在任务中的精确操作能力。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在视觉注意力分配上表现分散，无法准确聚焦目标区域，影响了任务执行效果。

Method: 提出ReconVLA，利用扩散变换器重构图像中的注视区域，引导模型学习细粒度表示并准确分配视觉注意力。

Result: 实验表明，ReconVLA在仿真和现实场景中均表现出优越的精确操作和泛化能力。

Conclusion: ReconVLA通过隐式接地范式有效提升了VLA模型的视觉注意力分配和任务执行精度。

Abstract: Recent advances in Vision-Language-Action (VLA) models have enabled robotic
agents to integrate multimodal understanding with action execution. However,
our empirical analysis reveals that current VLAs struggle to allocate visual
attention to target regions. Instead, visual attention is always dispersed. To
guide the visual attention grounding on the correct target, we propose
ReconVLA, a reconstructive VLA model with an implicit grounding paradigm.
Conditioned on the model's visual outputs, a diffusion transformer aims to
reconstruct the gaze region of the image, which corresponds to the target
manipulated objects. This process prompts the VLA model to learn fine-grained
representations and accurately allocate visual attention, thus effectively
leveraging task-specific visual information and conducting precise
manipulation. Moreover, we curate a large-scale pretraining dataset comprising
over 100k trajectories and 2 million data samples from open-source robotic
datasets, further boosting the model's generalization in visual reconstruction.
Extensive experiments in simulation and the real world demonstrate the
superiority of our implicit grounding method, showcasing its capabilities of
precise manipulation and generalization. Our project page is
https://zionchow.github.io/ReconVLA/.

</details>


### [5] [BEASST: Behavioral Entropic Gradient based Adaptive Source Seeking for Mobile Robots](https://arxiv.org/abs/2508.10363)
*Donipolo Ghimire,Aamodh Suresh,Carlos Nieto-Granda,Solmaz S. Kia*

Main category: cs.RO

TL;DR: BEASST是一种新型机器人源搜索框架，通过行为熵和概率加权函数动态调整机器人行为，在复杂未知环境中高效平衡探索与利用。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在未知环境中源搜索时探索与利用的平衡问题，提高搜索效率和适应性。

Method: 利用行为熵和Prelec概率加权函数定义目标函数，动态调整机器人行为（从风险规避到风险寻求），并结合理论收敛保证和实际稳定性。

Result: 实验表明，BEASST在路径长度减少15%和源定位速度提高20%方面优于现有方法。

Conclusion: BEASST通过智能不确定性驱动导航，在复杂环境中表现出色，为机器人源搜索提供了高效解决方案。

Abstract: This paper presents BEASST (Behavioral Entropic Gradient-based Adaptive
Source Seeking for Mobile Robots), a novel framework for robotic source seeking
in complex, unknown environments. Our approach enables mobile robots to
efficiently balance exploration and exploitation by modeling normalized signal
strength as a surrogate probability of source location. Building on Behavioral
Entropy(BE) with Prelec's probability weighting function, we define an
objective function that adapts robot behavior from risk-averse to risk-seeking
based on signal reliability and mission urgency. The framework provides
theoretical convergence guarantees under unimodal signal assumptions and
practical stability under bounded disturbances. Experimental validation across
DARPA SubT and multi-room scenarios demonstrates that BEASST consistently
outperforms state-of-the-art methods, achieving 15% reduction in path length
and 20% faster source localization through intelligent uncertainty-driven
navigation that dynamically transitions between aggressive pursuit and cautious
exploration.

</details>


### [6] [Few-shot Vision-based Human Activity Recognition with MLLM-based Visual Reinforcement Learning](https://arxiv.org/abs/2508.10371)
*Wenqi Zheng,Yutaka Arakawa*

Main category: cs.RO

TL;DR: 论文提出了一种名为FAVOR的方法，通过视觉强化学习扩展多模态大语言模型在少样本人类活动识别（HAR）中的应用，显著提升了模型的泛化能力和推理能力。


<details>
  <summary>Details</summary>
Motivation: 在少样本数据场景下，强化学习在人类活动识别领域的应用尚未充分探索，因此研究如何利用视觉强化学习提升模型的性能。

Method: 结合多模态大语言模型（MLLM）生成候选响应，通过奖励函数评估并使用GRPO算法优化模型，实现少样本适应。

Result: 在四个HAR数据集和五种不同设置下的实验证明了FAVOR方法的优越性。

Conclusion: FAVOR方法通过视觉强化学习有效提升了少样本人类活动识别的性能，并增强了模型的推理和可解释性。

Abstract: Reinforcement learning in large reasoning models enables learning from
feedback on their outputs, making it particularly valuable in scenarios where
fine-tuning data is limited. However, its application in multi-modal human
activity recognition (HAR) domains remains largely underexplored. Our work
extends reinforcement learning to the human activity recognition domain with
multimodal large language models. By incorporating visual reinforcement
learning in the training process, the model's generalization ability on
few-shot recognition can be greatly improved. Additionally, visual
reinforcement learning can enhance the model's reasoning ability and enable
explainable analysis in the inference stage. We name our few-shot human
activity recognition method with visual reinforcement learning FAVOR.
Specifically, our approach first utilizes a multimodal large language model
(MLLM) to generate multiple candidate responses for the human activity image,
each containing reasoning traces and final answers. These responses are then
evaluated using reward functions, and the MLLM model is subsequently optimized
using the Group Relative Policy Optimization (GRPO) algorithm. In this way, the
MLLM model can be adapted to human activity recognition with only a few
samples. Extensive experiments on four human activity recognition datasets and
five different settings demonstrate the superiority of the proposed method.

</details>


### [7] [A Semantic-Aware Framework for Safe and Intent-Integrative Assistance in Upper-Limb Exoskeletons](https://arxiv.org/abs/2508.10378)
*Yu Chen,Shu Miao,Chunyu Wu,Jingsong Mu,Bo OuYang,Xiang Li*

Main category: cs.RO

TL;DR: 本文提出了一种语义感知框架，通过整合大语言模型到任务规划中，使上肢外骨骼能根据任务语义调整辅助配置，提升安全性和意图整合能力。


<details>
  <summary>Details</summary>
Motivation: 现有上肢外骨骼缺乏对任务语义的理解和与用户的协作规划能力，限制了其通用性。

Method: 框架包括透明模式捕捉用户意图、语义信息提取、扩散异常检测器实时监测及在线轨迹优化与阻抗控制。

Result: 实验表明，该方法能有效适应用户认知、语义任务变化，并可靠响应异常。

Conclusion: 该框架提升了外骨骼的语义理解和协作能力，为家庭护理场景提供了更安全的辅助支持。

Abstract: Upper-limb exoskeletons are primarily designed to provide assistive support
by accurately interpreting and responding to human intentions. In home-care
scenarios, exoskeletons are expected to adapt their assistive configurations
based on the semantic information of the task, adjusting appropriately in
accordance with the nature of the object being manipulated. However, existing
solutions often lack the ability to understand task semantics or
collaboratively plan actions with the user, limiting their generalizability. To
address this challenge, this paper introduces a semantic-aware framework that
integrates large language models into the task planning framework, enabling the
delivery of safe and intent-integrative assistance. The proposed approach
begins with the exoskeleton operating in transparent mode to capture the
wearer's intent during object grasping. Once semantic information is extracted
from the task description, the system automatically configures appropriate
assistive parameters. In addition, a diffusion-based anomaly detector is used
to continuously monitor the state of human-robot interaction and trigger
real-time replanning in response to detected anomalies. During task execution,
online trajectory refinement and impedance control are used to ensure safety
and regulate human-robot interaction. Experimental results demonstrate that the
proposed method effectively aligns with the wearer's cognition, adapts to
semantically varying tasks, and responds reliably to anomalies.

</details>


### [8] [Super LiDAR Reflectance for Robotic Perception](https://arxiv.org/abs/2508.10398)
*Wei Gao,Jie Zhang,Mingle Zhao,Zhiyuan Zhang,Shu Kong,Maani Ghaffari,Dezhen Song,Cheng-Zhong Xu,Hui Kong*

Main category: cs.RO

TL;DR: 论文提出了一种从稀疏LiDAR数据生成密集反射图像的新框架，解决了低成本LiDAR因数据稀疏性受限的问题，并展示了其在机器人感知任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统上，主动光学传感未被视为主流视觉模态，但随着技术进步，LiDAR等传感器为主动视觉开辟了新领域。然而，低成本LiDAR的数据稀疏性限制了其广泛应用。

Method: 利用非重复扫描LiDAR（NRS-LiDAR）的特性，提出了一种创新框架，包括反射率校准和从静态到动态场景的转换，以生成密集反射图像。

Result: 构建了用于LiDAR反射图像密集化的数据集，开发了针对NRS-LiDAR的密集化网络，并在环路闭合和交通车道检测等应用中验证了其效果。

Conclusion: 该框架成功解决了低成本LiDAR数据稀疏性问题，扩展了其在机器人感知任务中的应用范围，为主动视觉领域提供了新工具。

Abstract: Conventionally, human intuition often defines vision as a modality of passive
optical sensing, while active optical sensing is typically regarded as
measuring rather than the default modality of vision. However, the situation
now changes: sensor technologies and data-driven paradigms empower active
optical sensing to redefine the boundaries of vision, ushering in a new era of
active vision. Light Detection and Ranging (LiDAR) sensors capture reflectance
from object surfaces, which remains invariant under varying illumination
conditions, showcasing significant potential in robotic perception tasks such
as detection, recognition, segmentation, and Simultaneous Localization and
Mapping (SLAM). These applications often rely on dense sensing capabilities,
typically achieved by high-resolution, expensive LiDAR sensors. A key challenge
with low-cost LiDARs lies in the sparsity of scan data, which limits their
broader application. To address this limitation, this work introduces an
innovative framework for generating dense LiDAR reflectance images from sparse
data, leveraging the unique attributes of non-repeating scanning LiDAR
(NRS-LiDAR). We tackle critical challenges, including reflectance calibration
and the transition from static to dynamic scene domains, facilitating the
reconstruction of dense reflectance images in real-world settings. The key
contributions of this work include a comprehensive dataset for LiDAR
reflectance image densification, a densification network tailored for
NRS-LiDAR, and diverse applications such as loop closure and traffic lane
detection using the generated dense reflectance images.

</details>


### [9] [Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning](https://arxiv.org/abs/2508.10399)
*Wenlong Liang,Rui Zhou,Yang Ma,Bing Zhang,Songlin Li,Yijia Liao,Ping Kuang*

Main category: cs.RO

TL;DR: 本文综述了大模型赋能的具身AI，重点探讨自主决策与具身学习，分析分层与端到端决策范式，并首次将世界模型纳入具身AI研究。


<details>
  <summary>Details</summary>
Motivation: 具身AI旨在开发具备感知、决策、行动和学习能力的智能系统，但实现开放动态环境中人类水平的通用智能仍具挑战。大模型的突破为具身AI带来革命性进展。

Method: 研究分层与端到端决策范式，分析大模型如何提升高层规划、低层执行及反馈；探讨大模型如何增强模仿学习与强化学习；首次整合世界模型。

Result: 大模型显著提升了具身AI的决策与学习能力，但仍有挑战。

Conclusion: 尽管取得进展，具身AI仍面临挑战，未来研究方向包括进一步优化大模型的应用。

Abstract: Embodied AI aims to develop intelligent systems with physical forms capable
of perceiving, decision-making, acting, and learning in real-world
environments, providing a promising way to Artificial General Intelligence
(AGI). Despite decades of explorations, it remains challenging for embodied
agents to achieve human-level intelligence for general-purpose tasks in open
dynamic environments. Recent breakthroughs in large models have revolutionized
embodied AI by enhancing perception, interaction, planning and learning. In
this article, we provide a comprehensive survey on large model empowered
embodied AI, focusing on autonomous decision-making and embodied learning. We
investigate both hierarchical and end-to-end decision-making paradigms,
detailing how large models enhance high-level planning, low-level execution,
and feedback for hierarchical decision-making, and how large models enhance
Vision-Language-Action (VLA) models for end-to-end decision making. For
embodied learning, we introduce mainstream learning methodologies, elaborating
on how large models enhance imitation learning and reinforcement learning
in-depth. For the first time, we integrate world models into the survey of
embodied AI, presenting their design methods and critical roles in enhancing
decision-making and learning. Though solid advances have been achieved,
challenges still exist, which are discussed at the end of this survey,
potentially as the further research directions.

</details>


### [10] [CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model](https://arxiv.org/abs/2508.10416)
*Zhuoyuan Yu,Yuxing Long,Zihan Yang,Chengyan Zeng,Hongwei Fan,Jiyao Zhang,Hao Dong*

Main category: cs.RO

TL;DR: 提出了一种名为Self-correction Flywheel的后训练范式，通过利用模型的错误轨迹生成自校正数据，逐步提升视觉-语言导航模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言导航模型在执行指令时容易偏离正确轨迹，且缺乏有效的错误校正能力。

Method: 通过识别错误轨迹中的偏差，自动生成感知和动作的自校正数据，并利用这些数据持续训练模型。

Result: 在R2R-CE和RxR-CE基准测试中，CorrectNav模型分别达到65.1%和69.3%的成功率，优于之前的最佳模型。

Conclusion: Self-correction Flywheel范式显著提升了模型的错误校正能力和性能，适用于复杂环境中的导航任务。

Abstract: Existing vision-and-language navigation models often deviate from the correct
trajectory when executing instructions. However, these models lack effective
error correction capability, hindering their recovery from errors. To address
this challenge, we propose Self-correction Flywheel, a novel post-training
paradigm. Instead of considering the model's error trajectories on the training
set as a drawback, our paradigm emphasizes their significance as a valuable
data source. We have developed a method to identify deviations in these error
trajectories and devised innovative techniques to automatically generate
self-correction data for perception and action. These self-correction data
serve as fuel to power the model's continued training. The brilliance of our
paradigm is revealed when we re-evaluate the model on the training set,
uncovering new error trajectories. At this time, the self-correction flywheel
begins to spin. Through multiple flywheel iterations, we progressively enhance
our monocular RGB-based VLA navigation model CorrectNav. Experiments on R2R-CE
and RxR-CE benchmarks show CorrectNav achieves new state-of-the-art success
rates of 65.1% and 69.3%, surpassing prior best VLA navigation models by 8.2%
and 16.4%. Real robot tests in various indoor and outdoor environments
demonstrate \method's superior capability of error correction, dynamic obstacle
avoidance, and long instruction following.

</details>


### [11] [MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion](https://arxiv.org/abs/2508.10423)
*Qi Liu,Xiaopeng Zhang,Mingshan Tan,Shuaikang Ma,Jinliang Ding,Yanjie Li*

Main category: cs.RO

TL;DR: 提出了一种基于协作异构多智能体深度强化学习（MARL）的新方法MASH，用于优化单个人形机器人的运动能力，通过将每个肢体视为独立智能体并共享全局批评器，显著提升了训练效率和全身协作能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常采用单智能体强化学习或多智能体强化学习用于多机器人系统任务，而本文提出将协作异构MARL应用于单个人形机器人，以探索更高效的运动策略。

Method: 提出MASH方法，将人形机器人的每个肢体（腿和手臂）视为独立智能体，通过共享全局批评器进行协作学习，优化机器人的动作空间探索。

Result: 实验表明，MASH加速了训练收敛速度，并提升了全身协作能力，优于传统的单智能体强化学习方法。

Conclusion: MASH为单个人形机器人控制中的MARL应用提供了新思路，展示了高效运动策略的潜力。

Abstract: This paper proposes a novel method to enhance locomotion for a single
humanoid robot through cooperative-heterogeneous multi-agent deep reinforcement
learning (MARL). While most existing methods typically employ single-agent
reinforcement learning algorithms for a single humanoid robot or MARL
algorithms for multi-robot system tasks, we propose a distinct paradigm:
applying cooperative-heterogeneous MARL to optimize locomotion for a single
humanoid robot. The proposed method, multi-agent reinforcement learning for
single humanoid locomotion (MASH), treats each limb (legs and arms) as an
independent agent that explores the robot's action space while sharing a global
critic for cooperative learning. Experiments demonstrate that MASH accelerates
training convergence and improves whole-body cooperation ability, outperforming
conventional single-agent reinforcement learning methods. This work advances
the integration of MARL into single-humanoid-robot control, offering new
insights into efficient locomotion strategies.

</details>


### [12] [Enabling Generic Robot Skill Implementation Using Object Oriented Programming](https://arxiv.org/abs/2508.10497)
*Abdullah Farrukh,Achim Wagner,Martin Ruskowski*

Main category: cs.RO

TL;DR: 提出一个简化机器人系统接口的软件框架，旨在降低部署机器人系统的复杂性，特别针对中小企业和研究人员。


<details>
  <summary>Details</summary>
Motivation: 中小企业和研究人员在缺乏机器人专业知识的情况下，难以实现和维护机器人系统，且依赖外部集成商可能导致供应商锁定。

Method: 使用Python实现一个原型框架，通过抽象层统一不同制造商和型号的机器人接口。

Result: 开发了一个专注于简化现代机器人系统接口的概念框架。

Conclusion: 该框架为中小企业和研究人员提供了一种减少机器人系统部署复杂性的解决方案。

Abstract: Developing robotic algorithms and integrating a robotic subsystem into a
larger system can be a difficult task. Particularly in small and medium-sized
enterprises (SMEs) where robotics expertise is lacking, implementing,
maintaining and developing robotic systems can be a challenge. As a result,
many companies rely on external expertise through system integrators, which, in
some cases, can lead to vendor lock-in and external dependency. In the academic
research on intelligent manufacturing systems, robots play a critical role in
the design of robust autonomous systems. Similar challenges are faced by
researchers who want to use robotic systems as a component in a larger smart
system, without having to deal with the complexity and vastness of the robot
interfaces in detail. In this paper, we propose a software framework that
reduces the effort required to deploy a working robotic system. The focus is
solely on providing a concept for simplifying the different interfaces of a
modern robot system and using an abstraction layer for different manufacturers
and models. The Python programming language is used to implement a prototype of
the concept. The target system is a bin-picking cell containing a Yaskawa
Motoman GP4.

</details>


### [13] [KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection](https://arxiv.org/abs/2508.10511)
*Andrea Rosasco,Federico Ceola,Giulia Pasquale,Lorenzo Natale*

Main category: cs.RO

TL;DR: KDPE通过基于核密度估计的策略改进Diffusion Policy，过滤有害轨迹并保持低计算开销，在仿真和真实机器人实验中表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决Diffusion Policy在机器人行为克隆中的随机性和数据异常问题。

Method: 提出KDPE，利用流形感知核密度估计过滤Diffusion Policy输出的有害轨迹。

Result: KDPE在仿真单臂任务和真实机器人实验中表现优于Diffusion Policy。

Conclusion: KDPE有效解决了Diffusion Policy的局限性，提升了性能。

Abstract: Learning robot policies that capture multimodality in the training data has
been a long-standing open challenge for behavior cloning. Recent approaches
tackle the problem by modeling the conditional action distribution with
generative models. One of these approaches is Diffusion Policy, which relies on
a diffusion model to denoise random points into robot action trajectories.
While achieving state-of-the-art performance, it has two main drawbacks that
may lead the robot out of the data distribution during policy execution. First,
the stochasticity of the denoising process can highly impact on the quality of
generated trajectory of actions. Second, being a supervised learning approach,
it can learn data outliers from the dataset used for training. Recent work
focuses on mitigating these limitations by combining Diffusion Policy either
with large-scale training or with classical behavior cloning algorithms.
Instead, we propose KDPE, a Kernel Density Estimation-based strategy that
filters out potentially harmful trajectories output of Diffusion Policy while
keeping a low test-time computational overhead. For Kernel Density Estimation,
we propose a manifold-aware kernel to model a probability density function for
actions composed of end-effector Cartesian position, orientation, and gripper
state. KDPE overall achieves better performance than Diffusion Policy on
simulated single-arm tasks and real robot experiments.
  Additional material and code are available on our project page
https://hsp-iit.github.io/KDPE/.

</details>


### [14] [MLM: Learning Multi-task Loco-Manipulation Whole-Body Control for Quadruped Robot with Arm](https://arxiv.org/abs/2508.10538)
*Xin Liu,Bida Ma,Chenkun Qi,Yan Ding,Zhaxizhuoma,Guorong Zhang,Pengan Chen,Kehui Liu,Zhongjie Jia,Chuyue Guan,Yule Mo,Jiaqi Liu,Feng Gao,Jiangwei Zhong,Bin Zhao,Xuelong Li*

Main category: cs.RO

TL;DR: 提出了一种名为MLM的强化学习框架，结合真实世界和仿真数据，使配备六自由度机械臂的四足机器人能够自主或通过远程操作完成全身定位操作任务。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人配备机械臂时全身定位操作的多任务控制难题。

Method: 引入轨迹库和自适应课程采样机制，提出轨迹-速度预测策略网络，利用仿真数据和课程奖励实现零样本迁移。

Result: 仿真和真实世界实验验证了方法的有效性和在多任务执行中的良好性能。

Conclusion: MLM框架成功解决了多任务全身定位操作问题，并在真实机器人上展示了优异的性能。

Abstract: Whole-body loco-manipulation for quadruped robots with arm remains a
challenging problem, particularly in achieving multi-task control. To address
this, we propose MLM, a reinforcement learning framework driven by both
real-world and simulation data. It enables a six-DoF robotic arm--equipped
quadruped robot to perform whole-body loco-manipulation for multiple tasks
autonomously or under human teleoperation. To address the problem of balancing
multiple tasks during the learning of loco-manipulation, we introduce a
trajectory library with an adaptive, curriculum-based sampling mechanism. This
approach allows the policy to efficiently leverage real-world collected
trajectories for learning multi-task loco-manipulation. To address deployment
scenarios with only historical observations and to enhance the performance of
policy execution across tasks with different spatial ranges, we propose a
Trajectory-Velocity Prediction policy network. It predicts unobservable future
trajectories and velocities. By leveraging extensive simulation data and
curriculum-based rewards, our controller achieves whole-body behaviors in
simulation and zero-shot transfer to real-world deployment. Ablation studies in
simulation verify the necessity and effectiveness of our approach, while
real-world experiments on the Go2 robot with an Airbot robotic arm demonstrate
the policy's good performance in multi-task execution.

</details>


### [15] [Why Report Failed Interactions With Robots?! Towards Vignette-based Interaction Quality](https://arxiv.org/abs/2508.10603)
*Agnes Axelsson,Merle Reimann,Ronald Cumbal,Hannah Pelikan,Divesh Lala*

Main category: cs.RO

TL;DR: 论文提出使用民族志小故事（ethnographic vignettes）来突出人机交互（HRI）中的失败案例，弥补现有研究的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs提升了人机交互质量，但与人人交互相比仍存在不足，且失败案例因情境而异，难以泛化。

Method: 提出通过撰写民族志小故事的方法，记录多学科视角下的失败案例，增强透明度和意外行为记录。

Result: 小故事能有效揭示罕见失败案例，促进对机器人能力的透明认知。

Conclusion: 建议将小故事作为现有交互评估方法的补充工具。

Abstract: Although the quality of human-robot interactions has improved with the advent
of LLMs, there are still various factors that cause systems to be sub-optimal
when compared to human-human interactions. The nature and criticality of
failures are often dependent on the context of the interaction and so cannot be
generalized across the wide range of scenarios and experiments which have been
implemented in HRI research. In this work we propose the use of a technique
overlooked in the field of HRI, ethnographic vignettes, to clearly highlight
these failures, particularly those that are rarely documented. We describe the
methodology behind the process of writing vignettes and create our own based on
our personal experiences with failures in HRI systems. We emphasize the
strength of vignettes as the ability to communicate failures from a
multi-disciplinary perspective, promote transparency about the capabilities of
robots, and document unexpected behaviours which would otherwise be omitted
from research reports. We encourage the use of vignettes to augment existing
interaction evaluation methods.

</details>


### [16] [Synthesis of Deep Neural Networks with Safe Robust Adaptive Control for Reliable Operation of Wheeled Mobile Robots](https://arxiv.org/abs/2508.10634)
*Mehdi Heydari Shahna,Jouni Mattila*

Main category: cs.RO

TL;DR: 论文提出了一种结合深度神经网络（DNN）和鲁棒自适应控制（RAC）的分层控制策略，用于重型轮式移动机器人（WMR），以确保高精度和安全性。


<details>
  <summary>Details</summary>
Motivation: 重型WMR在严格国际标准下运行，易受干扰和故障影响，传统黑盒DNN方法难以满足其安全需求。

Method: 设计了分层控制策略：DNN作为主控策略，RAC作为低层安全层，高层安全层监控系统性能。

Result: 实验验证了该方法在6000 kg WMR上的有效性，确保了系统的稳定性和安全性。

Conclusion: DNN与RAC的结合为重型WMR提供了高精度和鲁棒性的控制方案。

Abstract: Deep neural networks (DNNs) can enable precise control while maintaining low
computational costs by circumventing the need for dynamic modeling. However,
the deployment of such black-box approaches remains challenging for heavy-duty
wheeled mobile robots (WMRs), which are subject to strict international
standards and prone to faults and disturbances. We designed a hierarchical
control policy for heavy-duty WMRs, monitored by two safety layers with
differing levels of authority. To this end, a DNN policy was trained and
deployed as the primary control strategy, providing high-precision performance
under nominal operating conditions. When external disturbances arise and reach
a level of intensity such that the system performance falls below a predefined
threshold, a low-level safety layer intervenes by deactivating the primary
control policy and activating a model-free robust adaptive control (RAC)
policy. This transition enables the system to continue operating while ensuring
stability by effectively managing the inherent trade-off between system
robustness and responsiveness. Regardless of the control policy in use, a
high-level safety layer continuously monitors system performance during
operation. It initiates a shutdown only when disturbances become sufficiently
severe such that compensation is no longer viable and continued operation would
jeopardize the system or its environment. The proposed synthesis of DNN and RAC
policy guarantees uniform exponential stability of the entire WMR system while
adhering to safety standards to some extent. The effectiveness of the proposed
approach was further validated through real-time experiments using a 6,000 kg
WMR.

</details>


### [17] [An Open-Source User-Friendly Interface for Simulating Magnetic Soft Robots using Simulation Open Framework Architecture (SOFA)](https://arxiv.org/abs/2508.10686)
*Carla Wehner,Finn Schubert,Heiko Hellkamp,Julius Hahnewald,Kilian Scheafer,Muhammad Bilal Khan,Oliver Gutfleisch*

Main category: cs.RO

TL;DR: 该论文介绍了一个基于SOFA的开源、用户友好的磁性软体机器人仿真工具，旨在填补现有平台在磁性材料建模方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有仿真工具缺乏对磁性材料的专门支持，导致不同专业水平的研究人员难以使用，因此需要开发一个更易用的仿真平台。

Method: 利用SOFA框架开发了一个仿真界面，支持定义材料属性、施加磁场并实时观察变形，同时集成了直观控制和应力分析功能。

Result: 通过四个基准模型（梁、三指和四指夹持器、蝴蝶）验证了工具的功能性，证明其适用于初学者和高级研究人员。

Conclusion: 未来将通过实验验证和与行业标准有限元求解器的比较，进一步提高仿真精度，确保预测的准确性。

Abstract: Soft robots, particularly magnetic soft robots, require specialized
simulation tools to accurately model their deformation under external magnetic
fields. However, existing platforms often lack dedicated support for magnetic
materials, making them difficult to use for researchers at different expertise
levels. This work introduces an open-source, user-friendly simulation interface
using the Simulation Open Framework Architecture (SOFA), specifically designed
to model magnetic soft robots. The tool enables users to define material
properties, apply magnetic fields, and observe resulting deformations in real
time. By integrating intuitive controls and stress analysis capabilities, it
aims to bridge the gap between theoretical modeling and practical design. Four
benchmark models - a beam, three- and four-finger grippers, and a butterfly -
demonstrate its functionality. The software's ease of use makes it accessible
to both beginners and advanced researchers. Future improvements will refine
accuracy through experimental validation and comparison with industry-standard
finite element solvers, ensuring realistic and predictive simulations of
magnetic soft robots.

</details>


### [18] [Biasing Frontier-Based Exploration with Saliency Areas](https://arxiv.org/abs/2508.10689)
*Matteo Luperto,Valerii Stakanov,Giacomo Boracchi,Nicola Basilico,Francesco Amigoni*

Main category: cs.RO

TL;DR: 论文提出了一种基于显著性区域的方法，用于优化机器人在未知环境中的自主探索策略。


<details>
  <summary>Details</summary>
Motivation: 现有探索策略通常仅关注最大化探索面积，而忽略了环境中某些区域对探索效率的重要性。

Method: 利用神经网络生成的显著性地图识别关键区域（显著性区域），并将其融入现有探索策略中。

Result: 实验表明，该方法能显著影响机器人的探索行为，提高探索效率。

Conclusion: 通过引入显著性区域，可以更高效地指导机器人在未知环境中的探索。

Abstract: Autonomous exploration is a widely studied problem where a robot
incrementally builds a map of a previously unknown environment. The robot
selects the next locations to reach using an exploration strategy. To do so,
the robot has to balance between competing objectives, like exploring the
entirety of the environment, while being as fast as possible. Most exploration
strategies try to maximise the explored area to speed up exploration; however,
they do not consider that parts of the environment are more important than
others, as they lead to the discovery of large unknown areas. We propose a
method that identifies \emph{saliency areas} as those areas that are of high
interest for exploration, by using saliency maps obtained from a neural network
that, given the current map, implements a termination criterion to estimate
whether the environment can be considered fully-explored or not. We use
saliency areas to bias some widely used exploration strategies, showing, with
an extensive experimental campaign, that this knowledge can significantly
influence the behavior of the robot during exploration.

</details>


### [19] [Learning Task Execution Hierarchies for Redundant Robots](https://arxiv.org/abs/2508.10780)
*Alessandro Adami,Aris Synodinos,Matteo Iovino,Ruggero Carli,Pietro Falco*

Main category: cs.RO

TL;DR: 论文提出了一种自动学习任务堆叠（SoT）层次和参数的新框架，结合强化学习和遗传编程，无需人工干预即可发现任务优先级和控制策略。


<details>
  <summary>Details</summary>
Motivation: 传统SoT由专家手动设计，限制了其适应性和可访问性，因此需要一种自动化的解决方案。

Method: 结合强化学习和遗传编程，通过基于精度、安全性和执行时间的成本函数指导学习过程。

Result: 在移动-YuMi平台上验证，结果表明学习的SoT使机器人能动态适应环境和输入，平衡竞争目标并保持稳健任务执行。

Conclusion: 该方法为复杂机器人冗余管理提供了通用且用户友好的解决方案，减少了专家设计的依赖。

Abstract: Modern robotic systems, such as mobile manipulators, humanoids, and aerial
robots with arms, often possess high redundancy, enabling them to perform
multiple tasks simultaneously. Managing this redundancy is key to achieving
reliable and flexible behavior. A widely used approach is the Stack of Tasks
(SoT), which organizes control objectives by priority within a unified
framework. However, traditional SoTs are manually designed by experts, limiting
their adaptability and accessibility. This paper introduces a novel framework
that automatically learns both the hierarchy and parameters of a SoT from
user-defined objectives. By combining Reinforcement Learning and Genetic
Programming, the system discovers task priorities and control strategies
without manual intervention. A cost function based on intuitive metrics such as
precision, safety, and execution time guides the learning process. We validate
our method through simulations and experiments on the mobile-YuMi platform, a
dual-arm mobile manipulator with high redundancy. Results show that the learned
SoTs enable the robot to dynamically adapt to changing environments and inputs,
balancing competing objectives while maintaining robust task execution. This
approach provides a general and user-friendly solution for redundancy
management in complex robots, advancing human-centered robot programming and
reducing the need for expert design.

</details>


### [20] [The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems](https://arxiv.org/abs/2508.10798)
*Troi Williams*

Main category: cs.RO

TL;DR: 论文提出SET感知因素框架，用于系统分析环境因素对机器人感知的影响，以提升自主系统的安全性和可信度。


<details>
  <summary>Details</summary>
Motivation: 自主系统的部署引发了对安全和可信度的担忧，尤其是感知故障可能导致事故，削弱公众信任。

Method: 引入SET框架，通过SET状态树和因素树分类和建模感知任务中的不确定性，并开发感知因素模型量化风险。

Result: SET框架提供了一种透明、标准化的方法来识别、建模和传达感知风险。

Conclusion: 该框架旨在通过系统性分析感知风险，增强自主系统的安全性和公众信任。

Abstract: Future autonomous systems promise significant societal benefits, yet their
deployment raises concerns about safety and trustworthiness. A key concern is
assuring the reliability of robot perception, as perception seeds safe
decision-making. Failures in perception are often due to complex yet common
environmental factors and can lead to accidents that erode public trust. To
address this concern, we introduce the SET (Self, Environment, and Target)
Perceptual Factors Framework. We designed the framework to systematically
analyze how factors such as weather, occlusion, or sensor limitations
negatively impact perception. To achieve this, the framework employs SET State
Trees to categorize where such factors originate and SET Factor Trees to model
how these sources and factors impact perceptual tasks like object detection or
pose estimation. Next, we develop Perceptual Factor Models using both trees to
quantify the uncertainty for a given task. Our framework aims to promote
rigorous safety assurances and cultivate greater public understanding and trust
in autonomous systems by offering a transparent and standardized method for
identifying, modeling, and communicating perceptual risks.

</details>


### [21] [A Multimodal Neural Network for Recognizing Subjective Self-Disclosure Towards Social Robots](https://arxiv.org/abs/2508.10828)
*Henry Powell,Guy Laban,Emily S. Cross*

Main category: cs.RO

TL;DR: 论文提出了一种基于情感识别文献的多模态注意力网络，用于建模人类与机器人互动中的主观自我披露行为，并通过新设计的损失函数显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 主观自我披露是人类社交互动的重要特征，但目前缺乏计算模型来准确建模，尤其是在人类与机器人互动中的自我披露行为。随着社交机器人在多种社交场景中的应用需求增加，这一研究变得尤为重要。

Method: 开发了一种基于情感识别文献的多模态注意力网络，使用自收集的自我披露视频语料库进行训练，并设计了一种新的损失函数——尺度保持交叉熵损失。

Result: 最佳模型在新损失函数下取得了F1分数0.83，比基线模型提升了0.48。

Conclusion: 该研究为社交机器人识别互动伙伴的自我披露行为提供了重要进展，这对具备社交认知能力的机器人至关重要。

Abstract: Subjective self-disclosure is an important feature of human social
interaction. While much has been done in the social and behavioural literature
to characterise the features and consequences of subjective self-disclosure,
little work has been done thus far to develop computational systems that are
able to accurately model it. Even less work has been done that attempts to
model specifically how human interactants self-disclose with robotic partners.
It is becoming more pressing as we require social robots to work in conjunction
with and establish relationships with humans in various social settings. In
this paper, our aim is to develop a custom multimodal attention network based
on models from the emotion recognition literature, training this model on a
large self-collected self-disclosure video corpus, and constructing a new loss
function, the scale preserving cross entropy loss, that improves upon both
classification and regression versions of this problem. Our results show that
the best performing model, trained with our novel loss function, achieves an F1
score of 0.83, an improvement of 0.48 from the best baseline model. This result
makes significant headway in the aim of allowing social robots to pick up on an
interaction partner's self-disclosures, an ability that will be essential in
social robots with social cognition.

</details>


### [22] [CVIRO: A Consistent and Tightly-Coupled Visual-Inertial-Ranging Odometry on Lie Groups](https://arxiv.org/abs/2508.10867)
*Yizhi Zhou,Ziwei Kang,Jiawei Xia,Xuan Wang*

Main category: cs.RO

TL;DR: 提出了一种基于李群的视觉-惯性-测距里程计系统（CVIRO），通过联合估计机器人状态和UWB锚点状态，确保一致性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决视觉-惯性里程计（VIO）系统中因观测性不一致和UWB锚点位置假设导致的定位性能下降问题。

Method: 将UWB锚点状态纳入系统状态，利用李群的不变误差特性，确保观测性一致性。

Result: CVIRO在仿真和实验中表现出优于现有方法的定位精度和一致性。

Conclusion: CVIRO通过联合估计和观测性一致性设计，显著提升了定位系统的性能。

Abstract: Ultra Wideband (UWB) is widely used to mitigate drift in visual-inertial
odometry (VIO) systems. Consistency is crucial for ensuring the estimation
accuracy of a UWBaided VIO system. An inconsistent estimator can degrade
localization performance, where the inconsistency primarily arises from two
main factors: (1) the estimator fails to preserve the correct system
observability, and (2) UWB anchor positions are assumed to be known, leading to
improper neglect of calibration uncertainty. In this paper, we propose a
consistent and tightly-coupled visual-inertial-ranging odometry (CVIRO) system
based on the Lie group. Our method incorporates the UWB anchor state into the
system state, explicitly accounting for UWB calibration uncertainty and
enabling the joint and consistent estimation of both robot and anchor states.
Furthermore, observability consistency is ensured by leveraging the invariant
error properties of the Lie group. We analytically prove that the CVIRO
algorithm naturally maintains the system's correct unobservable subspace,
thereby preserving estimation consistency. Extensive simulations and
experiments demonstrate that CVIRO achieves superior localization accuracy and
consistency compared to existing methods.

</details>


### [23] [TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning](https://arxiv.org/abs/2508.10872)
*Anantha Narayanan,Battu Bhanu Teja,Pruthwik Mishra*

Main category: cs.RO

TL;DR: 论文提出了一种基于强化学习（A2C算法）的框架，用于优化低地球轨道卫星的轨道参数，以实现精确的地面覆盖，并减少碰撞风险。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道日益拥挤，对地球观测卫星的高效部署和安全运行提出了挑战。需要一种方法在满足任务需求的同时降低碰撞风险。

Method: 使用A2C算法，将问题建模为马尔可夫决策过程（MDP），在自定义的OpenAI Gymnasium环境中模拟轨道动力学，调整五个轨道参数以实现目标覆盖。

Result: A2C在累积奖励（10.0 vs 9.263025）和收敛速度（2,000 vs 63,000时间步）上优于PPO，且能高效满足任务需求。

Conclusion: 强化学习为可扩展且智能的低地球轨道任务规划提供了高效的计算替代方案。

Abstract: The increasing congestion of Low Earth Orbit (LEO) poses persistent
challenges to the efficient deployment and safe operation of Earth observation
satellites. Mission planners must now account not only for mission-specific
requirements but also for the increasing collision risk with active satellites
and space debris. This work presents a reinforcement learning framework using
the Advantage Actor-Critic (A2C) algorithm to optimize satellite orbital
parameters for precise terrestrial coverage within predefined surface radii. By
formulating the problem as a Markov Decision Process (MDP) within a custom
OpenAI Gymnasium environment, our method simulates orbital dynamics using
classical Keplerian elements. The agent progressively learns to adjust five of
the orbital parameters - semi-major axis, eccentricity, inclination, right
ascension of ascending node, and the argument of perigee-to achieve targeted
terrestrial coverage. Comparative evaluation against Proximal Policy
Optimization (PPO) demonstrates A2C's superior performance, achieving 5.8x
higher cumulative rewards (10.0 vs 9.263025) while converging in 31.5x fewer
timesteps (2,000 vs 63,000). The A2C agent consistently meets mission
objectives across diverse target coordinates while maintaining computational
efficiency suitable for real-time mission planning applications. Key
contributions include: (1) a TLE-based orbital simulation environment
incorporating physics constraints, (2) validation of actor-critic methods'
superiority over trust region approaches in continuous orbital control, and (3)
demonstration of rapid convergence enabling adaptive satellite deployment. This
approach establishes reinforcement learning as a computationally efficient
alternative for scalable and intelligent LEO mission planning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions](https://arxiv.org/abs/2508.10047)
*Ziyang Xiao,Jingrong Xie,Lilin Xu,Shisi Guan,Jingyan Zhu,Xiongwei Han,Xiaojin Fu,WingYin Yu,Han Wu,Wei Shi,Qingcan Kang,Jiahui Duan,Tao Zhong,Mingxuan Yuan,Jia Zeng,Yuan Wang,Gang Chen,Dongxiang Zhang*

Main category: cs.AI

TL;DR: 本文综述了利用大语言模型（LLMs）自动化数学建模的最新进展，包括数据合成、模型微调、推理框架、基准数据集和性能评估，并构建了一个新的公平评估排行榜和在线资源门户。


<details>
  <summary>Details</summary>
Motivation: 优化建模在解决实际问题中具有重要价值，但需要大量专业知识。LLMs的出现为自动化数学建模提供了新机会。

Method: 综述了技术栈的各个方面，包括数据合成、模型微调、推理框架等，并清理了基准数据集，构建了新的排行榜和在线门户。

Result: 发现基准数据集错误率较高，清理后构建了公平评估的排行榜和资源门户。

Conclusion: 总结了当前方法的局限性，并提出了未来研究方向。

Abstract: By virtue of its great utility in solving real-world problems, optimization
modeling has been widely employed for optimal decision-making across various
sectors, but it requires substantial expertise from operations research
professionals. With the advent of large language models (LLMs), new
opportunities have emerged to automate the procedure of mathematical modeling.
This survey presents a comprehensive and timely review of recent advancements
that cover the entire technical stack, including data synthesis and fine-tuning
for the base model, inference frameworks, benchmark datasets, and performance
evaluation. In addition, we conducted an in-depth analysis on the quality of
benchmark datasets, which was found to have a surprisingly high error rate. We
cleaned the datasets and constructed a new leaderboard with fair performance
evaluation in terms of base LLM model and datasets. We also build an online
portal that integrates resources of cleaned datasets, code and paper repository
to benefit the community. Finally, we identify limitations in current
methodologies and outline future research opportunities.

</details>


### [25] [Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development](https://arxiv.org/abs/2508.10108)
*Sattvik Sahai,Prasoon Goyal,Michael Johnston,Anna Gottardi,Yao Lu,Lucy Hu,Luke Dai,Shaohua Liu,Samyuth Sagi,Hangjie Shi,Desheng Zhang,Lavina Vaz,Leslie Ball,Maureen Murray,Rahul Gupta,Shankar Ananthakrishna*

Main category: cs.AI

TL;DR: 亚马逊Nova AI挑战赛通过对抗性竞赛推动AI安全技术发展，大学团队开发了自动红队和安全AI助手，并引入创新方法提升AI安全性。


<details>
  <summary>Details</summary>
Motivation: 解决AI在软件开发中的安全性问题，推动安全AI技术的发展。

Method: 通过对抗性竞赛（红队与AI助手对话）和高质量标注数据，团队开发了推理安全对齐、模型护栏等技术。

Result: 团队提出了创新方法，如多轮越狱和高效探测LLM，亚马逊提供了基础设施支持。

Conclusion: 该挑战赛提升了AI安全性，展示了协作努力的重要性。

Abstract: AI systems for software development are rapidly gaining prominence, yet
significant challenges remain in ensuring their safety. To address this, Amazon
launched the Trusted AI track of the Amazon Nova AI Challenge, a global
competition among 10 university teams to drive advances in secure AI. In the
challenge, five teams focus on developing automated red teaming bots, while the
other five create safe AI assistants. This challenge provides teams with a
unique platform to evaluate automated red-teaming and safety alignment methods
through head-to-head adversarial tournaments where red teams have multi-turn
conversations with the competing AI coding assistants to test their safety
alignment. Along with this, the challenge provides teams with a feed of high
quality annotated data to fuel iterative improvement. Throughout the challenge,
teams developed state-of-the-art techniques, introducing novel approaches in
reasoning-based safety alignment, robust model guardrails, multi-turn
jail-breaking, and efficient probing of large language models (LLMs). To
support these efforts, the Amazon Nova AI Challenge team made substantial
scientific and engineering investments, including building a custom baseline
coding specialist model for the challenge from scratch, developing a tournament
orchestration service, and creating an evaluation harness. This paper outlines
the advancements made by university teams and the Amazon Nova AI Challenge team
in addressing the safety challenges of AI for software development,
highlighting this collaborative effort to raise the bar for AI safety.

</details>


### [26] [MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection](https://arxiv.org/abs/2508.10143)
*Alexandru-Andrei Avram,Adrian Groza,Alexandru Lecu*

Main category: cs.AI

TL;DR: 本文提出了一种多智能体系统，通过关系提取检测新闻中的虚假信息，结合四种智能体，实现高准确率和F1分数。


<details>
  <summary>Details</summary>
Motivation: 数字平台上虚假信息的广泛传播对信息完整性构成重大挑战，需要高效检测方法。

Method: 系统包含四种智能体：机器学习代理、维基百科知识检查代理、连贯性检测代理和网络数据抓取分析代理，通过模型上下文协议（MCP）协调。

Result: 多智能体系统准确率达95.3%，F1分数0.964，显著优于传统方法。

Conclusion: 该系统模块化设计易于扩展，且决策过程透明，为虚假信息检测提供了高效解决方案。

Abstract: The large spread of disinformation across digital platforms creates
significant challenges to information integrity. This paper presents a
multi-agent system that uses relation extraction to detect disinformation in
news articles, focusing on titles and short text snippets. The proposed Agentic
AI system combines four agents: (i) a machine learning agent (logistic
regression), (ii) a Wikipedia knowledge check agent (which relies on named
entity recognition), (iii) a coherence detection agent (using LLM prompt
engineering), and (iv) a web-scraped data analyzer that extracts relational
triplets for fact checking. The system is orchestrated via the Model Context
Protocol (MCP), offering shared context and live learning across components.
Results demonstrate that the multi-agent ensemble achieves 95.3% accuracy with
an F1 score of 0.964, significantly outperforming individual agents and
traditional approaches. The weighted aggregation method, mathematically derived
from individual agent misclassification rates, proves superior to algorithmic
threshold optimization. The modular architecture makes the system easily
scalable, while also maintaining details of the decision processes.

</details>


### [27] [Agentic AI Frameworks: Architectures, Protocols, and Design Challenges](https://arxiv.org/abs/2508.10146)
*Hana Derouiche,Zaki Brahmi,Haithem Mazeni*

Main category: cs.AI

TL;DR: 本文系统回顾并比较了主流Agentic AI框架，分析了其架构、通信机制、内存管理等，提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探索Agentic AI框架的发展现状与挑战，为下一代自主AI系统提供参考。

Method: 通过系统回顾和比较分析，评估多个框架的架构原则、通信协议等。

Result: 建立了Agentic AI系统的基础分类法，并提出了未来研究方向。

Conclusion: 本文为研究人员和从业者提供了全面的参考，推动自主AI系统的发展。

Abstract: The emergence of Large Language Models (LLMs) has ushered in a transformative
paradigm in artificial intelligence, Agentic AI, where intelligent agents
exhibit goal-directed autonomy, contextual reasoning, and dynamic multi-agent
coordination. This paper provides a systematic review and comparative analysis
of leading Agentic AI frameworks, including CrewAI, LangGraph, AutoGen,
Semantic Kernel, Agno, Google ADK, and MetaGPT, evaluating their architectural
principles, communication mechanisms, memory management, safety guardrails, and
alignment with service-oriented computing paradigms. Furthermore, we identify
key limitations, emerging trends, and open challenges in the field. To address
the issue of agent communication, we conduct an in-depth analysis of protocols
such as the Contract Net Protocol (CNP), Agent-to-Agent (A2A), Agent Network
Protocol (ANP), and Agora. Our findings not only establish a foundational
taxonomy for Agentic AI systems but also propose future research directions to
enhance scalability, robustness, and interoperability. This work serves as a
comprehensive reference for researchers and practitioners working to advance
the next generation of autonomous AI systems.

</details>


### [28] [Improving and Evaluating Open Deep Research Agents](https://arxiv.org/abs/2508.10152)
*Doaa Allabadi,Kyle Bradbury,Jordan M. Malof*

Main category: cs.AI

TL;DR: 本文研究了开源深度研究代理（ODR）与专有系统在BrowseComp-Small基准上的表现，通过改进ODR提出了ODR+模型，其性能优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究代理（DRA）多为闭源系统，缺乏开源选择，因此研究开源DRA的性能和改进潜力。

Method: 通过调整BrowseComp基准为BC-Small，比较ODR与专有系统，并引入三项改进提出ODR+。

Result: 所有系统在60个测试问题上准确率为0%，改进后的ODR+达到10%的成功率。

Conclusion: 开源DRA通过改进可以接近专有系统性能，为学术研究提供了可行工具。

Abstract: We focus here on Deep Research Agents (DRAs), which are systems that can take
a natural language prompt from a user, and then autonomously search for, and
utilize, internet-based content to address the prompt. Recent DRAs have
demonstrated impressive capabilities on public benchmarks however, recent
research largely involves proprietary closed-source systems. At the time of
this work, we only found one open-source DRA, termed Open Deep Research (ODR).
In this work we adapt the challenging recent BrowseComp benchmark to compare
ODR to existing proprietary systems. We propose BrowseComp-Small (BC-Small),
comprising a subset of BrowseComp, as a more computationally-tractable DRA
benchmark for academic labs. We benchmark ODR and two other proprietary systems
on BC-Small: one system from Anthropic and one system from Google. We find that
all three systems achieve 0% accuracy on the test set of 60 questions. We
introduce three strategic improvements to ODR, resulting in the ODR+ model,
which achieves a state-of-the-art 10% success rate on BC-Small among both
closed-source and open-source systems. We report ablation studies indicating
that all three of our improvements contributed to the success of ODR+.

</details>


### [29] [Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization](https://arxiv.org/abs/2508.10164)
*Bin Hong,Jiayu Liu,Zhenya Huang,Kai Zhang,Mengdi Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种名为LCPO的方法，通过控制生成路径长度，显著减少大型推理模型的输出长度，同时保持推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型（LRMs）的长链推理（CoT）虽然性能强，但输出过长导致计算成本高和过思考问题，需要平衡推理效率与质量。

Method: 分析生成路径分布并通过难度估计筛选轨迹，研究偏好优化方法的收敛行为，提出LCPO方法直接平衡隐式奖励与NLL损失。

Result: 实验表明，LCPO在多个基准测试中平均输出长度减少50%以上，同时保持推理性能。

Conclusion: LCPO展示了在有限数据和训练下实现高效推理的潜力，为LRMs的优化提供了新方向。

Abstract: Recent advances in Large Reasoning Models (LRMs) have demonstrated strong
performance on complex tasks through long Chain-of-Thought (CoT) reasoning.
However, their lengthy outputs increase computational costs and may lead to
overthinking, raising challenges in balancing reasoning effectiveness and
efficiency. Current methods for efficient reasoning often compromise reasoning
quality or require extensive resources. This paper investigates efficient
methods to reduce the generation length of LRMs. We analyze generation path
distributions and filter generated trajectories through difficulty estimation.
Subsequently, we analyze the convergence behaviors of the objectives of various
preference optimization methods under a Bradley-Terry loss based framework.
Based on the analysis, we propose Length Controlled Preference Optimization
(LCPO) that directly balances the implicit reward related to NLL loss. LCPO can
effectively learn length preference with limited data and training. Extensive
experiments demonstrate that our approach significantly reduces the average
output length by over 50\% across multiple benchmarks while maintaining the
reasoning performance. Our work highlights the potential for computationally
efficient approaches in guiding LRMs toward efficient reasoning.

</details>


### [30] [KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems](https://arxiv.org/abs/2508.10177)
*Stepan Kulibaba,Artem Dzhalilov,Roman Pakhomov,Oleg Svidchenko,Alexander Gasnikov,Aleksei Shpilman*

Main category: cs.AI

TL;DR: KompeteAI是一种新型AutoML框架，通过动态解决方案空间探索和检索增强生成（RAG）技术，解决了现有LLM-based AutoML系统的探索和执行瓶颈问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-based AutoML系统存在探索策略受限和执行瓶颈问题，如缺乏多样性和无法重组部分解决方案，以及代码验证周期长阻碍迭代优化。

Method: KompeteAI引入动态解决方案空间探索，包括合并阶段组合候选方案，并集成RAG技术从Kaggle和arXiv中获取策略。此外，通过预测评分模型和加速调试方法减少执行时间。

Result: KompeteAI在MLE-Bench基准测试中平均优于其他方法3%，并将管道评估速度提升6.9倍。

Conclusion: KompeteAI通过创新方法解决了AutoML系统的关键问题，并在性能上实现了显著提升。

Abstract: Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive
capabilities but face significant limitations such as constrained exploration
strategies and a severe execution bottleneck. Exploration is hindered by
one-shot methods lacking diversity and Monte Carlo Tree Search (MCTS)
approaches that fail to recombine strong partial solutions. The execution
bottleneck arises from lengthy code validation cycles that stifle iterative
refinement. To overcome these challenges, we introduce KompeteAI, a novel
AutoML framework with dynamic solution space exploration. Unlike previous MCTS
methods that treat ideas in isolation, KompeteAI introduces a merging stage
that composes top candidates. We further expand the hypothesis space by
integrating Retrieval-Augmented Generation (RAG), sourcing ideas from Kaggle
notebooks and arXiv papers to incorporate real-world strategies. KompeteAI also
addresses the execution bottleneck via a predictive scoring model and an
accelerated debugging method, assessing solution potential using early stage
metrics to avoid costly full-code execution. This approach accelerates pipeline
evaluation 6.9 times. KompeteAI outperforms leading methods (e.g., RD-agent,
AIDE, and Ml-Master) by an average of 3\% on the primary AutoML benchmark,
MLE-Bench. Additionally, we propose Kompete-bench to address limitations in
MLE-Bench, where KompeteAI also achieves state-of-the-art results

</details>


### [31] [Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence](https://arxiv.org/abs/2508.10241)
*Mark Zilberman*

Main category: cs.AI

TL;DR: 论文提出了一种基于事件熵势的概念，用于增强AI中的不确定性量化、决策和可解释性，并探讨了其在多个AI应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 通过引入事件熵势，旨在统一和强化智能系统中的不确定性建模，结合物理学、信息论和机器学习的原理。

Method: 将物理学中的熵势概念调整到AI领域，提出事件中心度量，强调条件期望以处理反事实场景。

Result: 框架在策略评估、内在奖励设计、可解释AI和异常检测中展示了潜力，并通过强化学习、贝叶斯推理等实例验证。

Conclusion: 熵势框架为AI中的不确定性管理提供了理论基础、可解释且多功能的方法。

Abstract: This work demonstrates how the concept of the entropic potential of events --
a parameter quantifying the influence of discrete events on the expected future
entropy of a system -- can enhance uncertainty quantification, decision-making,
and interpretability in artificial intelligence (AI). Building on its original
formulation in physics, the framework is adapted for AI by introducing an
event-centric measure that captures how actions, observations, or other
discrete occurrences impact uncertainty at future time horizons. Both the
original and AI-adjusted definitions of entropic potential are formalized, with
the latter emphasizing conditional expectations to account for counterfactual
scenarios. Applications are explored in policy evaluation, intrinsic reward
design, explainable AI, and anomaly detection, highlighting the metric's
potential to unify and strengthen uncertainty modeling in intelligent systems.
Conceptual examples illustrate its use in reinforcement learning, Bayesian
inference, and anomaly detection, while practical considerations for
computation in complex AI models are discussed. The entropic potential
framework offers a theoretically grounded, interpretable, and versatile
approach to managing uncertainty in AI, bridging principles from
thermodynamics, information theory, and machine learning.

</details>


### [32] [Why Cannot Large Language Models Ever Make True Correct Reasoning?](https://arxiv.org/abs/2508.10265)
*Jingde Cheng*

Main category: cs.AI

TL;DR: 论文认为大语言模型（LLMs）的“理解能力”和“推理能力”是误解，本质限制使其无法真正具备这些能力。


<details>
  <summary>Details</summary>
Motivation: 针对当前对LLMs能力的过度乐观，作者试图澄清其本质局限性。

Method: 通过分析LLMs的工作原理，指出其无法实现真正推理的根本原因。

Result: LLMs因本质限制无法具备真正的理解和推理能力。

Conclusion: LLMs的能力被误解，其本质限制决定了它们无法实现真正的推理。

Abstract: Recently, with the application progress of AIGC tools based on large language
models (LLMs), led by ChatGPT, many AI experts and more non-professionals are
trumpeting the "understanding ability" and "reasoning ability" of the LLMs. The
present author considers that the so-called "understanding ability" and
"reasoning ability" of LLMs are just illusions of those people who with vague
concepts. In fact, the LLMs can never have the true understanding ability and
true reasoning ability. This paper intents to explain that, because the
essential limitations of their working principle, the LLMs can never have the
ability of true correct reasoning.

</details>


### [33] [Promoting Efficient Reasoning with Verifiable Stepwise Reward](https://arxiv.org/abs/2508.10293)
*Chuhuai Yue,Chengqi Dong,Yinan Gao,Hang He,Jiajun Chai,Guojun Yin,Wei Lin*

Main category: cs.AI

TL;DR: 提出了一种基于规则的可验证逐步奖励机制（VSRM），通过奖励有效推理步骤并惩罚无效步骤，解决了大型推理模型（LRMs）的过度思考问题，显著提高了效率。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂任务中表现优异，但存在过度思考问题，导致计算资源浪费和效率下降。现有方法需要预设预算或选择推理模式，缺乏灵活性。

Method: 提出VSRM机制，根据推理轨迹中中间状态的表现分配奖励，结合PPO和Reinforce++进行实验。

Result: 在AIME24和AIME25等数学推理基准测试中，VSRM显著减少了输出长度，同时保持了推理性能，有效抑制了无效步骤。

Conclusion: VSRM通过奖励有效步骤和惩罚无效步骤，从根本上缓解了过度思考问题，实现了效率与准确性的平衡。

Abstract: Large reasoning models (LRMs) have recently achieved significant progress in
complex reasoning tasks, aided by reinforcement learning with verifiable
rewards. However, LRMs often suffer from overthinking, expending excessive
computation on simple problems and reducing efficiency. Existing efficient
reasoning methods typically require accurate task assessment to preset token
budgets or select reasoning modes, which limits their flexibility and
reliability. In this work, we revisit the essence of overthinking and identify
that encouraging effective steps while penalizing ineffective ones is key to
its solution. To this end, we propose a novel rule-based verifiable stepwise
reward mechanism (VSRM), which assigns rewards based on the performance of
intermediate states in the reasoning trajectory. This approach is intuitive and
naturally fits the step-by-step nature of reasoning tasks. We conduct extensive
experiments on standard mathematical reasoning benchmarks, including AIME24 and
AIME25, by integrating VSRM with PPO and Reinforce++. Results show that our
method achieves substantial output length reduction while maintaining original
reasoning performance, striking an optimal balance between efficiency and
accuracy. Further analysis of overthinking frequency and pass@k score before
and after training demonstrates that our approach in deed effectively
suppresses ineffective steps and encourages effective reasoning, fundamentally
alleviating the overthinking problem. All code will be released upon
acceptance.

</details>


### [34] [A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering](https://arxiv.org/abs/2508.10337)
*Chenliang Zhang,Lin Wang,Yuanyuan Lu,Yusheng Qi,Kexin Wang,Peixu Hou,Wenshi Chen*

Main category: cs.AI

TL;DR: 论文介绍了Dianping-Trust-Safety团队在META CRAG-MM挑战中的解决方案，包括多模态多轮问答系统的构建，任务1基于视觉大语言模型，任务2和3结合了外部知识，取得了显著成绩。


<details>
  <summary>Details</summary>
Motivation: 解决多模态多轮问答的复杂需求，提升系统在结构化数据检索、信息合成和多轮对话中的表现。

Method: 任务1使用视觉大语言模型并优化训练策略；任务2和3结合外部知识搜索API。

Result: 任务1以52.38%的优势排名第一，任务3排名第三。

Conclusion: 结合课程学习与强化学习的训练方法在多模态问答任务中表现优异。

Abstract: This paper describes the solutions of the Dianping-Trust-Safety team for the
META CRAG-MM challenge. The challenge requires building a comprehensive
retrieval-augmented generation system capable for multi-modal multi-turn
question answering. The competition consists of three tasks: (1) answering
questions using structured data retrieved from an image-based mock knowledge
graph, (2) synthesizing information from both knowledge graphs and web search
results, and (3) handling multi-turn conversations that require context
understanding and information aggregation from multiple sources. For Task 1,
our solution is based on the vision large language model, enhanced by
supervised fine-tuning with knowledge distilled from GPT-4.1. We further
applied curriculum learning strategies to guide reinforcement learning,
resulting in improved answer accuracy and reduced hallucination. For Task 2 and
Task 3, we additionally leveraged web search APIs to incorporate external
knowledge, enabling the system to better handle complex queries and multi-turn
conversations. Our approach achieved 1st place in Task 1 with a significant
lead of 52.38\%, and 3rd place in Task 3, demonstrating the effectiveness of
the integration of curriculum learning with reinforcement learning in our
training pipeline.

</details>


### [35] [Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach](https://arxiv.org/abs/2508.10340)
*Chak Lam Shek,Guangyao Shi,Pratap Tokekar*

Main category: cs.AI

TL;DR: 论文提出两种方法（HATRPO-W和HATRPO-G）来优化多智能体强化学习中的KL散度阈值分配，显著提升了HATRPO的性能。


<details>
  <summary>Details</summary>
Motivation: 传统HATRPO方法中，为所有智能体分配相同的KL散度阈值可能导致训练缓慢和局部最优，尤其在异构环境中。

Method: 提出HATRPO-W（基于KKT条件优化全局KL约束）和HATRPO-G（基于改进-散度比的贪心算法）来动态分配KL阈值。

Result: 实验表明，两种方法均显著提升性能（超过22.5%），HATRPO-W还表现出更稳定的学习动态。

Conclusion: 动态分配KL阈值能有效提升异构多智能体强化学习的性能和稳定性。

Abstract: Multi-agent reinforcement learning (MARL) requires coordinated and stable
policy updates among interacting agents. Heterogeneous-Agent Trust Region
Policy Optimization (HATRPO) enforces per-agent trust region constraints using
Kullback-Leibler (KL) divergence to stabilize training. However, assigning each
agent the same KL threshold can lead to slow and locally optimal updates,
especially in heterogeneous settings. To address this limitation, we propose
two approaches for allocating the KL divergence threshold across agents:
HATRPO-W, a Karush-Kuhn-Tucker-based (KKT-based) method that optimizes
threshold assignment under global KL constraints, and HATRPO-G, a greedy
algorithm that prioritizes agents based on improvement-to-divergence ratio. By
connecting sequential policy optimization with constrained threshold
scheduling, our approach enables more flexible and effective learning in
heterogeneous-agent settings. Experimental results demonstrate that our methods
significantly boost the performance of HATRPO, achieving faster convergence and
higher final rewards across diverse MARL benchmarks. Specifically, HATRPO-W and
HATRPO-G achieve comparable improvements in final performance, each exceeding
22.5%. Notably, HATRPO-W also demonstrates more stable learning dynamics, as
reflected by its lower variance.

</details>


### [36] [What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles](https://arxiv.org/abs/2508.10358)
*Mengtao Zhou,Sifan Wu,Huan Zhang,Qi Sima,Bang Liu*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型（LLMs）在信息稀疏环境中的想象推理能力，提出了基于“Turtle Soup”游戏的框架，包括新基准、代理和评估协议。


<details>
  <summary>Details</summary>
Motivation: 现有基准多为静态或关注社交推理，无法捕捉动态探索性推理过程，因此需要新方法评估LLMs的想象推理能力。

Method: 引入TurtleSoup-Bench（800个双语谜题）和Mosaic-Agent，开发多维评估协议（逻辑一致性、细节完整性和结论对齐）。

Result: 实验显示LLMs在想象推理中存在明显能力限制和常见失败模式，与人类表现有显著差距。

Conclusion: 研究为LLMs的想象推理能力提供了新见解，为未来探索性代理行为研究奠定了基础。

Abstract: We investigate the capacity of Large Language Models (LLMs) for imaginative
reasoning--the proactive construction, testing, and revision of hypotheses in
information-sparse environments. Existing benchmarks, often static or focused
on social deduction, fail to capture the dynamic, exploratory nature of this
reasoning process. To address this gap, we introduce a comprehensive research
framework based on the classic "Turtle Soup" game, integrating a benchmark, an
agent, and an evaluation protocol. We present TurtleSoup-Bench, the first
large-scale, bilingual, interactive benchmark for imaginative reasoning,
comprising 800 turtle soup puzzles sourced from both the Internet and expert
authors. We also propose Mosaic-Agent, a novel agent designed to assess LLMs'
performance in this setting. To evaluate reasoning quality, we develop a
multi-dimensional protocol measuring logical consistency, detail completion,
and conclusion alignment. Experiments with leading LLMs reveal clear capability
limits, common failure patterns, and a significant performance gap compared to
humans. Our work offers new insights into LLMs' imaginative reasoning and
establishes a foundation for future research on exploratory agent behavior.

</details>


### [37] [LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval](https://arxiv.org/abs/2508.10391)
*Yaoze Zhang,Rong Wu,Pinlong Cai,Xiaoman Wang,Guohang Yan,Song Mao,Ding Wang,Botian Shi*

Main category: cs.AI

TL;DR: LeanRAG通过知识聚合和检索策略的深度协作设计，解决了现有知识图谱RAG方法中的语义孤岛和检索效率问题，显著提升了问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱RAG方法存在语义孤岛和检索效率低的问题，限制了其有效性。

Method: LeanRAG采用语义聚合算法构建实体集群和显式关系，并结合自底向上的结构引导检索策略。

Result: 在四个QA基准测试中，LeanRAG显著优于现有方法，同时减少46%的检索冗余。

Conclusion: LeanRAG通过优化知识组织和检索策略，有效提升了RAG的性能和效率。

Abstract: Retrieval-Augmented Generation (RAG) plays a crucial role in grounding Large
Language Models by leveraging external knowledge, whereas the effectiveness is
often compromised by the retrieval of contextually flawed or incomplete
information. To address this, knowledge graph-based RAG methods have evolved
towards hierarchical structures, organizing knowledge into multi-level
summaries. However, these approaches still suffer from two critical,
unaddressed challenges: high-level conceptual summaries exist as disconnected
``semantic islands'', lacking the explicit relations needed for cross-community
reasoning; and the retrieval process itself remains structurally unaware, often
degenerating into an inefficient flat search that fails to exploit the graph's
rich topology. To overcome these limitations, we introduce LeanRAG, a framework
that features a deeply collaborative design combining knowledge aggregation and
retrieval strategies. LeanRAG first employs a novel semantic aggregation
algorithm that forms entity clusters and constructs new explicit relations
among aggregation-level summaries, creating a fully navigable semantic network.
Then, a bottom-up, structure-guided retrieval strategy anchors queries to the
most relevant fine-grained entities and then systematically traverses the
graph's semantic pathways to gather concise yet contextually comprehensive
evidence sets. The LeanRAG can mitigate the substantial overhead associated
with path retrieval on graphs and minimizes redundant information retrieval.
Extensive experiments on four challenging QA benchmarks with different domains
demonstrate that LeanRAG significantly outperforming existing methods in
response quality while reducing 46\% retrieval redundancy. Code is available
at: https://github.com/RaZzzyz/LeanRAG

</details>


### [38] [HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation](https://arxiv.org/abs/2508.10425)
*Yan Ting Chok,Soyon Park,Seungheun Baek,Hajung Kim,Junhyun Lee,Jaewoo Kang*

Main category: cs.AI

TL;DR: HiRef框架结合医学本体层次结构和EHR共现模式，提升药物推荐的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决EHR数据中罕见实体和缺失记录导致的泛化问题。

Method: 使用双曲空间嵌入医学本体，结合先验引导的稀疏正则化优化EHR共现图。

Result: 在MIMIC-III和MIMIC-IV基准测试中表现优异，对未见代码保持高准确性。

Conclusion: HiRef通过结合本体和EHR数据，显著提升了药物推荐的鲁棒性和泛化能力。

Abstract: Medication recommendation is a crucial task for assisting physicians in
making timely decisions from longitudinal patient medical records. However,
real-world EHR data present significant challenges due to the presence of
rarely observed medical entities and incomplete records that may not fully
capture the clinical ground truth. While data-driven models trained on
longitudinal Electronic Health Records often achieve strong empirical
performance, they struggle to generalize under missing or novel conditions,
largely due to their reliance on observed co-occurrence patterns. To address
these issues, we propose Hierarchical Ontology and Network Refinement for
Robust Medication Recommendation (HiRef), a unified framework that combines two
complementary structures: (i) the hierarchical semantics encoded in curated
medical ontologies, and (ii) refined co-occurrence patterns derived from
real-world EHRs. We embed ontology entities in hyperbolic space, which
naturally captures tree-like relationships and enables knowledge transfer
through shared ancestors, thereby improving generalizability to unseen codes.
To further improve robustness, we introduce a prior-guided sparse
regularization scheme that refines the EHR co-occurrence graph by suppressing
spurious edges while preserving clinically meaningful associations. Our model
achieves strong performance on EHR benchmarks (MIMIC-III and MIMIC-IV) and
maintains high accuracy under simulated unseen-code settings. Extensive
experiments with comprehensive ablation studies demonstrate HiRef's resilience
to unseen medical codes, supported by in-depth analyses of the learned
sparsified graph structure and medical code embeddings.

</details>


### [39] [MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance](https://arxiv.org/abs/2508.10429)
*Yi Dong,Yusuke Muraoka,Scott Shi,Yi Zhang*

Main category: cs.AI

TL;DR: MM-Food-100K是一个公开的10万样本多模态食品数据集，具有可验证来源，用于食品智能研究。


<details>
  <summary>Details</summary>
Motivation: 提供高质量、可追溯的食品数据集，支持多模态食品智能研究。

Method: 通过Codatta贡献模型收集数据，结合社区众包和AI辅助质量检查，并采用链下账本确保可追溯性。

Result: 在图像营养预测任务中，微调大型视觉语言模型（如ChatGPT 5）表现优于基线。

Conclusion: MM-Food-100K的发布为食品智能研究提供了有价值的资源，未来可能扩展商业用途。

Abstract: We present MM-Food-100K, a public 100,000-sample multimodal food intelligence
dataset with verifiable provenance. It is a curated approximately 10% open
subset of an original 1.2 million, quality-accepted corpus of food images
annotated for a wide range of information (such as dish name, region of
creation). The corpus was collected over six weeks from over 87,000
contributors using the Codatta contribution model, which combines community
sourcing with configurable AI-assisted quality checks; each submission is
linked to a wallet address in a secure off-chain ledger for traceability, with
a full on-chain protocol on the roadmap. We describe the schema, pipeline, and
QA, and validate utility by fine-tuning large vision-language models (ChatGPT
5, ChatGPT OSS, Qwen-Max) on image-based nutrition prediction. Fine-tuning
yields consistent gains over out-of-box baselines across standard metrics; we
report results primarily on the MM-Food-100K subset. We release MM-Food-100K
for publicly free access and retain approximately 90% for potential commercial
access with revenue sharing to contributors.

</details>


### [40] [We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning](https://arxiv.org/abs/2508.10433)
*Runqi Qiao,Qiuna Tan,Peiqing Yang,Yanzi Wang,Xiaowan Wang,Enhui Wan,Sitong Zhou,Guanting Dong,Yuchen Zeng,Yida Xu,Jie Wang,Chong Sun,Chen Li,Honggang Zhang*

Main category: cs.AI

TL;DR: We-Math 2.0通过结构化数学知识系统、模型中心数据空间建模和强化学习训练范式，显著提升多模态大语言模型的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注数据集构建和方法优化，但忽视了知识驱动设计和数据空间建模的重要性。

Method: 提出MathBook知识系统、MathBook-Standard & Pro数据集、MathBook-RL两阶段强化学习框架和MathBookEval基准。

Result: 在四个基准测试中表现优异，并在MathBookEval上展现出强泛化能力。

Conclusion: We-Math 2.0为提升MLLMs的数学推理能力提供了全面解决方案。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive
capabilities across various tasks, but still struggle with complex mathematical
reasoning. Existing research primarily focuses on dataset construction and
method optimization, often overlooking two critical aspects: comprehensive
knowledge-driven design and model-centric data space modeling. In this paper,
we introduce We-Math 2.0, a unified system that integrates a structured
mathematical knowledge system, model-centric data space modeling, and a
reinforcement learning (RL)-based training paradigm to comprehensively enhance
the mathematical reasoning abilities of MLLMs. The key contributions of We-Math
2.0 are fourfold: (1) MathBook Knowledge System: We construct a five-level
hierarchical system encompassing 491 knowledge points and 1,819 fundamental
principles. (2) MathBook-Standard & Pro: We develop MathBook-Standard, a
dataset that ensures broad conceptual coverage and flexibility through dual
expansion. Additionally, we define a three-dimensional difficulty space and
generate 7 progressive variants per problem to build MathBook-Pro, a
challenging dataset for robust training. (3) MathBook-RL: We propose a
two-stage RL framework comprising: (i) Cold-Start Fine-tuning, which aligns the
model with knowledge-oriented chain-of-thought reasoning; and (ii) Progressive
Alignment RL, leveraging average-reward learning and dynamic data scheduling to
achieve progressive alignment across difficulty levels. (4) MathBookEval: We
introduce a comprehensive benchmark covering all 491 knowledge points with
diverse reasoning step distributions. Experimental results show that
MathBook-RL performs competitively with existing baselines on four widely-used
benchmarks and achieves strong results on MathBookEval, suggesting promising
generalization in mathematical reasoning.

</details>


### [41] [FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs](https://arxiv.org/abs/2508.10467)
*Xueli Pan,Victor de Boer,Jacco van Ossenbruggen*

Main category: cs.AI

TL;DR: 论文提出FIRESPARQL框架，通过微调LLM、检索增强生成和SPARQL查询修正层，解决学术知识图谱问答中LLM生成SPARQL查询的结构和语义错误。


<details>
  <summary>Details</summary>
Motivation: 学术知识图谱问答中，LLM生成的SPARQL查询存在结构不一致和语义不准确的问题，需要改进。

Method: 提出FIRESPARQL框架，结合微调LLM、检索增强生成（RAG）和SPARQL查询修正层，评估不同配置（零样本、单样本、微调等）。

Result: 微调配置表现最佳，测试集上ROUGE-L为0.90，RelaxedEM为0.85。

Conclusion: FIRESPARQL框架显著提升了学术知识图谱问答的准确性和性能。

Abstract: Question answering over Scholarly Knowledge Graphs (SKGs) remains a
challenging task due to the complexity of scholarly content and the intricate
structure of these graphs. Large Language Model (LLM) approaches could be used
to translate natural language questions (NLQs) into SPARQL queries; however,
these LLM-based approaches struggle with SPARQL query generation due to limited
exposure to SKG-specific content and the underlying schema. We identified two
main types of errors in the LLM-generated SPARQL queries: (i) structural
inconsistencies, such as missing or redundant triples in the queries, and (ii)
semantic inaccuracies, where incorrect entities or properties are shown in the
queries despite a correct query structure. To address these issues, we propose
FIRESPARQL, a modular framework that supports fine-tuned LLMs as a core
component, with optional context provided via retrieval-augmented generation
(RAG) and a SPARQL query correction layer. We evaluate the framework on the
SciQA Benchmark using various configurations (zero-shot, zero-shot with RAG,
one-shot, fine-tuning, and fine-tuning with RAG) and compare the performance
with baseline and state-of-the-art approaches. We measure query accuracy using
BLEU and ROUGE metrics, and query result accuracy using relaxed exact
match(RelaxedEM), with respect to the gold standards containing the NLQs,
SPARQL queries, and the results of the queries. Experimental results
demonstrate that fine-tuning achieves the highest overall performance, reaching
0.90 ROUGE-L for query accuracy and 0.85 RelaxedEM for result accuracy on the
test set.

</details>


### [42] [SEQ-GPT: LLM-assisted Spatial Query via Example](https://arxiv.org/abs/2508.10486)
*Ivan Khai Ze Lim,Ningyi Liao,Yiming Yang,Gerald Wei Yong Yip,Siqiang Luo*

Main category: cs.AI

TL;DR: 论文提出了一种基于大型语言模型（LLMs）的空间查询系统SEQ-GPT，用于通过自然语言实现更灵活的空间范例查询（SEQ）。


<details>
  <summary>Details</summary>
Motivation: 当前空间服务（如在线地图）主要依赖用户查询进行位置搜索，但在执行复杂任务（如同时搜索多个相关位置）时用户体验受限。

Method: 引入SEQ-GPT系统，利用LLMs的语言能力实现自然语言交互，包括澄清查询细节和动态调整搜索。提出了一种定制化的LLM适应流程，通过对话合成和多模型协作将自然语言与结构化空间数据对齐。

Result: SEQ-GPT为扩展空间搜索提供了端到端的解决方案，支持真实数据和实际应用场景。

Conclusion: SEQ-GPT通过LLMs的自然语言处理能力，显著提升了复杂空间查询的交互性和灵活性。

Abstract: Contemporary spatial services such as online maps predominantly rely on user
queries for location searches. However, the user experience is limited when
performing complex tasks, such as searching for a group of locations
simultaneously. In this study, we examine the extended scenario known as
Spatial Exemplar Query (SEQ), where multiple relevant locations are jointly
searched based on user-specified examples. We introduce SEQ-GPT, a spatial
query system powered by Large Language Models (LLMs) towards more versatile SEQ
search using natural language. The language capabilities of LLMs enable unique
interactive operations in the SEQ process, including asking users to clarify
query details and dynamically adjusting the search based on user feedback. We
also propose a tailored LLM adaptation pipeline that aligns natural language
with structured spatial data and queries through dialogue synthesis and
multi-model cooperation. SEQ-GPT offers an end-to-end demonstration for
broadening spatial search with realistic data and application scenarios.

</details>


### [43] [Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model](https://arxiv.org/abs/2508.10492)
*Shicheng Xu,Xin Huang,Zihao Wei,Liang Pang,Huawei Shen,Xueqi Cheng*

Main category: cs.AI

TL;DR: 论文提出DxDirector-7B，一种能够主导全流程临床诊断的AI模型，显著减少医生工作量并提高诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 当前AI在临床诊断中仅作为辅助工具，无法主导全流程诊断，限制了其减轻医生负担和提升效率的潜力。

Method: 提出DxDirector-7B，一种具备深度思考能力的LLM，能够主导诊断流程并建立责任框架。

Result: 在罕见、复杂和真实案例中，DxDirector-7B显著优于现有医学LLM和通用LLM，减少医生工作量。

Conclusion: DxDirector-7B标志着AI从辅助工具转变为诊断主导者，为高效准确的诊断提供了新解决方案。

Abstract: Full-process clinical diagnosis in the real world encompasses the entire
diagnostic workflow that begins with only an ambiguous chief complaint. While
artificial intelligence (AI), particularly large language models (LLMs), is
transforming clinical diagnosis, its role remains largely as an assistant to
physicians. This AI-assisted working pattern makes AI can only answer specific
medical questions at certain parts within the diagnostic process, but lack the
ability to drive the entire diagnostic process starting from an ambiguous
complaint, which still relies heavily on human physicians. This gap limits AI's
ability to fully reduce physicians' workload and enhance diagnostic efficiency.
To address this, we propose a paradigm shift that reverses the relationship
between physicians and AI: repositioning AI as the primary director, with
physicians serving as its assistants. So we present DxDirector-7B, an LLM
endowed with advanced deep thinking capabilities, enabling it to drive the
full-process diagnosis with minimal physician involvement. Furthermore,
DxDirector-7B establishes a robust accountability framework for misdiagnoses,
delineating responsibility between AI and human physicians. In evaluations
across rare, complex, and real-world cases under full-process diagnosis
setting, DxDirector-7B not only achieves significant superior diagnostic
accuracy but also substantially reduces physician workload than
state-of-the-art medical LLMs as well as general-purpose LLMs. Fine-grained
analyses across multiple clinical departments and tasks validate its efficacy,
with expert evaluations indicating its potential to serve as a viable
substitute for medical specialists. These findings mark a new era where AI,
traditionally a physicians' assistant, now drives the entire diagnostic process
to drastically reduce physicians' workload, indicating an efficient and
accurate diagnostic solution.

</details>


### [44] [Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based Generalized Planning](https://arxiv.org/abs/2508.10747)
*Sangwoo Jeon,Juchul Shin,Gyeong-Tae Kim,YeonJe Cho,Seongwoo Kim*

Main category: cs.AI

TL;DR: 提出了一种稀疏、目标感知的GNN表示方法，解决了大规模规划问题中密集图表示的信息稀释和内存爆炸问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用全连接图表示规划状态，导致信息稀疏和内存需求指数增长，难以应对大规模问题。

Method: 采用稀疏、目标感知的GNN表示，选择性编码局部关系并显式整合目标相关空间特征。

Result: 实验验证了该方法在大规模网格环境中有效扩展，显著提升策略泛化性和成功率。

Conclusion: 为大规模广义规划任务提供了实用基础。

Abstract: Generalized planning using deep reinforcement learning (RL) combined with
graph neural networks (GNNs) has shown promising results in various symbolic
planning domains described by PDDL. However, existing approaches typically
represent planning states as fully connected graphs, leading to a combinatorial
explosion in edge information and substantial sparsity as problem scales grow,
especially evident in large grid-based environments. This dense representation
results in diluted node-level information, exponentially increases memory
requirements, and ultimately makes learning infeasible for larger-scale
problems. To address these challenges, we propose a sparse, goal-aware GNN
representation that selectively encodes relevant local relationships and
explicitly integrates spatial features related to the goal. We validate our
approach by designing novel drone mission scenarios based on PDDL within a grid
world, effectively simulating realistic mission execution environments. Our
experimental results demonstrate that our method scales effectively to larger
grid sizes previously infeasible with dense graph representations and
substantially improves policy generalization and success rates. Our findings
provide a practical foundation for addressing realistic, large-scale
generalized planning tasks.

</details>


### [45] [PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning](https://arxiv.org/abs/2508.10501)
*Yushi Feng,Junye Du,Yingying Hong,Qifan Wang,Lequan Yu*

Main category: cs.AI

TL;DR: PASS是一个多模态框架，通过概率标注的决策路径和自适应工具选择，解决了现有工具增强代理系统在医疗AI中的信任、多模态集成和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有系统存在黑盒推理、多模态集成不足和效率低下等问题，限制了其在医疗任务中的应用。PASS旨在解决这些问题，提升医疗AI的安全性和适应性。

Method: PASS通过多工具图自适应采样代理工作流，利用任务条件分布选择工具，并通过三阶段训练优化性能与成本平衡。

Result: PASS在多个指标上显著优于基线模型，同时平衡了计算成本，推动了可解释、自适应和多模态医疗代理系统的发展。

Conclusion: PASS为医疗AI提供了一种可解释、高效且多模态的解决方案，为未来医疗代理系统设定了新范式。

Abstract: Existing tool-augmented agentic systems are limited in the real world by (i)
black-box reasoning steps that undermine trust of decision-making and pose
safety risks, (ii) poor multimodal integration, which is inherently critical
for healthcare tasks, and (iii) rigid and computationally inefficient agentic
pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the
first multimodal framework to address these challenges in the context of Chest
X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a
multi-tool graph, yielding decision paths annotated with interpretable
probabilities. Given the complex CXR reasoning task with multimodal medical
data, PASS leverages its learned task-conditioned distribution over the agentic
supernet. Thus, it adaptively selects the most suitable tool at each supernet
layer, offering probability-annotated trajectories for post-hoc audits and
directly enhancing medical AI safety. PASS also continuously compresses salient
findings into an evolving personalized memory, while dynamically deciding
whether to deepen its reasoning path or invoke an early exit for efficiency. To
optimize a Pareto frontier balancing performance and cost, we design a novel
three-stage training procedure, including expert knowledge warm-up, contrastive
path-ranking, and cost-aware reinforcement learning. To facilitate rigorous
evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step,
safety-critical, free-form CXR reasoning. Experiments across various benchmarks
validate that PASS significantly outperforms strong baselines in multiple
metrics (e.g., accuracy, AUC, LLM-J.) while balancing computational costs,
pushing a new paradigm shift towards interpretable, adaptive, and multimodal
medical agentic systems.

</details>


### [46] [Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment](https://arxiv.org/abs/2508.10530)
*Zetian Sun,Dongfang Li,Baotian Hu*

Main category: cs.AI

TL;DR: 论文探讨了语言模型（LM）对齐人类偏好的方法，发现动态策略数据（on-policy）并非总是最优，并提出对齐阶段假设来解释这一现象。


<details>
  <summary>Details</summary>
Motivation: 语言模型对齐人类偏好对构建可靠AI系统至关重要，但现有方法（如DPO）的动态策略数据效果不稳定，需深入研究。

Method: 提出对齐阶段假设，将对齐分为偏好注入和偏好微调两阶段，并通过理论和实验分析验证其有效性。

Result: 实验表明，动态策略数据在不同模型（如Llama-3和Zephyr）中效果差异显著（3× vs. 0.4×），验证了阶段假设的普适性。

Conclusion: 对齐阶段假设为LM对齐提供了新视角，动态策略数据的效果需根据阶段选择，未来可优化算法以提升对齐效率。

Abstract: The alignment of language models (LMs) with human preferences is critical for
building reliable AI systems. The problem is typically framed as optimizing an
LM policy to maximize the expected reward that reflects human preferences.
Recently, Direct Preference Optimization (DPO) was proposed as a LM alignment
method that directly optimize the policy from static preference data, and
further improved by incorporating on-policy sampling (i.e., preference
candidates generated during the training loop) for better LM alignment.
However, we show on-policy data is not always optimal, with systematic
effectiveness difference emerging between static and on-policy preference
candidates. For example, on-policy data can result in a 3$\times$ effectiveness
compared with static data for Llama-3, and a 0.4$\times$ effectiveness for
Zephyr. To explain the phenomenon, we propose the alignment stage assumption,
which divides the alignment process into two distinct stages: the preference
injection stage, which benefits from diverse data, and the preference
fine-tuning stage, which favors high-quality data. Through theoretical and
empirical analysis, we characterize these stages and propose an effective
algorithm to identify the boundaries between them. We perform experiments on 5
models (Llama, Zephyr, Phi-2, Qwen, Pythia) and 2 alignment methods (DPO,
SLiC-HF) to show the generalizability of alignment stage assumption and
boundary measurement.

</details>


### [47] [Improving Value-based Process Verifier via Low-Cost Variance Reduction](https://arxiv.org/abs/2508.10539)
*Zetian Sun,Dongfang Li,Baotian Hu,Min Zhang*

Main category: cs.AI

TL;DR: 论文提出ComMCS方法，通过结合当前和后续步骤的蒙特卡洛估计器，减少方差并保持无偏估计，显著提升大语言模型在数学推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂领域（如数学）的推理能力仍有限，现有基于值的验证方法因蒙特卡洛采样方差高而效果受限。

Method: 提出ComMCS方法，线性组合当前和后续步骤的蒙特卡洛估计器，降低方差且无需额外推理成本。

Result: 在MATH-500和GSM8K基准测试中，ComMCS显著优于基线方法，如Best-of-32实验中提升2.8分。

Conclusion: ComMCS通过减少方差有效提升推理验证性能，为复杂任务中的大语言模型优化提供新思路。

Abstract: Large language models (LLMs) have achieved remarkable success in a wide range
of tasks. However, their reasoning capabilities, particularly in complex
domains like mathematics, remain a significant challenge. Value-based process
verifiers, which estimate the probability of a partial reasoning chain leading
to a correct solution, are a promising approach for improving reasoning.
Nevertheless, their effectiveness is often hindered by estimation error in
their training annotations, a consequence of the limited number of Monte Carlo
(MC) samples feasible due to the high cost of LLM inference. In this paper, we
identify that the estimation error primarily arises from high variance rather
than bias, and the MC estimator is a Minimum Variance Unbiased Estimator
(MVUE). To address the problem, we propose the \textsc{Com}pound \textsc{M}onte
\textsc{C}arlo \textsc{S}ampling (ComMCS) method, which constructs an unbiased
estimator by linearly combining the MC estimators from the current and
subsequent steps. Theoretically, we show that our method leads to a predictable
reduction in variance, while maintaining an unbiased estimation without
additional LLM inference cost. We also perform empirical experiments on the
MATH-500 and GSM8K benchmarks to demonstrate the effectiveness of our method.
Notably, ComMCS outperforms regression-based optimization method by 2.8 points,
the non-variance-reduced baseline by 2.2 points on MATH-500 on Best-of-32
sampling experiment.

</details>


### [48] [MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models](https://arxiv.org/abs/2508.10599)
*Xinyan Jiang,Lin Zhang,Jiayi Zhang,Qingsong Yang,Guimin Hu,Di Wang,Lijie Hu*

Main category: cs.AI

TL;DR: MSRS提出了一种多属性控制框架，通过正交子空间分配和混合子空间组合策略减少属性干扰，实现精细行为调控。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多属性联合控制时存在干扰和权衡问题，MSRS旨在解决这一问题。

Method: MSRS通过正交子空间分配隔离属性影响，结合共享子空间和动态权重函数实现精确控制，并引入令牌级调控机制。

Result: 实验表明MSRS显著减少属性冲突，优于现有方法，并能泛化到多种下游任务。

Conclusion: MSRS为多属性控制提供了一种有效且通用的解决方案。

Abstract: Activation steering offers a promising approach to controlling the behavior
of Large Language Models by directly manipulating their internal activations.
However, most existing methods struggle to jointly steer multiple attributes,
often resulting in interference and undesirable trade-offs. To address this
challenge, we propose Multi-Subspace Representation Steering (MSRS), a novel
framework for effective multi-attribute steering via subspace representation
fine-tuning. MSRS reduces inter-attribute interference by allocating orthogonal
subspaces to each attribute, isolating their influence within the model's
representation space. MSRS also incorporates a hybrid subspace composition
strategy: it combines attribute-specific subspaces for unique steering
directions with a shared subspace for common steering directions. A dynamic
weighting function learns to efficiently integrate these components for precise
control. During inference, MSRS introduces a token-level steering mechanism
that dynamically identifies and intervenes on the most semantically relevant
tokens, enabling fine-grained behavioral modulation. Experimental results show
that MSRS significantly reduces attribute conflicts, surpasses existing methods
across a range of attributes, and generalizes effectively to diverse downstream
tasks.

</details>


### [49] [STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation](https://arxiv.org/abs/2508.10669)
*Zhenye Yang,Jinpeng Chen,Huan Li,Xiongnan Jin,Xuanyang Li,Junwei Zhang,Hongbo Gao,Kaimin Wei,Senzhang Wang*

Main category: cs.AI

TL;DR: STEP是一种基于预训练语言模型的对话推荐系统，通过课程引导的上下文-知识融合和轻量级任务特定提示调优，显著提升了推荐和对话质量。


<details>
  <summary>Details</summary>
Motivation: 现有对话推荐系统在捕捉用户偏好深度语义和对话上下文方面存在挑战，尤其是如何高效整合外部知识图谱信息。

Method: STEP采用三阶段课程逐步对齐对话上下文与知识图谱实体，并通过双提示方案（对话前缀和推荐前缀）注入冻结的语言模型。

Result: STEP在两个公共数据集上的推荐精度和对话质量优于主流方法。

Conclusion: STEP通过上下文-知识融合和双提示方案，有效解决了语义对齐问题，提升了推荐和对话性能。

Abstract: Conversational recommender systems (CRSs) aim to proactively capture user
preferences through natural language dialogue and recommend high-quality items.
To achieve this, CRS gathers user preferences via a dialog module and builds
user profiles through a recommendation module to generate appropriate
recommendations. However, existing CRS faces challenges in capturing the deep
semantics of user preferences and dialogue context. In particular, the
efficient integration of external knowledge graph (KG) information into
dialogue generation and recommendation remains a pressing issue. Traditional
approaches typically combine KG information directly with dialogue content,
which often struggles with complex semantic relationships, resulting in
recommendations that may not align with user expectations.
  To address these challenges, we introduce STEP, a conversational recommender
centered on pre-trained language models that combines curriculum-guided
context-knowledge fusion with lightweight task-specific prompt tuning. At its
heart, an F-Former progressively aligns the dialogue context with
knowledge-graph entities through a three-stage curriculum, thus resolving
fine-grained semantic mismatches. The fused representation is then injected
into the frozen language model via two minimal yet adaptive prefix prompts: a
conversation prefix that steers response generation toward user intent and a
recommendation prefix that biases item ranking toward knowledge-consistent
candidates. This dual-prompt scheme allows the model to share cross-task
semantics while respecting the distinct objectives of dialogue and
recommendation. Experimental results show that STEP outperforms mainstream
methods in the precision of recommendation and dialogue quality in two public
datasets.

</details>


### [50] [GenOM: Ontology Matching with Description Generation and Large Language Model](https://arxiv.org/abs/2508.10703)
*Yiping Song,Jiaoyan Chen,Renate A. Schmidt*

Main category: cs.AI

TL;DR: GenOM是一种基于大型语言模型的框架，通过生成文本定义、嵌入模型检索和对齐工具提升本体匹配性能，在生物医学领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决生物医学领域异构知识源间的语义互操作性问题，提升本体匹配的准确性和效率。

Method: 结合生成文本定义、嵌入模型检索和精确匹配工具，进行本体对齐。

Result: 在OAEI Bio-ML测试中表现优异，超越传统方法和近期LLM方法。

Conclusion: GenOM框架通过语义增强和少样本提示，展现出强大的适应性和鲁棒性。

Abstract: Ontology matching (OM) plays an essential role in enabling semantic
interoperability and integration across heterogeneous knowledge sources,
particularly in the biomedical domain which contains numerous complex concepts
related to diseases and pharmaceuticals. This paper introduces GenOM, a large
language model (LLM)-based ontology alignment framework, which enriches the
semantic representations of ontology concepts via generating textual
definitions, retrieves alignment candidates with an embedding model, and
incorporates exact matching-based tools to improve precision. Extensive
experiments conducted on the OAEI Bio-ML track demonstrate that GenOM can often
achieve competitive performance, surpassing many baselines including
traditional OM systems and recent LLM-based methods. Further ablation studies
confirm the effectiveness of semantic enrichment and few-shot prompting,
highlighting the framework's robustness and adaptability.

</details>


### [51] [Agentic Design Review System](https://arxiv.org/abs/2508.10745)
*Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan*

Main category: cs.AI

TL;DR: 提出了一种多代理协作的设计评审系统（AgenticDRS），通过图匹配和提示扩展方法提升代理的设计意识，并在DRS-BENCH基准上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 图形设计评估需要多维度综合反馈，但现有方法缺乏系统性。

Method: 采用多代理协作框架，结合图匹配和提示扩展技术，由元代理协调评审。

Result: 实验表明AgenticDRS在评估设计和生成反馈方面优于现有方法。

Conclusion: 该系统为设计评估提供了实用解决方案，并呼吁更多关注这一研究方向。

Abstract: Evaluating graphic designs involves assessing it from multiple facets like
alignment, composition, aesthetics and color choices. Evaluating designs in a
holistic way involves aggregating feedback from individual expert reviewers.
Towards this, we propose an Agentic Design Review System (AgenticDRS), where
multiple agents collaboratively analyze a design, orchestrated by a meta-agent.
A novel in-context exemplar selection approach based on graph matching and a
unique prompt expansion method plays central role towards making each agent
design aware. Towards evaluating this framework, we propose DRS-BENCH
benchmark. Thorough experimental evaluation against state-of-the-art baselines
adapted to the problem setup, backed-up with critical ablation experiments
brings out the efficacy of Agentic-DRS in evaluating graphic designs and
generating actionable feedback. We hope that this work will attract attention
to this pragmatic, yet under-explored research direction.

</details>


### [52] [Modeling Human Responses to Multimodal AI Content](https://arxiv.org/abs/2508.10769)
*Zhiqi Shen,Shaojing Fan,Danni Xu,Terence Sim,Mohan Kankanhalli*

Main category: cs.AI

TL;DR: 论文研究了AI生成内容对人类感知和行为的影响，提出MhAIM数据集和T-Lens系统，量化用户对内容的信任度、影响力和开放性，并设计HR-MCP协议以增强LLM的人类感知能力。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容的普及，其潜在风险（如虚假信息）日益凸显。现有研究多关注内容真实性，而对其如何影响人类行为的研究较少。尤其在金融等领域，预测人类反应比验证内容真实性更为关键。

Method: 引入MhAIM数据集（含154,552条在线帖子，其中111,153条为AI生成），通过人类研究分析多模态内容对识别AI生成内容的影响。提出信任度、影响力和开放性三项新指标，并开发基于LLM的T-Lens系统，集成HR-MCP协议以预测人类反应。

Result: 研究发现，当帖子包含图文且内容不一致时，人类更容易识别AI生成内容。T-Lens系统通过HR-MCP协议显著提升了LLM对人类反应的预测能力。

Conclusion: 研究为LLM提供了人类感知能力的实证工具，揭示了AI、人类认知与信息接收的复杂关系，为减少AI虚假信息风险提供了可行策略。

Abstract: As AI-generated content becomes widespread, so does the risk of
misinformation. While prior research has primarily focused on identifying
whether content is authentic, much less is known about how such content
influences human perception and behavior. In domains like trading or the stock
market, predicting how people react (e.g., whether a news post will go viral),
can be more critical than verifying its factual accuracy. To address this, we
take a human-centered approach and introduce the MhAIM Dataset, which contains
154,552 online posts (111,153 of them AI-generated), enabling large-scale
analysis of how people respond to AI-generated content. Our human study reveals
that people are better at identifying AI content when posts include both text
and visuals, particularly when inconsistencies exist between the two. We
propose three new metrics: trustworthiness, impact, and openness, to quantify
how users judge and engage with online content. We present T-Lens, an LLM-based
agent system designed to answer user queries by incorporating predicted human
responses to multimodal information. At its core is HR-MCP (Human Response
Model Context Protocol), built on the standardized Model Context Protocol
(MCP), enabling seamless integration with any LLM. This integration allows
T-Lens to better align with human reactions, enhancing both interpretability
and interaction capabilities. Our work provides empirical insights and
practical tools to equip LLMs with human-awareness capabilities. By
highlighting the complex interplay among AI, human cognition, and information
reception, our findings suggest actionable strategies for mitigating the risks
of AI-driven misinformation.

</details>


### [53] [The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference](https://arxiv.org/abs/2508.10777)
*Maël Jullien,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: 研究发现，尽管大型语言模型在临床知识访问上表现优异，但在复杂推理任务中表现不佳，揭示了其内部表征的结构性局限。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型是否通过数据规模和参数扩展获得结构化、可泛化的内部表征，尤其是在高风险的临床推理领域。

Method: 引入临床试验自然语言推理基准（CT-NLI），包含四种推理类型，并设计GKMRV探针分离知识访问与推理失败。评估六种当代LLM在直接和思维链提示下的表现。

Result: 模型在GKMRV探针上表现优异（平均准确率0.918），但在主推理任务中表现差（平均准确率0.25），输出推理高度一致（一致性0.87），表明其依赖启发式方法。

Conclusion: 当前LLM缺乏结构化、可组合的内部表征，限制了其在复杂推理任务中的可靠性，GKMRV框架为评估高风险领域LLM提供了有效工具。

Abstract: Large language models are often assumed to acquire increasingly structured,
generalizable internal representations simply by scaling data and parameters.
We interrogate this assumption by introducing a Clinical Trial Natural Language
Inference benchmark comprising four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction.
Each item is paired with a targeted Ground Knowledge and Meta-Level Reasoning
Verification (GKMRV) probe, allowing us to dissociate failures of factual
access from failures of inference. We evaluate six contemporary LLMs under both
direct and chain of thought prompting.
  Models achieve near-ceiling GKMRV accuracy (mean accuracy 0.918) yet perform
poorly on the main reasoning tasks (mean accuracy 0.25). Despite low accuracy,
output inferences are highly consistent across samples (mean 0.87), indicating
a systematic application of underlying heuristics and shortcuts.
  These results reveal fundamental structural and representational limitations:
current LLMs often possess the relevant clinical knowledge but lack the
structured, composable internal representations needed to deploy it reliably
(e.g., integrating constraints, weighing evidence, or simulating
counterfactuals). Decoupling knowledge from reasoning with GKMRV makes this
dissociation explicit and measurable, providing an effective framework for
probing the reliability of LLMs in high-stakes domains.

</details>


### [54] [Who Benefits from AI Explanations? Towards Accessible and Interpretable Systems](https://arxiv.org/abs/2508.10806)
*Maria J. P. Peixoto,Akriti Pandey,Ahsan Zaman,Peter R. Lewis*

Main category: cs.AI

TL;DR: 论文探讨了可解释AI（XAI）在视觉障碍用户中的可访问性不足问题，提出了一种四步方法以促进包容性设计。


<details>
  <summary>Details</summary>
Motivation: 随着AI在关键领域决策支持中的应用增加，可解释性成为提升用户理解和选择的关键，但视觉障碍用户的可访问性研究不足。

Method: 通过文献综述（79项研究）和四步方法（分类、角色定义、原型设计、评估）研究XAI的可访问性。

Result: 初步结果显示，简化解释比详细解释更易理解，多模态呈现有助于提升公平性。

Conclusion: XAI设计需更多关注视觉障碍用户，简化解释和多模态呈现是提升可访问性的关键。

Abstract: As AI systems are increasingly deployed to support decision-making in
critical domains, explainability has become a means to enhance the
understandability of these outputs and enable users to make more informed and
conscious choices. However, despite growing interest in the usability of
eXplainable AI (XAI), the accessibility of these methods, particularly for
users with vision impairments, remains underexplored. This paper investigates
accessibility gaps in XAI through a two-pronged approach. First, a literature
review of 79 studies reveals that evaluations of XAI techniques rarely include
disabled users, with most explanations relying on inherently visual formats.
Second, we present a four-part methodological proof of concept that
operationalizes inclusive XAI design: (1) categorization of AI systems, (2)
persona definition and contextualization, (3) prototype design and
implementation, and (4) expert and user assessment of XAI techniques for
accessibility. Preliminary findings suggest that simplified explanations are
more comprehensible for non-visual users than detailed ones, and that
multimodal presentation is required for more equitable interpretability.

</details>
