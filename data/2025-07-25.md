<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 16]
- [cs.AI](#cs.AI) [Total: 21]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [PinchBot: Long-Horizon Deformable Manipulation with Guided Diffusion Policy](https://arxiv.org/abs/2507.17846)
*Alison Bartsch,Arvind Car,Amir Barati Farimani*

Main category: cs.RO

TL;DR: 本文提出了一种名为PinchBot的机器人系统，通过捏合动作完成简单陶艺制作，结合扩散策略模型和多模态技术。


<details>
  <summary>Details</summary>
Motivation: 探索多模态、长时程的可变形物体操控挑战，尤其是陶艺制作中的精细动作需求。

Method: 使用目标条件扩散策略模型，结合预训练的3D点云嵌入、任务进度预测和碰撞约束动作投影。

Result: PinchBot成功制作了多种简单陶艺目标。

Conclusion: 该系统展示了在复杂多模态任务中的潜力，为可变形物体操控提供了新思路。

Abstract: Pottery creation is a complicated art form that requires dexterous, precise
and delicate actions to slowly morph a block of clay to a meaningful, and often
useful 3D goal shape. In this work, we aim to create a robotic system that can
create simple pottery goals with only pinch-based actions. This pinch pottery
task allows us to explore the challenges of a highly multi-modal and
long-horizon deformable manipulation task. To this end, we present PinchBot, a
goal-conditioned diffusion policy model that when combined with pre-trained 3D
point cloud embeddings, task progress prediction and collision-constrained
action projection, is able to successfully create a variety of simple pottery
goals. For experimental videos and access to the demonstration dataset, please
visit our project website:
https://sites.google.com/andrew.cmu.edu/pinchbot/home.

</details>


### [2] [A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.17856)
*Dennis Benders,Laura Ferranti,Johannes Köhler*

Main category: cs.RO

TL;DR: 该技术报告介绍了如何设计非线性模型预测控制（NMPC）方案，以确保移动机器人在充满障碍物的环境中安全导航，并提供了从理论到实现的实用路径。


<details>
  <summary>Details</summary>
Motivation: 确保机器人在存在干扰和测量噪声的情况下，遵守状态和输入约束并避免碰撞，是机器人领域的关键任务。

Method: 报告采用非线性模型预测控制（NMPC）作为基础，提供逐步实现方案，强调安全性和性能保证。

Result: 报告为研究人员和工程师提供了从理论到实际应用的桥梁，重点关注安全导航的实现。

Conclusion: 该报告旨在填补NMPC理论与实际机器人应用之间的差距，并欢迎反馈以持续改进。

Abstract: Designing a Model Predictive Control (MPC) scheme that enables a mobile robot
to safely navigate through an obstacle-filled environment is a complicated yet
essential task in robotics. In this technical report, safety refers to ensuring
that the robot respects state and input constraints while avoiding collisions
with obstacles despite the presence of disturbances and measurement noise. This
report offers a step-by-step approach to implementing Nonlinear Model
Predictive Control (NMPC) schemes addressing these safety requirements.
Numerous books and survey papers provide comprehensive overviews of linear MPC
(LMPC) \cite{bemporad2007robust,kouvaritakis2016model}, NMPC
\cite{rawlings2017model,allgower2004nonlinear,mayne2014model,grune2017nonlinear,saltik2018outlook},
and their applications in various domains, including robotics
\cite{nascimento2018nonholonomic,nguyen2021model,shi2021advanced,wei2022mpc}.
This report does not aim to replicate those exhaustive reviews. Instead, it
focuses specifically on NMPC as a foundation for safe mobile robot navigation.
The goal is to provide a practical and accessible path from theoretical
concepts to mathematical proofs and implementation, emphasizing safety and
performance guarantees. It is intended for researchers, robotics engineers, and
practitioners seeking to bridge the gap between theoretical NMPC formulations
and real-world robotic applications.
  This report is not necessarily meant to remain fixed over time. If someone
finds an error in the presented theory, please reach out via the given email
addresses. We are happy to update the document if necessary.

</details>


### [3] [OpenNav: Open-World Navigation with Multimodal Large Language Models](https://arxiv.org/abs/2507.18033)
*Mingfeng Yuan,Letian Wang,Steven L. Waslander*

Main category: cs.RO

TL;DR: 利用多模态大语言模型（MLLMs）实现机器人导航任务，通过语言指令生成轨迹点，结合视觉语言感知模型和空间地图，验证了其在室内外场景的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决语言描述与机器人实际动作之间的差距，实现开放世界中的复杂指令导航任务。

Method: 利用MLLMs的跨模态理解和代码生成能力，结合视觉语言感知模型生成鸟瞰价值图，整合语义与空间信息。

Result: 在户外导航任务中验证了零样本视觉语言导航框架的多样性指令执行能力，并在Husky机器人上展示了室内外场景的实用性。

Conclusion: MLLMs能够有效支持开放集指令和对象的导航任务，具备实际应用的鲁棒性和适应性。

Abstract: Pre-trained large language models (LLMs) have demonstrated strong
common-sense reasoning abilities, making them promising for robotic navigation
and planning tasks. However, despite recent progress, bridging the gap between
language descriptions and actual robot actions in the open-world, beyond merely
invoking limited predefined motion primitives, remains an open challenge. In
this work, we aim to enable robots to interpret and decompose complex language
instructions, ultimately synthesizing a sequence of trajectory points to
complete diverse navigation tasks given open-set instructions and open-set
objects. We observe that multi-modal large language models (MLLMs) exhibit
strong cross-modal understanding when processing free-form language
instructions, demonstrating robust scene comprehension. More importantly,
leveraging their code-generation capability, MLLMs can interact with
vision-language perception models to generate compositional 2D bird-eye-view
value maps, effectively integrating semantic knowledge from MLLMs with spatial
information from maps to reinforce the robot's spatial understanding. To
further validate our approach, we effectively leverage large-scale autonomous
vehicle datasets (AVDs) to validate our proposed zero-shot vision-language
navigation framework in outdoor navigation tasks, demonstrating its capability
to execute a diverse range of free-form natural language navigation
instructions while maintaining robustness against object detection errors and
linguistic ambiguities. Furthermore, we validate our system on a Husky robot in
both indoor and outdoor scenes, demonstrating its real-world robustness and
applicability. Supplementary videos are available at
https://trailab.github.io/OpenNav-website/

</details>


### [4] [Modular Robot and Landmark Localisation Using Relative Bearing Measurements](https://arxiv.org/abs/2507.18070)
*Behzad Zamani,Jochen Trumpf,Chris Manzie*

Main category: cs.RO

TL;DR: 提出了一种模块化非线性最小二乘滤波方法，用于独立子系统组成的系统，通过协方差交集算法避免信息重复计算，并在机器人-地标定位问题中验证其性能。


<details>
  <summary>Details</summary>
Motivation: 解决多子系统状态估计中信息重复计算的问题，并探索模块化方法的性能与通信带宽需求的权衡。

Method: 采用模块化非线性最小二乘滤波，结合协方差交集算法，独立更新各子系统状态和误差协方差。

Result: 在机器人-地标定位问题中，模块化方法性能与联合状态滤波器相当，且在通信带宽减少时性能逐渐下降。

Conclusion: 模块化方法在多子系统状态估计中有效，协方差交集算法是关键，适用于通信受限场景。

Abstract: In this paper we propose a modular nonlinear least squares filtering approach
for systems composed of independent subsystems. The state and error covariance
estimate of each subsystem is updated independently, even when a relative
measurement simultaneously depends on the states of multiple subsystems. We
integrate the Covariance Intersection (CI) algorithm as part of our solution in
order to prevent double counting of information when subsystems share estimates
with each other. An alternative derivation of the CI algorithm based on least
squares estimation makes this integration possible. We particularise the
proposed approach to the robot-landmark localization problem. In this problem,
noisy measurements of the bearing angle to a stationary landmark position
measured relative to the SE(2) pose of a moving robot couple the estimation
problems for the robot pose and the landmark position. In a randomized
simulation study, we benchmark the proposed modular method against a monolithic
joint state filter to elucidate their respective trade-offs. In this study we
also include variants of the proposed method that achieve a graceful
degradation of performance with reduced communication and bandwidth
requirements.

</details>


### [5] [A Modular Residual Learning Framework to Enhance Model-Based Approach for Robust Locomotion](https://arxiv.org/abs/2507.18138)
*Min-Gyu Kim,Dongyun Kang,Hajun Kim,Hae-Won Park*

Main category: cs.RO

TL;DR: 提出了一种结合模型和学习的框架，通过残差模块提升机器人运动控制的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决模型不匹配导致的性能下降问题，提升在高不确定性环境中的控制表现。

Method: 将残差模块与基于模型的框架（如步态规划和动态模型）结合，选择适合的学习方法优化模块。

Result: 在真实四足机器人上验证，成功保持平衡并跟踪指令速度，同时提升了学习效率和控制器鲁棒性。

Conclusion: 该框架有效结合模型与学习优势，适用于高不确定性环境，并具有实际应用潜力。

Abstract: This paper presents a novel approach that combines the advantages of both
model-based and learning-based frameworks to achieve robust locomotion. The
residual modules are integrated with each corresponding part of the model-based
framework, a footstep planner and dynamic model designed using heuristics, to
complement performance degradation caused by a model mismatch. By utilizing a
modular structure and selecting the appropriate learning-based method for each
residual module, our framework demonstrates improved control performance in
environments with high uncertainty, while also achieving higher learning
efficiency compared to baseline methods. Moreover, we observed that our
proposed methodology not only enhances control performance but also provides
additional benefits, such as making nominal controllers more robust to
parameter tuning. To investigate the feasibility of our framework, we
demonstrated residual modules combined with model predictive control in a real
quadrupedal robot. Despite uncertainties beyond the simulation, the robot
successfully maintains balance and tracks the commanded velocity.

</details>


### [6] [Autonomous UAV Navigation for Search and Rescue Missions Using Computer Vision and Convolutional Neural Networks](https://arxiv.org/abs/2507.18160)
*Luka Šiktar,Branimir Ćaran,Bojan Šekoranja,Marko Švaco*

Main category: cs.RO

TL;DR: 该论文提出了一种基于无人机（UAV）的搜索与救援子系统，结合ROS2框架和多种卷积神经网络（CNN），实现人员检测、人脸识别及个体跟踪。


<details>
  <summary>Details</summary>
Motivation: 旨在通过无人机技术提升搜索与救援任务的效率，特别是在复杂环境中快速定位和跟踪特定个体。

Method: 集成ROS2框架，使用YOLOv11和YOLOv11-pose CNN进行跟踪，dlib库进行人脸识别，并通过系统识别和PD控制器实现自主导航。

Result: 初步实验在14名已知个体上验证了系统的实时有效性。

Conclusion: 下一步计划将系统部署于大型实验无人机，并整合GPS导航以用于实际救援任务。

Abstract: In this paper, we present a subsystem, using Unmanned Aerial Vehicles (UAV),
for search and rescue missions, focusing on people detection, face recognition
and tracking of identified individuals. The proposed solution integrates a UAV
with ROS2 framework, that utilizes multiple convolutional neural networks (CNN)
for search missions. System identification and PD controller deployment are
performed for autonomous UAV navigation. The ROS2 environment utilizes the
YOLOv11 and YOLOv11-pose CNNs for tracking purposes, and the dlib library CNN
for face recognition. The system detects a specific individual, performs face
recognition and starts tracking. If the individual is not yet known, the UAV
operator can manually locate the person, save their facial image and
immediately initiate the tracking process. The tracking process relies on
specific keypoints identified on the human body using the YOLOv11-pose CNN
model. These keypoints are used to track a specific individual and maintain a
safe distance. To enhance accurate tracking, system identification is
performed, based on measurement data from the UAVs IMU. The identified system
parameters are used to design PD controllers that utilize YOLOv11-pose to
estimate the distance between the UAVs camera and the identified individual.
The initial experiments, conducted on 14 known individuals, demonstrated that
the proposed subsystem can be successfully used in real time. The next step
involves implementing the system on a large experimental UAV for field use and
integrating autonomous navigation with GPS-guided control for rescue operations
planning.

</details>


### [7] [MoRPI-PINN: A Physics-Informed Framework for Mobile Robot Pure Inertial Navigation](https://arxiv.org/abs/2507.18206)
*Arup Kumar Sahoo,Itzik Klein*

Main category: cs.RO

TL;DR: MoRPI-PINN是一种基于物理信息的神经网络框架，用于提高移动机器人在无卫星或摄像头情况下的惯性导航精度。


<details>
  <summary>Details</summary>
Motivation: 解决在卫星导航或摄像头不可用时，仅依赖惯性传感器导致的导航漂移问题。

Method: 通过蛇形运动增强惯性信号信噪比，并结合物理定律和约束训练神经网络。

Result: 实验显示，MoRPI-PINN的导航精度比其他方法提高85%以上。

Conclusion: MoRPI-PINN是一种轻量级、高精度的导航解决方案，适用于边缘设备和典型移动机器人应用。

Abstract: A fundamental requirement for full autonomy in mobile robots is accurate
navigation even in situations where satellite navigation or cameras are
unavailable. In such practical situations, relying only on inertial sensors
will result in navigation solution drift due to the sensors' inherent noise and
error terms. One of the emerging solutions to mitigate drift is to maneuver the
robot in a snake-like slithering motion to increase the inertial
signal-to-noise ratio, allowing the regression of the mobile robot position. In
this work, we propose MoRPI-PINN as a physics-informed neural network framework
for accurate inertial-based mobile robot navigation. By embedding physical laws
and constraints into the training process, MoRPI-PINN is capable of providing
an accurate and robust navigation solution. Using real-world experiments, we
show accuracy improvements of over 85% compared to other approaches. MoRPI-PINN
is a lightweight approach that can be implemented even on edge devices and used
in any typical mobile robot application.

</details>


### [8] [Evaluation of facial landmark localization performance in a surgical setting](https://arxiv.org/abs/2507.18248)
*Ines Frajtag,Marko Švaco,Filip Šuligoj*

Main category: cs.RO

TL;DR: 研究测试了MediaPipe算法在手术灯光下检测面部标志的准确性，发现其在大角度偏转时性能提升，但存在精度问题。


<details>
  <summary>Details</summary>
Motivation: 解决面部检测算法在手术中因光线和位置变化导致的精度问题。

Method: 使用机器人手臂调整位置，固定手术灯和模型，测试MediaPipe算法在不同角度下的表现。

Result: 手术灯光下，面部标志检测的准确性在大角度偏转时显著提高，但存在标准偏差增大的问题。

Conclusion: MediaPipe算法在医疗程序中有潜在应用价值，但需进一步优化精度。

Abstract: The use of robotics, computer vision, and their applications is becoming
increasingly widespread in various fields, including medicine. Many face
detection algorithms have found applications in neurosurgery, ophthalmology,
and plastic surgery. A common challenge in using these algorithms is variable
lighting conditions and the flexibility of detection positions to identify and
precisely localize patients. The proposed experiment tests the MediaPipe
algorithm for detecting facial landmarks in a controlled setting, using a
robotic arm that automatically adjusts positions while the surgical light and
the phantom remain in a fixed position. The results of this study demonstrate
that the improved accuracy of facial landmark detection under surgical lighting
significantly enhances the detection performance at larger yaw and pitch
angles. The increase in standard deviation/dispersion occurs due to imprecise
detection of selected facial landmarks. This analysis allows for a discussion
on the potential integration of the MediaPipe algorithm into medical
procedures.

</details>


### [9] [ReSem3D: Refinable 3D Spatial Constraints via Fine-Grained Semantic Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2507.18262)
*Chenyu Su,Weiwei Shang,Chen Qian,Fei Zhang,Shuang Cong*

Main category: cs.RO

TL;DR: ReSem3D提出了一种基于语义驱动的3D空间约束框架，通过结合MLLMs和VFMs实现细粒度视觉定位和实时优化，解决了现有方法在语义建模、实时规划和鲁棒性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在语义建模粒度、实时闭环规划和语义多样性环境中的鲁棒性方面存在不足，限制了机器人在复杂环境中的操作能力。

Method: ReSem3D利用MLLMs和VFMs的协同作用，通过两阶段（部分级提取和区域级细化）从自然语言指令和RGB-D观测中动态构建3D空间约束，并将其编码为实时优化目标。

Result: 在丰富语义的家庭环境和稀疏语义的化学实验室环境中，ReSem3D在零样本条件下表现出强大的适应性和泛化能力。

Conclusion: ReSem3D通过语义驱动的3D空间约束和实时优化，显著提升了机器人在复杂环境中的操作能力，具有广泛的应用潜力。

Abstract: Semantics-driven 3D spatial constraints align highlevel semantic
representations with low-level action spaces, facilitating the unification of
task understanding and execution in robotic manipulation. The synergistic
reasoning of Multimodal Large Language Models (MLLMs) and Vision Foundation
Models (VFMs) enables cross-modal 3D spatial constraint construction.
Nevertheless, existing methods have three key limitations: (1) coarse semantic
granularity in constraint modeling, (2) lack of real-time closed-loop planning,
(3) compromised robustness in semantically diverse environments. To address
these challenges, we propose ReSem3D, a unified manipulation framework for
semantically diverse environments, leveraging the synergy between VFMs and
MLLMs to achieve fine-grained visual grounding and dynamically constructs
hierarchical 3D spatial constraints for real-time manipulation. Specifically,
the framework is driven by hierarchical recursive reasoning in MLLMs, which
interact with VFMs to automatically construct 3D spatial constraints from
natural language instructions and RGB-D observations in two stages: part-level
extraction and region-level refinement. Subsequently, these constraints are
encoded as real-time optimization objectives in joint space, enabling reactive
behavior to dynamic disturbances. Extensive simulation and real-world
experiments are conducted in semantically rich household and sparse chemical
lab environments. The results demonstrate that ReSem3D performs diverse
manipulation tasks under zero-shot conditions, exhibiting strong adaptability
and generalization. Code and videos at https://resem3d.github.io.

</details>


### [10] [Adaptive Articulated Object Manipulation On The Fly with Foundation Model Reasoning and Part Grounding](https://arxiv.org/abs/2507.18276)
*Xiaojie Zhang,Yuanfei Wang,Ruihai Wu,Kunqi Xu,Yu Li,Liuyu Xiang,Hao Dong,Zhaofeng He*

Main category: cs.RO

TL;DR: AdaRPG框架利用基础模型提取物体局部几何信息，提升视觉功能泛化能力，并通过部分级功能标注数据集训练模型，实现跨类别铰接物体操作的泛化。


<details>
  <summary>Details</summary>
Motivation: 铰接物体的几何多样性和功能机制差异导致视觉感知和统一操作策略的困难，需解决跨类别泛化问题。

Method: 提出AdaRPG框架，利用基础模型提取局部几何信息，构建部分级功能标注数据集，并基于功能推理生成高级控制代码。

Result: 仿真和真实实验表明AdaRPG在新型铰接物体类别上具有强泛化能力。

Conclusion: AdaRPG通过局部几何和功能推理有效解决了铰接物体操作的泛化挑战。

Abstract: Articulated objects pose diverse manipulation challenges for robots. Since
their internal structures are not directly observable, robots must adaptively
explore and refine actions to generate successful manipulation trajectories.
While existing works have attempted cross-category generalization in adaptive
articulated object manipulation, two major challenges persist: (1) the
geometric diversity of real-world articulated objects complicates visual
perception and understanding, and (2) variations in object functions and
mechanisms hinder the development of a unified adaptive manipulation strategy.
To address these challenges, we propose AdaRPG, a novel framework that
leverages foundation models to extract object parts, which exhibit greater
local geometric similarity than entire objects, thereby enhancing visual
affordance generalization for functional primitive skills. To support this, we
construct a part-level affordance annotation dataset to train the affordance
model. Additionally, AdaRPG utilizes the common knowledge embedded in
foundation models to reason about complex mechanisms and generate high-level
control codes that invoke primitive skill functions based on part affordance
inference. Simulation and real-world experiments demonstrate AdaRPG's strong
generalization ability across novel articulated object categories.

</details>


### [11] [AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments](https://arxiv.org/abs/2507.18317)
*Chenglong Qian,Yang Xu,Xiufang Shi,Jiming Chen,Liang Li*

Main category: cs.RO

TL;DR: AF-RLIO是一种自适应融合方法，结合4D毫米波雷达、LiDAR、IMU和GPS，提升复杂环境中机器人导航的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决单传感器系统（如LiDAR或GPS）在烟雾、隧道等复杂动态环境中性能下降的问题。

Method: 包括预处理模块（雷达辅助LiDAR去除动态点）、动态感知多模态里程计（点云匹配与IMU紧耦合）和因子图优化模块（平衡里程计与GPS权重）。

Result: 在数据集和真实环境中测试，证明其在烟雾和隧道等挑战性条件下优于现有方法。

Conclusion: AF-RLIO通过多传感器融合显著提升了复杂环境中的导航稳定性和安全性。

Abstract: In robotic navigation, maintaining precise pose estimation and navigation in
complex and dynamic environments is crucial. However, environmental challenges
such as smoke, tunnels, and adverse weather can significantly degrade the
performance of single-sensor systems like LiDAR or GPS, compromising the
overall stability and safety of autonomous robots. To address these challenges,
we propose AF-RLIO: an adaptive fusion approach that integrates 4D
millimeter-wave radar, LiDAR, inertial measurement unit (IMU), and GPS to
leverage the complementary strengths of these sensors for robust odometry
estimation in complex environments. Our method consists of three key modules.
Firstly, the pre-processing module utilizes radar data to assist LiDAR in
removing dynamic points and determining when environmental conditions are
degraded for LiDAR. Secondly, the dynamic-aware multimodal odometry selects
appropriate point cloud data for scan-to-map matching and tightly couples it
with the IMU using the Iterative Error State Kalman Filter. Lastly, the factor
graph optimization module balances weights between odometry and GPS data,
constructing a pose graph for optimization. The proposed approach has been
evaluated on datasets and tested in real-world robotic environments,
demonstrating its effectiveness and advantages over existing methods in
challenging conditions such as smoke and tunnels.

</details>


### [12] [G2S-ICP SLAM: Geometry-aware Gaussian Splatting ICP SLAM](https://arxiv.org/abs/2507.18344)
*Gyuhyeon Pak,Hae Min Cho,Euntai Kim*

Main category: cs.RO

TL;DR: 提出了一种基于几何感知的RGB-D高斯泼溅SLAM系统G2S-ICP SLAM，通过局部切平面约束的高斯分布实现高保真3D重建和实时相机位姿跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM系统使用各向同性的3D椭球表示，导致多视角深度解释不一致。本文旨在通过几何感知的高斯分布改进这一问题。

Method: 采用局部切平面约束的高斯分布表示场景元素，并将其嵌入广义ICP框架，引入各向异性协方差先验，同时提出几何感知损失函数监督光度、深度和法线一致性。

Result: 在Replica和TUM-RGBD数据集上的实验表明，G2S-ICP SLAM在定位精度、重建完整性和渲染质量上优于现有SLAM系统。

Conclusion: G2S-ICP SLAM通过几何感知的高斯表示和优化框架，实现了实时高保真3D重建和鲁棒的相机跟踪。

Abstract: In this paper, we present a novel geometry-aware RGB-D Gaussian Splatting
SLAM system, named G2S-ICP SLAM. The proposed method performs high-fidelity 3D
reconstruction and robust camera pose tracking in real-time by representing
each scene element using a Gaussian distribution constrained to the local
tangent plane. This effectively models the local surface as a 2D Gaussian disk
aligned with the underlying geometry, leading to more consistent depth
interpretation across multiple viewpoints compared to conventional 3D
ellipsoid-based representations with isotropic uncertainty. To integrate this
representation into the SLAM pipeline, we embed the surface-aligned Gaussian
disks into a Generalized ICP framework by introducing anisotropic covariance
prior without altering the underlying registration formulation. Furthermore we
propose a geometry-aware loss that supervises photometric, depth, and normal
consistency. Our system achieves real-time operation while preserving both
visual and geometric fidelity. Extensive experiments on the Replica and
TUM-RGBD datasets demonstrate that G2S-ICP SLAM outperforms prior SLAM systems
in terms of localization accuracy, reconstruction completeness, while
maintaining the rendering quality.

</details>


### [13] [Residual Koopman Model Predictive Control for Enhanced Vehicle Dynamics with Small On-Track Data Input](https://arxiv.org/abs/2507.18396)
*Yonghao Fu,Cheng Hu,Haokun Xiong,Zhangpeng Bao,Wenyuan Du,Edoardo Ghignone,Michele Magno,Lei Xie,Hongye Su*

Main category: cs.RO

TL;DR: 论文提出了一种基于残差Koopman的模型预测控制（RKMPC）框架，用于车辆轨迹跟踪任务，结合线性MPC和神经网络补偿输入，显著提升了跟踪性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统Pure Pursuit控制未考虑车辆模型约束，MPC依赖精确建模但面临非线性动态与计算效率的权衡。RKMPC旨在解决这些问题，提升控制性能。

Method: 采用双线性MPC架构：LMPC基于车辆运动学模型计算基线输入，神经网络RKMPC计算补偿输入，两者相加得到最终控制指令。

Result: 实验显示，RKMPC仅需传统KMPC20%的训练数据，横向误差减少11.7%-22.1%，航向误差降低8.9%-15.8%，前轮转向稳定性提升27.6%。

Conclusion: RKMPC在保持传统模型可靠性的同时，通过残差建模优化性能，适用于车辆轨迹跟踪任务。

Abstract: In vehicle trajectory tracking tasks, the simplest approach is the Pure
Pursuit (PP) Control. However, this single-point preview tracking strategy
fails to consider vehicle model constraints, compromising driving safety. Model
Predictive Control (MPC) as a widely adopted control method, optimizes control
actions by incorporating mechanistic models and physical constraints. While its
control performance critically depends on the accuracy of vehicle modeling.
Traditional vehicle modeling approaches face inherent trade-offs between
capturing nonlinear dynamics and maintaining computational efficiency, often
resulting in reduced control performance. To address these challenges, this
paper proposes Residual Koopman Model Predictive Control (RKMPC) framework.
This method uses two linear MPC architecture to calculate control inputs: a
Linear Model Predictive Control (LMPC) computes the baseline control input
based on the vehicle kinematic model, and a neural network-based RKMPC
calculates the compensation input. The final control command is obtained by
adding these two components. This design preserves the reliability and
interpretability of traditional mechanistic model while achieving performance
optimization through residual modeling. This method has been validated on the
Carsim-Matlab joint simulation platform and a physical 1:10 scale F1TENTH
racing car. Experimental results show that RKMPC requires only 20% of the
training data needed by traditional Koopman Model Predictive Control (KMPC)
while delivering superior tracking performance. Compared to traditional LMPC,
RKMPC reduces lateral error by 11.7%-22.1%, decreases heading error by
8.9%-15.8%, and improves front-wheel steering stability by up to 27.6%. The
implementation code is available at: https://github.com/ZJU-DDRX/Residual
Koopman.

</details>


### [14] [Evaluating the Pre-Dressing Step: Unfolding Medical Garments Via Imitation Learning](https://arxiv.org/abs/2507.18436)
*David Blanco-Mulero,Júlia Borràs,Carme Torras*

Main category: cs.RO

TL;DR: 论文提出了一种机器人辅助穿衣前的展开衣物步骤（pre-dressing），通过模仿学习学习三种操作动作，并结合视觉分类器判断衣物状态。实验表明，动态动作组合能有效提升展开效果。


<details>
  <summary>Details</summary>
Motivation: 医疗场景中衣物通常以折叠状态存放，现有研究假设衣物已展开，忽略了展开步骤的重要性。

Method: 利用模仿学习学习三种操作动作（包括高低加速度动作），并采用视觉分类器判断衣物状态（闭合、部分展开、完全展开）。

Result: 实验表明，动态动作组合能高效提升衣物的展开效果，而单独的高动态动作对刚拆封衣物效果不佳。

Conclusion: 研究强调了展开步骤在机器人辅助穿衣中的重要性，动态动作组合是提升效率的关键。

Abstract: Robotic-assisted dressing has the potential to significantly aid both
patients as well as healthcare personnel, reducing the workload and improving
the efficiency in clinical settings. While substantial progress has been made
in robotic dressing assistance, prior works typically assume that garments are
already unfolded and ready for use. However, in medical applications gowns and
aprons are often stored in a folded configuration, requiring an additional
unfolding step. In this paper, we introduce the pre-dressing step, the process
of unfolding garments prior to assisted dressing. We leverage imitation
learning for learning three manipulation primitives, including both high and
low acceleration motions. In addition, we employ a visual classifier to
categorise the garment state as closed, partly opened, and fully opened. We
conduct an empirical evaluation of the learned manipulation primitives as well
as their combinations. Our results show that highly dynamic motions are not
effective for unfolding freshly unpacked garments, where the combination of
motions can efficiently enhance the opening configuration.

</details>


### [15] [A Novel Monte-Carlo Compressed Sensing and Dictionary Learning Method for the Efficient Path Planning of Remote Sensing Robots](https://arxiv.org/abs/2507.18462)
*Alghalya Al-Hajri,Ejmen Al-Ubejdij,Aiman Erbad,Ali Safa*

Main category: cs.RO

TL;DR: 论文提出了一种基于压缩感知（CS）的机器人采样轨迹优化方法，通过蒙特卡洛优化框架减少机器人路径长度和信号重建误差，并结合字典学习提高重建精度。


<details>
  <summary>Details</summary>
Motivation: 压缩感知在机器人环境数据采集中潜力巨大，但现有方法未充分利用CS测量矩阵结构优化采样轨迹。本文旨在填补这一空白。

Method: 提出蒙特卡洛优化框架，生成优化测量矩阵，结合字典学习（DL）提升稀疏变换效果，减少采样数量。

Result: 实验显示，该方法将机器人路径缩短至全覆盖路径的10%，重建精度比传统CS方法提高5倍，比现有IPP方法提高2倍。

Conclusion: 该方法显著提升了机器人环境数据采集的效率和精度，为压缩感知在机器人领域的应用提供了新思路。

Abstract: In recent years, Compressed Sensing (CS) has gained significant interest as a
technique for acquiring high-resolution sensory data using fewer measurements
than traditional Nyquist sampling requires. At the same time, autonomous
robotic platforms such as drones and rovers have become increasingly popular
tools for remote sensing and environmental monitoring tasks, including
measurements of temperature, humidity, and air quality. Within this context,
this paper presents, to the best of our knowledge, the first investigation into
how the structure of CS measurement matrices can be exploited to design
optimized sampling trajectories for robotic environmental data collection. We
propose a novel Monte Carlo optimization framework that generates measurement
matrices designed to minimize both the robot's traversal path length and the
signal reconstruction error within the CS framework. Central to our approach is
the application of Dictionary Learning (DL) to obtain a data-driven sparsifying
transform, which enhances reconstruction accuracy while further reducing the
number of samples that the robot needs to collect. We demonstrate the
effectiveness of our method through experiments reconstructing $NO_2$ pollution
maps over the Gulf region. The results indicate that our approach can reduce
robot travel distance to less than $10\%$ of a full-coverage path, while
improving reconstruction accuracy by over a factor of five compared to
traditional CS methods based on DCT and polynomial dictionaries, as well as by
a factor of two compared to previously-proposed Informative Path Planning (IPP)
methods.

</details>


### [16] [Experimental Comparison of Whole-Body Control Formulations for Humanoid Robots in Task Acceleration and Task Force Spaces](https://arxiv.org/abs/2507.18502)
*Sait Sovukluk,Grazia Zambella,Tobias Egle,Christian Ott*

Main category: cs.RO

TL;DR: 本文通过实验比较了两种人形机器人全身控制方法：逆动力学全身控制（ID-WBC）和基于被动性的全身控制（PB-WBC），分析了它们在多种条件下的性能差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于比较两种控制方法在实际应用中的鲁棒性，尤其是在非理想条件下的表现。

Method: 通过实验对比两种控制方法在摆动脚位置和方向控制、下蹲（带/不带额外重量）和跳跃任务中的表现。

Result: 实验揭示了两种控制方法在不同任务中的性能差异，并分析了各自的优缺点。

Conclusion: 结论指出两种控制方法各有优劣，需根据具体应用场景选择合适的方法。

Abstract: This paper studies the experimental comparison of two different whole-body
control formulations for humanoid robots: inverse dynamics whole-body control
(ID-WBC) and passivity-based whole-body control (PB-WBC). The two controllers
fundamentally differ from each other as the first is formulated in task
acceleration space and the latter is in task force space with passivity
considerations. Even though both control methods predict stability under ideal
conditions in closed-loop dynamics, their robustness against joint friction,
sensor noise, unmodeled external disturbances, and non-perfect contact
conditions is not evident. Therefore, we analyze and experimentally compare the
two controllers on a humanoid robot platform through swing foot position and
orientation control, squatting with and without unmodeled additional weights,
and jumping. We also relate the observed performance and characteristic
differences with the controller formulations and highlight each controller's
advantages and disadvantages.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [17] [ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics](https://arxiv.org/abs/2507.17777)
*Theofanis Aravanis,Grigorios Chrimatopoulos,Mohammad Ferdows,Michalis Xenos,Efstratios Em Tzirtzilakis*

Main category: cs.AI

TL;DR: 该研究利用符号回归（SR）和答案集编程（ASP）结合的方法，从数值模拟数据中推导出三维不可压缩流动的解析方程，并验证其与理论解的一致性。


<details>
  <summary>Details</summary>
Motivation: 在流体力学中，理解流动物理机制与准确预测同样重要，而传统机器学习方法缺乏可解释性。因此，研究采用SR来揭示复杂物理系统中的数学关系。

Method: 使用PySR库从数值模拟数据中推导符号方程，并结合ASP框架确保方程在统计准确的同时符合物理原理。

Result: SR生成的方程不仅近似模拟了抛物线速度分布和压力降，还与文献中的解析解完全一致。

Conclusion: 研究表明SR能简化复杂流动行为为可解释方程，且知识表示方法可提升数据驱动模型的可靠性和领域一致性。

Abstract: Unlike conventional Machine-Learning (ML) approaches, often criticized as
"black boxes", Symbolic Regression (SR) stands out as a powerful tool for
revealing interpretable mathematical relationships in complex physical systems,
requiring no a priori assumptions about models' structures. Motivated by the
recognition that, in fluid mechanics, an understanding of the underlying flow
physics is as crucial as accurate prediction, this study applies SR to model a
fundamental three-dimensional (3D) incompressible flow in a rectangular
channel, focusing on the (axial) velocity and pressure fields under laminar
conditions. By employing the PySR library, compact symbolic equations were
derived directly from numerical simulation data, revealing key characteristics
of the flow dynamics. These equations not only approximate the parabolic
velocity profile and pressure drop observed in the studied fluid flow, but also
perfectly coincide with analytical solutions from the literature. Furthermore,
we propose an innovative approach that integrates SR with the
knowledge-representation framework of Answer Set Programming (ASP), combining
the generative power of SR with the declarative reasoning strengths of ASP. The
proposed hybrid SR/ASP framework ensures that the SR-generated symbolic
expressions are not only statistically accurate, but also physically plausible,
adhering to domain-specific principles. Overall, the study highlights two key
contributions: SR's ability to simplify complex flow behaviours into concise,
interpretable equations, and the potential of knowledge-representation
approaches to improve the reliability and alignment of data-driven SR models
with domain principles. Insights from the examined 3D channel flow pave the way
for integrating such hybrid approaches into efficient frameworks, [...] where
explainable predictions and real-time data analysis are crucial.

</details>


### [18] [I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis](https://arxiv.org/abs/2507.17874)
*SaiBarath Sundar,Pranav Satheesan,Udayaadithya Avadhanam*

Main category: cs.AI

TL;DR: I2I-STRADA是一种多智能体架构，通过结构化推理过程改进数据分析中的认知工作流，优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 现有数据分析系统忽视结构化推理过程，而实际分析需要一致的认知工作流。

Method: 提出I2I-STRADA架构，通过模块化子任务模拟分析推理的认知步骤。

Result: 在DABstep和DABench基准测试中表现优于现有系统，规划一致性和洞察对齐性更优。

Conclusion: 结构化认知工作流对数据分析智能体设计至关重要。

Abstract: Recent advances in agentic systems for data analysis have emphasized
automation of insight generation through multi-agent frameworks, and
orchestration layers. While these systems effectively manage tasks like query
translation, data transformation, and visualization, they often overlook the
structured reasoning process underlying analytical thinking. Reasoning large
language models (LLMs) used for multi-step problem solving are trained as
general-purpose problem solvers. As a result, their reasoning or thinking steps
do not adhere to fixed processes for specific tasks. Real-world data analysis
requires a consistent cognitive workflow: interpreting vague goals, grounding
them in contextual knowledge, constructing abstract plans, and adapting
execution based on intermediate outcomes. We introduce I2I-STRADA
(Information-to-Insight via Structured Reasoning Agent for Data Analysis), an
agentic architecture designed to formalize this reasoning process. I2I-STRADA
focuses on modeling how analysis unfolds via modular sub-tasks that reflect the
cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench
benchmarks show that I2I-STRADA outperforms prior systems in planning coherence
and insight alignment, highlighting the importance of structured cognitive
workflows in agent design for data analysis.

</details>


### [19] [SMARTAPS: Tool-augmented LLMs for Operations Management](https://arxiv.org/abs/2507.17927)
*Timothy Tin Long Yu,Mahdi Mostajabdaveh,Jabo Serge Byusa,Rindra Ramamonjison,Giuseppe Carenini,Kun Mao,Zirui Zhou,Yong Zhang*

Main category: cs.AI

TL;DR: SmartAPS是一个基于大型语言模型（LLM）的对话系统，旨在通过自然语言交互帮助供应链规划师更便捷地使用高级规划系统（APS）。


<details>
  <summary>Details</summary>
Motivation: 传统APS系统因定制和维护成本高昂，许多用户无法负担。SmartAPS通过LLM提供自然语言界面，降低使用门槛。

Method: 基于工具增强的LLM构建对话系统，支持查询、反事实推理、推荐和场景分析。

Result: SmartAPS为供应链规划师提供直观的交互方式，提升操作管理的便捷性。

Conclusion: SmartAPS通过LLM技术解决了传统APS系统的可访问性问题，具有实际应用潜力。

Abstract: Large language models (LLMs) present intriguing opportunities to enhance user
interaction with traditional algorithms and tools in real-world applications.
An advanced planning system (APS) is a sophisticated software that leverages
optimization to help operations planners create, interpret, and modify an
operational plan. While highly beneficial, many customers are priced out of
using an APS due to the ongoing costs of consultants responsible for
customization and maintenance. To address the need for a more accessible APS
expressed by supply chain planners, we present SmartAPS, a conversational
system built on a tool-augmented LLM. Our system provides operations planners
with an intuitive natural language chat interface, allowing them to query
information, perform counterfactual reasoning, receive recommendations, and
execute scenario analysis to better manage their operation. A short video
demonstrating the system has been released: https://youtu.be/KtIrJjlDbyw

</details>


### [20] [Synthesis of timeline-based planning strategies avoiding determinization](https://arxiv.org/abs/2507.17988)
*Dario Della Monica,Angelo Montanari,Pietro Sala*

Main category: cs.AI

TL;DR: 本文提出了一种定性时间线规划的片段，其计划存在性问题可直接映射到确定性有限自动机的非空性问题，从而合成策略。


<details>
  <summary>Details</summary>
Motivation: 定性时间线规划的计划存在性问题虽已证明为PSPACE完全，但非确定性自动机无法直接用于合成策略，需进行昂贵的确定性转换。

Method: 识别一种定性时间线规划的片段，将其计划存在性问题映射到确定性有限自动机的非空性问题，并确定适合该片段的Allen关系的最大子集。

Result: 提出了一种可直接映射到确定性有限自动机的规划片段，并确定了适合该片段的Allen关系的最大子集。

Conclusion: 该研究为合成规划策略提供了一种更高效的方法，避免了非确定性自动机的确定性转换成本。

Abstract: Qualitative timeline-based planning models domains as sets of independent,
but
  interacting, components whose behaviors over time, the timelines, are
governed
  by sets of qualitative temporal constraints (ordering relations), called
  synchronization rules.
  Its plan-existence problem has been shown to be PSPACE-complete; in
  particular, PSPACE-membership has been proved via reduction to the
  nonemptiness problem for nondeterministic finite automata.
  However, nondeterministic automata cannot be directly used to synthesize
  planning strategies as a costly determinization step is needed.
  In this paper, we identify a fragment of qualitative timeline-based planning
  whose plan-existence problem can be directly mapped into the nonemptiness
  problem of deterministic finite automata, which can then
  synthesize strategies.
  In addition, we identify a maximal subset of Allen's relations that fits into
  such a deterministic fragment.

</details>


### [21] [E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI](https://arxiv.org/abs/2507.18004)
*Yusen Peng,Shuhua Mao*

Main category: cs.AI

TL;DR: 论文提出了E.A.R.T.H.框架，通过五阶段生成流程将模型生成的错误转化为创意资产，显著提升创造力。


<details>
  <summary>Details</summary>
Motivation: 探索AI如何超越模仿实现真正的创造力，提出‘创意潜力隐藏在失败中’的理念。

Method: 采用五阶段生成流程（错误生成、放大、精炼选择、转换、利用反馈），结合结构化提示、语义评分和人类参与评估。

Result: 创造力评分提升70.4%，精炼后的标语更短、更新颖，跨模态测试显示强对齐性，人类评估中60%输出得分≥4.0。

Conclusion: 错误中心和反馈驱动的生成方法能有效提升创造力，为自我进化、与人类对齐的创意AI提供可行路径。

Abstract: How can AI move beyond imitation toward genuine creativity? This paper
proposes the E.A.R.T.H. framework, a five-stage generative pipeline that
transforms model-generated errors into creative assets through Error
generation, Amplification, Refine selection, Transform, and Harness feedback.
Drawing on cognitive science and generative modeling, we posit that "creative
potential hides in failure" and operationalize this via structured prompts,
semantic scoring, and human-in-the-loop evaluation. Implemented using
LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the
pipeline employs a composite reward function based on novelty, surprise, and
relevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to
1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4%
improvement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a
4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment
(CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs
scored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones
(3.99). Feedback highlights stylistic precision and emotional resonance. These
results demonstrate that error-centered, feedback-driven generation enhances
creativity, offering a scalable path toward self-evolving, human-aligned
creative AI.

</details>


### [22] [Does visualization help AI understand data?](https://arxiv.org/abs/2507.18022)
*Victoria R. Li,Johnathan Sun,Martin Wattenberg*

Main category: cs.AI

TL;DR: 研究表明，图表能提升AI系统（如GPT 4.1和Claude 3.5）在数据分析任务中的精确性和准确性，尤其是数据复杂度高时。


<details>
  <summary>Details</summary>
Motivation: 探讨图表是否对AI系统分析数据有帮助。

Method: 通过实验比较两种商业视觉语言模型在三种分析任务中的表现，分别测试原始数据、散点图、空白图和错误图的效果。

Result: AI系统在数据伴随散点图时表现更优，表明图表内容对性能提升起关键作用。

Conclusion: 初步证明AI系统也能像人类一样从可视化中受益。

Abstract: Charts and graphs help people analyze data, but can they also be useful to AI
systems? To investigate this question, we perform a series of experiments with
two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three
representative analysis tasks, the two systems describe synthetic datasets more
precisely and accurately when raw data is accompanied by a scatterplot,
especially as datasets grow in complexity. Comparison with two baselines --
providing a blank chart and a chart with mismatched data -- shows that the
improved performance is due to the content of the charts. Our results are
initial evidence that AI systems, like humans, can benefit from visualization.

</details>


### [23] [Multi-Agent Guided Policy Optimization](https://arxiv.org/abs/2507.18059)
*Yueheng Li,Guangming Xie,Zongqing Lu*

Main category: cs.AI

TL;DR: MAGPO是一种新型CTDE框架，通过整合集中式指导和分散式执行，优化多智能体强化学习。


<details>
  <summary>Details</summary>
Motivation: 现有CTDE方法未能充分利用集中训练或缺乏理论保证。

Method: MAGPO采用自回归联合策略进行可扩展的协调探索，并明确与分散策略对齐。

Result: 在43个任务和6个环境中，MAGPO表现优于CTDE基线，并匹配或超越完全集中式方法。

Conclusion: MAGPO为分散式多智能体学习提供了理论保证和实用解决方案。

Abstract: Due to practical constraints such as partial observability and limited
communication, Centralized Training with Decentralized Execution (CTDE) has
become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning
(MARL). However, existing CTDE methods often underutilize centralized training
or lack theoretical guarantees. We propose Multi-Agent Guided Policy
Optimization (MAGPO), a novel framework that better leverages centralized
training by integrating centralized guidance with decentralized execution.
MAGPO uses an auto-regressive joint policy for scalable, coordinated
exploration and explicitly aligns it with decentralized policies to ensure
deployability under partial observability. We provide theoretical guarantees of
monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across
6 diverse environments. Results show that MAGPO consistently outperforms strong
CTDE baselines and matches or surpasses fully centralized approaches, offering
a principled and practical solution for decentralized multi-agent learning. Our
code and experimental data can be found in https://github.com/liyheng/MAGPO.

</details>


### [24] [AlphaGo Moment for Model Architecture Discovery](https://arxiv.org/abs/2507.18074)
*Yixiu Liu,Yang Nan,Weixian Xu,Xiangkun Hu,Lyumanshan Ye,Zhen Qin,Pengfei Liu*

Main category: cs.AI

TL;DR: ASI-Arch是一种自主超级智能系统，用于AI研究中的神经网络架构发现，突破了人类认知限制，实现了从自动化优化到自动化创新的转变。


<details>
  <summary>Details</summary>
Motivation: AI研究受限于人类认知能力，导致发展瓶颈。ASI-Arch旨在通过自主创新突破这一限制。

Method: ASI-Arch通过自主假设、实现、训练和验证新型架构，进行了大量实验，发现了106种创新架构。

Result: 系统发现了超越人类设计的新型架构，并首次建立了科学发现的扩展定律。

Conclusion: ASI-Arch为AI系统的自我加速提供了蓝图，将研究进程从人类限制转变为可计算扩展的过程。

Abstract: While AI systems demonstrate exponentially improving capabilities, the pace
of AI research itself remains linearly bounded by human cognitive capacity,
creating an increasingly severe development bottleneck. We present ASI-Arch,
the first demonstration of Artificial Superintelligence for AI research
(ASI4AI) in the critical domain of neural architecture discovery--a fully
autonomous system that shatters this fundamental constraint by enabling AI to
conduct its own architectural innovation. Moving beyond traditional Neural
Architecture Search (NAS), which is fundamentally limited to exploring
human-defined spaces, we introduce a paradigm shift from automated optimization
to automated innovation. ASI-Arch can conduct end-to-end scientific research in
the domain of architecture discovery, autonomously hypothesizing novel
architectural concepts, implementing them as executable code, training and
empirically validating their performance through rigorous experimentation and
past experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000
GPU hours, culminating in the discovery of 106 innovative, state-of-the-art
(SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed
unexpected strategic insights invisible to human players, our AI-discovered
architectures demonstrate emergent design principles that systematically
surpass human-designed baselines and illuminate previously unknown pathways for
architectural innovation. Crucially, we establish the first empirical scaling
law for scientific discovery itself--demonstrating that architectural
breakthroughs can be scaled computationally, transforming research progress
from a human-limited to a computation-scalable process. We provide
comprehensive analysis of the emergent design patterns and autonomous research
capabilities that enabled these breakthroughs, establishing a blueprint for
self-accelerating AI systems.

</details>


### [25] [Agentic AI framework for End-to-End Medical Data Inference](https://arxiv.org/abs/2507.18115)
*Soorya Ram Shimgekar,Shayan Vassef,Abhay Goyal,Navin Kumar,Koustuv Saha*

Main category: cs.AI

TL;DR: 提出了一种自动化临床数据管道的Agentic AI框架，通过模块化代理处理数据预处理、特征提取、模型选择等任务，减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 解决医疗领域机器学习解决方案部署成本高、流程分散及数据隐私约束严格的问题。

Method: 采用模块化代理系统，包括数据识别、匿名化、特征提取、模型匹配、预处理推荐与实施、模型推理等步骤。

Result: 在老年医学、姑息治疗和结肠镜影像等公开数据集上验证了框架的有效性。

Conclusion: 该框架自动化了机器学习生命周期中的高摩擦阶段，为临床环境中的AI应用提供了可扩展且经济高效的解决方案。

Abstract: Building and deploying machine learning solutions in healthcare remains
expensive and labor-intensive due to fragmented preprocessing workflows, model
compatibility issues, and stringent data privacy constraints. In this work, we
introduce an Agentic AI framework that automates the entire clinical data
pipeline, from ingestion to inference, through a system of modular,
task-specific agents. These agents handle both structured and unstructured
data, enabling automatic feature selection, model selection, and preprocessing
recommendation without manual intervention. We evaluate the system on publicly
available datasets from geriatrics, palliative care, and colonoscopy imaging.
For example, in the case of structured data (anxiety data) and unstructured
data (colonoscopy polyps data), the pipeline begins with file-type detection by
the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring
privacy compliance, where we first identify the data type and then anonymize
it. The Feature Extraction Agent identifies features using an embedding-based
approach for tabular data, extracting all column names, and a multi-stage
MedGemma-based approach for image data, which infers modality and disease name.
These features guide the Model-Data Feature Matcher Agent in selecting the
best-fit model from a curated repository. The Preprocessing Recommender Agent
and Preprocessing Implementor Agent then apply tailored preprocessing based on
data type and model requirements. Finally, the ``Model Inference Agent" runs
the selected model on the uploaded data and generates interpretable outputs
using tools like SHAP, LIME, and DETR attention maps. By automating these
high-friction stages of the ML lifecycle, the proposed framework reduces the
need for repeated expert intervention, offering a scalable, cost-efficient
pathway for operationalizing AI in clinical environments.

</details>


### [26] [Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes](https://arxiv.org/abs/2507.18123)
*Sedigh Khademi,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila,Jim Black*

Main category: cs.AI

TL;DR: 利用自然语言处理（NLP）和主动学习技术，开发分类器以从急诊科分诊笔记中快速检测疫苗安全问题，提升疫苗安全监测效率。


<details>
  <summary>Details</summary>
Motivation: 由于临床试验和早期广泛实施中安全数据收集时间有限，需要建立许可后监测系统，以应对COVID-19疫苗的安全问题。

Method: 结合自然语言处理（NLP）、主动学习和数据增强技术，开发分类器分析急诊科分诊笔记，优化标注过程和数据质量。

Result: 该方法能够更准确高效地检测疫苗安全问题，减少误报，并加快模型实施。

Conclusion: NLP与主动学习的结合为疫苗安全监测提供了高效解决方案，尤其在数据稀缺的医疗领域具有显著优势。

Abstract: The rapid development of COVID-19 vaccines has showcased the global
communitys ability to combat infectious diseases. However, the need for
post-licensure surveillance systems has grown due to the limited window for
safety data collection in clinical trials and early widespread implementation.
This study aims to employ Natural Language Processing techniques and Active
Learning to rapidly develop a classifier that detects potential vaccine safety
issues from emergency department notes. ED triage notes, containing expert,
succinct vital patient information at the point of entry to health systems, can
significantly contribute to timely vaccine safety signal surveillance. While
keyword-based classification can be effective, it may yield false positives and
demand extensive keyword modifications. This is exacerbated by the infrequency
of vaccination-related ED presentations and their similarity to other reasons
for ED visits. NLP offers a more accurate and efficient alternative, albeit
requiring annotated data, which is often scarce in the medical field. Active
learning optimizes the annotation process and the quality of annotated data,
which can result in faster model implementation and improved model performance.
This work combines active learning, data augmentation, and active learning and
evaluation techniques to create a classifier that is used to enhance vaccine
safety surveillance from ED triage notes.

</details>


### [27] [Logical Characterizations of GNNs with Mean Aggregation](https://arxiv.org/abs/2507.18145)
*Moritz Schönherr,Carsten Lutz*

Main category: cs.AI

TL;DR: 研究了使用均值聚合函数的图神经网络（GNNs）的表达能力，发现其在非均匀设置下与比率模态逻辑等价，而在均匀设置下低于求和与最大值聚合的GNNs。


<details>
  <summary>Details</summary>
Motivation: 探索均值聚合GNNs的表达能力，并与求和、最大值聚合GNNs进行对比。

Method: 通过非均匀和均匀设置下的理论分析，比较均值聚合GNNs与模态逻辑的关系。

Result: 均值聚合GNNs在非均匀设置下表达力高于最大值聚合但低于求和聚合；均匀设置下表达力低于两者。

Conclusion: 均值聚合GNNs的表达力受设置和假设影响，灵活性较高但均匀设置下较弱。

Abstract: We study the expressive power of graph neural networks (GNNs) with mean as
the aggregation function. In the non-uniform setting, we show that such GNNs
have exactly the same expressive power as ratio modal logic, which has modal
operators expressing that at least a certain ratio of the successors of a
vertex satisfies a specified property. The non-uniform expressive power of mean
GNNs is thus higher than that of GNNs with max aggregation, but lower than for
sum aggregation--the latter are characterized by modal logic and graded modal
logic, respectively. In the uniform setting, we show that the expressive power
relative to MSO is exactly that of alternation-free modal logic, under the
natural assumptions that combination functions are continuous and
classification functions are thresholds. This implies that, relative to MSO and
in the uniform setting, mean GNNs are strictly less expressive than sum GNNs
and max GNNs. When any of the assumptions is dropped, the expressive power
increases.

</details>


### [28] [Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory](https://arxiv.org/abs/2507.18178)
*Mutian Yang,Jiandong Gao,Ji Wu*

Main category: cs.AI

TL;DR: 论文提出了一种认知归因框架，通过分解知识检索和推理调整两阶段，量化大型语言模型（LLMs）中知识和推理的贡献。实验表明推理调整具有领域特异性，参数规模提升对知识改进更显著，且知识和推理分别分布于网络的不同层次。


<details>
  <summary>Details</summary>
Motivation: 受双系统认知理论启发，研究旨在区分LLMs中的知识和推理能力，以提升模型分析、可解释性和开发。

Method: 通过提示LLMs在快速思维和慢速思维两种认知模式下生成答案，分解知识检索（Phase 1）和推理调整（Phase 2），并分析不同模式下的表现。

Result: 实验发现推理调整对推理密集型领域有益，参数规模提升对知识改进更显著，且知识和推理分别分布于网络的不同层次。

Conclusion: 该框架为理解LLMs提供了新视角，并对现有研究（如规模法则、分层知识编辑和小模型推理限制）提供了新见解。

Abstract: While large language models (LLMs) leverage both knowledge and reasoning
during inference, the capacity to distinguish between them plays a pivotal role
in model analysis, interpretability, and development. Inspired by dual-system
cognitive theory, we propose a cognition attribution framework to decouple the
contribution of knowledge and reasoning. In particular, the cognition of LLMs
is decomposed into two distinct yet complementary phases: knowledge retrieval
(Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs
are prompted to generate answers under two different cognitive modes, fast
thinking and slow thinking, respectively. The performance under different
cognitive modes is analyzed to quantify the contribution of knowledge and
reasoning. This architecture is employed to 15 LLMs across 3 datasets. Results
reveal: (1) reasoning adjustment is domain-specific, benefiting
reasoning-intensive domains (e.g., mathematics, physics, and chemistry) and
potentially imparing knowledge-intensive domains. (2) Parameter scaling
improves both knowledge and reasoning, with knowledge improvements being more
pronounced. Additionally, parameter scaling make LLMs reasoning significantly
more prudent, while moderately more intelligent. (3) Knowledge primarily
resides in lower network layers, while reasoning operates in higher layers. Our
framework not only helps understand LLMs from a "decoupling" perspective, but
also provides new insights into existing research, including scaling laws,
hierarchical knowledge editing, and limitations of small-model reasoning.

</details>


### [29] [Comparing Non-minimal Semantics for Disjunction in Answer Set Programming](https://arxiv.org/abs/2507.18198)
*Felicidad Aguado,Pedro Cabalar,Brais Muñiz,Gilberto Pérez,Concepción Vidal*

Main category: cs.AI

TL;DR: 本文比较了四种不遵循模型最小化原则的析取语义，证明其中三种方法（Forks、Justified Models和DI语义的合理松弛）实际上是一致的，且比第四种方法（Strongly Supported Models）更强。


<details>
  <summary>Details</summary>
Motivation: 探讨在Answer Set Programming中不依赖模型最小化原则的析取语义，比较不同方法的异同。

Method: 比较四种不同的析取语义：Justified Models、Strongly Supported Models、Forks和DI语义，分析其定义和关系。

Result: 证明Forks、Justified Models和DI语义的合理松弛实际上是一致的，且比Strongly Supported Models更强。

Conclusion: 这三种方法构成了一种统一的语义，且比传统逻辑中的析取处理更强。

Abstract: In this paper, we compare four different semantics for disjunction in Answer
Set Programming that, unlike stable models, do not adhere to the principle of
model minimality. Two of these approaches, Cabalar and Mu\~niz' \emph{Justified
Models} and Doherty and Szalas' \emph{Strongly Supported Models}, directly
provide an alternative non-minimal semantics for disjunction. The other two,
Aguado et al's \emph{Forks} and Shen and Eiter's \emph{Determining Inference}
(DI) semantics, actually introduce a new disjunction connective, but are
compared here as if they constituted new semantics for the standard disjunction
operator. We are able to prove that three of these approaches (Forks, Justified
Models and a reasonable relaxation of the DI semantics) actually coincide,
constituting a common single approach under different definitions. Moreover,
this common semantics always provides a superset of the stable models of a
program (in fact, modulo any context) and is strictly stronger than the fourth
approach (Strongly Supported Models), that actually treats disjunctions as in
classical logic.

</details>


### [30] [Foundations for Risk Assessment of AI in Protecting Fundamental Rights](https://arxiv.org/abs/2507.18290)
*Antonino Rotolo,Beatrice Ferrigno,Jose Miguel Angel Garcia Godinez,Claudio Novelli,Giovanni Sartor*

Main category: cs.AI

TL;DR: 提出了一种定性评估AI风险的框架，结合定义性平衡和可废止推理，以应对欧盟AI法案下的法律合规和基本权利保护问题。


<details>
  <summary>Details</summary>
Motivation: 解决AI部署场景中的法律冲突和基本权利保护问题，为AI风险评估提供理论基础。

Method: 采用定义性平衡（比例分析）和可废止推理，分析AI部署场景及其对基本权利的多层次影响。

Result: 提出了一个分层的风险评估框架，适用于高风险AI系统和通用AI系统，并强调了后者的广泛适用性。

Conclusion: 未来工作将开发形式化模型和算法，以增强AI风险评估，支持负责任的AI治理。

Abstract: This chapter introduces a conceptual framework for qualitative risk
assessment of AI, particularly in the context of the EU AI Act. The framework
addresses the complexities of legal compliance and fundamental rights
protection by itegrating definitional balancing and defeasible reasoning.
Definitional balancing employs proportionality analysis to resolve conflicts
between competing rights, while defeasible reasoning accommodates the dynamic
nature of legal decision-making. Our approach stresses the need for an analysis
of AI deployment scenarios and for identifying potential legal violations and
multi-layered impacts on fundamental rights. On the basis of this analysis, we
provide philosophical foundations for a logical account of AI risk analysis. In
particular, we consider the basic building blocks for conceptually grasping the
interaction between AI deployment scenarios and fundamental rights,
incorporating in defeasible reasoning definitional balancing and arguments
about the contextual promotion or demotion of rights. This layered approach
allows for more operative models of assessment of both high-risk AI systems and
General Purpose AI (GPAI) systems, emphasizing the broader applicability of the
latter. Future work aims to develop a formal model and effective algorithms to
enhance AI risk assessment, bridging theoretical insights with practical
applications to support responsible AI governance.

</details>


### [31] [The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams](https://arxiv.org/abs/2507.18337)
*Peter Baumgartner,Lachlan McGinness*

Main category: cs.AI

TL;DR: 提出了一种结合计算机代数系统、SMT求解器和项重写系统的自动评分方法，利用大语言模型处理学生答案，并通过自动推理技术评估正确性。


<details>
  <summary>Details</summary>
Motivation: 解决物理考试中学生答案的自动评分问题，尤其是处理语言表达和数学形式化转换的挑战。

Method: 结合计算机代数系统、SMT求解器和项重写系统，利用大语言模型预处理学生答案，再通过自动定理证明评估正确性。

Result: 在2023年澳大利亚物理奥林匹克竞赛的1500多份真实学生答案上进行了评估。

Conclusion: 提出的方法能够有效处理物理考试中的自动评分问题，尤其在处理三角函数表达式时表现出色。

Abstract: We present our method for automatically marking Physics exams. The marking
problem consists in assessing typed student answers for correctness with
respect to a ground truth solution. This is a challenging problem that we seek
to tackle using a combination of a computer algebra system, an SMT solver and a
term rewriting system. A Large Language Model is used to interpret and remove
errors from student responses and rewrite these in a machine readable format.
Once formalized and language-aligned, the next step then consists in applying
automated reasoning techniques for assessing student solution correctness. We
consider two methods of automated theorem proving: off-the-shelf SMT solving
and term rewriting systems tailored for physics problems involving
trigonometric expressions. The development of the term rewrite system and
establishing termination and confluence properties was not trivial, and we
describe it in some detail in the paper. We evaluate our system on a rich pool
of over 1500 real-world student exam responses from the 2023 Australian Physics
Olympiad.

</details>


### [32] [Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios](https://arxiv.org/abs/2507.18368)
*Zhuang Qiang Bok,Watson Wei Khong Chua*

Main category: cs.AI

TL;DR: ConDiFi是一个评估LLM在金融任务中发散与收敛思维的基准，包含607个宏观金融提示和990个多跳对抗选择题。测试14个领先模型后发现，GPT-4o在创新性和可操作性上表现不佳，而DeepSeek-R1和Cohere Command R+表现优异。


<details>
  <summary>Details</summary>
Motivation: 金融领域需要LLM不仅能做出最优决策，还需在不确定性下生成创造性未来情景，现有基准未充分评估这一能力。

Method: ConDiFi通过607个发散思维提示和990个收敛思维选择题，评估LLM的金融推理能力。

Result: GPT-4o在创新性和可操作性上表现不佳，而DeepSeek-R1和Cohere Command R+表现突出。

Conclusion: ConDiFi为评估LLM在金融领域的安全和战略部署提供了新视角。

Abstract: Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step
logic. In finance, however, professionals must not only converge on optimal
decisions but also generate creative, plausible futures under uncertainty. We
introduce ConDiFi, a benchmark that jointly evaluates divergent and convergent
thinking in LLMs for financial tasks.
  ConDiFi features 607 macro-financial prompts for divergent reasoning and 990
multi-hop adversarial MCQs for convergent reasoning. Using this benchmark, we
evaluated 14 leading models and uncovered striking differences. Despite high
fluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models
like DeepSeek-R1 and Cohere Command R+ rank among the top for generating
actionable, insights suitable for investment decisions. ConDiFi provides a new
perspective to assess reasoning capabilities essential to safe and strategic
deployment of LLMs in finance.

</details>


### [33] [Revisiting LLM Reasoning via Information Bottleneck](https://arxiv.org/abs/2507.18391)
*Shiye Lei,Zhihao Cheng,Kai Jia,Dacheng Tao*

Main category: cs.AI

TL;DR: 论文提出了一种基于信息瓶颈（IB）原则的理论框架IBRO，用于优化大语言模型（LLM）的推理能力，并通过轻量级的IB正则化方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖启发式和直觉，缺乏理论支持，限制了方法论的发展。

Method: 提出IB-aware reasoning optimization（IBRO）框架，推导出token级代理目标，并提出高效的轻量级IB正则化方法。

Result: 在多个数学推理基准和RL算法中验证了IB正则化的有效性，显著提升了LLM的推理性能。

Conclusion: IBRO框架为LLM推理提供了理论支持，IB正则化方法简单高效，可无缝集成到现有RL训练框架中。

Abstract: Large language models (LLMs) have recently demonstrated remarkable progress
in reasoning capabilities through reinforcement learning with verifiable
rewards (RLVR). By leveraging simple rule-based rewards, RL effectively
incentivizes LLMs to produce extended chain-of-thought (CoT) reasoning
trajectories, progressively guiding them toward correct answers. However,
existing approaches remain largely heuristic and intuition-driven, limiting the
development of principled methodologies. In this paper, we present a
theoretical characterization of LLM reasoning grounded in information
bottleneck (IB) principle, introducing IB-aware reasoning optimization (IBRO),
a framework that encourages reasoning trajectories to be both informative about
the final correct answer and generalizable across diverse prompts. We derive a
practical token-level surrogate objective and propose an efficient
approximation, resulting in the lightweight IB regularization method. This
technique integrates seamlessly into existing RL-based post-training frameworks
without additional computational overhead, requiring only a one-line code
modification. Empirically, we validate IB regularization across multiple
mathematical reasoning benchmarks and RL algorithms, demonstrating consistent
improvements in LLM reasoning performance.

</details>


### [34] [Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation](https://arxiv.org/abs/2507.18398)
*Kwong Ho Li,Wathsala Karunarathne*

Main category: cs.AI

TL;DR: 论文研究了强化学习在呼叫中心路由优化中的应用，比较了基于模型的Value Iteration（VI）和无模型的Proximal Policy Optimisation（PPO）方法，结果显示PPO表现最佳。


<details>
  <summary>Details</summary>
Motivation: 优化呼叫中心的路由策略，以减少客户等待时间和员工空闲时间。

Method: 1. 基于模型的VI方法（已知系统动态）；2. 无模型的PPO方法（通过经验学习）。两者均在MDP框架下实现，使用仿真模型评估策略。

Result: 经过1,000次测试，PPO在奖励、客户等待时间和员工空闲时间上表现最优，但训练时间较长。

Conclusion: PPO在呼叫中心路由优化中效果显著，尽管训练时间较长，但其性能优于其他方法。

Abstract: This paper investigates the application of Reinforcement Learning (RL) to
optimise call routing in call centres to minimise client waiting time and staff
idle time. Two methods are compared: a model-based approach using Value
Iteration (VI) under known system dynamics, and a model-free approach using
Proximal Policy Optimisation (PPO) that learns from experience. For the
model-based approach, a theoretical model is used, while a simulation model
combining Discrete Event Simulation (DES) with the OpenAI Gym environment is
developed for model-free learning. Both models frame the problem as a Markov
Decision Process (MDP) within a Skills-Based Routing (SBR) framework, with
Poisson client arrivals and exponentially distributed service and abandonment
times. For policy evaluation, random, VI, and PPO policies are evaluated using
the simulation model. After 1,000 test episodes, PPO consistently achives the
highest rewards, along with the lowest client waiting time and staff idle time,
despite requiring longer training time.

</details>


### [35] [GPU Accelerated Compact-Table Propagation](https://arxiv.org/abs/2507.18413)
*Enrico Santi,Fabio Tardivo,Agostino Dovier,Andrea Formisano*

Main category: cs.AI

TL;DR: 本文探讨了如何利用现代GPU的计算能力增强Compact-Table（CT）算法，以处理大规模表约束问题。


<details>
  <summary>Details</summary>
Motivation: 传统CPU在处理包含数百或数千个有效案例的表约束问题时效率不足，需要更高效的方法。

Method: 设计并实现了GPU加速的CT算法，并将其集成到现有约束求解器中。

Result: 通过实验验证，GPU加速的CT算法在大量实例中表现优异。

Conclusion: GPU加速的CT算法为处理大规模表约束问题提供了高效解决方案。

Abstract: Constraint Programming developed within Logic Programming in the Eighties;
nowadays all Prolog systems encompass modules capable of handling constraint
programming on finite domains demanding their solution to a constraint solver.
This work focuses on a specific form of constraint, the so-called table
constraint, used to specify conditions on the values of variables as an
enumeration of alternative options. Since every condition on a set of finite
domain variables can be ultimately expressed as a finite set of cases, Table
can, in principle, simulate any other constraint. These characteristics make
Table one of the most studied constraints ever, leading to a series of
increasingly efficient propagation algorithms. Despite this, it is not uncommon
to encounter real-world problems with hundreds or thousands of valid cases that
are simply too many to be handled effectively with standard CPU-based
approaches. In this paper, we deal with the Compact-Table (CT) algorithm, the
state-of-the-art propagation algorithms for Table. We describe how CT can be
enhanced by exploiting the massive computational power offered by modern GPUs
to handle large Table constraints. In particular, we report on the design and
implementation of GPU-accelerated CT, on its integration into an existing
constraint solver, and on an experimental validation performed on a significant
set of instances.

</details>


### [36] [On the Performance of Concept Probing: The Influence of the Data (Extended Version)](https://arxiv.org/abs/2507.18550)
*Manuel de Sousa Ribeiro,Afonso Leote,João Leite*

Main category: cs.AI

TL;DR: 本文探讨了概念探测中训练数据对性能的影响，并提供了两个常用数据集的概念标签。


<details>
  <summary>Details</summary>
Motivation: 概念探测用于解释人工神经网络的内部表示，但以往研究忽视了训练数据对探测模型性能的影响。

Method: 聚焦图像分类任务，研究训练数据对概念探测模型性能的影响，并提供两个数据集的概念标签。

Result: 分析了数据对探测模型性能的具体影响。

Conclusion: 强调了训练数据在概念探测中的重要性，并公开了相关数据集的概念标签。

Abstract: Concept probing has recently garnered increasing interest as a way to help
interpret artificial neural networks, dealing both with their typically large
size and their subsymbolic nature, which ultimately renders them unfeasible for
direct human interpretation. Concept probing works by training additional
classifiers to map the internal representations of a model into human-defined
concepts of interest, thus allowing humans to peek inside artificial neural
networks. Research on concept probing has mainly focused on the model being
probed or the probing model itself, paying limited attention to the data
required to train such probing models. In this paper, we address this gap.
Focusing on concept probing in the context of image classification tasks, we
investigate the effect of the data used to train probing models on their
performance. We also make available concept labels for two widely used
datasets.

</details>


### [37] [SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law](https://arxiv.org/abs/2507.18576)
*Shanghai AI Lab,:,Yicheng Bao,Guanxu Chen,Mingkang Chen,Yunhao Chen,Chiyu Chen,Lingjie Chen,Sirui Chen,Xinquan Chen,Jie Cheng,Yu Cheng,Dengke Deng,Yizhuo Ding,Dan Ding,Xiaoshan Ding,Yi Ding,Zhichen Dong,Lingxiao Du,Yuyu Fan,Xinshun Feng,Yanwei Fu,Yuxuan Gao,Ruijun Ge,Tianle Gu,Lujun Gui,Jiaxuan Guo,Qianxi He,Yuenan Hou,Xuhao Hu,Hong Huang,Kaichen Huang,Shiyang Huang,Yuxian Jiang,Shanzhe Lei,Jie Li,Lijun Li,Hao Li,Juncheng Li,Xiangtian Li,Yafu Li,Lingyu Li,Xueyan Li,Haotian Liang,Dongrui Liu,Qihua Liu,Zhixuan Liu,Bangwei Liu,Huacan Liu,Yuexiao Liu,Zongkai Liu,Chaochao Lu,Yudong Lu,Xiaoya Lu,Zhenghao Lu,Qitan Lv,Caoyuan Ma,Jiachen Ma,Xiaoya Ma,Zhongtian Ma,Lingyu Meng,Ziqi Miao,Yazhe Niu,Yuezhang Peng,Yuan Pu,Han Qi,Chen Qian,Xingge Qiao,Jingjing Qu,Jiashu Qu,Wanying Qu,Wenwen Qu,Xiaoye Qu,Qihan Ren,Qingnan Ren,Qingyu Ren,Jing Shao,Wenqi Shao,Shuai Shao,Dongxing Shi,Xin Song,Xinhao Song,Yan Teng,Xuan Tong,Yingchun Wang,Xuhong Wang,Shujie Wang,Xin Wang,Yige Wang,Yixu Wang,Yuanfu Wang,Futing Wang,Ruofan Wang,Wenjie Wang,Yajie Wang,Muhao Wei,Xiaoyu Wen,Fenghua Weng,Yuqi Wu,Yingtong Xiong,Xingcheng Xu,Chao Yang,Yue Yang,Yang Yao,Yulei Ye,Zhenyun Yin,Yi Yu,Bo Zhang,Qiaosheng Zhang,Jinxuan Zhang,Yexin Zhang,Yinqiang Zheng,Hefeng Zhou,Zhanhui Zhou,Pengyu Zhu,Qingzi Zhu,Yubo Zhu,Bowen Zhou*

Main category: cs.AI

TL;DR: SafeWork-R1是一种多模态推理模型，通过SafeLadder框架实现能力与安全的协同进化，显著提升安全性表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有对齐方法（如RLHF）仅学习人类偏好的局限性，开发具备内在安全推理和自省能力的AI模型。

Method: 采用SafeLadder框架，结合大规模渐进式安全导向的强化学习后训练和多原则验证器，支持推理时干预和步级验证。

Result: SafeWork-R1在安全基准上平均提升46.54%，超越GPT-4.1和Claude Opus 4，同时保持通用能力。

Conclusion: SafeLadder框架证明安全与能力可协同进化，适用于构建稳健、可靠的通用AI。

Abstract: We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that
demonstrates the coevolution of capabilities and safety. It is developed by our
proposed SafeLadder framework, which incorporates large-scale, progressive,
safety-oriented reinforcement learning post-training, supported by a suite of
multi-principled verifiers. Unlike previous alignment methods such as RLHF that
simply learn human preferences, SafeLadder enables SafeWork-R1 to develop
intrinsic safety reasoning and self-reflection abilities, giving rise to safety
`aha' moments. Notably, SafeWork-R1 achieves an average improvement of
$46.54\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks
without compromising general capabilities, and delivers state-of-the-art safety
performance compared to leading proprietary models such as GPT-4.1 and Claude
Opus 4. To further bolster its reliability, we implement two distinct
inference-time intervention methods and a deliberative search mechanism,
enforcing step-level verification. Finally, we further develop
SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and
SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and
capability can co-evolve synergistically, highlighting the generalizability of
our framework in building robust, reliable, and trustworthy general-purpose AI.

</details>
