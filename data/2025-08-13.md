<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 25]
- [cs.AI](#cs.AI) [Total: 41]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Humanoid Robot Acrobatics Utilizing Complete Articulated Rigid Body Dynamics](https://arxiv.org/abs/2508.08258)
*Gerald Brantner*

Main category: cs.RO

TL;DR: 提出了一种结合轨迹优化和全身控制的架构，通过模型抽象实现人形机器人高动态运动。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人高自由度带来的运动规划和控制难题，避免传统线性化和模型近似方法的性能下降。

Method: 采用轨迹优化和全身控制，中间通过模型抽象匹配未简化的刚体运动方程。

Result: 仿真实验验证了系统在高动态运动中的有效性。

Conclusion: 该架构成功实现了人形机器人的高动态运动，为复杂运动控制提供了新思路。

Abstract: Endowing humanoid robots with the ability to perform highly dynamic motions
akin to human-level acrobatics has been a long-standing challenge. Successfully
performing these maneuvers requires close consideration of the underlying
physics in both trajectory optimization for planning and control during
execution. This is particularly challenging due to humanoids' high
degree-of-freedom count and associated exponentially scaling complexities,
which makes planning on the explicit equations of motion intractable. Typical
workarounds include linearization methods and model approximations. However,
neither are sufficient because they produce degraded performance on the true
robotic system. This paper presents a control architecture comprising
trajectory optimization and whole-body control, intermediated by a matching
model abstraction, that enables the execution of acrobatic maneuvers, including
constraint and posture behaviors, conditioned on the unabbreviated equations of
motion of the articulated rigid body model. A review of underlying modeling and
control methods is given, followed by implementation details including model
abstraction, trajectory optimization and whole-body controller. The system's
effectiveness is analyzed in simulation.

</details>


### [2] [Koopman Operator Based Linear Model Predictive Control for Quadruped Trotting](https://arxiv.org/abs/2508.08259)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 本文提出了一种基于Koopman算子的线性模型预测控制方法，用于四足机器人的在线最优控制，解决了传统线性化模型的不准确性问题。


<details>
  <summary>Details</summary>
Motivation: 在线最优控制能帮助四足机器人实时适应输入变化和环境变化，但传统线性模型预测控制（LMPC）因模型线性化可能导致不准确性。

Method: 使用Koopman算子在高维空间中构建线性模型，保留运动方程的非线性特性，并结合LMPC实现控制。

Result: 实验表明，该方法能实现高精度的轨迹跟踪和干扰抑制。

Conclusion: 这是首次将Koopman算子理论应用于四足机器人LMPC的研究，展示了其在非线性控制中的潜力。

Abstract: Online optimal control of quadruped robots would enable them to adapt to
varying inputs and changing conditions in real time. A common way of achieving
this is linear model predictive control (LMPC), where a quadratic programming
(QP) problem is formulated over a finite horizon with a quadratic cost and
linear constraints obtained by linearizing the equations of motion and solved
on the fly. However, the model linearization may lead to model inaccuracies. In
this paper, we use the Koopman operator to create a linear model of the
quadrupedal system in high dimensional space which preserves the nonlinearity
of the equations of motion. Then using LMPC, we demonstrate high fidelity
tracking and disturbance rejection on a quadrupedal robot. This is the first
work that uses the Koopman operator theory for LMPC of quadrupedal locomotion.

</details>


### [3] [Forecast-Driven MPC for Decentralized Multi-Robot Collision Avoidance](https://arxiv.org/abs/2508.08264)
*Hadush Hailu,Bruk Gebregziabher,Prudhvi Raj*

Main category: cs.RO

TL;DR: eIFP-MPC是IFP的优化扩展版本，通过改进威胁优先级、路径生成和动态可行性，提升了在多机器人路径规划中的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决IFP在对称配置中易发生碰撞和死锁的问题，提升在密集动态环境中的性能。

Method: 引入时间到碰撞启发式优化威胁优先级，通过基于成本的路径点选择稳定路径生成，并整合模型预测控制（MPC）确保动态可行性。

Result: 在对称和高密度场景中显著减少振荡，确保无碰撞运动，并提高轨迹效率。

Conclusion: 几何规划器通过优化可显著提升性能，适用于复杂多智能体环境。

Abstract: The Iterative Forecast Planner (IFP) is a geometric planning approach that
offers lightweight computations, scalable, and reactive solutions for
multi-robot path planning in decentralized, communication-free settings.
However, it struggles in symmetric configurations, where mirrored interactions
often lead to collisions and deadlocks. We introduce eIFP-MPC, an optimized and
extended version of IFP that improves robustness and path consistency in dense,
dynamic environments. The method refines threat prioritization using a
time-to-collision heuristic, stabilizes path generation through cost-based
via-point selection, and ensures dynamic feasibility by incorporating model
predictive control (MPC) into the planning process. These enhancements are
tightly integrated into the IFP to preserve its efficiency while improving its
adaptability and stability. Extensive simulations across symmetric and
high-density scenarios show that eIFP-MPC significantly reduces oscillations,
ensures collision-free motion, and improves trajectory efficiency. The results
demonstrate that geometric planners can be strengthened through optimization,
enabling robust performance at scale in complex multi-agent environments.

</details>


### [4] [emg2tendon: From sEMG Signals to Tendon Control in Musculoskeletal Hands](https://arxiv.org/abs/2508.08269)
*Sagar Verma*

Main category: cs.RO

TL;DR: 论文提出首个大规模EMG到肌腱控制数据集，用于肌腱驱动机械手，并开发了一种基于扩散的回归模型，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 肌腱驱动机械手控制复杂，传统方法依赖运动捕捉数据，但存在映射困难和视觉跟踪不准确的问题。sEMG传感器提供了一种替代方案，但缺乏相关数据集和有效模型。

Method: 扩展了emg2pose数据集，包含193名受试者的370小时数据，结合MyoSuite MyoHand模型生成肌腱控制信号。提出了三种基线回归模型和一种新型扩散回归模型。

Result: 数据集和模型框架为肌腱驱动机械手的精确控制提供了基础，解决了无效姿态等问题。

Conclusion: 该研究为肌腱驱动机械手的可扩展和精确控制奠定了基础，推动了灵巧操作的发展。

Abstract: Tendon-driven robotic hands offer unparalleled dexterity for manipulation
tasks, but learning control policies for such systems presents unique
challenges. Unlike joint-actuated robotic hands, tendon-driven systems lack a
direct one-to-one mapping between motion capture (mocap) data and tendon
controls, making the learning process complex and expensive. Additionally,
visual tracking methods for real-world applications are prone to occlusions and
inaccuracies, further complicating joint tracking. Wrist-wearable surface
electromyography (sEMG) sensors present an inexpensive, robust alternative to
capture hand motion. However, mapping sEMG signals to tendon control remains a
significant challenge despite the availability of EMG-to-pose data sets and
regression-based models in the existing literature.
  We introduce the first large-scale EMG-to-Tendon Control dataset for robotic
hands, extending the emg2pose dataset, which includes recordings from 193
subjects, spanning 370 hours and 29 stages with diverse gestures. This dataset
incorporates tendon control signals derived using the MyoSuite MyoHand model,
addressing limitations such as invalid poses in prior methods. We provide three
baseline regression models to demonstrate emg2tendon utility and propose a
novel diffusion-based regression model for predicting tendon control from sEMG
recordings. This dataset and modeling framework marks a significant step
forward for tendon-driven dexterous robotic manipulation, laying the groundwork
for scalable and accurate tendon control in robotic hands.
https://emg2tendon.github.io/

</details>


### [5] [Evaluation of an Autonomous Surface Robot Equipped with a Transformable Mobility Mechanism for Efficient Mobility Control](https://arxiv.org/abs/2508.08303)
*Yasuyuki Fujii,Dinh Tuan Tran,Joo-Ho Lee*

Main category: cs.RO

TL;DR: 研究开发了一种可变形的移动机制，用于水面机器人，通过两种控制模式（驻留和移动）提高能源效率和机动性。实验表明，移动模式比驻留模式节能10%，并减少5%的移动时间。


<details>
  <summary>Details</summary>
Motivation: 长期水面环境监测中，高效移动和低功耗对自主水面机器人至关重要。

Method: 开发并评估了一种可变形的移动机制，包含驻留和移动两种控制模式。

Result: 移动模式在往返任务中比驻留模式节能10%，并减少5%的移动时间。

Conclusion: 可变形的移动机制显著提升了水面巡逻的操作效率。

Abstract: Efficient mobility and power consumption are critical for autonomous water
surface robots in long-term water environmental monitoring. This study develops
and evaluates a transformable mobility mechanism for a water surface robot with
two control modes: station-keeping and traveling to improve energy efficiency
and maneuverability. Field experiments show that, in a round-trip task between
two points, the traveling mode reduces power consumption by 10\% and decreases
the total time required for travel by 5\% compared to the station-keeping mode.
These results confirm the effectiveness of the transformable mobility mechanism
for enhancing operational efficiency in patrolling on water surface.

</details>


### [6] [Whole-Body Coordination for Dynamic Object Grasping with Legged Manipulators](https://arxiv.org/abs/2508.08328)
*Qiwei Liang,Boyang Cai,Rongyi He,Hui Li,Tao Teng,Haihan Duan,Changxin Huang,Runhao Zeng*

Main category: cs.RO

TL;DR: 论文提出DQ-Bench基准和DQ-Net框架，用于评估和实现动态目标抓取，通过师生网络结构提升四足机器人动态抓取能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于静态目标抓取，忽略了动态目标的挑战，限制了在物流分拣和人机协作等动态场景中的应用。

Method: 提出DQ-Bench基准，系统评估动态抓取；设计DQ-Net师生框架，教师网络利用特权信息建模目标静态和动态特性，学生网络仅用有限感知数据实现闭环动作输出。

Result: DQ-Net在DQ-Bench上表现优异，动态抓取成功率和响应速度显著优于基线方法。

Conclusion: DQ-Net为四足机器人在动态环境中抓取提供了高效解决方案，扩展了其应用场景。

Abstract: Quadrupedal robots with manipulators offer strong mobility and adaptability
for grasping in unstructured, dynamic environments through coordinated
whole-body control. However, existing research has predominantly focused on
static-object grasping, neglecting the challenges posed by dynamic targets and
thus limiting applicability in dynamic scenarios such as logistics sorting and
human-robot collaboration. To address this, we introduce DQ-Bench, a new
benchmark that systematically evaluates dynamic grasping across varying object
motions, velocities, heights, object types, and terrain complexities, along
with comprehensive evaluation metrics. Building upon this benchmark, we propose
DQ-Net, a compact teacher-student framework designed to infer grasp
configurations from limited perceptual cues. During training, the teacher
network leverages privileged information to holistically model both the static
geometric properties and dynamic motion characteristics of the target, and
integrates a grasp fusion module to deliver robust guidance for motion
planning. Concurrently, we design a lightweight student network that performs
dual-viewpoint temporal modeling using only the target mask, depth map, and
proprioceptive state, enabling closed-loop action outputs without reliance on
privileged data. Extensive experiments on DQ-Bench demonstrate that DQ-Net
achieves robust dynamic objects grasping across multiple task settings,
substantially outperforming baseline methods in both success rate and
responsiveness.

</details>


### [7] [A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems](https://arxiv.org/abs/2508.08473)
*Hossein B. Jond*

Main category: cs.RO

TL;DR: 提出了一种新的群体行为模型，通过相对位置、速度和局部密度调控，实现灵活、无碰撞的群体动态，并扩展至认知自主系统。


<details>
  <summary>Details</summary>
Motivation: 现有模型（如Vicsek、Cucker-Smale）缺乏碰撞避免，而Olfati-Saber模型过于刚性，限制了其在群体机器人中的应用。

Method: 使用相对位置、速度和局部密度调控代理动态，引入空间偏移和动力学偏移两个可调参数。

Result: 模型实现了空间灵活且无碰撞的群体行为，并支持能量感知的群体与集群行为切换。

Conclusion: 该模型为多机器人系统（如自主空中群体）提供了鲁棒的基础。

Abstract: Collective behaviors such as swarming and flocking emerge from simple,
decentralized interactions in biological systems. Existing models, such as
Vicsek and Cucker-Smale, lack collision avoidance, whereas the Olfati-Saber
model imposes rigid formations, limiting their applicability in swarm robotics.
To address these limitations, this paper proposes a minimal yet expressive
model that governs agent dynamics using relative positions, velocities, and
local density, modulated by two tunable parameters: the spatial offset and
kinetic offset. The model achieves spatially flexible, collision-free behaviors
that reflect naturalistic group dynamics. Furthermore, we extend the framework
to cognitive autonomous systems, enabling energy-aware phase transitions
between swarming and flocking through adaptive control parameter tuning. This
cognitively inspired approach offers a robust foundation for real-world
applications in multi-robot systems, particularly autonomous aerial swarms.

</details>


### [8] [AZRA: Extending the Affective Capabilities of Zoomorphic Robots using Augmented Reality](https://arxiv.org/abs/2508.08507)
*Shaun Macdonald,Salma ElSayed,Mark McGill*

Main category: cs.RO

TL;DR: AZRA是一个增强现实框架，旨在提升仿生机器人与用户之间的情感互动能力，无需物理改造。


<details>
  <summary>Details</summary>
Motivation: 现有的仿生机器人情感互动简单且短暂，限制了其在家居环境中的应用潜力。

Method: 通过AR技术扩展机器人的情感表现（如面部、灯光、声音、气泡）和互动方式（如语音、触摸、接近、注视），并结合情感计算模型。

Result: AZRA成功增强了Petit Qoobo机器人的情感互动能力，并支持快速参与式原型设计。

Conclusion: AZRA为未来仿生机器人的开发提供了新的方向，强调了情感互动的重要性。

Abstract: Zoomorphic robots could serve as accessible and practical alternatives for
users unable or unwilling to keep pets. However, their affective interactions
are often simplistic and short-lived, limiting their potential for domestic
adoption. In order to facilitate more dynamic and nuanced affective
interactions and relationships between users and zoomorphic robots we present
AZRA, a novel augmented reality (AR) framework that extends the affective
capabilities of these robots without physical modifications. To demonstrate
AZRA, we augment a zoomorphic robot, Petit Qoobo, with novel emotional displays
(face, light, sound, thought bubbles) and interaction modalities (voice, touch,
proximity, gaze). Additionally, AZRA features a computational model of emotion
to calculate the robot's emotional responses, daily moods, evolving personality
and needs. We highlight how AZRA can be used for rapid participatory
prototyping and enhancing existing robots, then discuss implications on future
zoomorphic robot development.

</details>


### [9] [DeepFleet: Multi-Agent Foundation Models for Mobile Robots](https://arxiv.org/abs/2508.08574)
*Ameya Agaskar,Sriram Siva,William Pickering,Kyle O'Brien,Charles Kekeh,Ang Li,Brianna Gallo Sarker,Alicia Chua,Mayur Nemade,Charun Thattai,Jiaming Di,Isaac Iyengar,Ramya Dharoor,Dino Kirouani,Jimmy Erskine,Tamir Hegazy,Scott Niekum,Usman A. Khan,Federico Pecora,Joseph W. Durham*

Main category: cs.RO

TL;DR: DeepFleet是一套用于大规模移动机器人车队协调和规划的基础模型，基于亚马逊仓库数据训练，包含四种架构设计，其中机器人中心模型和图-地面模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决大规模移动机器人车队的协调和规划问题，探索多智能体基础模型的设计空间。

Method: 设计了四种模型架构：机器人中心模型（RC）、机器人-地面模型（RF）、图像-地面模型（IF）和图-地面模型（GF），并评估其性能。

Result: 机器人中心模型和图-地面模型表现最佳，能有效利用更大规模的数据集。

Conclusion: 机器人中心模型和图-地面模型因其异步状态更新和局部交互结构的设计，在多智能体基础模型中具有潜力。

Abstract: We introduce DeepFleet, a suite of foundation models designed to support
coordination and planning for large-scale mobile robot fleets. These models are
trained on fleet movement data, including robot positions, goals, and
interactions, from hundreds of thousands of robots in Amazon warehouses
worldwide. DeepFleet consists of four architectures that each embody a distinct
inductive bias and collectively explore key points in the design space for
multi-agent foundation models: the robot-centric (RC) model is an
autoregressive decision transformer operating on neighborhoods of individual
robots; the robot-floor (RF) model uses a transformer with cross-attention
between robots and the warehouse floor; the image-floor (IF) model applies
convolutional encoding to a multi-channel image representation of the full
fleet; and the graph-floor (GF) model combines temporal attention with graph
neural networks for spatial relationships. In this paper, we describe these
models and present our evaluation of the impact of these design choices on
prediction task performance. We find that the robot-centric and graph-floor
models, which both use asynchronous robot state updates and incorporate the
localized structure of robot interactions, show the most promise. We also
present experiments that show that these two models can make effective use of
larger warehouses operation datasets as the models are scaled up.

</details>


### [10] [Developing a Calibrated Physics-Based Digital Twin for Construction Vehicles](https://arxiv.org/abs/2508.08576)
*Deniz Karanfil,Daniel Lindmark,Martin Servin,David Torick,Bahram Ravani*

Main category: cs.RO

TL;DR: 本文开发了一种校准的数字孪生轮式装载机，通过高保真数字模型实现自动化诊断、操作优化和预规划模拟。


<details>
  <summary>Details</summary>
Motivation: 通过数字孪生技术提升轮式装载机的自动化能力，实现高保真模拟和优化操作。

Method: 使用AGX Dynamics软件中的多体动力学模型，结合传感器校准数字模型。

Result: 校准后的数字孪生能高精度估计铲斗受力，实现高保真模拟。

Conclusion: 校准数字孪生技术为轮式装载机的自动化操作提供了高保真模拟和优化方案。

Abstract: This paper presents the development of a calibrated digital twin of a wheel
loader. A calibrated digital twin integrates a construction vehicle with a
high-fidelity digital model allowing for automated diagnostics and optimization
of operations as well as pre-planning simulations enhancing automation
capabilities. The high-fidelity digital model is a virtual twin of the physical
wheel loader. It uses a physics-based multibody dynamic model of the wheel
loader in the software AGX Dynamics. Interactions of the wheel loader's bucket
while in use in construction can be simulated in the virtual model. Calibration
makes this simulation of high-fidelity which can enhance realistic planning for
automation of construction operations. In this work, a wheel loader was
instrumented with several sensors used to calibrate the digital model. The
calibrated digital twin was able to estimate the magnitude of the forces on the
bucket base with high accuracy, providing a high-fidelity simulation.

</details>


### [11] [Autonomous Mobile Plant Watering Robot : A Kinematic Approach](https://arxiv.org/abs/2508.08607)
*Justin London*

Main category: cs.RO

TL;DR: 提出了一种新型自主移动植物浇水机器人，结合6自由度机械臂和计算机视觉技术，实现智能浇水。


<details>
  <summary>Details</summary>
Motivation: 现有农业机器人价格昂贵且功能有限，无法满足植物浇水的灵活性和精准性需求。

Method: 使用6自由度机械臂和4轮驱动底盘，配备Jetson Nano和Arduino微控制器，结合YOLOv5和Pl@ntNet-300K数据集进行植物识别，利用LIDAR避障。

Result: 机器人能够自主移动、识别植物并精准浇水，无需预定义路径。

Conclusion: 该机器人解决了现有农业机器人的局限性，提供了一种经济高效的智能浇水方案。

Abstract: Plants need regular and the appropriate amount of watering to thrive and
survive. While agricultural robots exist that can spray water on plants and
crops such as the , they are expensive and have limited mobility and/or
functionality. We introduce a novel autonomous mobile plant watering robot that
uses a 6 degree of freedom (DOF) manipulator, connected to a 4 wheel drive
alloy chassis, to be able to hold a garden hose, recognize and detect plants,
and to water them with the appropriate amount of water by being able to insert
a soil humidity/moisture sensor into the soil. The robot uses Jetson Nano and
Arduino microcontroller and real sense camera to perform computer vision to
detect plants using real-time YOLOv5 with the Pl@ntNet-300K dataset. The robot
uses LIDAR for object and collision avoideance and does not need to move on a
pre-defined path and can keep track of which plants it has watered. We provide
the Denavit-Hartenberg (DH) Table, forward kinematics, differential driving
kinematics, and inverse kinematics along with simulation and experiment results

</details>


### [12] [Communication Efficient Robotic Mixed Reality with Gaussian Splatting Cross-Layer Optimization](https://arxiv.org/abs/2508.08624)
*Chenxuan Liu,He Li,Zongze Li,Shuai Wang,Wei Xu,Kejiang Ye,Derrick Wing Kwan Ng,Chengzhong Xu*

Main category: cs.RO

TL;DR: 论文提出GSMR和GSCLO框架，通过高斯泼溅模型减少图像上传需求，并优化内容切换和功率分配，显著降低通信成本。


<details>
  <summary>Details</summary>
Motivation: 解决机器人混合现实系统中高分辨率图像上传的高通信成本问题。

Method: 提出GSMR框架，利用高斯泼溅模型生成逼真视图；进一步提出GSCLO框架，联合优化内容切换和功率分配，采用APO算法降低计算复杂度。

Result: 实验表明，GSMR和GSCLO在多种场景和机器人上显著优于现有基准，首次实现超低通信成本的RoboMR。

Conclusion: 高斯泼溅模型和GSCLO框架有效降低通信成本，动态场景中混合数据可提升性能。

Abstract: Realizing low-cost communication in robotic mixed reality (RoboMR) systems
presents a challenge, due to the necessity of uploading high-resolution images
through wireless channels. This paper proposes Gaussian splatting (GS) RoboMR
(GSMR), which enables the simulator to opportunistically render a
photo-realistic view from the robot's pose by calling ``memory'' from a GS
model, thus reducing the need for excessive image uploads. However, the GS
model may involve discrepancies compared to the actual environments. To this
end, a GS cross-layer optimization (GSCLO) framework is further proposed, which
jointly optimizes content switching (i.e., deciding whether to upload image or
not) and power allocation (i.e., adjusting to content profiles) across
different frames by minimizing a newly derived GSMR loss function. The GSCLO
problem is addressed by an accelerated penalty optimization (APO) algorithm
that reduces computational complexity by over $10$x compared to traditional
branch-and-bound and search algorithms. Moreover, variants of GSCLO are
presented to achieve robust, low-power, and multi-robot GSMR. Extensive
experiments demonstrate that the proposed GSMR paradigm and GSCLO method
achieve significant improvements over existing benchmarks on both wheeled and
legged robots in terms of diverse metrics in various scenarios. For the first
time, it is found that RoboMR can be achieved with ultra-low communication
costs, and mixture of data is useful for enhancing GS performance in dynamic
scenarios.

</details>


### [13] [ZS-Puffin: Design, Modeling and Implementation of an Unmanned Aerial-Aquatic Vehicle with Amphibious Wings](https://arxiv.org/abs/2508.08690)
*Zhenjiang Wang,Yunhua Jiang,Zikun Zhen,Yifan Jiang,Yubin Tan,Wubin Wang*

Main category: cs.RO

TL;DR: 本文提出了一种基于海雀翅膀启发的两栖翼无人空中-水下飞行器（UAAV），通过单一自由度设计实现空中和水下的高效推进，并引入人工中央模式发生器（CPG）优化运动平滑性。


<details>
  <summary>Details</summary>
Motivation: 解决无人空中-水下飞行器在介质差异下推进系统的挑战，同时减少对海洋生物的干扰，实现环保设计。

Method: 重新设计固定翼结构为两栖翼，具有单一俯仰自由度，无需额外组件；引入CPG优化水下扑翼运动的平滑性。

Result: 成功开发出原型机，展示了两栖翼在空中和水下的功能，验证了设计的可行性和环保性。

Conclusion: 两栖翼设计为UAAV提供了高效且环保的推进方案，CPG进一步提升了运动性能，具有广阔的应用前景。

Abstract: Unmanned aerial-aquatic vehicles (UAAVs) can operate both in the air and
underwater, giving them broad application prospects. Inspired by the
dual-function wings of puffins, we propose a UAAV with amphibious wings to
address the challenge posed by medium differences on the vehicle's propulsion
system. The amphibious wing, redesigned based on a fixed-wing structure,
features a single degree of freedom in pitch and requires no additional
components. It can generate lift in the air and function as a flapping wing for
propulsion underwater, reducing disturbance to marine life and making it
environmentally friendly. Additionally, an artificial central pattern generator
(CPG) is introduced to enhance the smoothness of the flapping motion. This
paper presents the prototype, design details, and practical implementation of
this concept.

</details>


### [14] [OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing](https://arxiv.org/abs/2508.08706)
*Zhengxue Cheng,Yiqian Zhang,Wenkang Zhang,Haoyu Li,Keyu Wang,Li Song,Hengdi Zhang*

Main category: cs.RO

TL;DR: OmniVTLA提出了一种结合触觉感知的VLA模型新架构，通过双路径触觉编码器和多模态数据集ObjTac，显著提升了接触密集型任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型因触觉传感器的异质性和数据获取困难，忽视了触觉感知的重要性，导致在接触密集型任务中表现不佳。

Method: 提出OmniVTLA架构，包括双路径触觉编码器（ViT和SA-ViT）和ObjTac数据集（135K三模态样本），训练语义对齐的触觉编码器。

Result: 在真实实验中，OmniVTLA在抓取任务中成功率显著提升（夹爪96.9%，灵巧手100%），任务完成时间缩短，轨迹更平滑。

Conclusion: OmniVTLA通过触觉感知显著提升了VLA模型的性能，尤其在接触密集型任务中表现优异。

Abstract: Recent vision-language-action (VLA) models build upon vision-language
foundations, and have achieved promising results and exhibit the possibility of
task generalization in robot manipulation. However, due to the heterogeneity of
tactile sensors and the difficulty of acquiring tactile data, current VLA
models significantly overlook the importance of tactile perception and fail in
contact-rich tasks. To address this issue, this paper proposes OmniVTLA, a
novel architecture involving tactile sensing. Specifically, our contributions
are threefold. First, our OmniVTLA features a dual-path tactile encoder
framework. This framework enhances tactile perception across diverse
vision-based and force-based tactile sensors by using a pretrained vision
transformer (ViT) and a semantically-aligned tactile ViT (SA-ViT). Second, we
introduce ObjTac, a comprehensive force-based tactile dataset capturing
textual, visual, and tactile information for 56 objects across 10 categories.
With 135K tri-modal samples, ObjTac supplements existing visuo-tactile
datasets. Third, leveraging this dataset, we train a semantically-aligned
tactile encoder to learn a unified tactile representation, serving as a better
initialization for OmniVTLA. Real-world experiments demonstrate substantial
improvements over state-of-the-art VLA baselines, achieving 96.9% success rates
with grippers, (21.9% higher over baseline) and 100% success rates with
dexterous hands (6.2% higher over baseline) in pick-and-place tasks. Besides,
OmniVTLA significantly reduces task completion time and generates smoother
trajectories through tactile sensing compared to existing VLA.

</details>


### [15] [Towards Safe Imitation Learning via Potential Field-Guided Flow Matching](https://arxiv.org/abs/2508.08707)
*Haoran Ding,Anqing Duan,Zezhou Sun,Leonel Rozo,Noémie Jaquier,Dezhen Song,Yoshihiko Nakamura*

Main category: cs.RO

TL;DR: 提出了一种名为PF2MP的新方法，通过结合势场和流匹配技术，在模仿学习中生成更安全的运动策略。


<details>
  <summary>Details</summary>
Motivation: 当前深度生成模型（如扩散和流匹配模型）在模仿学习中表现优异，但生成运动的安全性在复杂环境中被忽视。

Method: PF2MP通过从成功演示中同时学习任务策略和障碍相关势场，并在推理阶段通过势场调节流匹配向量场，实现安全运动生成。

Result: 实验表明，PF2MP在导航和机器人操作任务中显著减少碰撞，提升安全性而不影响任务成功率。

Conclusion: PF2MP为复杂环境中的安全运动生成提供了有效解决方案。

Abstract: Deep generative models, particularly diffusion and flow matching models, have
recently shown remarkable potential in learning complex policies through
imitation learning. However, the safety of generated motions remains
overlooked, particularly in complex environments with inherent obstacles. In
this work, we address this critical gap by proposing Potential Field-Guided
Flow Matching Policy (PF2MP), a novel approach that simultaneously learns task
policies and extracts obstacle-related information, represented as a potential
field, from the same set of successful demonstrations. During inference, PF2MP
modulates the flow matching vector field via the learned potential field,
enabling safe motion generation. By leveraging these complementary fields, our
approach achieves improved safety without compromising task success across
diverse environments, such as navigation tasks and robotic manipulation
scenarios. We evaluate PF2MP in both simulation and real-world settings,
demonstrating its effectiveness in task space and joint space control.
Experimental results demonstrate that PF2MP enhances safety, achieving a
significant reduction of collisions compared to baseline policies. This work
paves the way for safer motion generation in unstructured and obstaclerich
environments.

</details>


### [16] [CRADLE: Conversational RTL Design Space Exploration with LLM-based Multi-Agent Systems](https://arxiv.org/abs/2508.08709)
*Lukas Krupp,Maximilian Schöffel,Elias Biehl,Norbert Wehn*

Main category: cs.RO

TL;DR: CRADLE是一个基于LLM多智能体系统的对话框架，用于RTL设计空间探索，支持用户引导的流程，并具备自验证、修正和优化功能。实验显示其在FPGA资源最小化方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法过于僵化，无法灵活支持用户引导的设计流程和内部优化。CRADLE旨在解决这一问题。

Method: 采用生成器-批评家智能体系统，结合最先进的LLM技术，针对FPGA资源最小化进行优化。

Result: 在RTLLM基准测试中，CRADLE显著减少了资源使用，LUT和FF的平均降幅分别为48%和40%。

Conclusion: CRADLE通过灵活的对话框架和多智能体协作，有效提升了RTL设计的资源优化效率。

Abstract: This paper presents CRADLE, a conversational framework for design space
exploration of RTL designs using LLM-based multi-agent systems. Unlike existing
rigid approaches, CRADLE enables user-guided flows with internal
self-verification, correction, and optimization. We demonstrate the framework
with a generator-critic agent system targeting FPGA resource minimization using
state-of-the-art LLMs. Experimental results on the RTLLM benchmark show that
CRADLE achieves significant reductions in resource usage with averages of 48%
and 40% in LUTs and FFs across all benchmark designs.

</details>


### [17] [Boosting Action-Information via a Variational Bottleneck on Unlabelled Robot Videos](https://arxiv.org/abs/2508.08743)
*Haoyu Zhang,Long Cheng*

Main category: cs.RO

TL;DR: 论文提出了一种新框架，通过最大化潜在动作与真实动作的互信息，直接从无标记视频演示中学习，提升了策略性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于演示的学习（LfD）依赖大量标记动作的专家轨迹，限制了训练数据规模。直接从无标记视频学习是一种有前景的替代方案，但现有方法提取的潜在动作与真实动作互信息低，导致控制性能不佳。

Method: 引入了一种新框架，利用变分信息瓶颈提取与动作相关的表示，同时丢弃任务无关信息，最大化潜在动作与真实动作的互信息。

Result: 在仿真和真实机器人环境中的实验表明，该方法显著提升了互信息，并一致改善了策略性能。

Conclusion: 提出的框架有效解决了无标记视频学习中潜在动作与真实动作互信息低的问题，为LfD提供了更高效的数据利用方式。

Abstract: Learning from demonstrations (LfD) typically relies on large amounts of
action-labeled expert trajectories, which fundamentally constrains the scale of
available training data. A promising alternative is to learn directly from
unlabeled video demonstrations. However, we find that existing methods tend to
encode latent actions that share little mutual information with the true robot
actions, leading to suboptimal control performance. To address this limitation,
we introduce a novel framework that explicitly maximizes the mutual information
between latent actions and true actions, even in the absence of action labels.
Our method leverage the variational information-bottleneck to extract
action-relevant representations while discarding task-irrelevant information.
We provide a theoretical analysis showing that our objective indeed maximizes
the mutual information between latent and true actions. Finally, we validate
our approach through extensive experiments: first in simulated robotic
environments and then on real-world robotic platforms, the experimental results
demonstrate that our method significantly enhances mutual information and
consistently improves policy performance.

</details>


### [18] [Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT](https://arxiv.org/abs/2508.08748)
*Muhammad A. Muttaqien,Tomohiro Motoda,Ryo Hanai,Yukiyasu Domae*

Main category: cs.RO

TL;DR: 本文提出了一种基于标注引导视觉提示和动作分块模仿学习的机器人抓取与放置方法，解决了零售环境中密集物体排列和遮挡的挑战。


<details>
  <summary>Details</summary>
Motivation: 便利店中的机器人抓取与放置任务因物体密集排列、遮挡及属性差异（如颜色、形状、大小和纹理）而复杂化，传统方法难以应对。

Method: 采用标注引导视觉提示（通过边界框标注识别可抓取物体和放置位置），并结合动作分块Transformer（ACT）模仿学习算法，预测连续动作序列。

Result: 实验表明，该方法提高了抓取成功率和适应性，尤其在零售环境中表现优异。

Conclusion: 提出的感知-动作管道结合ACT算法，为复杂环境下的机器人操作提供了高效、数据驱动的解决方案。

Abstract: Robotic pick-and-place tasks in convenience stores pose challenges due to
dense object arrangements, occlusions, and variations in object properties such
as color, shape, size, and texture. These factors complicate trajectory
planning and grasping. This paper introduces a perception-action pipeline
leveraging annotation-guided visual prompting, where bounding box annotations
identify both pickable objects and placement locations, providing structured
spatial guidance. Instead of traditional step-by-step planning, we employ
Action Chunking with Transformers (ACT) as an imitation learning algorithm,
enabling the robotic arm to predict chunked action sequences from human
demonstrations. This facilitates smooth, adaptive, and data-driven
pick-and-place operations. We evaluate our system based on success rate and
visual analysis of grasping behavior, demonstrating improved grasp accuracy and
adaptability in retail environments.

</details>


### [19] [Robot can reduce superior's dominance in group discussions with human social hierarchy](https://arxiv.org/abs/2508.08767)
*Kazuki Komura,Kumi Ozaki,Seiji Yamada*

Main category: cs.RO

TL;DR: 研究探讨机器人能否通过干预社交层级关系，减少上级主导并平衡讨论参与。实验结果显示机器人行为可能影响发言时间，但未显著差异，且不降低上级满意度。


<details>
  <summary>Details</summary>
Motivation: 在层级化讨论中，上级常主导发言，机器人干预可能平衡参与。

Method: 30名医生和学生参与实验，机器人根据层级关系鼓励发言，对比无干预和均等干预。

Result: 机器人行为可能影响发言时间，但未显著差异，且未降低上级满意度。

Conclusion: 机器人干预可能抑制上级主导并平衡讨论参与。

Abstract: This study investigated whether robotic agents that deal with social
hierarchical relationships can reduce the dominance of superiors and equalize
participation among participants in discussions with hierarchical structures.
Thirty doctors and students having hierarchical relationship were gathered as
participants, and an intervention experiment was conducted using a robot that
can encourage participants to speak depending on social hierarchy. These were
compared with strategies that intervened equally for all participants without
considering hierarchy and with a no-action. The robots performed follow
actions, showing backchanneling to speech, and encourage actions, prompting
speech from members with less speaking time, on the basis of the hierarchical
relationships among group members to equalize participation. The experimental
results revealed that the robot's actions could potentially influence the
speaking time among members, but it could not be conclusively stated that there
were significant differences between the robot's action conditions. However,
the results suggested that it might be possible to influence speaking time
without decreasing the satisfaction of superiors. This indicates that in
discussion scenarios where experienced superiors are likely to dominate,
controlling the robot's backchanneling behavior could potentially suppress
dominance and equalize participation among group members.

</details>


### [20] [Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors](https://arxiv.org/abs/2508.08896)
*Haoyu Zhao,Linghao Zhuang,Xingyue Zhao,Cheng Zeng,Haoran Xu,Yuming Jiang,Jun Cen,Kexiang Wang,Jiayan Guo,Siteng Huang,Xin Li,Deli Zhao,Hua Zou*

Main category: cs.RO

TL;DR: AffordDex是一个两阶段训练框架，通过学习人类手部运动先验和物体功能感知，实现通用灵巧抓取。


<details>
  <summary>Details</summary>
Motivation: 现有方法过于关注低层次抓取稳定性，忽略了功能感知定位和类人姿势，这对下游操作至关重要。

Method: 两阶段训练：第一阶段预训练轨迹模仿器学习人类手部运动先验；第二阶段通过残差模块和NAA模块调整运动以适应具体物体。

Result: AffordDex在已见物体、未见实例和新类别上均显著优于现有方法，抓取姿势类人且功能合理。

Conclusion: AffordDex通过结合运动先验和功能感知，实现了通用且类人的灵巧抓取。

Abstract: A dexterous hand capable of generalizable grasping objects is fundamental for
the development of general-purpose embodied AI. However, previous methods focus
narrowly on low-level grasp stability metrics, neglecting affordance-aware
positioning and human-like poses which are crucial for downstream manipulation.
To address these limitations, we propose AffordDex, a novel framework with
two-stage training that learns a universal grasping policy with an inherent
understanding of both motion priors and object affordances. In the first stage,
a trajectory imitator is pre-trained on a large corpus of human hand motions to
instill a strong prior for natural movement. In the second stage, a residual
module is trained to adapt these general human-like motions to specific object
instances. This refinement is critically guided by two components: our Negative
Affordance-aware Segmentation (NAA) module, which identifies functionally
inappropriate contact regions, and a privileged teacher-student distillation
process that ensures the final vision-based policy is highly successful.
Extensive experiments demonstrate that AffordDex not only achieves universal
dexterous grasping but also remains remarkably human-like in posture and
functionally appropriate in contact location. As a result, AffordDex
significantly outperforms state-of-the-art baselines across seen objects,
unseen instances, and even entirely novel categories.

</details>


### [21] [Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion](https://arxiv.org/abs/2508.08982)
*Seungeun Rho,Kartik Garg,Morgan Byrd,Sehoon Ha*

Main category: cs.RO

TL;DR: 提出了一种名为SDAX的学习框架，通过无监督技能发现减少人工工程需求，使四足机器人掌握多种敏捷行为。


<details>
  <summary>Details</summary>
Motivation: 探索对于四足机器人学习克服障碍的敏捷行为至关重要，但传统方法依赖人工设计或专家演示，限制了泛化能力。

Method: SDAX利用无监督技能发现和双层优化动态调节探索程度，自主获取多样化技能。

Result: SDAX使机器人掌握了爬行、攀爬、跳跃等敏捷行为，并成功迁移到真实硬件。

Conclusion: SDAX显著减少了人工工程需求，提升了机器人行为的多样性和泛化能力。

Abstract: Exploration is crucial for enabling legged robots to learn agile locomotion
behaviors that can overcome diverse obstacles. However, such exploration is
inherently challenging, and we often rely on extensive reward engineering,
expert demonstrations, or curriculum learning - all of which limit
generalizability. In this work, we propose Skill Discovery as Exploration
(SDAX), a novel learning framework that significantly reduces human engineering
effort. SDAX leverages unsupervised skill discovery to autonomously acquire a
diverse repertoire of skills for overcoming obstacles. To dynamically regulate
the level of exploration during training, SDAX employs a bi-level optimization
process that autonomously adjusts the degree of exploration. We demonstrate
that SDAX enables quadrupedal robots to acquire highly agile behaviors
including crawling, climbing, leaping, and executing complex maneuvers such as
jumping off vertical walls. Finally, we deploy the learned policy on real
hardware, validating its successful transfer to the real world.

</details>


### [22] [Rational Inverse Reasoning](https://arxiv.org/abs/2508.08983)
*Ben Zandonati,Tomás Lozano-Pérez,Leslie Pack Kaelbling*

Main category: cs.RO

TL;DR: 论文提出Rational Inverse Reasoning (RIR)框架，通过分层生成模型推断潜在程序，实现机器人从少量演示中泛化到新任务。


<details>
  <summary>Details</summary>
Motivation: 人类能从单一演示中泛化到不同任务，而机器人需要大量数据且泛化能力差。RIR旨在通过推断潜在的结构化程序解决这一问题。

Method: RIR采用贝叶斯程序归纳框架，结合视觉语言模型和规划器，迭代生成并评分任务假设，最终得到可执行程序。

Result: 在连续操作任务测试中，RIR仅需一次演示即可推断任务结构并泛化到新场景，优于现有视觉语言模型。

Conclusion: RIR通过推断潜在程序，显著提升了机器人在少量演示下的泛化能力。

Abstract: Humans can observe a single, imperfect demonstration and immediately
generalize to very different problem settings. Robots, in contrast, often
require hundreds of examples and still struggle to generalize beyond the
training conditions. We argue that this limitation arises from the inability to
recover the latent explanations that underpin intelligent behavior, and that
these explanations can take the form of structured programs consisting of
high-level goals, sub-task decomposition, and execution constraints. In this
work, we introduce Rational Inverse Reasoning (RIR), a framework for inferring
these latent programs through a hierarchical generative model of behavior. RIR
frames few-shot imitation as Bayesian program induction: a vision-language
model iteratively proposes structured symbolic task hypotheses, while a
planner-in-the-loop inference scheme scores each by the likelihood of the
observed demonstration under that hypothesis. This loop yields a posterior over
concise, executable programs. We evaluate RIR on a suite of continuous
manipulation tasks designed to test one-shot and few-shot generalization across
variations in object pose, count, geometry, and layout. With as little as one
demonstration, RIR infers the intended task structure and generalizes to novel
settings, outperforming state-of-the-art vision-language model baselines.

</details>


### [23] [Generation of Real-time Robotic Emotional Expressions Learning from Human Demonstration in Mixed Reality](https://arxiv.org/abs/2508.08999)
*Chao Wang,Michael Gienger,Fan Zhang*

Main category: cs.RO

TL;DR: 提出一种基于混合现实（MR）的框架，通过专家演示生成机器人情感表达。


<details>
  <summary>Details</summary>
Motivation: 机器人情感表达对与人类互动至关重要，需生成真实多样的表达方式。

Method: 利用MR捕捉专家演示，通过流匹配生成模型实时生成机器人行为。

Result: 初步测试验证了该框架生成自主情感表达的有效性。

Conclusion: 该框架为机器人情感表达提供了新的生成方法。

Abstract: Expressive behaviors in robots are critical for effectively conveying their
emotional states during interactions with humans. In this work, we present a
framework that autonomously generates realistic and diverse robotic emotional
expressions based on expert human demonstrations captured in Mixed Reality
(MR). Our system enables experts to teleoperate a virtual robot from a
first-person perspective, capturing their facial expressions, head movements,
and upper-body gestures, and mapping these behaviors onto corresponding robotic
components including eyes, ears, neck, and arms. Leveraging a
flow-matching-based generative process, our model learns to produce coherent
and varied behaviors in real-time in response to moving objects, conditioned
explicitly on given emotional states. A preliminary test validated the
effectiveness of our approach for generating autonomous expressions.

</details>


### [24] [Large Scale Robotic Material Handling: Learning, Planning, and Control](https://arxiv.org/abs/2508.09003)
*Filippo A. Spinelli,Yifan Zhai,Fang Nan,Pascal Egli,Julian Nubert,Thilo Bleumer,Lukas Miller,Ferdinand Hofmann,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种用于大规模物料搬运任务的自主执行框架，结合感知、路径规划和运动控制模块，并通过强化学习优化抓取点和轨迹控制。


<details>
  <summary>Details</summary>
Motivation: 物料搬运是许多行业中的核心操作，但传统方法依赖人工操作，效率低且存在安全隐患。

Method: 系统整合环境感知、抓取点选择、路径规划和运动控制模块，采用强化学习优化抓取点和轨迹控制。

Result: 在40吨物料搬运设备上验证了框架的有效性，精度、重复性和安全性优于人工操作。

Conclusion: 首次实现了全规模物料搬运任务的自动化，展示了其在高效和高精度任务中的潜力。

Abstract: Bulk material handling involves the efficient and precise moving of large
quantities of materials, a core operation in many industries, including cargo
ship unloading, waste sorting, construction, and demolition. These repetitive,
labor-intensive, and safety-critical operations are typically performed using
large hydraulic material handlers equipped with underactuated grippers. In this
work, we present a comprehensive framework for the autonomous execution of
large-scale material handling tasks. The system integrates specialized modules
for environment perception, pile attack point selection, path planning, and
motion control. The main contributions of this work are two reinforcement
learning-based modules: an attack point planner that selects optimal grasping
locations on the material pile to maximize removal efficiency and minimize the
number of scoops, and a robust trajectory following controller that addresses
the precision and safety challenges associated with underactuated grippers in
movement, while utilizing their free-swinging nature to release material
through dynamic throwing. We validate our framework through real-world
experiments on a 40 t material handler in a representative worksite, focusing
on two key tasks: high-throughput bulk pile management and high-precision truck
loading. Comparative evaluations against human operators demonstrate the
system's effectiveness in terms of precision, repeatability, and operational
safety. To the best of our knowledge, this is the first complete automation of
material handling tasks on a full scale.

</details>


### [25] [GeoVLA: Empowering 3D Representations in Vision-Language-Action Models](https://arxiv.org/abs/2508.09071)
*Lin Sun,Bin Xie,Yingfei Liu,Hao Shi,Tiancai Wang,Jiale Cao*

Main category: cs.RO

TL;DR: GeoVLA是一种新型的Vision-Language-Action模型，通过整合3D几何信息提升机器人操作的性能和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型主要依赖2D视觉输入，忽略了3D物理世界中的几何信息，限制了空间感知和适应性。

Method: GeoVLA结合视觉语言模型处理图像和语言指令，同时通过点嵌入网络处理深度图生成3D几何嵌入，最后由3D增强动作专家整合信息生成精确动作序列。

Result: 在LIBERO和ManiSkill2仿真基准测试中达到最优性能，并在真实任务中表现出高度适应性和鲁棒性。

Conclusion: GeoVLA通过整合3D信息显著提升了机器人操作的性能和适应性，为未来研究提供了新方向。

Abstract: Vision-Language-Action (VLA) models have emerged as a promising approach for
enabling robots to follow language instructions and predict corresponding
actions.However, current VLA models mainly rely on 2D visual inputs, neglecting
the rich geometric information in the 3D physical world, which limits their
spatial awareness and adaptability. In this paper, we present GeoVLA, a novel
VLA framework that effectively integrates 3D information to advance robotic
manipulation. It uses a vision-language model (VLM) to process images and
language instructions,extracting fused vision-language embeddings. In parallel,
it converts depth maps into point clouds and employs a customized point
encoder, called Point Embedding Network, to generate 3D geometric embeddings
independently. These produced embeddings are then concatenated and processed by
our proposed spatial-aware action expert, called 3D-enhanced Action Expert,
which combines information from different sensor modalities to produce precise
action sequences. Through extensive experiments in both simulation and
real-world environments, GeoVLA demonstrates superior performance and
robustness. It achieves state-of-the-art results in the LIBERO and ManiSkill2
simulation benchmarks and shows remarkable robustness in real-world tasks
requiring height adaptability, scale awareness and viewpoint invariance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [26] [Topos Theory for Generative AI and LLMs](https://arxiv.org/abs/2508.08293)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 论文提出了一种基于拓扑理论的新型生成式AI架构（GAIAs），利用范畴论中的通用构造设计新的LLM组合结构。


<details>
  <summary>Details</summary>
Motivation: 现有LLM架构多为线性或混合专家模型，缺乏理论支持的组合性结构。本文旨在利用范畴论中的拓扑性质（如极限、指数对象等）构建更强大的LLM架构。

Method: 通过证明LLM范畴的完备性和拓扑性质（如存在极限、指数对象等），设计新的组合结构（如拉回、推出、子对象分类器等）。

Result: 理论验证了LLM范畴的完备性及拓扑性质，并提出了一种基于反向传播函子的实现方法。

Conclusion: 利用范畴论构建的新型LLM架构具有更强的组合性和理论支持，为未来生成式AI设计提供了新方向。

Abstract: We propose the design of novel categorical generative AI architectures
(GAIAs) using topos theory, a type of category that is ``set-like": a topos has
all (co)limits, is Cartesian closed, and has a subobject classifier. Previous
theoretical results on the Transformer model have shown that it is a universal
sequence-to-sequence function approximator, and dense in the space of all
continuous functions with compact support on the Euclidean space of embeddings
of tokens. Building on this theoretical result, we explore novel architectures
for LLMs that exploit the property that the category of LLMs, viewed as
functions, forms a topos. Previous studies of large language models (LLMs) have
focused on daisy-chained linear architectures or mixture-of-experts. In this
paper, we use universal constructions in category theory to construct novel LLM
architectures based on new types of compositional structures. In particular,
these new compositional structures are derived from universal properties of LLM
categories, and include pullback, pushout, (co) equalizers, exponential
objects, and subobject classifiers. We theoretically validate these new
compositional structures by showing that the category of LLMs is (co)complete,
meaning that all diagrams have solutions in the form of (co)limits. Building on
this completeness result, we then show that the category of LLMs forms a topos,
a ``set-like" category, which requires showing the existence of exponential
objects as well as subobject classifiers. We use a functorial characterization
of backpropagation to define a potential implementation of an LLM topos
architecture.

</details>


### [27] [Topos Causal Models](https://arxiv.org/abs/2508.08295)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 本文提出了一种新型因果模型——拓扑因果模型（TCMs），利用拓扑范畴的关键性质（如完备性、子对象分类器和指数对象），展示了这些性质在因果推断中的重要性。


<details>
  <summary>Details</summary>
Motivation: 传统因果模型在处理复杂因果图时存在局限性，TCMs通过拓扑范畴的性质提供更强大的建模能力。

Method: 基于拓扑范畴的完备性、子对象分类器和指数对象，构建TCMs，并证明其范畴的完备性。

Result: TCMs能够解决任意复杂因果图，支持因果干预和等价类推理，并具备内部逻辑。

Conclusion: TCMs为因果推断提供了更灵活和强大的数学框架，适用于复杂因果关系的建模与分析。

Abstract: We propose topos causal models (TCMs), a novel class of causal models that
exploit the key properties of a topos category: they are (co)complete, meaning
all (co)limits exist, they admit a subobject classifier, and allow exponential
objects. The main goal of this paper is to show that these properties are
central to many applications in causal inference. For example, subobject
classifiers allow a categorical formulation of causal intervention, which
creates sub-models. Limits and colimits allow causal diagrams of arbitrary
complexity to be ``solved", using a novel interpretation of causal
approximation. Exponential objects enable reasoning about equivalence classes
of operations on causal models, such as covered edge reversal and causal
homotopy. Analogous to structural causal models (SCMs), TCMs are defined by a
collection of functions, each defining a ``local autonomous" causal mechanism
that assemble to induce a unique global function from exogenous to endogenous
variables. Since the category of TCMs is (co)complete, which we prove in this
paper, every causal diagram has a ``solution" in the form of a (co)limit: this
implies that any arbitrary causal model can be ``approximated" by some global
function with respect to the morphisms going into or out of the diagram.
Natural transformations are crucial in measuring the quality of approximation.
In addition, we show that causal interventions are modeled by subobject
classifiers: any sub-model is defined by a monic arrow into its parent model.
Exponential objects permit reasoning about entire classes of causal
equivalences and interventions. Finally, as TCMs form a topos, they admit an
internal logic defined as a Mitchell-Benabou language with an associated
Kripke-Joyal semantics. We show how to reason about causal models in TCMs using
this internal logic.

</details>


### [28] [An Efficient Application of Goal Programming to Tackle Multiobjective Problems with Recurring Fitness Landscapes](https://arxiv.org/abs/2508.08297)
*Rodrigo Lankaites Pinheiro,Dario Landa-Silva,Wasakorn Laesanklang,Ademir Aparecido Constantino*

Main category: cs.AI

TL;DR: 提出一种结合多目标算法和目标规划的方法，利用问题实例间的相似性，高效求解多目标车辆路径问题。


<details>
  <summary>Details</summary>
Motivation: 解决高度约束多目标问题中难以获得良好近似解集的挑战，利用问题实例间的相似性提高求解效率。

Method: 先用计算密集型多目标算法求解一个实例，再用目标规划和高效单目标算法求解其他相似实例。

Result: 在多目标车辆路径问题基准实例上，该方法能在短时间内产生良好结果。

Conclusion: 该方法结合多目标算法的有效性和目标规划的高效性，适用于具有相似适应度景观的问题场景。

Abstract: Many real-world applications require decision-makers to assess the quality of
solutions while considering multiple conflicting objectives. Obtaining good
approximation sets for highly constrained many-objective problems is often a
difficult task even for modern multiobjective algorithms. In some cases,
multiple instances of the problem scenario present similarities in their
fitness landscapes. That is, there are recurring features in the fitness
landscapes when searching for solutions to different problem instances. We
propose a methodology to exploit this characteristic by solving one instance of
a given problem scenario using computationally expensive multiobjective
algorithms to obtain a good approximation set and then using Goal Programming
with efficient single-objective algorithms to solve other instances of the same
problem scenario. We use three goal-based objective functions and show that on
benchmark instances of the multiobjective vehicle routing problem with time
windows, the methodology is able to produce good results in short computation
time. The methodology allows to combine the effectiveness of state-of-the-art
multiobjective algorithms with the efficiency of goal programming to find good
compromise solutions in problem scenarios where instances have similar fitness
landscapes.

</details>


### [29] [LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models](https://arxiv.org/abs/2508.08300)
*Yongchao Huang*

Main category: cs.AI

TL;DR: 论文探讨了使用大型语言模型（LLM）自动化贝叶斯推断的可行性，提出LLM-BI流程，并通过实验验证其潜力。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯推断的广泛应用受限于先验分布和似然函数的设定需要专业知识，研究旨在通过LLM自动化这一过程。

Method: 提出LLM-BI流程，通过两个实验验证LLM能否从自然语言中提取先验分布（实验I）和完整模型结构（实验II）。

Result: 实验表明LLM能成功从自然语言中提取先验分布和模型结构，验证了自动化贝叶斯建模的潜力。

Conclusion: LLM有望实现贝叶斯建模关键步骤的自动化，为概率编程提供自动化推断流程。

Abstract: A significant barrier to the widespread adoption of Bayesian inference is the
specification of prior distributions and likelihoods, which often requires
specialized statistical expertise. This paper investigates the feasibility of
using a Large Language Model (LLM) to automate this process. We introduce
LLM-BI (Large Language Model-driven Bayesian Inference), a conceptual pipeline
for automating Bayesian workflows. As a proof-of-concept, we present two
experiments focused on Bayesian linear regression. In Experiment I, we
demonstrate that an LLM can successfully elicit prior distributions from
natural language. In Experiment II, we show that an LLM can specify the entire
model structure, including both priors and the likelihood, from a single
high-level problem description. Our results validate the potential of LLMs to
automate key steps in Bayesian modeling, enabling the possibility of an
automated inference pipeline for probabilistic programming.

</details>


### [30] [First Ask Then Answer: A Framework Design for AI Dialogue Based on Supplementary Questioning with Large Language Models](https://arxiv.org/abs/2508.08308)
*Chuanruo Fu,Yuncheng Du*

Main category: cs.AI

TL;DR: 论文提出了一种名为FATA的新交互范式，通过引导LLMs主动生成多维补充问题，显著提升了回答质量和相关性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在用户信息不完整或模糊时回答不准确的问题，强调完整性和用户参与。

Method: 采用单轮策略，通过提示词引导LLMs生成补充问题，整合用户反馈后生成回答。

Result: 实验显示FATA在综合指标上优于基线提示40%，且稳定性更高。

Conclusion: FATA通过增强用户参与和完整性，显著提升了LLMs的交互效果。

Abstract: Large Language Models (LLMs) often struggle to deliver accurate and
actionable answers when user-provided information is incomplete or
ill-specified. We propose a new interaction paradigm, First Ask Then Answer
(FATA), in which, through prompt words, LLMs are guided to proactively generate
multidimensional supplementary questions for users prior to response
generation. Subsequently, by integrating user-provided supplementary
information with the original query through sophisticated prompting techniques,
we achieve substantially improved response quality and relevance. In contrast
to existing clarification approaches -- such as the CLAM framework oriented to
ambiguity and the self-interrogation Self-Ask method -- FATA emphasizes
completeness (beyond mere disambiguation) and user participation (inviting
human input instead of relying solely on model-internal reasoning). It also
adopts a single-turn strategy: all clarifying questions are produced at once,
thereby reducing dialogue length and improving efficiency. Conceptually, FATA
uses the reasoning power of LLMs to scaffold user expression, enabling
non-expert users to formulate more comprehensive and contextually relevant
queries. To evaluate FATA, we constructed a multi-domain benchmark and compared
it with two controls: a baseline prompt (B-Prompt) and a context-enhanced
expert prompt (C-Prompt). Experimental results show that FATA outperforms
B-Prompt by approximately 40% in aggregate metrics and exhibits a coefficient
of variation 8% lower than C-Prompt, indicating superior stability.

</details>


### [31] [What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge](https://arxiv.org/abs/2508.08344)
*Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Yuan He,Jiaoyan Chen,Evgeny Kharlamov,Steffen Staab*

Main category: cs.AI

TL;DR: 论文提出了一种评估KG-RAG方法的新方法，发现现有方法在知识缺失时推理能力有限，且依赖内部记忆。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法区分模型是推理还是直接检索答案，且评估指标不一致，导致难以比较。

Method: 提出了一种构建基准测试的通用方法及评估协议，系统评估KG-RAG在知识缺失下的表现。

Result: 实验表明当前KG-RAG方法在知识缺失时推理能力有限，依赖记忆，且泛化能力因设计而异。

Conclusion: 需要改进KG-RAG方法以提升其在知识缺失时的推理能力和泛化性。

Abstract: Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) is an
increasingly explored approach for combining the reasoning capabilities of
large language models with the structured evidence of knowledge graphs.
However, current evaluation practices fall short: existing benchmarks often
include questions that can be directly answered using existing triples in KG,
making it unclear whether models perform reasoning or simply retrieve answers
directly. Moreover, inconsistent evaluation metrics and lenient answer matching
criteria further obscure meaningful comparisons. In this work, we introduce a
general method for constructing benchmarks, together with an evaluation
protocol, to systematically assess KG-RAG methods under knowledge
incompleteness. Our empirical results show that current KG-RAG methods have
limited reasoning ability under missing knowledge, often rely on internal
memorization, and exhibit varying degrees of generalization depending on their
design.

</details>


### [32] [UrzaGPT: LoRA-Tuned Large Language Models for Card Selection in Collectible Card Games](https://arxiv.org/abs/2508.08382)
*Timo Bertram*

Main category: cs.AI

TL;DR: UrzaGPT是一种基于大型语言模型的AI，用于实时推荐《魔法风云会》的选牌决策，通过微调小型模型达到66.2%的准确率。


<details>
  <summary>Details</summary>
Motivation: 由于集换式卡牌游戏（CCG）的部分可观察性、长期决策和卡牌更新特性，现有AI表现远逊于人类玩家。

Method: 使用低秩适应（LoRA）对开源LLM进行微调，利用标注的选牌日志数据集。

Result: UrzaGPT在零样本LLM和领域专用模型对比中表现优异，微调后准确率达66.2%。

Conclusion: LLM可用于构建高效、通用且易于更新的选牌AI，未来潜力巨大。

Abstract: Collectible card games (CCGs) are a difficult genre for AI due to their
partial observability, long-term decision-making, and evolving card sets. Due
to this, current AI models perform vastly worse than human players at CCG tasks
such as deckbuilding and gameplay. In this work, we introduce UrzaGPT, a
domain-adapted large language model that recommends real-time drafting
decisions in Magic: The Gathering. Starting from an open-weight LLM, we use
Low-Rank Adaptation fine-tuning on a dataset of annotated draft logs. With
this, we leverage the language modeling capabilities of LLM, and can quickly
adapt to different expansions of the game. We benchmark UrzaGPT in comparison
to zero-shot LLMs and the state-of-the-art domain-specific model. Untuned,
small LLMs like Llama-3-8B are completely unable to draft, but the larger
GPT-4o achieves a zero-shot performance of 43%. Using UrzaGPT to fine-tune
smaller models, we achieve an accuracy of 66.2% using only 10,000 steps.
Despite this not reaching the capability of domain-specific models, we show
that solely using LLMs to draft is possible and conclude that using LLMs can
enable performant, general, and update-friendly drafting AIs in the future.

</details>


### [33] [Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning](https://arxiv.org/abs/2508.08385)
*Masataro Asai*

Main category: cs.AI

TL;DR: 论文提出了一种改进的MCTS方法，通过双层结构和树折叠技术优化节点选择时间，解决经典规划中搜索深度大的问题。


<details>
  <summary>Details</summary>
Motivation: 传统MCTS在经典规划中因搜索深度大导致节点选择时间显著，而游戏树搜索中此问题不显著。

Method: 提出双层MCTS，对每个选中的叶节点运行最佳优先搜索，并引入树折叠技术减少动作选择步骤。

Result: 实现了节点选择的摊销O(1)时间复杂度，性能显著提升。

Conclusion: 双层MCTS和树折叠技术有效解决了经典规划中MCTS的瓶颈问题。

Abstract: We study an efficient implementation of Multi-Armed Bandit (MAB)-based
Monte-Carlo Tree Search (MCTS) for classical planning. One weakness of MCTS is
that it spends a significant time deciding which node to expand next. While
selecting a node from an OPEN list with $N$ nodes has $O(1)$ runtime complexity
with traditional array-based priority-queues for dense integer keys, the
tree-based OPEN list used by MCTS requires $O(\log N)$, which roughly
corresponds to the search depth $d$. In classical planning, $d$ is arbitrarily
large (e.g., $2^k-1$ in $k$-disk Tower-of-Hanoi) and the runtime for node
selection is significant, unlike in game tree search, where the cost is
negligible compared to the node evaluation (rollouts) because $d$ is inherently
limited by the game (e.g., $d\leq 361$ in Go). To improve this bottleneck, we
propose a bilevel modification to MCTS that runs a best-first search from each
selected leaf node with an expansion budget proportional to $d$, which achieves
amortized $O(1)$ runtime for node selection, equivalent to the traditional
queue-based OPEN list. In addition, we introduce Tree Collapsing, an
enhancement that reduces action selection steps and further improves the
performance.

</details>


### [34] [Solver-Aided Expansion of Loops to Avoid Generate-and-Test](https://arxiv.org/abs/2508.08442)
*Niklas Dewally,Özgür Akgün*

Main category: cs.AI

TL;DR: 提出了一种避免完全枚举的方法，通过求解器仅计算生成最终约束所需的组合，显著提高了编译效率。


<details>
  <summary>Details</summary>
Motivation: 传统方法在编译时需要展开所有循环组合，效率低下，尤其是在变量范围大且选择性条件多的情况下。

Method: 使用求解器动态计算必要的组合，避免完全枚举，同时保持模型与传统方法一致。

Result: 生成的模型与传统方法相同，但编译速度显著提升，尤其适用于大范围和选择性条件的场景。

Conclusion: 该方法提高了高级用户模型到求解器形式的转换效率，优化了约束建模语言的编译过程。

Abstract: Constraint modelling languages like MiniZinc and Essence rely on unrolling
loops (in the form of quantified expressions and comprehensions) during
compilation. Standard approaches generate all combinations of induction
variables and use partial evaluation to discard those that simplify to identity
elements of associative-commutative operators (e.g. true for conjunction, 0 for
summation). This can be inefficient for problems where most combinations are
ultimately irrelevant. We present a method that avoids full enumeration by
using a solver to compute only the combinations required to generate the final
set of constraints. The resulting model is identical to that produced by
conventional flattening, but compilation can be significantly faster. This
improves the efficiency of translating high-level user models into solver-ready
form, particularly when induction variables range over large domains with
selective preconditions.

</details>


### [35] [OverFill: Two-Stage Models for Efficient Language Model Decoding](https://arxiv.org/abs/2508.08446)
*Woojeong Kim,Junxiong Wang,Jing Nathan Yan,Mohamed Abdelfattah,Alexander M. Rush*

Main category: cs.AI

TL;DR: OverFill通过解耦LLM的预填充和解码阶段，优化了准确性与效率的权衡，显著提升了生成质量并减少了延迟。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在推理阶段面临高成本问题，尤其是解码阶段对长序列的延迟影响显著。当前模型对预填充和解码阶段采用统一处理，未考虑其计算特性的差异。

Method: OverFill将预填充和解码阶段分离，预填充阶段使用完整模型并行处理输入，解码阶段切换到密集剪枝模型顺序生成令牌。

Result: 3B到1B的OverFill配置比1B剪枝模型性能提升83.2%，8B到3B配置比3B剪枝模型提升79.2%，且训练数据需求显著减少。

Conclusion: OverFill在保持性能的同时显著降低了训练和推理成本，为LLM的高效部署提供了新思路。

Abstract: Large language models (LLMs) excel across diverse tasks but face significant
deployment challenges due to high inference costs. LLM inference comprises
prefill (compute-bound) and decode (memory-bound) stages, with decode
dominating latency particularly for long sequences. Current decoder-only models
handle both stages uniformly, despite their distinct computational profiles. We
propose OverFill, which decouples these stages to optimize accuracy-efficiency
tradeoffs. OverFill begins with a full model for prefill, processing system and
user inputs in parallel. It then switches to a dense pruned model, while
generating tokens sequentially. Leveraging more compute during prefill,
OverFill improves generation quality with minimal latency overhead. Our
3B-to-1B OverFill configuration outperforms 1B pruned models by 83.2%, while
the 8B-to-3B configuration improves over 3B pruned models by 79.2% on average
across standard benchmarks. OverFill matches the performance of same-sized
models trained from scratch, while using significantly less training data. Our
code is available at https://github.com/friendshipkim/overfill.

</details>


### [36] [A Fast GRASP Metaheuristic for the Trigger Arc TSP with MIP-Based Construction and Multi-Neighborhood Local Search](https://arxiv.org/abs/2508.08477)
*Joan Salvà Soler,Grégoire de Lambertye*

Main category: cs.AI

TL;DR: 本文提出了一种基于GRASP的元启发式算法，用于解决动态弧成本的触发弧旅行商问题（TA-TSP），在60秒内实现了接近最优解的性能。


<details>
  <summary>Details</summary>
Motivation: TA-TSP扩展了经典TSP，引入了动态弧成本，适用于仓库操作等场景。现有方法难以高效处理此类问题，因此需要新的算法。

Method: 结合多种构造启发式和多邻域局部搜索的GRASP元启发式算法，构造阶段使用MIP技术，改进阶段应用2-Opt、Swap和Relocate操作。

Result: 在MESS 2024竞赛实例中，平均最优性差距为0.77%和0.40%；在合成数据集上，性能优于Gurobi求解器11.3%。

Conclusion: 该算法在实时路由应用中表现优异，适合处理状态依赖的旅行成本问题。

Abstract: The Trigger Arc Traveling Salesman Problem (TA-TSP) extends the classical TSP
by introducing dynamic arc costs that change when specific \textit{trigger}
arcs are traversed, modeling scenarios such as warehouse operations with
compactable storage systems. This paper introduces a GRASP-based metaheuristic
that combines multiple construction heuristics with a multi-neighborhood local
search. The construction phase uses mixed-integer programming (MIP) techniques
to transform the TA-TSP into a sequence of tailored TSP instances, while the
improvement phase applies 2-Opt, Swap, and Relocate operators. Computational
experiments on MESS 2024 competition instances achieved average optimality gaps
of 0.77\% and 0.40\% relative to the best-known solutions within a 60-second
limit. On smaller, synthetically generated datasets, the method produced
solutions 11.3\% better than the Gurobi solver under the same time constraints.
The algorithm finished in the top three at MESS 2024, demonstrating its
suitability for real-time routing applications with state-dependent travel
costs.

</details>


### [37] [Beyond Ordinal Preferences: Why Alignment Needs Cardinal Human Feedback](https://arxiv.org/abs/2508.08486)
*Parker Whitfill,Stewy Slocum*

Main category: cs.AI

TL;DR: 论文指出基于序数比较的LLM对齐方法存在根本性限制，无法系统性地恢复最优模型。提出通过基数反馈（如支付意愿）收集数据，实验证明其优于传统序数方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐方法依赖序数偏好数据，但这类数据无法解决模型间的权衡问题，导致无法系统性选择最优模型。

Method: 提出使用基数反馈（支付意愿）收集偏好数据，并公开了一个包含25,000条基数判断的数据集。

Result: 实验表明，基数反馈能帮助模型优先高价值改进，并在下游基准（如Arena-Hard）上优于序数方法。

Conclusion: 基数反馈是解决LLM对齐中偏好数据局限性的有效方法，能显著提升模型性能。

Abstract: Alignment techniques for LLMs rely on optimizing preference-based objectives
-- where these preferences are typically elicited as ordinal, binary choices
between responses. Recent work has focused on improving label quality or
mitigating particular biases, but we identify a more fundamental limitation:
these methods collect the wrong kind of data. We prove an impossibility result:
no algorithm relying solely on ordinal comparisons can systematically recover
the most preferred model. Intuitively, ordinal data lacks the information
needed to resolve tradeoffs -- e.g., fixing a factual error on one prompt
versus improving style on another. We show that selecting the optimal model
requires recovering preferences over \emph{models} (rather than just
responses), which can only be identified given cardinal feedback about response
quality. To address this, we collect and publicly release a dataset of 25,000
cardinal judgments using willingness-to-pay elicitations, a well-established
tool from experimental economics. Empirically, we find that incorporating
cardinal feedback into preference fine-tuning allows models to prioritize
high-impact improvements and outperform ordinal-only methods on downstream
benchmarks, such as Arena-Hard.

</details>


### [38] [POMO+: Leveraging starting nodes in POMO for solving Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2508.08493)
*Szymon Jakubicz,Karol Kuźniak,Jan Wawszczak,Paweł Gora*

Main category: cs.AI

TL;DR: 论文提出了一种改进的POMO方法（POMO+），通过更智能地利用初始节点来提升组合问题的求解效果，实验表明其收敛更快且结果更优。


<details>
  <summary>Details</summary>
Motivation: 尽管POMO在组合问题中表现优异，但仍存在改进空间，尤其是在车辆路径问题（VRP）中。

Method: 改进POMO，提出POMO+方法，通过更智能地利用初始节点来优化求解过程。

Result: 在CVRPLIB数据集上验证，POMO+在100个顾客以内的问题实例中表现更优，收敛速度更快。

Conclusion: POMO+为组合问题的求解提供了进一步改进的方向，有望推动领域发展。

Abstract: In recent years, reinforcement learning (RL) methods have emerged as a
promising approach for solving combinatorial problems. Among RL-based models,
POMO has demonstrated strong performance on a variety of tasks, including
variants of the Vehicle Routing Problem (VRP). However, there is room for
improvement for these tasks. In this work, we improved POMO, creating a method
(\textbf{POMO+}) that leverages the initial nodes to find a solution in a more
informed way. We ran experiments on our new model and observed that our
solution converges faster and achieves better results. We validated our models
on the CVRPLIB dataset and noticed improvements in problem instances with up to
100 customers. We hope that our research in this project can lead to further
advancements in the field.

</details>


### [39] [Large Language Models as Oracles for Ontology Alignment](https://arxiv.org/abs/2508.08500)
*Sviatoslav Lushnei,Dmytro Shumskyi,Severyn Shykula,Ernesto Jimenez-Ruiz,Artur d'Avila Garcez*

Main category: cs.AI

TL;DR: 探讨使用大型语言模型（LLM）替代领域专家验证本体对齐中不确定的对应关系，并通过实验评估其性能。


<details>
  <summary>Details</summary>
Motivation: 本体对齐在跨领域数据整合中至关重要，但高精度对齐仍需人工参与，成本高昂。研究LLM作为替代方案的可行性。

Method: 通过OAEI的多个匹配任务，评估不同LLM的性能，使用本体驱动的提示模板，并与模拟Oracle对比。

Result: 实验表明LLM在验证不确定对应关系时具有一定潜力，但性能受提示模板和任务复杂度影响。

Conclusion: LLM可作为本体对齐中人工验证的补充，但需进一步优化提示设计和模型选择。

Abstract: Ontology alignment plays a crucial role in integrating diverse data sources
across domains. There is a large plethora of systems that tackle the ontology
alignment problem, yet challenges persist in producing highly quality
correspondences among a set of input ontologies. Human-in-the-loop during the
alignment process is essential in applications requiring very accurate
mappings. User involvement is, however, expensive when dealing with large
ontologies. In this paper, we explore the feasibility of using Large Language
Models (LLM) as an alternative to the domain expert. The use of the LLM focuses
only on the validation of the subset of correspondences where an ontology
alignment system is very uncertain. We have conducted an extensive evaluation
over several matching tasks of the Ontology Alignment Evaluation Initiative
(OAEI), analysing the performance of several state-of-the-art LLMs using
different ontology-driven prompt templates. The LLM results are also compared
against simulated Oracles with variable error rates.

</details>


### [40] [GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games](https://arxiv.org/abs/2508.08501)
*Yuchen Li,Cong Lin,Muhammad Umair Nasir,Philip Bontrager,Jialin Liu,Julian Togelius*

Main category: cs.AI

TL;DR: GVGAI-LLM是一个基于视频游戏的基准测试，用于评估大型语言模型（LLMs）的推理和问题解决能力，揭示了其在空间推理和基础规划方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准测试大多缺乏对空间推理和规划能力的评估，GVGAI-LLM旨在填补这一空白，并提供多样化的游戏任务。

Method: 基于General Video Game AI框架，使用游戏描述语言快速生成新游戏和关卡，通过ASCII字符表示游戏场景，定义可解释的评估指标（如步骤效率、总体得分）。

Result: 零样本评估显示LLMs在空间推理和基础规划方面存在持续缺陷，结构化提示和空间接地技术仅带来部分改进。

Conclusion: GVGAI-LLM为语言模型能力研究提供了可重复的测试平台，重点关注代理行为和上下文推理。

Abstract: We introduce GVGAI-LLM, a video game benchmark for evaluating the reasoning
and problem-solving capabilities of large language models (LLMs). Built on the
General Video Game AI framework, it features a diverse collection of
arcade-style games designed to test a model's ability to handle tasks that
differ from most existing LLM benchmarks. The benchmark leverages a game
description language that enables rapid creation of new games and levels,
helping to prevent overfitting over time. Each game scene is represented by a
compact set of ASCII characters, allowing for efficient processing by language
models. GVGAI-LLM defines interpretable metrics, including the meaningful step
ratio, step efficiency, and overall score, to assess model behavior. Through
zero-shot evaluations across a broad set of games and levels with diverse
challenges and skill depth, we reveal persistent limitations of LLMs in spatial
reasoning and basic planning. Current models consistently exhibit spatial and
logical errors, motivating structured prompting and spatial grounding
techniques. While these interventions lead to partial improvements, the
benchmark remains very far from solved. GVGAI-LLM provides a reproducible
testbed for advancing research on language model capabilities, with a
particular emphasis on agentic behavior and contextual reasoning.

</details>


### [41] [SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering](https://arxiv.org/abs/2508.08529)
*Arshia Ilaty,Hossein Shirazi,Hajar Homayouni*

Main category: cs.AI

TL;DR: SynLLM是一个模块化框架，利用20种开源LLM生成高质量合成医疗数据，通过结构化提示和全面评估框架解决隐私与数据质量问题。


<details>
  <summary>Details</summary>
Motivation: 真实医疗数据因隐私法规受限，合成数据是替代方案，但现有方法缺乏系统性提示策略和全面评估。

Method: SynLLM使用四种提示类型（如示例驱动和规则约束）指导LLM生成数据，无需微调，并通过多维度评估框架验证数据质量。

Result: 在三个医疗数据集上测试表明，规则提示在隐私与质量间取得最佳平衡，LLM能生成临床合理且隐私安全的合成数据。

Conclusion: SynLLM证明LLM在合理提示和评估下可生成高质量合成医疗数据，推动医疗研究数据共享。

Abstract: Access to real-world medical data is often restricted due to privacy
regulations, posing a significant barrier to the advancement of healthcare
research. Synthetic data offers a promising alternative; however, generating
realistic, clinically valid, and privacy-conscious records remains a major
challenge. Recent advancements in Large Language Models (LLMs) offer new
opportunities for structured data generation; however, existing approaches
frequently lack systematic prompting strategies and comprehensive,
multi-dimensional evaluation frameworks.
  In this paper, we present SynLLM, a modular framework for generating
high-quality synthetic medical tabular data using 20 state-of-the-art
open-source LLMs, including LLaMA, Mistral, and GPT variants, guided by
structured prompts. We propose four distinct prompt types, ranging from
example-driven to rule-based constraints, that encode schema, metadata, and
domain knowledge to control generation without model fine-tuning. Our framework
features a comprehensive evaluation pipeline that rigorously assesses generated
data across statistical fidelity, clinical consistency, and privacy
preservation.
  We evaluate SynLLM across three public medical datasets, including Diabetes,
Cirrhosis, and Stroke, using 20 open-source LLMs. Our results show that prompt
engineering significantly impacts data quality and privacy risk, with
rule-based prompts achieving the best privacy-quality balance. SynLLM
establishes that, when guided by well-designed prompts and evaluated with
robust, multi-metric criteria, LLMs can generate synthetic medical data that is
both clinically plausible and privacy-aware, paving the way for safer and more
effective data sharing in healthcare research.

</details>


### [42] [UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss](https://arxiv.org/abs/2508.08615)
*Zhichao Wang,Xinhai Chen,Qinglin Wang,Xiang Gao,Qingyang Zhang,Menghan Jia,Xiang Zhang,Jie Liu*

Main category: cs.AI

TL;DR: 提出了一种无监督且通用的网格移动网络（UGM2N），通过局部几何特征学习和物理约束损失函数，实现了高效、通用的网格自适应。


<details>
  <summary>Details</summary>
Motivation: 传统网格移动方法计算复杂度高且几何灵活性不足，而现有监督学习方法难以实现零样本泛化。

Method: 引入无监督网格自适应和物理约束损失函数（M-Uniform loss），实现网格节点的动态调整。

Result: 实验表明，UGM2N在多种PDE和网格拓扑中表现优越，具有高效性和通用性。

Conclusion: UGM2N在网格自适应中实现了方程无关的泛化和几何独立性，优于现有方法。

Abstract: Partial differential equations (PDEs) form the mathematical foundation for
modeling physical systems in science and engineering, where numerical solutions
demand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address
this challenge by dynamically relocating mesh nodes to rapidly-varying regions,
enhancing both simulation accuracy and computational efficiency. However,
traditional approaches suffer from high computational complexity and geometric
inflexibility, limiting their applicability, and existing supervised
learning-based approaches face challenges in zero-shot generalization across
diverse PDEs and mesh topologies.In this paper, we present an Unsupervised and
Generalizable Mesh Movement Network (UGM2N). We first introduce unsupervised
mesh adaptation through localized geometric feature learning, eliminating the
dependency on pre-adapted meshes. We then develop a physics-constrained loss
function, M-Uniform loss, that enforces mesh equidistribution at the nodal
level.Experimental results demonstrate that the proposed network exhibits
equation-agnostic generalization and geometric independence in efficient mesh
adaptation. It demonstrates consistent superiority over existing methods,
including robust performance across diverse PDEs and mesh geometries,
scalability to multi-scale resolutions and guaranteed error reduction without
mesh tangling.

</details>


### [43] [AgriGPT: a Large Language Model Ecosystem for Agriculture](https://arxiv.org/abs/2508.08632)
*Bo Yang,Yu Zhang,Lanfei Feng,Yunkui Chen,Jianyu Zhang,Xiao Xu,Nueraili Aierken,Yurui Li,Yuxuan Chen,Guijun Yang,Yong He,Runhe Huang,Shijian Li*

Main category: cs.AI

TL;DR: AgriGPT是一个专为农业设计的LLM生态系统，通过多代理数据引擎构建高质量数据集Agri-342K，并采用Tri-RAG框架提升推理可靠性，显著优于通用LLM。


<details>
  <summary>Details</summary>
Motivation: 解决农业领域缺乏专业LLM、高质量数据集和评估框架的问题。

Method: 设计多代理数据引擎构建Agri-342K数据集，采用Tri-RAG框架（密集检索、稀疏检索和多跳知识图谱推理）增强推理。

Result: AgriGPT在领域适应和推理任务上显著优于通用LLM。

Conclusion: AgriGPT为农业提供了一个模块化、可扩展的LLM生态系统，并为其他科学和行业专用LLM开发提供了通用框架。

Abstract: Despite the rapid progress of Large Language Models (LLMs), their application
in agriculture remains limited due to the lack of domain-specific models,
curated datasets, and robust evaluation frameworks. To address these
challenges, we propose AgriGPT, a domain-specialized LLM ecosystem for
agricultural usage. At its core, we design a multi-agent scalable data engine
that systematically compiles credible data sources into Agri-342K, a
high-quality, standardized question-answer (QA) dataset. Trained on this
dataset, AgriGPT supports a broad range of agricultural stakeholders, from
practitioners to policy-makers. To enhance factual grounding, we employ
Tri-RAG, a three-channel Retrieval-Augmented Generation framework combining
dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning,
thereby improving the LLM's reasoning reliability. For comprehensive
evaluation, we introduce AgriBench-13K, a benchmark suite comprising 13 tasks
with varying types and complexities. Experiments demonstrate that AgriGPT
significantly outperforms general-purpose LLMs on both domain adaptation and
reasoning. Beyond the model itself, AgriGPT represents a modular and extensible
LLM ecosystem for agriculture, comprising structured data construction,
retrieval-enhanced generation, and domain-specific evaluation. This work
provides a generalizable framework for developing scientific and
industry-specialized LLMs. All models, datasets, and code will be released to
empower agricultural communities, especially in underserved regions, and to
promote open, impactful research.

</details>


### [44] [Diminution: On Reducing the Size of Grounding ASP Programs](https://arxiv.org/abs/2508.08633)
*HuanYu Yang,Fengming Zhu,YangFan Wu,Jianmin Ji*

Main category: cs.AI

TL;DR: 该论文提出了一种称为“diminution”的方法，通过选择Herbrand宇宙的子集来减少ASP中的基础程序规模，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: ASP常因基础程序规模过大而遇到性能瓶颈，现有方法多依赖临时启发式策略，缺乏通用性。

Method: 提出diminution概念，定义其形式化属性，并通过特定编码利用现有ASP求解器评估候选子集。

Result: 在五个基准测试中，该方法平均减少70%的基础时间，基础文件大小减少85%。

Conclusion: diminution是一种通用且有效的方法，可显著缓解ASP中的基础瓶颈。

Abstract: Answer Set Programming (ASP) is often hindered by the grounding bottleneck:
large Herbrand universes generate ground programs so large that solving becomes
difficult. Many methods employ ad-hoc heuristics to improve grounding
performance, motivating the need for a more formal and generalizable strategy.
We introduce the notion of diminution, defined as a selected subset of the
Herbrand universe used to generate a reduced ground program before solving. We
give a formal definition of diminution, analyze its key properties, and study
the complexity of identifying it. We use a specific encoding that enables
off-the-shelf ASP solver to evaluate candidate subsets. Our approach integrates
seamlessly with existing grounders via domain predicates. In extensive
experiments on five benchmarks, applying diminutions selected by our strategy
yields significant performance improvements, reducing grounding time by up to
70% on average and decreasing the size of grounding files by up to 85%. These
results demonstrate that leveraging diminutions constitutes a robust and
general-purpose approach for alleviating the grounding bottleneck in ASP.

</details>


### [45] [P-CAFE: Personalized Cost-Aware Incremental Feature Selection For Electronic Health Records](https://arxiv.org/abs/2508.08646)
*Naama Kashani,Mira Cohen,Uri Shaham*

Main category: cs.AI

TL;DR: 提出了一种针对电子健康记录（EHR）数据的个性化、在线且成本感知的特征选择框架，旨在解决传统方法在处理稀疏和异构数据时的不足。


<details>
  <summary>Details</summary>
Motivation: EHR数据复杂且多模态，传统特征选择方法难以应对其稀疏性和异质性，尤其是在考虑患者个体差异和特征成本时。

Method: 开发了一种在线获取特征的新框架，结合预算约束和特征可变性成本，为个体患者定制特征选择。

Result: 该框架能有效管理稀疏和多模态数据，在多样化医疗场景中表现出稳健且可扩展的性能。

Conclusion: 该方法支持医生在患者筛查中逐步获取最具信息量的特征，提升诊断信心并优化资源利用。

Abstract: Electronic Health Records (EHR) have revolutionized healthcare by digitizing
patient data, improving accessibility, and streamlining clinical workflows.
However, extracting meaningful insights from these complex and multimodal
datasets remains a significant challenge for researchers. Traditional feature
selection methods often struggle with the inherent sparsity and heterogeneity
of EHR data, especially when accounting for patient-specific variations and
feature costs in clinical applications. To address these challenges, we propose
a novel personalized, online and cost-aware feature selection framework
tailored specifically for EHR datasets. The features are aquired in an online
fashion for individual patients, incorporating budgetary constraints and
feature variability costs. The framework is designed to effectively manage
sparse and multimodal data, ensuring robust and scalable performance in diverse
healthcare contexts. A primary application of our proposed method is to support
physicians' decision making in patient screening scenarios. By guiding
physicians toward incremental acquisition of the most informative features
within budget constraints, our approach aims to increase diagnostic confidence
while optimizing resource utilization.

</details>


### [46] [Prompt-and-Check: Using Large Language Models to Evaluate Communication Protocol Compliance in Simulation-Based Training](https://arxiv.org/abs/2508.08652)
*Vishakha Lall,Yisi Liu*

Main category: cs.AI

TL;DR: 本文提出了一种基于提示推理的轻量级方法（Prompt-and-Check），利用开源大语言模型（LLMs）评估程序性通信合规性，适用于安全关键领域的模拟训练。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域，程序性通信合规性的准确评估对模拟训练至关重要，但传统方法可能成本高或效率低。

Method: 使用上下文丰富的提示，结合开源LLMs（如LLaMA 2 7B、LLaMA 3 8B和Mistral 7B），基于转录的语音交换评估协议清单的合规性。

Result: 实验表明，提示方法能有效实现上下文感知推理，无需任务特定训练，且模型输出与专家标注的真实数据具有较高一致性。

Conclusion: LLMs在增强训练环境中的反馈、评估和自动化方面具有实际应用潜力。

Abstract: Accurate evaluation of procedural communication compliance is essential in
simulation-based training, particularly in safety-critical domains where
adherence to compliance checklists reflects operational competence. This paper
explores a lightweight, deployable approach using prompt-based inference with
open-source large language models (LLMs) that can run efficiently on
consumer-grade GPUs. We present Prompt-and-Check, a method that uses
context-rich prompts to evaluate whether each checklist item in a protocol has
been fulfilled, solely based on transcribed verbal exchanges. We perform a case
study in the maritime domain with participants performing an identical
simulation task, and experiment with models such as LLama 2 7B, LLaMA 3 8B and
Mistral 7B, running locally on an RTX 4070 GPU. For each checklist item, a
prompt incorporating relevant transcript excerpts is fed into the model, which
outputs a compliance judgment. We assess model outputs against expert-annotated
ground truth using classification accuracy and agreement scores. Our findings
demonstrate that prompting enables effective context-aware reasoning without
task-specific training. This study highlights the practical utility of LLMs in
augmenting debriefing, performance feedback, and automated assessment in
training environments.

</details>


### [47] [Hybrid Node-Destroyer Model with Large Neighborhood Search for Solving the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2508.08659)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux,Daniele Vigo*

Main category: cs.AI

TL;DR: 提出了一种结合机器学习的混合优化求解器，用于提升元启发式算法在CVRP问题中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有元启发式算法在解决CVRP问题时性能有限，需通过机器学习方法优化节点选择和搜索空间。

Method: 结合Node-Destroyer模型（基于GNN）和LNS算子，利用图结构信息指导节点移除策略。

Result: 在标准CVRP基准测试中提升了解质量，并验证了在3万节点大规模实例中的可扩展性。

Conclusion: 该混合机制显著提升了元启发式算法的性能，且无需针对不同规模问题重新训练。

Abstract: In this research, we propose an iterative learning hybrid optimization solver
developed to strengthen the performance of metaheuristic algorithms in solving
the Capacitated Vehicle Routing Problem (CVRP). The iterative hybrid mechanism
integrates the proposed Node-Destroyer Model, a machine learning hybrid model
that utilized Graph Neural Networks (GNNs) such identifies and selects customer
nodes to guide the Large Neighborhood Search (LNS) operator within the
metaheuristic optimization frameworks. This model leverages the structural
properties of the problem and solution that can be represented as a graph, to
guide strategic selections concerning node removal. The proposed approach
reduces operational complexity and scales down the search space involved in the
optimization process. The hybrid approach is applied specifically to the CVRP
and does not require retraining across problem instances of different sizes.
The proposed hybrid mechanism is able to improve the performance of baseline
metaheuristic algorithms. Our approach not only enhances the solution quality
for standard CVRP benchmarks but also proves scalability on very large-scale
instances with up to 30,000 customer nodes. Experimental evaluations on
benchmark datasets show that the proposed hybrid mechanism is capable of
improving different baseline algorithms, achieving better quality of solutions
under similar settings.

</details>


### [48] [Aryabhata: An exam-focused language model for JEE Math](https://arxiv.org/abs/2508.08665)
*Ritvik Rastogi,Sachin Dharashivkar,Sandeep Varma*

Main category: cs.AI

TL;DR: Aryabhata 1.0是一个7B参数的数学推理模型，专为印度JEE考试优化，通过融合开源模型、监督微调和强化学习提升性能，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在教育领域的适用性有限，Aryabhata 1.0旨在为印度学术考试提供高效、准确的数学推理支持。

Method: 模型通过融合开源推理模型，使用监督微调（SFT）和强化学习（RLVR）优化，并结合新颖的探索策略如自适应组大小调整和温度缩放。

Result: Aryabhata在JEE Main 2025和其他基准测试（如MATH、GSM8K）中表现优于现有模型，并提供教学有用的逐步推理。

Conclusion: Aryabhata 1.0作为开源小语言模型的基础模型发布，旨在推动考试中心化的小型语言模型发展，并计划进一步优化以提升学生学习效果。

Abstract: We present Aryabhata 1.0, a compact 7B parameter math reasoning model
optimized for the Indian academic exam, the Joint Entrance Examination (JEE).
Despite rapid progress in large language models (LLMs), current models often
remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong
open-weight reasoning models, followed by supervised fine-tuning (SFT) with
curriculum learning on verified chain-of-thought (CoT) traces curated through
best-of-$n$ rejection sampling. To further boost performance, we apply
reinforcement learning with verifiable rewards (RLVR) using A2C objective with
group-relative advantage estimation along with novel exploration strategies
such as Adaptive Group Resizing and Temperature Scaling. Evaluated on both
in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K)
benchmarks, Aryabhata outperforms existing models in accuracy and efficiency,
while offering pedagogically useful step-by-step reasoning. We release
Aryabhata as a foundation model to advance exam-centric, open-source small
language models. This marks our first open release for community feedback
(https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0); PW is actively training
future models to further improve learning outcomes for students.

</details>


### [49] [STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision](https://arxiv.org/abs/2508.08688)
*Chen Li,Han Zhang,Zhantao Yang,Fangyi Chen,Zihan Wang,Anudeepsekhar Bolimera,Marios Savvides*

Main category: cs.AI

TL;DR: STELAR-Vision框架通过拓扑感知推理和Frugal Learning技术，显著提升了视觉语言模型在复杂多模态任务中的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型依赖链式推理（CoT），难以处理复杂任务且输出冗长，需要更灵活的拓扑结构支持。

Method: 提出STELAR-Vision框架，包括TopoAug数据增强管道，结合监督微调和强化学习，优化模型推理拓扑和输出效率。

Result: 在MATH-V和VLM-S2H上，准确率提升9.7%；在OOD基准测试中，表现优于其他模型，最高提升28.4%。

Conclusion: STELAR-Vision通过拓扑感知推理和高效学习策略，显著提升模型性能，具有强泛化能力。

Abstract: Vision-language models (VLMs) have made significant strides in reasoning, yet
they often struggle with complex multimodal tasks and tend to generate overly
verbose outputs. A key limitation is their reliance on chain-of-thought (CoT)
reasoning, despite many tasks benefiting from alternative topologies like trees
or graphs. To address this, we introduce STELAR-Vision, a training framework
for topology-aware reasoning. At its core is TopoAug, a synthetic data pipeline
that enriches training with diverse topological structures. Using supervised
fine-tuning and reinforcement learning, we post-train Qwen2VL models with both
accuracy and efficiency in mind. Additionally, we propose Frugal Learning,
which reduces output length with minimal accuracy loss. On MATH-V and VLM-S2H,
STELAR-Vision improves accuracy by 9.7% over its base model and surpasses the
larger Qwen2VL-72B-Instruct by 7.3%. On five out-of-distribution benchmarks, it
outperforms Phi-4-Multimodal-Instruct by up to 28.4% and
LLaMA-3.2-11B-Vision-Instruct by up to 13.2%, demonstrating strong
generalization. Compared to Chain-Only training, our approach achieves 4.3%
higher overall accuracy on in-distribution datasets and consistently
outperforms across all OOD benchmarks. We have released datasets, and code will
be available.

</details>


### [50] [Simulating Generative Social Agents via Theory-Informed Workflow Design](https://arxiv.org/abs/2508.08726)
*Yuwei Yan,Jinghua Piao,Xiaochong Lan,Chenyang Shao,Pan Hui,Yong Li*

Main category: cs.AI

TL;DR: 论文提出了一种基于社会认知理论的统一框架，用于设计LLM社交代理，包含动机、行动规划和学习模块，显著提升了行为的真实性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有社交代理多为场景定制，缺乏通用框架，限制了其在不同社交环境中的泛化能力和行为一致性。

Method: 基于社会认知理论，提出包含动机、行动规划和学习三个模块的系统化设计框架。

Result: 实验表明，该框架代理在复杂条件下能重现真实人类行为模式，行为偏差比传统基线低75%，模块消融研究证实各模块的独立贡献。

Conclusion: 理论驱动的框架显著提升了LLM社交代理的行为真实性和适应性，为通用社交代理设计提供了系统化方法。

Abstract: Recent advances in large language models have demonstrated strong reasoning
and role-playing capabilities, opening new opportunities for agent-based social
simulations. However, most existing agents' implementations are
scenario-tailored, without a unified framework to guide the design. This lack
of a general social agent limits their ability to generalize across different
social contexts and to produce consistent, realistic behaviors. To address this
challenge, we propose a theory-informed framework that provides a systematic
design process for LLM-based social agents. Our framework is grounded in
principles from Social Cognition Theory and introduces three key modules:
motivation, action planning, and learning. These modules jointly enable agents
to reason about their goals, plan coherent actions, and adapt their behavior
over time, leading to more flexible and contextually appropriate responses.
Comprehensive experiments demonstrate that our theory-driven agents reproduce
realistic human behavior patterns under complex conditions, achieving up to 75%
lower deviation from real-world behavioral data across multiple fidelity
metrics compared to classical generative baselines. Ablation studies further
show that removing motivation, planning, or learning modules increases errors
by 1.5 to 3.2 times, confirming their distinct and essential contributions to
generating realistic and coherent social behaviors.

</details>


### [51] [Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance](https://arxiv.org/abs/2508.08774)
*Dongwook Choi,Taeyoon Kwon,Dongil Yang,Hyojun Kim,Jinyoung Yeo*

Main category: cs.AI

TL;DR: 提出了一种基于记忆增强的AR代理框架，以解决当前AR系统在复杂多步骤场景中的局限性，通过学习和适应用户长期经验提供个性化任务辅助。


<details>
  <summary>Details</summary>
Motivation: 当前AR代理在复杂多步骤场景中表现不佳，因其无法捕捉和利用用户的长期交互历史。本文旨在通过记忆增强框架提升AR系统的智能化和个性化能力。

Method: 提出包含四个模块的框架：感知模块（多模态传感器处理）、记忆模块（时空经验存储）、时空推理模块（上下文合成）和执行模块（AR通信）。

Result: 框架展示了在多样化领域中的实际应用潜力，并提供了实现路线图和评估策略。

Conclusion: 该工作为未来研究智能AR系统提供了方向，旨在通过结合用户交互历史实现更自适应的任务辅助。

Abstract: Augmented Reality (AR) systems are increasingly integrating foundation
models, such as Multimodal Large Language Models (MLLMs), to provide more
context-aware and adaptive user experiences. This integration has led to the
development of AR agents to support intelligent, goal-directed interactions in
real-world environments. While current AR agents effectively support immediate
tasks, they struggle with complex multi-step scenarios that require
understanding and leveraging user's long-term experiences and preferences. This
limitation stems from their inability to capture, retain, and reason over
historical user interactions in spatiotemporal contexts. To address these
challenges, we propose a conceptual framework for memory-augmented AR agents
that can provide personalized task assistance by learning from and adapting to
user-specific experiences over time. Our framework consists of four
interconnected modules: (1) Perception Module for multimodal sensor processing,
(2) Memory Module for persistent spatiotemporal experience storage, (3)
Spatiotemporal Reasoning Module for synthesizing past and present contexts, and
(4) Actuator Module for effective AR communication. We further present an
implementation roadmap, a future evaluation strategy, a potential target
application and use cases to demonstrate the practical applicability of our
framework across diverse domains. We aim for this work to motivate future
research toward developing more intelligent AR systems that can effectively
bridge user's interaction history with adaptive, context-aware task assistance.

</details>


### [52] [A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions](https://arxiv.org/abs/2508.08795)
*Amir Mohammad Salehoof,Ali Ramezani,Yadollah Yaghoobzadeh,Majid Nili Ahmadabadi*

Main category: cs.AI

TL;DR: 该论文提出了一种基于功能的知识编辑分类法，补充现有机制导向的研究，探讨不同编辑方法对不同类型知识（如事实、时间、概念等）的适用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的知识可能过时或不准确，而重新训练成本高昂。知识编辑提供了一种高效替代方案，但现有研究多关注编辑机制，忽视了知识的功能特性。

Method: 引入功能导向的分类法，结合知识类型（事实、时间、概念等）和编辑机制，系统分析现有方法的适用性和局限性。

Result: 通过功能分类法，揭示了编辑效果与知识类型的紧密关联，并总结了现有方法的优缺点。

Conclusion: 论文为知识编辑领域提供了更全面的视角，指出了未来研究方向，如优化编辑方法以适应不同知识类型。

Abstract: Large language models (LLMs) acquire vast knowledge from large text corpora,
but this information can become outdated or inaccurate. Since retraining is
computationally expensive, knowledge editing offers an efficient alternative --
modifying internal knowledge without full retraining. These methods aim to
update facts precisely while preserving the model's overall capabilities. While
existing surveys focus on the mechanism of editing (e.g., parameter changes vs.
external memory), they often overlook the function of the knowledge being
edited. This survey introduces a novel, complementary function-based taxonomy
to provide a more holistic view. We examine how different mechanisms apply to
various knowledge types -- factual, temporal, conceptual, commonsense, and
social -- highlighting how editing effectiveness depends on the nature of the
target knowledge. By organizing our review along these two axes, we map the
current landscape, outline the strengths and limitations of existing methods,
define the problem formally, survey evaluation tasks and datasets, and conclude
with open challenges and future directions.

</details>


### [53] [GRainsaCK: a Comprehensive Software Library for Benchmarking Explanations of Link Prediction Tasks on Knowledge Graphs](https://arxiv.org/abs/2508.08815)
*Roberto Barile,Claudia d'Amato,Nicola Fanizzi*

Main category: cs.AI

TL;DR: GRainsaCK是一个可复用的软件资源，用于标准化和简化知识图谱链接预测中解释方法的评估和比较。


<details>
  <summary>Details</summary>
Motivation: 知识图谱通常不完整，而现有的链接预测方法缺乏可解释性，且缺乏统一的评估标准和资源。

Method: 提出GRainsaCK，一个模块化、可扩展的软件资源，支持从模型训练到解释评估的全流程标准化。

Result: GRainsaCK实现了统一的评估协议，并提供了详细的文档和教程。

Conclusion: GRainsaCK填补了知识图谱解释方法评估的空白，促进了该领域的研究和应用。

Abstract: Since Knowledge Graphs are often incomplete, link prediction methods are
adopted for predicting missing facts. Scalable embedding based solutions are
mostly adopted for this purpose, however, they lack comprehensibility, which
may be crucial in several domains. Explanation methods tackle this issue by
identifying supporting knowledge explaining the predicted facts. Regretfully,
evaluating/comparing quantitatively the resulting explanations is challenging
as there is no standard evaluation protocol and overall benchmarking resource.
We fill this important gap by proposing GRainsaCK, a reusable software resource
that fully streamlines all the tasks involved in benchmarking explanations,
i.e., from model training to evaluation of explanations along the same
evaluation protocol. Moreover, GRainsaCK furthers modularity/extensibility by
implementing the main components as functions that can be easily replaced.
Finally, fostering its reuse, we provide extensive documentation including a
tutorial.

</details>


### [54] [Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval Augmented Generation](https://arxiv.org/abs/2508.08816)
*Yuechen Wang,Yuming Qiao,Dan Meng,Jun Yang,Haonan Lu,Zhenyu Yang,Xudong Zhang*

Main category: cs.AI

TL;DR: 论文提出E-Agent框架，通过动态规划多模态工具和任务执行优化mRAG工作流，显著提升性能并减少冗余搜索。


<details>
  <summary>Details</summary>
Motivation: 解决现有mRAG方法在动态规划和视觉信息利用上的不足，适应实时场景需求。

Method: 提出E-Agent框架，包含动态规划的多模态工具协调器（mRAG planner）和任务执行器（task executor），采用一次性规划策略。

Result: 在RemPlan基准测试中，E-Agent比现有方法准确率提升13%，冗余搜索减少37%。

Conclusion: E-Agent通过动态规划和优化执行策略，显著提升了mRAG系统的效率和实用性。

Abstract: Multimodal Retrieval-Augmented Generation (mRAG) has emerged as a promising
solution to address the temporal limitations of Multimodal Large Language
Models (MLLMs) in real-world scenarios like news analysis and trending topics.
However, existing approaches often suffer from rigid retrieval strategies and
under-utilization of visual information. To bridge this gap, we propose
E-Agent, an agent framework featuring two key innovations: a mRAG planner
trained to dynamically orchestrate multimodal tools based on contextual
reasoning, and a task executor employing tool-aware execution sequencing to
implement optimized mRAG workflows. E-Agent adopts a one-time mRAG planning
strategy that enables efficient information retrieval while minimizing
redundant tool invocations. To rigorously assess the planning capabilities of
mRAG systems, we introduce the Real-World mRAG Planning (RemPlan) benchmark.
This novel benchmark contains both retrieval-dependent and
retrieval-independent question types, systematically annotated with essential
retrieval tools required for each instance. The benchmark's explicit mRAG
planning annotations and diverse question design enhance its practical
relevance by simulating real-world scenarios requiring dynamic mRAG decisions.
Experiments across RemPlan and three established benchmarks demonstrate
E-Agent's superiority: 13% accuracy gain over state-of-the-art mRAG methods
while reducing redundant searches by 37%.

</details>


### [55] [Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition](https://arxiv.org/abs/2508.08830)
*Mustafa Akben,Vinayaka Gude,Haya Ajjan*

Main category: cs.AI

TL;DR: MLLMs在情感识别任务中表现优于人类个体，但人类集体智慧优于MLLMs，人机协作表现最佳。


<details>
  <summary>Details</summary>
Motivation: 探索AI（尤其是MLLMs）在情感识别任务中的能力，并与人类表现对比，以推动情感智能AI的发展。

Method: 使用RMET和MRMET测试MLLMs和人类的情感识别能力，比较个体和集体表现，并尝试人机协作。

Result: MLLMs个体表现优于人类，但人类集体智慧更强；人机协作表现最佳。

Conclusion: MLLMs在个体层面表现优异，但人类集体智慧和人机协作是情感智能AI的未来方向。

Abstract: The ability to discern subtle emotional cues is fundamental to human social
intelligence. As artificial intelligence (AI) becomes increasingly common, AI's
ability to recognize and respond to human emotions is crucial for effective
human-AI interactions. In particular, whether such systems can match or surpass
human experts remains to be seen. However, the emotional intelligence of AI,
particularly multimodal large language models (MLLMs), remains largely
unexplored. This study evaluates the emotion recognition abilities of MLLMs
using the Reading the Mind in the Eyes Test (RMET) and its multiracial
counterpart (MRMET), and compares their performance against human participants.
Results show that, on average, MLLMs outperform humans in accurately
identifying emotions across both tests. This trend persists even when comparing
performance across low, medium, and expert-level performing groups. Yet when we
aggregate independent human decisions to simulate collective intelligence,
human groups significantly surpass the performance of aggregated MLLM
predictions, highlighting the wisdom of the crowd. Moreover, a collaborative
approach (augmented intelligence) that combines human and MLLM predictions
achieves greater accuracy than either humans or MLLMs alone. These results
suggest that while MLLMs exhibit strong emotion recognition at the individual
level, the collective intelligence of humans and the synergistic potential of
human-AI collaboration offer the most promising path toward effective emotional
AI. We discuss the implications of these findings for the development of
emotionally intelligent AI systems and future research directions.

</details>


### [56] [Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation](https://arxiv.org/abs/2508.08882)
*Dayu Wang,Jiaye Yang,Weikang Li,Jiahui Liang,Yang Li*

Main category: cs.AI

TL;DR: 论文提出了一种双代理混合框架，通过分离推理和代码生成任务，减少认知干扰，提升数学推理系统的性能。


<details>
  <summary>Details</summary>
Motivation: 当前单代理数学推理系统在推理和代码生成之间切换时会产生认知负荷干扰，导致推理路径正确率下降。

Method: 采用双代理框架：推理代理负责问题分解，代码代理负责代码生成与执行。训练结合模仿学习和强化学习。

Result: 双代理框架显著减少了认知干扰，提升了推理与代码生成的协调稳定性。

Conclusion: 分离推理与代码生成任务的双代理设计能有效提升数学推理系统的性能。

Abstract: Current tool-integrated mathematical reasoning systems often adopt a
single-agent paradigm, where one large language model handles problem
reasoning, code generation, and code execution in an integrated workflow. While
this design eases coordination, we hypothesize that it imposes cognitive load
interference, as the agent must interleave long-horizon reasoning with precise
program synthesis. We validate this hypothesis through a controlled comparison
between a reasoning-only agent and a reasoning-plus-code agent, finding that
the latter produces significantly fewer correct reasoning paths despite having
tool-calling capabilities. To address this, we propose a dual-agent hybrid
framework: a Reasoning Agent performs stepwise problem decomposition, and a
Code Agent handles code generation and execution. Training combines imitation
learning and reinforcement learning: the Code Agent receives strong rewards for
matching intermediate ground-truth programs and weaker rewards for valid
execution, while the Reasoning Agent is optimized chiefly via final-answer
accuracy using advantage estimation to credit intermediate steps. This
decoupled role design reduces cognitive interference and promotes stable
reasoning-coding coordination.

</details>


### [57] [Compass-Thinker-7B Technical Report](https://arxiv.org/abs/2508.08909)
*Anxiang Zeng,Haibo Zhang,Kaixiang Mo,Long Zhang,Shuman Liu,Yanhui Huang,Yawen Liu,Yuepeng Sheng,Yuwei Huang*

Main category: cs.AI

TL;DR: Compass-Thinker-7B模型通过强化学习探索低成本、高效率的推理能力，在数学问题上表现优异。


<details>
  <summary>Details</summary>
Motivation: 大规模模型直接进行强化学习实验成本高、风险大，需探索更经济的替代方案。

Method: 基于开源模型设计强化学习流程，使用3万道可验证数学题数据集，分阶段配置数据与训练设置。

Result: Compass-Thinker-7B在数学推理上表现卓越，AIME2024评测中达到40%准确率。

Conclusion: 该模型为大规模模型的强化学习研究提供了低成本、高效率的参考方案。

Abstract: Recent R1-Zero-like research further demonstrates that reasoning extension
has given large language models (LLMs) unprecedented reasoning capabilities,
and Reinforcement Learning is the core technology to elicit its complex
reasoning. However, conducting RL experiments directly on hyperscale models
involves high computational costs and resource demands, posing significant
risks. We propose the Compass-Thinker-7B model, which aims to explore the
potential of Reinforcement Learning with less computational resources and
costs, and provides insights for further research into RL recipes for larger
models. Compass-Thinker-7B is trained from an open source model through a
specially designed Reinforcement Learning Pipeline. we curate a dataset of 30k
verifiable mathematics problems for the Reinforcement Learning Pipeline. By
configuring data and training settings with different difficulty distributions
for different stages, the potential of the model is gradually released and the
training efficiency is improved. Extensive evaluations show that
Compass-Thinker-7B possesses exceptional reasoning potential, and achieves
superior performance on mathematics compared to the same-sized RL
model.Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B
achieves 40% accuracy.

</details>


### [58] [Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models](https://arxiv.org/abs/2508.08926)
*Wei Cai,Jian Zhao,Yuchu Jiang,Tianle Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: 论文提出“隐式推理安全”概念，揭示大型视觉语言模型（LVLM）因跨模态隐式推理缺陷导致的安全漏洞，并发布首个相关数据集SSUI。实验表明，简单上下文学习可显著缓解此类威胁。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在多模态输入下存在安全隐患，尤其是隐式推理缺陷可能导致不安全输出，亟需研究解决。

Method: 提出“隐式推理安全”概念，构建SSUI数据集，并通过上下文学习验证其缓解隐式推理威胁的效果。

Result: 实验证明，简单上下文学习能显著减少隐式推理引发的安全问题。

Conclusion: 跨模态隐式推理缺陷是LVLM的重要安全隐患，需进一步研究改进。

Abstract: Large Vision-Language Models face growing safety challenges with multimodal
inputs. This paper introduces the concept of Implicit Reasoning Safety, a
vulnerability in LVLMs. Benign combined inputs trigger unsafe LVLM outputs due
to flawed or hidden reasoning. To showcase this, we developed Safe Semantics,
Unsafe Interpretations, the first dataset for this critical issue. Our
demonstrations show that even simple In-Context Learning with SSUI
significantly mitigates these implicit multimodal threats, underscoring the
urgent need to improve cross-modal implicit reasoning.

</details>


### [59] [Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty](https://arxiv.org/abs/2508.08992)
*Rui Wang,Qihan Lin,Jiayu Liu,Qing Zong,Tianshi Zheng,Weiqi Wang,Yangqiu Song*

Main category: cs.AI

TL;DR: 研究探讨了前景理论（PT）是否适用于大型语言模型（LLMs），以及表达不确定性的认知标记（如“可能”）是否影响其决策行为。通过三阶段实验，发现PT对LLMs的建模并不完全可靠，尤其是在语言形式多样时。


<details>
  <summary>Details</summary>
Motivation: 前景理论（PT）用于人类不确定性决策，但尚未明确是否适用于LLMs，且认知标记对LLMs决策的影响未被充分研究。

Method: 设计基于经济问卷的三阶段实验，提出通用评估框架，结合认知标记的概率值分析其对LLMs决策的影响。

Result: PT对LLMs的决策建模不一致，尤其在语言形式多样时可靠性降低。

Conclusion: LLMs的决策行为受语言形式影响，PT模型需进一步优化以适应多样化表达。

Abstract: Prospect Theory (PT) models human decision-making under uncertainty, while
epistemic markers (e.g., maybe) serve to express uncertainty in language.
However, it remains largely unexplored whether Prospect Theory applies to
contemporary Large Language Models and whether epistemic markers, which express
human uncertainty, affect their decision-making behaviour. To address these
research gaps, we design a three-stage experiment based on economic
questionnaires. We propose a more general and precise evaluation framework to
model LLMs' decision-making behaviour under PT, introducing uncertainty through
the empirical probability values associated with commonly used epistemic
markers in comparable contexts. We then incorporate epistemic markers into the
evaluation framework based on their corresponding probability values to examine
their influence on LLM decision-making behaviours. Our findings suggest that
modelling LLMs' decision-making with PT is not consistently reliable,
particularly when uncertainty is expressed in diverse linguistic forms. Our
code is released in https://github.com/HKUST-KnowComp/MarPT.

</details>


### [60] [Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory](https://arxiv.org/abs/2508.08997)
*Sizhe Yuen,Francisco Gomez Medina,Ting Su,Yali Du,Adam J. Sobey*

Main category: cs.AI

TL;DR: 论文提出了一种名为“Intrinsic Memory Agents”的新框架，通过结构化、与角色对齐的记忆模板解决多智能体LLM系统中的记忆一致性问题，并在PDDL数据集和复杂数据管道设计任务中表现出显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 多智能体LLM系统在复杂协作问题解决中表现出潜力，但受限于上下文窗口，导致记忆一致性、角色遵循和程序完整性等问题。

Method: 提出Intrinsic Memory Agents框架，通过角色对齐的记忆模板动态更新记忆，专注于任务相关信息。

Result: 在PDDL数据集上性能提升38.6%，并在复杂数据管道设计任务中在5个指标上表现更优。

Conclusion: 结构化、内在的记忆方法能显著提升多智能体LLM系统在结构化规划任务中的能力。

Abstract: Multi-agent systems built on Large Language Models (LLMs) show exceptional
promise for complex collaborative problem-solving, yet they face fundamental
challenges stemming from context window limitations that impair memory
consistency, role adherence, and procedural integrity. This paper introduces
Intrinsic Memory Agents, a novel framework that addresses these limitations
through structured agent-specific memories that evolve intrinsically with agent
outputs. Specifically, our method maintains role-aligned memory templates that
preserve specialized perspectives while focusing on task-relevant information.
We benchmark our approach on the PDDL dataset, comparing its performance to
existing state-of-the-art multi-agentic memory approaches and showing an
improvement of 38.6\% with the highest token efficiency. An additional
evaluation is performed on a complex data pipeline design task, we demonstrate
that our approach produces higher quality designs when comparing 5 metrics:
scalability, reliability, usability, cost-effectiveness and documentation with
additional qualitative evidence of the improvements. Our findings suggest that
addressing memory limitations through structured, intrinsic approaches can
improve the capabilities of multi-agent LLM systems on structured planning
tasks.

</details>


### [61] [Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs](https://arxiv.org/abs/2508.09019)
*Shivam Dubey*

Main category: cs.AI

TL;DR: 提出一种端到端系统，通过机制可解释性技术直接识别和缓解模型内部偏见，包括训练线性探针检测偏见表示和利用转向向量实时修正生成内容。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型可能放大有害偏见，传统方法（如数据过滤或后处理）效果有限，需更直接、可解释的解决方案。

Method: 1. 训练线性探针检测模型内部激活中的偏见表示；2. 计算转向向量，通过调整激活模式实时修正偏见输出。

Result: 在GPT2-large上验证，探针能高精度识别偏见，转向向量有效将偏见生成修正为中性内容。

Conclusion: 该系统为构建更安全、可解释的LLMs提供了直接且可复现的方法。

Abstract: As large language models (LLMs) become more integrated into societal systems,
the risk of them perpetuating and amplifying harmful biases becomes a critical
safety concern. Traditional methods for mitigating bias often rely on data
filtering or post-hoc output moderation, which treat the model as an opaque
black box. In this work, we introduce a complete, end-to-end system that uses
techniques from mechanistic interpretability to both identify and actively
mitigate bias directly within a model's internal workings. Our method involves
two primary stages. First, we train linear "probes" on the internal activations
of a model to detect the latent representations of various biases (e.g.,
gender, race, age). Our experiments on \texttt{gpt2-large} demonstrate that
these probes can identify biased content with near-perfect accuracy, revealing
that bias representations become most salient in the model's later layers.
Second, we leverage these findings to compute "steering vectors" by contrasting
the model's activation patterns for biased and neutral statements. By adding
these vectors during inference, we can actively steer the model's generative
process away from producing harmful, stereotypical, or biased content in
real-time. We demonstrate the efficacy of this activation steering technique,
showing that it successfully alters biased completions toward more neutral
alternatives. We present our work as a robust and reproducible system that
offers a more direct and interpretable approach to building safer and more
accountable LLMs.

</details>


### [62] [A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems](https://arxiv.org/abs/2508.09027)
*Jie Wang,Guang Wang*

Main category: cs.AI

TL;DR: 论文提出了一种基于特征交互的XGBoost模型（FiXGBoost），用于预测乘客在提交乘车请求前的等待时间，填补了现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注已知司机信息后的等待时间预测，而乘客在提交请求前的等待时间预测同样重要，有助于提升用户体验和平台效率。

Method: 通过数据驱动分析供需动态对等待时间的影响，设计FiXGBoost模型，结合特征工程和重要性分析。

Result: 在大规模真实数据集（超3000万条记录）上验证，FiXGBoost表现出色且具有高解释性。

Conclusion: FiXGBoost为预请求等待时间预测提供了有效且可解释的解决方案。

Abstract: Passenger waiting time prediction plays a critical role in enhancing both
ridesharing user experience and platform efficiency. While most existing
research focuses on post-request waiting time prediction with knowing the
matched driver information, pre-request waiting time prediction (i.e., before
submitting a ride request and without matching a driver) is also important, as
it enables passengers to plan their trips more effectively and enhance the
experience of both passengers and drivers. However, it has not been fully
studied by existing works. In this paper, we take the first step toward
understanding the predictability and explainability of pre-request passenger
waiting time in ridesharing systems. Particularly, we conduct an in-depth
data-driven study to investigate the impact of demand&supply dynamics on
passenger waiting time. Based on this analysis and feature engineering, we
propose FiXGBoost, a novel feature interaction-based XGBoost model designed to
predict waiting time without knowing the assigned driver information. We
further perform an importance analysis to quantify the contribution of each
factor. Experiments on a large-scale real-world ridesharing dataset including
over 30 million trip records show that our FiXGBoost can achieve a good
performance for pre-request passenger waiting time prediction with high
explainability.

</details>


### [63] [CVCM Track Circuits Pre-emptive Failure Diagnostics for Predictive Maintenance Using Deep Neural Networks](https://arxiv.org/abs/2508.09054)
*Debdeep Mukherjee,Eduardo Di Santi,Clément Lefebvre,Nenad Mijatovic,Victor Martin,Thierry Josse,Jonathan Brown,Kenza Saiah*

Main category: cs.AI

TL;DR: 提出了一种基于深度神经网络的预测性维护框架，用于早期检测铁路轨道电路中的异常，以减少故障和停机时间。


<details>
  <summary>Details</summary>
Motivation: 轨道电路是铁路运营的关键部分，其故障可能导致连锁反应。传统方法难以检测早期细微异常，因此需要一种更有效的预测性维护方法。

Method: 采用深度神经网络分类异常，并通过符合ISO-17359标准的方法验证。结合保形预测提供不确定性估计。

Result: 在10个CVCM故障案例中，方法总体准确率达99.31%，并在异常出现1%内完成检测，置信度达99%。

Conclusion: 该方法具有可扩展性和适应性，可提升轨道电路及其他铁路系统的运行可靠性。

Abstract: Track circuits are critical for railway operations, acting as the main
signalling sub-system to locate trains. Continuous Variable Current Modulation
(CVCM) is one such technology. Like any field-deployed, safety-critical asset,
it can fail, triggering cascading disruptions. Many failures originate as
subtle anomalies that evolve over time, often not visually apparent in
monitored signals. Conventional approaches, which rely on clear signal changes,
struggle to detect them early. Early identification of failure types is
essential to improve maintenance planning, minimising downtime and revenue
loss. Leveraging deep neural networks, we propose a predictive maintenance
framework that classifies anomalies well before they escalate into failures.
Validated on 10 CVCM failure cases across different installations, the method
is ISO-17359 compliant and outperforms conventional techniques, achieving
99.31% overall accuracy with detection within 1% of anomaly onset. Through
conformal prediction, we provide uncertainty estimates, reaching 99% confidence
with consistent coverage across classes. Given CVCMs global deployment, the
approach is scalable and adaptable to other track circuits and railway systems,
enhancing operational reliability.

</details>


### [64] [SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling](https://arxiv.org/abs/2508.09105)
*Shixuan Sun,Siyuan Liang,Ruoyu Chen,Jianjie Huang,Jingzhi Li,Xiaochun Cao*

Main category: cs.AI

TL;DR: 论文提出了一种名为SMA的方法，用于在多模态检索增强生成（MRAG）系统中追踪生成内容的来源，解决了现有方法无法区分内容来源的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法可靠地追踪生成内容的来源（预训练数据、外部检索或用户输入），导致隐私泄露责任不明确。

Method: SMA通过半黑盒审计和零阶优化机制，结合跨模态归因技术，实现了对生成内容的细粒度来源追踪。

Result: SMA首次实现了对图像检索痕迹的成员推断，并能够近似输入令牌对输出的真实影响。

Conclusion: SMA将成员推断的焦点从‘数据是否被记忆’转向‘内容来源何处’，为复杂生成系统的数据溯源提供了新视角。

Abstract: Retrieval-Augmented Generation (RAG) and its Multimodal Retrieval-Augmented
Generation (MRAG) significantly improve the knowledge coverage and contextual
understanding of Large Language Models (LLMs) by introducing external knowledge
sources. However, retrieval and multimodal fusion obscure content provenance,
rendering existing membership inference methods unable to reliably attribute
generated outputs to pre-training, external retrieval, or user input, thus
undermining privacy leakage accountability
  To address these challenges, we propose the first Source-aware Membership
Audit (SMA) that enables fine-grained source attribution of generated content
in a semi-black-box setting with retrieval control capabilities.To address the
environmental constraints of semi-black-box auditing, we further design an
attribution estimation mechanism based on zero-order optimization, which
robustly approximates the true influence of input tokens on the output through
large-scale perturbation sampling and ridge regression modeling. In addition,
SMA introduces a cross-modal attribution technique that projects image inputs
into textual descriptions via MLLMs, enabling token-level attribution in the
text modality, which for the first time facilitates membership inference on
image retrieval traces in MRAG systems. This work shifts the focus of
membership inference from 'whether the data has been memorized' to 'where the
content is sourced from', offering a novel perspective for auditing data
provenance in complex generative systems.

</details>


### [65] [OpenCUA: Open Foundations for Computer-Use Agents](https://arxiv.org/abs/2508.09123)
*Xinyuan Wang,Bowen Wang,Dunjie Lu,Junlin Yang,Tianbao Xie,Junli Wang,Jiaqi Deng,Xiaole Guo,Yiheng Xu,Chen Henry Wu,Zhennan Shen,Zhuokai Li,Ryan Li,Xiaochuan Li,Junda Chen,Boyuan Zheng,Peihang Li,Fangyu Lei,Ruisheng Cao,Yeqiao Fu,Dongchan Shin,Martin Shin,Jiarui Hu,Yuyan Wang,Jixuan Chen,Yuxiao Ye,Danyang Zhang,Dikang Du,Hao Hu,Huarong Chen,Zaida Zhou,Yipu Wang,Heng Wang,Diyi Yang,Victor Zhong,Flood Sung,Y. Charles,Zhilin Yang,Tao Yu*

Main category: cs.AI

TL;DR: OpenCUA是一个开源框架，旨在解决视觉语言模型作为计算机使用代理（CUA）的封闭性问题，提供数据、模型和工具以支持研究。


<details>
  <summary>Details</summary>
Motivation: 随着CUA的商业潜力增长，其封闭性限制了研究社区对其能力、局限性和风险的研究。OpenCUA旨在填补这一空白。

Method: OpenCUA包括：1）标注基础设施；2）AgentNet数据集；3）可扩展的演示转换管道。

Result: OpenCUA-32B在OSWorld-Verified上达到34.8%的平均成功率，超越GPT-4o，成为开源模型的新SOTA。

Conclusion: OpenCUA为CUA研究提供了开放基础，其方法在跨领域泛化和计算扩展方面表现优异。

Abstract: Vision-language models have demonstrated impressive capabilities as
computer-use agents (CUAs) capable of automating diverse computer tasks. As
their commercial potential grows, critical details of the most capable CUA
systems remain closed. As these agents will increasingly mediate digital
interactions and execute consequential decisions on our behalf, the research
community needs access to open CUA frameworks to study their capabilities,
limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive
open-source framework for scaling CUA data and foundation models. Our framework
consists of: (1) an annotation infrastructure that seamlessly captures human
computer-use demonstrations; (2) AgentNet, the first large-scale computer-use
task dataset spanning 3 operating systems and 200+ applications and websites;
(3) a scalable pipeline that transforms demonstrations into state-action pairs
with reflective long Chain-of-Thought reasoning that sustain robust performance
gains as data scales. Our end-to-end agent models demonstrate strong
performance across CUA benchmarks. In particular, OpenCUA-32B achieves an
average success rate of 34.8% on OSWorld-Verified, establishing a new
state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA
(GPT-4o). Further analysis confirms that our approach generalizes well across
domains and benefits significantly from increased test-time computation. We
release our annotation tool, datasets, code, and models to build open
foundations for further CUA research.

</details>


### [66] [BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair](https://arxiv.org/abs/2508.09129)
*Xianghe Pang,Shuo Tang,Rui Ye,Yuwen Du,Yaxin Du,Siheng Chen*

Main category: cs.AI

TL;DR: BrowseMaster是一个可扩展的框架，通过规划器-执行器代理对解决LLM代理在信息搜索中的局限性，提升搜索广度和推理深度。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的代理在信息搜索中难以平衡搜索广度和推理深度，导致覆盖范围受限和多步推理中断。

Method: 提出BrowseMaster框架，包含规划器和执行器：规划器制定搜索策略，执行器高效检索相关证据。

Result: 在英语和中文基准测试中表现优异，BrowseComp-en得分30.0，BrowseComp-zh得分46.5。

Conclusion: BrowseMaster在复杂、推理密集型信息搜索任务中表现出色，优于现有方法。

Abstract: Effective information seeking in the vast and ever-growing digital landscape
requires balancing expansive search with strategic reasoning. Current large
language model (LLM)-based agents struggle to achieve this balance due to
limitations in search breadth and reasoning depth, where slow, serial querying
restricts coverage of relevant sources and noisy raw inputs disrupt the
continuity of multi-step reasoning. To address these challenges, we propose
BrowseMaster, a scalable framework built around a programmatically augmented
planner-executor agent pair. The planner formulates and adapts search
strategies based on task constraints, while the executor conducts efficient,
targeted retrieval to supply the planner with concise, relevant evidence. This
division of labor preserves coherent, long-horizon reasoning while sustaining
broad and systematic exploration, overcoming the trade-off that limits existing
agents. Extensive experiments on challenging English and Chinese benchmarks
show that BrowseMaster consistently outperforms open-source and proprietary
baselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh,
which demonstrates its strong capability in complex, reasoning-heavy
information-seeking tasks at scale.

</details>
