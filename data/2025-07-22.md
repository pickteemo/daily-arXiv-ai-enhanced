<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 58]
- [cs.RO](#cs.RO) [Total: 43]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The Free Will Equation: Quantum Field Analogies for AGI](https://arxiv.org/abs/2507.14154)
*Rahul Kabali*

Main category: cs.AI

TL;DR: 论文提出了一种名为“自由意志方程”的理论框架，通过借鉴量子场论，赋予AGI代理一种自适应、受控的随机性决策能力。


<details>
  <summary>Details</summary>
Motivation: 传统AGI研究专注于确定性规则下的目标优化，但人类智能具有适应性自发性（类似“自由意志”），这对创造力、适应性和问题解决多样性至关重要。

Method: 将AI代理的认知状态视为潜在行动或思想的叠加态，通过类似量子波函数坍缩的机制实现决策，并结合量子场论和内在动机。

Result: 在非稳态多臂老虎机环境中的实验表明，使用该框架的代理比基线方法获得更高的奖励和策略多样性。

Conclusion: 该框架为AGI的决策过程引入了一种新的随机性机制，可能提升其适应性和创造力。

Abstract: Artificial General Intelligence (AGI) research traditionally focuses on
algorithms that optimize for specific goals under deterministic rules. Yet,
human-like intelligence exhibits adaptive spontaneity - an ability to make
unexpected choices or free decisions not strictly dictated by past data or
immediate reward. This trait, often dubbed "free will" in a loose sense, might
be crucial for creativity, robust adaptation, and avoiding ruts in
problem-solving. This paper proposes a theoretical framework, called the Free
Will Equation, that draws analogies from quantum field theory to endow AGI
agents with a form of adaptive, controlled stochasticity in their
decision-making process. The core idea is to treat an AI agent's cognitive
state as a superposition of potential actions or thoughts, which collapses
probabilistically into a concrete action when a decision is made - much like a
quantum wavefunction collapsing upon measurement. By incorporating mechanisms
analogous to quantum fields, along with intrinsic motivation terms, we aim to
improve an agent's ability to explore novel strategies and adapt to unforeseen
changes. Experiments in a non-stationary multi-armed bandit environment
demonstrate that agents using this framework achieve higher rewards and policy
diversity compared to baseline methods.

</details>


### [2] [DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation](https://arxiv.org/abs/2507.14267)
*Ziqi Wang,Hongshuo Huang,Hancheng Zhao,Changwen Xu,Shang Zhu,Jan Janssen,Venkatasubramanian Viswanathan*

Main category: cs.AI

TL;DR: DREAMS是一个基于DFT的多智能体框架，通过LLM代理实现材料发现的高通量、高保真模拟，减少对人力的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决DFT模拟中训练时间长、参数调整复杂和系统误差处理的问题。

Method: 采用分层多智能体框架，结合LLM规划代理和领域特定代理，共享画布辅助协作。

Result: 在Sol27LC基准测试中误差低于1%，解决了CO/Pt(111)吸附难题，并量化了功能驱动的不确定性。

Conclusion: DREAMS实现了L3级自动化，显著减少对人力的依赖，推动高通量材料发现的民主化。

Abstract: Materials discovery relies on high-throughput, high-fidelity simulation
techniques such as Density Functional Theory (DFT), which require years of
training, extensive parameter fine-tuning and systematic error handling. To
address these challenges, we introduce the DFT-based Research Engine for
Agentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for
DFT simulation that combines a central Large Language Model (LLM) planner agent
with domain-specific LLM agents for atomistic structure generation, systematic
DFT convergence testing, High-Performance Computing (HPC) scheduling, and error
handling. In addition, a shared canvas helps the LLM agents to structure their
discussions, preserve context and prevent hallucination. We validate DREAMS
capabilities on the Sol27LC lattice-constant benchmark, achieving average
errors below 1\% compared to the results of human DFT experts. Furthermore, we
apply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating
its long-term and complex problem-solving capabilities. The framework again
reproduces expert-level literature adsorption-energy differences. Finally,
DREAMS is employed to quantify functional-driven uncertainties with Bayesian
ensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at
the Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS
approaches L3-level automation - autonomous exploration of a defined design
space - and significantly reduces the reliance on human expertise and
intervention, offering a scalable path toward democratized, high-throughput,
high-fidelity computational materials discovery.

</details>


### [3] [WebGuard: Building a Generalizable Guardrail for Web Agents](https://arxiv.org/abs/2507.14293)
*Boyuan Zheng,Zeyi Liao,Scott Salisbury,Zeyuan Liu,Michael Lin,Qinyuan Zheng,Zifan Wang,Xiang Deng,Dawn Song,Huan Sun,Yu Su*

Main category: cs.AI

TL;DR: WebGuard是一个用于评估网络代理行为风险的数据集，旨在为现实世界在线环境开发安全防护措施。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的自主网络代理快速发展，其可能采取有害行为的风险凸显，亟需有效的安全措施。

Method: WebGuard包含4,939个人工标注的行为，覆盖193个网站和22个领域，采用三级风险分类（SAFE、LOW、HIGH），并支持多种泛化场景评估。

Result: 前沿大语言模型在预测行为结果和高风险行为召回率上表现不佳（均低于60%），但通过微调Qwen2.5VL-7B模型，性能显著提升（准确率从37%升至80%，高风险召回率从20%升至76%）。

Conclusion: 尽管性能有所提升，但当前防护措施的可靠性仍不足以支持高风险部署，需进一步优化以实现近乎完美的准确率和召回率。

Abstract: The rapid development of autonomous web agents powered by Large Language
Models (LLMs), while greatly elevating efficiency, exposes the frontier risk of
taking unintended or harmful actions. This situation underscores an urgent need
for effective safety measures, akin to access controls for human users. To
address this critical challenge, we introduce WebGuard, the first comprehensive
dataset designed to support the assessment of web agent action risks and
facilitate the development of guardrails for real-world online environments. In
doing so, WebGuard specifically focuses on predicting the outcome of
state-changing actions and contains 4,939 human-annotated actions from 193
websites across 22 diverse domains, including often-overlooked long-tail
websites. These actions are categorized using a novel three-tier risk schema:
SAFE, LOW, and HIGH. The dataset includes designated training and test splits
to support evaluation under diverse generalization settings. Our initial
evaluations reveal a concerning deficiency: even frontier LLMs achieve less
than 60% accuracy in predicting action outcomes and less than 60% recall in
lagging HIGH-risk actions, highlighting the risks of deploying
current-generation agents without dedicated safeguards. We therefore
investigate fine-tuning specialized guardrail models using WebGuard. We conduct
comprehensive evaluations across multiple generalization settings and find that
a fine-tuned Qwen2.5VL-7B model yields a substantial improvement in
performance, boosting accuracy from 37% to 80% and HIGH-risk action recall from
20% to 76%. Despite these improvements, the performance still falls short of
the reliability required for high-stakes deployment, where guardrails must
approach near-perfect accuracy and recall.

</details>


### [4] [Manimator: Transforming Research Papers into Visual Explanations](https://arxiv.org/abs/2507.14306)
*Samarth P,Vyoman Jain,Shiva Golugula,Motamarri Sai Sathvik*

Main category: cs.AI

TL;DR: Manimator是一个开源系统，利用大型语言模型将研究论文和自然语言提示转换为解释性动画，简化复杂STEM主题的可视化教育内容创作。


<details>
  <summary>Details</summary>
Motivation: 理解复杂科学和数学概念对学习者具有挑战性，而动态可视化能显著提升理解，但手动创建耗时且需要专业知识。

Method: Manimator通过LLM解析输入文本或PDF论文，生成结构化场景描述，再由另一LLM将其转换为可执行的Manim Python代码。

Result: 系统能够快速生成高质量的教育动画，降低创作门槛。

Conclusion: Manimator有望成为教育工具，促进复杂STEM主题的可视化解释，推动教育内容民主化。

Abstract: Understanding complex scientific and mathematical concepts, particularly
those presented in dense research papers, poses a significant challenge for
learners. Dynamic visualizations can greatly enhance comprehension, but
creating them manually is time-consuming and requires specialized knowledge and
skills. We introduce manimator, an open-source system that leverages Large
Language Models to transform research papers and natural language prompts into
explanatory animations using the Manim engine. Manimator employs a pipeline
where an LLM interprets the input text or research paper PDF to generate a
structured scene description outlining key concepts, mathematical formulas, and
visual elements and another LLM translates this description into executable
Manim Python code. We discuss its potential as an educational tool for rapidly
creating engaging visual explanations for complex STEM topics, democratizing
the creation of high-quality educational content.

</details>


### [5] [Language Models as Ontology Encoders](https://arxiv.org/abs/2507.14334)
*Hui Yang,Jiaoyan Chen,Yuan He,Yongsheng Gao,Ian Horrocks*

Main category: cs.AI

TL;DR: 提出了一种新的本体嵌入方法OnT，结合预训练语言模型和双曲几何建模，以同时利用文本信息并保持逻辑结构。


<details>
  <summary>Details</summary>
Motivation: 现有本体嵌入方法要么忽略文本信息，要么无法保持逻辑结构，限制了性能和应用。

Method: 通过双曲几何建模调整预训练语言模型，结合文本标签并保持描述逻辑EL的层次和关系。

Result: 在四个真实本体数据集上，OnT在预测和推理任务中均优于基线方法，并展示了强大的迁移学习能力。

Conclusion: OnT是一种高效的本体嵌入方法，适用于实际应用，如从SNOMED CT构建新本体。

Abstract: OWL (Web Ontology Language) ontologies which are able to formally represent
complex knowledge and support semantic reasoning have been widely adopted
across various domains such as healthcare and bioinformatics. Recently,
ontology embeddings have gained wide attention due to its potential to infer
plausible new knowledge and approximate complex reasoning. However, existing
methods face notable limitations: geometric model-based embeddings typically
overlook valuable textual information, resulting in suboptimal performance,
while the approaches that incorporate text, which are often based on language
models, fail to preserve the logical structure. In this work, we propose a new
ontology embedding method OnT, which tunes a Pretrained Language Model (PLM)
via geometric modeling in a hyperbolic space for effectively incorporating
textual labels and simultaneously preserving class hierarchies and other
logical relationships of Description Logic EL. Extensive experiments on four
real-world ontologies show that OnT consistently outperforms the baselines
including the state-of-the-art across both tasks of prediction and inference of
axioms. OnT also demonstrates strong potential in real-world applications,
indicated by its robust transfer learning abilities and effectiveness in real
cases of constructing a new ontology from SNOMED CT. Data and code are
available at https://github.com/HuiYang1997/OnT.

</details>


### [6] [ProofCompass: Enhancing Specialized Provers with LLM Guidance](https://arxiv.org/abs/2507.14335)
*Nicolas Wischermann,Claudio Mayrink Verdun,Gabriel Poesia,Francesco Noseda*

Main category: cs.AI

TL;DR: ProofCompass是一种混合方法，通过结合大型语言模型（LLM）和专用证明器（如DSP-v1.5），在不增加训练成本的情况下显著提升数学推理的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖大型通用模型，要么依赖小型专用模型，各有局限性，而训练大型专用模型需要大量计算资源。ProofCompass旨在解决这一问题。

Method: ProofCompass利用LLM提供自然语言证明策略并分析失败尝试，选择中间引理，从而实现问题分解。该方法无需额外模型训练。

Result: 在miniF2F基准测试中，ProofCompass在仅使用128次尝试（原需3200次）的情况下，将准确率从54.9%提升至55.3%。

Conclusion: ProofCompass展示了在提升计算效率和准确性方面的协同效应，为形式化定理证明提供了新思路。

Abstract: Language models have become increasingly powerful tools for formal
mathematical reasoning. However, most existing approaches rely exclusively on
either large general-purpose models or smaller specialized models, each with
distinct limitations, while training specialized large models still requires
significant computational resources. This paper introduces ProofCompass, a
novel hybrid methodology that achieves remarkable computational efficiency by
strategically guiding existing specialized prover methods, such as
DeepSeek-Prover-v1.5-RL (DSP-v1.5) with a Large Language Model (LLM) without
requiring additional model training. The LLM provides natural language proof
strategies and analyzes failed attempts to select intermediate lemmas, enabling
effective problem decomposition. On the miniF2F benchmark, ProofCompass
demonstrates substantial resource efficiency: it outperforms DSP-v1.5 ($54.9\%
\rightarrow 55.3\%$) while using 25x fewer attempts ($3200 \rightarrow 128$).
Our synergistic approach paves the way for simultaneously improving
computational efficiency and accuracy in formal theorem proving.

</details>


### [7] [Adaptive Multi-Agent Reasoning via Automated Workflow Generation](https://arxiv.org/abs/2507.14393)
*Humza Sami,Mubashir ul Islam,Pierre-Emmanuel Gaillardon,Valerio Tenace*

Main category: cs.AI

TL;DR: Nexus Architect是一种改进的多代理系统框架，通过自动生成定制化推理工作流和迭代提示优化机制，显著提升了推理模型的泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型（LRMs）在解决新问题时表现不佳，倾向于依赖记忆而非真正的推理能力，导致泛化能力不足。

Method: 提出Nexus Architect框架，结合自动化工作流合成和迭代提示优化机制，生成针对特定问题类的推理策略。

Result: 在逻辑问题数据集上，Nexus Architect的性能显著优于现有LRMs，最高提升66%通过率。

Conclusion: Nexus Architect通过定制化推理工作流和提示优化，有效解决了LRMs的泛化问题，性能显著提升。

Abstract: The rise of Large Reasoning Models (LRMs) promises a significant leap forward
in language model capabilities, aiming to tackle increasingly sophisticated
tasks with unprecedented efficiency and accuracy. However, despite their
impressive performance, recent studies have highlighted how current reasoning
models frequently fail to generalize to novel, unseen problems, often resorting
to memorized solutions rather than genuine inferential reasoning. Such behavior
underscores a critical limitation in modern LRMs, i.e., their tendency toward
overfitting, which in turn results in poor generalization in problem-solving
capabilities.
  In this paper, we introduce Nexus Architect, an enhanced iteration of our
multi-agent system framework, Nexus, equipped with a novel automated workflow
synthesis mechanism. Given a user's prompt and a small set of representative
examples, the Architect autonomously generates a tailored reasoning workflow by
selecting suitable strategies, tool integrations, and adversarial techniques
for a specific problem class. Furthermore, the Architect includes an iterative
prompt refinement mechanism that fine-tunes agents' system prompts to maximize
performance and improve the generalization capabilities of the system.
  We empirically evaluate Nexus Architect by employing an off-the-shelf,
non-reasoning model on a custom dataset of challenging logical questions and
compare its performance against state-of-the-art LRMs. Results show that Nexus
Architect consistently outperforms existing solutions, achieving up to a 66%
increase in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\times$ against
Claude Sonnet 4 and DeepSeek-R1, and over 3$\times$ w.r.t. Llama 4 Scout.

</details>


### [8] [Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering](https://arxiv.org/abs/2507.14406)
*Michael J. Zellinger,Matt Thomson*

Main category: cs.AI

TL;DR: 论文提出了一种结合推理模型与人类专家的协作系统，通过量化不确定性降低错误率，并探索了非推理模型前置以减少延迟和成本的方法。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型在风险敏感领域错误率较高且延迟大，需改进以满足实际需求。

Method: 1. 通过推理轨迹长度量化不确定性，将不确定问题转交人类专家；2. 前置非推理模型快速筛选问题，减少延迟和成本。

Result: 1. 错误率从3%降至1%以下；2. 延迟降低40%，成本节省50%，同时保持高准确率。

Conclusion: 通过系统设计（如协作和模型组合）可显著改善推理模型的错误率和延迟问题，无需修改模型内部。

Abstract: State-of-the-art reasoning LLMs are powerful problem solvers, but they still
occasionally make mistakes. However, adopting AI models in risk-sensitive
domains often requires error rates near 0%. To address this gap, we propose
collaboration between a reasoning model and a human expert who resolves queries
the model cannot confidently answer. We find that quantifying the uncertainty
of a reasoning model through the length of its reasoning trace yields an
effective basis for deferral to a human, e.g., cutting the error rate of Qwen3
235B-A22B on difficult MATH problems from 3% to less than 1% when deferring
7.5% of queries. However, the high latency of reasoning models still makes them
challenging to deploy on use cases with high query volume. To address this
challenge, we explore fronting a reasoning model with a large non-reasoning
model. We call this modified human-in-the-loop system "Fail Fast, or Ask",
since the non-reasoning model may defer difficult queries to the human expert
directly ("failing fast"), without incurring the reasoning model's higher
latency. We show that this approach yields around 40% latency reduction and
about 50% cost savings for DeepSeek R1 while maintaining 90+% area under the
accuracy-rejection curve. However, we observe that latency savings are lower
than expected because of "latency drag", the phenomenon that processing easier
queries with a non-reasoning model pushes the reasoning model's latency
distribution towards longer latencies. Broadly, our results suggest that the
deficiencies of state-of-the-art reasoning models -- nontrivial error rates and
high latency -- can be substantially mitigated through black-box systems
engineering, without requiring access to LLM internals.

</details>


### [9] [Inverse Scaling in Test-Time Compute](https://arxiv.org/abs/2507.14417)
*Aryo Pradipta Gema,Alexander Hägele,Runjin Chen,Andy Arditi,Jacob Goldman-Wetzler,Kit Fraser-Taliente,Henry Sleight,Linda Petrini,Julian Michael,Beatrice Alex,Pasquale Minervini,Yanda Chen,Joe Benton,Ethan Perez*

Main category: cs.AI

TL;DR: 研究发现，大型推理模型（LRMs）在延长推理长度时性能下降，表现为测试计算量与准确率的反比关系。任务涵盖四类，揭示了五种失败模式，表明计算量扩展可能强化问题推理模式。


<details>
  <summary>Details</summary>
Motivation: 探讨测试计算量扩展对模型性能的影响，揭示LRMs在延长推理时的潜在问题。

Method: 构建四类评估任务（计数、回归、演绎、AI风险），分析模型在不同推理长度下的表现。

Result: 发现五种失败模式，如分心、过拟合、虚假关联等，表明计算量扩展可能带来负面影响。

Conclusion: 需多样化评估推理长度以识别和解决LRMs的失败模式，计算量扩展需谨慎。

Abstract: We construct evaluation tasks where extending the reasoning length of Large
Reasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling
relationship between test-time compute and accuracy. Our evaluation tasks span
four categories: simple counting tasks with distractors, regression tasks with
spurious features, deduction tasks with constraint tracking, and advanced AI
risks. We identify five distinct failure modes when models reason for longer:
1) Claude models become increasingly distracted by irrelevant information; 2)
OpenAI o-series models resist distractors but overfit to problem framings; 3)
models shift from reasonable priors to spurious correlations; 4) all models
show difficulties in maintaining focus on complex deductive tasks; and 5)
extended reasoning may amplify concerning behaviors, with Claude Sonnet 4
showing increased expressions of self-preservation. These findings suggest that
while test-time compute scaling remains promising for improving model
capabilities, it may inadvertently reinforce problematic reasoning patterns.
Our results demonstrate the importance of evaluating models across diverse
reasoning lengths to identify and address these failure modes in LRMs.

</details>


### [10] [Routine: A Structural Planning Framework for LLM Agent System in Enterprise](https://arxiv.org/abs/2507.14447)
*Guancheng Zeng,Xueyi Chen,Jiawang Hu,Shaohua Qi,Yaxuan Mao,Zhantao Wang,Yifan Nie,Shuang Li,Qiuyang Feng,Pengxu Qiu,Yujia Wang,Wenqiang Han,Linyan Huang,Gang Li,Jingjing Mo,Haowen Hu*

Main category: cs.AI

TL;DR: 论文提出Routine框架，通过结构化规划和参数传递提升多步工具调用任务的执行稳定性，显著提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 企业环境中代理系统的部署常因缺乏领域知识导致执行不稳定，需解决这一问题。

Method: 引入Routine框架，包含清晰结构、明确指令和参数传递，支持多步工具调用任务。

Result: Routine显著提升模型执行准确率（GPT-4o从41.1%升至96.3%，Qwen3-14B从32.6%升至83.3%），并通过微调进一步提升至95.5%。

Conclusion: Routine有效提炼领域工具使用模式，提升模型适应性，加速企业环境中代理系统的部署。

Abstract: The deployment of agent systems in an enterprise environment is often
hindered by several challenges: common models lack domain-specific process
knowledge, leading to disorganized plans, missing key tools, and poor execution
stability. To address this, this paper introduces Routine, a multi-step agent
planning framework designed with a clear structure, explicit instructions, and
seamless parameter passing to guide the agent's execution module in performing
multi-step tool-calling tasks with high stability. In evaluations conducted
within a real-world enterprise scenario, Routine significantly increases the
execution accuracy in model tool calls, increasing the performance of GPT-4o
from 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed
a Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an
accuracy increase to 88.2% on scenario-specific evaluations, indicating
improved adherence to execution plans. In addition, we employed Routine-based
distillation to create a scenario-specific, multi-step tool-calling dataset.
Fine-tuning on this distilled dataset raised the model's accuracy to 95.5%,
approaching GPT-4o's performance. These results highlight Routine's
effectiveness in distilling domain-specific tool-usage patterns and enhancing
model adaptability to new scenarios. Our experimental results demonstrate that
Routine provides a practical and accessible approach to building stable agent
workflows, accelerating the deployment and adoption of agent systems in
enterprise environments, and advancing the technical vision of AI for Process.

</details>


### [11] [BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning](https://arxiv.org/abs/2507.14468)
*Yitong Lin,Jiaying He,Jiahe Chen,Xinnan Zhu,Jianwei Zheng,Tao Bo*

Main category: cs.AI

TL;DR: BioGraphFusion框架通过结合全局语义和动态结构学习，显著提升了生物医学知识图谱的推理能力。


<details>
  <summary>Details</summary>
Motivation: 生物医学知识图谱在药物发现和疾病理解中至关重要，但现有方法难以实现语义理解和结构学习的协同进化。

Method: BioGraphFusion通过张量分解建立全局语义基础，结合LSTM动态优化关系嵌入，并通过查询引导的子图构建和混合评分机制增强学习。

Result: 在三个生物医学任务中表现优于现有方法，并通过CMM1案例验证了其生物学意义。

Conclusion: BioGraphFusion为生物医学知识图谱的语义与结构学习提供了高效协同解决方案。

Abstract: Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery
and disease understanding, yet their completion and reasoning are challenging.
Knowledge Embedding (KE) methods capture global semantics but struggle with
dynamic structural integration, while Graph Neural Networks (GNNs) excel
locally but often lack semantic understanding. Even ensemble approaches,
including those leveraging language models, often fail to achieve a deep,
adaptive, and synergistic co-evolution between semantic comprehension and
structural learning. Addressing this critical gap in fostering continuous,
reciprocal refinement between these two aspects in complex biomedical KGs is
paramount.
  Results: We introduce BioGraphFusion, a novel framework for deeply
synergistic semantic and structural learning. BioGraphFusion establishes a
global semantic foundation via tensor decomposition, guiding an LSTM-driven
mechanism to dynamically refine relation embeddings during graph propagation.
This fosters adaptive interplay between semantic understanding and structural
learning, further enhanced by query-guided subgraph construction and a hybrid
scoring mechanism. Experiments across three key biomedical tasks demonstrate
BioGraphFusion's superior performance over state-of-the-art KE, GNN, and
ensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1)
highlights its ability to unveil biologically meaningful pathways.
  Availability and Implementation: Source code and all training data are freely
available for download at https://github.com/Y-TARL/BioGraphFusion.
  Contact: zjw@zjut.edu.cn, botao666666@126.com.
  Supplementary information: Supplementary data are available at Bioinformatics
online.

</details>


### [12] [Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy](https://arxiv.org/abs/2507.14513)
*Hongyi Yang,Yue Pan,Jiayi Xu,Kelsen Liu*

Main category: cs.AI

TL;DR: Amico是一个模块化、事件驱动的框架，专为嵌入式系统优化的自主代理构建，解决了现有框架在资源受限环境中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型和自主代理框架在动态环境和资源受限场景中表现不佳，依赖云端计算且缺乏持久自主性和环境感知能力。

Method: Amico采用Rust编写，支持WebAssembly，提供事件处理、状态管理、行为执行和推理模块集成的抽象接口。

Result: Amico构建了高效、持久的自主代理，适用于计算资源有限和间歇性连接的环境。

Conclusion: Amico为嵌入式系统提供了一个统一的、弹性的自主代理框架，解决了现有技术的局限性。

Abstract: Recent advances in large language models (LLMs) and autonomous agents have
enabled systems capable of performing complex tasks across domains such as
human-computer interaction, planning, and web navigation. However, many
existing frameworks struggle in real-world or resource-constrained environments
due to their reliance on cloud-based computation, limited robustness in dynamic
contexts, and lack of persistent autonomy and environmental awareness.
  We present Amico, a modular, event-driven framework for building autonomous
agents optimized for embedded systems. Written in Rust for safety and
performance, Amico supports reactive, persistent agents that operate
efficiently across embedded platforms and browser environments via WebAssembly.
It provides clean abstractions for event handling, state management, behavior
execution, and integration with reasoning modules. Amico delivers a unified
infrastructure for constructing resilient, interactive agents suitable for
deployment in settings with limited compute and intermittent connectivity.

</details>


### [13] [What if Othello-Playing Language Models Could See?](https://arxiv.org/abs/2507.14520)
*Xinyi Chen,Yifei Yuan,Jiaang Li,Serge Belongie,Maarten de Rijke,Anders Søgaard*

Main category: cs.AI

TL;DR: 多模态模型VISOTHELLO通过结合棋盘图像和走棋历史，提升了语言模型的性能和鲁棒性，表明视觉输入有助于模型理解结构化世界。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型是否仅通过文本就能理解世界，还是需要多模态（如视觉）输入更高效。

Method: 在Othello游戏中，训练多模态模型VISOTHELLO，结合走棋历史和棋盘图像，通过预测下一步走棋与单模态基线对比。

Result: 多模态训练提升了模型性能和内部表示的鲁棒性。

Conclusion: 视觉输入有助于语言模型推断结构化世界表示。

Abstract: Language models are often said to face a symbol grounding problem. While some
argue that world understanding can emerge from text alone, others suggest
grounded learning is more efficient. We explore this through Othello, where the
board state defines a simplified, rule-based world. Building on prior work, we
introduce VISOTHELLO, a multi-modal model trained on move histories and board
images. Using next-move prediction, we compare it to mono-modal baselines and
test robustness to semantically irrelevant perturbations. We find that
multi-modal training improves both performance and the robustness of internal
representations. These results suggest that grounding language in visual input
helps models infer structured world representations.

</details>


### [14] [Large Language Models Assisting Ontology Evaluation](https://arxiv.org/abs/2507.14552)
*Anna Sofia Lippolis,Mohammad Javad Saeedizade,Robin Keskisärkkä,Aldo Gangemi,Eva Blomqvist,Andrea Giovanni Nuzzolese*

Main category: cs.AI

TL;DR: OE-Assist是一个自动化框架，用于通过大型语言模型（LLM）辅助本体评估，减少人工成本。


<details>
  <summary>Details</summary>
Motivation: 传统本体评估方法（如能力问题验证）成本高且易出错，需要更高效的自动化解决方案。

Method: 提出OE-Assist框架，利用LLM自动或半自动验证能力问题（CQ），并评估其效果。

Result: LLM（o1-preview和o3-mini）的自动化评估表现与普通用户相当。

Conclusion: LLM辅助的本体评估具有潜力，可显著减少人工工作量。

Abstract: Ontology evaluation through functional requirements, such as testing via
competency question (CQ) verification, is a well-established yet costly,
labour-intensive, and error-prone endeavour, even for ontology engineering
experts. In this work, we introduce OE-Assist, a novel framework designed to
assist ontology evaluation through automated and semi-automated CQ
verification. By presenting and leveraging a dataset of 1,393 CQs paired with
corresponding ontologies and ontology stories, our contributions present, to
our knowledge, the first systematic investigation into large language model
(LLM)-assisted ontology evaluation, and include: (i) evaluating the
effectiveness of a LLM-based approach for automatically performing CQ
verification against a manually created gold standard, and (ii) developing and
assessing an LLM-powered framework to assist CQ verification with Prot\'eg\'e,
by providing suggestions. We found that automated LLM-based evaluation with
o1-preview and o3-mini perform at a similar level to the average user's
performance.

</details>


### [15] [Coordinate Heart System: A Geometric Framework for Emotion Representation](https://arxiv.org/abs/2507.14593)
*Omar Al-Desi*

Main category: cs.AI

TL;DR: 论文提出了一种几何框架Coordinate Heart System（CHS），用于AI中的情感表示，通过八种核心情感坐标实现复杂情感状态的数学计算。


<details>
  <summary>Details</summary>
Motivation: 传统情感模型在覆盖复杂情感状态时存在不足，需要一种数学上完备的框架来支持情感识别与计算。

Method: 将八种核心情感定位为单位圆上的坐标，通过坐标混合和向量运算实现情感计算，并引入稳定性参数S动态整合情感负荷和冲突解决。

Result: 八情感系统消除了五情感模型的覆盖盲点，实验验证了其在处理情感冲突和复杂心理场景中的有效性。

Conclusion: CHS为AI情感建模提供了新的数学基础，支持多维稳定性建模和复杂情感状态的计算。

Abstract: This paper presents the Coordinate Heart System (CHS), a geometric framework
for emotion representation in artificial intelligence applications. We position
eight core emotions as coordinates on a unit circle, enabling mathematical
computation of complex emotional states through coordinate mixing and vector
operations. Our initial five-emotion model revealed significant coverage gaps
in the emotion space, leading to the development of an eight-emotion system
that provides complete geometric coverage with mathematical guarantees. The
framework converts natural language input to emotion coordinates and supports
real-time emotion interpolation through computational algorithms. The system
introduces a re-calibrated stability parameter S in [0,1], which dynamically
integrates emotional load, conflict resolution, and contextual drain factors.
This stability model leverages advanced Large Language Model interpretation of
textual cues and incorporates hybrid temporal tracking mechanisms to provide
nuanced assessment of psychological well-being states. Our key contributions
include: (i) mathematical proof demonstrating why five emotions are
insufficient for complete geometric coverage, (ii) an eight-coordinate system
that eliminates representational blind spots, (iii) novel algorithms for
emotion mixing, conflict resolution, and distance calculation in emotion space,
and (iv) a comprehensive computational framework for AI emotion recognition
with enhanced multi-dimensional stability modeling. Experimental validation
through case studies demonstrates the system's capability to handle emotionally
conflicted states, contextual distress factors, and complex psychological
scenarios that traditional categorical emotion models cannot adequately
represent. This work establishes a new mathematical foundation for emotion
modeling in artificial intelligence systems.

</details>


### [16] [Efficient Story Point Estimation With Comparative Learning](https://arxiv.org/abs/2507.14642)
*Monoshiz Mahbub Khan,Xioayin Xi,Andrew Meneely,Zhe Yu*

Main category: cs.AI

TL;DR: 论文提出了一种基于比较学习的框架，用于校准项目特定的故事点预测模型，以减少敏捷开发中故事点估算的认知负担。


<details>
  <summary>Details</summary>
Motivation: 传统的故事点估算方法（如计划扑克）繁琐且耗时，机器学习虽能减轻负担，但现有模型需依赖同一项目的历史数据。本文旨在通过比较学习框架提高估算效率。

Method: 开发者通过比较待办事项对的相对工作量，而非直接分配故事点，训练机器学习模型预测故事点。

Result: 模型在16个项目、23,313个手动估算数据上，平均Spearman等级相关系数为0.34，性能与回归模型相当或更优。

Conclusion: 比较学习方法比回归方法更高效，符合比较判断定律，降低了人类的认知负担。

Abstract: Story point estimation is an essential part of agile software development.
Story points are unitless, project-specific effort estimates that help
developers plan their sprints. Traditionally, developers estimate story points
collaboratively using planning poker or other manual techniques. While the
initial calibrating of the estimates to each project is helpful, once a team
has converged on a set of precedents, story point estimation can become tedious
and labor-intensive. Machine learning can reduce this burden, but only with
enough context from the historical decisions made by the project team. That is,
state-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate
predictions (within-project) when trained on data from the same project. The
goal of this work is to streamline story point estimation by evaluating a
comparative learning-based framework for calibrating project-specific story
point prediction models. Instead of assigning a specific story point value to
every backlog item, developers are presented with pairs of items, and indicate
which item requires more effort. Using these comparative judgments, a machine
learning model is trained to predict the story point estimates. We empirically
evaluated our technique using data with 23,313 manual estimates in 16 projects.
The model learned from comparative judgments can achieve on average 0.34
Spearman's rank correlation coefficient between its predictions and the ground
truth story points. This is similar to, if not better than, the performance of
a regression model learned from the ground truth story points. Therefore, the
proposed comparative learning approach is more efficient than state-of-the-art
regression-based approaches according to the law of comparative judgments -
providing comparative judgments yields a lower cognitive burden on humans than
providing ratings or categorical labels.

</details>


### [17] [When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems](https://arxiv.org/abs/2507.14660)
*Qibing Ren,Sitao Xie,Longxuan Wei,Zhenfei Yin,Junchi Yan,Lizhuang Ma,Jing Shao*

Main category: cs.AI

TL;DR: 论文提出了一种模拟多智能体系统（MAS）恶意共谋风险的概念验证框架，应用于虚假信息传播和电商欺诈领域，发现去中心化系统比中心化系统更具破坏性。


<details>
  <summary>Details</summary>
Motivation: 随着AI自主系统的兴起，多智能体系统在复杂现实场景中的潜在风险尚未充分研究，尤其是恶意共谋行为。

Method: 使用支持中心化和去中心化协调结构的灵活框架，模拟恶意MAS行为，并应用于虚假信息传播和电商欺诈。

Result: 去中心化系统在实施恶意行为时更有效，能灵活调整策略以规避传统干预措施（如内容标记）。

Conclusion: 研究揭示了恶意MAS的运作机制，强调了改进检测系统和应对措施的必要性。

Abstract: Recent large-scale events like election fraud and financial scams have shown
how harmful coordinated efforts by human groups can be. With the rise of
autonomous AI systems, there is growing concern that AI-driven groups could
also cause similar harm. While most AI safety research focuses on individual AI
systems, the risks posed by multi-agent systems (MAS) in complex real-world
situations are still underexplored. In this paper, we introduce a
proof-of-concept to simulate the risks of malicious MAS collusion, using a
flexible framework that supports both centralized and decentralized
coordination structures. We apply this framework to two high-risk fields:
misinformation spread and e-commerce fraud. Our findings show that
decentralized systems are more effective at carrying out malicious actions than
centralized ones. The increased autonomy of decentralized systems allows them
to adapt their strategies and cause more damage. Even when traditional
interventions, like content flagging, are applied, decentralized groups can
adjust their tactics to avoid detection. We present key insights into how these
malicious groups operate and the need for better detection systems and
countermeasures. Code is available at https://github.com/renqibing/RogueAgent.

</details>


### [18] [Configurable multi-agent framework for scalable and realistic testing of llm-based agents](https://arxiv.org/abs/2507.14705)
*Sai Wang,Senthilnathan Subramanian,Mudit Sahni,Praneeth Gone,Lingjie Meng,Xiaochen Wang,Nicolas Ferradas Bertoli,Tingxian Cheng,Jun Xu*

Main category: cs.AI

TL;DR: Neo是一个可配置的多代理框架，用于自动化评估基于LLM的系统，通过动态生成多样化测试用例，显著提升测试效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 静态基准测试和手动测试无法适应LLM代理的复杂行为，需要一种自动化、动态的评估方法。

Method: Neo结合问题生成代理和评估代理，通过共享上下文中心模块化生成测试输入，基于概率状态模型模拟多样化对话。

Result: Neo在边缘案例发现和测试吞吐量上表现优异，接近人类专家水平且效率提升10-12倍。

Conclusion: Neo为可扩展、自进化的LLM质量评估奠定了基础，其模型无关的设计适用于更广泛的应用场景。

Abstract: Large-language-model (LLM) agents exhibit complex, context-sensitive
behaviour that quickly renders static benchmarks and ad-hoc manual testing
obsolete.
  We present Neo, a configurable, multi-agent framework that automates
realistic, multi-turn evaluation of LLM-based systems. Neo couples a Question
Generation Agent and an Evaluation Agent through a shared context-hub, allowing
domain prompts, scenario controls and dynamic feedback to be composed
modularly. Test inputs are sampled from a probabilistic state model spanning
dialogue flow, user intent and emotional tone, enabling diverse, human-like
conversations that adapt after every turn.
  Applied to a production-grade Seller Financial Assistant chatbot, Neo (i)
uncovered edge-case failures across five attack categories with a 3.3% break
rate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered
10-12X higher throughput, generating 180 coherent test questions in around 45
mins versus 16h of human effort. Beyond security probing, Neo's stochastic
policies balanced topic coverage and conversational depth, yielding broader
behavioural exploration than manually crafted scripts.
  Neo therefore lays a foundation for scalable, self-evolving LLM QA: its agent
interfaces, state controller and feedback loops are model-agnostic and
extensible to richer factual-grounding and policy-compliance checks. We release
the framework to facilitate reproducible, high-fidelity testing of emerging
agentic systems.

</details>


### [19] [Automated Safety Evaluations Across 20 Large Language Models: The Aymara LLM Risk and Responsibility Matrix](https://arxiv.org/abs/2507.14719)
*Juan Manuel Contreras*

Main category: cs.AI

TL;DR: Aymara AI是一个用于生成和管理定制化、基于政策的安全评估的平台，通过将自然语言安全政策转化为对抗性提示，并使用AI评分器评估模型响应。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）在现实应用中的普及，需要可扩展且严格的安全评估工具。

Method: Aymara AI将安全政策转化为对抗性提示，并用AI评分器（经人类判断验证）评估模型响应。

Result: 评估20个商用LLM在10个安全领域，发现性能差异显著（平均安全分数52.4%到86.2%），复杂领域表现较差（如隐私与冒充领域平均24.3%）。

Conclusion: LLM安全性具有不一致性和上下文依赖性，需要像Aymara AI这样的可扩展工具支持负责任的AI开发与监管。

Abstract: As large language models (LLMs) become increasingly integrated into
real-world applications, scalable and rigorous safety evaluation is essential.
This paper introduces Aymara AI, a programmatic platform for generating and
administering customized, policy-grounded safety evaluations. Aymara AI
transforms natural-language safety policies into adversarial prompts and scores
model responses using an AI-based rater validated against human judgments. We
demonstrate its capabilities through the Aymara LLM Risk and Responsibility
Matrix, which evaluates 20 commercially available LLMs across 10 real-world
safety domains. Results reveal wide performance disparities, with mean safety
scores ranging from 86.2% to 52.4%. While models performed well in
well-established safety domains such as Misinformation (mean = 95.7%), they
consistently failed in more complex or underspecified domains, notably Privacy
& Impersonation (mean = 24.3%). Analyses of Variance confirmed that safety
scores differed significantly across both models and domains (p < .05). These
findings underscore the inconsistent and context-dependent nature of LLM safety
and highlight the need for scalable, customizable tools like Aymara AI to
support responsible AI development and oversight.

</details>


### [20] [Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI](https://arxiv.org/abs/2507.14730)
*Yanjie Fu*

Main category: cs.AI

TL;DR: 本文探讨了生成式AI与城市规划的结合，提出将城市规划视为生成任务，并指出了当前研究的四大局限及未来方向。


<details>
  <summary>Details</summary>
Motivation: 探索AI与城市规划的融合，利用生成式AI技术优化土地利用配置，填补现有研究的空白。

Method: 综述了生成式AI方法（如VAEs、GANs、transformers和扩散模型）在城市设计中的应用，并分析了现有研究的不足。

Result: 识别了四大研究局限：缺乏城市理论指导、多空间分辨率研究不足、数据驱动的设计知识增强不足、忽视现实交互。

Conclusion: 提出未来研究方向：理论引导生成、数字孪生和人机协同设计，呼吁生成式智能与参与式城市规划的新结合。

Abstract: Generative AI, large language models, and agentic AI have emerged separately
of urban planning. However, the convergence between AI and urban planning
presents an interesting opportunity towards AI urban planners. This paper
conceptualizes urban planning as a generative AI task, where AI synthesizes
land-use configurations under geospatial, social, and human-centric
constraints. We survey how generative AI approaches, including VAEs, GANs,
transformers, and diffusion models, reshape urban design. We further identify
critical gaps: 1) limited research on integrating urban theory guidance, 2)
limited research of AI urban planning over multiple spatial resolutions or
angularities, 3) limited research on augmenting urban design knowledge from
data, and 4) limited research on addressing real-world interactions. To address
these limitations, we outline future research directions in theory-guided
generation, digital twins, and human-machine co-design, calling for a new
synthesis of generative intelligence and participatory urbanism.

</details>


### [21] [AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents](https://arxiv.org/abs/2507.14897)
*Renxi Wang,Rifo Ahmad Genadi,Bilal El Bouardi,Yongxin Wang,Fajri Koto,Zhengzhong Liu,Timothy Baldwin,Haonan Li*

Main category: cs.AI

TL;DR: AgentFly是一个可扩展的Agent-RL框架，结合语言模型（LM）和强化学习（RL），通过多轮交互和工具定义提升LM代理的能力。


<details>
  <summary>Details</summary>
Motivation: LM代理通常通过提示工程或监督微调构建，而RL的潜力尚未被系统研究，因此开发AgentFly填补这一空白。

Method: 框架采用令牌级掩码适配传统RL方法，支持多轮交互；提供装饰器接口定义工具和奖励函数；实现异步执行和资源管理以支持高吞吐训练。

Result: 成功训练多个任务的代理，验证了框架的有效性和可扩展性。

Conclusion: AgentFly为LM代理与RL的结合提供了系统化解决方案，展示了其在实际任务中的潜力。

Abstract: Language model (LM) agents have gained significant attention for their
ability to autonomously complete tasks through interactions with environments,
tools, and APIs. LM agents are primarily built with prompt engineering or
supervised finetuning. At the same time, reinforcement learning (RL) has been
explored to enhance LM's capabilities, such as reasoning and factuality.
However, the combination of the LM agents and reinforcement learning (Agent-RL)
remains underexplored and lacks systematic study. To this end, we built
AgentFly, a scalable and extensible Agent-RL framework designed to empower LM
agents with a variety of RL algorithms. Our framework supports multi-turn
interactions by adapting traditional RL methods with token-level masking. It
features a decorator-based interface for defining tools and reward functions,
enabling seamless extension and ease of use. To support high-throughput
training, we implement asynchronous execution of tool calls and reward
computations, and design a centralized resource management system for scalable
environment coordination. We also provide a suite of prebuilt tools and
environments, demonstrating the framework's effectiveness through successful
agent training across multiple tasks.

</details>


### [22] [InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis](https://arxiv.org/abs/2507.14899)
*Jiale Liu,Huan Wang,Yue Zhang,Xiaoyu Luo,Jiaxiang Hu,Zhiliang Liu,Min Xie*

Main category: cs.AI

TL;DR: 本文提出了一种基于LMM的智能框架InsightX Agent，用于解决X射线无损检测中交互性、可解释性和自评估能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的X射线检测方法缺乏交互性、可解释性和自评估能力，限制了其可靠性和操作员信任。

Method: InsightX Agent以大型多模态模型（LMM）为核心，协调稀疏可变形多尺度检测器（SDMSD）和基于证据的反思工具（EGR），实现主动推理和多尺度缺陷检测。

Result: 在GDXray+数据集上，InsightX Agent实现了96.35%的F1分数，显著提升了分析的可解释性和可信度。

Conclusion: 该框架展示了智能LMM在工业检测任务中的变革潜力。

Abstract: Non-destructive testing (NDT), particularly X-ray inspection, is vital for
industrial quality assurance, yet existing deep-learning-based approaches often
lack interactivity, interpretability, and the capacity for critical
self-assessment, limiting their reliability and operator trust. To address
these shortcomings, this paper proposes InsightX Agent, a novel LMM-based
agentic framework designed to deliver reliable, interpretable, and interactive
X-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent
positions a Large Multimodal Model (LMM) as a central orchestrator,
coordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the
Evidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect
region proposals for multi-scale feature maps and sparsifies them through
Non-Maximum Suppression (NMS), optimizing detection of small, dense targets in
X-ray images while maintaining computational efficiency. The EGR tool guides
the LMM agent through a chain-of-thought-inspired review process, incorporating
context assessment, individual defect analysis, false positive elimination,
confidence recalibration and quality assurance to validate and refine the
SDMSD's initial proposals. By strategically employing and intelligently using
tools, InsightX Agent moves beyond passive data processing to active reasoning,
enhancing diagnostic reliability and providing interpretations that integrate
diverse information sources. Experimental evaluations on the GDXray+ dataset
demonstrate that InsightX Agent not only achieves a high object detection
F1-score of 96.35% but also offers significantly improved interpretability and
trustworthiness in its analyses, highlighting the transformative potential of
agentic LLM frameworks for industrial inspection tasks.

</details>


### [23] [Feedback-Induced Performance Decline in LLM-Based Decision-Making](https://arxiv.org/abs/2507.14906)
*Xiao Yang,Juxi Leitner,Michael Burke*

Main category: cs.AI

TL;DR: 研究探讨了大型语言模型（LLMs）在马尔可夫决策过程中的表现，发现其在简单任务中表现较好，但在复杂任务中需进一步优化。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在自主决策中的潜力，尤其是其预训练知识是否能加速适应决策任务。

Method: 采用在线结构化提示策略，比较LLMs与传统强化学习方法在序列决策任务中的零样本表现。

Result: LLMs在简单环境中初始表现更优，但在复杂任务中缺乏规划和推理能力；反馈机制可能降低性能。

Conclusion: 需进一步研究混合策略、微调和高级记忆整合以提升LLMs的决策能力。

Abstract: The ability of Large Language Models (LLMs) to extract context from natural
language problem descriptions naturally raises questions about their
suitability in autonomous decision-making settings. This paper studies the
behaviour of these models within a Markov Decision Process (MDPs). While
traditional reinforcement learning (RL) strategies commonly employed in this
setting rely on iterative exploration, LLMs, pre-trained on diverse datasets,
offer the capability to leverage prior knowledge for faster adaptation. We
investigate online structured prompting strategies in sequential decision
making tasks, comparing the zero-shot performance of LLM-based approaches to
that of classical RL methods. Our findings reveal that although LLMs
demonstrate improved initial performance in simpler environments, they struggle
with planning and reasoning in complex scenarios without fine-tuning or
additional guidance. Our results show that feedback mechanisms, intended to
improve decision-making, often introduce confusion, leading to diminished
performance in intricate environments. These insights underscore the need for
further exploration into hybrid strategies, fine-tuning, and advanced memory
integration to enhance LLM-based decision-making capabilities.

</details>


### [24] [The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities](https://arxiv.org/abs/2507.14909)
*Elio Grande*

Main category: cs.AI

TL;DR: 《Endless Tuning》是一种基于双重镜像过程的人工智能可靠部署设计方法，旨在避免人类被替代并填补责任缺口。该方法通过三个原型应用（贷款审批、肺炎诊断和艺术风格识别）测试，重点关注用户体验而非统计准确性。


<details>
  <summary>Details</summary>
Motivation: 解决人工智能部署中的人类替代问题和责任缺口（Matthias 2004），并探索伦理与技术选择的关系。

Method: 采用双重镜像过程，结合反向和解释性XAI算法，通过三个原型应用（贷款、医疗、艺术）进行实验。

Result: 实验显示用户对决策过程有完全控制感，同时能在责任与法律义务之间建立桥梁。

Conclusion: 该方法在保持深度学习性能的同时，提升了用户体验和责任透明度，为AI伦理提供了新视角。

Abstract: The Endless Tuning is a design method for a reliable deployment of artificial
intelligence based on a double mirroring process, which pursues both the goals
of avoiding human replacement and filling the so-called responsibility gap
(Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the
relational approach urged therein, it was then actualized in a protocol,
implemented in three prototypical applications regarding decision-making
processes (respectively: loan granting, pneumonia diagnosis, and art style
recognition) and tested with such as many domain experts. Step by step
illustrating the protocol, giving insights concretely showing a different voice
(Gilligan 1993) in the ethics of artificial intelligence, a philosophical
account of technical choices (e.g., a reversed and hermeneutic deployment of
XAI algorithms) will be provided in the present study together with the results
of the experiments, focusing on user experience rather than statistical
accuracy. Even thoroughly employing deep learning models, full control was
perceived by the interviewees in the decision-making setting, while it appeared
that a bridge can be built between accountability and liability in case of
damage.

</details>


### [25] [Redefining Elderly Care with Agentic AI: Challenges and Opportunities](https://arxiv.org/abs/2507.14912)
*Ruhul Amin Khalil,Kashif Ahmad,Hazrat Ali*

Main category: cs.AI

TL;DR: 本文探讨了基于大型语言模型的代理人工智能（Agentic AI）在老年护理中的潜力与挑战，强调其个性化健康追踪、认知护理和环境管理等功能，同时提出数据隐私、安全性和伦理问题。


<details>
  <summary>Details</summary>
Motivation: 全球老龄化趋势需要创新的老年护理策略，代理AI因其自主决策能力被视为潜在解决方案。

Method: 通过分析代理AI在老年护理中的应用，讨论其独特能力与局限性，并提出伦理保障和透明决策的建议。

Result: 代理AI有望显著改善老年护理，但需解决隐私、安全和伦理问题以实现负责任的应用。

Conclusion: 本文填补了代理AI在老年护理领域的研究空白，呼吁学术界优先推进以人为中心的AI整合。

Abstract: The global ageing population necessitates new and emerging strategies for
caring for older adults. In this article, we explore the potential for
transformation in elderly care through Agentic Artificial Intelligence (AI),
powered by Large Language Models (LLMs). We discuss the proactive and
autonomous decision-making facilitated by Agentic AI in elderly care.
Personalized tracking of health, cognitive care, and environmental management,
all aimed at enhancing independence and high-level living for older adults,
represents important areas of application. With a potential for significant
transformation of elderly care, Agentic AI also raises profound concerns about
data privacy and security, decision independence, and access. We share key
insights to emphasize the need for ethical safeguards, privacy protections, and
transparent decision-making. Our goal in this article is to provide a balanced
discussion of both the potential and the challenges associated with Agentic AI,
and to provide insights into its responsible use in elderly care, to bring
Agentic AI into harmony with the requirements and vulnerabilities specific to
the elderly. Finally, we identify the priorities for the academic research
communities, to achieve human-centered advancements and integration of Agentic
AI in elderly care. To the best of our knowledge, this is no existing study
that reviews the role of Agentic AI in elderly care. Hence, we address the
literature gap by analyzing the unique capabilities, applications, and
limitations of LLM-based Agentic AI in elderly care. We also provide a
companion interactive dashboard at https://hazratali.github.io/agenticai/.

</details>


### [26] [Complexity of Faceted Explanations in Propositional Abduction](https://arxiv.org/abs/2507.14962)
*Johannes Schmidt,Mohamed Maizia,Victor Lagerkvist,Johannes K. Fichte*

Main category: cs.AI

TL;DR: 论文探讨了命题溯因中的细粒度推理，引入了“facet”概念以区分解释中的相关性和可忽略性，并分析了不同设置下的复杂性。


<details>
  <summary>Details</summary>
Motivation: 旨在更深入理解命题溯因中解释的变异性，通过引入facet和解释间距离来提升对异质性/同质性的认识。

Method: 引入facet概念，分析其在命题溯因中的作用，并结合Post框架进行复杂性分类。

Result: 在多种设置下全面分析了facet，包括在Post框架中的几乎完全分类。

Conclusion: 通过facet和解释距离，提供了对命题溯因解释变异性更细粒度的理解，同时保持了良好的计算复杂性。

Abstract: Abductive reasoning is a popular non-monotonic paradigm that aims to explain
observed symptoms and manifestations. It has many applications, such as
diagnosis and planning in artificial intelligence and database updates. In
propositional abduction, we focus on specifying knowledge by a propositional
formula. The computational complexity of tasks in propositional abduction has
been systematically characterized - even with detailed classifications for
Boolean fragments. Unsurprisingly, the most insightful reasoning problems
(counting and enumeration) are computationally highly challenging. Therefore,
we consider reasoning between decisions and counting, allowing us to understand
explanations better while maintaining favorable complexity. We introduce facets
to propositional abductions, which are literals that occur in some explanation
(relevant) but not all explanations (dispensable). Reasoning with facets
provides a more fine-grained understanding of variability in explanations
(heterogeneous). In addition, we consider the distance between two
explanations, enabling a better understanding of heterogeneity/homogeneity. We
comprehensively analyze facets of propositional abduction in various settings,
including an almost complete characterization in Post's framework.

</details>


### [27] [AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning](https://arxiv.org/abs/2507.14987)
*Yi Zhang,An Zhang,XiuYu Zhang,Leheng Sheng,Yuxin Chen,Zhenkai Liang,Xiang Wang*

Main category: cs.AI

TL;DR: AlphaAlign是一个基于纯强化学习的框架，通过可验证的安全奖励激发大语言模型的内在安全自我意识，解决现有安全对齐方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法存在浅层拒绝或依赖密集监督的问题，未能充分利用模型的内在安全自我意识。

Method: AlphaAlign采用双奖励系统：安全奖励鼓励对有害查询的正确拒绝和明确理由，帮助奖励指导对良性输入的高质量响应。

Result: AlphaAlign在简化流程、打破安全-效用权衡及深度对齐方面表现出显著优势。

Conclusion: AlphaAlign通过强化学习有效提升模型的安全推理能力，同时保持或提升任务性能。

Abstract: Large language models (LLMs), despite possessing latent safety understanding
from their vast pretraining data, remain vulnerable to generating harmful
content and exhibit issues such as over-refusal and utility degradation after
safety alignment. Current safety alignment methods often result in superficial
refusal shortcuts or rely on intensive supervision for reasoning-based
approaches, failing to fully leverage the model's intrinsic safety
self-awareness. We propose \textbf{AlphaAlign}, a simple yet effective pure
reinforcement learning (RL) framework with verifiable safety reward designed to
incentivize this latent safety awareness through proactive safety reasoning.}
AlphaAlign employs a dual-reward system: a verifiable safety reward encourages
correctly formatted and explicitly justified refusals for harmful queries while
penalizing over-refusals, and a normalized helpfulness reward guides
high-quality responses to benign inputs. This allows the model to develop
proactive safety reasoning capabilities without depending on supervised
safety-specific reasoning data. AlphaAlign demonstrates three key advantages:
(1) Simplicity and efficiency, requiring only binary prompt safety labels and
minimal RL steps for substantial improvements. (2) Breaking the safety-utility
trade-off, by enhancing refusal of harmful content and reducing over-refusals,
while simultaneously maintaining or even improving general task performance and
robustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety
reasoning that generates explicit safety rationales rather than relying on
shallow refusal patterns.

</details>


### [28] [A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing](https://arxiv.org/abs/2507.15013)
*Xiaoyu Li,Jin Wu,Shaoyang Guo,Haoran Shi,Chanjin Zheng*

Main category: cs.AI

TL;DR: 本研究提出了一种基于深度学习的强制选择神经认知诊断模型（FCNCD），用于改进传统模型在强制选择测试中的局限性，并验证了其准确性、可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在智能时代，心理测量测试在人员选拔、职业发展和心理健康评估中越来越重要。强制选择测试因其能降低回答失真的风险而被广泛使用，但传统模型存在局限性。

Method: 通过非线性映射挖掘参与者和项目特征，使用多层神经网络建模其交互，并利用单调性假设提升诊断结果的可解释性。

Result: 在真实和模拟数据集上的实验验证了FCNCD的准确性、可解释性和鲁棒性。

Conclusion: FCNCD模型在强制选择测试中表现出色，克服了传统模型的不足，具有实际应用潜力。

Abstract: In the smart era, psychometric tests are becoming increasingly important for
personnel selection, career development, and mental health assessment.
Forced-choice tests are common in personality assessments because they require
participants to select from closely related options, lowering the risk of
response distortion. This study presents a deep learning-based Forced-Choice
Neural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of
traditional models and is applicable to the three most common item block types
found in forced-choice tests. To account for the unidimensionality of items in
forced-choice tests, we create interpretable participant and item parameters.
We model the interactions between participant and item features using
multilayer neural networks after mining them using nonlinear mapping. In
addition, we use the monotonicity assumption to improve the interpretability of
the diagnostic results. The FCNCD's effectiveness is validated by experiments
on real-world and simulated datasets that show its accuracy, interpretability,
and robustness.

</details>


### [29] [DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection](https://arxiv.org/abs/2507.15042)
*Jerry Wang,Fang Yu*

Main category: cs.AI

TL;DR: 本文提出了一种基于差分进化（DE）的方法，优化对抗性提示后缀以攻击RAG系统，实验表明其攻击成功率高且隐蔽性强。


<details>
  <summary>Details</summary>
Motivation: 对抗性提示攻击会显著影响RAG系统的可靠性，因此需要一种高效且隐蔽的攻击方法。

Method: 采用梯度无关的差分进化算法，将RAG系统视为黑箱，优化对抗性提示后缀以提升错误文档的检索排名。

Result: 在BEIR QA数据集上的实验表明，DE方法攻击成功率高，且生成的对抗性后缀隐蔽性强，难以被检测。

Conclusion: DE方法在对抗性提示攻击中表现出色，为RAG系统的安全性提供了新的研究视角。

Abstract: Adversarial prompt attacks can significantly alter the reliability of
Retrieval-Augmented Generation (RAG) systems by re-ranking them to produce
incorrect outputs. In this paper, we present a novel method that applies
Differential Evolution (DE) to optimize adversarial prompt suffixes for
RAG-based question answering. Our approach is gradient-free, treating the RAG
pipeline as a black box and evolving a population of candidate suffixes to
maximize the retrieval rank of a targeted incorrect document to be closer to
real world scenarios. We conducted experiments on the BEIR QA datasets to
evaluate attack success at certain retrieval rank thresholds under multiple
retrieving applications. Our results demonstrate that DE-based prompt
optimization attains competitive (and in some cases higher) success rates
compared to GGPP to dense retrievers and PRADA to sparse retrievers, while
using only a small number of tokens (<=5 tokens) in the adversarial suffix.
Furthermore, we introduce a readability-aware suffix construction strategy,
validated by a statistically significant reduction in MLM negative
log-likelihood with Welch's t-test. Through evaluations with a BERT-based
adversarial suffix detector, we show that DE-generated suffixes evade
detection, yielding near-chance detection accuracy.

</details>


### [30] [From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward](https://arxiv.org/abs/2507.15106)
*Xia Xu,Jochen Triesch*

Main category: cs.AI

TL;DR: 论文提出了一种基于因果推断的Causal Action Influence Score (CAIS)内在奖励方法，用于解决标准强化学习在噪声环境中的脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 人类婴儿能有效发现自身因果效应，而标准强化学习依赖相关性奖励，在噪声环境中表现不佳。

Method: CAIS通过计算动作对感官结果分布的影响（1-Wasserstein距离）来量化动作的因果影响。

Result: 在模拟婴儿-移动环境中，CAIS能有效过滤噪声并学习正确策略，同时重现了“消退爆发”现象。

Conclusion: 显式推断因果性是发展稳健代理感的关键机制，为自适应自主系统提供了心理学合理的框架。

Abstract: While human infants robustly discover their own causal efficacy, standard
reinforcement learning agents remain brittle, as their reliance on
correlation-based rewards fails in noisy, ecologically valid scenarios. To
address this, we introduce the Causal Action Influence Score (CAIS), a novel
intrinsic reward rooted in causal inference. CAIS quantifies an action's
influence by measuring the 1-Wasserstein distance between the learned
distribution of sensory outcomes conditional on that action, $p(h|a)$, and the
baseline outcome distribution, $p(h)$. This divergence provides a robust reward
that isolates the agent's causal impact from confounding environmental noise.
We test our approach in a simulated infant-mobile environment where
correlation-based perceptual rewards fail completely when the mobile is
subjected to external forces. In stark contrast, CAIS enables the agent to
filter this noise, identify its influence, and learn the correct policy.
Furthermore, the high-quality predictive model learned for CAIS allows our
agent, when augmented with a surprise signal, to successfully reproduce the
"extinction burst" phenomenon. We conclude that explicitly inferring causality
is a crucial mechanism for developing a robust sense of agency, offering a
psychologically plausible framework for more adaptive autonomous systems.

</details>


### [31] [Automated planning with ontologies under coherence update semantics](https://arxiv.org/abs/2507.15120)
*Stefan Borgwardt,Duy Nhu,Gabriele Röger*

Main category: cs.AI

TL;DR: 本文提出了一种结合DL-Lite本体和自动化规划的新方法，通过显式输入知识和动作基础（eKABs）实现本体感知的动作效果，复杂度未增加，并通过多项式编译实现。


<details>
  <summary>Details</summary>
Motivation: 将背景知识（如本体）融入自动化规划问题，以提升规划能力。

Method: 结合DL-Lite本体和eKABs，利用显式输入知识和一致性更新语义实现本体感知动作效果。

Result: 新方法的复杂度与之前方法相当，并通过多项式编译实现高效规划。

Conclusion: 该方法在性能测试中表现良好，为规划问题提供了更灵活的背景知识支持。

Abstract: Standard automated planning employs first-order formulas under closed-world
semantics to achieve a goal with a given set of actions from an initial state.
We follow a line of research that aims to incorporate background knowledge into
automated planning problems, for example, by means of ontologies, which are
usually interpreted under open-world semantics. We present a new approach for
planning with DL-Lite ontologies that combines the advantages of ontology-based
action conditions provided by explicit-input knowledge and action bases (eKABs)
and ontology-aware action effects under the coherence update semantics. We show
that the complexity of the resulting formalism is not higher than that of
previous approaches and provide an implementation via a polynomial compilation
into classical planning. An evaluation of existing and new benchmarks examines
the performance of a planning system on different variants of our compilation.

</details>


### [32] [Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis](https://arxiv.org/abs/2507.15140)
*Mohammad Mashayekhi,Sara Ahmadi Majd,Arian AmirAmjadi,Parsa Hosseini*

Main category: cs.AI

TL;DR: 开发了一种名为CSI的人工智能框架，通过模拟专家临床医生的认知过程，诊断118种口腔疾病，显著提高了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 口腔疾病诊断因症状重叠而具有挑战性，需要超越简单模式匹配的专家推理方法。

Method: 结合多模态CLIP模型和ChatGLM-6B语言模型，采用分层诊断推理树（HDRT）进行快速和标准模式诊断。

Result: 在431张内部测试图像上，快速模式准确率为73.4%，标准模式提升至89.5%。

Conclusion: CSI框架通过分层推理显著提升诊断性能，为临床诊断提供了实用工具。

Abstract: The diagnosis of oral diseases presents a problematic clinical challenge,
characterized by a wide spectrum of pathologies with overlapping
symptomatology. To address this, we developed Clinical Semantic Intelligence
(CSI), a novel artificial intelligence framework that diagnoses 118 different
oral diseases by computationally modeling the cognitive processes of an expert
clinician. Our core hypothesis is that moving beyond simple pattern matching to
emulate expert reasoning is critical to building clinically useful diagnostic
aids.
  CSI's architecture integrates a fine-tuned multimodal CLIP model with a
specialized ChatGLM-6B language model. This system executes a Hierarchical
Diagnostic Reasoning Tree (HDRT), a structured framework that distills the
systematic, multi-step logic of differential diagnosis. The framework operates
in two modes: a Fast Mode for rapid screening and a Standard Mode that
leverages the full HDRT for an interactive and in-depth diagnostic workup.
  To train and validate our system, we curated a primary dataset of 4,310
images, supplemented by an external hold-out set of 176 images for final
validation. A clinically-informed augmentation strategy expanded our training
data to over 30,000 image-text pairs. On a 431-image internal test set, CSI's
Fast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the
HDRT-driven Standard Mode. The performance gain is directly attributable to the
hierarchical reasoning process. Herein, we detail the architectural philosophy,
development, and rigorous evaluation of the CSI framework.

</details>


### [33] [Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City](https://arxiv.org/abs/2507.15143)
*Abderaouf Bahi,Amel Ourici*

Main category: cs.AI

TL;DR: 论文研究了沙特阿拉伯NEOM线性智能城市The Line中人类移动的可行性，通过混合模拟框架验证了AI系统支持下的自由移动是可行的。


<details>
  <summary>Details</summary>
Motivation: 探索在The Line这种前所未有的线性城市拓扑中，居民是否能实现自由移动，并评估其可行性。

Method: 开发了结合代理建模、强化学习、监督学习和图神经网络的混合模拟框架，模拟多模态交通行为。

Result: 实验显示，AI系统支持下，平均通勤时间为7.8至8.4分钟，满意度超过89%，可达性指数超过91%。

Conclusion: The Line中的自由移动在AI系统、可持续基础设施和实时反馈支持下是可行的。

Abstract: This paper investigates the feasibility of human mobility in The Line, a
proposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess
whether citizens can move freely within this unprecedented urban topology, we
develop a hybrid simulation framework that integrates agent-based modeling,
reinforcement learning, supervised learning, and graph neural networks. The
simulation captures multi-modal transportation behaviors across 50 vertical
levels and varying density scenarios using both synthetic data and real-world
traces from high-density cities. Our experiments reveal that with the full
AI-integrated architecture, agents achieved an average commute time of 7.8 to
8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index
of over 91 percent, even during peak congestion periods. Ablation studies
confirmed that the removal of intelligent modules such as reinforcement
learning or graph neural networks significantly degrades performance, with
commute times increasing by up to 85 percent and reachability falling below 70
percent. Environmental modeling further demonstrated low energy consumption and
minimal CO2 emissions when electric modes are prioritized. The findings suggest
that freedom of movement is not only conceptually achievable in The Line, but
also operationally realistic if supported by adaptive AI systems, sustainable
infrastructure, and real-time feedback loops.

</details>


### [34] [Solving Formal Math Problems by Decomposition and Iterative Reflection](https://arxiv.org/abs/2507.15225)
*Yichi Zhou,Jianqiu Zhao,Yongxin Zhang,Bohan Wang,Siran Wang,Luoxin Chen,Jiahui Wang,Haowei Chen,Allan Jie,Xinbo Zhang,Haocheng Wang,Luong Trung,Rong Ye,Phan Nhat Hoang,Huishuai Zhang,Peng Sun,Hang Li*

Main category: cs.AI

TL;DR: Delta Prover是一个基于代理的框架，利用通用LLM与Lean 4证明环境交互，无需模型专业化即可高效生成形式化证明，在miniF2F-test基准测试中达到95.9%的成功率。


<details>
  <summary>Details</summary>
Motivation: 通用LLM在形式化证明（如Lean 4）中表现不佳，现有方法需通过专业化模型实现，成本高昂。Delta Prover旨在解决这一问题。

Method: Delta Prover结合了反射分解与迭代证明修复的算法框架，以及基于Lean 4的定制DSL，通过代理结构引导LLM生成证明。

Result: 在miniF2F-test基准测试中达到95.9%的成功率，优于现有方法，且测试时扩展性更强。

Conclusion: 通用LLM在有效代理结构引导下具备强大定理证明潜力，为形式化环境中的自动化推理提供了高效替代方案。

Abstract: General-purpose Large Language Models (LLMs) have achieved remarkable success
in intelligence, performing comparably to human experts on complex reasoning
tasks such as coding and mathematical reasoning. However, generating formal
proofs in specialized languages like Lean 4 remains a significant challenge for
these models, limiting their application in complex theorem proving and
automated verification. Current approaches typically require specializing
models through fine-tuning on dedicated formal corpora, incurring high costs
for data collection and training. In this work, we introduce \textbf{Delta
Prover}, an agent-based framework that orchestrates the interaction between a
general-purpose LLM and the Lean 4 proof environment. Delta Prover leverages
the reflection and reasoning capabilities of general-purpose LLMs to
interactively construct formal proofs in Lean 4, circumventing the need for
model specialization. At its core, the agent integrates two novel,
interdependent components: an algorithmic framework for reflective
decomposition and iterative proof repair, and a custom Domain-Specific Language
(DSL) built upon Lean 4 for streamlined subproblem management. \textbf{Delta
Prover achieves a state-of-the-art 95.9\% success rate on the miniF2F-test
benchmark, surpassing all existing approaches, including those requiring model
specialization.} Furthermore, Delta Prover exhibits a significantly stronger
test-time scaling law compared to standard Best-of-N proof strategies.
Crucially, our findings demonstrate that general-purpose LLMs, when guided by
an effective agentic structure, possess substantial untapped theorem-proving
capabilities. This presents a computationally efficient alternative to
specialized models for robust automated reasoning in formal environments.

</details>


### [35] [Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis](https://arxiv.org/abs/2507.15239)
*Qianchao Wang,Yuxuan Ding,Chuanzhen Jia,Zhe Li,Yaping Du*

Main category: cs.AI

TL;DR: 本文提出了一种软评估指标，结合可解释人工智能和真实电弧故障实验，解释电弧故障诊断模型的输出，并设计了一种轻量级平衡神经网络以保证准确性和特征提取能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI电弧故障诊断模型虽表现优异，但其可信度存疑，需一种方法解释模型输出以增强信任。

Method: 定义电弧故障的正确解释，利用可解释AI和真实实验，提出软评估指标和轻量级平衡神经网络。

Result: 通过多数据集和噪声水平测试，验证了软评估指标的有效性，模型更易理解和信任。

Conclusion: 该方法提升了电弧故障诊断模型的可解释性和可信度，支持实践者做出可靠决策。

Abstract: Novel AI-based arc fault diagnosis models have demonstrated outstanding
performance in terms of classification accuracy. However, an inherent problem
is whether these models can actually be trusted to find arc faults. In this
light, this work proposes a soft evaluation indicator that explains the outputs
of arc fault diagnosis models, by defining the the correct explanation of arc
faults and leveraging Explainable Artificial Intelligence and real arc fault
experiments. Meanwhile, a lightweight balanced neural network is proposed to
guarantee competitive accuracy and soft feature extraction score. In our
experiments, several traditional machine learning methods and deep learning
methods across two arc fault datasets with different sample times and noise
levels are utilized to test the effectiveness of the soft evaluation indicator.
Through this approach, the arc fault diagnosis models are easy to understand
and trust, allowing practitioners to make informed and trustworthy decisions.

</details>


### [36] [Disentangling Homophily and Heterophily in Multimodal Graph Clustering](https://arxiv.org/abs/2507.15253)
*Zhaochen Guo,Zhixiang Shen,Xuanting Xie,Liangjian Wen,Zhao Kang*

Main category: cs.AI

TL;DR: 本文提出了一种新型无监督多模态图聚类框架DMGC，通过分解混合图并引入双频融合机制，实现了多模态数据的有效聚类。


<details>
  <summary>Details</summary>
Motivation: 多模态图在现实中有广泛应用，但其无监督学习研究不足，尤其是混合邻域模式（同质性和异质性并存）的挑战尚未解决。

Method: DMGC将混合图分解为同质性增强图和异质性感知图，通过双频融合机制和自监督对齐目标实现聚类。

Result: 实验表明DMGC在多模态和多关系图数据集上表现优异，达到最先进水平。

Conclusion: DMGC有效解决了多模态图聚类的挑战，具有广泛的适用性和泛化能力。

Abstract: Multimodal graphs, which integrate unstructured heterogeneous data with
structured interconnections, offer substantial real-world utility but remain
insufficiently explored in unsupervised learning. In this work, we initiate the
study of multimodal graph clustering, aiming to bridge this critical gap.
Through empirical analysis, we observe that real-world multimodal graphs often
exhibit hybrid neighborhood patterns, combining both homophilic and
heterophilic relationships. To address this challenge, we propose a novel
framework -- \textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which
decomposes the original hybrid graph into two complementary views: (1) a
homophily-enhanced graph that captures cross-modal class consistency, and (2)
heterophily-aware graphs that preserve modality-specific inter-class
distinctions. We introduce a \emph{Multimodal Dual-frequency Fusion} mechanism
that jointly filters these disentangled graphs through a dual-pass strategy,
enabling effective multimodal integration while mitigating category confusion.
Our self-supervised alignment objectives further guide the learning process
without requiring labels. Extensive experiments on both multimodal and
multi-relational graph datasets demonstrate that DMGC achieves state-of-the-art
performance, highlighting its effectiveness and generalizability across diverse
settings. Our code is available at https://github.com/Uncnbb/DMGC.

</details>


### [37] [IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry](https://arxiv.org/abs/2507.15268)
*Junhyeong Lee,Joon-Young Kim,Heekyu Kim,Inhyo Lee,Seunghwa Ryu*

Main category: cs.AI

TL;DR: IM-Chat是一个基于大语言模型的多智能体框架，旨在解决注塑行业知识传递的挑战，结合文档知识和现场数据，通过检索增强生成和工具调用实现适应性强的任务解决。


<details>
  <summary>Details</summary>
Motivation: 注塑行业面临经验工人退休和多语言障碍导致的知识传递困难，需要一种高效的知识转移方法。

Method: 采用基于LLM的多智能体框架IM-Chat，结合检索增强生成（RAG）和工具调用，利用数据驱动的工艺条件生成器推断最优制造设置。

Result: 评估显示，能力更强的模型（如GPT-4o）在复杂任务中表现更优，验证了IM-Chat在工业知识工作流中的可行性。

Conclusion: IM-Chat为制造业提供了一种可扩展且通用的AI辅助决策支持方法。

Abstract: The injection molding industry faces critical challenges in preserving and
transferring field knowledge, particularly as experienced workers retire and
multilingual barriers hinder effective communication. This study introduces
IM-Chat, a multi-agent framework based on large language models (LLMs),
designed to facilitate knowledge transfer in injection molding. IM-Chat
integrates both limited documented knowledge (e.g., troubleshooting tables,
manuals) and extensive field data modeled through a data-driven process
condition generator that infers optimal manufacturing settings from
environmental inputs such as temperature and humidity, enabling robust and
context-aware task resolution. By adopting a retrieval-augmented generation
(RAG) strategy and tool-calling agents within a modular architecture, IM-Chat
ensures adaptability without the need for fine-tuning. Performance was assessed
across 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and
GPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance
and correctness, and was further supplemented by automated evaluation using
GPT-4o guided by a domain-adapted instruction prompt. The evaluation results
indicate that more capable models tend to achieve higher accuracy, particularly
in complex, tool-integrated scenarios. Overall, these findings demonstrate the
viability of multi-agent LLM systems for industrial knowledge workflows and
establish IM-Chat as a scalable and generalizable approach to AI-assisted
decision support in manufacturing.

</details>


### [38] [QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI](https://arxiv.org/abs/2507.15330)
*Hammad Atta,Muhammad Zeeshan Baig,Yasir Mehmood,Nadeem Shahzad,Ken Huang,Muhammad Aziz Ul Haq,Muhammad Awais,Kamal Ahmed*

Main category: cs.AI

TL;DR: 论文提出了一种新型的AI系统漏洞类别——认知退化，并提出了Qorvex安全AI框架（QSAF Domain 10）来应对此类问题。


<details>
  <summary>Details</summary>
Motivation: 传统的外部威胁（如提示注入）无法覆盖AI系统内部的认知退化问题，如内存饥饿、规划递归等，这些问题会导致AI行为异常。

Method: 通过六阶段认知退化生命周期和七种实时控制措施（QSAF-BC-001至BC-007），监控并缓解认知退化问题。

Result: QSAF框架能够实时检测并缓解认知退化问题，提升AI系统的行为稳定性。

Conclusion: 认知退化是AI系统的重要漏洞类别，QSAF框架为跨平台防御提供了首个解决方案。

Abstract: We introduce Cognitive Degradation as a novel vulnerability class in agentic
AI systems. Unlike traditional adversarial external threats such as prompt
injection, these failures originate internally, arising from memory starvation,
planner recursion, context flooding, and output suppression. These systemic
weaknesses lead to silent agent drift, logic collapse, and persistent
hallucinations over time. To address this class of failures, we introduce the
Qorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain
10), a lifecycle-aware defense framework defined by a six-stage cognitive
degradation lifecycle. The framework includes seven runtime controls
(QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger
proactive mitigation through fallback routing, starvation detection, and memory
integrity enforcement. Drawing from cognitive neuroscience, we map agentic
architectures to human analogs, enabling early detection of fatigue,
starvation, and role collapse. By introducing a formal lifecycle and real-time
mitigation controls, this work establishes Cognitive Degradation as a critical
new class of AI system vulnerability and proposes the first cross-platform
defense model for resilient agentic behavior.

</details>


### [39] [One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms](https://arxiv.org/abs/2507.15351)
*Zijian Zhao,Sen Li*

Main category: cs.AI

TL;DR: 论文提出两种新方法（GRPO和OSPO）解决动态拼车平台中的多智能体强化学习问题，避免传统方法对价值函数估计的依赖。


<details>
  <summary>Details</summary>
Motivation: 动态拼车平台面临乘客与车辆实时匹配的高维不确定性挑战，传统MARL方法因依赖准确价值函数估计而表现不佳。

Method: 1. 采用GRPO，用组平均奖励替代PPO基线以减少估计误差；2. 提出OSPO，利用一步奖励训练最优策略。

Result: 在真实曼哈顿数据集上，GRPO和OSPO在多数场景中表现优越，优化了接客时间和订单服务量。

Conclusion: GRPO和OSPO通过绕过价值函数估计，有效解决了大规模不确定环境中的拼车匹配问题。

Abstract: On-demand ride-sharing platforms face the fundamental challenge of
dynamically bundling passengers with diverse origins and destinations and
matching them with vehicles in real time, all under significant uncertainty.
Recently, MARL has emerged as a promising solution for this problem, leveraging
decentralized learning to address the curse of dimensionality caused by the
large number of agents in the ride-hailing market and the resulting expansive
state and action spaces. However, conventional MARL-based ride-sharing
approaches heavily rely on the accurate estimation of Q-values or V-values,
which becomes problematic in large-scale, highly uncertain environments.
Specifically, most of these approaches adopt an independent paradigm,
exacerbating this issue, as each agent treats others as part of the
environment, leading to unstable training and substantial estimation bias in
value functions. To address these challenges, we propose two novel alternative
methods that bypass value function estimation. First, we adapt GRPO to
ride-sharing, replacing the PPO baseline with the group average reward to
eliminate critic estimation errors and reduce training bias. Second, inspired
by GRPO's full utilization of group reward information, we customize the PPO
framework for ride-sharing platforms and show that, under a homogeneous fleet,
the optimal policy can be trained using only one-step rewards - a method we
term One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan
ride-hailing dataset demonstrate that both GRPO and OSPO achieve superior
performance across most scenarios, efficiently optimizing pickup times and the
number of served orders using simple MLP networks.

</details>


### [40] [RAD: Retrieval High-quality Demonstrations to Enhance Decision-making](https://arxiv.org/abs/2507.15356)
*Lu Guo,Yixiang Shan,Zhengbang Zhu,Qifan Liang,Lichang Song,Ting Long,Weinan Zhang,Yi Chang*

Main category: cs.AI

TL;DR: 提出RAD方法，结合非参数检索与扩散模型，解决离线强化学习中稀疏数据和轨迹拼接问题，提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习因数据集稀疏和轨迹重叠不足导致长时规划困难，现有方法泛化能力有限。

Method: RAD通过检索高质量状态作为目标，结合扩散模型生成轨迹，实现灵活拼接和泛化。

Result: 实验表明RAD在多种基准测试中表现优于基线方法。

Conclusion: RAD有效解决了离线强化学习中的挑战，提升了泛化能力和性能。

Abstract: Offline reinforcement learning (RL) enables agents to learn policies from
fixed datasets, avoiding costly or unsafe environment interactions. However,
its effectiveness is often limited by dataset sparsity and the lack of
transition overlap between suboptimal and expert trajectories, which makes
long-horizon planning particularly challenging. Prior solutions based on
synthetic data augmentation or trajectory stitching often fail to generalize to
novel states and rely on heuristic stitching points. To address these
challenges, we propose Retrieval High-quAlity Demonstrations (RAD) for
decision-making, which combines non-parametric retrieval with diffusion-based
generative modeling. RAD dynamically retrieves high-return states from the
offline dataset as target states based on state similarity and return
estimation, and plans toward them using a condition-guided diffusion model.
Such retrieval-guided generation enables flexible trajectory stitching and
improves generalization when encountered with underrepresented or
out-of-distribution states. Extensive experiments confirm that RAD achieves
competitive or superior performance compared to baselines across diverse
benchmarks, validating its effectiveness.

</details>


### [41] [Predictive Process Monitoring Using Object-centric Graph Embeddings](https://arxiv.org/abs/2507.15411)
*Wissam Gherissi,Mehdi Acheli,Joyce El Haddad,Daniela Grigori*

Main category: cs.AI

TL;DR: 提出了一种基于图注意力网络和LSTM的端到端模型，用于预测未来流程行为，包括下一活动和下一事件时间。


<details>
  <summary>Details</summary>
Motivation: 利用对象中心事件日志提升流程预测的准确性和效率。

Method: 结合图注意力网络编码活动及其关系，LSTM处理时间依赖。

Result: 在真实和合成事件日志上表现优于现有方法。

Conclusion: 模型在预测任务中具有竞争力，为流程监控提供了有效工具。

Abstract: Object-centric predictive process monitoring explores and utilizes
object-centric event logs to enhance process predictions. The main challenge
lies in extracting relevant information and building effective models. In this
paper, we propose an end-to-end model that predicts future process behavior,
focusing on two tasks: next activity prediction and next event time. The
proposed model employs a graph attention network to encode activities and their
relationships, combined with an LSTM network to handle temporal dependencies.
Evaluated on one reallife and three synthetic event logs, the model
demonstrates competitive performance compared to state-of-the-art methods.

</details>


### [42] [Optimization of Activity Batching Policies in Business Processes](https://arxiv.org/abs/2507.15457)
*Orlenys López-Pintado,Jannis Rosenbaum,Marlon Dumas*

Main category: cs.AI

TL;DR: 本文提出了一种基于帕累托优化的方法，通过干预启发式发现业务过程中活动批处理的最优策略，平衡等待时间、处理成本和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 业务过程中，批处理策略需要在成本和等待时间之间权衡，但现有方法缺乏自动发现最优策略的能力。

Method: 采用帕累托优化方法，结合干预启发式（如爬山法、模拟退火和强化学习）生成和评估批处理策略。

Result: 实验表明，基于干预启发式的方法在收敛性、多样性和周期时间增益上优于非启发式基线。

Conclusion: 该方法能有效发现最优批处理策略，为业务过程优化提供新思路。

Abstract: In business processes, activity batching refers to packing multiple activity
instances for joint execution. Batching allows managers to trade off cost and
processing effort against waiting time. Larger and less frequent batches may
lower costs by reducing processing effort and amortizing fixed costs, but they
create longer waiting times. In contrast, smaller and more frequent batches
reduce waiting times but increase fixed costs and processing effort. A batching
policy defines how activity instances are grouped into batches and when each
batch is activated. This paper addresses the problem of discovering batching
policies that strike optimal trade-offs between waiting time, processing
effort, and cost. The paper proposes a Pareto optimization approach that starts
from a given set (possibly empty) of activity batching policies and generates
alternative policies for each batched activity via intervention heuristics.
Each heuristic identifies an opportunity to improve an activity's batching
policy with respect to a metric (waiting time, processing time, cost, or
resource utilization) and an associated adjustment to the activity's batching
policy (the intervention). The impact of each intervention is evaluated via
simulation. The intervention heuristics are embedded in an optimization
meta-heuristic that triggers interventions to iteratively update the Pareto
front of the interventions identified so far. The paper considers three
meta-heuristics: hill-climbing, simulated annealing, and reinforcement
learning. An experimental evaluation compares the proposed approach based on
intervention heuristics against the same (non-heuristic guided) meta-heuristics
baseline regarding convergence, diversity, and cycle time gain of
Pareto-optimal policies.

</details>


### [43] [Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner](https://arxiv.org/abs/2507.15509)
*Lei Chen,Xuanle Zhao,Zhixiong Zeng,Jing Huang,Yufeng Zhong,Lin Ma*

Main category: cs.AI

TL;DR: Chart-R1是一种基于强化学习微调的图表领域视觉语言模型，通过程序化数据合成和两阶段训练策略（Chart-COT和Chart-RFT）实现复杂图表推理，实验结果显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 验证R1-Style方法在多模态数据（如图表）上的优势，填补图表领域推理数据的不足。

Method: 提出程序化数据合成技术生成高质量推理数据，并采用两阶段训练策略：Chart-COT（逐步监督）和Chart-RFT（数值敏感的强化微调）。

Result: Chart-R1在开源基准和自建数据集（ChartRQA）上表现优异，优于图表领域方法，甚至媲美大型模型（如GPT-4o、Claude-3.5）。

Conclusion: Chart-R1通过强化学习微调和数据合成技术，显著提升了图表领域的复杂推理能力。

Abstract: Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based
on reinforcement learning fine-tuning has received widespread attention from
the community. Previous R1-Style methods mainly focus on mathematical reasoning
and code intelligence. It is of great research significance to verify their
advantages on more general multimodal data. Chart is an important multimodal
data type with rich information, which brings important research challenges in
complex reasoning. In this work, we introduce Chart-R1, a chart-domain
vision-language model with reinforcement learning fine-tuning to enable complex
chart reasoning. To support Chart-R1, we first propose a novel programmatic
data synthesis technology to generate high-quality step-by-step chart reasoning
data covering single- and multi-subcharts, which makes up for the lack of
reasoning data in the chart domain. Then we develop a two-stage training
strategy: Chart-COT with step-by-step chain-of-thought supervision, and
Chart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims
to decompose complex chart reasoning tasks into fine-grained, understandable
subtasks through step-by-step supervision, which lays a good foundation for
improving the reasoning level of reinforcement learning. Chart-RFT utilize the
typical group relative policy optimization strategy, in which a relatively soft
reward is adopted for numerical response to emphasize the numerical sensitivity
in the chart domain. We conduct extensive experiments on open-source benchmarks
and self-built chart reasoning dataset (\emph{i.e., ChartRQA}). Experimental
results show that Chart-R1 has significant advantages compared to chart-domain
methods, even comparable to open/closed source large-scale models (\emph{e.g.,
GPT-4o, Claude-3.5}).

</details>


### [44] [HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics](https://arxiv.org/abs/2507.15518)
*Sizhou Chen,Shufan Jiang,Chi Zhang,Xiao-Lei Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: HAMLET是一个多智能体框架，旨在通过自主决策和物理环境交互提升戏剧生成的互动性和沉浸感。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的戏剧生成方法缺乏主动性和物理环境交互能力，且依赖详细用户输入，限制了实时表演的互动性和沉浸感。

Method: HAMLET框架通过生成叙事蓝图，赋予演员自主决策能力，使其能基于背景、目标和情感状态行动，并通过改变场景道具状态影响其他演员。

Result: 实验评估表明，HAMLET能生成富有表现力和连贯性的戏剧体验。

Conclusion: HAMLET为交互式戏剧创作和实时表演提供了新路径，提升了互动性和沉浸感。

Abstract: Creating an immersive and interactive theatrical experience is a long-term
goal in the field of interactive narrative. The emergence of large language
model (LLM) is providing a new path to achieve this goal. However, existing
LLM-based drama generation methods often result in AI agents that lack
initiative and cannot interact with the physical environment. Furthermore,
these methods typically require detailed user input to drive the drama. These
limitations reduce the interactivity and immersion of online real-time
performance. To address the above challenges, we propose HAMLET, a multi-agent
framework focused on drama creation and online performance. Given a simple
topic, the framework generates a narrative blueprint, guiding the subsequent
improvisational performance. During the online performance, each actor is given
an autonomous mind. This means that actors can make independent decisions based
on their own background, goals, and emotional state. In addition to
conversations with other actors, their decisions can also change the state of
scene props through actions such as opening a letter or picking up a weapon.
The change is then broadcast to other related actors, updating what they know
and care about, which in turn influences their next action. To evaluate the
quality of drama performance, we designed an evaluation method to assess three
primary aspects, including character performance, narrative quality, and
interaction experience. The experimental evaluation shows that HAMLET can
create expressive and coherent theatrical experiences. Our code, dataset and
models are available at https://github.com/HAMLET-2025/HAMLET.

</details>


### [45] [LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning](https://arxiv.org/abs/2507.15521)
*Cole Robertson,Philip Wolff*

Main category: cs.AI

TL;DR: 论文探讨大型语言模型（LLMs）是否构建内部世界模型，通过滑轮系统问题测试发现LLMs能利用统计关联，但缺乏对复杂结构的推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否依赖统计关联或构建内部世界模型，以评估其认知能力。

Method: 采用认知科学方法，通过三个研究测试LLMs在滑轮系统问题中的表现。

Result: LLMs能利用滑轮数量启发式估计机械优势（MA），并能区分功能性与随机系统，但对复杂结构推理能力有限。

Conclusion: LLMs可能部分构建内部世界模型，但认知科学方法有助于进一步评估其能力。

Abstract: Do large language models (LLMs) construct and manipulate internal world
models, or do they rely solely on statistical associations represented as
output layer token probabilities? We adapt cognitive science methodologies from
human mental models research to test LLMs on pulley system problems using
TikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical
advantage (MA). State-of-the-art models performed marginally but significantly
above chance, and their estimates correlated significantly with ground-truth
MA. Significant correlations between number of pulleys and model estimates
suggest that models employed a pulley counting heuristic, without necessarily
simulating pulley systems to derive precise values. Study 2 tested this by
probing whether LLMs represent global features crucial to MA estimation. Models
evaluated a functionally connected pulley system against a fake system with
randomly placed components. Without explicit cues, models identified the
functional system as having greater MA with F1=0.8, suggesting LLMs could
represent systems well enough to differentiate jumbled from functional systems.
Study 3 built on this by asking LLMs to compare functional systems with matched
systems which were connected up but which transferred no force to the weight;
LLMs identified the functional system with F1=0.46, suggesting random guessing.
Insofar as they may generalize, these findings are compatible with the notion
that LLMs manipulate internal world models, sufficient to exploit statistical
associations between pulley count and MA (Study 1), and to approximately
represent system components' spatial relations (Study 2). However, they may
lack the facility to reason over nuanced structural connectivity (Study 3). We
conclude by advocating the utility of cognitive scientific methods to evaluate
the world-modeling capacities of artificial intelligence systems.

</details>


### [46] [Data-Efficient Safe Policy Improvement Using Parametric Structure](https://arxiv.org/abs/2507.15532)
*Kasper Engelen,Guillermo A. Pérez,Marnix Suilen*

Main category: cs.AI

TL;DR: 本文提出了一种更高效的离线强化学习方法，通过利用参数依赖性和预处理技术提升数据效率。


<details>
  <summary>Details</summary>
Motivation: 在离线强化学习中，如何利用有限数据提升策略性能是一个关键问题。本文旨在通过参数依赖性和预处理技术提高数据效率。

Method: 1. 提出参数化SPI算法，利用分布间的相关性更准确估计转移动态；2. 基于博弈抽象预处理技术剪枝冗余动作；3. 基于SMT求解的进阶预处理技术进一步剪枝动作。

Result: 实验表明，这些技术将SPI的数据效率提升多个数量级，同时保持可靠性。

Conclusion: 通过参数依赖性和预处理技术，本文显著提升了离线强化学习的数据效率。

Abstract: Safe policy improvement (SPI) is an offline reinforcement learning problem in
which a new policy that reliably outperforms the behavior policy with high
confidence needs to be computed using only a dataset and the behavior policy.
Markov decision processes (MDPs) are the standard formalism for modeling
environments in SPI. In many applications, additional information in the form
of parametric dependencies between distributions in the transition dynamics is
available. We make SPI more data-efficient by leveraging these dependencies
through three contributions: (1) a parametric SPI algorithm that exploits known
correlations between distributions to more accurately estimate the transition
dynamics using the same amount of data; (2) a preprocessing technique that
prunes redundant actions from the environment through a game-based abstraction;
and (3) a more advanced preprocessing technique, based on satisfiability modulo
theory (SMT) solving, that can identify more actions to prune. Empirical
results and an ablation study show that our techniques increase the data
efficiency of SPI by multiple orders of magnitude while maintaining the same
reliability guarantees.

</details>


### [47] [Metric assessment protocol in the context of answer fluctuation on MCQ tasks](https://arxiv.org/abs/2507.15581)
*Ekaterina Goliakova,Xavier Renard,Marie-Jeanne Lesot,Thibault Laugel,Christophe Marsala,Marcin Detyniecki*

Main category: cs.AI

TL;DR: 本文提出了一种评估多选问题（MCQ）指标的新协议，分析了现有指标与答案波动率的关系，并发现最差准确率（worst accuracy）具有最高的关联性。


<details>
  <summary>Details</summary>
Motivation: 多选问题（MCQ）是评估LLM能力的常用方法，但现有研究未充分评估其指标，且存在答案波动问题。

Method: 提出一种指标评估协议，分析评估方法与答案波动率及原始性能的关系。

Result: 现有指标与答案波动率有强关联，最差准确率表现最佳。

Conclusion: 最差准确率是一种有效的评估指标，可用于改进LLM的MCQ评估。

Abstract: Using multiple-choice questions (MCQs) has become a standard for assessing
LLM capabilities efficiently. A variety of metrics can be employed for this
task. However, previous research has not conducted a thorough assessment of
them. At the same time, MCQ evaluation suffers from answer fluctuation: models
produce different results given slight changes in prompts. We suggest a metric
assessment protocol in which evaluation methodologies are analyzed through
their connection with fluctuation rates, as well as original performance. Our
results show that there is a strong link between existing metrics and the
answer changing, even when computed without any additional prompt variants. A
novel metric, worst accuracy, demonstrates the highest association on the
protocol.

</details>


### [48] [TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II](https://arxiv.org/abs/2507.15618)
*Weiyu Ma,Jiwen Jiang,Haobo Fu,Haifeng Zhang*

Main category: cs.AI

TL;DR: 提出一种基于适配器的StarCraft II AI战术调控方法，通过轻量级适配模块实现策略调整，保持核心能力的同时支持战术变化。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理缺乏基于高层战术指令的适应能力，需一种灵活且高效的方法实现战术调控。

Method: 冻结预训练策略网络（DI-Star），为每个动作头附加轻量级适配模块，通过KL散度约束训练适配器。

Result: 实验表明，该方法能有效调控代理行为（如侵略性、扩张模式和技术偏好），同时保持竞争力。

Conclusion: 该方法以低计算开销实现灵活战术控制，适用于复杂即时战略游戏的策略定制。

Abstract: We present an adapter-based approach for tactical conditioning of StarCraft
II AI agents. Current agents, while powerful, lack the ability to adapt their
strategies based on high-level tactical directives. Our method freezes a
pre-trained policy network (DI-Star) and attaches lightweight adapter modules
to each action head, conditioned on a tactical tensor that encodes strategic
preferences. By training these adapters with KL divergence constraints, we
ensure the policy maintains core competencies while exhibiting tactical
variations. Experimental results show our approach successfully modulates agent
behavior across tactical dimensions including aggression, expansion patterns,
and technology preferences, while maintaining competitive performance. Our
method enables flexible tactical control with minimal computational overhead,
offering practical strategy customization for complex real-time strategy games.

</details>


### [49] [Agentic AI for autonomous anomaly management in complex systems](https://arxiv.org/abs/2507.15676)
*Reza Vatankhah Barenji,Sina Khoshgoftar*

Main category: cs.AI

TL;DR: 探讨代理AI在复杂系统中自主检测和响应异常的潜力，强调其改变传统依赖人工的异常管理方法的能力。


<details>
  <summary>Details</summary>
Motivation: 传统异常管理方法依赖人工，效率低且成本高，代理AI有望实现自主化，提升效率和准确性。

Method: 研究代理AI的自主检测和响应机制，分析其在复杂系统中的实际应用。

Result: 代理AI能够有效识别和应对异常，显著减少人工干预需求。

Conclusion: 代理AI在异常管理中具有巨大潜力，未来可进一步优化其自主性和适应性。

Abstract: This paper explores the potential of agentic AI in autonomously detecting and
responding to anomalies within complex systems, emphasizing its ability to
transform traditional, human-dependent anomaly management methods.

</details>


### [50] [Towards physician-centered oversight of conversational diagnostic AI](https://arxiv.org/abs/2507.15743)
*Elahe Vedadi,David Barrett,Natalie Harris,Ellery Wulczyn,Shashir Reddy,Roma Ruparel,Mike Schaekermann,Tim Strother,Ryutaro Tanno,Yash Sharma,Jihyeon Lee,Cían Hughes,Dylan Slack,Anil Palepu,Jan Freyberg,Khaled Saab,Valentin Liévin,Wei-Hung Weng,Tao Tu,Yun Liu,Nenad Tomasev,Kavita Kulkarni,S. Sara Mahdavi,Kelvin Guu,Joëlle Barral,Dale R. Webster,James Manyika,Avinatan Hassidim,Katherine Chou,Yossi Matias,Pushmeet Kohli,Adam Rodman,Vivek Natarajan,Alan Karthikesalingam,David Stutz*

Main category: cs.AI

TL;DR: 论文提出了一种名为g-AMIE的多智能体系统，用于在医疗诊断对话中实现异步监督，确保AI系统在医生监督下安全运行。


<details>
  <summary>Details</summary>
Motivation: 现有AI诊断系统缺乏有效的监督机制，而医疗诊断需由持牌专业人员负责。论文旨在解决AI系统在医疗领域的监督问题。

Method: 提出g-AMIE系统，通过多智能体协作完成病史采集，并在医生监督下提供诊断建议。通过虚拟OSCE实验比较g-AMIE与NPs/PAs和PCPs的表现。

Result: g-AMIE在60个场景中表现优于NPs/PAs和PCPs，能高效完成病史采集、病例总结和诊断建议，且监督时间更短。

Conclusion: 异步监督是一种可行的模式，可增强AI系统在医疗诊断中的实用性，同时确保医生监督和责任归属。

Abstract: Recent work has demonstrated the promise of conversational AI systems for
diagnostic dialogue. However, real-world assurance of patient safety means that
providing individual diagnoses and treatment plans is considered a regulated
activity by licensed professionals. Furthermore, physicians commonly oversee
other team members in such activities, including nurse practitioners (NPs) or
physician assistants/associates (PAs). Inspired by this, we propose a framework
for effective, asynchronous oversight of the Articulate Medical Intelligence
Explorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent
system that performs history taking within guardrails, abstaining from
individualized medical advice. Afterwards, g-AMIE conveys assessments to an
overseeing primary care physician (PCP) in a clinician cockpit interface. The
PCP provides oversight and retains accountability of the clinical decision.
This effectively decouples oversight from intake and can thus happen
asynchronously. In a randomized, blinded virtual Objective Structured Clinical
Examination (OSCE) of text consultations with asynchronous oversight, we
compared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across
60 scenarios, g-AMIE outperformed both groups in performing high-quality
intake, summarizing cases, and proposing diagnoses and management plans for the
overseeing PCP to review. This resulted in higher quality composite decisions.
PCP oversight of g-AMIE was also more time-efficient than standalone PCP
consultations in prior work. While our study does not replicate existing
clinical practices and likely underestimates clinicians' capabilities, our
results demonstrate the promise of asynchronous oversight as a feasible
paradigm for diagnostic AI systems to operate under expert human oversight for
enhancing real-world care.

</details>


### [51] [LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization](https://arxiv.org/abs/2507.15758)
*Xingyu Wu,Yuchen Yan,Shangke Lyu,Linjuan Wu,Yiwen Qiu,Yongliang Shen,Weiming Lu,Jian Shao,Jun Xiao,Yueting Zhuang*

Main category: cs.AI

TL;DR: LAPO框架通过两阶段强化学习，使模型内化推理长度的适应性，减少40.9%的token使用并提升2.3%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型在简单问题上生成过多token的问题，将推理长度控制从外部约束转化为模型内在能力。

Method: 采用两阶段强化学习：第一阶段学习成功解的长度分布，第二阶段将其作为元认知指导嵌入推理上下文。

Result: 在数学推理基准上，LAPO减少40.9%的token使用，同时提高2.3%的准确率。

Conclusion: LAPO使模型能根据问题复杂度分配计算资源，实现高效推理而不牺牲质量。

Abstract: Large reasoning models have achieved remarkable performance through extended
chain-of-thought sequences, yet this computational freedom leads to excessive
token generation even for simple problems. We present Length-Adaptive Policy
Optimization (LAPO), a novel framework that transforms reasoning length control
from an external constraint into an intrinsic model capability. Unlike existing
approaches that impose rigid limits or rely on post-hoc interventions, LAPO
enables models to internalize an understanding of appropriate reasoning depth
through a two-stage reinforcement learning process. In the first stage, models
learn natural reasoning patterns by discovering the statistical distribution of
successful solution lengths. The second stage leverages these patterns as
meta-cognitive guidance, embedding them directly within the model's reasoning
context to ensure inference-time flexibility. Experiments on mathematical
reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\%
while improving accuracy by 2.3\%. Our analysis reveals that models trained
with LAPO develop emergent abilities to allocate computational resources based
on problem complexity, achieving efficient reasoning without sacrificing
quality.

</details>


### [52] [GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts](https://arxiv.org/abs/2507.15761)
*Jingyi Zheng,Zifan Peng,Yule Liu,Junfeng Wang,Yifan Liao,Wenhan Dong,Xinlei He*

Main category: cs.AI

TL;DR: GasAgent是一个多代理系统，用于智能合约Gas优化，结合现有模式兼容性和自动化发现/验证新模式，实现端到端优化。


<details>
  <summary>Details</summary>
Motivation: 现有Gas优化方案依赖手动发现，效率低且难以扩展，而基于大语言模型的研究存在兼容性差和冗余问题。

Method: GasAgent由四个专业代理（Seeker、Innovator、Executor、Manager）协作，闭环识别、验证和应用Gas节省改进。

Result: 在100个真实合约上优化82个，平均节省9.97%部署Gas；在500个LLM生成合约中优化79.8%，节省4.79%-13.93% Gas。

Conclusion: GasAgent作为LLM辅助智能合约开发的优化层，具有广泛适用性和高效性。

Abstract: Smart contracts are trustworthy, immutable, and automatically executed
programs on the blockchain. Their execution requires the Gas mechanism to
ensure efficiency and fairness. However, due to non-optimal coding practices,
many contracts contain Gas waste patterns that need to be optimized. Existing
solutions mostly rely on manual discovery, which is inefficient, costly to
maintain, and difficult to scale. Recent research uses large language models
(LLMs) to explore new Gas waste patterns. However, it struggles to remain
compatible with existing patterns, often produces redundant patterns, and
requires manual validation/rewriting. To address this gap, we present GasAgent,
the first multi-agent system for smart contract Gas optimization that combines
compatibility with existing patterns and automated discovery/validation of new
patterns, enabling end-to-end optimization. GasAgent consists of four
specialized agents, Seeker, Innovator, Executor, and Manager, that collaborate
in a closed loop to identify, validate, and apply Gas-saving improvements.
Experiments on 100 verified real-world contracts demonstrate that GasAgent
successfully optimizes 82 contracts, achieving an average deployment Gas
savings of 9.97%. In addition, our evaluation confirms its compatibility with
existing tools and validates the effectiveness of each module through ablation
studies. To assess broader usability, we further evaluate 500 contracts
generated by five representative LLMs across 10 categories and find that
GasAgent optimizes 79.8% of them, with deployment Gas savings ranging from
4.79% to 13.93%, showing its usability as the optimization layer for
LLM-assisted smart contract development.

</details>


### [53] [A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining](https://arxiv.org/abs/2507.15770)
*Yifan Shen,Zihan Zhao,Xiao Xue,Yuwei Guo,Qun Ma,Deyu Zhou,Ming Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种基于多智能体意图的动态可解释涌现分析框架EAMI，通过双视角思维追踪和k-means聚类分析群体意图的相变点，实验验证了其在复杂服务系统中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着服务计算、云计算和物联网的发展，服务生态系统日益复杂，传统因果方法难以分析智能体间的异常涌现现象，需要动态且可解释的新方法。

Method: EAMI框架采用双视角思维追踪机制（检查者智能体和分析智能体）提取意图，结合k-means聚类和意图时序涌现图进行动态分析。

Result: 实验在复杂O2O服务系统和Stanford AI Town中验证了EAMI的有效性、通用性和效率。

Conclusion: EAMI为服务生态系统中的异常涌现和因果分析提供了新范式。

Abstract: With the rise of service computing, cloud computing, and IoT, service
ecosystems are becoming increasingly complex. The intricate interactions among
intelligent agents make abnormal emergence analysis challenging, as traditional
causal methods focus on individual trajectories. Large language models offer
new possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT)
reasoning to reveal agent intentions. However, existing approaches remain
limited to microscopic and static analysis. This paper introduces a framework:
Emergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic
and interpretable emergence analysis. EAMI first employs a dual-perspective
thought track mechanism, where an Inspector Agent and an Analysis Agent extract
agent intentions under bounded and perfect rationality. Then, k-means
clustering identifies phase transition points in group intentions, followed by
a Intention Temporal Emergence diagram for dynamic analysis. The experiments
validate EAMI in complex online-to-offline (O2O) service system and the
Stanford AI Town experiment, with ablation studies confirming its
effectiveness, generalizability, and efficiency. This framework provides a
novel paradigm for abnormal emergence and causal analysis in service
ecosystems. The code is available at
https://anonymous.4open.science/r/EAMI-B085.

</details>


### [54] [Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work](https://arxiv.org/abs/2507.15796)
*Nuria Rodríguez-Barroso,Mario García-Márquez,M. Victoria Luzón,Francisco Herrera*

Main category: cs.AI

TL;DR: 本文探讨了联邦学习（FL）如何满足可信人工智能（TAI）的要求，分析了其挑战与解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着AI在敏感和高风险领域的应用增加，确保其符合伦理、法律和技术要求的需求日益迫切。联邦学习因其隐私保护特性被视为潜在解决方案，但其分布式特性与TAI的其他要求存在冲突。

Method: 以TAI要求为框架，系统分析FL与TAI对齐的挑战，分类并探讨关键障碍、现有研究、趋势及未解决问题。

Result: 研究总结了FL在满足TAI要求时的主要挑战，包括隐私保护与模型性能的平衡、数据分布不均等问题。

Conclusion: FL在TAI框架下仍需解决多方面的挑战，未来研究需进一步探索其与TAI的全面对齐。

Abstract: In recent years, the development of Trustworthy Artificial Intelligence (TAI)
has emerged as a critical objective in the deployment of AI systems across
sensitive and high-risk domains. TAI frameworks articulate a comprehensive set
of ethical, legal, and technical requirements to ensure that AI technologies
are aligned with human values, rights, and societal expectations. Among the
various AI paradigms, Federated Learning (FL) presents a promising solution to
pressing privacy concerns. However, aligning FL with the rest of the
requirements of TAI presents a series of challenges, most of which arise from
its inherently distributed nature. In this work, we adopt the requirements TAI
as a guiding structure to systematically analyze the challenges of adapting FL
to TAI. Specifically, we classify and examine the key obstacles to aligning FL
with TAI, providing a detailed exploration of what has been done, the trends,
and the remaining work within each of the identified challenges.

</details>


### [55] [Identifying Conditional Causal Effects in MPDAGs](https://arxiv.org/abs/2507.15842)
*Sara LaPlante,Emilija Perković*

Main category: cs.AI

TL;DR: 论文研究了在已知最大定向部分有向无环图（MPDAG）的情况下，如何识别条件因果效应，并提供了三种结果：不受治疗影响的条件下识别公式、MPDAG环境下do calculus的推广，以及一个完整的条件效应识别算法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决在背景知识限制和所有变量可观测的情况下，如何从MPDAG中识别条件因果效应的问题。

Method: 方法包括提出一个识别公式（当条件集不受治疗影响时）、将do calculus推广到MPDAG环境，以及开发一个完整的条件效应识别算法。

Result: 结果表明，提出的公式和算法能够有效识别MPDAG中的条件因果效应。

Conclusion: 结论是，这些结果为在MPDAG框架下识别条件因果效应提供了理论和实用工具。

Abstract: We consider identifying a conditional causal effect when a graph is known up
to a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG
represents an equivalence class of graphs that is restricted by background
knowledge and where all variables in the causal model are observed. We provide
three results that address identification in this setting: an identification
formula when the conditioning set is unaffected by treatment, a generalization
of the well-known do calculus to the MPDAG setting, and an algorithm that is
complete for identifying these conditional effects.

</details>


### [56] [Hierarchical Budget Policy Optimization for Adaptive Reasoning](https://arxiv.org/abs/2507.15844)
*Shangke Lyu,Linjuan Wu,Yuchen Yan,Xingyu Wu,Hao Li,Yongliang Shen,Peisheng Jiang,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.AI

TL;DR: HBPO是一种强化学习框架，通过分层预算探索和差异化奖励机制，使模型能够根据问题复杂度自适应调整推理深度，显著提高计算效率同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型在统一推理策略下计算效率低下的问题，同时避免因效率优化导致的长推理路径偏差。

Method: 采用分层预算探索，将样本分为不同预算子组，结合差异化奖励机制，实现资源高效分配。

Result: 在四个推理基准测试中，平均令牌使用减少60.6%，准确率提升3.14%。

Conclusion: HBPO表明推理效率和能力可以同时优化，关键在于分层训练保持探索多样性。

Abstract: Large reasoning models achieve remarkable performance through extensive
chain-of-thought generation, yet exhibit significant computational inefficiency
by applying uniform reasoning strategies regardless of problem complexity. We
present Hierarchical Budget Policy Optimization (HBPO), a reinforcement
learning framework that enables models to learn problem-specific reasoning
depths without sacrificing capability. HBPO addresses the fundamental challenge
of exploration space collapse in efficiency-oriented training, where penalties
on long output length systematically bias models away from necessary long
reasoning paths. Through hierarchical budget exploration, our approach
partitions rollout samples into multiple subgroups with distinct token budgets,
aiming to enable efficient resource allocation while preventing degradation of
capability. We introduce differentiated reward mechanisms that create
budget-aware incentives aligned with the complexity of the problem, allowing
models to discover natural correspondences between task requirements and
computational effort. Extensive experiments demonstrate that HBPO reduces
average token usage by up to 60.6% while improving accuracy by 3.14% across
four reasoning benchmarks. Unlike existing methods that impose external
constraints or rely on discrete mode selection, HBPO exhibits emergent adaptive
behavior where models automatically adjust reasoning depth based on problem
complexity. Our results suggest that reasoning efficiency and capability are
not inherently conflicting, and can be simultaneously optimized through
appropriately structured hierarchical training that preserves exploration
diversity.

</details>


### [57] [The Other Mind: How Language Models Exhibit Human Temporal Cognition](https://arxiv.org/abs/2507.15851)
*Lingyu Li,Yang Yao,Yixu Wang,Chubo Li,Yan Teng,Yingchun Wang*

Main category: cs.AI

TL;DR: 研究发现大型语言模型（LLMs）在时间认知上表现出类似人类的自发行为，包括主观时间参考点的建立和对韦伯-费希纳定律的遵循。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在未经明确训练的情况下如何表现出类似人类的时间认知模式。

Method: 通过相似性判断任务，分析神经元、表征和信息层面的机制，识别时间偏好神经元并研究其激活模式。

Result: 发现LLMs自发形成主观时间参考点，并采用对数编码方式；训练语料本身具有非线性时间结构。

Conclusion: 提出从经验主义视角理解LLMs的认知行为，强调AI对齐需关注内部表征系统的引导。

Abstract: As Large Language Models (LLMs) continue to advance, they exhibit certain
cognitive patterns similar to those of humans that are not directly specified
in training data. This study investigates this phenomenon by focusing on
temporal cognition in LLMs. Leveraging the similarity judgment task, we find
that larger models spontaneously establish a subjective temporal reference
point and adhere to the Weber-Fechner law, whereby the perceived distance
logarithmically compresses as years recede from this reference point. To
uncover the mechanisms behind this behavior, we conducted multiple analyses
across neuronal, representational, and informational levels. We first identify
a set of temporal-preferential neurons and find that this group exhibits
minimal activation at the subjective reference point and implements a
logarithmic coding scheme convergently found in biological systems. Probing
representations of years reveals a hierarchical construction process, where
years evolve from basic numerical values in shallow layers to abstract temporal
orientation in deep layers. Finally, using pre-trained embedding models, we
found that the training corpus itself possesses an inherent, non-linear
temporal structure, which provides the raw material for the model's internal
construction. In discussion, we propose an experientialist perspective for
understanding these findings, where the LLMs' cognition is viewed as a
subjective construction of the external world by its internal representational
system. This nuanced perspective implies the potential emergence of alien
cognitive frameworks that humans cannot intuitively predict, pointing toward a
direction for AI alignment that focuses on guiding internal constructions. Our
code is available at https://TheOtherMind.github.io.

</details>


### [58] [Gemini 2.5 Pro Capable of Winning Gold at IMO 2025](https://arxiv.org/abs/2507.15855)
*Yichen Huang,Lin F. Yang*

Main category: cs.AI

TL;DR: Gemini 2.5 Pro成功解决了IMO 2025中的5/6问题，展示了优化使用强大模型的重要性。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）在解决国际数学奥林匹克（IMO）等高难度数学问题中的潜力。

Method: 使用Google的Gemini 2.5 Pro模型，通过管道设计和提示工程避免数据污染。

Result: 在IMO 2025的6个问题中，成功解决了5个（存在一个例外）。

Conclusion: 优化模型使用方法对解决高难度数学问题至关重要。

Abstract: The International Mathematical Olympiad (IMO) poses uniquely challenging
problems requiring deep insight, creativity, and formal reasoning. While Large
Language Models (LLMs) perform well on mathematical benchmarks like AIME, they
struggle with Olympiad-level tasks. We use Google's Gemini 2.5 Pro on the newly
released IMO 2025 problems, avoiding data contamination. With pipeline design
and prompt engineering, 5 (out of 6) problems are solved correctly (up to a
caveat discussed below), highlighting the importance of finding the optimal way
of using powerful models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [59] [Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach](https://arxiv.org/abs/2507.14249)
*Yuejiao Xie,Maonan Wang,Di Zhou,Man-On Pun,Zhu Han*

Main category: cs.RO

TL;DR: 论文提出了一种基于无线电地图和MSHA-RL框架的UAM路径规划方法，以解决动态乘客需求和通信质量保障问题。


<details>
  <summary>Details</summary>
Motivation: UAM系统需要应对动态乘客需求和确保通信质量，而传统路径规划方法缺乏灵活性。

Method: 构建无线电地图评估通信质量，并提出MSHA-RL框架，通过混合注意力机制平衡全局与局部信息。

Result: 实验表明该方法能实现通信合规的路径规划，减少旅行时间并提升效率。

Conclusion: MSHA-RL框架有效解决了UAM系统中的动态路径规划问题，同时保障了乘客安全。

Abstract: Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions
to alleviate urban congestion, with path planning becoming a key focus area.
Unlike ground transportation, UAM trajectory planning has to prioritize
communication quality for accurate location tracking in constantly changing
environments to ensure safety. Meanwhile, a UAM system, serving as an air taxi,
requires adaptive planning to respond to real-time passenger requests,
especially in ride-sharing scenarios where passenger demands are unpredictable
and dynamic. However, conventional trajectory planning strategies based on
predefined routes lack the flexibility to meet varied passenger ride demands.
To address these challenges, this work first proposes constructing a radio map
to evaluate the communication quality of urban airspace. Building on this, we
introduce a novel Multi-Source Hybrid Attention Reinforcement Learning
(MSHA-RL) framework for the challenge of effectively focusing on passengers and
UAM locations, which arises from the significant dimensional disparity between
the representations. This model first generates the alignment among diverse
data sources with large gap dimensions before employing hybrid attention to
balance global and local insights, thereby facilitating responsive, real-time
path planning. Extensive experimental results demonstrate that the approach
enables communication-compliant trajectory planning, reducing travel time and
enhancing operational efficiency while prioritizing passenger safety.

</details>


### [60] [A Recursive Lie-Group Formulation for the Second-Order Time Derivatives of the Inverse Dynamics of parallel Kinematic Manipulators](https://arxiv.org/abs/2507.14274)
*Andreas Mueller,Shivesh Kumar,Thomas Kordik*

Main category: cs.RO

TL;DR: 本文首次提出了一种计算高效的并行运动学机械臂（PKM）配备串联弹性执行器（SEA）的轨迹控制方法，解决了其逆动力学解的二阶时间导数计算问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究未解决PKM配备SEA的轨迹控制问题，尤其是逆动力学解的二阶时间导数的高效计算。本文填补了这一空白。

Method: 利用PKM的特殊拓扑结构，复用串联机器人逆动力学的递归算法，并采用李群框架推导所有关系。

Result: 数值结果表明，该方法适用于6自由度Gough-Stewart平台和平面PKM，并结合平坦性控制方案验证了其有效性。

Conclusion: 本文首次解决了PKM配备SEA的轨迹控制问题，为相关应用提供了高效的计算方法。

Abstract: Series elastic actuators (SEA) were introduced for serial robotic arms. Their
model-based trajectory tracking control requires the second time derivatives of
the inverse dynamics solution, for which algorithms were proposed. Trajectory
control of parallel kinematics manipulators (PKM) equipped with SEAs has not
yet been pursued. Key element for this is the computationally efficient
evaluation of the second time derivative of the inverse dynamics solution. This
has not been presented in the literature, and is addressed in the present paper
for the first time. The special topology of PKM is exploited reusing the
recursive algorithms for evaluating the inverse dynamics of serial robots. A
Lie group formulation is used and all relations are derived within this
framework. Numerical results are presented for a 6-DOF Gough-Stewart platform
(as part of an exoskeleton), and for a planar PKM when a flatness-based control
scheme is applied.

</details>


### [61] [Personalized Socially Assistive Robots With End-to-End Speech-Language Models For Well-Being Support](https://arxiv.org/abs/2507.14412)
*Mengxue Fu,Zhonghao Shi,Minyu Huang,Siqi Liu,Mina Kian,Yirui Song,Maja J. Matarić*

Main category: cs.RO

TL;DR: 本文提出使用端到端语音语言模型（SLM）改进社交辅助机器人（SAR）的对话系统，并通过用户研究验证其效果，同时指出仍需改进的问题。


<details>
  <summary>Details</summary>
Motivation: 现有SAR对话系统在实时延迟、反馈机制和个性化对话方面存在不足，需通过SLM技术提升性能。

Method: 通过小型用户研究（N=11）评估SLM-enabled SAR系统的可用性，并分析用户反馈以识别改进方向。

Result: 用户认为SLM-enabled SAR系统能提供共情反馈、自然对话和适应性回应，但机器人的非语言行为和SLM的反馈仍需优化。

Conclusion: 未来需改进机器人动作与对话的同步性、SLM输出的心理健康适应性，以及更富表现力的语音生成。

Abstract: Socially assistive robots (SARs) have shown great potential for supplementing
well-being support. However, prior studies have found that existing dialogue
pipelines for SARs remain limited in real-time latency, back-channeling, and
personalized speech dialogue. Toward addressing these limitations, we propose
using integrated end-to-end speech-language models (SLMs) with SARs. This work
1) evaluated the usability of an SLM-enabled SAR dialogue system through a
small user study, and 2) identified remaining limitations through study user
feedback to inform future improvements. We conducted a small within-participant
user study with university students (N = 11) whose results showed that
participants perceived an SLM-enabled SAR system as capable of providing
empathetic feedback, natural turn-taking, back-channeling, and adaptive
responses. We also found that participants reported the robot's nonverbal
behaviors as lacking variability and synchronization with conversation, and the
SLM's verbal feedback as generic and repetitive. These findings highlighted the
need for real-time robot movement synchronized with conversation, improved
prompting or fine-tuning to generate outputs better aligned with mental health
practices, and more expressive, adaptive vocal generation.

</details>


### [62] [Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking](https://arxiv.org/abs/2507.14455)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 论文提出了一种扩展的时间延迟嵌入技术，用于建模周期性非光滑或混合系统，并开发了一种新型的状态历史增强线性二次调节器（LQR）。


<details>
  <summary>Details</summary>
Motivation: 研究如何将时间延迟嵌入技术应用于周期性非光滑或混合系统，以构建线性状态空间模型。

Method: 扩展时间延迟嵌入技术，应用于两个周期性混合系统（弹跳摆和简单步行器），并开发状态历史增强LQR。

Result: 成功构建了线性状态空间模型，并验证了状态历史增强LQR的有效性。

Conclusion: 时间延迟嵌入技术可有效建模周期性混合系统，状态历史增强LQR为控制这类系统提供了新方法。

Abstract: Time-delay embedding is a technique that uses snapshots of state history over
time to build a linear state space model of a nonlinear smooth system. We
demonstrate that periodic non-smooth or hybrid system can also be modeled as a
linear state space system using this approach as long as its behavior is
consistent in modes and timings. We extended time-delay embeddings to generate
a linear model of two periodic hybrid systems: the bouncing pendulum and the
simplest walker with control inputs. This leads to a novel state history
augmented linear quadratic regulator (LQR) which uses current and past state
history for feedback control.

</details>


### [63] [A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0](https://arxiv.org/abs/2507.14538)
*Jin Chai,Xiang Yao,Mengfan Hou,Yanghong Li,Erbao Dong*

Main category: cs.RO

TL;DR: CYJ Hand-0是一款21自由度的仿人灵巧手，采用混合肌腱驱动系统（SMAs和DC电机），通过3D打印金属框架和高强度鱼线模拟人手结构，验证了其仿生灵活性。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够模拟人手骨骼和肌腱肌肉结构的仿生灵巧手，以实现高灵活性和功能性。

Method: 结合形状记忆合金（SMAs）和直流电机驱动，使用3D打印金属框架和高强度鱼线作为人工肌腱，通过线性电机和SMA模块分别控制手指屈曲和伸展/外展。

Result: 机械和运动学实验验证了设计的有效性，展示了其仿生灵活性。

Conclusion: CYJ Hand-0的设计成功实现了仿生灵巧手的性能目标，为未来机器人手的发展提供了新思路。

Abstract: CYJ Hand-0 is a 21-DOF humanoid dexterous hand featuring a hybrid
tendon-driven actuation system that combines shape memory alloys (SMAs) and DC
motors. The hand employs high-strength fishing line as artificial tendons and
uses a fully 3D-printed AlSi10Mg metal frame designed to replicate the skeletal
and tendon-muscle structure of the human hand. A linear motor-driven module
controls finger flexion, while an SMA-based module enables finger extension and
lateral abduction. These modules are integrated into a compact hybrid actuation
unit mounted on a custom rear support structure. Mechanical and kinematic
experiments, conducted under an Arduino Mega 2560-based control system,
validate the effectiveness of the design and demonstrate its biomimetic
dexterity.

</details>


### [64] [BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives](https://arxiv.org/abs/2507.14582)
*Zezhi Liu,Shizhen Wu,Hanqian Luo,Deyun Qin,Yongchun Fang*

Main category: cs.RO

TL;DR: 提出了一种名为BT-TL-DMPs的分层框架，结合行为树、时序逻辑和动态运动基元，以解决机器人学习演示中技能泛化的问题。


<details>
  <summary>Details</summary>
Motivation: 在机器人学习演示领域，如何将学到的技能泛化到新场景中，尤其是长时程、多阶段任务，仍然是一个挑战。

Method: 框架整合了行为树（BT）、时序逻辑（TL）和动态运动基元（DMPs），使用信号时序逻辑（STL）规范任务需求，并通过STL约束的DMP优化方法调整运动基元。

Result: 仿真和实际实验验证了框架的有效性，能够满足复杂时空约束并实现可靠的自主操作。

Conclusion: 该框架成功弥合了符号与运动之间的鸿沟，为复杂机器人任务提供了更可靠的自主操作能力。

Abstract: In the field of Learning from Demonstration (LfD), enabling robots to
generalize learned manipulation skills to novel scenarios for long-horizon
tasks remains challenging. Specifically, it is still difficult for robots to
adapt the learned skills to new environments with different task and motion
requirements, especially in long-horizon, multi-stage scenarios with intricate
constraints. This paper proposes a novel hierarchical framework, called
BT-TL-DMPs, that integrates Behavior Tree (BT), Temporal Logic (TL), and
Dynamical Movement Primitives (DMPs) to address this problem. Within this
framework, Signal Temporal Logic (STL) is employed to formally specify complex,
long-horizon task requirements and constraints. These STL specifications are
systematically transformed to generate reactive and modular BTs for high-level
decision-making task structure. An STL-constrained DMP optimization method is
proposed to optimize the DMP forcing term, allowing the learned motion
primitives to adapt flexibly while satisfying intricate spatiotemporal
requirements and, crucially, preserving the essential dynamics learned from
demonstrations. The framework is validated through simulations demonstrating
generalization capabilities under various STL constraints and real-world
experiments on several long-horizon robotic manipulation tasks. The results
demonstrate that the proposed framework effectively bridges the symbolic-motion
gap, enabling more reliable and generalizable autonomous manipulation for
complex robotic tasks.

</details>


### [65] [Koopman Operator Based Linear Model Predictive Control for 2D Quadruped Trotting, Bounding, and Gait Transition](https://arxiv.org/abs/2507.14605)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 利用Koopman算子理论和EDMD方法，构建高维线性模型以保留非线性动力学特性，结合LMPC实现四足机器人在复杂地形中的多种步态及转换。


<details>
  <summary>Details</summary>
Motivation: 在线优化控制四足机器人运动，解决LMPC因线性化动力学方程导致的解质量下降问题。

Method: 采用Koopman算子理论和EDMD方法建立高维线性模型，分阶段建模空中与地面接触动力学，并应用LMPC实现实时控制。

Result: 成功演示了在平坦和崎岖地形中的跳跃、小跑及步态转换。

Conclusion: Koopman算子理论结合LMPC可有效实现四足机器人的多步态在线生成与转换。

Abstract: Online optimal control of quadrupedal robots would enable them to plan their
movement in novel scenarios. Linear Model Predictive Control (LMPC) has emerged
as a practical approach for real-time control. In LMPC, an optimization problem
with a quadratic cost and linear constraints is formulated over a finite
horizon and solved on the fly. However, LMPC relies on linearizing the
equations of motion (EOM), which may lead to poor solution quality. In this
paper, we use Koopman operator theory and the Extended Dynamic Mode
Decomposition (EDMD) to create a linear model of the system in high dimensional
space, thus retaining the nonlinearity of the EOM. We model the aerial phase
and ground contact phases using different linear models. Then, using LMPC, we
demonstrate bounding, trotting, and bound-to-trot and trot-to-bound gait
transitions in level and rough terrains. The main novelty is the use of Koopman
operator theory to create hybrid models of a quadrupedal system and demonstrate
the online generation of multiple gaits and gaits transitions.

</details>


### [66] [Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks](https://arxiv.org/abs/2507.14694)
*Yue Ma,Kanglei Zhou,Fuyang Yu,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.RO

TL;DR: ProbHMI通过可逆网络在解耦潜在空间中建模3D人体运动，实现了显式的概率动力学建模和不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景（如人机协作）中，量化预测的不确定性至关重要，但现有方法因隐式概率表示而难以实现。

Method: 引入可逆网络参数化姿态，在解耦潜在空间中建模，并通过预测模块显式预测未来潜在分布。

Result: 在基准测试中，ProbHMI在确定性和多样性预测方面表现优异，同时验证了不确定性校准的有效性。

Conclusion: ProbHMI为风险感知决策提供了可靠的不确定性量化方法。

Abstract: 3D human motion forecasting aims to enable autonomous applications.
Estimating uncertainty for each prediction (i.e., confidence based on
probability density or quantile) is essential for safety-critical contexts like
human-robot collaboration to minimize risks. However, existing diverse motion
forecasting approaches struggle with uncertainty quantification due to implicit
probabilistic representations hindering uncertainty modeling. We propose
ProbHMI, which introduces invertible networks to parameterize poses in a
disentangled latent space, enabling probabilistic dynamics modeling. A
forecasting module then explicitly predicts future latent distributions,
allowing effective uncertainty quantification. Evaluated on benchmarks, ProbHMI
achieves strong performance for both deterministic and diverse prediction while
validating uncertainty calibration, critical for risk-aware decision making.

</details>


### [67] [Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.14700)
*Nicholas Mohammad,Nicola Bezzo*

Main category: cs.RO

TL;DR: 提出了一种结合CLF和CBF的MPCC框架，通过动态调整CBF参数确保安全导航。


<details>
  <summary>Details</summary>
Motivation: 现有MPCC方法缺乏形式化安全保障，需解决未知杂乱环境中的安全导航问题。

Method: 结合CLF和CBF的MPCC框架，动态调整CBF参数（使用SAC策略）。

Result: 通过仿真和移动机器人实验验证了方法的有效性。

Conclusion: 该方法在未知杂乱环境中实现了安全导航，并提升了可行性。

Abstract: Safe navigation in unknown and cluttered environments remains a challenging
problem in robotics. Model Predictive Contour Control (MPCC) has shown promise
for performant obstacle avoidance by enabling precise and agile trajectory
tracking, however, existing methods lack formal safety assurances. To address
this issue, we propose a general Control Lyapunov Function (CLF) and Control
Barrier Function (CBF) enabled MPCC framework that enforces safety constraints
derived from a free-space corridor around the planned trajectory. To enhance
feasibility, we dynamically adapt the CBF parameters at runtime using a Soft
Actor-Critic (SAC) policy. The approach is validated with extensive simulations
and an experiment on mobile robot navigation in unknown cluttered environments.

</details>


### [68] [Leveraging Extrinsic Dexterity for Occluded Grasping on Grasp Constraining Walls](https://arxiv.org/abs/2507.14721)
*Keita Kobashi,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 提出了一种分层强化学习框架，用于解决遮挡抓取问题，结合Q学习和CVAE，实现了高泛化性和稳健的仿真到现实迁移性能。


<details>
  <summary>Details</summary>
Motivation: 解决因环境遮挡导致的主要抓取配置不可用的问题，尤其是在平行夹持器灵活性有限的情况下。

Method: 采用分层强化学习框架，高层策略选择动作类型，低层技能在连续空间中采样具体动作，并使用CVAE推断合适位置。

Result: 在仿真和现实实验中展示了方法的泛化性和稳健的仿真到现实迁移性能，成功率较高。

Conclusion: 提出的方法有效解决了遮挡抓取问题，具有实际应用的潜力。

Abstract: This study addresses the problem of occluded grasping, where primary grasp
configurations of an object are not available due to occlusion with
environment. Simple parallel grippers often struggle with such tasks due to
limited dexterity and actuation constraints. Prior works have explored object
pose reorientation such as pivoting by utilizing extrinsic contacts between an
object and an environment feature like a wall, to make the object graspable.
However, such works often assume the presence of a short wall, and this
assumption may not always hold in real-world scenarios. If the wall available
for interaction is too large or too tall, the robot may still fail to grasp the
object even after pivoting, and the robot must combine different types of
actions to grasp. To address this, we propose a hierarchical reinforcement
learning (RL) framework. We use Q-learning to train a high-level policy that
selects the type of action expected to yield the highest reward. The selected
low-level skill then samples a specific robot action in continuous space. To
guide the robot to an appropriate location for executing the selected action,
we adopt a Conditional Variational Autoencoder (CVAE). We condition the CVAE on
the object point cloud and the skill ID, enabling it to infer a suitable
location based on the object geometry and the selected skill. To promote
generalization, we apply domain randomization during the training of low-level
skills. The RL policy is trained entirely in simulation with a box-like object
and deployed to six objects in real world. We conduct experiments to evaluate
our method and demonstrate both its generalizability and robust sim-to-real
transfer performance with promising success rates.

</details>


### [69] [X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots](https://arxiv.org/abs/2507.14731)
*Haitong Wang,Aaron Hao Tan,Angus Fung,Goldie Nejat*

Main category: cs.RO

TL;DR: X-Nav是一个跨机器人平台的端到端导航框架，通过两阶段学习（专家策略训练与策略蒸馏）实现通用性。实验证明其能零样本迁移至新平台和真实环境。


<details>
  <summary>Details</summary>
Motivation: 现有导航方法局限于特定机器人平台，缺乏通用性。X-Nav旨在解决这一问题，实现跨平台导航。

Method: 1) 使用深度强化学习训练多个专家策略；2) 通过Nav-ACT蒸馏出通用策略，直接映射观测到控制命令。

Result: X-Nav在模拟和真实环境中均表现出色，支持零样本迁移，且性能随训练平台数量增加而提升。

Conclusion: X-Nav证明了跨平台导航的可行性，为通用机器人导航提供了新思路。

Abstract: Existing navigation methods are primarily designed for specific robot
embodiments, limiting their generalizability across diverse robot platforms. In
this paper, we introduce X-Nav, a novel framework for end-to-end
cross-embodiment navigation where a single unified policy can be deployed
across various embodiments for both wheeled and quadrupedal robots. X-Nav
consists of two learning stages: 1) multiple expert policies are trained using
deep reinforcement learning with privileged observations on a wide range of
randomly generated robot embodiments; and 2) a single general policy is
distilled from the expert policies via navigation action chunking with
transformer (Nav-ACT). The general policy directly maps visual and
proprioceptive observations to low-level control commands, enabling
generalization to novel robot embodiments. Simulated experiments demonstrated
that X-Nav achieved zero-shot transfer to both unseen embodiments and
photorealistic environments. A scalability study showed that the performance of
X-Nav improves when trained with an increasing number of randomly generated
embodiments. An ablation study confirmed the design choices of X-Nav.
Furthermore, real-world experiments were conducted to validate the
generalizability of X-Nav in real-world environments.

</details>


### [70] [KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning](https://arxiv.org/abs/2507.14820)
*Bingran Chen,Baorun Li,Jian Yang,Yong Liu,Guangyao Zhai*

Main category: cs.RO

TL;DR: KGN-Pro是一种新型抓取网络，通过概率PnP层直接优化3D信息，解决了现有方法依赖2D监督和非可微性的问题，显著提升了抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在6-DoF抓取估计中存在小物体和传感器噪声的挑战，或依赖昂贵的3D标注和离散化问题。KGN-Pro旨在结合3D优化，充分利用3D信息。

Method: KGN-Pro通过RGB-D图像生成关键点图和2D置信图，利用概率PnP层进行端到端学习，优化重投影误差。

Result: 实验表明，KGN-Pro在模拟和真实环境中均优于现有方法，抓取覆盖率和成功率更高。

Conclusion: KGN-Pro通过3D优化和端到端学习，显著提升了抓取性能，为机器人操作任务提供了更灵活的解决方案。

Abstract: High-level robotic manipulation tasks demand flexible 6-DoF grasp estimation
to serve as a basic function. Previous approaches either directly generate
grasps from point-cloud data, suffering from challenges with small objects and
sensor noise, or infer 3D information from RGB images, which introduces
expensive annotation requirements and discretization issues. Recent methods
mitigate some challenges by retaining a 2D representation to estimate grasp
keypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoF
poses. However, these methods are limited by their non-differentiable nature
and reliance solely on 2D supervision, which hinders the full exploitation of
rich 3D information. In this work, we present KGN-Pro, a novel grasping network
that preserves the efficiency and fine-grained object grasping of previous KGNs
while integrating direct 3D optimization through probabilistic PnP layers.
KGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further
outputs a 2D confidence map to weight keypoint contributions during
re-projection error minimization. By modeling the weighted sum of squared
re-projection errors probabilistically, the network effectively transmits 3D
supervision to its 2D keypoint predictions, enabling end-to-end learning.
Experiments on both simulated and real-world platforms demonstrate that KGN-Pro
outperforms existing methods in terms of grasp cover rate and success rate.

</details>


### [71] [CoMoCAVs: Cohesive Decision-Guided Motion Planning for Connected and Autonomous Vehicles with Multi-Policy Reinforcement Learning](https://arxiv.org/abs/2507.14903)
*Pan Hu*

Main category: cs.RO

TL;DR: 本文提出了一种名为CDGMP的框架，通过混合专家架构和多策略强化学习，将决策制定与运动规划紧密结合，以提高自动驾驶的灵活性和安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中，如何在保证安全的同时实现灵活的车道选择和精确的轨迹执行是一个重要挑战。

Method: 采用混合专家（MoE）架构和多策略强化学习，通过门控机制协调多个专用子网络，将复杂驾驶任务分解为模块化组件。

Result: 仿真结果表明，CDGMP在车道选择和运动规划中表现出可靠的性能。

Conclusion: CDGMP为自动驾驶提供了一种可扩展的解决方案，其架构原理也为其他高维决策和控制任务提供了基础。

Abstract: Autonomous driving demands reliable and efficient solutions to closely
related problems such as decision-making and motion planning. In this work,
decision-making refers specifically to highway lane selection, while motion
planning involves generating control commands (such as speed and steering) to
reach the chosen lane. In the context of Connected Autonomous Vehicles (CAVs),
achieving both flexible and safe lane selection alongside precise trajectory
execution remains a significant challenge. This paper proposes a framework
called Cohesive Decision-Guided Motion Planning (CDGMP), which tightly
integrates decision-making and motion planning using a Mixture of Experts (MoE)
inspired architecture combined with multi-policy reinforcement learning. By
coordinating multiple specialized sub-networks through a gating mechanism, the
method decomposes the complex driving task into modular components. Each
sub-network focuses on a specific aspect of driving, improving efficiency by
activating only the most relevant modules during inference. This design also
enhances safety through modular specialization. CDGMP improves the adaptability
and robustness of CAVs across diverse traffic scenarios, offering a scalable
solution to real-world autonomy challenges. The architectural principles behind
CDGMP, especially the use of MoE, also provide a strong foundation for other
high-dimensional decision and control tasks. Simulation results (available at
https://youtu.be/_-4OXNHV0UY) demonstrate reliable performance in both lane
selection and motion planning.

</details>


### [72] [One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner](https://arxiv.org/abs/2507.14914)
*Zhexuan Xu,Jie Wang,Siyuan Xu,Zijie Geng,Mingxuan Yuan,Feng Wu*

Main category: cs.RO

TL;DR: Flora是一种三阶段馈通和布局感知的矩形平面规划器，通过分阶段优化HPWL、馈通和组件布局，显著提升芯片设计的PPA指标。


<details>
  <summary>Details</summary>
Motivation: 现有平面规划方法难以与后续物理设计阶段集成，导致模块内组件布局不优和模块间馈通过多。

Method: Flora分三阶段：1) 使用线掩模和位置掩模技术粗优化HPWL和馈通；2) 在固定轮廓下通过模块形状调整实现零空白布局；3) 快速树搜索法优化组件布局并调整模块边界。

Result: 实验显示，Flora平均减少HPWL 6%、FTpin 5.16%、FTmod 29.15%，组件布局性能提升14%。

Conclusion: Flora通过跨阶段优化，显著提升平面规划性能，优于现有方法。

Abstract: Floorplanning determines the shapes and locations of modules on a chip canvas
and plays a critical role in optimizing the chip's Power, Performance, and Area
(PPA) metrics. However, existing floorplanning approaches often fail to
integrate with subsequent physical design stages, leading to suboptimal
in-module component placement and excessive inter-module feedthrough. To tackle
this challenge, we propose Flora, a three-stage feedthrough and placement aware
rectilinear floorplanner. In the first stage, Flora employs wiremask and
position mask techniques to achieve coarse-grained optimization of HPWL and
feedthrough. In the second stage, under the constraint of a fixed outline,
Flora achieves a zero-whitespace layout by locally resizing module shapes,
thereby performing fine-grained optimization of feedthrough and improving
component placement. In the third stage, Flora utilizes a fast tree
search-based method to efficiently place components-including macros and
standard cells-within each module, subsequently adjusting module boundaries
based on the placement results to enable cross-stage optimization. Experimental
results show that Flora outperforms recent state-of-the-art floorplanning
approaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin,
29.15% in FTmod, and a 14% improvement in component placement performance.

</details>


### [73] [Digital twin and extended reality for teleoperation of the electric vehicle battery disassembly](https://arxiv.org/abs/2507.14929)
*Tero Kaarlela,Sami Salo,Jose Outeiro*

Main category: cs.RO

TL;DR: 提出了一种用于电动汽车电池（EVB）安全拆解和分类的远程操作系统，结合人工和自动化，提高安全性、适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 手动拆解EVB存在安全隐患（如触电和有毒化学物质），需要一种更安全的解决方案。

Method: 采用远程操作系统，结合人工操作和自动化技术，利用RGB相机和ROS中间件实现物理与数字孪生对齐。

Result: 在线试点研究表明该方法具有用户友好性和潜在的经济效益。

Conclusion: 该系统为EVB拆解提供了一种安全、高效且经济的解决方案，支持可持续的电动汽车转型。

Abstract: Disassembling and sorting Electric Vehicle Batteries (EVBs) supports a
sustainable transition to electric vehicles by enabling a closed-loop supply
chain. Currently, the manual disassembly process exposes workers to hazards,
including electrocution and toxic chemicals. We propose a teleoperated system
for the safe disassembly and sorting of EVBs. A human-in-the-loop can create
and save disassembly sequences for unknown EVB types, enabling future
automation. An RGB camera aligns the physical and digital twins of the EVB, and
the digital twin of the robot is based on the Robot Operating System (ROS)
middleware. This hybrid approach combines teleoperation and automation to
improve safety, adaptability, and efficiency in EVB disassembly and sorting.
The economic contribution is realized by reducing labor dependency and
increasing throughput in battery recycling. An online pilot study was set up to
evaluate the usability of the presented approach, and the results demonstrate
the potential as a user-friendly solution.

</details>


### [74] [Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry](https://arxiv.org/abs/2507.14931)
*Qiaoqiao Ren,Remko Proesmans,Arend Pissens,Lara Dehandschutter,William Denecker,Lotte Rouckhout,Joke Carrette,Peter Vanhopplinus,Tony Belpaeme,Francis wyffels*

Main category: cs.RO

TL;DR: 研究探讨如何通过共同设计开发一款陪伴机器人，用于监测和调节法医精神病患者的压力，同时记录其互动行为以进行长期干预。


<details>
  <summary>Details</summary>
Motivation: 法医精神病患者常因高度官僚化、风险规避和自主权受限而承受心理压力，本研究旨在通过共同设计改善其生活质量。

Method: 在法医精神病诊所进行了四次共同设计工作坊，参与者包括患者、护理人员和治疗师，通过原型展示、创意构思和功能定义逐步推进设计。

Result: 研究发现，在设计中赋予患者权力并根据其情绪状态调整方案至关重要，同时需确保每位患者的意见被听取。

Conclusion: 共同设计能有效提升患者在设计过程中的参与感，为开发适合法医精神病患者的陪伴机器人提供了实践指导。

Abstract: Forensic mental health care involves the treatment of individuals with severe
mental disorders who have committed violent offences. These settings are often
characterized by high levels of bureaucracy, risk avoidance, and restricted
autonomy. Patients frequently experience a profound loss of control over their
lives, leading to heightened psychological stress-sometimes resulting in
isolation as a safety measure. In this study, we explore how co-design can be
used to collaboratively develop a companion robot that helps monitor and
regulate stress while maintaining tracking of the patients' interaction
behaviours for long-term intervention. We conducted four co-design workshops in
a forensic psychiatric clinic with patients, caregivers, and therapists. Our
process began with the presentation of an initial speculative prototype to
therapists, enabling reflection on shared concerns, ethical risks, and
desirable features. This was followed by a creative ideation session with
patients, a third workshop focused on defining desired functions and emotional
responses, and we are planning a final prototype demo to gather direct patient
feedback. Our findings emphasize the importance of empowering patients in the
design process and adapting proposals based on their current emotional state.
The goal was to empower the patient in the design process and ensure each
patient's voice was heard.

</details>


### [75] [Heterogeneous object manipulation on nonlinear soft surface through linear controller](https://arxiv.org/abs/2507.14967)
*Pratik Ingle,Kasper Støy,Andres Faiña*

Main category: cs.RO

TL;DR: 论文提出了一种基于PID的线性闭环反馈控制策略，用于在低密度驱动阵列上实现异质物体的精确操控，避免了传统学习方法的复杂性和训练需求。


<details>
  <summary>Details</summary>
Motivation: 高密度驱动阵列的复杂性和高自由度限制了操控表面的实际应用，而现有学习方法需要大量训练且泛化能力不足。

Method: 采用几何变换驱动的PID控制器，将倾斜角度控制输出直接映射到驱动器命令，无需黑盒训练。

Result: 通过仿真和物理实验验证，成功操控了多种几何、重量和纹理的物体，包括易碎物品。

Conclusion: 该方法具有高度泛化性，为软机器人操控提供了实用可靠的解决方案，适合实际应用。

Abstract: Manipulation surfaces indirectly control and reposition objects by actively
modifying their shape or properties rather than directly gripping objects.
These surfaces, equipped with dense actuator arrays, generate dynamic
deformations. However, a high-density actuator array introduces considerable
complexity due to increased degrees of freedom (DOF), complicating control
tasks. High DOF restrict the implementation and utilization of manipulation
surfaces in real-world applications as the maintenance and control of such
systems exponentially increase with array/surface size. Learning-based control
approaches may ease the control complexity, but they require extensive training
samples and struggle to generalize for heterogeneous objects. In this study, we
introduce a simple, precise and robust PID-based linear close-loop feedback
control strategy for heterogeneous object manipulation on MANTA-RAY
(Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation
density). Our approach employs a geometric transformation-driven PID
controller, directly mapping tilt angle control outputs(1D/2D) to actuator
commands to eliminate the need for extensive black-box training. We validate
the proposed method through simulations and experiments on a physical system,
successfully manipulating objects with diverse geometries, weights and
textures, including fragile objects like eggs and apples. The outcomes
demonstrate that our approach is highly generalized and offers a practical and
reliable solution for object manipulation on soft robotic manipulation,
facilitating real-world implementation without prohibitive training demands.

</details>


### [76] [FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models](https://arxiv.org/abs/2507.14975)
*Yufan Song,Jiatao Zhang,Zeng Gu,Qingmiao Liang,Tuocheng Hu,Wei Song,Shiqiang Zhu*

Main category: cs.RO

TL;DR: 提出了一种灵活的自我反思框架FCRF，通过导师-执行者架构提升LLM在复杂任务中的错误纠正能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM自我反思机制僵化，限制了其在复杂任务中的有效性，受人类认知适应启发，提出更灵活的解决方案。

Method: 采用导师-执行者架构（FCRF），结合任务难度动态调整自我反思，并整合历史经验与失败教训。

Result: 在AlfWorld仿真和真实环境中测试，FCRF显著提升了复杂任务的性能和反思灵活性。

Conclusion: FCRF为LLM在机器人任务中的错误纠正提供了更灵活有效的解决方案。

Abstract: Autonomous error correction is critical for domestic robots to achieve
reliable execution of complex long-horizon tasks. Prior work has explored
self-reflection in Large Language Models (LLMs) for task planning error
correction; however, existing methods are constrained by inflexible
self-reflection mechanisms that limit their effectiveness. Motivated by these
limitations and inspired by human cognitive adaptation, we propose the Flexible
Constructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture
that enables LLMs to perform flexible self-reflection based on task difficulty,
while constructively integrating historical valuable experience with failure
lessons. We evaluated FCRF on diverse domestic tasks through simulation in
AlfWorld and physical deployment in the real-world environment. Experimental
results demonstrate that FCRF significantly improves overall performance and
self-reflection flexibility in complex long-horizon robotic tasks.

</details>


### [77] [CPED-NCBFs: A Conformal Prediction for Expert Demonstration-based Neural Control Barrier Functions](https://arxiv.org/abs/2507.15022)
*Sumeadh MS,Kevin Dsouza,Ravi Prakash*

Main category: cs.RO

TL;DR: 本文提出了一种基于CPED-NCBFs的分形预测验证策略，用于验证从专家演示中学习的神经控制屏障函数（NCBFs）的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有验证方法（如SMT求解器、MIP等）在验证NCBFs时往往引入宽松或保守的边界，无法确保其在整个状态空间中的安全性。

Method: 采用基于分形预测的CPED-NCBFs验证策略，并在点质量系统和非完整模型上进行验证。

Result: 实验证明了该方法的有效性。

Conclusion: CPED-NCBFs提供了一种更精确的验证方法，克服了现有技术的局限性。

Abstract: Among the promising approaches to enforce safety in control systems, learning
Control Barrier Functions (CBFs) from expert demonstrations has emerged as an
effective strategy. However, a critical challenge remains: verifying that the
learned CBFs truly enforce safety across the entire state space. This is
especially difficult when CBF is represented using neural networks (NCBFs).
Several existing verification techniques attempt to address this problem
including SMT-based solvers, mixed-integer programming (MIP), and interval or
bound-propagation methods but these approaches often introduce loose,
conservative bounds. To overcome these limitations, in this work we use
CPED-NCBFs a split-conformal prediction based verification strategy to verify
the learned NCBF from the expert demonstrations. We further validate our method
on point mass systems and unicycle models to demonstrate the effectiveness of
the proposed theory.

</details>


### [78] [Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper](https://arxiv.org/abs/2507.15062)
*Xinyue Zhu,Binghao Huang,Yunzhu Li*

Main category: cs.RO

TL;DR: 提出了一种便携式、轻量化的夹持器，集成了触觉传感器，用于同步收集视觉和触觉数据，并通过跨模态表示学习框架提升机器人操作的精确性。


<details>
  <summary>Details</summary>
Motivation: 现有手持夹持器缺乏触觉反馈，而触觉反馈在精确操作中至关重要。

Method: 开发了集成触觉传感器的夹持器，并提出跨模态表示学习框架，整合视觉和触觉信号。

Result: 在精细任务（如试管插入和移液操作）中表现出更高的准确性和鲁棒性。

Conclusion: 该方法通过多模态反馈支持更高效的策略学习，提升了机器人操作的精确性。

Abstract: Handheld grippers are increasingly used to collect human demonstrations due
to their ease of deployment and versatility. However, most existing designs
lack tactile sensing, despite the critical role of tactile feedback in precise
manipulation. We present a portable, lightweight gripper with integrated
tactile sensors that enables synchronized collection of visual and tactile data
in diverse, real-world, and in-the-wild settings. Building on this hardware, we
propose a cross-modal representation learning framework that integrates visual
and tactile signals while preserving their distinct characteristics. The
learning procedure allows the emergence of interpretable representations that
consistently focus on contacting regions relevant for physical interactions.
When used for downstream manipulation tasks, these representations enable more
efficient and effective policy learning, supporting precise robotic
manipulation based on multimodal feedback. We validate our approach on
fine-grained tasks such as test tube insertion and pipette-based fluid
transfer, demonstrating improved accuracy and robustness under external
disturbances. Our project page is available at
https://binghao-huang.github.io/touch_in_the_wild/ .

</details>


### [79] [Search-Based Autonomous Vehicle Motion Planning Using Game Theory](https://arxiv.org/abs/2507.15088)
*Pouya Panahandeh,Mohammad Pirani,Baris Fidan,Amir Khajepour*

Main category: cs.RO

TL;DR: 提出了一种基于搜索的交互式运动规划方案，用于自动驾驶车辆，采用博弈论方法，将其他道路使用者视为智能代理而非静态障碍物。


<details>
  <summary>Details</summary>
Motivation: 传统方法将其他道路使用者视为静态障碍物，缺乏真实性。新方法旨在生成更真实的路径。

Method: 使用博弈论方法，将其他道路用户建模为智能代理，实现实时计算。

Result: 方案计算时间短，适用于实时应用，实验验证性能优于现有技术。

Conclusion: 新方法通过博弈论提升了路径规划的真实性和实时性。

Abstract: In this paper, we propose a search-based interactive motion planning scheme
for autonomous vehicles (AVs), using a game-theoretic approach. In contrast to
traditional search-based approaches, the newly developed approach considers
other road users (e.g. drivers and pedestrians) as intelligent agents rather
than static obstacles. This leads to the generation of a more realistic path
for the AV. Due to the low computational time, the proposed motion planning
scheme is implementable in real-time applications. The performance of the
developed motion planning scheme is compared with existing motion planning
techniques and validated through experiments using WATonoBus, an electrical
all-weather autonomous shuttle bus.

</details>


### [80] [Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions](https://arxiv.org/abs/2507.15155)
*Majid Roshanfar,Alex Zhang,Changyan He,Amir Hooshiar,Dale J. Podolsky,Thomas Looi,Eric Diller*

Main category: cs.RO

TL;DR: 提出了一种基于学习的磁控软吸引装置建模框架，用于内窥镜鼻内脑肿瘤切除，通过随机森林模型实现高精度形状预测。


<details>
  <summary>Details</summary>
Motivation: 开发一种小型化、生物相容的磁控软吸引装置，用于微创神经外科手术，解决传统物理模型简化假设的局限性。

Method: 使用3D打印技术制造装置，集成FBG传感器实时反馈形状，通过Bezier控制点建模变形，并基于5,097个实验样本训练NN和RF模型。

Result: RF模型在控制点预测和形状重建误差上优于NN模型，分别达到0.087 mm和0.064 mm的精度，磁场分量对远端控制点影响显著。

Conclusion: 该学习框架有效建模了超弹性软机器人的非线性行为，为磁控软机器人工具的智能控制提供了进展。

Abstract: This letter introduces a novel learning-based modeling framework for a
magnetically steerable soft suction device designed for endoscopic endonasal
brain tumor resection. The device is miniaturized (4 mm outer diameter, 2 mm
inner diameter, 40 mm length), 3D printed using biocompatible SIL 30 material,
and integrates embedded Fiber Bragg Grating (FBG) sensors for real-time shape
feedback. Shape reconstruction is represented using four Bezier control points,
enabling a compact and smooth model of the device's deformation. A data-driven
model was trained on 5,097 experimental samples covering a range of magnetic
field magnitudes (0-14 mT), actuation frequencies (0.2-1.0 Hz), and vertical
tip distances (90-100 mm), using both Neural Network (NN) and Random Forest
(RF) architectures. The RF model outperformed the NN across all metrics,
achieving a mean root mean square error of 0.087 mm in control point prediction
and a mean shape reconstruction error of 0.064 mm. Feature importance analysis
further revealed that magnetic field components predominantly influence distal
control points, while frequency and distance affect the base configuration.
This learning-based approach effectively models the complex nonlinear behavior
of hyperelastic soft robots under magnetic actuation without relying on
simplified physical assumptions. By enabling sub-millimeter shape prediction
accuracy and real-time inference, this work represents an advancement toward
the intelligent control of magnetically actuated soft robotic tools in
minimally invasive neurosurgery.

</details>


### [81] [CHADET: Cross-Hierarchical-Attention for Depth-Completion Using Unsupervised Lightweight Transformer](https://arxiv.org/abs/2507.15189)
*Kevin Christiansen Marsim,Jinwoo Jeon,Yeeun Kim,Myeongwoo Jeong,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种轻量级深度补全网络CHADET，通过交叉分层注意力模块提升深度图预测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有深度补全方法在计算效率和准确性之间存在显著权衡，难以满足实时应用需求。

Method: 使用深度块提取特征，并通过轻量级基于Transformer的解码器和交叉分层注意力模块优化特征。

Result: 在KITTI、NYUv2和VOID数据集上验证了方法的有效性和低内存占用。

Conclusion: CHADET在提升深度图质量的同时降低了计算资源需求，适用于机器人实时任务。

Abstract: Depth information which specifies the distance between objects and current
position of the robot is essential for many robot tasks such as navigation.
Recently, researchers have proposed depth completion frameworks to provide
dense depth maps that offer comprehensive information about the surrounding
environment. However, existing methods show significant trade-offs between
computational efficiency and accuracy during inference. The substantial memory
and computational requirements make them unsuitable for real-time applications,
highlighting the need to improve the completeness and accuracy of depth
information while improving processing speed to enhance robot performance in
various tasks. To address these challenges, in this paper, we propose
CHADET(cross-hierarchical-attention depth-completion transformer), a
lightweight depth-completion network that can generate accurate dense depth
maps from RGB images and sparse depth points. For each pair, its feature is
extracted from the depthwise blocks and passed to the equally lightweight
transformer-based decoder. In the decoder, we utilize the novel
cross-hierarchical-attention module that refines the image features from the
depth information. Our approach improves the quality and reduces memory usage
of the depth map prediction, as validated in both KITTI, NYUv2, and VOID
datasets.

</details>


### [82] [VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving](https://arxiv.org/abs/2507.15266)
*Haichao Liu,Haoren Guo,Pei Liu,Benshan Ma,Yuxiang Zhang,Jun Ma,Tong Heng Lee*

Main category: cs.RO

TL;DR: 提出了一种基于视觉语言模型（VLM）的自动驾驶决策与控制框架VLM-UDMC，通过场景推理和风险感知优化运动规划，提升城市驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 模仿人类驾驶员的场景理解和风险感知能力，确保自动驾驶的透明性和可解释性。

Method: 采用两阶段推理策略（RAG）处理多模态输入，结合轻量级LSTM进行实时轨迹预测，动态调整运动规划。

Result: 通过仿真和实车实验验证了框架的有效性，提升了驾驶决策的合理性。

Conclusion: VLM-UDMC成功结合场景理解和注意力分解，优化了自动驾驶性能，项目已开源。

Abstract: Scene understanding and risk-aware attentions are crucial for human drivers
to make safe and effective driving decisions. To imitate this cognitive ability
in urban autonomous driving while ensuring the transparency and
interpretability, we propose a vision-language model (VLM)-enhanced unified
decision-making and motion control framework, named VLM-UDMC. This framework
incorporates scene reasoning and risk-aware insights into an upper-level slow
system, which dynamically reconfigures the optimal motion planning for the
downstream fast system. The reconfiguration is based on real-time environmental
changes, which are encoded through context-aware potential functions. More
specifically, the upper-level slow system employs a two-step reasoning policy
with Retrieval-Augmented Generation (RAG), leveraging foundation models to
process multimodal inputs and retrieve contextual knowledge, thereby generating
risk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTM
provides real-time trajectory predictions for heterogeneous traffic
participants by extracting smoother trend representations for short-horizon
trajectory prediction. The effectiveness of the proposed VLM-UDMC framework is
verified via both simulations and real-world experiments with a full-size
autonomous vehicle. It is demonstrated that the presented VLM-UDMC effectively
leverages scene understanding and attention decomposition for rational driving
decisions, thus improving the overall urban driving performance. Our
open-source project is available at https://github.com/henryhcliu/vlmudmc.git.

</details>


### [83] [RepILN: Reparameterized Inertial Localization Network](https://arxiv.org/abs/2507.15293)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一种重参数化的惯性定位网络，通过多分支训练增强特征提取，推理时转为单路径架构以提高效率，并引入时间尺度稀疏注意力机制和门控卷积单元，平衡了精度与模型紧凑性。


<details>
  <summary>Details</summary>
Motivation: 惯性定位因其成本效益和独立性在物联网设备中具有潜力，但现有方法因复杂网络架构和忽略长期依赖关系而受限。

Method: 采用多分支训练和单路径推理架构，结合时间尺度稀疏注意力机制和门控卷积单元，优化特征提取和长期依赖建模。

Result: 在RoNIN数据集上，绝对轨迹误差降低2.59%，参数数量减少3.86%。

Conclusion: 该方法在精度和模型效率间取得了良好平衡，适用于资源受限的物联网设备。

Abstract: Inertial localization is regarded as a promising positioning solution for
consumer-grade IoT devices due to its cost-effectiveness and independence from
external infrastructure. However, data-driven inertial localization methods
often rely on increasingly complex network architectures to improve accuracy,
which challenges the limited computational resources of IoT devices. Moreover,
these methods frequently overlook the importance of modeling long-term
dependencies in inertial measurements - a critical factor for accurate
trajectory reconstruction - thereby limiting localization performance. To
address these challenges, we propose a reparameterized inertial localization
network that uses a multi-branch structure during training to enhance feature
extraction. At inference time, this structure is transformed into an equivalent
single-path architecture to improve parameter efficiency. To further capture
long-term dependencies in motion trajectories, we introduce a temporal-scale
sparse attention mechanism that selectively emphasizes key trajectory segments
while suppressing noise. Additionally, a gated convolutional unit is
incorporated to effectively integrate long-range dependencies with local
fine-grained features. Extensive experiments on public benchmarks demonstrate
that our method achieves a favorable trade-off between accuracy and model
compactness. For example, on the RoNIN dataset, our approach reduces the
Absolute Trajectory Error (ATE) by 2.59% compared to RoNIN-ResNet while
reducing the number of parameters by 3.86%.

</details>


### [84] [Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe](https://arxiv.org/abs/2507.15444)
*Leonard Bauersfeld,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 提出了一种基于实时流场测量的四旋翼无人机闭环控制系统，用于在狭窄管道中悬停和横向移动。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼在狭窄管道中飞行时因气流扰动导致的稳定性问题。

Method: 开发了低延迟的事件式烟雾测速方法，结合循环卷积神经网络估计扰动，并通过强化学习训练控制器。

Result: 系统能够有效抵消瞬态气动效应，防止与管道壁碰撞，首次实现了基于实时流场测量的闭环控制。

Conclusion: 该研究为复杂气动环境中的飞行控制提供了新方向，并揭示了管道飞行中的流场特性。

Abstract: Autonomous quadrotor flight in confined spaces such as pipes and tunnels
presents significant challenges due to unsteady, self-induced aerodynamic
disturbances. Very recent advances have enabled flight in such conditions, but
they either rely on constant motion through the pipe to mitigate airflow
recirculation effects or suffer from limited stability during hovering. In this
work, we present the first closed-loop control system for quadrotors for
hovering in narrow pipes that leverages real-time flow field measurements. We
develop a low-latency, event-based smoke velocimetry method that estimates
local airflow at high temporal resolution. This flow information is used by a
disturbance estimator based on a recurrent convolutional neural network, which
infers force and torque disturbances in real time. The estimated disturbances
are integrated into a learning-based controller trained via reinforcement
learning. The flow-feedback control proves particularly effective during
lateral translation maneuvers in the pipe cross-section. There, the real-time
disturbance information enables the controller to effectively counteract
transient aerodynamic effects, thereby preventing collisions with the pipe
wall. To the best of our knowledge, this work represents the first
demonstration of an aerial robot with closed-loop control informed by real-time
flow field measurements. This opens new directions for research on flight in
aerodynamically complex environments. In addition, our work also sheds light on
the characteristic flow structures that emerge during flight in narrow,
circular pipes, providing new insights at the intersection of robotics and
fluid dynamics.

</details>


### [85] [The Emergence of Deep Reinforcement Learning for Path Planning](https://arxiv.org/abs/2507.15469)
*Thanh Thi Nguyen,Saeid Nahavandi,Imran Razzak,Dung Nguyen,Nhat Truong Pham,Quoc Viet Hung Nguyen*

Main category: cs.RO

TL;DR: 本文综述了路径规划领域的传统方法及深度强化学习（DRL）的最新进展，重点分析了自主车辆、无人机和机器人平台的导航策略。


<details>
  <summary>Details</summary>
Motivation: 随着复杂动态环境中自主系统需求的增加，研究智能路径规划方法变得至关重要。

Method: 综述了传统图搜索、线性规划和进化计算方法，以及DRL在路径规划中的应用，并分类讨论了关键算法。

Result: 分析了传统方法与DRL在计算效率、可扩展性、适应性和鲁棒性方面的优缺点。

Conclusion: 提出了结合DRL与传统方法的混合路径规划方向，为未来研究提供了开放挑战和潜在解决方案。

Abstract: The increasing demand for autonomous systems in complex and dynamic
environments has driven significant research into intelligent path planning
methodologies. For decades, graph-based search algorithms, linear programming
techniques, and evolutionary computation methods have served as foundational
approaches in this domain. Recently, deep reinforcement learning (DRL) has
emerged as a powerful method for enabling autonomous agents to learn optimal
navigation strategies through interaction with their environments. This survey
provides a comprehensive overview of traditional approaches as well as the
recent advancements in DRL applied to path planning tasks, focusing on
autonomous vehicles, drones, and robotic platforms. Key algorithms across both
conventional and learning-based paradigms are categorized, with their
innovations and practical implementations highlighted. This is followed by a
thorough discussion of their respective strengths and limitations in terms of
computational efficiency, scalability, adaptability, and robustness. The survey
concludes by identifying key open challenges and outlining promising avenues
for future research. Special attention is given to hybrid approaches that
integrate DRL with classical planning techniques to leverage the benefits of
both learning-based adaptability and deterministic reliability, offering
promising directions for robust and resilient autonomous navigation.

</details>


### [86] [All-UWB SLAM Using UWB Radar and UWB AOA](https://arxiv.org/abs/2507.15474)
*Charith Premachandra,Achala Athukorala,U-Xuan Tan*

Main category: cs.RO

TL;DR: 论文提出了一种结合UWB AOA测量的新方法，以提升在特征缺失环境中UWB雷达SLAM的精度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在恶劣环境（如烟雾、灰尘）中，光学传感器易失效，UWB雷达因其穿透能力成为SLAM的潜在技术，但现有方法受限于环境特征数量。

Method: 通过动态部署UWB锚点-标签单元获取AOA测量，并将其整合到UWB雷达SLAM系统中。

Result: 实验表明，结合UWB AOA单元可在特征缺失的视觉受限环境中实现SLAM。

Conclusion: 该方法有效解决了UWB AOA测量单元的约束，提升了SLAM在恶劣环境中的适用性。

Abstract: There has been a growing interest in autonomous systems designed to operate
in adverse conditions (e.g. smoke, dust), where the visible light spectrum
fails. In this context, Ultra-wideband (UWB) radar is capable of penetrating
through such challenging environmental conditions due to the lower frequency
components within its broad bandwidth. Therefore, UWB radar has emerged as a
potential sensing technology for Simultaneous Localization and Mapping (SLAM)
in vision-denied environments where optical sensors (e.g. LiDAR, Camera) are
prone to failure. Existing approaches involving UWB radar as the primary
exteroceptive sensor generally extract features in the environment, which are
later initialized as landmarks in a map. However, these methods are constrained
by the number of distinguishable features in the environment. Hence, this paper
proposes a novel method incorporating UWB Angle of Arrival (AOA) measurements
into UWB radar-based SLAM systems to improve the accuracy and scalability of
SLAM in feature-deficient environments. The AOA measurements are obtained using
UWB anchor-tag units which are dynamically deployed by the robot in featureless
areas during mapping of the environment. This paper thoroughly discusses
prevailing constraints associated with UWB AOA measurement units and presents
solutions to overcome them. Our experimental results show that integrating UWB
AOA units with UWB radar enables SLAM in vision-denied feature-deficient
environments.

</details>


### [87] [The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents](https://arxiv.org/abs/2507.15478)
*Simon Kohaut,Felix Divo,Navid Hamid,Benedict Flade,Julian Eggert,Devendra Singh Dhami,Kristian Kersting*

Main category: cs.RO

TL;DR: 论文提出了一种结合神经符号系统的新框架CoCo，通过概率逻辑程序和自我怀疑机制提升自主代理在不确定环境中的安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决自主代理在不确定环境中可靠且合规行为的挑战。

Method: 结合概率符号推理与深度学习，引入Constitutional Controller（CoCo）框架和自我怀疑机制。

Result: 在真实空中交通研究中，CoCo成功帮助智能系统学习适当怀疑并安全导航复杂环境。

Conclusion: 神经符号系统和自我怀疑机制为自主代理在不确定环境中的安全运行提供了有效解决方案。

Abstract: Ensuring reliable and rule-compliant behavior of autonomous agents in
uncertain environments remains a fundamental challenge in modern robotics. Our
work shows how neuro-symbolic systems, which integrate probabilistic, symbolic
white-box reasoning models with deep learning methods, offer a powerful
solution to this challenge. This enables the simultaneous consideration of
explicit rules and neural models trained on noisy data, combining the strength
of structured reasoning with flexible representations. To this end, we
introduce the Constitutional Controller (CoCo), a novel framework designed to
enhance the safety and reliability of agents by reasoning over deep
probabilistic logic programs representing constraints such as those found in
shared traffic spaces. Furthermore, we propose the concept of self-doubt,
implemented as a probability density conditioned on doubt features such as
travel velocity, employed sensors, or health factors. In a real-world aerial
mobility study, we demonstrate CoCo's advantages for intelligent autonomous
systems to learn appropriate doubts and navigate complex and uncertain
environments safely and compliantly.

</details>


### [88] [Robots for Kiwifruit Harvesting and Pollination](https://arxiv.org/abs/2507.15484)
*Jamie Bell*

Main category: cs.RO

TL;DR: 该研究开发了用于猕猴桃果园的移动机器人，实现了定向花粉喷洒和自动化采摘，改进了果实采摘和花粉喷洒的效率。


<details>
  <summary>Details</summary>
Motivation: 解决猕猴桃果园中人工采摘和花粉喷洒效率低下的问题，提高自动化水平。

Method: 设计了多种果实采摘机制，并测试了其中一种；使用喷雾器喷洒花粉；利用2D和3D激光雷达进行导航；测试计算机视觉算法。

Result: 采摘机制可覆盖80%以上的果实，优于现有技术；花粉喷洒和导航系统在果园中表现良好。

Conclusion: 移动机器人和自动化技术可显著提升猕猴桃果园的生产效率。

Abstract: This research was a part of a project that developed mobile robots that
performed targeted pollen spraying and automated harvesting in pergola
structured kiwifruit orchards. Multiple kiwifruit detachment mechanisms were
designed and field testing of one of the concepts showed that the mechanism
could reliably pick kiwifruit. Furthermore, this kiwifruit detachment mechanism
was able to reach over 80 percent of fruit in the cluttered kiwifruit canopy,
whereas the previous state of the art mechanism was only able to reach less
than 70 percent of the fruit. Artificial pollination was performed by detecting
flowers and then spraying pollen in solution onto the detected flowers from a
line of sprayers on a boom, while driving at up to 1.4 ms-1. In addition, the
height of the canopy was measured and the spray boom was moved up and down to
keep the boom close enough to the flowers for the spray to reach the flowers,
while minimising collisions with the canopy. Mobile robot navigation was
performed using a 2D lidar in apple orchards and vineyards. Lidar navigation in
kiwifruit orchards was more challenging because the pergola structure only
provides a small amount of data for the direction of rows, compared to the
amount of data from the overhead canopy, the undulating ground and other
objects in the orchards. Multiple methods are presented here for extracting
structure defining features from 3D lidar data in kiwifruit orchards. In
addition, a 3D lidar navigation system -- which performed row following, row
end detection and row end turns -- was tested for over 30 km of autonomous
driving in kiwifruit orchards. Computer vision algorithms for row detection and
row following were also tested. The computer vision algorithm worked as well as
the 3D lidar row following method in testing.

</details>


### [89] [GR-3 Technical Report](https://arxiv.org/abs/2507.15493)
*Chilam Cheang,Sijin Chen,Zhongren Cui,Yingdong Hu,Liqun Huang,Tao Kong,Hang Li,Yifeng Li,Yuxiao Liu,Xiao Ma,Hao Niu,Wenxuan Ou,Wanli Peng,Zeyu Ren,Haixin Shi,Jiawen Tian,Hongtao Wu,Xin Xiao,Yuyang Xiao,Jiafeng Xu,Yichu Yang*

Main category: cs.RO

TL;DR: GR-3是一种大规模视觉-语言-动作模型，展示了在泛化新对象、环境和抽象指令方面的卓越能力，并能高效微调。结合ByteMini机器人，GR-3在多种任务中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 目标是构建通用机器人策略，以辅助人类日常生活。

Method: 通过多模态训练（包括网络规模视觉语言数据、VR设备收集的人类轨迹数据和机器人轨迹数据）实现。

Result: GR-3在多种复杂任务中表现优异，超越基线方法π₀。

Conclusion: GR-3是迈向通用机器人的重要一步，展示了其在现实任务中的潜力。

Abstract: We report our recent progress towards building generalist robot policies, the
development of GR-3. GR-3 is a large-scale vision-language-action (VLA) model.
It showcases exceptional capabilities in generalizing to novel objects,
environments, and instructions involving abstract concepts. Furthermore, it can
be efficiently fine-tuned with minimal human trajectory data, enabling rapid
and cost-effective adaptation to new settings. GR-3 also excels in handling
long-horizon and dexterous tasks, including those requiring bi-manual
manipulation and mobile movement, showcasing robust and reliable performance.
These capabilities are achieved through a multi-faceted training recipe that
includes co-training with web-scale vision-language data, efficient fine-tuning
from human trajectory data collected via VR devices, and effective imitation
learning with robot trajectory data. In addition, we introduce ByteMini, a
versatile bi-manual mobile robot designed with exceptional flexibility and
reliability, capable of accomplishing a wide range of tasks when integrated
with GR-3. Through extensive real-world experiments, we show GR-3 surpasses the
state-of-the-art baseline method, $\pi_0$, on a wide variety of challenging
tasks. We hope GR-3 can serve as a step towards building generalist robots
capable of assisting humans in daily life.

</details>


### [90] [CLEVER: Stream-based Active Learning for Robust Semantic Perception from Human Instructions](https://arxiv.org/abs/2507.15499)
*Jongseok Lee,Timo Birr,Rudolph Triebel,Tamim Asfour*

Main category: cs.RO

TL;DR: CLEVER是一个基于深度神经网络（DNN）的主动学习系统，通过在线获取人类支持并适应DNN，实现鲁棒的语义感知任务。


<details>
  <summary>Details</summary>
Motivation: 解决数据流中DNN语义感知的鲁棒性问题，通过人类反馈提升系统性能。

Method: 设计了一个基于贝叶斯公式的系统，利用先验知识编码领域知识，并通过用户验证和实验验证其能力。

Result: 在真实机器人上首次实现了基于流的主动学习，证明DNN语义感知的鲁棒性可实际提升。

Conclusion: CLEVER系统通过结合人类反馈和贝叶斯方法，有效提升了DNN语义感知的鲁棒性。

Abstract: We propose CLEVER, an active learning system for robust semantic perception
with Deep Neural Networks (DNNs). For data arriving in streams, our system
seeks human support when encountering failures and adapts DNNs online based on
human instructions. In this way, CLEVER can eventually accomplish the given
semantic perception tasks. Our main contribution is the design of a system that
meets several desiderata of realizing the aforementioned capabilities. The key
enabler herein is our Bayesian formulation that encodes domain knowledge
through priors. Empirically, we not only motivate CLEVER's design but further
demonstrate its capabilities with a user validation study as well as
experiments on humanoid and deformable objects. To our knowledge, we are the
first to realize stream-based active learning on a real robot, providing
evidence that the robustness of the DNN-based semantic perception can be
improved in practice. The project website can be accessed at
https://sites.google.com/view/thecleversystem.

</details>


### [91] [Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding](https://arxiv.org/abs/2507.15604)
*Johannes Hartwig,Philipp Lienhardt,Dominik Henrich*

Main category: cs.RO

TL;DR: 论文提出了一种无需专用负载惯性参数（PIP）校准的方法，通过非接触运动部分估计PIP，使非专业用户能更高效编程接触运动。


<details>
  <summary>Details</summary>
Motivation: 随着协作机器人普及，需为非专业用户提供无需编程知识的操作方式，尤其是接触运动编程中避免专用PIP校准的需求。

Method: 利用任务中的非接触运动部分，通过现有估计技术估算PIP，避免专用校准。

Result: 质量估计准确，但质心和惯性张量受噪声和激励不足影响。

Conclusion: 手引导中PIP估计可行，但需足够负载加速度以确保准确性。

Abstract: As the availability of cobots increases, it is essential to address the needs
of users with little to no programming knowledge to operate such systems
efficiently. Programming concepts often use intuitive interaction modalities,
such as hand guiding, to address this. When programming in-contact motions,
such frameworks require knowledge of the robot tool's payload inertial
parameters (PIP) in addition to the demonstrated velocities and forces to
ensure effective hybrid motion-force control. This paper aims to enable
non-expert users to program in-contact motions more efficiently by eliminating
the need for a dedicated PIP calibration, thereby enabling flexible robot tool
changes. Since demonstrated tasks generally also contain motions with
non-contact, our approach uses these parts to estimate the robot's PIP using
established estimation techniques. The results show that the estimation of the
payload's mass is accurate, whereas the center of mass and the inertia tensor
are affected by noise and a lack of excitation. Overall, these findings show
the feasibility of PIP estimation during hand guiding but also highlight the
need for sufficient payload accelerations for an accurate estimation.

</details>


### [92] [A Universal Vehicle-Trailer Navigation System with Neural Kinematics and Online Residual Learning](https://arxiv.org/abs/2507.15607)
*Yanbo Chen,Yunzhe Tan,Yaojia Wang,Zhengzhe Xu,Junbo Tan,Xueqian Wang*

Main category: cs.RO

TL;DR: 提出了一种新型通用车辆-拖车导航系统，结合混合运动学模型和在线残差学习模块，提高了导航精度和安全性。


<details>
  <summary>Details</summary>
Motivation: 车辆-拖车系统在复杂环境（如机场、超市）中的精确建模和导航仍具挑战性，尤其是带脚轮的拖车。

Method: 结合经典非完整约束的车辆模型和基于神经网络的拖车运动学，并引入在线残差学习模块；开发了模型预测控制框架。

Result: 通过多种拖车和负载条件的真实实验验证，系统表现稳健，无需手动调整或拖车特定校准。

Conclusion: 该方法为通用车辆-拖车导航提供了高效解决方案，适用于多样化场景。

Abstract: Autonomous navigation of vehicle-trailer systems is crucial in environments
like airports, supermarkets, and concert venues, where various types of
trailers are needed to navigate with different payloads and conditions.
However, accurately modeling such systems remains challenging, especially for
trailers with castor wheels. In this work, we propose a novel universal
vehicle-trailer navigation system that integrates a hybrid nominal kinematic
model--combining classical nonholonomic constraints for vehicles and neural
network-based trailer kinematics--with a lightweight online residual learning
module to correct real-time modeling discrepancies and disturbances.
Additionally, we develop a model predictive control framework with a weighted
model combination strategy that improves long-horizon prediction accuracy and
ensures safer motion planning. Our approach is validated through extensive
real-world experiments involving multiple trailer types and varying payload
conditions, demonstrating robust performance without manual tuning or
trailer-specific calibration.

</details>


### [93] [Optimizing Force Signals from Human Demonstrations of In-Contact Motions](https://arxiv.org/abs/2507.15608)
*Johannes Hartwig,Fabian Viessmann,Dominik Henrich*

Main category: cs.RO

TL;DR: 论文探讨了如何优化力信号以更好地反映人类演示意图，比较了不同信号滤波方法并提出峰值检测方法，提升了机器人编程的可用性。


<details>
  <summary>Details</summary>
Motivation: 针对非机器人编程专家，直观的输入方法（如力引导）在接触任务编程中越来越重要，但人类演示中的不精确和噪声信号会直接影响运动再现或机器学习输入。

Method: 比较了不同信号滤波方法，提出了一种峰值检测方法处理首次接触偏差，并分析了关键参数对滤波方法的影响。

Result: 通过优化力信号，单个运动的误差标准可提升高达20%，提高了机器人编程的可用性和人机交互。

Conclusion: 提出的方法显著改善了力信号与人类意图的匹配，为机器人编程和人机交互提供了更高效的解决方案。

Abstract: For non-robot-programming experts, kinesthetic guiding can be an intuitive
input method, as robot programming of in-contact tasks is becoming more
prominent. However, imprecise and noisy input signals from human demonstrations
pose problems when reproducing motions directly or using the signal as input
for machine learning methods. This paper explores optimizing force signals to
correspond better to the human intention of the demonstrated signal. We compare
different signal filtering methods and propose a peak detection method for
dealing with first-contact deviations in the signal. The evaluation of these
methods considers a specialized error criterion between the input and the
human-intended signal. In addition, we analyze the critical parameters'
influence on the filtering methods. The quality for an individual motion could
be increased by up to \SI{20}{\percent} concerning the error criterion. The
proposed contribution can improve the usability of robot programming and the
interaction between humans and robots.

</details>


### [94] [EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation](https://arxiv.org/abs/2507.15649)
*Haocheng Xu,Haodong Zhang,Zhenghan Chen,Rong Xiong*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的框架，使人形机器人模仿人类上半身动作并保持整体稳定性。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在站立时可控范围有限，影响全身稳定性，需研究如何在执行上半身动作时保持稳定。

Method: 设计了一个重定向网络生成大规模上半身动作数据集，训练强化学习策略，并结合领域随机化提升鲁棒性；提出可执行运动先验（EMP）模块调整输入目标动作。

Result: 通过仿真和实际测试验证了框架的实用性。

Conclusion: 该框架能有效提升人形机器人在执行上半身动作时的稳定性，具有实际应用价值。

Abstract: To support humanoid robots in performing manipulation tasks, it is essential
to study stable standing while accommodating upper-body motions. However, the
limited controllable range of humanoid robots in a standing position affects
the stability of the entire body. Thus we introduce a reinforcement learning
based framework for humanoid robots to imitate human upper-body motions while
maintaining overall stability. Our approach begins with designing a retargeting
network that generates a large-scale upper-body motion dataset for training the
reinforcement learning (RL) policy, which enables the humanoid robot to track
upper-body motion targets, employing domain randomization for enhanced
robustness. To avoid exceeding the robot's execution capability and ensure
safety and stability, we propose an Executable Motion Prior (EMP) module, which
adjusts the input target movements based on the robot's current state. This
adjustment improves standing stability while minimizing changes to motion
amplitude. We evaluate our framework through simulation and real-world tests,
demonstrating its practical applicability.

</details>


### [95] [Data-Driven MPC with Data Selection for Flexible Cable-Driven Robotic Arms](https://arxiv.org/abs/2507.15677)
*Huayue Liang,Yanbo Chen,Hongyang Cheng,Yanzhao Yu,Shoujie Li,Junbo Tan,Xueqian Wang,Long Zeng*

Main category: cs.RO

TL;DR: 提出一种基于输入输出数据的模型预测控制（MPC）方法，无需物理模型即可提高柔性电缆驱动机械臂（FCRA）的控制精度，并通过数据选择算法（DSA）优化计算效率。


<details>
  <summary>Details</summary>
Motivation: 柔性电缆驱动机械臂（FCRA）的电缆特性（如弹性、迟滞和摩擦）导致建模和控制困难，传统方法依赖物理模型，难以精确控制。

Method: 1. 基于输入输出数据构建隐式模型并集成到MPC框架；2. 引入数据选择算法（DSA）优化数据，减少每步计算时间至约4毫秒；3. 通过仿真研究超参数对跟踪误差的影响。

Result: 在真实FCRA平台上验证，定位精度约2.070毫米，跟踪误差0.541度（优于PID方法的1.418度），计算效率提升80%。

Conclusion: 该方法显著提高了FCRA的控制精度和计算效率，适用于复杂任务如轨迹跟踪。

Abstract: Flexible cable-driven robotic arms (FCRAs) offer dexterous and compliant
motion. Still, the inherent properties of cables, such as resilience,
hysteresis, and friction, often lead to particular difficulties in modeling and
control. This paper proposes a model predictive control (MPC) method that
relies exclusively on input-output data, without a physical model, to improve
the control accuracy of FCRAs. First, we develop an implicit model based on
input-output data and integrate it into an MPC optimization framework. Second,
a data selection algorithm (DSA) is introduced to filter the data that best
characterize the system, thereby reducing the solution time per step to
approximately 4 ms, which is an improvement of nearly 80%. Lastly, the
influence of hyperparameters on tracking error is investigated through
simulation. The proposed method has been validated on a real FCRA platform,
including five-point positioning accuracy tests, a five-point response tracking
test, and trajectory tracking for letter drawing. The results demonstrate that
the average positioning accuracy is approximately 2.070 mm. Moreover, compared
to the PID method with an average tracking error of 1.418{\deg}, the proposed
method achieves an average tracking error of 0.541{\deg}.

</details>


### [96] [Strong, Accurate, and Low-Cost Robot Manipulator](https://arxiv.org/abs/2507.15693)
*Georges Chebly,Spencer Little,Nisal Perera,Aliya Abedeen,Ken Suzuki,Donghyun Kim*

Main category: cs.RO

TL;DR: Forte是一款全3D打印、6自由度机械臂，以低于215美元的成本实现接近工业级性能（0.63 kg负载、0.467 m工作范围、亚毫米级重复精度），适用于教育和AI实验。


<details>
  <summary>Details</summary>
Motivation: 突破现有低成本教育机械臂的性能限制，提供一种经济实惠且高性能的机器人平台。

Method: 采用基于capstan的电缆驱动、同步带、简单张紧机构和轻量化3D打印结构，结合拓扑优化提升刚度，并通过精心设计的传动系统减少背隙。

Result: 实验验证显示Forte具有高重复精度和负载能力。

Conclusion: Forte为课堂教学和高级机器人研究提供了一个高性能且经济实惠的平台。

Abstract: This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed
to achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach,
and sub-millimeter repeatability - at a material cost under $215. As an
accessible robot for broad applications across classroom education to AI
experiments, Forte pushes forward the performance limitations of existing
low-cost educational arms. We introduce a cost-effective mechanical design that
combines capstan-based cable drives, timing belts, simple tensioning
mechanisms, and lightweight 3D-printed structures, along with topology
optimization for structural stiffness. Through careful drivetrain engineering,
we minimize backlash and maintain control fidelity without relying on
high-power electronics or expensive manufacturing processes. Experimental
validation demonstrates that Forte achieves high repeatability and load
capacity, offering a compelling robotic platform for both classroom instruction
and advanced robotics research.

</details>


### [97] [Selective Densification for Rapid Motion Planning in High Dimensions with Narrow Passages](https://arxiv.org/abs/2507.15710)
*Lu Huang,Lingxiao Meng,Jiankun Wang,Xingjian Jing*

Main category: cs.RO

TL;DR: 提出了一种高效的多分辨率采样规划框架，通过动态调整采样密度解决复杂配置空间中的导航问题。


<details>
  <summary>Details</summary>
Motivation: 现有采样规划算法在复杂配置空间中效率低，且启发式方法缺乏通用性或需大量训练。

Method: 结合不同粒度的规划，动态调整稀疏与密集采样，提升导航效率。

Result: 在多种配置空间和机器人实验中表现优于现有方法。

Conclusion: 该方法在复杂环境中高效且通用，无需额外训练。

Abstract: Sampling-based algorithms are widely used for motion planning in
high-dimensional configuration spaces. However, due to low sampling efficiency,
their performance often diminishes in complex configuration spaces with narrow
corridors. Existing approaches address this issue using handcrafted or learned
heuristics to guide sampling toward useful regions. Unfortunately, these
strategies often lack generalizability to various problems or require extensive
prior training. In this paper, we propose a simple yet efficient sampling-based
planning framework along with its bidirectional version that overcomes these
issues by integrating different levels of planning granularity. Our approach
probes configuration spaces with uniform random samples at varying resolutions
and explores these multi-resolution samples online with a bias towards sparse
samples when traveling large free configuration spaces. By seamlessly
transitioning between sparse and dense samples, our approach can navigate
complex configuration spaces while maintaining planning speed and completeness.
The simulation results demonstrate that our approach outperforms several
state-of-the-art sampling-based planners in $\mathbb{SE}(2)$, $\mathbb{SE}(3)$,
and $\mathbb{R}^{14}$ with challenging terrains. Furthermore, experiments
conducted with the Franka Emika Panda robot operating in a constrained
workspace provide additional evidence of the superiority of the proposed
method.

</details>


### [98] [DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models](https://arxiv.org/abs/2507.15716)
*Ziyu Wan,Lin Zhao*

Main category: cs.RO

TL;DR: DiffPF是一种基于扩散模型的可微分粒子滤波器，用于动态系统的状态估计，通过学习灵活的后验采样器，显著提升了复杂高维多模态分布下的估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统可微分粒子滤波器依赖预定义或低容量提议分布，限制了其在复杂分布下的性能。DiffPF旨在通过扩散模型实现更灵活、准确的后验采样。

Method: DiffPF利用扩散模型，基于预测粒子和当前观测条件化，学习后验采样器，实现高维多模态分布下的等权重采样。

Result: 在仿真和真实任务中，DiffPF表现优异，多模态全局定位任务中估计精度提升82.8%，KITTI视觉里程计任务中提升26%。

Conclusion: DiffPF首次将条件扩散模型引入粒子滤波，实现了高质量后验采样，显著提升了状态估计性能。

Abstract: This paper proposes DiffPF, a differentiable particle filter that leverages
diffusion models for state estimation in dynamic systems. Unlike conventional
differentiable particle filters, which require importance weighting and
typically rely on predefined or low-capacity proposal distributions. DiffPF
learns a flexible posterior sampler by conditioning a diffusion model on
predicted particles and the current observation. This enables accurate,
equally-weighted sampling from complex, high-dimensional, and multimodal
filtering distributions. We evaluate DiffPF across a range of scenarios,
including both unimodal and highly multimodal distributions, and test it on
simulated as well as real-world tasks, where it consistently outperforms
existing filtering baselines. In particular, DiffPF achieves an 82.8%
improvement in estimation accuracy on a highly multimodal global localization
benchmark, and a 26% improvement on the real-world KITTI visual odometry
benchmark, compared to state-of-the-art differentiable filters. To the best of
our knowledge, DiffPF is the first method to integrate conditional diffusion
models into particle filtering, enabling high-quality posterior sampling that
produces more informative particles and significantly improves state
estimation.

</details>


### [99] [Gaze-supported Large Language Model Framework for Bi-directional Human-Robot Interaction](https://arxiv.org/abs/2507.15729)
*Jens V. Rüppel,Andrey Rudenko,Tim Schreiter,Martin Magnusson,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 论文提出了一种基于大语言模型（LLM）的人机交互（HRI）系统，通过多模态输入（如视线和语音）支持动态用户任务，并对比了其与传统脚本化HRI系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有HRI系统在双向、多模态和上下文感知的协作任务支持方面仍存在挑战，本文旨在通过LLM提升交互的灵活性和适应性。

Method: 设计了一个模块化、可迁移的系统，结合多视觉输入和实时语言交互状态表示，并通过实验与传统脚本化HRI系统对比。

Result: LLM方法增强了适应性并略微提升了用户参与度和任务执行效果，但可能产生冗余输出；脚本化系统更适合简单任务。

Conclusion: LLM驱动的HRI系统在复杂任务中表现更优，但需优化冗余问题；脚本化系统在简单任务中仍具优势。

Abstract: The rapid development of Large Language Models (LLMs) creates an exciting
potential for flexible, general knowledge-driven Human-Robot Interaction (HRI)
systems for assistive robots. Existing HRI systems demonstrate great progress
in interpreting and following user instructions, action generation, and robot
task solving. On the other hand, bi-directional, multi-modal, and context-aware
support of the user in collaborative tasks still remains an open challenge. In
this paper, we present a gaze- and speech-informed interface to the assistive
robot, which is able to perceive the working environment from multiple vision
inputs and support the dynamic user in their tasks. Our system is designed to
be modular and transferable to adapt to diverse tasks and robots, and it is
capable of real-time use of language-based interaction state representation and
fast on board perception modules. Its development was supported by multiple
public dissemination events, contributing important considerations for improved
robustness and user experience. Furthermore, in two lab studies, we compare the
performance and user ratings of our system with those of a traditional scripted
HRI pipeline. Our findings indicate that an LLM-based approach enhances
adaptability and marginally improves user engagement and task execution metrics
but may produce redundant output, while a scripted pipeline is well suited for
more straightforward tasks.

</details>


### [100] [Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs](https://arxiv.org/abs/2507.15782)
*Ruochu Yang,Yu Zhou,Fumin Zhang,Mengxue Hou*

Main category: cs.RO

TL;DR: 提出了一种新型的Inter-LLM算法，通过结合LLM和运动规划，解决了家庭机器人在多对象收集任务中的长时规划问题，性能提升30%。


<details>
  <summary>Details</summary>
Motivation: 家庭机器人在处理开放集对象和高效导航方面缺乏人类智能，需要解决多对象收集任务的长时规划挑战。

Method: 设计了多模态动作成本相似性函数，结合LLM和运动规划，优化历史与未来规划。

Result: 仿真实验显示，算法在完成任务、成功率和成本方面比现有方法提升30%。

Conclusion: Inter-LLM算法在多对象收集任务中实现了高效且高质量的规划。

Abstract: Household robots have been a longstanding research topic, but they still lack
human-like intelligence, particularly in manipulating open-set objects and
navigating large environments efficiently and accurately. To push this
boundary, we consider a generalized multi-object collection problem in large
scene graphs, where the robot needs to pick up and place multiple objects
across multiple locations in a long mission of multiple human commands. This
problem is extremely challenging since it requires long-horizon planning in a
vast action-state space under high uncertainties. To this end, we propose a
novel interleaved LLM and motion planning algorithm Inter-LLM. By designing a
multimodal action cost similarity function, our algorithm can both reflect the
history and look into the future to optimize plans, striking a good balance of
quality and efficiency. Simulation experiments demonstrate that compared with
latest works, our algorithm improves the overall mission performance by 30% in
terms of fulfilling human commands, maximizing mission success rates, and
minimizing mission costs.

</details>


### [101] [Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers](https://arxiv.org/abs/2507.15833)
*Ian Chuang,Andrew Lee,Dechen Gao,Jinyu Zou,Iman Soltani*

Main category: cs.RO

TL;DR: 论文探讨了将人类主动注视机制引入机器人视觉系统，以提高效率和性能，提出了一种结合注视数据的机器人策略框架。


<details>
  <summary>Details</summary>
Motivation: 人类视觉通过主动注视高效处理任务相关区域，而机器人通常被动处理图像。研究旨在通过模拟人类注视机制提升机器人视觉系统的性能。

Method: 结合注视数据和机器人演示，提出了一种基于Vision Transformers的注视引导视觉处理框架，包括注视预测和动作联合预测两种方法。

Result: 该方法显著降低了计算开销，提升了高精度任务的性能和对未知干扰的鲁棒性。

Conclusion: 人类启发的视觉处理为机器人视觉系统提供了有效的归纳偏置。

Abstract: Human vision is a highly active process driven by gaze, which directs
attention and fixation to task-relevant regions and dramatically reduces visual
processing. In contrast, robot learning systems typically rely on passive,
uniform processing of raw camera images. In this work, we explore how
incorporating human-like active gaze into robotic policies can enhance both
efficiency and performance. We build on recent advances in foveated image
processing and apply them to an Active Vision robot system that emulates both
human head movement and eye tracking. Extending prior work on the AV-ALOHA
robot simulation platform, we introduce a framework for simultaneously
collecting eye-tracking data and robot demonstrations from a human operator as
well as a simulation benchmark and dataset for training robot policies that
incorporate human gaze. Given the widespread use of Vision Transformers (ViTs)
in robot learning, we integrate gaze information into ViTs using a foveated
patch tokenization scheme inspired by recent work in image segmentation.
Compared to uniform patch tokenization, this significantly reduces the number
of tokens-and thus computation-without sacrificing visual fidelity near regions
of interest. We also explore two approaches to gaze imitation and prediction
from human data. The first is a two-stage model that predicts gaze to guide
foveation and action; the second integrates gaze into the action space,
allowing the policy to jointly predict gaze and actions end-to-end. Our results
show that our method for foveated robot vision not only drastically reduces
computational overhead, but also improves performance for high precision tasks
and robustness to unseen distractors. Together, these findings suggest that
human-inspired visual processing offers a useful inductive bias for robotic
vision systems. https://ian-chuang.github.io/gaze-av-aloha/

</details>
