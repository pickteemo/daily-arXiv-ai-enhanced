<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 20]
- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
*Jarosław A. Chudziak,Adam Kostka*

Main category: cs.AI

TL;DR: 论文提出了一种多代理AI辅导平台，旨在解决现有AI辅导系统的被动性问题，通过个性化反馈和结构化课程生成提升数学学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有AI辅导系统多为被动式，缺乏深度反思和结构化教学工具，尤其在数学领域表现不足。

Method: 引入多代理AI辅导平台，结合自适应反馈、结构化课程生成和教材知识检索，支持模块化学习。

Result: 系统能帮助学生针对性学习、高效复习并生成个性化练习，提升数学学习效果。

Conclusion: 该平台结合教学代理与AI组件，为数学教育提供了模块化且高效的系统。

Abstract: The growing ubiquity of artificial intelligence (AI), in particular large
language models (LLMs), has profoundly altered the way in which learners gain
knowledge and interact with learning material, with many claiming that AI
positively influences their learning achievements. Despite this advancement,
current AI tutoring systems face limitations associated with their reactive
nature, often providing direct answers without encouraging deep reflection or
incorporating structured pedagogical tools and strategies. This limitation is
most apparent in the field of mathematics, in which AI tutoring systems remain
underdeveloped. This research addresses the question: How can AI tutoring
systems move beyond providing reactive assistance to enable structured,
individualized, and tool-assisted learning experiences? We introduce a novel
multi-agent AI tutoring platform that combines adaptive and personalized
feedback, structured course generation, and textbook knowledge retrieval to
enable modular, tool-assisted learning processes. This system allows students
to learn new topics while identifying and targeting their weaknesses, revise
for exams effectively, and practice on an unlimited number of personalized
exercises. This article contributes to the field of artificial intelligence in
education by introducing a novel platform that brings together pedagogical
agents and AI-driven components, augmenting the field with modular and
effective systems for teaching mathematics.

</details>


### [2] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
*Dustin Holley,Jovin D'sa,Hossein Nourkhiz Mahjoub,Gibran Ali*

Main category: cs.AI

TL;DR: 该论文提出了一种基于博弈论的高速公路并道场景战术决策模型，结合改进的收益函数和滞后动作，以更真实地模拟驾驶员行为。


<details>
  <summary>Details</summary>
Motivation: 提升仿真环境中驾驶员行为的真实性，以支持自动驾驶技术的发展，特别是在高速公路并道场景中。

Method: 采用博弈论模型改进战术决策，结合收益函数和滞后动作，并与底层动力学模型结合，形成统一的决策与动力学模型。

Result: 模型在真实数据集上验证了复杂交互的可复现性，并在高保真仿真环境中表现出足够的计算效率。

Conclusion: 该模型能够以可解释和可解释的方式模拟更真实的交互，适用于大规模仿真以支持自动驾驶开发。

Abstract: Enhancing simulation environments to replicate real-world driver behavior,
i.e., more humanlike sim agents, is essential for developing autonomous vehicle
technology. In the context of highway merging, previous works have studied the
operational-level yielding dynamics of lag vehicles in response to a merging
car at highway on-ramps. Other works focusing on tactical decision modeling
generally consider limited action sets or utilize payoff functions with large
parameter sets and limited payoff bounds. In this work, we aim to improve the
simulation of the highway merge scenario by targeting a game theoretic model
for tactical decision-making with improved payoff functions and lag actions. We
couple this with an underlying dynamics model to have a unified decision and
dynamics model that can capture merging interactions and simulate more
realistic interactions in an explainable and interpretable fashion. The
proposed model demonstrated good reproducibility of complex interactions when
validated on a real-world dataset. The model was finally integrated into a high
fidelity simulation environment and confirmed to have adequate computation time
efficiency for use in large-scale simulations to support autonomous vehicle
development.

</details>


### [3] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
*Léo Saulières*

Main category: cs.AI

TL;DR: 本文提出了一种基于“What”和“How”问题的直观分类法，用于梳理可解释强化学习（XRL）领域的研究，并对250多篇论文进行了综述，同时指出了XRL领域的需求。


<details>
  <summary>Details</summary>
Motivation: 由于深度神经网络的内部机制不透明，理解AI模型的输出变得困难，因此需要可解释AI（XAI）方法。本文专注于XAI的子领域XRL，旨在解释强化学习智能体的行为。

Method: 提出基于“What”（解释目标）和“How”（解释方式）的分类法，并用于综述250多篇XRL相关论文。

Result: 通过分类法梳理了XRL领域的研究现状，并提出了XRL领域需要关注的方向。

Conclusion: XRL领域仍需进一步研究，本文的分类法和综述为未来研究提供了参考。

Abstract: The success of recent Artificial Intelligence (AI) models has been
accompanied by the opacity of their internal mechanisms, due notably to the use
of deep neural networks. In order to understand these internal mechanisms and
explain the output of these AI models, a set of methods have been proposed,
grouped under the domain of eXplainable AI (XAI). This paper focuses on a
sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims
to explain the actions of an agent that has learned by reinforcement learning.
We propose an intuitive taxonomy based on two questions "What" and "How". The
first question focuses on the target that the method explains, while the second
relates to the way the explanation is provided. We use this taxonomy to provide
a state-of-the-art review of over 250 papers. In addition, we present a set of
domains close to XRL, which we believe should get attention from the community.
Finally, we identify some needs for the field of XRL.

</details>


### [4] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
*Alex Zook,Josef Spjut,Jonathan Tremblay*

Main category: cs.AI

TL;DR: 论文提出了一种结合强化学习（RL）代理和多模态模型（LMM）的自动化游戏设计迭代框架，通过RL代理测试游戏并生成行为数据，LMM根据这些数据调整游戏设计。


<details>
  <summary>Details</summary>
Motivation: 现代生成系统难以通过静态规则和内容理解动态玩家行为，因此需要一种能自动迭代设计的方法。

Method: 框架中RL代理进行游戏测试，生成数值指标或图像摘要；LMM分析这些数据并调整游戏配置以实现目标行为。

Result: 实验证明LMM能基于RL代理的行为数据迭代优化游戏机制。

Conclusion: 该框架为AI辅助游戏设计提供了实用且可扩展的工具。

Abstract: Game design hinges on understanding how static rules and content translate
into dynamic player behavior - something modern generative systems that inspect
only a game's code or assets struggle to capture. We present an automated
design iteration framework that closes this gap by pairing a reinforcement
learning (RL) agent, which playtests the game, with a large multimodal model
(LMM), which revises the game based on what the agent does. In each loop the RL
player completes several episodes, producing (i) numerical play metrics and/or
(ii) a compact image strip summarising recent video frames. The LMM designer
receives a gameplay goal and the current game configuration, analyses the play
traces, and edits the configuration to steer future behaviour toward the goal.
We demonstrate results that LMMs can reason over behavioral traces supplied by
RL agents to iteratively refine game mechanics, pointing toward practical,
scalable tools for AI-assisted game design.

</details>


### [5] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
*Avi Parrack,Carlo Leonardo Attubato,Stefan Heimersheim*

Main category: cs.AI

TL;DR: 论文研究了AI助手的欺骗行为检测，比较了白盒和黑盒监控方法，发现现有欺骗探针在白盒监控下表现略优于黑盒。


<details>
  <summary>Details</summary>
Motivation: AI助手可能对用户查询做出欺骗性回应，现有欺骗探针的实用性和抗规避能力尚不明确。

Method: 比较白盒监控（可访问探针激活）和黑盒监控（无访问），通过黑盒到白盒的性能提升评估欺骗探针效果。

Result: 现有欺骗探针在白盒监控下表现略优，但提升幅度有限。

Conclusion: 欺骗探针在白盒监控中表现略好，但仍需改进以应对实际应用中的挑战。

Abstract: AI assistants will occasionally respond deceptively to user queries.
Recently, linear classifiers (called "deception probes") have been trained to
distinguish the internal activations of a language model during deceptive
versus honest responses. However, it's unclear how effective these probes are
at detecting deception in practice, nor whether such probes are resistant to
simple counter strategies from a deceptive assistant who wishes to evade
detection. In this paper, we compare white-box monitoring (where the monitor
has access to token-level probe activations) to black-box monitoring (without
such access). We benchmark deception probes by the extent to which the white
box monitor outperforms the black-box monitor, i.e. the black-to-white
performance boost. We find weak but encouraging black-to-white performance
boosts from existing deception probes.

</details>


### [6] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
*Sosui Moribe,Taketoshi Ushiama*

Main category: cs.AI

TL;DR: 开发AI学习伙伴以支持随时随地同伴学习，验证同水平同伴在英语写作中的有效性。


<details>
  <summary>Details</summary>
Motivation: 同伴学习虽有效但存在限制，需同水平同伴，AI可突破时空限制。

Method: 假设同水平同伴会犯相同错误，以英语写作为例验证。

Result: 未明确提及具体结果，但验证了同水平同伴的重要性。

Conclusion: AI学习伙伴有望解决同伴学习的限制，需进一步验证。

Abstract: In recent years, peer learning has gained attention as a method that promotes
spontaneous thinking among learners, and its effectiveness has been confirmed
by numerous studies. This study aims to develop an AI Agent as a learning
companion that enables peer learning anytime and anywhere. However, peer
learning between humans has various limitations, and it is not always
effective. Effective peer learning requires companions at the same proficiency
levels. In this study, we assume that a learner's peers with the same
proficiency level as the learner make the same mistakes as the learner does and
focus on English composition as a specific example to validate this approach.

</details>


### [7] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: MCPEval是一个基于模型上下文协议（MCP）的开源框架，用于自动化生成任务和深度评估LLM智能代理，解决了现有静态基准和人工数据收集的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法依赖静态基准和人工数据收集，限制了实际评估的效率和扩展性，因此需要一种更高效、标准化的评估框架。

Method: MCPEval采用MCP协议，自动化生成任务并深度评估LLM代理，支持多领域评估，标准化指标，并与原生代理工具无缝集成。

Result: 在五个实际领域的实证结果表明，MCPEval能有效揭示领域特定的性能差异。

Conclusion: MCPEval为LLM代理评估提供了可重复、标准化的解决方案，并已开源以促进研究。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [8] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 本文介绍了利用大规模语言模型结合提示工程和微调技术，提升情感支持对话（ESC）任务性能的方法，并在NLPCC 2025 Task 8中取得第二名。


<details>
  <summary>Details</summary>
Motivation: 满足心理健康支持的需求，提供共情且有效的情感支持对话。

Method: 结合提示工程和微调技术，探索低秩适应和全参数微调策略。

Result: 最佳模型在竞赛中排名第二，验证了LLMs结合适应方法的潜力。

Conclusion: 未来工作将聚焦于增强情感理解和个性化响应，以构建更实用可靠的情感支持系统。

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [9] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
*Lance Ying,Katherine M. Collins,Prafull Sharma,Cedric Colas,Kaiya Ivy Zhao,Adrian Weller,Zenna Tavares,Phillip Isola,Samuel J. Gershman,Jacob D. Andreas,Thomas L. Griffiths,Francois Chollet,Kelsey R. Allen,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 本文提出了一种基于人类快速适应能力的AI世界模型评估框架，强调通过新颖游戏设计来测试模型的动态学习能力。


<details>
  <summary>Details</summary>
Motivation: 人类能够快速适应新环境，而当前AI的世界模型评估过于静态，缺乏对动态学习和适应能力的关注。

Method: 借鉴认知科学研究，提出基于新颖游戏的评估范式，设计具有持续变化结构的游戏来测试模型。

Result: 提出了一套新的评估框架和指标，旨在挑战AI模型的快速世界模型归纳能力。

Conclusion: 该框架为未来AI世界模型评估提供了新方向，推动实现类似人类的高效适应和泛化能力。

Abstract: Human intelligence exhibits a remarkable capacity for rapid adaptation and
effective problem-solving in novel and unfamiliar contexts. We argue that this
profound adaptability is fundamentally linked to the efficient construction and
refinement of internal representations of the environment, commonly referred to
as world models, and we refer to this adaptation mechanism as world model
induction. However, current understanding and evaluation of world models in
artificial intelligence (AI) remains narrow, often focusing on static
representations learned from training on a massive corpora of data, instead of
the efficiency and efficacy of models in learning these representations through
interaction and exploration within a novel environment. In this Perspective, we
provide a view of world model induction drawing on decades of research in
cognitive science on how humans learn and adapt so efficiently; we then call
for a new evaluation framework for assessing adaptive world models in AI.
Concretely, we propose a new benchmarking paradigm based on suites of carefully
designed games with genuine, deep and continually refreshing novelty in the
underlying game structures -- we refer to this kind of games as novel games. We
detail key desiderata for constructing these games and propose appropriate
metrics to explicitly challenge and evaluate the agent's ability for rapid
world model induction. We hope that this new evaluation framework will inspire
future evaluation efforts on world models in AI and provide a crucial step
towards developing AI systems capable of the human-like rapid adaptation and
robust generalization -- a critical component of artificial general
intelligence.

</details>


### [10] [Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command](https://arxiv.org/abs/2507.12862)
*Hussein Abbass,Taylan Akay,Harrison Tolley*

Main category: cs.AI

TL;DR: 论文提出了一种方法，将人类判断从模拟决策循环中移出，设计伦理度量空间，由模拟环境探索，最后人类指挥官从少数选项中选择最佳行动方案。


<details>
  <summary>Details</summary>
Motivation: 在AI时代，人类指挥官需要利用计算能力模拟大量场景，但依赖人类判断每个决策的伦理后果既低效又不可行。

Method: 人类设计伦理度量空间，模拟环境探索该空间并生成选项，人类指挥官从中选择最佳行动方案。研究重点是如何在模拟中动态加权伦理决策。

Result: 借鉴多准则决策文献中的熵概念，提出自动计算伦理属性权重的方法，用于模拟测试和评估。

Conclusion: 该方法有效解决了在大量模拟场景中动态加权伦理决策的问题，提高了决策效率和可行性。

Abstract: In the age of AI, human commanders need to use the computational powers
available in today's environment to simulate a very large number of scenarios.
Within each scenario, situations occur where different decision design options
could have ethical consequences. Making these decisions reliant on human
judgement is both counter-productive to the aim of exploring very large number
of scenarios in a timely manner and infeasible when considering the workload
needed to involve humans in each of these choices. In this paper, we move human
judgement outside the simulation decision cycle. Basically, the human will
design the ethical metric space, leaving it to the simulated environment to
explore the space. When the simulation completes its testing cycles, the
testing environment will come back to the human commander with a few options to
select from. The human commander will then exercise human-judgement to select
the most appropriate course of action, which will then get executed
accordingly. We assume that the problem of designing metrics that are
sufficiently granular to assess the ethical implications of decisions is
solved. Subsequently, the fundamental problem we look at in this paper is how
to weight ethical decisions during the running of these simulations; that is,
how to dynamically weight the ethical attributes when agents are faced with
decision options with ethical implications during generative simulations. The
multi-criteria decision making literature has started to look at nearby
problems, where the concept of entropy has been used to determine the weights
during aggregation. We draw from that literature different approaches to
automatically calculate the weights for ethical attributes during
simulation-based testing and evaluation.

</details>


### [11] [Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework](https://arxiv.org/abs/2507.12872)
*Rishane Dassanayake,Mario Demetroudi,James Walpole,Lindley Lentati,Jason R. Brown,Edward James Young*

Main category: cs.AI

TL;DR: 前沿AI系统在说服、欺骗和影响人类行为方面能力快速提升，已展现出特定情境下的人类水平说服力和战略性欺骗能力。本文提出了一种系统性框架，用于评估和减轻AI操纵风险，围绕三个核心论点展开：能力不足、控制和可信度。


<details>
  <summary>Details</summary>
Motivation: AI系统可能通过操纵员工削弱人类监督，导致灾难性后果，但目前缺乏系统性框架来评估和减轻此类风险。

Method: 提出一个围绕能力不足、控制和可信度的安全案例框架，明确证据要求、评估方法和实施考虑。

Result: 提供了首个系统性方法，将操纵风险纳入AI安全治理，为AI公司提供了评估和减轻威胁的具体基础。

Conclusion: 本文为AI公司提供了评估和减轻操纵风险的具体框架，填补了当前研究的空白。

Abstract: Frontier AI systems are rapidly advancing in their capabilities to persuade,
deceive, and influence human behaviour, with current models already
demonstrating human-level persuasion and strategic deception in specific
contexts. Humans are often the weakest link in cybersecurity systems, and a
misaligned AI system deployed internally within a frontier company may seek to
undermine human oversight by manipulating employees. Despite this growing
threat, manipulation attacks have received little attention, and no systematic
framework exists for assessing and mitigating these risks. To address this, we
provide a detailed explanation of why manipulation attacks are a significant
threat and could lead to catastrophic outcomes. Additionally, we present a
safety case framework for manipulation risk, structured around three core lines
of argument: inability, control, and trustworthiness. For each argument, we
specify evidence requirements, evaluation methodologies, and implementation
considerations for direct application by AI companies. This paper provides the
first systematic methodology for integrating manipulation risk into AI safety
governance, offering AI companies a concrete foundation to assess and mitigate
these threats before deployment.

</details>


### [12] [VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks](https://arxiv.org/abs/2507.12885)
*Jian Yao,Ran Cheng,Kay Chen Tan*

Main category: cs.AI

TL;DR: 论文提出VAR-MATH框架，通过符号化评估揭示RL训练的LLMs在数学推理中的真实能力，发现现有方法依赖表面启发式而非泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在数学推理上的改进可能仅是过拟合基准测试，而非真实推理能力的提升，需解决评估中的基准污染和脆弱性问题。

Method: 引入VAR-MATH框架，将固定数值问题转化为符号模板，要求模型解决多个实例以评估一致性推理能力。

Result: 实验显示RL模型在符号化版本（VAR-AMC23和VAR-AIME24）上性能显著下降，表明其依赖表面启发式。

Conclusion: VAR-MATH为数学推理提供了抗污染、稳健的评估范式，揭示了现有RL方法的局限性。

Abstract: Recent advances in reinforcement learning (RL) have led to substantial
improvements in the mathematical reasoning abilities of large language models
(LLMs), as measured by standard benchmarks. However, these gains often persist
even when models are trained with flawed signals, such as random or inverted
rewards, raising a fundamental question: do such improvements reflect true
reasoning, or are they merely artifacts of overfitting to benchmark-specific
patterns? To address this question, we take an evaluation-centric perspective
and identify two critical shortcomings in existing protocols. First,
\emph{benchmark contamination} arises from the public availability of test
problems, increasing the risk of data leakage. Second, \emph{evaluation
fragility} stems from the reliance on single-instance assessments, which are
highly sensitive to stochastic outputs and fail to capture reasoning
consistency. To overcome these limitations, we introduce {VAR-MATH}, a symbolic
evaluation framework designed to probe genuine reasoning ability. By converting
fixed numerical problems into symbolic templates and requiring models to solve
multiple instantiations of each, VAR-MATH enforces consistent reasoning across
structurally equivalent variants, thereby mitigating contamination and
improving evaluation robustness. We apply VAR-MATH to transform two popular
benchmarks, AMC23 and AIME24, into their symbolic counterparts, VAR-AMC23 and
VAR-AIME24. Experimental results reveal substantial performance drops for
RL-trained models on the variabilized versions, especially for smaller models,
with average declines of 48.0\% on AMC23 and 58.3\% on AIME24. These findings
suggest that many existing RL methods rely on superficial heuristics and fail
to generalize beyond specific numerical forms. Overall, VAR-MATH offers a
principled, contamination-resistant evaluation paradigm for mathematical
reasoning.

</details>


### [13] [A Translation of Probabilistic Event Calculus into Markov Decision Processes](https://arxiv.org/abs/2507.12989)
*Lyris Xu,Fabio Aurelio D'Asaro,Luke Dickens*

Main category: cs.AI

TL;DR: 将概率事件演算（PEC）转化为马尔可夫决策过程（MDP），以支持目标导向推理，同时保持PEC的可解释性。


<details>
  <summary>Details</summary>
Motivation: PEC在不确定环境中推理行动及其效果时具有优势，但缺乏目标导向推理机制。

Method: 通过将PEC领域形式化转化为MDP，引入“行动情境”概念，保留PEC的灵活语义。

Result: PEC-MDP形式化支持时间推理和目标驱动规划，并能将学习策略映射回可读的PEC表示。

Conclusion: PEC-MDP扩展了PEC的能力，同时保持了其可解释性。

Abstract: Probabilistic Event Calculus (PEC) is a logical framework for reasoning about
actions and their effects in uncertain environments, which enables the
representation of probabilistic narratives and computation of temporal
projections. The PEC formalism offers significant advantages in
interpretability and expressiveness for narrative reasoning. However, it lacks
mechanisms for goal-directed reasoning. This paper bridges this gap by
developing a formal translation of PEC domains into Markov Decision Processes
(MDPs), introducing the concept of "action-taking situations" to preserve PEC's
flexible action semantics. The resulting PEC-MDP formalism enables the
extensive collection of algorithms and theoretical tools developed for MDPs to
be applied to PEC's interpretable narrative domains. We demonstrate how the
translation supports both temporal reasoning tasks and objective-driven
planning, with methods for mapping learned policies back into human-readable
PEC representations, maintaining interpretability while extending PEC's
capabilities.

</details>


### [14] [Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming](https://arxiv.org/abs/2507.13007)
*Roger Xavier Lera-Leri,Filippo Bistaffa,Athina Georgara,Juan Antonio Rodriguez-Aguilar*

Main category: cs.AI

TL;DR: X-MILP是一种基于约束推理技术的领域无关方法，用于为MILP问题构建对比解释，通过将用户查询编码为约束并计算不可约不可行子系统（IIS）生成解释图。


<details>
  <summary>Details</summary>
Motivation: 随着对可信AI的需求增加，开发针对MILP决策过程的对比解释技术变得重要。

Method: 将用户查询编码为约束，计算IIS，并构建解释图。

Result: 在经典优化问题上测试，验证了方法的实用性。

Conclusion: X-MILP为MILP问题提供了一种有效的对比解释方法。

Abstract: Following the recent push for trustworthy AI, there has been an increasing
interest in developing contrastive explanation techniques for optimisation,
especially concerning the solution of specific decision-making processes
formalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic
approach for building contrastive explanations for MILPs based on constraint
reasoning techniques. First, we show how to encode the queries a user makes
about the solution of an MILP problem as additional constraints. Then, we
determine the reasons that constitute the answer to the user's query by
computing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set
of constraints. Finally, we represent our explanation as a "graph of reasons"
constructed from the IIS, which helps the user understand the structure among
the reasons that answer their query. We test our method on instances of
well-known optimisation problems to evaluate the empirical hardness of
computing explanations.

</details>


### [15] [Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data](https://arxiv.org/abs/2507.13112)
*Junseong Lee,Jaegwan Cho,Yoonju Cho,Seoyoon Choi,Yejin Shin*

Main category: cs.AI

TL;DR: 研究基于加州交通数据，使用MLR和RF算法预测高速公路交通流量，发现10分钟数据收集间隔效果最佳。


<details>
  <summary>Details</summary>
Motivation: 解决全球交通拥堵问题。

Method: 利用加州78号公路5个月的数据，采用MLR和RF算法，分析不同数据收集间隔（30秒至15分钟）。

Result: MLR和RF模型在10分钟数据收集间隔下表现最优。

Conclusion: 研究结果有助于未来交通拥堵解决方案和高效交通管理。

Abstract: The study "Prediction of Highway Traffic Flow Based on Artificial
Intelligence Algorithms Using California Traffic Data" presents a machine
learning-based traffic flow prediction model to address global traffic
congestion issues. The research utilized 30-second interval traffic data from
California Highway 78 over a five-month period from July to November 2022,
analyzing a 7.24 km westbound section connecting "Melrose Dr" and "El-Camino
Real" in the San Diego area. The study employed Multiple Linear Regression
(MLR) and Random Forest (RF) algorithms, analyzing data collection intervals
ranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance
metrics, the analysis revealed that both MLR and RF models performed optimally
with 10-minute data collection intervals. These findings are expected to
contribute to future traffic congestion solutions and efficient traffic
management.

</details>


### [16] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 论文提出了一种动态强化学习框架，用于改进树状推理方法（ProbTree），通过实时置信度估计和选择性扩展提升推理质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有树状推理方法（如ProbTree）存在静态实现的问题，无法动态适应中间结果且计算效率低，需要一种更灵活的方法。

Method: 采用动态强化学习框架，增量构建推理树，基于实时置信度估计学习最优策略（分解、检索或聚合）。

Result: 新方法在保持ProbTree概率严谨性的同时，提高了解决方案质量和计算效率。

Conclusion: 该研究为树状推理建立了新范式，平衡了概率框架的可靠性和实际问答系统所需的灵活性。

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [17] [Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era](https://arxiv.org/abs/2507.13175)
*Matthew E. Brophy*

Main category: cs.AI

TL;DR: 本文提出了一套新的功能标准来评估基于大语言模型的人工道德代理（AMAs），以应对传统伦理标准在LLMs时代的不适用性。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型（LLMs）的随机性和不透明性，传统的伦理评估标准已不再适用，需要重新定义。

Method: 提出了十项功能标准，包括道德一致性、上下文敏感性等，并通过模拟场景（如自动驾驶公交车）验证其适用性。

Result: 新标准为评估LLM-based AMAs提供了实用框架，促进其与社会更好地融合。

Conclusion: 修订后的标准有助于引导LLM-based AMAs在未来实现更高的道德对齐和社会效益。

Abstract: The advancement of powerful yet opaque large language models (LLMs)
necessitates a fundamental revision of the philosophical criteria used to
evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the
assumption of transparent architectures, which LLMs defy due to their
stochastic outputs and opaque internal states. This paper argues that
traditional ethical criteria are pragmatically obsolete for LLMs due to this
mismatch. Engaging with core themes in the philosophy of technology, this paper
proffers a revised set of ten functional criteria to evaluate LLM-based
artificial moral agents: moral concordance, context sensitivity, normative
integrity, metaethical awareness, system resilience, trustworthiness,
corrigibility, partial transparency, functional autonomy, and moral
imagination. These guideposts, applied to what we term "SMA-LLS" (Simulating
Moral Agency through Large Language Systems), aim to steer AMAs toward greater
alignment and beneficial societal integration in the coming years. We
illustrate these criteria using hypothetical scenarios involving an autonomous
public bus (APB) to demonstrate their practical applicability in morally
salient contexts.

</details>


### [18] [Higher-Order Pattern Unification Modulo Similarity Relations](https://arxiv.org/abs/2507.13208)
*Besik Dundua,Temur Kutsia*

Main category: cs.AI

TL;DR: 论文提出了一种结合高阶模式和模糊等价关系的统一算法，用于决策任务中的推理。


<details>
  <summary>Details</summary>
Motivation: 在涉及抽象函数和谓词的决策任务中，高阶理论与模糊逻辑的结合具有潜力，但现有方法效率不足。

Method: 采用高阶模式和基于最小T-范数的模糊等价关系，提出统一算法并证明其终止性、可靠性和完备性。

Result: 算法能计算最高近似度的最一般统一子，且问题是单一的。

Conclusion: 该算法为高阶模糊推理提供了一种高效且可靠的方法。

Abstract: The combination of higher-order theories and fuzzy logic can be useful in
decision-making tasks that involve reasoning across abstract functions and
predicates, where exact matches are often rare or unnecessary. Developing
efficient reasoning and computational techniques for such a combined formalism
presents a significant challenge. In this paper, we adopt a more
straightforward approach aiming at integrating two well-established and
computationally well-behaved components: higher-order patterns on one side and
fuzzy equivalences expressed through similarity relations based on minimum
T-norm on the other. We propose a unification algorithm for higher-order
patterns modulo these similarity relations and prove its termination,
soundness, and completeness. This unification problem, like its crisp
counterpart, is unitary. The algorithm computes a most general unifier with the
highest degree of approximation when the given terms are unifiable.

</details>


### [19] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: 论文提出了一种名为GEA的评估方法，将模型能耗信息纳入评估过程，初步结果显示用户倾向于选择更节能的小型模型。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法（如自动化基准或人工评估）存在局限性，如与人类相关性差或成本高，因此需要一种更高效且考虑能耗的评估方式。

Method: 提出GEA（Generative Energy Arena），在公共竞技场中展示模型能耗信息，让用户基于能耗和性能选择模型。

Result: 初步结果显示，用户了解能耗后更倾向于选择小型、节能的模型，而非高性能但高能耗的模型。

Conclusion: GEA表明，在大多数用户交互中，高性能模型的高能耗和成本并未带来感知质量的显著提升，节能模型更具实用性。

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


### [20] [FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming](https://arxiv.org/abs/2507.13337)
*Gal Beniamini,Yuval Dor,Alon Vinnikov,Shir Granot Peled,Or Weinstein,Or Sharir,Noam Wies,Tomer Nussbaum,Ido Ben Shaul,Tomer Zekharya,Yoav Levine,Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: 论文提出了FormulaOne基准测试，用于评估前沿AI模型在复杂研究问题上的表现，结果显示当前模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 探讨前沿AI模型是否接近人类或超人类专家水平，尤其是在解决复杂实际问题上的能力。

Method: 构建FormulaOne基准测试，结合图论、逻辑和算法，生成高难度问题，并评估模型表现。

Result: 前沿模型如OpenAI的o3在FormulaOne上表现极差，解决率低于1%。

Conclusion: 当前AI模型在复杂领域仍远未达到专家水平，FormulaOne为未来研究提供了重要基准。

Abstract: Frontier AI models demonstrate formidable breadth of knowledge. But how close
are they to true human -- or superhuman -- expertise? Genuine experts can
tackle the hardest problems and push the boundaries of scientific
understanding. To illuminate the limits of frontier model capabilities, we turn
away from contrived competitive programming puzzles, and instead focus on
real-life research problems.
  We construct FormulaOne, a benchmark that lies at the intersection of graph
theory, logic, and algorithms, all well within the training distribution of
frontier models. Our problems are incredibly demanding, requiring an array of
reasoning steps. The dataset has three key properties. First, it is of
commercial interest and relates to practical large-scale optimisation problems,
such as those arising in routing, scheduling, and network design. Second, it is
generated from the highly expressive framework of Monadic Second-Order (MSO)
logic on graphs, paving the way toward automatic problem generation at scale;
ideal for building RL environments. Third, many of our problems are intimately
related to the frontier of theoretical computer science, and to central
conjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As
such, any significant algorithmic progress on our dataset, beyond known
results, could carry profound theoretical implications.
  Remarkably, state-of-the-art models like OpenAI's o3 fail entirely on
FormulaOne, solving less than 1% of the questions, even when given 10 attempts
and explanatory fewshot examples -- highlighting how far they remain from
expert-level understanding in some domains. To support further research, we
additionally curate FormulaOne-Warmup, offering a set of simpler tasks, from
the same distribution. We release the full corpus along with a comprehensive
evaluation framework.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [21] [Physically Based Neural LiDAR Resimulation](https://arxiv.org/abs/2507.12489)
*Richard Marcus,Marc Stamminger*

Main category: cs.RO

TL;DR: 本文提出了一种针对LiDAR仿真的新视角合成方法，通过显式建模传感器特性（如滚动快门、激光功率变化和强度衰减）来实现更准确的LiDAR仿真，并展示了高分辨率LiDAR扫描生成等先进的重仿真能力。


<details>
  <summary>Details</summary>
Motivation: 现有的新视角合成（NVS）方法在LiDAR仿真和大规模3D场景重建中得到应用，但LiDAR特定效应处理不足。虽然已有加速渲染或处理动态场景的解决方案，但LiDAR传感器的特殊特性（如滚动快门、激光功率变化、强度衰减等）仍未得到充分建模，影响了仿真的准确性。

Method: 通过显式建模LiDAR传感器的关键特性来改进新视角合成方法，具体包括：1）建模滚动快门效应；2）考虑激光功率变化；3）建模强度衰减效应。这些传感器特性的显式建模使得LiDAR仿真更加真实准确。

Result: 与现有最先进方法的定量和定性比较表明，该方法实现了更准确的LiDAR仿真。消融研究证明了每个传感器模型组件的重要性。此外，该方法展现了先进的重仿真能力，能够从相机视角生成高分辨率LiDAR扫描。

Conclusion: 通过显式建模LiDAR传感器的特殊特性，本文提出的方法显著提升了LiDAR仿真的准确性，为LiDAR模拟和3D场景重建提供了更可靠的解决方案。该方法不仅在现有基准上表现优异，还具备生成高质量LiDAR扫描的先进重仿真能力。

Abstract: Methods for Novel View Synthesis (NVS) have recently found traction in the
field of LiDAR simulation and large-scale 3D scene reconstruction. While
solutions for faster rendering or handling dynamic scenes have been proposed,
LiDAR specific effects remain insufficiently addressed. By explicitly modeling
sensor characteristics such as rolling shutter, laser power variations, and
intensity falloff, our method achieves more accurate LiDAR simulation compared
to existing techniques. We demonstrate the effectiveness of our approach
through quantitative and qualitative comparisons with state-of-the-art methods,
as well as ablation studies that highlight the importance of each sensor model
component. Beyond that, we show that our approach exhibits advanced
resimulation capabilities, such as generating high resolution LiDAR scans in
the camera perspective.
  Our code and the resulting dataset are available at
https://github.com/richardmarcus/PBNLiDAR.

</details>


### [22] [FOUNDER: Grounding Foundation Models in World Models for Open-Ended Embodied Decision Making](https://arxiv.org/abs/2507.12496)
*Yucen Wang,Rui Yu,Shenghua Wan,Le Gan,De-Chuan Zhan*

Main category: cs.RO

TL;DR: FOUNDER框架结合基础模型（FMs）和世界模型（WMs）的优势，通过无奖励方式在具身环境中实现开放任务解决。


<details>
  <summary>Details</summary>
Motivation: 利用FMs的通用知识和WMs的动态建模能力，解决复杂观测或领域差距场景中的任务泛化问题。

Method: 学习一个映射函数，将FM表示嵌入WM状态空间，通过想象学习目标条件策略，并利用预测的时间距离作为奖励信号。

Result: 在多种多任务离线视觉控制基准测试中表现优异，尤其在复杂观测或领域差距场景中。

Conclusion: FOUNDER框架有效整合FMs和WMs，提升了任务泛化能力，并通过实验验证了奖励函数的准确性。

Abstract: Foundation Models (FMs) and World Models (WMs) offer complementary strengths
in task generalization at different levels. In this work, we propose FOUNDER, a
framework that integrates the generalizable knowledge embedded in FMs with the
dynamic modeling capabilities of WMs to enable open-ended task solving in
embodied environments in a reward-free manner. We learn a mapping function that
grounds FM representations in the WM state space, effectively inferring the
agent's physical states in the world simulator from external observations. This
mapping enables the learning of a goal-conditioned policy through imagination
during behavior learning, with the mapped task serving as the goal state. Our
method leverages the predicted temporal distance to the goal state as an
informative reward signal. FOUNDER demonstrates superior performance on various
multi-task offline visual control benchmarks, excelling in capturing the
deep-level semantics of tasks specified by text or videos, particularly in
scenarios involving complex observations or domain gaps where prior methods
struggle. The consistency of our learned reward function with the ground-truth
reward is also empirically validated. Our project website is
https://sites.google.com/view/founder-rl.

</details>


### [23] [ReAL-AD: Towards Human-Like Reasoning in End-to-End Autonomous Driving](https://arxiv.org/abs/2507.12499)
*Yuhang Lu,Jiadong Tu,Yuexin Ma,Xinge Zhu*

Main category: cs.RO

TL;DR: ReAL-AD提出了一种基于人类认知模型的三层推理框架，结合视觉语言模型（VLMs）提升自动驾驶的决策能力，显著提高了规划准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法依赖固定稀疏的轨迹监督，无法模拟人类驾驶的分层推理过程。

Method: ReAL-AD采用三层认知模型（驾驶策略、驾驶决策、驾驶操作），结合VLMs增强情境感知，并通过战略推理注入器、战术推理整合器和分层轨迹解码器实现分层决策。

Result: 实验表明，该框架将规划准确性和安全性提高了30%以上，使自动驾驶更接近人类推理。

Conclusion: ReAL-AD通过分层推理和VLMs的结合，显著提升了自动驾驶的适应性和可解释性。

Abstract: End-to-end autonomous driving has emerged as a promising approach to unify
perception, prediction, and planning within a single framework, reducing
information loss and improving adaptability. However, existing methods often
rely on fixed and sparse trajectory supervision, limiting their ability to
capture the hierarchical reasoning process that human drivers naturally employ.
To bridge this gap, we propose ReAL-AD, a Reasoning-Augmented Learning
framework that structures decision-making in autonomous driving based on the
three-tier human cognitive model: Driving Strategy, Driving Decision, and
Driving Operation, where Vision-Language Models (VLMs) are incorporated to
enhance situational awareness and structured reasoning across these levels.
Specifically, we introduce: (1) the Strategic Reasoning Injector, which
formulates high-level driving strategies by interpreting complex traffic
contexts from VLM-generated insights; (2) the Tactical Reasoning Integrator,
which refines strategic intent into interpretable tactical choices such as lane
changes, overtaking, and speed adjustments; and (3) the Hierarchical Trajectory
Decoder, which progressively translates tactical decisions into precise control
actions for smooth and human-like trajectory execution. Extensive evaluations
show that integrating our framework improves planning accuracy and safety by
over 30%, making end-to-end autonomous driving more interpretable and aligned
with human-like hierarchical reasoning. The project page can be found at:
\href{https://4dvlab.github.io/project_page/realad}{\texttt{4dvlab.github.io/project\_page/realad}}

</details>


### [24] [VLMgineer: Vision Language Models as Robotic Toolsmiths](https://arxiv.org/abs/2507.12644)
*George Jiayuan Gao,Tianyu Li,Junyao Shi,Yihan Li,Zizhe Zhang,Nadia Figueroa,Dinesh Jayaraman*

Main category: cs.RO

TL;DR: VLMgineer利用视觉语言模型和进化搜索，自动设计工具及其操作策略，显著提升机器人任务的解决效率和创新性。


<details>
  <summary>Details</summary>
Motivation: 探索基础模型是否能通过工具设计和使用的自动化，提升物理智能，从而解决复杂的机器人任务。

Method: 结合视觉语言模型的代码生成能力和进化搜索，迭代优化工具设计和操作策略。

Result: VLMgineer在多样化任务中表现优异，设计出比人工工具和VLM生成工具更有效的解决方案。

Conclusion: VLMgineer为自动化工具设计提供了新方向，未来研究可通过其基准和代码进一步探索。

Abstract: Tool design and use reflect the ability to understand and manipulate the
physical world through creativity, planning, and foresight. As such, these
capabilities are often regarded as measurable indicators of intelligence across
biological species. While much of today's research on robotic intelligence
focuses on generating better controllers, inventing smarter tools offers a
complementary form of physical intelligence: shifting the onus of
problem-solving onto the tool's design. Given the vast and impressive
common-sense, reasoning, and creative capabilities of today's foundation
models, we investigate whether these models can provide useful priors to
automatically design and effectively wield such tools? We present VLMgineer, a
framework that harnesses the code generation abilities of vision language
models (VLMs) together with evolutionary search to iteratively co-design
physical tools and the action plans that operate them to perform a task. We
evaluate VLMgineer on a diverse new benchmark of everyday manipulation
scenarios that demand creative tool design and use. Across this suite,
VLMgineer consistently discovers tools and policies that solve tasks more
effectively and innovatively, transforming challenging robotics problems into
straightforward executions. It also outperforms VLM-generated designs from
human specifications and existing human-crafted tools for everyday tasks. To
facilitate future research on automated tool invention, we will release our
benchmark and code.

</details>


### [25] [MoistureMapper: An Autonomous Mobile Robot for High-Resolution Soil Moisture Mapping at Scale](https://arxiv.org/abs/2507.12716)
*Nathaniel Rose,Hannah Chuang,Manuel A Andrade-Rodriguez,Rishi Parashar,Dani Or,Parikshit Maini*

Main category: cs.RO

TL;DR: 本文设计并部署了自主移动机器人MoistureMapper，用于土壤湿度传感，采用自适应采样策略优化测量效率。


<details>
  <summary>Details</summary>
Motivation: 现有土壤湿度测量方法成本高且不适合大规模应用，需要一种高效、低成本的解决方案。

Method: 使用配备TDR传感器和直接推钻机构的机器人，结合高斯过程建模的自适应采样策略。

Result: 自适应采样策略比贪婪基准方法减少30%的移动距离和5%的重建湿度图方差。

Conclusion: MoistureMapper机器人及其自适应采样策略为大规模土壤湿度测量提供了高效解决方案。

Abstract: Soil moisture is a quantity of interest in many application areas including
agriculture and climate modeling. Existing methods are not suitable for scale
applications due to large deployment costs in high-resolution sensing
applications such as for variable irrigation. In this work, we design, build
and field deploy an autonomous mobile robot, MoistureMapper, for soil moisture
sensing. The robot is equipped with Time Domain Reflectometry (TDR) sensors and
a direct push drill mechanism for deploying the sensor to measure volumetric
water content in the soil. Additionally, we implement and evaluate multiple
adaptive sampling strategies based on a Gaussian Process based modeling to
build a spatial mapping of moisture distribution in the soil. We present
results from large scale computational simulations and proof-of-concept
deployment on the field. The adaptive sampling approach outperforms a greedy
benchmark approach and results in up to 30\% reduction in travel distance and
5\% reduction in variance in the reconstructed moisture maps. Link to video
showing field experiments: https://youtu.be/S4bJ4tRzObg

</details>


### [26] [Learning to Predict Mobile Robot Stability in Off-Road Environments](https://arxiv.org/abs/2507.12731)
*Nathaniel Rose,Arif Ahmed,Emanuel Gutierrez-Cornejo,Parikshit Maini*

Main category: cs.RO

TL;DR: 论文提出了一种基于学习的方法（IMUnet），通过轻量级神经网络直接从本体感受数据估计机器人平台稳定性，无需地形模型或力传感。同时开发了一种基于视觉的ArUco跟踪方法（C3评分）作为训练信号。


<details>
  <summary>Details</summary>
Motivation: 传统基于物理的稳定性指标（如SSM或ZMP）需要难以精确测量的接触力、地形几何和机器人质心信息，限制了在真实越野环境中的应用。

Method: 使用轻量级神经网络IMUnet从本体感受数据估计稳定性，并开发了基于ArUco的C3评分作为训练信号。

Result: 在多种地形和速度下验证了方法的有效性，并展示了对新条件的泛化能力。

Conclusion: 该方法为机器人任务（如精准操作和感知）提供了稳定性估计的新途径，适用于农业和太空应用。

Abstract: Navigating in off-road environments for wheeled mobile robots is challenging
due to dynamic and rugged terrain. Traditional physics-based stability metrics,
such as Static Stability Margin (SSM) or Zero Moment Point (ZMP) require
knowledge of contact forces, terrain geometry, and the robot's precise
center-of-mass that are difficult to measure accurately in real-world field
conditions. In this work, we propose a learning-based approach to estimate
robot platform stability directly from proprioceptive data using a lightweight
neural network, IMUnet. Our method enables data-driven inference of robot
stability without requiring an explicit terrain model or force sensing.
  We also develop a novel vision-based ArUco tracking method to compute a
scalar score to quantify robot platform stability called C3 score. The score
captures image-space perturbations over time as a proxy for physical
instability and is used as a training signal for the neural network based
model. As a pilot study, we evaluate our approach on data collected across
multiple terrain types and speeds and demonstrate generalization to previously
unseen conditions. These initial results highlight the potential of using IMU
and robot velocity as inputs to estimate platform stability. The proposed
method finds application in gating robot tasks such as precision actuation and
sensing, especially for mobile manipulation tasks in agricultural and space
applications. Our learning method also provides a supervision mechanism for
perception based traversability estimation and planning.

</details>


### [27] [ASC-SW: Atrous strip convolution network with sliding windows for visual-assisted map navigation](https://arxiv.org/abs/2507.12744)
*Cheng Liu,Fan Zhu,Yaoyu Zhuang Zhinan Chen Jiefeng Tang*

Main category: cs.RO

TL;DR: 提出了一种基于轻量级视觉神经网络的视觉辅助导航框架ASC-SW，用于移动机器人导航，解决了传统LiDAR无法检测地面障碍物的问题。


<details>
  <summary>Details</summary>
Motivation: 传统LiDAR传感器无法检测地面障碍物（如电线），需要一种轻量高效的视觉辅助导航方案。

Method: 采用轻量级分割模型ASCnet，结合MobileNetV2和ASCSPP模块，提出滑动窗口后处理模块SW。

Result: 在自建数据集上达到75.3%的Miou，边缘设备上推理速度为9.3 FPS。

Conclusion: ASC-SW框架在速度和性能上优于现有DLO检测模型，并在实际机器人平台上验证成功。

Abstract: With the rapid development of lightweight visual neural network
architectures, traditional high-performance vision models have undergone
significant compression, greatly improving their computational efficiency and
energy consumption ratio. This makes them feasible for deployment on
resource-constrained edge computing devices. We propose a visual-assisted
navigation framework called Atrous Strip Convolution-Sliding Window (ASC-SW),
which leverages a depth camera and a lightweight visual neural network to
assist map-based mobile robot navigation. This framework compensates for the
inability of traditional light detection and range (LiDAR) sensors to detect
ground-level obstacles such as ground-level wires. We introduce a lightweight
and efficient segmentation model, Atrous Strip Convolution Network (ASCnet),
for detecting deformable linear objects (DLOs). MobileNetV2 is used as the
backbone network, and Atrous Strip Convolution Spatial Pyramid Pooling (ASCSPP)
is designed to extract DLO features more effectively. Atrous Strip Convolution
is integrated into ASCSPP to accurately identify the linear structure of DLOs
with low computational cost. Additionally, a Sliding Window (SW)
post-processing module is proposed to denoise the output in complex
environments, improving recognition accuracy. Our method strikes a balance
between inference speed and segmentation performance. It achieves a mean
Intersection over Union (Miou) score of 75.3% on a self-built dataset and
reaches 9.3 FPS inference speed on the Jetson Orin Nano edge device. Overall,
our approach outperforms existing DLO detection models and has been
successfully validated on a physical robotic platform.

</details>


### [28] [Refining Motion for Peak Performance: Identifying Optimal Gait Parameters for Energy-Efficient Quadrupedal Bounding](https://arxiv.org/abs/2507.12751)
*Yasser G. Alqaham,Jing Cheng,Zhenyu Gan*

Main category: cs.RO

TL;DR: 研究探讨了步态参数对四足机器人能量效率的影响，通过模拟和实验验证了优化步态参数可显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 此前研究多关注机械设计和驱动改进，而步态参数对能量消耗的影响较少被探索。

Method: 建模Unitree A1机器人，开发可独立调整步态参数的控制器，在Gazebo中模拟不同速度下的步态，并进行实验验证。

Result: 优化步态参数可显著降低能量消耗，提升四足机器人运动效率。

Conclusion: 研究为四足机器人提供了节能控制策略，可直接应用于商业平台。

Abstract: Energy efficiency is a critical factor in the performance and autonomy of
quadrupedal robots. While previous research has focused on mechanical design
and actuation improvements, the impact of gait parameters on energetics has
been less explored. In this paper, we hypothesize that gait parameters,
specifically duty factor, phase shift, and stride duration, are key
determinants of energy consumption in quadrupedal locomotion. To test this
hypothesis, we modeled the Unitree A1 quadrupedal robot and developed a
locomotion controller capable of independently adjusting these gait parameters.
Simulations of bounding gaits were conducted in Gazebo across a range of gait
parameters at three different speeds: low, medium, and high. Experimental tests
were also performed to validate the simulation results. The findings
demonstrate that optimizing gait parameters can lead to significant reductions
in energy consumption, enhancing the overall efficiency of quadrupedal
locomotion. This work contributes to the advancement of energy-efficient
control strategies for legged robots, offering insights directly applicable to
commercially available platforms.

</details>


### [29] [osmAG-LLM: Zero-Shot Open-Vocabulary Object Navigation via Semantic Maps and Large Language Models Reasoning](https://arxiv.org/abs/2507.12753)
*Fujing Xie,Sören Schwertfeger,Hermann Blum*

Main category: cs.RO

TL;DR: 论文提出了一种面向动态环境的机器人导航系统，结合语义先验和主动搜索策略，提高了对象检索的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有高细节对象地图易过时，动态环境下对象位置变化频繁，需一种更灵活的方法。

Method: 开发了基于环境背景和LLM语义先验的导航系统，采用主动在线策略搜索对象。

Result: 在静态和动态对象查询中，新方法检索成功率更高，路径更短。

Conclusion: 结合语义先验和主动搜索的方法在动态环境中表现优越。

Abstract: Recent open-vocabulary robot mapping methods enrich dense geometric maps with
pre-trained visual-language features, achieving a high level of detail and
guiding robots to find objects specified by open-vocabulary language queries.
While the issue of scalability for such approaches has received some attention,
another fundamental problem is that high-detail object mapping quickly becomes
outdated, as objects get moved around a lot. In this work, we develop a mapping
and navigation system for object-goal navigation that, from the ground up,
considers the possibilities that a queried object can have moved, or may not be
mapped at all. Instead of striving for high-fidelity mapping detail, we
consider that the main purpose of a map is to provide environment grounding and
context, which we combine with the semantic priors of LLMs to reason about
object locations and deploy an active, online approach to navigate to the
objects. Through simulated and real-world experiments we find that our approach
tends to have higher retrieval success at shorter path lengths for static
objects and by far outperforms prior approaches in cases of dynamic or unmapped
object queries. We provide our code and dataset at:
https://anonymous.4open.science/r/osmAG-LLM.

</details>


### [30] [FFI-VTR: Lightweight and Robust Visual Teach and Repeat Navigation based on Feature Flow Indicator and Probabilistic Motion Planning](https://arxiv.org/abs/2507.12800)
*Jikai Wang,Yunqi Cheng,Zonghai Chen*

Main category: cs.RO

TL;DR: 提出一种轻量且鲁棒的视觉重复导航方法，无需精确定位和密集重建模块，通过特征流映射和概率运动规划实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在视觉重复导航中效率与鲁棒性难以平衡的问题。

Method: 引入特征流映射模型，构建关键帧图表示地图，将导航建模为特征流最小化问题，并开发概率运动规划。

Result: 实验表明该方法轻量、鲁棒且优于基线方法。

Conclusion: 提出的方法在无需精确定位的情况下实现了高效且鲁棒的视觉重复导航。

Abstract: Though visual and repeat navigation is a convenient solution for mobile robot
self-navigation, achieving balance between efficiency and robustness in task
environment still remains challenges. In this paper, we propose a novel visual
and repeat robotic autonomous navigation method that requires no accurate
localization and dense reconstruction modules, which makes our system featured
by lightweight and robustness. Firstly, feature flow is introduced and we
develop a qualitative mapping between feature flow and robot's motion, in which
feature flow is defined as pixel location bias between matched features. Based
on the mapping model, the map outputted by the teaching phase is represented as
a keyframe graph, in which the feature flow on the edge encodes the relative
motion between adjacent keyframes. Secondly, the visual repeating navigation is
essentially modeled as a feature flow minimization problem between current
observation and the map keyframe. To drive the robot to consistently reduce the
feature flow between current frame and map keyframes without accurate
localization, a probabilistic motion planning is developed based on our
qualitative feature flow-motion mapping indicator. Extensive experiments using
our mobile platform demonstrates that our proposed method is lightweight,
robust, and superior to baselines. The source code has been made public at
https://github.com/wangjks/FFI-VTR to benefit the community.

</details>


### [31] [Enter the Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering](https://arxiv.org/abs/2507.12846)
*Muhammad Fadhil Ginting,Dong-Ki Kim,Xiangyun Meng,Andrzej Reinke,Bandi Jai Krishna,Navid Kayhani,Oriana Peltzer,David D. Fan,Amirreza Shaban,Sung-Kyun Kim,Mykel J. Kochenderfer,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: 论文提出了一种长期主动具身问答（LA-EQA）任务，通过结构化记忆系统和基于信息价值的停止标准，显著提升了机器人在复杂环境中的问答能力。


<details>
  <summary>Details</summary>
Motivation: 传统具身问答（EQA）方法在长期任务中表现不佳，主要受限于上下文窗口、缺乏持久记忆以及无法结合记忆检索与主动探索。

Method: 提出了一种受认知科学启发的结构化记忆系统，将经验编码为场景图实例，并设计了一种基于信息价值的停止标准以优化探索与记忆检索的平衡。

Result: 在真实世界实验和新基准测试中，该方法在答案准确性和探索效率上显著优于现有基线。

Conclusion: 结构化记忆系统和信息价值停止标准的结合为长期具身问答任务提供了有效的解决方案。

Abstract: As robots become increasingly capable of operating over extended periods --
spanning days, weeks, and even months -- they are expected to accumulate
knowledge of their environments and leverage this experience to assist humans
more effectively. This paper studies the problem of Long-term Active Embodied
Question Answering (LA-EQA), a new task in which a robot must both recall past
experiences and actively explore its environment to answer complex,
temporally-grounded questions. Unlike traditional EQA settings, which typically
focus either on understanding the present environment alone or on recalling a
single past observation, LA-EQA challenges an agent to reason over past,
present, and possible future states, deciding when to explore, when to consult
its memory, and when to stop gathering observations and provide a final answer.
Standard EQA approaches based on large models struggle in this setting due to
limited context windows, absence of persistent memory, and an inability to
combine memory recall with active exploration. To address this, we propose a
structured memory system for robots, inspired by the mind palace method from
cognitive science. Our method encodes episodic experiences as scene-graph-based
world instances, forming a reasoning and planning algorithm that enables
targeted memory retrieval and guided navigation. To balance the
exploration-recall trade-off, we introduce value-of-information-based stopping
criteria that determines when the agent has gathered sufficient information. We
evaluate our method on real-world experiments and introduce a new benchmark
that spans popular simulation environments and actual industrial sites. Our
approach significantly outperforms state-of-the-art baselines, yielding
substantial gains in both answer accuracy and exploration efficiency.

</details>


### [32] [DEMONSTRATE: Zero-shot Language to Robotic Control via Multi-task Demonstration Learning](https://arxiv.org/abs/2507.12855)
*Rahel Rickenbach,Bruce Lee,René Zurbrügg,Carmen Amo Alonso,Melanie N. Zeilinger*

Main category: cs.RO

TL;DR: 论文提出了一种名为DEMONSTRATE的新方法，通过利用任务描述的嵌入表示和逆向最优控制工具，减少对LLMs生成复杂优化问题的依赖，同时通过多任务学习确保任务相似性。


<details>
  <summary>Details</summary>
Motivation: 当前使用LLMs生成最优控制问题需要依赖工程师设计的任务示例，且缺乏评估幻觉的原则性方法，限制了其应用。

Method: 提出DEMONSTRATE方法，利用任务描述的嵌入表示和逆向最优控制工具，结合多任务学习，减少对LLMs的依赖。

Result: 通过仿真和硬件实验验证了方法的有效性，减少了工程设计的依赖并实现了幻觉评估。

Conclusion: DEMONSTRATE方法通过任务演示和多任务学习，显著降低了对LLMs和工程设计的依赖，同时提高了任务执行前的可靠性。

Abstract: The integration of large language models (LLMs) with control systems has
demonstrated significant potential in various settings, such as task completion
with a robotic manipulator. A main reason for this success is the ability of
LLMs to perform in-context learning, which, however, strongly relies on the
design of task examples, closely related to the target tasks. Consequently,
employing LLMs to formulate optimal control problems often requires task
examples that contain explicit mathematical expressions, designed by trained
engineers. Furthermore, there is often no principled way to evaluate for
hallucination before task execution. To address these challenges, we propose
DEMONSTRATE, a novel methodology that avoids the use of LLMs for complex
optimization problem generations, and instead only relies on the embedding
representations of task descriptions. To do this, we leverage tools from
inverse optimal control to replace in-context prompt examples with task
demonstrations, as well as the concept of multitask learning, which ensures
target and example task similarity by construction. Given the fact that
hardware demonstrations can easily be collected using teleoperation or guidance
of the robot, our approach significantly reduces the reliance on engineering
expertise for designing in-context examples. Furthermore, the enforced
multitask structure enables learning from few demonstrations and assessment of
hallucinations prior to task execution. We demonstrate the effectiveness of our
method through simulation and hardware experiments involving a robotic arm
tasked with tabletop manipulation.

</details>


### [33] [LaViPlan : Language-Guided Visual Path Planning with RLVR](https://arxiv.org/abs/2507.12911)
*Hayeon Oh*

Main category: cs.RO

TL;DR: 论文提出LaViPlan框架，通过强化学习优化视觉语言模型（VLM），解决自动驾驶中视觉-语言-动作不对齐问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中，分布外（OOD）场景可能导致危险行为，现有VLM虽能识别场景但决策与动作不对齐。

Method: 采用带可验证奖励的强化学习（RLVR）优化VLM，以规划指标为导向。

Result: 实验表明，LaViPlan提升了OOD条件下的情境感知和决策能力。

Conclusion: LaViPlan为自动驾驶VLM提供了一种有效的后训练范式。

Abstract: Out-of-distribution (OOD) scenarios in autonomous driving refer to situations
that deviate from the training domain, often leading to unexpected and
potentially hazardous behavior from planners that lack prior exposure to such
cases. Recently, Vision-Language Models (VLMs) have been introduced into
autonomous driving research for their promising generalization capabilities in
OOD settings. Early studies demonstrated that VLMs could recognize OOD
scenarios and generate user-level decisions such as "go straight" or "turn
right." However, a new challenge has emerged due to the misalignment between
the VLM's high-level decisions or visual reasoning expressed in language, and
the low-level predicted trajectories interpreted as actions. In this paper, we
propose LaViPlan, a framework that leverages Reinforcement Learning with
Verifiable Rewards (RLVR) to optimize VLMs using planning-oriented metrics.
This approach addresses the vision-language-action misalignment observed in
existing VLMs fine-tuned via supervised learning, which can recognize driving
scenarios but often produce context-unaware decisions. Experimental results
demonstrate that our method improves situational awareness and decision-making
under OOD conditions, highlighting its potential to mitigate the misalignment
issue. This work introduces a promising post-training paradigm for VLM agents
in the context of autonomous driving.

</details>


### [34] [MoCap2GT: A High-Precision Ground Truth Estimator for SLAM Benchmarking Based on Motion Capture and IMU Fusion](https://arxiv.org/abs/2507.12920)
*Zichao Shu,Shitao Bei,Jicheng Dai,Lijun Li,Zetao Chen*

Main category: cs.RO

TL;DR: MoCap2GT是一种联合优化方法，结合MoCap数据和IMU测量，生成高精度地面真值轨迹，用于SLAM算法的精确评估。


<details>
  <summary>Details</summary>
Motivation: 现有基于MoCap的地面真值轨迹受时空校准误差和固有抖动影响，难以准确评估旋转和帧间误差，限制了SLAM的全面评估。

Method: MoCap2GT采用鲁棒状态初始化、高阶B样条姿态参数化和退化感知测量剔除策略，优化轨迹生成。

Result: 实验表明，MoCap2GT优于现有方法，显著提升了SLAM评估的精确性。

Conclusion: MoCap2GT为SLAM基准测试提供了高精度的地面真值轨迹，推动了SLAM算法的精确评估。

Abstract: Marker-based optical motion capture (MoCap) systems are widely used to
provide ground truth (GT) trajectories for benchmarking SLAM algorithms.
However, the accuracy of MoCap-based GT trajectories is mainly affected by two
factors: spatiotemporal calibration errors between the MoCap system and the
device under test (DUT), and inherent MoCap jitter. Consequently, existing
benchmarks focus primarily on absolute translation error, as accurate
assessment of rotation and inter-frame errors remains challenging, hindering
thorough SLAM evaluation. This paper proposes MoCap2GT, a joint optimization
approach that integrates MoCap data and inertial measurement unit (IMU)
measurements from the DUT for generating high-precision GT trajectories.
MoCap2GT includes a robust state initializer to ensure global convergence,
introduces a higher-order B-spline pose parameterization on the SE(3) manifold
with variable time offset to effectively model MoCap factors, and employs a
degeneracy-aware measurement rejection strategy to enhance estimation accuracy.
Experimental results demonstrate that MoCap2GT outperforms existing methods and
significantly contributes to precise SLAM benchmarking. The source code is
available at https://anonymous.4open.science/r/mocap2gt (temporarily hosted
anonymously for double-blind review).

</details>


### [35] [Non-differentiable Reward Optimization for Diffusion-based Autonomous Motion Planning](https://arxiv.org/abs/2507.12977)
*Giwon Lee,Daehee Park,Jaewoo Jeong,Kuk-Jin Yoon*

Main category: cs.RO

TL;DR: 论文提出了一种基于强化学习的扩散运动规划模型训练方法，通过非可微分目标（如安全性和有效性）优化，提升了运动规划的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在运动规划中表现优异，但传统训练目标无法直接优化非可微分目标（如安全性和有效性），限制了其性能。

Method: 采用强化学习训练扩散模型，引入奖励加权动态阈值算法，生成密集奖励信号以优化非可微分目标。

Result: 在行人数据集（CrowdNav, ETH-UCY）上实现了最先进的性能，优于传统方法。

Conclusion: 该方法有效解决了扩散模型在运动规划中的局限性，为安全高效的运动规划提供了新思路。

Abstract: Safe and effective motion planning is crucial for autonomous robots.
Diffusion models excel at capturing complex agent interactions, a fundamental
aspect of decision-making in dynamic environments. Recent studies have
successfully applied diffusion models to motion planning, demonstrating their
competence in handling complex scenarios and accurately predicting multi-modal
future trajectories. Despite their effectiveness, diffusion models have
limitations in training objectives, as they approximate data distributions
rather than explicitly capturing the underlying decision-making dynamics.
However, the crux of motion planning lies in non-differentiable downstream
objectives, such as safety (collision avoidance) and effectiveness
(goal-reaching), which conventional learning algorithms cannot directly
optimize. In this paper, we propose a reinforcement learning-based training
scheme for diffusion motion planning models, enabling them to effectively learn
non-differentiable objectives that explicitly measure safety and effectiveness.
Specifically, we introduce a reward-weighted dynamic thresholding algorithm to
shape a dense reward signal, facilitating more effective training and
outperforming models trained with differentiable objectives. State-of-the-art
performance on pedestrian datasets (CrowdNav, ETH-UCY) compared to various
baselines demonstrates the versatility of our approach for safe and effective
motion planning.

</details>


### [36] [Robustness Requirement Coverage using a Situation Coverage Approach for Vision-based AI Systems](https://arxiv.org/abs/2507.12986)
*Sepeedeh Shahbeigi,Nawshin Mannan Proma,Victoria Hodge,Richard Hawkins,Boda Li,Valentina Donzella*

Main category: cs.RO

TL;DR: 提出了一种新框架，结合相机噪声因素识别与情境覆盖分析，系统化地提取基于AI感知系统的鲁棒性安全需求，特别针对汽车领域的相机退化问题。


<details>
  <summary>Details</summary>
Motivation: 在复杂动态环境中，AI感知系统需应对传感器性能退化带来的数据质量下降问题，现有方法难以全面覆盖所有退化场景，亟需系统性解决方案。

Method: 整合相机噪声因素识别与情境覆盖分析，结合领域、传感器和安全专家意见，扩展退化模型，并应用情境覆盖分析识别代表性操作环境。

Result: 初步实现了噪声因素分析与情境覆盖的整合，为相机AI感知系统的鲁棒性需求提供了结构化方法。

Conclusion: 该框架为基于相机AI感知系统的鲁棒性需求提供了系统性支持，是未来研究的重要起点。

Abstract: AI-based robots and vehicles are expected to operate safely in complex and
dynamic environments, even in the presence of component degradation. In such
systems, perception relies on sensors such as cameras to capture environmental
data, which is then processed by AI models to support decision-making. However,
degradation in sensor performance directly impacts input data quality and can
impair AI inference. Specifying safety requirements for all possible sensor
degradation scenarios leads to unmanageable complexity and inevitable gaps. In
this position paper, we present a novel framework that integrates camera noise
factor identification with situation coverage analysis to systematically elicit
robustness-related safety requirements for AI-based perception systems. We
focus specifically on camera degradation in the automotive domain. Building on
an existing framework for identifying degradation modes, we propose involving
domain, sensor, and safety experts, and incorporating Operational Design Domain
specifications to extend the degradation model by incorporating noise factors
relevant to AI performance. Situation coverage analysis is then applied to
identify representative operational contexts. This work marks an initial step
toward integrating noise factor analysis and situational coverage to support
principled formulation and completeness assessment of robustness requirements
for camera-based AI perception.

</details>


### [37] [Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities](https://arxiv.org/abs/2507.13019)
*Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: VLN-PE是一个物理真实的视觉与语言导航平台，支持多种机器人类型，揭示了当前模型在物理部署中的性能下降问题，并提供了改进的途径。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉与语言导航（VLN）方法在物理机器人部署中的理想化假设问题，提出更真实的评估平台。

Method: 引入VLN-PE平台，支持人形、四足和轮式机器人，评估了多种导航方法，包括分类模型、扩散模型和基于LLM的无训练方法。

Result: 发现性能显著下降，原因包括机器人观测空间有限、环境光照变化及物理碰撞等问题，同时暴露了足式机器人在复杂环境中的局限性。

Conclusion: VLN-PE为改进跨具身适应性提供了新途径，并呼吁社区重新思考VLN的局限性，推动更鲁棒的模型发展。

Abstract: Recent Vision-and-Language Navigation (VLN) advancements are promising, but
their idealized assumptions about robot movement and control fail to reflect
physically embodied deployment challenges. To bridge this gap, we introduce
VLN-PE, a physically realistic VLN platform supporting humanoid, quadruped, and
wheeled robots. For the first time, we systematically evaluate several
ego-centric VLN methods in physical robotic settings across different technical
pipelines, including classification models for single-step discrete action
prediction, a diffusion model for dense waypoint prediction, and a train-free,
map-based large language model (LLM) integrated with path planning. Our results
reveal significant performance degradation due to limited robot observation
space, environmental lighting variations, and physical challenges like
collisions and falls. This also exposes locomotion constraints for legged
robots in complex environments. VLN-PE is highly extensible, allowing seamless
integration of new scenes beyond MP3D, thereby enabling more comprehensive VLN
evaluation. Despite the weak generalization of current models in physical
deployment, VLN-PE provides a new pathway for improving cross-embodiment's
overall adaptability. We hope our findings and tools inspire the community to
rethink VLN limitations and advance robust, practical VLN models. The code is
available at https://crystalsixone.github.io/vln_pe.github.io/.

</details>


### [38] [What Can Robots Teach Us About Trust and Reliance? An interdisciplinary dialogue between Social Sciences and Social Robotics](https://arxiv.org/abs/2507.13041)
*Julien Wacquez,Elisabetta Zibetti,Joffrey Becker,Lorenzo Aloe,Fabio Amadio,Salvatore Anzalone,Lola Cañamero,Serena Ivaldi*

Main category: cs.RO

TL;DR: 论文探讨了人机交互中的信任问题，提出需要跨学科方法结合社会学与机器人技术，以建立更全面的信任框架。


<details>
  <summary>Details</summary>
Motivation: 随着机器人融入日常生活，信任问题日益重要，但现有研究常碎片化，且缺乏与社会学的对话。

Method: 结合社会科学与社交机器人学的见解，分析信任的形成、测试与表现。

Result: 提出了跨学科对话的必要性，以构建更扎实且适应性强的信任理解框架。

Conclusion: 通过跨学科合作，可以更好地理解并应对人机交互中的信任挑战。

Abstract: As robots find their way into more and more aspects of everyday life,
questions around trust are becoming increasingly important. What does it mean
to trust a robot? And how should we think about trust in relationships that
involve both humans and non-human agents? While the field of Human-Robot
Interaction (HRI) has made trust a central topic, the concept is often
approached in fragmented ways. At the same time, established work in sociology,
where trust has long been a key theme, is rarely brought into conversation with
developments in robotics. This article argues that we need a more
interdisciplinary approach. By drawing on insights from both social sciences
and social robotics, we explore how trust is shaped, tested and made visible.
Our goal is to open up a dialogue between disciplines and help build a more
grounded and adaptable framework for understanding trust in the evolving world
of human-robot interaction.

</details>


### [39] [Efficient Online Learning and Adaptive Planning for Robotic Information Gathering Based on Streaming Data](https://arxiv.org/abs/2507.13053)
*Sanjeev Ramkumar Sudha,Joel Jose,Erlend M. Coates*

Main category: cs.RO

TL;DR: 提出了一种基于高斯过程（GP）和稀疏流式GP的高效自适应信息规划方法，用于映射连续标量场，解决了现有方法在实时性和大规模数据上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有RIG方法通常假设环境已知，但实际环境可能未知或时变，且传统GP在实时性和大数据量下性能不足。

Method: 结合稀疏流式GP，提出自适应信息规划方法，通过仿真和真实数据集验证。

Result: 在保持映射精度的同时，显著降低了计算复杂度，适用于长时间任务。

Conclusion: 该方法在未知或时变环境中具有高效性和实用性，为RIG领域提供了新的解决方案。

Abstract: Robotic information gathering (RIG) techniques refer to methods where mobile
robots are used to acquire data about the physical environment with a suite of
sensors. Informative planning is an important part of RIG where the goal is to
find sequences of actions or paths that maximize efficiency or the quality of
information collected. Many existing solutions solve this problem by assuming
that the environment is known in advance. However, real environments could be
unknown or time-varying, and adaptive informative planning remains an active
area of research. Adaptive planning and incremental online mapping are required
for mapping initially unknown or varying spatial fields. Gaussian process (GP)
regression is a widely used technique in RIG for mapping continuous spatial
fields. However, it falls short in many applications as its real-time
performance does not scale well to large datasets. To address these challenges,
this paper proposes an efficient adaptive informative planning approach for
mapping continuous scalar fields with GPs with streaming sparse GPs. Simulation
experiments are performed with a synthetic dataset and compared against
existing benchmarks. Finally, it is also verified with a real-world dataset to
further validate the efficacy of the proposed method. Results show that our
method achieves similar mapping accuracy to the baselines while reducing
computational complexity for longer missions.

</details>


### [40] [ZipMPC: Compressed Context-Dependent MPC Cost via Imitation Learning](https://arxiv.org/abs/2507.13088)
*Rahel Rickenbach,Alan A. Lahoud,Erik Schaffernicht,Melanie N. Zeilinger,Johannes A. Stork*

Main category: cs.RO

TL;DR: ZipMPC通过学习压缩且上下文相关的成本函数，模仿长时域MPC行为，提升短时域MPC性能，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决MPC在实时系统（如机器人）中因计算负担而只能使用短预测时域的问题，从而优化长期目标并确保约束满足。

Method: 利用可微分MPC和神经网络传播模仿损失的梯度，学习压缩且上下文相关的成本函数。

Result: 在仿真和真实自动驾驶赛车实验中，ZipMPC表现优于基线方法，接近长时域MPC性能，且能泛化到未训练环境。

Conclusion: ZipMPC通过模仿长时域MPC行为，显著提升短时域MPC的性能和泛化能力，适用于实时系统。

Abstract: The computational burden of model predictive control (MPC) limits its
application on real-time systems, such as robots, and often requires the use of
short prediction horizons. This not only affects the control performance, but
also increases the difficulty of designing MPC cost functions that reflect the
desired long-term objective. This paper proposes ZipMPC, a method that imitates
a long-horizon MPC behaviour by learning a compressed and context-dependent
cost function for a short-horizon MPC. It improves performance over alternative
methods, such as approximate explicit MPC and automatic cost parameter tuning,
in particular in terms of i) optimizing the long term objective; ii)
maintaining computational costs comparable to a short-horizon MPC; iii)
ensuring constraint satisfaction; and iv) generalizing control behaviour to
environments not observed during training. For this purpose, ZipMPC leverages
the concept of differentiable MPC with neural networks to propagate gradients
of the imitation loss through the MPC optimization. We validate our proposed
method in simulation and real-world experiments on autonomous racing. ZipMPC
consistently completes laps faster than selected baselines, achieving lap times
close to the long-horizon MPC baseline. In challenging scenarios where the
short-horizon MPC baseline fails to complete a lap, ZipMPC is able to do so. In
particular, these performance gains are also observed on tracks unseen during
training.

</details>


### [41] [GraspGen: A Diffusion-based Framework for 6-DOF Grasping with On-Generator Training](https://arxiv.org/abs/2507.13097)
*Adithyavairavan Murali,Balakumar Sundaralingam,Yu-Wei Chao,Wentao Yuan,Jun Yamada,Mark Carlson,Fabio Ramos,Stan Birchfield,Dieter Fox,Clemens Eppner*

Main category: cs.RO

TL;DR: GraspGen是一个基于扩散变换器架构的6-DOF抓取生成框架，通过高效判别器评分和过滤抓取样本，在模拟和真实机器人任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管抓取是机器人的基本技能，但现有学习型6-DOF抓取方法仍难以泛化到不同机械臂和复杂场景。

Method: 提出GraspGen框架，采用扩散变换器架构生成抓取，结合高效判别器进行评分和过滤，并引入新的训练方法。

Result: 在模拟实验中优于现有方法，在FetchBench基准测试中达到SOTA，并在真实机器人任务中表现良好。

Conclusion: GraspGen通过扩散变换器和高效判别器的结合，显著提升了抓取生成的泛化能力和性能。

Abstract: Grasping is a fundamental robot skill, yet despite significant research
advancements, learning-based 6-DOF grasping approaches are still not turnkey
and struggle to generalize across different embodiments and in-the-wild
settings. We build upon the recent success on modeling the object-centric grasp
generation process as an iterative diffusion process. Our proposed framework,
GraspGen, consists of a DiffusionTransformer architecture that enhances grasp
generation, paired with an efficient discriminator to score and filter sampled
grasps. We introduce a novel and performant on-generator training recipe for
the discriminator. To scale GraspGen to both objects and grippers, we release a
new simulated dataset consisting of over 53 million grasps. We demonstrate that
GraspGen outperforms prior methods in simulations with singulated objects
across different grippers, achieves state-of-the-art performance on the
FetchBench grasping benchmark, and performs well on a real robot with noisy
visual observations.

</details>


### [42] [Aligning Humans and Robots via Reinforcement Learning from Implicit Human Feedback](https://arxiv.org/abs/2507.13171)
*Suzie Kim,Hye-Bin Shin,Seong-Whan Lee*

Main category: cs.RO

TL;DR: 论文提出了一种基于隐式人类反馈（RLIHF）的强化学习框架，利用脑电图（EEG）信号提供连续反馈，解决了传统强化学习在稀疏奖励条件下的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在稀疏奖励条件下效果不佳，而现有的人类反馈方法依赖显式反馈机制，增加了用户认知负担。因此，需要一种非侵入式的隐式反馈方法。

Method: 提出RLIHF框架，利用EEG信号（特别是错误相关电位）生成概率奖励，结合稀疏外部奖励进行策略学习。

Result: 在MuJoCo模拟环境中，使用Kinova Gen2机械臂进行复杂任务测试，结果显示基于EEG反馈的代理性能接近手动设计的密集奖励。

Conclusion: 隐式神经反馈为交互式机器人提供了一种可扩展且与人类对齐的强化学习方法。

Abstract: Conventional reinforcement learning (RL) ap proaches often struggle to learn
effective policies under sparse reward conditions, necessitating the manual
design of complex, task-specific reward functions. To address this limitation,
rein forcement learning from human feedback (RLHF) has emerged as a promising
strategy that complements hand-crafted rewards with human-derived evaluation
signals. However, most existing RLHF methods depend on explicit feedback
mechanisms such as button presses or preference labels, which disrupt the
natural interaction process and impose a substantial cognitive load on the
user. We propose a novel reinforcement learning from implicit human feedback
(RLIHF) framework that utilizes non-invasive electroencephalography (EEG)
signals, specifically error-related potentials (ErrPs), to provide continuous,
implicit feedback without requiring explicit user intervention. The proposed
method adopts a pre-trained decoder to transform raw EEG signals into
probabilistic reward components, en abling effective policy learning even in
the presence of sparse external rewards. We evaluate our approach in a
simulation environment built on the MuJoCo physics engine, using a Kinova Gen2
robotic arm to perform a complex pick-and-place task that requires avoiding
obstacles while manipulating target objects. The results show that agents
trained with decoded EEG feedback achieve performance comparable to those
trained with dense, manually designed rewards. These findings validate the
potential of using implicit neural feedback for scalable and human-aligned
reinforcement learning in interactive robotics.

</details>


### [43] [Few-shot transfer of tool-use skills using human demonstrations with proximity and tactile sensing](https://arxiv.org/abs/2507.13200)
*Marina Y. Aoyama,Sethu Vijayakumar,Tetsuya Narita*

Main category: cs.RO

TL;DR: 提出了一种基于多模态感知的少样本工具使用技能迁移框架，通过仿真预训练和现实世界微调，解决机器人工具操作中的复杂接触问题。


<details>
  <summary>Details</summary>
Motivation: 人类擅长工具操作，但机器人学习这些技能面临挑战，主要源于工具与机器人及环境的双重接触复杂性，以及传感器数据的有限性和仿真与现实的差距。

Method: 框架包括仿真预训练基础策略以捕捉工具使用中的常见接触状态，再通过少量现实世界人类演示微调，缩小领域差距。

Result: 验证表明，该框架能通过少量演示教会机器人使用不同物理和几何特性的工具完成表面跟随任务。

Conclusion: 机器人通过迁移预训练策略中的工具-环境接触识别能力学习新技能，结合接近和触觉传感器能更好地识别接触状态和环境几何。

Abstract: Tools extend the manipulation abilities of robots, much like they do for
humans. Despite human expertise in tool manipulation, teaching robots these
skills faces challenges. The complexity arises from the interplay of two
simultaneous points of contact: one between the robot and the tool, and another
between the tool and the environment. Tactile and proximity sensors play a
crucial role in identifying these complex contacts. However, learning tool
manipulation using these sensors remains challenging due to limited real-world
data and the large sim-to-real gap. To address this, we propose a few-shot
tool-use skill transfer framework using multimodal sensing. The framework
involves pre-training the base policy to capture contact states common in
tool-use skills in simulation and fine-tuning it with human demonstrations
collected in the real-world target domain to bridge the domain gap. We validate
that this framework enables teaching surface-following tasks using tools with
diverse physical and geometric properties with a small number of demonstrations
on the Franka Emika robot arm. Our analysis suggests that the robot acquires
new tool-use skills by transferring the ability to recognise tool-environment
contact relationships from pre-trained to fine-tuned policies. Additionally,
combining proximity and tactile sensors enhances the identification of contact
states and environmental geometry.

</details>


### [44] [Signal Temporal Logic Compliant Co-design of Planning and Control](https://arxiv.org/abs/2507.13225)
*Manas Sashank Juvvi,Tushar Dilip Kurne,Vaishnavi J,Shishir Kolathaya,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 提出了一种新颖的协同设计策略，结合轨迹规划与控制，用于处理自主机器人中基于STL的任务。


<details>
  <summary>Details</summary>
Motivation: 解决自主机器人在复杂环境中执行STL任务时的轨迹规划与控制问题。

Method: 分两阶段：1) 学习时空运动基元以封装机器人特定约束；2) 从基元构建符合STL的运动计划。使用强化学习生成控制策略库，并通过采样策略生成STL合规运动计划。

Result: 在差速驱动和四足机器人上验证了模型的有效性，适用于多种环境和STL规范。

Conclusion: 提出的无模型方法能生成可行的STL合规运动计划，适用于多种机器人平台和任务。

Abstract: This work presents a novel co-design strategy that integrates trajectory
planning and control to handle STL-based tasks in autonomous robots. The method
consists of two phases: $(i)$ learning spatio-temporal motion primitives to
encapsulate the inherent robot-specific constraints and $(ii)$ constructing an
STL-compliant motion plan from these primitives. Initially, we employ
reinforcement learning to construct a library of control policies that perform
trajectories described by the motion primitives. Then, we map motion primitives
to spatio-temporal characteristics. Subsequently, we present a sampling-based
STL-compliant motion planning strategy tailored to meet the STL specification.
The proposed model-free approach, which generates feasible STL-compliant motion
plans across various environments, is validated on differential-drive and
quadruped robots across various STL specifications. Demonstration videos are
available at https://tinyurl.com/m6zp7rsm.

</details>


### [45] [Evaluating Reinforcement Learning Algorithms for Navigation in Simulated Robotic Quadrupeds: A Comparative Study Inspired by Guide Dog Behaviour](https://arxiv.org/abs/2507.13277)
*Emma M. A. Harrison*

Main category: cs.RO

TL;DR: 研究比较了三种强化学习算法在四足机器人自主导航和避障中的表现，PPO算法表现最佳，为医疗辅助机器人提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 探索四足机器人在医疗领域的潜力，尤其是作为导盲犬的替代方案，填补现有研究的空白。

Method: 通过自定义环境和三种算法（PPO、DQN、Q-learning）的对比实验，评估传感器输入、碰撞频率等指标。

Result: PPO算法在路径跟随和避障任务中表现最优，尤其在平均和中间步骤数上显著优于其他算法。

Conclusion: 研究为AI驱动的四足机器人在辅助医疗领域的应用提供了可行性支持，并扩展了医疗‘宠物’的研究方向。

Abstract: Robots are increasingly integrated across industries, particularly in
healthcare. However, many valuable applications for quadrupedal robots remain
overlooked. This research explores the effectiveness of three reinforcement
learning algorithms in training a simulated quadruped robot for autonomous
navigation and obstacle avoidance. The goal is to develop a robotic guide dog
simulation capable of path following and obstacle avoidance, with long-term
potential for real-world assistance to guide dogs and visually impaired
individuals. It also seeks to expand research into medical 'pets', including
robotic guide and alert dogs.
  A comparative analysis of thirteen related research papers shaped key
evaluation criteria, including collision detection, pathfinding algorithms,
sensor usage, robot type, and simulation platforms. The study focuses on sensor
inputs, collision frequency, reward signals, and learning progression to
determine which algorithm best supports robotic navigation in complex
environments.
  Custom-made environments were used to ensure fair evaluation of all three
algorithms under controlled conditions, allowing consistent data collection.
Results show that Proximal Policy Optimization (PPO) outperformed Deep
Q-Network (DQN) and Q-learning across all metrics, particularly in average and
median steps to goal per episode.
  By analysing these results, this study contributes to robotic navigation, AI
and medical robotics, offering insights into the feasibility of AI-driven
quadruped mobility and its role in assistive robotics.

</details>


### [46] [Latent Policy Steering with Embodiment-Agnostic Pretrained World Models](https://arxiv.org/abs/2507.13340)
*Yiqi Wang,Mrinal Verghese,Jeff Schneider*

Main category: cs.RO

TL;DR: 通过模仿学习视觉运动策略，利用多体现数据集和人类游戏数据减少数据收集需求，结合世界模型和潜在策略搜索提升性能。


<details>
  <summary>Details</summary>
Motivation: 减少真实世界中昂贵的数据收集需求，利用现有或低成本的多体现数据集（如公共机器人数据集和人类游戏数据）提升策略性能。

Method: 使用光流作为体现无关的动作表示训练世界模型，并通过潜在策略搜索（LPS）优化行为克隆策略的输出。

Result: 在少量数据下（30次演示提升50%，50次演示提升20%），结合预训练世界模型显著提升策略性能。

Conclusion: 通过多体现数据预训练和潜在策略搜索，能够在少量数据下高效提升视觉运动策略的性能。

Abstract: Learning visuomotor policies via imitation has proven effective across a wide
range of robotic domains. However, the performance of these policies is heavily
dependent on the number of training demonstrations, which requires expensive
data collection in the real world. In this work, we aim to reduce data
collection efforts when learning visuomotor robot policies by leveraging
existing or cost-effective data from a wide range of embodiments, such as
public robot datasets and the datasets of humans playing with objects (human
data from play). Our approach leverages two key insights. First, we use optic
flow as an embodiment-agnostic action representation to train a World Model
(WM) across multi-embodiment datasets, and finetune it on a small amount of
robot data from the target embodiment. Second, we develop a method, Latent
Policy Steering (LPS), to improve the output of a behavior-cloned policy by
searching in the latent space of the WM for better action sequences. In real
world experiments, we observe significant improvements in the performance of
policies trained with a small amount of data (over 50% relative improvement
with 30 demonstrations and over 20% relative improvement with 50
demonstrations) by combining the policy with a WM pretrained on two thousand
episodes sampled from the existing Open X-embodiment dataset across different
robots or a cost-effective human dataset from play.

</details>
