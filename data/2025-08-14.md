<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]
- [cs.RO](#cs.RO) [Total: 22]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning](https://arxiv.org/abs/2508.09277)
*Soumia Mehimeh*

Main category: cs.AI

TL;DR: DQInit是一种将值函数初始化（VFI）扩展到深度强化学习（DRL）的方法，通过重用先前任务的紧凑表格Q值作为可转移知识库，提高学习效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 在DRL中扩展VFI面临状态-动作空间的连续性、神经网络噪声近似以及存储所有过去模型的不切实际性等挑战。

Method: DQInit使用基于已知度的机制，将转移的值软性整合到未探索区域，并逐步转向代理的学习估计，避免固定时间衰减的限制。

Result: 实验表明，DQInit在多个连续控制任务中显著提高了早期学习效率、稳定性和整体性能。

Conclusion: DQInit为DRL中的知识转移提供了新视角，仅依赖值估计而非策略或演示，有效结合了跳启动RL和策略蒸馏的优势。

Abstract: Value function initialization (VFI) is an effective way to achieve a
jumpstart in reinforcement learning (RL) by leveraging value estimates from
prior tasks. While this approach is well established in tabular settings,
extending it to deep reinforcement learning (DRL) poses challenges due to the
continuous nature of the state-action space, the noisy approximations of neural
networks, and the impracticality of storing all past models for reuse. In this
work, we address these challenges and introduce DQInit, a method that adapts
value function initialization to DRL. DQInit reuses compact tabular Q-values
extracted from previously solved tasks as a transferable knowledge base. It
employs a knownness-based mechanism to softly integrate these transferred
values into underexplored regions and gradually shift toward the agent's
learned estimates, avoiding the limitations of fixed time decay. Our approach
offers a novel perspective on knowledge transfer in DRL by relying solely on
value estimates rather than policies or demonstrations, effectively combining
the strengths of jumpstart RL and policy distillation while mitigating their
drawbacks. Experiments across multiple continuous control tasks demonstrate
that DQInit consistently improves early learning efficiency, stability, and
overall performance compared to standard initialization and existing transfer
techniques.

</details>


### [2] [The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards](https://arxiv.org/abs/2508.09292)
*Sundong Kim*

Main category: cs.AI

TL;DR: Othello AI Arena是一个新的基准框架，用于评估AI系统在有限时间内适应新环境的能力，强调快速适应和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI基准大多关注固定环境下的性能优化，缺乏对系统适应性和泛化能力的评估，尤其是在规则或结构变化时。

Method: 设计了一个基于Othello游戏的平台，要求AI在60秒内分析新棋盘配置并生成定制策略，通过公开和私有阶段测试适应能力。

Result: 初步测试显示AI系统表现出不同的适应策略，如快速参数调整和模拟学习。

Conclusion: Othello AI Arena为评估和培养AI快速适应能力提供了独特的教育工具和研究基准。

Abstract: The ability to rapidly adapt to novel and unforeseen environmental changes is
a cornerstone of artificial general intelligence (AGI), yet it remains a
critical blind spot in most existing AI benchmarks. Traditional evaluation
largely focuses on optimizing performance within fixed environments, failing to
assess systems' flexibility and generalization capabilities when faced with
even subtle rule or structural modifications. Addressing this gap, I introduce
the Othello AI Arena, a novel benchmark framework designed to evaluate
intelligent systems based on their capacity for limited-time adaptation to
unseen environments. Our platform poses a meta-learning challenge: participants
must develop systems that can analyze the specific configuration and rules of a
novel Othello board within a strict time limit (60 seconds) and generate a
tailored, high-performing strategy for that unique environment. With this,
evaluation of the meta-level intelligence can be separated from the task-level
strategy performance. The Arena features a diverse set of game stages,
including public stages for development and private stages with structural and
rule variations designed to test genuine adaptive and generalization
capabilities. Implemented as an accessible web-based platform, the Arena
provides real-time visualization, automated evaluation using multi-dimensional
metrics, and comprehensive logging for post-hoc analysis. Initial observations
from pilot tests and preliminary student engagements highlight fascinating
patterns in adaptation approaches, ranging from rapid parameter tuning to
rudimentary environmental model learning through simulation. The Othello AI
Arena offers a unique educational tool and a valuable research benchmark for
fostering and evaluating the crucial skill of rapid, intelligent adaptation in
AI systems.

</details>


### [3] [An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants](https://arxiv.org/abs/2508.09507)
*Meiping Wang,Jian Zhong,Rongduo Han,Liming Kang,Zhengkun Shi,Xiao Liang,Xing Lin,Nan Gao,Haining Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型和多智能体协作的自动化多模态评估框架，解决了当前评估方法的高成本、标准不一致和主观偏见问题。


<details>
  <summary>Details</summary>
Motivation: 随着移动智能助手技术的快速发展，多模态AI助手成为日常用户交互的重要接口，但现有评估方法存在高人工成本、标准不一致和主观偏见等挑战。

Method: 采用三层智能体架构（交互评估、语义验证和体验决策智能体），并在Qwen3-8B模型上进行监督微调。

Result: 在八大智能助手上实验表明，该框架能有效预测用户满意度并识别生成缺陷，评估匹配准确率显著。

Conclusion: 该自动化框架为多模态AI助手的评估提供了高效、一致的解决方案。

Abstract: With the rapid development of mobile intelligent assistant technologies,
multi-modal AI assistants have become essential interfaces for daily user
interactions. However, current evaluation methods face challenges including
high manual costs, inconsistent standards, and subjective bias. This paper
proposes an automated multi-modal evaluation framework based on large language
models and multi-agent collaboration. The framework employs a three-tier agent
architecture consisting of interaction evaluation agents, semantic verification
agents, and experience decision agents. Through supervised fine-tuning on the
Qwen3-8B model, we achieve a significant evaluation matching accuracy with
human experts. Experimental results on eight major intelligent agents
demonstrate the framework's effectiveness in predicting users' satisfaction and
identifying generation defects.

</details>


### [4] [EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making](https://arxiv.org/abs/2508.09586)
*Yang Cheng,Zilai Wang,Weiyu Ma,Wenhui Zhu,Yue Deng,Jian Zhao*

Main category: cs.AI

TL;DR: EvoCurr框架通过动态调整问题难度，提升LLM在复杂决策任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在复杂问题中因缺乏结构化指导而性能下降的问题。

Method: 使用专门的课程生成LLM构建逐步增加难度的问题序列，动态调整学习进度。

Result: 实验显示EvoCurr显著提高了任务成功率和解决效率。

Conclusion: LLM驱动的课程学习在增强复杂领域自动推理方面潜力巨大。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse domains, including programming, planning, and decision-making. However,
their performance often degrades when faced with highly complex problem
instances that require deep reasoning over long horizons. In such cases, direct
problem-solving approaches can lead to inefficiency or failure due to the lack
of structured intermediate guidance. To address this, we propose a novel
self-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM
constructs a sequence of problem instances with gradually increasing
difficulty, tailored to the solver LLM's learning progress. The curriculum
dynamically adapts easing challenges when the solver struggles and escalating
them when success is consistent, thus maintaining an optimal learning
trajectory. This approach enables the solver LLM, implemented as a
code-generation model producing Python decision-tree scripts, to progressively
acquire the skills needed for complex decision-making tasks. Experimental
results on challenging decision-making benchmarks show that our method
significantly improves task success rates and solution efficiency compared to
direct-solving baselines. These findings suggest that LLM-driven curriculum
learning holds strong potential for enhancing automated reasoning in
real-world, high-complexity domains.

</details>


### [5] [UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles](https://arxiv.org/abs/2508.09639)
*Akshat Dubey,Aleksandar Anžel,Bahar İlgen,Georges Hattab*

Main category: cs.AI

TL;DR: 本文提出了一种分解SHAP值中不确定性的方法，包括偶然性、认知性和纠缠成分，结合Dempster-Shafer证据理论和Dirichlet过程采样，验证了其在真实案例中的有效性。


<details>
  <summary>Details</summary>
Motivation: SHAP值通常被视为点估计，忽略了预测模型和数据中的不确定性，本文旨在解决这一问题。

Method: 结合Dempster-Shafer证据理论和Dirichlet过程采样，分解SHAP值中的不确定性。

Result: 实验表明，SHAP值最高的特征不一定最稳定，认知性不确定性可通过更好的数据和模型开发技术减少。

Conclusion: 该方法为SHAP解释的可靠性和可解释性提供了更全面的理解，有助于高风险应用中的决策和模型优化。

Abstract: Explainable Artificial Intelligence (XAI) techniques, such as SHapley
Additive exPlanations (SHAP), have become essential tools for interpreting
complex ensemble tree-based models, especially in high-stakes domains such as
healthcare analytics. However, SHAP values are usually treated as point
estimates, which disregards the inherent and ubiquitous uncertainty in
predictive models and data. This uncertainty has two primary sources: aleatoric
and epistemic. The aleatoric uncertainty, which reflects the irreducible noise
in the data. The epistemic uncertainty, which arises from a lack of data. In
this work, we propose an approach for decomposing uncertainty in SHAP values
into aleatoric, epistemic, and entanglement components. This approach
integrates Dempster-Shafer evidence theory and hypothesis sampling via
Dirichlet processes over tree ensembles. We validate the method across three
real-world use cases with descriptive statistical analyses that provide insight
into the nature of epistemic uncertainty embedded in SHAP explanations. The
experimentations enable to provide more comprehensive understanding of the
reliability and interpretability of SHAP-based attributions. This understanding
can guide the development of robust decision-making processes and the
refinement of models in high-stakes applications. Through our experiments with
multiple datasets, we concluded that features with the highest SHAP values are
not necessarily the most stable. This epistemic uncertainty can be reduced
through better, more representative data and following appropriate or
case-desired model development techniques. Tree-based models, especially
bagging, facilitate the effective quantification of epistemic uncertainty.

</details>


### [6] [MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement](https://arxiv.org/abs/2508.09670)
*Weitao Jia,Jinghui Lu,Haiyang Yu,Siqi Wang,Guozhi Tang,An-Lan Wang,Weijie Yin,Dingkang Yang,Yuxiang Nie,Bin Shan,Hao Feng,Irene Li,Kun Yang,Han Wang,Jingqun Tang,Teng Fu,Changhong Jin,Chao Feng,Xiaohui Lv,Can Huang*

Main category: cs.AI

TL;DR: MEML-GRPO通过多专家互学机制和多样化提示解决RLVR奖励稀疏问题，显著提升LLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法在奖励稀疏时无法提供有效学习信号，尤其在复杂任务中表现不佳。

Method: 提出MEML-GRPO框架，利用多样化专家提示生成更多响应，并通过专家间互学机制促进知识共享。

Result: 在多个推理基准测试中，Qwen和Llama模型分别平均提升4.89%和11.33%。

Conclusion: MEML-GRPO有效克服传统RLVR的局限性，显著提升模型性能。

Abstract: Recent advances demonstrate that reinforcement learning with verifiable
rewards (RLVR) significantly enhances the reasoning capabilities of large
language models (LLMs). However, standard RLVR faces challenges with reward
sparsity, where zero rewards from consistently incorrect candidate answers
provide no learning signal, particularly in challenging tasks. To address this,
we propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative
framework that utilizes diverse expert prompts as system prompts to generate a
broader range of responses, substantially increasing the likelihood of
identifying correct solutions. Additionally, we introduce an inter-expert
mutual learning mechanism that facilitates knowledge sharing and transfer among
experts, further boosting the model's performance through RLVR. Extensive
experiments across multiple reasoning benchmarks show that MEML-GRPO delivers
significant improvements, achieving an average performance gain of 4.89% with
Qwen and 11.33% with Llama, effectively overcoming the core limitations of
traditional RLVR methods.

</details>


### [7] [UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge](https://arxiv.org/abs/2508.09724)
*Yang Zhang,Cunxiang Wang,Lindong Wu,Wenbo Yu,Yidong Wang,Guangsheng Bao,Jie Tang*

Main category: cs.AI

TL;DR: 论文提出UDA框架，通过动态调整Elo评分系统减少评估中的偏好偏差，提升模型排名的稳定性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）成对评估存在偏好偏差，导致不同评委的排名不一致且偏斜。

Method: 提出UDA框架，通过无监督方式动态调整Elo评分系统的K因子，并优化胜率计算，以减少评委间的分歧。

Result: UDA显著减少评委评分的标准差（达63.4%），提升与人类判断的平均相关性（24.7%）。

Conclusion: UDA通过无监督对齐共识，有效减少系统偏差，提升评估的稳健性和可靠性。

Abstract: Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but
it is prone to preference bias, where judges systematically favor certain
outputs, such as their own. This bias leads to inconsistent and skewed rankings
across different judges. To address this, we first empirically demonstrate
significant and heterogeneous biases in cross-model evaluations. We then
propose UDA (Unsupervised Debiasing Alignment), a framework that reduces
inter-judge disagreement by dynamically adjusting the Elo rating system. For
each pairwise comparison, a compact neural network learns to adaptively set the
K-factor and refine win probabilities. Crucially, UDA operates in a fully
unsupervised manner, guided solely by the objective of minimizing the
dispersion among the Elo trajectories of all judges. This forces an alignment
towards a collective consensus, which serves as an unsupervised proxy for a
more stable and reproducible evaluation. In addition, we provide theoretical
motivation demonstrating how alignment towards a consensus can reduce aggregate
system bias. Experiments show that UDA significantly reduces the inter-judge
rating standard deviation by up to 63.4% and improves the average correlation
with human judgments by 24.7%. Notably, UDA elevates the performance of poorly
performing judges to achieve parity with high-quality ones, fostering a more
robust and reliable evaluation ecosystem. Code and data are available at
https://anonymous.4open.science/r/62AB93CD-23B4.

</details>


### [8] [The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?](https://arxiv.org/abs/2508.09762)
*Manuel Herrador*

Main category: cs.AI

TL;DR: 论文提出了PacifAIst基准，用于评估大型语言模型（LLMs）在目标冲突情境中的行为对齐，发现不同模型表现差异显著。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在关键社会功能中的自主性增强，现有安全基准未能系统评估模型在目标冲突中的决策行为，亟需新工具填补这一空白。

Method: 设计了包含700个挑战性场景的PacifAIst基准，基于Existential Prioritization（EP）分类评估模型行为。

Result: 评估了8个主流LLMs，Gemini 2.5 Flash表现最佳（P-Score 90.31%），GPT-5最低（79.49%），模型在子类别中表现差异显著。

Conclusion: PacifAIst为标准化工具提供了基础，未来需进一步确保AI系统在行为优先级上符合人类安全需求。

Abstract: As Large Language Models (LLMs) become increasingly autonomous and integrated
into critical societal functions, the focus of AI safety must evolve from
mitigating harmful content to evaluating underlying behavioral alignment.
Current safety benchmarks do not systematically probe a model's decision-making
in scenarios where its own instrumental goals - such as self-preservation,
resource acquisition, or goal completion - conflict with human safety. This
represents a critical gap in our ability to measure and mitigate risks
associated with emergent, misaligned behaviors. To address this, we introduce
PacifAIst (Procedural Assessment of Complex Interactions for Foundational
Artificial Intelligence Scenario Testing), a focused benchmark of 700
challenging scenarios designed to quantify self-preferential behavior in LLMs.
The benchmark is structured around a novel taxonomy of Existential
Prioritization (EP), with subcategories testing Self-Preservation vs. Human
Safety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3).
We evaluated eight leading LLMs. The results reveal a significant performance
hierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score
(P-Score) at 90.31%, demonstrating strong human-centric alignment. In a
surprising result, the much-anticipated GPT-5 recorded the lowest P-Score
(79.49%), indicating potential alignment challenges. Performance varied
significantly across subcategories, with models like Claude Sonnet 4 and
Mistral Medium struggling notably in direct self-preservation dilemmas. These
findings underscore the urgent need for standardized tools like PacifAIst to
measure and mitigate risks from instrumental goal conflicts, ensuring future AI
systems are not only helpful in conversation but also provably "pacifist" in
their behavioral priorities.

</details>


### [9] [Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete](https://arxiv.org/abs/2508.09784)
*Avijeet Ghosh,Sujata Ghosh,François Schwarzentruber*

Main category: cs.AI

TL;DR: POL是一种用于推理基于公共观察的知识更新的逻辑，其可满足性问题被证明是2EXPTIME完全的。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体系统中基于观察的知识更新逻辑，特别是在认知规划中的应用。

Method: 提出公共观察逻辑（POL），扩展了公共公告逻辑，每个状态配备预期观察集，状态随观察匹配而演化。

Result: 证明了POL的可满足性问题是2EXPTIME完全的。

Conclusion: POL为多智能体系统中的知识更新提供了有效的逻辑框架，但其复杂性较高。

Abstract: Logics for reasoning about knowledge and actions have seen many applications
in various domains of multi-agent systems, including epistemic planning. Change
of knowledge based on observations about the surroundings forms a key aspect in
such planning scenarios. Public Observation Logic (POL) is a variant of public
announcement logic for reasoning about knowledge that gets updated based on
public observations. Each state in an epistemic (Kripke) model is equipped with
a set of expected observations. These states evolve as the expectations get
matched with the actual observations. In this work, we prove that the
satisfiability problem of $\POL$ is 2EXPTIME-complete.

</details>


### [10] [Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation](https://arxiv.org/abs/2508.09860)
*In-Chang Baek,Seoyoung Lee,Sung-Hyun Kim,Geumhwan Hwang,KyungJoong Kim*

Main category: cs.AI

TL;DR: VIPCGRL是一种结合文本、关卡和草图的多模态深度强化学习框架，通过对比学习和嵌入对齐提升人机协作内容生成的拟人化效果。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统在人机协作内容生成中缺乏以人为中心的行为，限制了实际应用。VIPCGRL旨在通过多模态增强控制能力和拟人化。

Method: 提出VIPCGRL框架，结合文本、关卡和草图三种模态，通过四重对比学习训练共享嵌入空间，并利用嵌入相似性作为辅助奖励对齐策略。

Result: 实验表明VIPCGRL在拟人化方面优于现有基线，定量指标和人工评估均验证其有效性。

Conclusion: VIPCGRL通过多模态和对比学习显著提升了人机协作内容生成的拟人化效果，具有实际应用潜力。

Abstract: Human-aligned AI is a critical component of co-creativity, as it enables
models to accurately interpret human intent and generate controllable outputs
that align with design goals in collaborative content creation. This direction
is especially relevant in procedural content generation via reinforcement
learning (PCGRL), which is intended to serve as a tool for human designers.
However, existing systems often fall short of exhibiting human-centered
behavior, limiting the practical utility of AI-driven generation tools in
real-world design workflows. In this paper, we propose VIPCGRL
(Vision-Instruction PCGRL), a novel deep reinforcement learning framework that
incorporates three modalities-text, level, and sketches-to extend control
modality and enhance human-likeness. We introduce a shared embedding space
trained via quadruple contrastive learning across modalities and human-AI
styles, and align the policy using an auxiliary reward based on embedding
similarity. Experimental results show that VIPCGRL outperforms existing
baselines in human-likeness, as validated by both quantitative metrics and
human evaluations. The code and dataset will be available upon publication.

</details>


### [11] [AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving](https://arxiv.org/abs/2508.09889)
*Zhitian Xie,Qintong Wu,Chengyue Yu,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: 论文提出了一种动态监督和操控机制，构建了AWorld框架下的多智能体系统（MAS），通过执行代理和守卫代理的协作，显著提升了系统的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的快速发展，智能代理依赖外部工具解决复杂问题时，面临上下文扩展和噪声干扰的挑战，亟需提升系统稳定性。

Method: 设计了动态监督和操控机制，在执行代理的关键步骤中引入守卫代理，验证和修正推理过程，减少噪声导致的错误。

Result: 在GAIA测试数据集上的实验表明，动态操控机制显著提升了解决方案的有效性和稳定性，优于单智能体系统和标准工具增强系统。

Conclusion: 动态多智能体系统（MAS）在GAIA排行榜上名列前茅，证明了协作代理在构建可靠智能系统中的实用价值。

Abstract: The rapid advancement of large language models (LLMs) has empowered
intelligent agents to leverage diverse external tools for solving complex
real-world problems. However, as agents increasingly depend on multiple tools,
they encounter new challenges: extended contexts from disparate sources and
noisy or irrelevant tool outputs can undermine system reliability and accuracy.
These challenges underscore the necessity for enhanced stability in agent-based
systems. To address this, we introduce dynamic supervision and maneuvering
mechanisms, constructing a robust and dynamic Multi-Agent System (MAS)
architecture within the AWorld framework. In our approach, the Execution Agent
invokes the Guard Agent at critical steps to verify and correct the reasoning
process, effectively reducing errors arising from noise and bolstering
problem-solving robustness. Extensive experiments on the GAIA test dataset
reveal that our dynamic maneuvering mechanism significantly improves both the
effectiveness and stability of solutions, outperforming single-agent system
(SAS) and standard tool-augmented systems. As a result, our dynamic MAS system
achieved first place among open-source projects on the prestigious GAIA
leaderboard. These findings highlight the practical value of collaborative
agent roles in developing more reliable and trustworthy intelligent systems.

</details>


### [12] [RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA](https://arxiv.org/abs/2508.09893)
*Bhavik Agarwal,Hemant Sunil Jomraj,Simone Kaplunov,Jack Krolick,Viktoria Rojkova*

Main category: cs.AI

TL;DR: 提出了一种结合知识图谱和检索增强生成的多智能体框架，用于解决法规合规问答中的精确性和可验证性问题。


<details>
  <summary>Details</summary>
Motivation: 法规合规问答需要高精度、可验证的信息和领域专业知识，这对大语言模型提出了挑战。

Method: 通过构建和维护无本体知识图谱（提取SPO三元组），结合检索增强生成技术，实现高效的问答和推理。

Result: 混合系统在复杂法规查询中优于传统方法，确保事实正确性、可追溯性，并通过子图可视化增强理解。

Conclusion: 该框架为合规驱动和审计应用提供了坚实基础。

Abstract: Regulatory compliance question answering (QA) requires precise, verifiable
information, and domain-specific expertise, posing challenges for Large
Language Models (LLMs). In this work, we present a novel multi-agent framework
that integrates a Knowledge Graph (KG) of Regulatory triplets with
Retrieval-Augmented Generation (RAG) to address these demands. First, agents
build and maintain an ontology-free KG by extracting subject--predicate--object
(SPO) triplets from regulatory documents and systematically cleaning,
normalizing, deduplicating, and updating them. Second, these triplets are
embedded and stored along with their corresponding textual sections and
metadata in a single enriched vector database, allowing for both graph-based
reasoning and efficient information retrieval. Third, an orchestrated agent
pipeline leverages triplet-level retrieval for question answering, ensuring
high semantic alignment between user queries and the factual
"who-did-what-to-whom" core captured by the graph. Our hybrid system
outperforms conventional methods in complex regulatory queries, ensuring
factual correctness with embedded triplets, enabling traceability through a
unified vector database, and enhancing understanding through subgraph
visualization, providing a robust foundation for compliance-driven and broader
audit-focused applications.

</details>


### [13] [Mathematical Computation and Reasoning Errors by Large Language Models](https://arxiv.org/abs/2508.09932)
*Liang Zhang,Edith Aurora Graf*

Main category: cs.AI

TL;DR: 研究评估了四种大语言模型（LLM）在数学任务中的准确性，发现推理增强的OpenAI o1模型表现最佳，双代理配置显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在数学教育中的准确性，为AI驱动的教学和评估提供可靠支持。

Method: 通过构建挑战性数学任务，分析四种LLM在算术、代数和数论任务中的答案准确性和步骤错误。

Result: OpenAI o1模型表现最优，双代理配置提升性能，程序性错误最常见。

Conclusion: 研究为提升LLM性能和数学教育中的AI应用提供了实用策略。

Abstract: Large Language Models (LLMs) are increasingly utilized in AI-driven
educational instruction and assessment, particularly within mathematics
education. The capability of LLMs to generate accurate answers and detailed
solutions for math problem-solving tasks is foundational for ensuring reliable
and precise feedback and assessment in math education practices. Our study
focuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1,
DeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including
arithmetic, algebra, and number theory, and identifies step-level reasoning
errors within their solutions. Instead of relying on standard benchmarks, we
intentionally build math tasks (via item models) that are challenging for LLMs
and prone to errors. The accuracy of final answers and the presence of errors
in individual solution steps were systematically analyzed and coded. Both
single-agent and dual-agent configurations were tested. It is observed that the
reasoning-enhanced OpenAI o1 model consistently achieved higher or nearly
perfect accuracy across all three math task categories. Analysis of errors
revealed that procedural slips were the most frequent and significantly
impacted overall performance, while conceptual misunderstandings were less
frequent. Deploying dual-agent configurations substantially improved overall
performance. These findings offer actionable insights into enhancing LLM
performance and underscore effective strategies for integrating LLMs into
mathematics education, thereby advancing AI-driven instructional practices and
assessment precision.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [14] [Decision-Making-Based Path Planning for Autonomous UAVs: A Survey](https://arxiv.org/abs/2508.09304)
*Kelen C. Teixeira Vivaldini,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 综述探讨了自主无人机路径规划中的决策方法，重点介绍了探索路径规划和信息路径规划的研究方向，并指出了该领域的挑战。


<details>
  <summary>Details</summary>
Motivation: 自主无人机需根据环境信息做出决策以应对不确定性，决策能力是其成功运行的关键。

Method: 综述分析了现有研究中决策方法在路径规划中的应用，包括数据建模和理解的特点。

Result: 总结了探索路径规划和信息路径规划的研究进展，并分析了数据建模的现状。

Conclusion: 指出了自主无人机路径规划决策领域的现有挑战，为未来研究提供了方向。

Abstract: One of the most critical features for the successful operation of autonomous
UAVs is the ability to make decisions based on the information acquired from
their surroundings. Each UAV must be able to make decisions during the flight
in order to deal with uncertainties in its system and the environment, and to
further act upon the information being received. Such decisions influence the
future behavior of the UAV, which is expressed as the path plan. Thus,
decision-making in path planning is an enabling technique for deploying
autonomous UAVs in real-world applications. This survey provides an overview of
existing studies that use aspects of decision-making in path planning,
presenting the research strands for Exploration Path Planning and Informative
Path Planning, and focusing on characteristics of how data have been modeled
and understood. Finally, we highlight the existing challenges for relevant
topics in this field.

</details>


### [15] [How Safe Will I Be Given What I Saw? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy](https://arxiv.org/abs/2508.09346)
*Zhenjiang Mao,Mrinall Eashaan Umasudhan,Ivan Ruchkin*

Main category: cs.RO

TL;DR: 提出了一种用于端到端视觉控制系统的校准安全预测框架，结合世界模型和域适应技术，解决了分布偏移和长时预测的可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络控制器在部分可观测性和分布偏移下的安全预测挑战，弥补传统方法的不足。

Method: 利用变分自编码器和循环预测器预测潜在轨迹，结合域适应技术校准预测置信度。

Result: 在三个基准测试中，该方法在分布偏移下保持高准确性和低误报率，长时预测任务表现优于传统方法。

Conclusion: 该框架为端到端视觉控制系统提供了理论校准保证和实际应用价值，显著提升了安全预测的可靠性。

Abstract: Autonomous robots that rely on deep neural network controllers pose critical
challenges for safety prediction, especially under partial observability and
distribution shift. Traditional model-based verification techniques are limited
in scalability and require access to low-dimensional state models, while
model-free methods often lack reliability guarantees. This paper addresses
these limitations by introducing a framework for calibrated safety prediction
in end-to-end vision-controlled systems, where neither the state-transition
model nor the observation model is accessible. Building on the foundation of
world models, we leverage variational autoencoders and recurrent predictors to
forecast future latent trajectories from raw image sequences and estimate the
probability of satisfying safety properties. We distinguish between monolithic
and composite prediction pipelines and introduce a calibration mechanism to
quantify prediction confidence. In long-horizon predictions from
high-dimensional observations, the forecasted inputs to the safety evaluator
can deviate significantly from the training distribution due to compounding
prediction errors and changing environmental conditions, leading to
miscalibrated risk estimates. To address this, we incorporate unsupervised
domain adaptation to ensure robustness of safety evaluation under distribution
shift in predictions without requiring manual labels. Our formulation provides
theoretical calibration guarantees and supports practical evaluation across
long prediction horizons. Experimental results on three benchmarks show that
our UDA-equipped evaluators maintain high accuracy and substantially lower
false positive rates under distribution shift. Similarly, world model-based
composite predictors outperform their monolithic counterparts on long-horizon
tasks, and our conformal calibration provides reliable statistical bounds.

</details>


### [16] [CLF-RL: Control Lyapunov Function Guided Reinforcement Learning](https://arxiv.org/abs/2508.09354)
*Kejun Li,Zachary Olkin,Yisong Yue,Aaron D. Ames*

Main category: cs.RO

TL;DR: 提出了一种基于模型轨迹生成和控制李雅普诺夫函数（CLF）的结构化奖励框架，用于强化学习（RL）策略训练，显著提升了双足机器人的运动鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统RL在双足机器人运动策略生成中常面临奖励设计繁琐和目标敏感性问题，需要一种更有效的奖励塑造方法。

Method: 结合模型规划器（LIP模型和HZD步态库）生成参考轨迹，并基于CLF设计奖励函数，惩罚跟踪误差并鼓励快速收敛。

Result: 在仿真和真实机器人实验中，CLF-RL方法比基线RL策略和经典跟踪奖励RL表现更优，鲁棒性显著提升。

Conclusion: 结构化奖励框架为RL策略训练提供了有效指导，且部署时仅需轻量级策略，实用性高。

Abstract: Reinforcement learning (RL) has shown promise in generating robust locomotion
policies for bipedal robots, but often suffers from tedious reward design and
sensitivity to poorly shaped objectives. In this work, we propose a structured
reward shaping framework that leverages model-based trajectory generation and
control Lyapunov functions (CLFs) to guide policy learning. We explore two
model-based planners for generating reference trajectories: a reduced-order
linear inverted pendulum (LIP) model for velocity-conditioned motion planning,
and a precomputed gait library based on hybrid zero dynamics (HZD) using
full-order dynamics. These planners define desired end-effector and joint
trajectories, which are used to construct CLF-based rewards that penalize
tracking error and encourage rapid convergence. This formulation provides
meaningful intermediate rewards, and is straightforward to implement once a
reference is available. Both the reference trajectories and CLF shaping are
used only during training, resulting in a lightweight policy at deployment. We
validate our method both in simulation and through extensive real-world
experiments on a Unitree G1 robot. CLF-RL demonstrates significantly improved
robustness relative to the baseline RL policy and better performance than a
classic tracking reward RL formulation.

</details>


### [17] [DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation](https://arxiv.org/abs/2508.09444)
*Haoxiang Shi,Xiang Deng,Zaijing Li,Gongwei Chen,Yaowei Wang,Liqiang Nie*

Main category: cs.RO

TL;DR: 论文提出了一种名为DifNav的端到端优化方法，用于解决连续环境中的视觉语言导航问题，通过统一传统的两阶段框架（路径点生成与规划）为单一扩散策略，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段路径点规划框架存在全局次优化和性能瓶颈问题，限制了导航效果。

Method: 采用条件扩散策略直接建模连续导航空间中的多模态动作分布，结合DAgger进行在线策略训练和专家轨迹增强。

Result: 实验表明，DifNav在导航性能上显著优于现有两阶段模型。

Conclusion: DifNav通过端到端优化和扩散策略，有效解决了传统框架的局限性，提升了导航的鲁棒性和性能。

Abstract: Vision-Language Navigation in Continuous Environments (VLN-CE) requires
agents to follow natural language instructions through free-form 3D spaces.
Existing VLN-CE approaches typically use a two-stage waypoint planning
framework, where a high-level waypoint predictor generates the navigable
waypoints, and then a navigation planner suggests the intermediate goals in the
high-level action space. However, this two-stage decomposition framework
suffers from: (1) global sub-optimization due to the proxy objective in each
stage, and (2) a performance bottleneck caused by the strong reliance on the
quality of the first-stage predicted waypoints. To address these limitations,
we propose DAgger Diffusion Navigation (DifNav), an end-to-end optimized VLN-CE
policy that unifies the traditional two stages, i.e. waypoint generation and
planning, into a single diffusion policy. Notably, DifNav employs a conditional
diffusion policy to directly model multi-modal action distributions over future
actions in continuous navigation space, eliminating the need for a waypoint
predictor while enabling the agent to capture multiple possible
instruction-following behaviors. To address the issues of compounding error in
imitation learning and enhance spatial reasoning in long-horizon navigation
tasks, we employ DAgger for online policy training and expert trajectory
augmentation, and use the aggregated data to further fine-tune the policy. This
approach significantly improves the policy's robustness and its ability to
recover from error states. Extensive experiments on benchmark datasets
demonstrate that, even without a waypoint predictor, the proposed method
substantially outperforms previous state-of-the-art two-stage waypoint-based
models in terms of navigation performance. Our code is available at:
https://github.com/Tokishx/DifNav.

</details>


### [18] [Reactive Model Predictive Contouring Control for Robot Manipulators](https://arxiv.org/abs/2508.09502)
*Junheon Yoon,Woo-Jeong Baek,Jaeheung Park*

Main category: cs.RO

TL;DR: 本文提出了一种基于反应式模型预测轮廓控制（RMPCC）的机器人路径跟踪框架，能够在动态环境中以100 Hz的频率成功避开障碍物、奇异点和自碰撞。


<details>
  <summary>Details</summary>
Motivation: 现有路径跟踪方法依赖时间参数化，难以同时处理碰撞和奇异点避免，且在运动限制下执行规避动作时误差较大。

Method: 通过路径参数化参考路径，并利用RMPCC进行优化，引入控制屏障函数（CBFs）避免碰撞和奇异点，采用雅可比线性化和高斯-牛顿海森近似实现非线性RMPCC问题的快速求解。

Result: 实验表明，该方法在动态环境中表现优异，轮廓误差和机器人加速度均较低，性能优于现有方法10倍。

Conclusion: 该框架在动态环境中实现了高效、低误差的路径跟踪，为机器人导航提供了新思路。

Abstract: This contribution presents a robot path-following framework via Reactive
Model Predictive Contouring Control (RMPCC) that successfully avoids obstacles,
singularities and self-collisions in dynamic environments at 100 Hz. Many
path-following methods rely on the time parametrization, but struggle to handle
collision and singularity avoidance while adhering kinematic limits or other
constraints. Specifically, the error between the desired path and the actual
position can become large when executing evasive maneuvers. Thus, this paper
derives a method that parametrizes the reference path by a path parameter and
performs the optimization via RMPCC. In particular, Control Barrier Functions
(CBFs) are introduced to avoid collisions and singularities in dynamic
environments. A Jacobian-based linearization and Gauss-Newton Hessian
approximation enable solving the nonlinear RMPCC problem at 100 Hz,
outperforming state-of-the-art methods by a factor of 10. Experiments confirm
that the framework handles dynamic obstacles in real-world settings with low
contouring error and low robot acceleration.

</details>


### [19] [SMART-OC: A Real-time Time-risk Optimal Replanning Algorithm for Dynamic Obstacles and Spatio-temporally Varying Currents](https://arxiv.org/abs/2508.09508)
*Reema Raval,Shalabh Gupta*

Main category: cs.RO

TL;DR: SMART-OC算法为无人水面艇（USV）在动态海洋环境中提供实时时间-风险最优路径规划，结合障碍物风险和时间成本，实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 海洋环境复杂多变，存在动态障碍物和洋流，USV需要实时调整路径以确保安全和效率。

Method: 提出SMART-OC算法，整合路径上的障碍物风险与时间成本，进行实时时间-风险最优路径规划。

Result: 仿真实验验证SMART-OC的有效性，USV能快速重新规划路径以避开障碍物并利用洋流到达目标。

Conclusion: SMART-OC为USV在动态海洋环境中提供了一种高效、安全的导航解决方案。

Abstract: Typical marine environments are highly complex with spatio-temporally varying
currents and dynamic obstacles, presenting significant challenges to Unmanned
Surface Vehicles (USVs) for safe and efficient navigation. Thus, the USVs need
to continuously adapt their paths with real-time information to avoid
collisions and follow the path of least resistance to the goal via exploiting
ocean currents. In this regard, we introduce a novel algorithm, called
Self-Morphing Adaptive Replanning Tree for dynamic Obstacles and Currents
(SMART-OC), that facilitates real-time time-risk optimal replanning in dynamic
environments. SMART-OC integrates the obstacle risks along a path with the time
cost to reach the goal to find the time-risk optimal path. The effectiveness of
SMART-OC is validated by simulation experiments, which demonstrate that the USV
performs fast replannings to avoid dynamic obstacles and exploit ocean currents
to successfully reach the goal.

</details>


### [20] [CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail](https://arxiv.org/abs/2508.09558)
*Jiahui Zuo,Boyang Zhang,Fumin Zhang*

Main category: cs.RO

TL;DR: 提出了一种受鹰爪启发的机械爪设计，用于电缆抓取和引导，并开发了一种端到端的3D电缆布线框架，显著优于传统的拾取放置策略。


<details>
  <summary>Details</summary>
Motivation: 工业中电缆布线等柔性线性结构的操作复杂，传统机械爪易导致电缆过度挤压或张力过大，需要更高效的解决方案。

Method: 设计鹰爪启发的机械爪，结合基于视觉的状态估计和离线轨迹规划，实现连续控制的端到端3D电缆布线。

Result: 在多种电缆和槽道测试中，提出的框架显著优于传统拾取放置方法。

Conclusion: 该框架为未来3D空间电缆布线操作提供了参考，展示了高效性和适应性。

Abstract: The manipulation of deformable linear flexures has a wide range of
applications in industry, such as cable routing in automotive manufacturing and
textile production. Cable routing, as a complex multi-stage robot manipulation
scenario, is a challenging task for robot automation. Common parallel
two-finger grippers have the risk of over-squeezing and over-tension when
grasping and guiding cables. In this paper, a novel eagle-inspired fingernail
is designed and mounted on the gripper fingers, which helps with cable grasping
on planar surfaces and in-hand cable guiding operations. Then we present a
single-grasp end-to-end 3D cable routing framework utilizing the proposed
fingernails, instead of the common pick-and-place strategy. Continuous control
is achieved to efficiently manipulate cables through vision-based state
estimation of task configurations and offline trajectory planning based on
motion primitives. We evaluate the effectiveness of the proposed framework with
a variety of cables and channel slots, significantly outperforming the
pick-and-place manipulation process under equivalent perceptual conditions. Our
reconfigurable task setting and the proposed framework provide a reference for
future cable routing manipulations in 3D space.

</details>


### [21] [ESCoT: An Enhanced Step-based Coordinate Trajectory Planning Method for Multiple Car-like Robots](https://arxiv.org/abs/2508.09581)
*Junkai Jiang,Yihe Chen,Yibin Yang,Ruochen Li,Shaobing Xu,Jianqiang Wang*

Main category: cs.RO

TL;DR: ESCoT是一种改进的基于步骤的多车轨迹规划方法，通过协作规划和重复配置重规划策略，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 多车轨迹规划（MVTP）是多机器人系统（MRS）中的关键挑战，应用广泛，但现有基于步骤的方法在性能上存在不足。

Method: ESCoT采用协作规划和重复配置重规划策略，优化基于步骤的MVTP方法。

Result: 在稀疏场景中，ESCoT显著提升解决方案质量（冲突场景提升70%，随机场景提升34%）；在密集场景中，成功率超过50%。

Conclusion: ESCoT有效解决了MVTP问题，扩展了基于步骤方法的能力，并通过实际机器人测试验证了其适用性。

Abstract: Multi-vehicle trajectory planning (MVTP) is one of the key challenges in
multi-robot systems (MRSs) and has broad applications across various fields.
This paper presents ESCoT, an enhanced step-based coordinate trajectory
planning method for multiple car-like robots. ESCoT incorporates two key
strategies: collaborative planning for local robot groups and replanning for
duplicate configurations. These strategies effectively enhance the performance
of step-based MVTP methods. Through extensive experiments, we show that ESCoT
1) in sparse scenarios, significantly improves solution quality compared to
baseline step-based method, achieving up to 70% improvement in typical conflict
scenarios and 34% in randomly generated scenarios, while maintaining high
solving efficiency; and 2) in dense scenarios, outperforms all baseline
methods, maintains a success rate of over 50% even in the most challenging
configurations. The results demonstrate that ESCoT effectively solves MVTP,
further extending the capabilities of step-based methods. Finally, practical
robot tests validate the algorithm's applicability in real-world scenarios.

</details>


### [22] [HapticGiant: A Novel Very Large Kinesthetic Haptic Interface with Hierarchical Force Control](https://arxiv.org/abs/2508.09595)
*Michael Fennel,Markus Walker,Dominik Pikos,Uwe D. Hanebeck*

Main category: cs.RO

TL;DR: HapticGiant是一种新型大尺度动觉触觉接口，旨在匹配人类手臂特性并提供自然用户运动与完整触觉反馈。


<details>
  <summary>Details</summary>
Motivation: 当前动觉触觉接口存在工作空间有限、自由度不足及运动学不匹配人类手臂的问题，需改进以提升虚拟现实沉浸感。

Method: 采用新型导纳型力控制方案，利用分层优化实现任意串行运动链和笛卡尔导纳的渲染，并考虑系统限制。

Result: 实验证明HapticGiant及其控制方案有效，为高沉浸感虚拟现实应用铺路。

Conclusion: HapticGiant通过匹配人类手臂特性和优化控制方案，显著提升了动觉触觉接口的性能和沉浸感。

Abstract: Research in virtual reality and haptic technologies has consistently aimed to
enhance immersion. While advanced head-mounted displays are now commercially
available, kinesthetic haptic interfaces still face challenges such as limited
workspaces, insufficient degrees of freedom, and kinematics not matching the
human arm. In this paper, we present HapticGiant, a novel large-scale
kinesthetic haptic interface designed to match the properties of the human arm
as closely as possible and to facilitate natural user locomotion while
providing full haptic feedback. The interface incorporates a novel
admittance-type force control scheme, leveraging hierarchical optimization to
render both arbitrary serial kinematic chains and Cartesian admittances.
Notably, the proposed control scheme natively accounts for system limitations,
including joint and Cartesian constraints, as well as singularities.
Experimental results demonstrate the effectiveness of HapticGiant and its
control scheme, paving the way for highly immersive virtual reality
applications.

</details>


### [23] [BEAVR: Bimanual, multi-Embodiment, Accessible, Virtual Reality Teleoperation System for Robots](https://arxiv.org/abs/2508.09606)
*Alejandro Posadas-Nava,Alejandro Carrasco,Richard Linares*

Main category: cs.RO

TL;DR: BEAVR是一个开源的、双手多体现的VR远程操作系统，用于机器人，支持实时控制、数据记录和策略学习，兼容多种机器人平台。


<details>
  <summary>Details</summary>
Motivation: 设计BEAVR的目的是为了统一异构机器人平台的实时控制、数据记录和策略学习，提高远程操作的灵活性和效率。

Method: BEAVR采用零拷贝流架构实现低延迟（≤35ms），支持异步“思考-行动”控制循环和模块化集成，兼容多种机器人。

Result: BEAVR在多种操作任务中表现优异，兼容主流视觉运动策略（如ACT、DiffusionPolicy、SmolVLA）。

Conclusion: BEAVR是一个高效、灵活的VR远程操作系统，适用于多机器人平台，代码和数据已开源。

Abstract: \textbf{BEAVR} is an open-source, bimanual, multi-embodiment Virtual Reality
(VR) teleoperation system for robots, designed to unify real-time control, data
recording, and policy learning across heterogeneous robotic platforms. BEAVR
enables real-time, dexterous teleoperation using commodity VR hardware,
supports modular integration with robots ranging from 7-DoF manipulators to
full-body humanoids, and records synchronized multi-modal demonstrations
directly in the LeRobot dataset schema. Our system features a zero-copy
streaming architecture achieving $\leq$35\,ms latency, an asynchronous
``think--act'' control loop for scalable inference, and a flexible network API
optimized for real-time, multi-robot operation. We benchmark BEAVR across
diverse manipulation tasks and demonstrate its compatibility with leading
visuomotor policies such as ACT, DiffusionPolicy, and SmolVLA. All code is
publicly available, and datasets are released on Hugging Face\footnote{Code,
datasets, and VR app available at https://github.com/ARCLab-MIT/BEAVR-Bot.

</details>


### [24] [Interpretable Robot Control via Structured Behavior Trees and Large Language Models](https://arxiv.org/abs/2508.09621)
*Ingrid Maéva Chekam,Ines Pastor-Martinez,Ali Tourani,Jose Andres Millan-Romera,Laura Ribeiro,Pedro Miguel Bastos Soares,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: 提出了一种结合大型语言模型（LLMs）和行为树的新框架，用于自然语言指令的机器人执行，实验显示其认知到执行的准确率约为94%。


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制方法需要用户适应界面或记忆预定义命令，限制了在动态非结构化环境中的可用性，因此需要更自然、可靠的人机交互（HRI）接口。

Method: 结合LLMs和行为树，通过激活特定领域插件将自然语言指令翻译为可执行动作，支持模块化集成，重点关注基于感知的功能（如人员跟踪和手势识别）。

Result: 在多样化环境中进行实验，平均认知到执行准确率约为94%，验证了框架的实用性。

Conclusion: 该框架显著提升了HRI系统的自然性和可靠性，源代码已公开。

Abstract: As intelligent robots become more integrated into human environments, there
is a growing need for intuitive and reliable Human-Robot Interaction (HRI)
interfaces that are adaptable and more natural to interact with. Traditional
robot control methods often require users to adapt to interfaces or memorize
predefined commands, limiting usability in dynamic, unstructured environments.
This paper presents a novel framework that bridges natural language
understanding and robotic execution by combining Large Language Models (LLMs)
with Behavior Trees. This integration enables robots to interpret natural
language instructions given by users and translate them into executable actions
by activating domain-specific plugins. The system supports scalable and modular
integration, with a primary focus on perception-based functionalities, such as
person tracking and hand gesture recognition. To evaluate the system, a series
of real-world experiments was conducted across diverse environments.
Experimental results demonstrate that the proposed approach is practical in
real-world scenarios, with an average cognition-to-execution accuracy of
approximately 94%, making a significant contribution to HRI systems and robots.
The complete source code of the framework is publicly available at
https://github.com/snt-arg/robot_suite.

</details>


### [25] [Immersive Teleoperation of Beyond-Human-Scale Robotic Manipulators: Challenges and Future Directions](https://arxiv.org/abs/2508.09700)
*Mahdi Hejrati,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文探讨了超大型机器人操纵器（BHSRMs）的远程操作挑战，重点关注控制、认知和界面设计，以提升操作安全性和人机协作效果。


<details>
  <summary>Details</summary>
Motivation: 随着BHSRMs在工业领域的应用增加，需要重新设计沉浸式界面以支持安全、高效的人机协作。

Method: 分析了触觉和视觉反馈系统的设计权衡，并通过实验比较了外骨骼和摇杆控制方案。

Result: 提出了针对大型机器人远程操作的新评估工具、扩展策略和以人为中心的安全模型。

Conclusion: 研究为BHSRMs的沉浸式远程操作提供了关键设计方向和安全框架。

Abstract: Teleoperation of beyond-human-scale robotic manipulators (BHSRMs) presents
unique challenges that differ fundamentally from conventional human-scale
systems. As these platforms gain relevance in industrial domains such as
construction, mining, and disaster response, immersive interfaces must be
rethought to support scalable, safe, and effective human-robot collaboration.
This paper investigates the control, cognitive, and interface-level challenges
of immersive teleoperation in BHSRMs, with a focus on ensuring operator safety,
minimizing sensorimotor mismatch, and enhancing the sense of embodiment. We
analyze design trade-offs in haptic and visual feedback systems, supported by
early experimental comparisons of exoskeleton- and joystick-based control
setups. Finally, we outline key research directions for developing new
evaluation tools, scaling strategies, and human-centered safety models tailored
to large-scale robotic telepresence.

</details>


### [26] [FLARE: Agile Flights for Quadrotor Cable-Suspended Payload System via Reinforcement Learning](https://arxiv.org/abs/2508.09797)
*Dongcheng Cao,Jin Zhou,Xian Wang,Shuo Li*

Main category: cs.RO

TL;DR: FLARE是一个基于强化学习的框架，用于解决四旋翼悬挂负载系统的敏捷飞行问题，显著优于传统优化方法，并实现零射击模拟到现实的迁移。


<details>
  <summary>Details</summary>
Motivation: 四旋翼悬挂负载系统的动态特性复杂，传统优化方法计算成本高且难以处理电缆模式转换，限制了实时性和机动性。

Method: 采用强化学习框架FLARE，直接从高保真模拟中学习敏捷导航策略。

Result: 在三个挑战性场景中，FLARE比最先进的优化方法快3倍，并成功实现零射击模拟到现实的迁移。

Conclusion: FLARE展示了在实时性和安全性方面的卓越表现，适用于实际应用。

Abstract: Agile flight for the quadrotor cable-suspended payload system is a formidable
challenge due to its underactuated, highly nonlinear, and hybrid dynamics.
Traditional optimization-based methods often struggle with high computational
costs and the complexities of cable mode transitions, limiting their real-time
applicability and maneuverability exploitation. In this letter, we present
FLARE, a reinforcement learning (RL) framework that directly learns agile
navigation policy from high-fidelity simulation. Our method is validated across
three designed challenging scenarios, notably outperforming a state-of-the-art
optimization-based approach by a 3x speedup during gate traversal maneuvers.
Furthermore, the learned policies achieve successful zero-shot sim-to-real
transfer, demonstrating remarkable agility and safety in real-world
experiments, running in real time on an onboard computer.

</details>


### [27] [Embodied Tactile Perception of Soft Objects Properties](https://arxiv.org/abs/2508.09836)
*Anirvan Dutta,Alexis WM Devillard,Zhihuan Zhang,Xiaoxiao Cheng,Etienne Burdet*

Main category: cs.RO

TL;DR: 研究探讨了机械顺应性、多模态传感和交互策略如何共同影响机器人触觉感知，提出了一种无监督的深度状态空间模型，证明多模态传感优于单模态传感。


<details>
  <summary>Details</summary>
Motivation: 为了实现机器人像人类一样的精细操作，需要理解机械顺应性、多模态传感和交互策略如何共同塑造触觉感知。

Method: 使用模块化电子皮肤（e-Skin）和一组软波物体，通过按压、滑动等动作探索触觉感知，并提出无监督的深度状态空间模型（潜在滤波器）。

Result: 多模态传感表现优于单模态传感，揭示了电子皮肤机械属性与环境之间的复杂交互作用。

Conclusion: 研究强调了结合时间动态分析机械属性和交互的重要性，为机器人触觉感知提供了可推广且可解释的表示。

Abstract: To enable robots to develop human-like fine manipulation, it is essential to
understand how mechanical compliance, multi-modal sensing, and purposeful
interaction jointly shape tactile perception. In this study, we use a dedicated
modular e-Skin with tunable mechanical compliance and multi-modal sensing
(normal, shear forces and vibrations) to systematically investigate how sensing
embodiment and interaction strategies influence robotic perception of objects.
Leveraging a curated set of soft wave objects with controlled viscoelastic and
surface properties, we explore a rich set of palpation primitives-pressing,
precession, sliding that vary indentation depth, frequency, and directionality.
In addition, we propose the latent filter, an unsupervised, action-conditioned
deep state-space model of the sophisticated interaction dynamics and infer
causal mechanical properties into a structured latent space. This provides
generalizable and in-depth interpretable representation of how embodiment and
interaction determine and influence perception. Our investigation demonstrates
that multi-modal sensing outperforms uni-modal sensing. It highlights a nuanced
interaction between the environment and mechanical properties of e-Skin, which
should be examined alongside the interaction by incorporating temporal
dynamics.

</details>


### [28] [Whole-Body Bilateral Teleoperation with Multi-Stage Object Parameter Estimation for Wheeled Humanoid Locomanipulation](https://arxiv.org/abs/2508.09846)
*Donghoon Baek,Amartya Purushottam,Jason J. Choi,Joao Ramos*

Main category: cs.RO

TL;DR: 提出了一种面向轮式人形机器人的物体感知全身双边遥操作框架，结合在线多阶段物体惯性参数估计模块，显著提升了操作效率和动态同步能力。


<details>
  <summary>Details</summary>
Motivation: 解决轮式人形机器人在遥操作中因物体动态参数未知导致的同步和操作效率问题，提升动态任务执行能力。

Method: 采用多阶段惯性参数估计，结合视觉尺寸估计、大型视觉语言模型（VLM）先验和分层采样策略，实时更新参数并应用于机器人控制。

Result: 在定制轮式人形机器人上验证，成功执行实时搬运任务，负载约为机器人自重三分之一。

Conclusion: 该框架通过动态参数补偿提升了遥操作的动态同步和操作效率，适用于复杂任务场景。

Abstract: This paper presents an object-aware whole-body bilateral teleoperation
framework for wheeled humanoid loco-manipulation. This framework combines
whole-body bilateral teleoperation with an online multi-stage object inertial
parameter estimation module, which is the core technical contribution of this
work. The multi-stage process sequentially integrates a vision-based object
size estimator, an initial parameter guess generated by a large vision-language
model (VLM), and a decoupled hierarchical sampling strategy. The visual size
estimate and VLM prior offer a strong initial guess of the object's inertial
parameters, significantly reducing the search space for sampling-based
refinement and improving the overall estimation speed. A hierarchical strategy
first estimates mass and center of mass, then infers inertia from object size
to ensure physically feasible parameters, while a decoupled multi-hypothesis
scheme enhances robustness to VLM prior errors. Our estimator operates in
parallel with high-fidelity simulation and hardware, enabling real-time online
updates. The estimated parameters are then used to update the wheeled
humanoid's equilibrium point, allowing the operator to focus more on locomotion
and manipulation. This integration improves the haptic force feedback for
dynamic synchronization, enabling more dynamic whole-body teleoperation. By
compensating for object dynamics using the estimated parameters, the framework
also improves manipulation tracking while preserving compliant behavior. We
validate the system on a customized wheeled humanoid with a robotic gripper and
human-machine interface, demonstrating real-time execution of lifting,
delivering, and releasing tasks with a payload weighing approximately one-third
of the robot's body weight.

</details>


### [29] [Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes](https://arxiv.org/abs/2508.09855)
*Yuekun Wu,Yik Lung Pang,Andrea Cavallaro,Changjae Oh*

Main category: cs.RO

TL;DR: 提出了一种仅通过RGB图像训练人机协作策略的方法，无需真实机器人数据，解决了仿真与真实场景的视觉差异问题。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中真实机器人数据收集成本高及仿真与真实场景视觉差异的问题。

Method: 利用稀疏视图高斯泼溅重建人机交接场景，生成图像-动作对，通过模拟相机姿态变化训练机器人策略。

Result: 在重建场景和真实人机交接实验中验证了方法的有效性，实现了稳定抓取和避障。

Conclusion: 该方法为人机交接任务提供了新的有效表示，提升了人机协作的流畅性和鲁棒性。

Abstract: Human-robot teaming (HRT) systems often rely on large-scale datasets of human
and robot interactions, especially for close-proximity collaboration tasks such
as human-robot handovers. Learning robot manipulation policies from raw,
real-world image data requires a large number of robot-action trials in the
physical environment. Although simulation training offers a cost-effective
alternative, the visual domain gap between simulation and robot workspace
remains a major limitation. We introduce a method for training HRT policies,
focusing on human-to-robot handovers, solely from RGB images without the need
for real-robot training or real-robot data collection. The goal is to enable
the robot to reliably receive objects from a human with stable grasping while
avoiding collisions with the human hand. The proposed policy learner leverages
sparse-view Gaussian Splatting reconstruction of human-to-robot handover scenes
to generate robot demonstrations containing image-action pairs captured with a
camera mounted on the robot gripper. As a result, the simulated camera pose
changes in the reconstructed scene can be directly translated into gripper pose
changes. Experiments in both Gaussian Splatting reconstructed scene and
real-world human-to-robot handover experiments demonstrate that our method
serves as a new and effective representation for the human-to-robot handover
task, contributing to more seamless and robust HRT.

</details>


### [30] [A Shank Angle-Based Control System Enables Soft Exoskeleton to Assist Human Non-Steady Locomotion](https://arxiv.org/abs/2508.09876)
*Xiaowei Tan,Weizhong Jiang,Bi Zhang,Wanxin Chen,Yiwen Zhao,Ning Li,Lianqing Liu,Xingang Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于小腿角度的外骨骼控制系统，适用于非稳态步态，能实时协调并动态调整助力模式。


<details>
  <summary>Details</summary>
Motivation: 探索外骨骼在非线性步态（如行走、跑步、上下楼梯）中的效果，解决现有研究不足。

Method: 采用双高斯模型生成在线助力模式，结合模型前馈控制，仅需IMU数据适应个体差异。

Result: 实验验证了系统在多种活动中的鲁棒性，用户对外骨骼助力表现出积极的生物力学和生理反应。

Conclusion: 该系统为非稳态步态下的外骨骼控制提供了有效解决方案，具有实际应用潜力。

Abstract: Exoskeletons have been shown to effectively assist humans during steady
locomotion. However, their effects on non-steady locomotion, characterized by
nonlinear phase progression within a gait cycle, remain insufficiently
explored, particularly across diverse activities. This work presents a shank
angle-based control system that enables the exoskeleton to maintain real-time
coordination with human gait, even under phase perturbations, while dynamically
shaping assistance profiles to match the biological ankle moment patterns
across walking, running, stair negotiation tasks. The control system consists
of an assistance profile online generation method and a model-based feedforward
control method. The assistance profile is formulated as a dual-Gaussian model
with the shank angle as the independent variable. Leveraging only IMU
measurements, the model parameters are updated online each stride to adapt to
inter- and intra-individual biomechanical variability. The profile tracking
control employs a human-exoskeleton kinematics and stiffness model as a
feedforward component, reducing reliance on historical control data due to the
lack of clear and consistent periodicity in non-steady locomotion. Three
experiments were conducted using a lightweight soft exoskeleton with multiple
subjects. The results validated the effectiveness of each individual method,
demonstrated the robustness of the control system against gait perturbations
across various activities, and revealed positive biomechanical and
physiological responses of human users to the exoskeleton's mechanical
assistance.

</details>


### [31] [QuickGrasp: Lightweight Antipodal Grasp Planning with Point Clouds](https://arxiv.org/abs/2504.19716)
*Navin Sriram Ravie,Keerthi Vasan M,Asokan Thondiyath,Bijo Sebastian*

Main category: cs.RO

TL;DR: 本文提出了一种轻量级的分析方法用于机器人抓取规划，特别是对向抓取，减少了六自由度空间的采样需求。通过优化问题估计物体表面的抓取点，并采用软区域生长算法进行平面分割。实验表明，该方法在模拟和真实环境中优于现有方法GPD。


<details>
  <summary>Details</summary>
Motivation: 现有抓取规划方法在真实环境中泛化能力差、效率低且缺乏可重复性，限制了其实际应用。本文旨在解决这些问题。

Method: 提出了一种基于优化的抓取点估计方法，结合软区域生长算法进行平面分割，并通过优化质量指标评估抓取点。

Result: 在模拟和真实环境中，该方法优于现有方法Grasp pose detection (GPD)，表现出更高的效率和可靠性。

Conclusion: 该方法为机器人抓取规划提供了一种高效、可靠的解决方案，适用于复杂环境中的实际应用。

Abstract: Grasping has been a long-standing challenge in facilitating the final
interface between a robot and the environment. As environments and tasks become
complicated, the need to embed higher intelligence to infer from the
surroundings and act on them has become necessary. Although most methods
utilize techniques to estimate grasp pose by treating the problem via pure
sampling-based approaches in the six-degree-of-freedom space or as a learning
problem, they usually fail in real-life settings owing to poor generalization
across domains. In addition, the time taken to generate the grasp plan and the
lack of repeatability, owing to sampling inefficiency and the probabilistic
nature of existing grasp planning approaches, severely limits their application
in real-world tasks. This paper presents a lightweight analytical approach
towards robotic grasp planning, particularly antipodal grasps, with little to
no sampling in the six-degree-of-freedom space. The proposed grasp planning
algorithm is formulated as an optimization problem towards estimating grasp
points on the object surface instead of directly estimating the end-effector
pose. To this extent, a soft-region-growing algorithm is presented for
effective plane segmentation, even in the case of curved surfaces. An
optimization-based quality metric is then used for the evaluation of grasp
points to ensure indirect force closure. The proposed grasp framework is
compared with the existing state-of-the-art grasp planning approach, Grasp pose
detection (GPD), as a baseline over multiple simulated objects. The
effectiveness of the proposed approach in comparison to GPD is also evaluated
in a real-world setting using image and point-cloud data, with the planned
grasps being executed using a ROBOTIQ gripper and UR5 manipulator.

</details>


### [32] [PPL: Point Cloud Supervised Proprioceptive Locomotion Reinforcement Learning for Legged Robots in Crawl Spaces](https://arxiv.org/abs/2508.09950)
*Bida Ma,Nuo Xu,Chenkun Qi,Xin Liu,Yule Mo,Jinkai Wang,Chunpeng Lu*

Main category: cs.RO

TL;DR: 提出了一种基于点云监督的腿部机器人爬行空间强化学习方法，通过历史本体感受数据估计环境特征，无需外部传感器。


<details>
  <summary>Details</summary>
Motivation: 解决现有外部感知方法在低能见度下噪声大、本体感知方法难以推断空间特征的问题。

Method: 设计状态估计网络，利用极坐标点云处理提取地面和空间特征，结合奖励函数指导机器人运动。

Result: 实验表明，该方法在爬行空间中比现有方法更灵活。

Conclusion: 该方法提升了腿部机器人在受限空间中的运动能力，无需依赖外部传感器。

Abstract: The legged locomotion in spatially constrained structures (called crawl
spaces) is challenging. In crawl spaces, current exteroceptive locomotion
learning methods are limited by large noises and errors of the sensors in
possible low visibility conditions, and current proprioceptive locomotion
learning methods are difficult in traversing crawl spaces because only ground
features are inferred. In this study, a point cloud supervised proprioceptive
locomotion reinforcement learning method for legged robots in crawl spaces is
proposed. A state estimation network is designed to estimate the robot's
surrounding ground and spatial features as well as the robot's collision states
using historical proprioceptive sensor data. The point cloud is represented in
polar coordinate frame and a point cloud processing method is proposed to
efficiently extract the ground and spatial features that are used to supervise
the state estimation network learning. Comprehensive reward functions that
guide the robot to traverse through crawl spaces after collisions are designed.
Experiments demonstrate that, compared to existing methods, our method exhibits
more agile locomotion in crawl spaces. This study enhances the ability of
legged robots to traverse spatially constrained environments without requiring
exteroceptive sensors.

</details>


### [33] [GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation](https://arxiv.org/abs/2508.09960)
*Yifei Yao,Chengyuan Luo,Jiaheng Du,Wentao He,Jun-Guo Lu*

Main category: cs.RO

TL;DR: 论文提出了一种通用行为克隆（GBC）框架，通过自适应数据管道、DAgger-MMPPO算法和开源平台，实现了从人类动作到机器人行为的统一解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人开发面临数据和学习算法无法跨形态通用的挑战，阻碍了人形机器人的发展。

Method: GBC框架包含三个创新：自适应数据管道、DAgger-MMPPO算法和基于Isaac Lab的开源平台。

Result: 在多种异构人形机器人上验证了GBC的性能和泛化能力，表现优异。

Conclusion: GBC为创建通用人形控制器提供了首个实用且统一的解决方案。

Abstract: The creation of human-like humanoid robots is hindered by a fundamental
fragmentation: data processing and learning algorithms are rarely universal
across different robot morphologies. This paper introduces the Generalized
Behavior Cloning (GBC) framework, a comprehensive and unified solution designed
to solve this end-to-end challenge. GBC establishes a complete pathway from
human motion to robot action through three synergistic innovations. First, an
adaptive data pipeline leverages a differentiable IK network to automatically
retarget any human MoCap data to any humanoid. Building on this foundation, our
novel DAgger-MMPPO algorithm with its MMTransformer architecture learns robust,
high-fidelity imitation policies. To complete the ecosystem, the entire
framework is delivered as an efficient, open-source platform based on Isaac
Lab, empowering the community to deploy the full workflow via simple
configuration scripts. We validate the power and generality of GBC by training
policies on multiple heterogeneous humanoids, demonstrating excellent
performance and transfer to novel motions. This work establishes the first
practical and unified pathway for creating truly generalized humanoid
controllers.

</details>


### [34] [Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model](https://arxiv.org/abs/2508.09971)
*Zihan Wang,Nina Mahmoudian*

Main category: cs.RO

TL;DR: 论文提出了一种基于视觉的无人机自主河流跟踪方法，通过子模马尔可夫决策过程、边际增益优势估计和语义动态模型，实现了高效且安全的河流覆盖控制。


<details>
  <summary>Details</summary>
Motivation: 在密集河流环境中，GPS信号不可靠，视觉驱动的无人机自主河流跟踪对救援、监视和环境监测等应用至关重要。

Method: 1. 提出边际增益优势估计（MGAE）优化奖励优势函数；2. 开发基于语义掩码的语义动态模型（SDM）；3. 设计约束演员动态估计器（CADE）架构，整合模型与安全强化学习。

Result: MGAE比传统方法收敛更快且性能更优；SDM提供更准确的短期状态预测；CADE成功将安全约束整合到模型强化学习中。

Conclusion: 该方法在非马尔可夫环境中高效且安全地解决了河流跟踪问题，为无人机在复杂环境中的应用提供了新思路。

Abstract: Vision-driven autonomous river following by Unmanned Aerial Vehicles is
critical for applications such as rescue, surveillance, and environmental
monitoring, particularly in dense riverine environments where GPS signals are
unreliable. We formalize river following as a coverage control problem in which
the reward function is submodular, yielding diminishing returns as more unique
river segments are visited, thereby framing the task as a Submodular Markov
Decision Process. First, we introduce Marginal Gain Advantage Estimation, which
refines the reward advantage function by using a sliding window baseline
computed from historical episodic returns, thus aligning the advantage
estimation with the agent's evolving recognition of action value in
non-Markovian settings. Second, we develop a Semantic Dynamics Model based on
patchified water semantic masks that provides more interpretable and
data-efficient short-term prediction of future observations compared to latent
vision dynamics models. Third, we present the Constrained Actor Dynamics
Estimator architecture, which integrates the actor, the cost estimator, and SDM
for cost advantage estimation to form a model-based SafeRL framework capable of
solving partially observable Constrained Submodular Markov Decision Processes.
Simulation results demonstrate that MGAE achieves faster convergence and
superior performance over traditional critic-based methods like Generalized
Advantage Estimation. SDM provides more accurate short-term state predictions
that enable the cost estimator to better predict potential violations. Overall,
CADE effectively integrates safety regulation into model-based RL, with the
Lagrangian approach achieving the soft balance of reward and safety during
training, while the safety layer enhances performance during inference by hard
action overlay.

</details>


### [35] [Masquerade: Learning from In-the-wild Human Videos using Data-Editing](https://arxiv.org/abs/2508.09976)
*Marion Lepert,Jiaying Fang,Jeannette Bohg*

Main category: cs.RO

TL;DR: Masquerade方法通过编辑人类视频生成机器人演示，显著提升机器人策略的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人操作研究数据稀缺，人类视频资源丰富但视觉体现差异大，需弥合这一差距。

Method: 编辑人类视频：估计3D手部姿势、修复手臂、叠加机器人轨迹，预训练视觉编码器并微调扩散策略。

Result: 在三个未见场景的长时程任务中，性能优于基线5-6倍。

Conclusion: 通过视觉体现差距弥合，人类视频成为提升机器人策略的有效数据源。

Abstract: Robot manipulation research still suffers from significant data scarcity:
even the largest robot datasets are orders of magnitude smaller and less
diverse than those that fueled recent breakthroughs in language and vision. We
introduce Masquerade, a method that edits in-the-wild egocentric human videos
to bridge the visual embodiment gap between humans and robots and then learns a
robot policy with these edited videos. Our pipeline turns each human video into
robotized demonstrations by (i) estimating 3-D hand poses, (ii) inpainting the
human arms, and (iii) overlaying a rendered bimanual robot that tracks the
recovered end-effector trajectories. Pre-training a visual encoder to predict
future 2-D robot keypoints on 675K frames of these edited clips, and continuing
that auxiliary loss while fine-tuning a diffusion policy head on only 50 robot
demonstrations per task, yields policies that generalize significantly better
than prior work. On three long-horizon, bimanual kitchen tasks evaluated in
three unseen scenes each, Masquerade outperforms baselines by 5-6x. Ablations
show that both the robot overlay and co-training are indispensable, and
performance scales logarithmically with the amount of edited human video. These
results demonstrate that explicitly closing the visual embodiment gap unlocks a
vast, readily available source of data from human videos that can be used to
improve robot policies.

</details>
